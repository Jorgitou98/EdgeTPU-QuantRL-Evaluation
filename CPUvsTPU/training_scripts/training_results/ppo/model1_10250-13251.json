["{\"n\": 10250, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10712.023, \"total_train_time_s\": 14.364710807800293}", "{\"n\": 10251, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10513.315, \"total_train_time_s\": 13.785037279129028}", "{\"n\": 10252, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10375.905, \"total_train_time_s\": 13.90858507156372}", "{\"n\": 10253, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10105.055, \"total_train_time_s\": 12.803784370422363}", "{\"n\": 10254, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9947.286, \"total_train_time_s\": 12.862924814224243}", "{\"n\": 10255, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10010.707, \"total_train_time_s\": 13.801815271377563}", "{\"n\": 10256, \"episode_reward_min\": 1.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3906.0, \"learn_time_ms\": 10025.521, \"total_train_time_s\": 13.881587266921997}", "{\"n\": 10257, \"episode_reward_min\": 1.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3955.5, \"learn_time_ms\": 9955.905, \"total_train_time_s\": 13.080788373947144}", "{\"n\": 10258, \"episode_reward_min\": -4.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 4095.0, \"learn_time_ms\": 10044.26, \"total_train_time_s\": 14.336413145065308}", "{\"n\": 10259, \"episode_reward_min\": -4.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 4095.0, \"learn_time_ms\": 10021.871, \"total_train_time_s\": 13.463256359100342}", "{\"n\": 10260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6666666666666666, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.3333333333335, \"learn_time_ms\": 9984.796, \"total_train_time_s\": 13.96824049949646}", "{\"n\": 10261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.375, \"learn_time_ms\": 9895.536, \"total_train_time_s\": 13.25964641571045}", "{\"n\": 10262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.375, \"learn_time_ms\": 9869.677, \"total_train_time_s\": 13.74494481086731}", "{\"n\": 10263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3333333333333333, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.0, \"learn_time_ms\": 9963.658, \"total_train_time_s\": 13.763473510742188}", "{\"n\": 10264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.2, \"learn_time_ms\": 9968.747, \"total_train_time_s\": 12.998075246810913}", "{\"n\": 10265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3333333333333333, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3813.4166666666665, \"learn_time_ms\": 9964.471, \"total_train_time_s\": 13.935261964797974}", "{\"n\": 10266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3333333333333333, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3813.4166666666665, \"learn_time_ms\": 10038.079, \"total_train_time_s\": 14.647152423858643}", "{\"n\": 10267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7692307692307692, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.846153846154, \"learn_time_ms\": 10025.82, \"total_train_time_s\": 13.203738689422607}", "{\"n\": 10268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7142857142857142, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3786.0714285714284, \"learn_time_ms\": 9863.076, \"total_train_time_s\": 13.117215633392334}", "{\"n\": 10269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5625, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.4375, \"learn_time_ms\": 9836.216, \"total_train_time_s\": 13.074308633804321}", "{\"n\": 10270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5625, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.4375, \"learn_time_ms\": 9748.448, \"total_train_time_s\": 13.026206731796265}", "{\"n\": 10271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8888888888888888, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.8888888888887, \"learn_time_ms\": 9788.592, \"total_train_time_s\": 13.437093019485474}", "{\"n\": 10272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4736842105263157, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3763.0526315789475, \"learn_time_ms\": 9774.934, \"total_train_time_s\": 13.304837703704834}", "{\"n\": 10273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.85, \"learn_time_ms\": 9866.237, \"total_train_time_s\": 14.784794807434082}", "{\"n\": 10274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.85, \"learn_time_ms\": 9979.211, \"total_train_time_s\": 14.080971002578735}", "{\"n\": 10275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0454545454545454, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.6363636363635, \"learn_time_ms\": 10070.274, \"total_train_time_s\": 14.813746452331543}", "{\"n\": 10276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5217391304347827, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.304347826087, \"learn_time_ms\": 9953.166, \"total_train_time_s\": 13.379175662994385}", "{\"n\": 10277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4166666666666667, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3728.5833333333335, \"learn_time_ms\": 9936.365, \"total_train_time_s\": 12.653892517089844}", "{\"n\": 10278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.0, \"learn_time_ms\": 9976.904, \"total_train_time_s\": 13.112090826034546}", "{\"n\": 10279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3703703703703705, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3742.5185185185187, \"learn_time_ms\": 9982.599, \"total_train_time_s\": 13.279639482498169}", "{\"n\": 10280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3703703703703705, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3742.5185185185187, \"learn_time_ms\": 9978.302, \"total_train_time_s\": 13.125911712646484}", "{\"n\": 10281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.2758620689655173, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.793103448276, \"learn_time_ms\": 10090.779, \"total_train_time_s\": 14.721754789352417}", "{\"n\": 10282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3708.1, \"learn_time_ms\": 10028.549, \"total_train_time_s\": 12.83742094039917}", "{\"n\": 10283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4838709677419355, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.516129032258, \"learn_time_ms\": 9920.991, \"total_train_time_s\": 13.647822856903076}", "{\"n\": 10284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.375, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3729.46875, \"learn_time_ms\": 9845.333, \"total_train_time_s\": 13.355435609817505}", "{\"n\": 10285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3529411764705883, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.705882352941, \"learn_time_ms\": 9699.808, \"total_train_time_s\": 13.302684545516968}", "{\"n\": 10286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.2571428571428571, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3697.1714285714284, \"learn_time_ms\": 9733.457, \"total_train_time_s\": 13.667732238769531}", "{\"n\": 10287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9444444444444444, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.4166666666665, \"learn_time_ms\": 9792.799, \"total_train_time_s\": 13.299343585968018}", "{\"n\": 10288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9444444444444444, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.4166666666665, \"learn_time_ms\": 9809.302, \"total_train_time_s\": 13.441829442977905}", "{\"n\": 10289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.810810810811, \"learn_time_ms\": 9850.006, \"total_train_time_s\": 13.715868949890137}", "{\"n\": 10290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.325, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.075, \"learn_time_ms\": 9836.486, \"total_train_time_s\": 13.0191330909729}", "{\"n\": 10291, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.325, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.075, \"learn_time_ms\": 9802.017, \"total_train_time_s\": 14.363402605056763}", "{\"n\": 10292, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.325, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.075, \"learn_time_ms\": 9804.132, \"total_train_time_s\": 13.13987684249878}", "{\"n\": 10293, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5365853658536586, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.0243902439024, \"learn_time_ms\": 9713.709, \"total_train_time_s\": 13.026654958724976}", "{\"n\": 10294, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6363636363636364, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.068181818182, \"learn_time_ms\": 9729.996, \"total_train_time_s\": 13.516862869262695}", "{\"n\": 10295, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6363636363636364, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.068181818182, \"learn_time_ms\": 9874.048, \"total_train_time_s\": 15.153881788253784}", "{\"n\": 10296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6444444444444445, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.2444444444445, \"learn_time_ms\": 9837.279, \"total_train_time_s\": 13.413166761398315}", "{\"n\": 10297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.782608695652174, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.6304347826085, \"learn_time_ms\": 9864.795, \"total_train_time_s\": 13.929887533187866}", "{\"n\": 10298, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8125, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.8958333333335, \"learn_time_ms\": 9814.816, \"total_train_time_s\": 12.724162578582764}", "{\"n\": 10299, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9591836734693877, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.591836734694, \"learn_time_ms\": 9813.271, \"total_train_time_s\": 13.644033908843994}", "{\"n\": 10300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9591836734693877, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.591836734694, \"learn_time_ms\": 9838.992, \"total_train_time_s\": 13.238112688064575}", "{\"n\": 10301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9215686274509803, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.8039215686276, \"learn_time_ms\": 9722.594, \"total_train_time_s\": 13.025227546691895}", "{\"n\": 10302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9230769230769231, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.1153846153848, \"learn_time_ms\": 9710.122, \"total_train_time_s\": 12.518186330795288}", "{\"n\": 10303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0377358490566038, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.4716981132074, \"learn_time_ms\": 9752.786, \"total_train_time_s\": 13.194842100143433}", "{\"n\": 10304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1851851851851851, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.259259259259, \"learn_time_ms\": 9641.588, \"total_train_time_s\": 12.445584535598755}", "{\"n\": 10305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0178571428571428, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.6071428571427, \"learn_time_ms\": 9507.676, \"total_train_time_s\": 13.717383623123169}", "{\"n\": 10306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8245614035087719, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.9122807017543, \"learn_time_ms\": 9590.511, \"total_train_time_s\": 14.425325393676758}", "{\"n\": 10307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9827586206896551, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.2241379310344, \"learn_time_ms\": 9590.59, \"total_train_time_s\": 13.716710805892944}", "{\"n\": 10308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1016949152542372, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.508474576271, \"learn_time_ms\": 9730.645, \"total_train_time_s\": 14.443559885025024}", "{\"n\": 10309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0333333333333334, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.0333333333333, \"learn_time_ms\": 9773.465, \"total_train_time_s\": 13.974182844161987}", "{\"n\": 10310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3064516129032258, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.7741935483873, \"learn_time_ms\": 9782.631, \"total_train_time_s\": 13.366775274276733}", "{\"n\": 10311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4444444444444444, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.1111111111113, \"learn_time_ms\": 9853.826, \"total_train_time_s\": 13.890708446502686}", "{\"n\": 10312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46875, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.640625, \"learn_time_ms\": 9946.485, \"total_train_time_s\": 13.418766021728516}", "{\"n\": 10313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46875, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.640625, \"learn_time_ms\": 9977.616, \"total_train_time_s\": 13.409460306167603}", "{\"n\": 10314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.2878787878787878, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.712121212121, \"learn_time_ms\": 10039.272, \"total_train_time_s\": 12.990821599960327}", "{\"n\": 10315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3880597014925373, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.865671641791, \"learn_time_ms\": 9982.688, \"total_train_time_s\": 12.883413791656494}", "{\"n\": 10316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4852941176470589, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.705882352941, \"learn_time_ms\": 9900.88, \"total_train_time_s\": 13.153232336044312}", "{\"n\": 10317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.536231884057971, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.2753623188405, \"learn_time_ms\": 9938.51, \"total_train_time_s\": 14.284899711608887}", "{\"n\": 10318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5492957746478873, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.3380281690143, \"learn_time_ms\": 9804.875, \"total_train_time_s\": 13.007557153701782}", "{\"n\": 10319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5492957746478873, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.3380281690143, \"learn_time_ms\": 9721.799, \"total_train_time_s\": 13.312294483184814}", "{\"n\": 10320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4722222222222223, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.9444444444443, \"learn_time_ms\": 9837.143, \"total_train_time_s\": 14.414241790771484}", "{\"n\": 10321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6027397260273972, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.821917808219, \"learn_time_ms\": 9847.035, \"total_train_time_s\": 13.897489547729492}", "{\"n\": 10322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5333333333333334, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.9733333333334, \"learn_time_ms\": 9784.005, \"total_train_time_s\": 13.073270797729492}", "{\"n\": 10323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4473684210526316, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.7368421052633, \"learn_time_ms\": 9897.279, \"total_train_time_s\": 14.577661037445068}", "{\"n\": 10324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4473684210526316, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.7368421052633, \"learn_time_ms\": 9969.115, \"total_train_time_s\": 13.712082624435425}", "{\"n\": 10325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5384615384615385, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.2820512820513, \"learn_time_ms\": 10054.273, \"total_train_time_s\": 13.688668489456177}", "{\"n\": 10326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4936708860759493, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.0379746835442, \"learn_time_ms\": 10115.848, \"total_train_time_s\": 14.12087607383728}", "{\"n\": 10327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5875, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.125, \"learn_time_ms\": 10039.819, \"total_train_time_s\": 13.187824726104736}", "{\"n\": 10328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6049382716049383, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.740740740741, \"learn_time_ms\": 10046.669, \"total_train_time_s\": 12.98543095588684}", "{\"n\": 10329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6265060240963856, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.3614457831327, \"learn_time_ms\": 10053.167, \"total_train_time_s\": 13.459153413772583}", "{\"n\": 10330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6265060240963856, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.3614457831327, \"learn_time_ms\": 9919.848, \"total_train_time_s\": 13.112555027008057}", "{\"n\": 10331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.630952380952381, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.4761904761904, \"learn_time_ms\": 9880.153, \"total_train_time_s\": 13.613697052001953}", "{\"n\": 10332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7058823529411764, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.0235294117647, \"learn_time_ms\": 9954.138, \"total_train_time_s\": 13.664347410202026}", "{\"n\": 10333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7093023255813953, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.9302325581393, \"learn_time_ms\": 9820.833, \"total_train_time_s\": 13.24829888343811}", "{\"n\": 10334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6551724137931034, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.1494252873563, \"learn_time_ms\": 9734.517, \"total_train_time_s\": 12.86133337020874}", "{\"n\": 10335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6179775280898876, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.820224719101, \"learn_time_ms\": 9659.666, \"total_train_time_s\": 13.082316160202026}", "{\"n\": 10336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6179775280898876, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.820224719101, \"learn_time_ms\": 9623.757, \"total_train_time_s\": 13.64768934249878}", "{\"n\": 10337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5494505494505495, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.967032967033, \"learn_time_ms\": 9613.073, \"total_train_time_s\": 13.143285989761353}", "{\"n\": 10338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5806451612903225, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.7204301075267, \"learn_time_ms\": 9664.245, \"total_train_time_s\": 13.596809387207031}", "{\"n\": 10339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5806451612903225, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.7204301075267, \"learn_time_ms\": 9697.645, \"total_train_time_s\": 13.81925892829895}", "{\"n\": 10340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6382978723404256, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.0106382978724, \"learn_time_ms\": 9709.139, \"total_train_time_s\": 13.393193483352661}", "{\"n\": 10341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5263157894736843, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.915789473684, \"learn_time_ms\": 9767.289, \"total_train_time_s\": 14.191924095153809}", "{\"n\": 10342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.443298969072165, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.463917525773, \"learn_time_ms\": 9763.576, \"total_train_time_s\": 13.778793096542358}", "{\"n\": 10343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.530612244897959, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.2448979591836, \"learn_time_ms\": 9767.494, \"total_train_time_s\": 13.409760236740112}", "{\"n\": 10344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.530612244897959, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.2448979591836, \"learn_time_ms\": 9780.836, \"total_train_time_s\": 12.972676753997803}", "{\"n\": 10345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5252525252525253, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.4949494949497, \"learn_time_ms\": 9889.848, \"total_train_time_s\": 14.051739931106567}", "{\"n\": 10346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.47, \"learn_time_ms\": 9906.281, \"total_train_time_s\": 13.80016303062439}", "{\"n\": 10347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.47, \"learn_time_ms\": 9877.427, \"total_train_time_s\": 13.229413986206055}", "{\"n\": 10348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.05, \"learn_time_ms\": 9846.218, \"total_train_time_s\": 13.19527530670166}", "{\"n\": 10349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.87, \"learn_time_ms\": 9907.287, \"total_train_time_s\": 14.253835201263428}", "{\"n\": 10350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.05, \"learn_time_ms\": 9906.53, \"total_train_time_s\": 13.4009108543396}", "{\"n\": 10351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.17, \"learn_time_ms\": 9885.354, \"total_train_time_s\": 13.963897228240967}", "{\"n\": 10352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.17, \"learn_time_ms\": 9892.127, \"total_train_time_s\": 13.728601932525635}", "{\"n\": 10353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.89, \"learn_time_ms\": 9943.653, \"total_train_time_s\": 13.936107635498047}", "{\"n\": 10354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.0, \"learn_time_ms\": 9980.491, \"total_train_time_s\": 13.314205884933472}", "{\"n\": 10355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.0, \"learn_time_ms\": 9975.263, \"total_train_time_s\": 14.227360248565674}", "{\"n\": 10356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.31, \"learn_time_ms\": 10006.535, \"total_train_time_s\": 14.17482852935791}", "{\"n\": 10357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.13, \"learn_time_ms\": 10114.047, \"total_train_time_s\": 13.96352767944336}", "{\"n\": 10358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.88, \"learn_time_ms\": 10088.193, \"total_train_time_s\": 13.142797231674194}", "{\"n\": 10359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.69, \"learn_time_ms\": 10095.857, \"total_train_time_s\": 14.56354832649231}", "{\"n\": 10360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.84, \"learn_time_ms\": 10243.619, \"total_train_time_s\": 14.916109800338745}", "{\"n\": 10361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.84, \"learn_time_ms\": 10245.958, \"total_train_time_s\": 13.947521448135376}", "{\"n\": 10362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.17, \"learn_time_ms\": 10257.583, \"total_train_time_s\": 13.79901933670044}", "{\"n\": 10363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.17, \"learn_time_ms\": 10275.488, \"total_train_time_s\": 14.399819374084473}", "{\"n\": 10364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 10275.645, \"total_train_time_s\": 13.42472767829895}", "{\"n\": 10365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 10292.493, \"total_train_time_s\": 14.16960859298706}", "{\"n\": 10366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.72, \"learn_time_ms\": 10315.969, \"total_train_time_s\": 14.386822938919067}", "{\"n\": 10367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.34, \"learn_time_ms\": 10232.725, \"total_train_time_s\": 13.185490131378174}", "{\"n\": 10368, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.28, \"learn_time_ms\": 10255.58, \"total_train_time_s\": 13.337192058563232}", "{\"n\": 10369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.28, \"learn_time_ms\": 10130.696, \"total_train_time_s\": 13.272615432739258}", "{\"n\": 10370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.68, \"learn_time_ms\": 10050.762, \"total_train_time_s\": 13.90871286392212}", "{\"n\": 10371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.93, \"learn_time_ms\": 10098.714, \"total_train_time_s\": 14.393990516662598}", "{\"n\": 10372, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.79, \"learn_time_ms\": 9969.123, \"total_train_time_s\": 12.479760885238647}", "{\"n\": 10373, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.79, \"learn_time_ms\": 9917.376, \"total_train_time_s\": 13.484755277633667}", "{\"n\": 10374, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.11, \"learn_time_ms\": 9958.163, \"total_train_time_s\": 13.916118621826172}", "{\"n\": 10375, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.34, \"learn_time_ms\": 9844.644, \"total_train_time_s\": 13.286618947982788}", "{\"n\": 10376, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 9761.27, \"total_train_time_s\": 13.53466248512268}", "{\"n\": 10377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.68, \"learn_time_ms\": 9732.447, \"total_train_time_s\": 12.799618005752563}", "{\"n\": 10378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.41, \"learn_time_ms\": 9773.568, \"total_train_time_s\": 13.497788906097412}", "{\"n\": 10379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.85, \"learn_time_ms\": 9875.723, \"total_train_time_s\": 14.121744394302368}", "{\"n\": 10380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.48, \"learn_time_ms\": 9892.513, \"total_train_time_s\": 13.98591923713684}", "{\"n\": 10381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.62, \"learn_time_ms\": 9838.01, \"total_train_time_s\": 14.00348424911499}", "{\"n\": 10382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.06, \"learn_time_ms\": 9933.635, \"total_train_time_s\": 13.499936819076538}", "{\"n\": 10383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.34, \"learn_time_ms\": 10094.404, \"total_train_time_s\": 15.36017894744873}", "{\"n\": 10384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.34, \"learn_time_ms\": 10109.37, \"total_train_time_s\": 14.229358911514282}", "{\"n\": 10385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.06, \"learn_time_ms\": 10279.257, \"total_train_time_s\": 14.943861484527588}", "{\"n\": 10386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.68, \"learn_time_ms\": 10323.965, \"total_train_time_s\": 13.89778184890747}", "{\"n\": 10387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.69, \"learn_time_ms\": 10450.166, \"total_train_time_s\": 14.309373140335083}", "{\"n\": 10388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.69, \"learn_time_ms\": 10414.706, \"total_train_time_s\": 13.30937385559082}", "{\"n\": 10389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.43, \"learn_time_ms\": 10409.739, \"total_train_time_s\": 14.009811401367188}", "{\"n\": 10390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.76, \"learn_time_ms\": 10409.674, \"total_train_time_s\": 14.230056047439575}", "{\"n\": 10391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.76, \"learn_time_ms\": 10369.006, \"total_train_time_s\": 13.540089845657349}", "{\"n\": 10392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.21, \"learn_time_ms\": 10414.613, \"total_train_time_s\": 14.035022974014282}", "{\"n\": 10393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.88, \"learn_time_ms\": 10269.897, \"total_train_time_s\": 13.71721887588501}", "{\"n\": 10394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.7, \"learn_time_ms\": 10270.915, \"total_train_time_s\": 13.9814612865448}", "{\"n\": 10395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.7, \"learn_time_ms\": 10071.829, \"total_train_time_s\": 13.145645380020142}", "{\"n\": 10396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.33, \"learn_time_ms\": 9996.406, \"total_train_time_s\": 13.236846208572388}", "{\"n\": 10397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.39, \"learn_time_ms\": 9872.431, \"total_train_time_s\": 12.78725552558899}", "{\"n\": 10398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.25, \"learn_time_ms\": 9886.323, \"total_train_time_s\": 13.240427255630493}", "{\"n\": 10399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.25, \"learn_time_ms\": 9825.954, \"total_train_time_s\": 13.486032485961914}", "{\"n\": 10400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.46, \"learn_time_ms\": 9768.996, \"total_train_time_s\": 13.423033237457275}", "{\"n\": 10401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.16, \"learn_time_ms\": 9750.357, \"total_train_time_s\": 13.178277730941772}", "{\"n\": 10402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.2, \"learn_time_ms\": 9765.009, \"total_train_time_s\": 14.083684206008911}", "{\"n\": 10403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.65, \"learn_time_ms\": 9829.258, \"total_train_time_s\": 14.33617901802063}", "{\"n\": 10404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.65, \"learn_time_ms\": 9801.183, \"total_train_time_s\": 13.975759267807007}", "{\"n\": 10405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3714.69, \"learn_time_ms\": 9917.979, \"total_train_time_s\": 14.141852617263794}", "{\"n\": 10406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.81, \"learn_time_ms\": 10058.624, \"total_train_time_s\": 14.501803159713745}", "{\"n\": 10407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.81, \"learn_time_ms\": 10147.828, \"total_train_time_s\": 13.922768592834473}", "{\"n\": 10408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.81, \"learn_time_ms\": 10146.125, \"total_train_time_s\": 13.30815863609314}", "{\"n\": 10409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.55, \"learn_time_ms\": 10170.325, \"total_train_time_s\": 13.641294956207275}", "{\"n\": 10410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.3, \"learn_time_ms\": 10125.781, \"total_train_time_s\": 13.082828283309937}", "{\"n\": 10411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.3, \"learn_time_ms\": 10107.416, \"total_train_time_s\": 13.20633602142334}", "{\"n\": 10412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.52, \"learn_time_ms\": 10070.349, \"total_train_time_s\": 13.946771144866943}", "{\"n\": 10413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.94, \"learn_time_ms\": 9951.425, \"total_train_time_s\": 13.508093357086182}", "{\"n\": 10414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.27, \"learn_time_ms\": 9910.179, \"total_train_time_s\": 13.250676155090332}", "{\"n\": 10415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.27, \"learn_time_ms\": 9844.088, \"total_train_time_s\": 13.533449649810791}", "{\"n\": 10416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.27, \"learn_time_ms\": 9733.268, \"total_train_time_s\": 13.306199073791504}", "{\"n\": 10417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.33, \"learn_time_ms\": 9655.982, \"total_train_time_s\": 13.105449914932251}", "{\"n\": 10418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.33, \"learn_time_ms\": 9726.782, \"total_train_time_s\": 14.25574278831482}", "{\"n\": 10419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.33, \"learn_time_ms\": 9761.416, \"total_train_time_s\": 14.052115678787231}", "{\"n\": 10420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.72, \"learn_time_ms\": 9803.192, \"total_train_time_s\": 13.422784566879272}", "{\"n\": 10421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.06, \"learn_time_ms\": 9900.998, \"total_train_time_s\": 14.045408964157104}", "{\"n\": 10422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.6, \"learn_time_ms\": 9912.022, \"total_train_time_s\": 13.937406301498413}", "{\"n\": 10423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.6, \"learn_time_ms\": 10023.754, \"total_train_time_s\": 14.435355424880981}", "{\"n\": 10424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.11, \"learn_time_ms\": 10027.087, \"total_train_time_s\": 13.28769040107727}", "{\"n\": 10425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.11, \"learn_time_ms\": 10010.842, \"total_train_time_s\": 13.137301445007324}", "{\"n\": 10426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3714.39, \"learn_time_ms\": 9929.514, \"total_train_time_s\": 12.60490083694458}", "{\"n\": 10427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3714.39, \"learn_time_ms\": 10015.389, \"total_train_time_s\": 14.243829250335693}", "{\"n\": 10428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.19, \"learn_time_ms\": 10051.983, \"total_train_time_s\": 14.450453519821167}", "{\"n\": 10429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.19, \"learn_time_ms\": 9991.767, \"total_train_time_s\": 13.671905755996704}", "{\"n\": 10430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.19, \"learn_time_ms\": 10123.297, \"total_train_time_s\": 14.842037677764893}", "{\"n\": 10431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.72, \"learn_time_ms\": 10117.17, \"total_train_time_s\": 13.940356731414795}", "{\"n\": 10432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.54, \"learn_time_ms\": 10174.964, \"total_train_time_s\": 14.301381587982178}", "{\"n\": 10433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.54, \"learn_time_ms\": 10157.349, \"total_train_time_s\": 14.187921285629272}", "{\"n\": 10434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.54, \"learn_time_ms\": 10216.003, \"total_train_time_s\": 13.988354682922363}", "{\"n\": 10435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.24, \"learn_time_ms\": 10203.887, \"total_train_time_s\": 13.031879663467407}", "{\"n\": 10436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.67, \"learn_time_ms\": 10325.73, \"total_train_time_s\": 13.791598558425903}", "{\"n\": 10437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.67, \"learn_time_ms\": 10209.121, \"total_train_time_s\": 13.014841794967651}", "{\"n\": 10438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.15, \"learn_time_ms\": 10211.755, \"total_train_time_s\": 14.52389645576477}", "{\"n\": 10439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.64, \"learn_time_ms\": 10274.234, \"total_train_time_s\": 14.08259391784668}", "{\"n\": 10440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.64, \"learn_time_ms\": 10299.078, \"total_train_time_s\": 15.410632371902466}", "{\"n\": 10441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.64, \"learn_time_ms\": 10200.557, \"total_train_time_s\": 13.122773885726929}", "{\"n\": 10442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.46, \"learn_time_ms\": 10115.271, \"total_train_time_s\": 13.600795269012451}", "{\"n\": 10443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.81, \"learn_time_ms\": 10031.92, \"total_train_time_s\": 13.368566036224365}", "{\"n\": 10444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.81, \"learn_time_ms\": 10012.514, \"total_train_time_s\": 13.86600375175476}", "{\"n\": 10445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.22, \"learn_time_ms\": 10129.108, \"total_train_time_s\": 14.175856351852417}", "{\"n\": 10446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.8, \"learn_time_ms\": 10199.863, \"total_train_time_s\": 14.699307680130005}", "{\"n\": 10447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.26, \"learn_time_ms\": 10351.433, \"total_train_time_s\": 14.153813123703003}", "{\"n\": 10448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.26, \"learn_time_ms\": 10230.741, \"total_train_time_s\": 13.515383005142212}", "{\"n\": 10449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.53, \"learn_time_ms\": 10216.853, \"total_train_time_s\": 13.848764181137085}", "{\"n\": 10450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.3, \"learn_time_ms\": 9997.429, \"total_train_time_s\": 12.841853618621826}", "{\"n\": 10451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.04, \"learn_time_ms\": 10040.424, \"total_train_time_s\": 13.342168807983398}", "{\"n\": 10452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.99, \"learn_time_ms\": 10072.108, \"total_train_time_s\": 14.057516813278198}", "{\"n\": 10453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.06, \"learn_time_ms\": 10058.864, \"total_train_time_s\": 13.205053091049194}", "{\"n\": 10454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.56, \"learn_time_ms\": 10092.34, \"total_train_time_s\": 14.020384073257446}", "{\"n\": 10455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.9, \"learn_time_ms\": 10077.508, \"total_train_time_s\": 14.128536939620972}", "{\"n\": 10456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.34, \"learn_time_ms\": 10125.023, \"total_train_time_s\": 14.913430452346802}", "{\"n\": 10457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.92, \"learn_time_ms\": 10108.288, \"total_train_time_s\": 14.032702922821045}", "{\"n\": 10458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.61, \"learn_time_ms\": 10104.792, \"total_train_time_s\": 13.178123235702515}", "{\"n\": 10459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.61, \"learn_time_ms\": 10142.911, \"total_train_time_s\": 14.516782522201538}", "{\"n\": 10460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.96, \"learn_time_ms\": 10192.039, \"total_train_time_s\": 13.321006059646606}", "{\"n\": 10461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.51, \"learn_time_ms\": 10201.391, \"total_train_time_s\": 13.57936954498291}", "{\"n\": 10462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.37, \"learn_time_ms\": 10176.76, \"total_train_time_s\": 13.581513404846191}", "{\"n\": 10463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.72, \"learn_time_ms\": 10193.497, \"total_train_time_s\": 13.497843027114868}", "{\"n\": 10464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.72, \"learn_time_ms\": 10077.106, \"total_train_time_s\": 12.970846176147461}", "{\"n\": 10465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.19, \"learn_time_ms\": 9971.974, \"total_train_time_s\": 12.889163494110107}", "{\"n\": 10466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.19, \"learn_time_ms\": 9856.048, \"total_train_time_s\": 13.769115447998047}", "{\"n\": 10467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.82, \"learn_time_ms\": 9845.36, \"total_train_time_s\": 14.071250438690186}", "{\"n\": 10468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.2, \"learn_time_ms\": 9873.104, \"total_train_time_s\": 13.609610557556152}", "{\"n\": 10469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.2, \"learn_time_ms\": 9806.41, \"total_train_time_s\": 13.674301624298096}", "{\"n\": 10470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.88, \"learn_time_ms\": 9811.635, \"total_train_time_s\": 13.281723499298096}", "{\"n\": 10471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 9689.923, \"total_train_time_s\": 12.41373872756958}", "{\"n\": 10472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.39, \"learn_time_ms\": 9584.107, \"total_train_time_s\": 12.57755422592163}", "{\"n\": 10473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.39, \"learn_time_ms\": 9700.95, \"total_train_time_s\": 14.451070785522461}", "{\"n\": 10474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.39, \"learn_time_ms\": 9700.151, \"total_train_time_s\": 13.103207349777222}", "{\"n\": 10475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.19, \"learn_time_ms\": 9777.357, \"total_train_time_s\": 13.732532978057861}", "{\"n\": 10476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.19, \"learn_time_ms\": 9813.008, \"total_train_time_s\": 14.187947273254395}", "{\"n\": 10477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.19, \"learn_time_ms\": 9735.612, \"total_train_time_s\": 13.150347232818604}", "{\"n\": 10478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.52, \"learn_time_ms\": 9736.193, \"total_train_time_s\": 13.638032674789429}", "{\"n\": 10479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.57, \"learn_time_ms\": 9679.737, \"total_train_time_s\": 13.288411617279053}", "{\"n\": 10480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.3, \"learn_time_ms\": 9719.971, \"total_train_time_s\": 14.20348858833313}", "{\"n\": 10481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.3, \"learn_time_ms\": 9819.658, \"total_train_time_s\": 13.306281566619873}", "{\"n\": 10482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.92, \"learn_time_ms\": 9927.009, \"total_train_time_s\": 13.720841407775879}", "{\"n\": 10483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.57, \"learn_time_ms\": 9755.954, \"total_train_time_s\": 12.789654731750488}", "{\"n\": 10484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.57, \"learn_time_ms\": 9887.049, \"total_train_time_s\": 14.19511365890503}", "{\"n\": 10485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.57, \"learn_time_ms\": 9905.708, \"total_train_time_s\": 13.946354866027832}", "{\"n\": 10486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.61, \"learn_time_ms\": 9823.301, \"total_train_time_s\": 13.426244974136353}", "{\"n\": 10487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.61, \"learn_time_ms\": 9848.299, \"total_train_time_s\": 13.595963478088379}", "{\"n\": 10488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.89, \"learn_time_ms\": 9898.345, \"total_train_time_s\": 14.061142921447754}", "{\"n\": 10489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.97, \"learn_time_ms\": 9937.323, \"total_train_time_s\": 13.409507989883423}", "{\"n\": 10490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.25, \"learn_time_ms\": 9946.365, \"total_train_time_s\": 13.821429967880249}", "{\"n\": 10491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.25, \"learn_time_ms\": 9981.3, \"total_train_time_s\": 13.640021324157715}", "{\"n\": 10492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.0, \"learn_time_ms\": 9907.406, \"total_train_time_s\": 13.003055572509766}", "{\"n\": 10493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.54, \"learn_time_ms\": 10095.207, \"total_train_time_s\": 14.848152160644531}", "{\"n\": 10494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.8, \"learn_time_ms\": 10002.63, \"total_train_time_s\": 13.19869351387024}", "{\"n\": 10495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.8, \"learn_time_ms\": 9940.989, \"total_train_time_s\": 13.59389328956604}", "{\"n\": 10496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.14, \"learn_time_ms\": 9952.595, \"total_train_time_s\": 13.583370208740234}", "{\"n\": 10497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.87, \"learn_time_ms\": 9989.41, \"total_train_time_s\": 13.918796062469482}", "{\"n\": 10498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.08, \"learn_time_ms\": 9960.908, \"total_train_time_s\": 13.73831033706665}", "{\"n\": 10499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.65, \"learn_time_ms\": 9944.121, \"total_train_time_s\": 13.402023792266846}", "{\"n\": 10500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.14, \"learn_time_ms\": 9933.234, \"total_train_time_s\": 13.818873643875122}", "{\"n\": 10501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.53, \"learn_time_ms\": 9881.441, \"total_train_time_s\": 13.235187768936157}", "{\"n\": 10502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.92, \"learn_time_ms\": 9912.65, \"total_train_time_s\": 13.29718279838562}", "{\"n\": 10503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.92, \"learn_time_ms\": 9765.164, \"total_train_time_s\": 13.147783041000366}", "{\"n\": 10504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.95, \"learn_time_ms\": 9730.91, \"total_train_time_s\": 12.949689149856567}", "{\"n\": 10505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.7, \"learn_time_ms\": 9664.765, \"total_train_time_s\": 12.814180135726929}", "{\"n\": 10506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.7, \"learn_time_ms\": 9684.916, \"total_train_time_s\": 14.078245162963867}", "{\"n\": 10507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.74, \"learn_time_ms\": 9625.702, \"total_train_time_s\": 13.1521897315979}", "{\"n\": 10508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 9515.231, \"total_train_time_s\": 12.621052742004395}", "{\"n\": 10509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 9478.726, \"total_train_time_s\": 12.842070579528809}", "{\"n\": 10510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 9404.802, \"total_train_time_s\": 13.392672777175903}", "{\"n\": 10511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.6, \"learn_time_ms\": 9502.447, \"total_train_time_s\": 14.040619134902954}", "{\"n\": 10512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.46, \"learn_time_ms\": 9589.925, \"total_train_time_s\": 14.024575471878052}", "{\"n\": 10513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.46, \"learn_time_ms\": 9644.231, \"total_train_time_s\": 14.152353525161743}", "{\"n\": 10514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.82, \"learn_time_ms\": 9629.687, \"total_train_time_s\": 12.688102006912231}", "{\"n\": 10515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.51, \"learn_time_ms\": 9630.612, \"total_train_time_s\": 12.696469783782959}", "{\"n\": 10516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.51, \"learn_time_ms\": 9669.034, \"total_train_time_s\": 14.224148988723755}", "{\"n\": 10517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.51, \"learn_time_ms\": 9675.154, \"total_train_time_s\": 13.348680019378662}", "{\"n\": 10518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.56, \"learn_time_ms\": 9787.626, \"total_train_time_s\": 13.90688967704773}", "{\"n\": 10519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.04, \"learn_time_ms\": 9824.738, \"total_train_time_s\": 13.232055902481079}", "{\"n\": 10520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.04, \"learn_time_ms\": 9890.637, \"total_train_time_s\": 13.803940296173096}", "{\"n\": 10521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.04, \"learn_time_ms\": 9859.939, \"total_train_time_s\": 13.709952354431152}", "{\"n\": 10522, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.47, \"learn_time_ms\": 9734.531, \"total_train_time_s\": 13.035599708557129}", "{\"n\": 10523, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.47, \"learn_time_ms\": 9718.137, \"total_train_time_s\": 13.747645854949951}", "{\"n\": 10524, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.47, \"learn_time_ms\": 9882.3, \"total_train_time_s\": 14.314225673675537}", "{\"n\": 10525, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.54, \"learn_time_ms\": 9993.771, \"total_train_time_s\": 13.824165344238281}", "{\"n\": 10526, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.72, \"learn_time_ms\": 9904.808, \"total_train_time_s\": 13.203205347061157}", "{\"n\": 10527, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.72, \"learn_time_ms\": 9956.822, \"total_train_time_s\": 13.933019638061523}", "{\"n\": 10528, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.72, \"learn_time_ms\": 9881.536, \"total_train_time_s\": 12.98661184310913}", "{\"n\": 10529, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.08, \"learn_time_ms\": 9894.34, \"total_train_time_s\": 13.409350872039795}", "{\"n\": 10530, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.77, \"learn_time_ms\": 9945.603, \"total_train_time_s\": 14.106969833374023}", "{\"n\": 10531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.77, \"learn_time_ms\": 10031.332, \"total_train_time_s\": 14.805502891540527}", "{\"n\": 10532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.76, \"learn_time_ms\": 10089.779, \"total_train_time_s\": 13.488139152526855}", "{\"n\": 10533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.03, \"learn_time_ms\": 10073.419, \"total_train_time_s\": 13.511458396911621}", "{\"n\": 10534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.36, \"learn_time_ms\": 10059.29, \"total_train_time_s\": 14.358872413635254}", "{\"n\": 10535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.38, \"learn_time_ms\": 10009.428, \"total_train_time_s\": 13.188475608825684}", "{\"n\": 10536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.38, \"learn_time_ms\": 10001.982, \"total_train_time_s\": 13.286474466323853}", "{\"n\": 10537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.69, \"learn_time_ms\": 9985.657, \"total_train_time_s\": 13.589796781539917}", "{\"n\": 10538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 10016.448, \"total_train_time_s\": 13.437502145767212}", "{\"n\": 10539, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.39, \"learn_time_ms\": 9953.84, \"total_train_time_s\": 12.837277173995972}", "{\"n\": 10540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.39, \"learn_time_ms\": 9856.759, \"total_train_time_s\": 13.367552280426025}", "{\"n\": 10541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.19, \"learn_time_ms\": 9837.732, \"total_train_time_s\": 14.552741050720215}", "{\"n\": 10542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.19, \"learn_time_ms\": 9813.319, \"total_train_time_s\": 13.08575963973999}", "{\"n\": 10543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.2, \"learn_time_ms\": 9785.122, \"total_train_time_s\": 13.029462099075317}", "{\"n\": 10544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.29, \"learn_time_ms\": 9708.18, \"total_train_time_s\": 13.732087135314941}", "{\"n\": 10545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.17, \"learn_time_ms\": 9786.287, \"total_train_time_s\": 14.045252561569214}", "{\"n\": 10546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.93, \"learn_time_ms\": 9879.411, \"total_train_time_s\": 14.297482967376709}", "{\"n\": 10547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.93, \"learn_time_ms\": 9841.399, \"total_train_time_s\": 13.162180185317993}", "{\"n\": 10548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.4, \"learn_time_ms\": 9936.665, \"total_train_time_s\": 14.269003629684448}", "{\"n\": 10549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.25, \"learn_time_ms\": 10030.504, \"total_train_time_s\": 14.125571012496948}", "{\"n\": 10550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.59, \"learn_time_ms\": 10049.719, \"total_train_time_s\": 13.324980735778809}", "{\"n\": 10551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.06, \"learn_time_ms\": 9983.191, \"total_train_time_s\": 13.95427942276001}", "{\"n\": 10552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.06, \"learn_time_ms\": 9973.713, \"total_train_time_s\": 13.363809823989868}", "{\"n\": 10553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.19, \"learn_time_ms\": 10107.638, \"total_train_time_s\": 14.397511959075928}", "{\"n\": 10554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.61, \"learn_time_ms\": 10118.463, \"total_train_time_s\": 13.639755725860596}", "{\"n\": 10555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.4, \"learn_time_ms\": 10057.361, \"total_train_time_s\": 13.419697284698486}", "{\"n\": 10556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.4, \"learn_time_ms\": 10058.918, \"total_train_time_s\": 14.016673803329468}", "{\"n\": 10557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.65, \"learn_time_ms\": 10173.083, \"total_train_time_s\": 14.854897022247314}", "{\"n\": 10558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.09, \"learn_time_ms\": 10053.372, \"total_train_time_s\": 13.03815245628357}", "{\"n\": 10559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.09, \"learn_time_ms\": 9942.548, \"total_train_time_s\": 12.529832601547241}", "{\"n\": 10560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.3, \"learn_time_ms\": 9989.673, \"total_train_time_s\": 13.985511302947998}", "{\"n\": 10561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.39, \"learn_time_ms\": 9963.275, \"total_train_time_s\": 13.593032360076904}", "{\"n\": 10562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.67, \"learn_time_ms\": 10013.462, \"total_train_time_s\": 13.561805725097656}", "{\"n\": 10563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.43, \"learn_time_ms\": 9986.018, \"total_train_time_s\": 14.135483264923096}", "{\"n\": 10564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.43, \"learn_time_ms\": 9929.509, \"total_train_time_s\": 12.996022701263428}", "{\"n\": 10565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.23, \"learn_time_ms\": 9892.077, \"total_train_time_s\": 13.21253752708435}", "{\"n\": 10566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.79, \"learn_time_ms\": 9871.665, \"total_train_time_s\": 13.952179670333862}", "{\"n\": 10567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.46, \"learn_time_ms\": 9774.422, \"total_train_time_s\": 13.351956129074097}", "{\"n\": 10568, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.46, \"learn_time_ms\": 9849.852, \"total_train_time_s\": 13.777057647705078}", "{\"n\": 10569, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.99, \"learn_time_ms\": 9937.806, \"total_train_time_s\": 13.641806602478027}", "{\"n\": 10570, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3639.24, \"learn_time_ms\": 9889.366, \"total_train_time_s\": 13.479686737060547}", "{\"n\": 10571, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.47, \"learn_time_ms\": 9845.764, \"total_train_time_s\": 13.07712435722351}", "{\"n\": 10572, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.63, \"learn_time_ms\": 9961.95, \"total_train_time_s\": 14.774343729019165}", "{\"n\": 10573, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.99, \"learn_time_ms\": 9890.56, \"total_train_time_s\": 13.546649694442749}", "{\"n\": 10574, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.14, \"learn_time_ms\": 9895.31, \"total_train_time_s\": 13.200801849365234}", "{\"n\": 10575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.01, \"learn_time_ms\": 9961.293, \"total_train_time_s\": 13.76301383972168}", "{\"n\": 10576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.02, \"learn_time_ms\": 9980.27, \"total_train_time_s\": 13.996375560760498}", "{\"n\": 10577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.02, \"learn_time_ms\": 9967.615, \"total_train_time_s\": 13.479357481002808}", "{\"n\": 10578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.83, \"learn_time_ms\": 9928.195, \"total_train_time_s\": 13.264550685882568}", "{\"n\": 10579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 9898.432, \"total_train_time_s\": 13.426223039627075}", "{\"n\": 10580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.89, \"learn_time_ms\": 9904.895, \"total_train_time_s\": 13.43006944656372}", "{\"n\": 10581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.2, \"learn_time_ms\": 9894.285, \"total_train_time_s\": 12.95550537109375}", "{\"n\": 10582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.2, \"learn_time_ms\": 9795.139, \"total_train_time_s\": 13.679755926132202}", "{\"n\": 10583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3637.58, \"learn_time_ms\": 9761.055, \"total_train_time_s\": 13.04135799407959}", "{\"n\": 10584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.39, \"learn_time_ms\": 9692.417, \"total_train_time_s\": 12.40144658088684}", "{\"n\": 10585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.39, \"learn_time_ms\": 9573.422, \"total_train_time_s\": 12.88901972770691}", "{\"n\": 10586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.0, \"learn_time_ms\": 9528.585, \"total_train_time_s\": 13.563653945922852}", "{\"n\": 10587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.09, \"learn_time_ms\": 9598.997, \"total_train_time_s\": 14.227208375930786}", "{\"n\": 10588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.61, \"learn_time_ms\": 9610.349, \"total_train_time_s\": 13.565407037734985}", "{\"n\": 10589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 9693.845, \"total_train_time_s\": 14.153073072433472}", "{\"n\": 10590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 9721.675, \"total_train_time_s\": 13.908780336380005}", "{\"n\": 10591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.73, \"learn_time_ms\": 9777.599, \"total_train_time_s\": 13.608547925949097}", "{\"n\": 10592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.57, \"learn_time_ms\": 9696.076, \"total_train_time_s\": 13.086549997329712}", "{\"n\": 10593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.22, \"learn_time_ms\": 9842.022, \"total_train_time_s\": 14.565177202224731}", "{\"n\": 10594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.69, \"learn_time_ms\": 9988.337, \"total_train_time_s\": 13.863799810409546}", "{\"n\": 10595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.92, \"learn_time_ms\": 10192.991, \"total_train_time_s\": 14.673054218292236}", "{\"n\": 10596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.85, \"learn_time_ms\": 10243.286, \"total_train_time_s\": 14.236486911773682}", "{\"n\": 10597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.85, \"learn_time_ms\": 10179.654, \"total_train_time_s\": 13.276148796081543}", "{\"n\": 10598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3663.81, \"learn_time_ms\": 10132.489, \"total_train_time_s\": 13.174790620803833}", "{\"n\": 10599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.07, \"learn_time_ms\": 10077.704, \"total_train_time_s\": 13.415466785430908}", "{\"n\": 10600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.07, \"learn_time_ms\": 10099.281, \"total_train_time_s\": 13.866204500198364}", "{\"n\": 10601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.07, \"learn_time_ms\": 10109.814, \"total_train_time_s\": 13.830070972442627}", "{\"n\": 10602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.26, \"learn_time_ms\": 10157.545, \"total_train_time_s\": 13.474711656570435}", "{\"n\": 10603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.6, \"learn_time_ms\": 10075.735, \"total_train_time_s\": 14.107353925704956}", "{\"n\": 10604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.6, \"learn_time_ms\": 10141.646, \"total_train_time_s\": 14.526774644851685}", "{\"n\": 10605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3681.66, \"learn_time_ms\": 10032.576, \"total_train_time_s\": 13.556966066360474}", "{\"n\": 10606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3684.41, \"learn_time_ms\": 9922.386, \"total_train_time_s\": 13.1036057472229}", "{\"n\": 10607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.51, \"learn_time_ms\": 9951.274, \"total_train_time_s\": 13.734615564346313}", "{\"n\": 10608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.51, \"learn_time_ms\": 9986.982, \"total_train_time_s\": 13.314740657806396}", "{\"n\": 10609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.63, \"learn_time_ms\": 10027.022, \"total_train_time_s\": 13.995119333267212}", "{\"n\": 10610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.82, \"learn_time_ms\": 10031.7, \"total_train_time_s\": 14.129386186599731}", "{\"n\": 10611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3666.85, \"learn_time_ms\": 9967.802, \"total_train_time_s\": 12.978211164474487}", "{\"n\": 10612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3666.85, \"learn_time_ms\": 9943.47, \"total_train_time_s\": 13.29836368560791}", "{\"n\": 10613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.34, \"learn_time_ms\": 10028.54, \"total_train_time_s\": 14.693470001220703}", "{\"n\": 10614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.63, \"learn_time_ms\": 9879.924, \"total_train_time_s\": 13.008709907531738}", "{\"n\": 10615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.63, \"learn_time_ms\": 9862.582, \"total_train_time_s\": 13.478485107421875}", "{\"n\": 10616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.07, \"learn_time_ms\": 9987.064, \"total_train_time_s\": 14.204114437103271}", "{\"n\": 10617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.8, \"learn_time_ms\": 9995.268, \"total_train_time_s\": 13.972656726837158}", "{\"n\": 10618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.64, \"learn_time_ms\": 9947.776, \"total_train_time_s\": 12.867933511734009}", "{\"n\": 10619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.64, \"learn_time_ms\": 9827.523, \"total_train_time_s\": 12.59437608718872}", "{\"n\": 10620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.64, \"learn_time_ms\": 9733.973, \"total_train_time_s\": 13.218413591384888}", "{\"n\": 10621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.1, \"learn_time_ms\": 9810.482, \"total_train_time_s\": 13.740190744400024}", "{\"n\": 10622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.1, \"learn_time_ms\": 9758.441, \"total_train_time_s\": 12.873904705047607}", "{\"n\": 10623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.1, \"learn_time_ms\": 9680.376, \"total_train_time_s\": 14.15052342414856}", "{\"n\": 10624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.71, \"learn_time_ms\": 9698.059, \"total_train_time_s\": 13.401751041412354}", "{\"n\": 10625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.83, \"learn_time_ms\": 9787.118, \"total_train_time_s\": 14.332821607589722}", "{\"n\": 10626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.83, \"learn_time_ms\": 9732.745, \"total_train_time_s\": 13.657127141952515}", "{\"n\": 10627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.83, \"learn_time_ms\": 9717.216, \"total_train_time_s\": 13.648553133010864}", "{\"n\": 10628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.6, \"learn_time_ms\": 9766.946, \"total_train_time_s\": 13.347048997879028}", "{\"n\": 10629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.54, \"learn_time_ms\": 9832.339, \"total_train_time_s\": 13.400232076644897}", "{\"n\": 10630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.54, \"learn_time_ms\": 9863.001, \"total_train_time_s\": 13.251290321350098}", "{\"n\": 10631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.54, \"learn_time_ms\": 9782.544, \"total_train_time_s\": 12.974584579467773}", "{\"n\": 10632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.54, \"learn_time_ms\": 9792.308, \"total_train_time_s\": 12.669444799423218}", "{\"n\": 10633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.54, \"learn_time_ms\": 9867.729, \"total_train_time_s\": 14.539732456207275}", "{\"n\": 10634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.54, \"learn_time_ms\": 9919.481, \"total_train_time_s\": 13.802803039550781}", "{\"n\": 10635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.03, \"learn_time_ms\": 9858.877, \"total_train_time_s\": 13.733365297317505}", "{\"n\": 10636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.89, \"learn_time_ms\": 9911.092, \"total_train_time_s\": 14.328256845474243}", "{\"n\": 10637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.89, \"learn_time_ms\": 9964.784, \"total_train_time_s\": 14.380178213119507}", "{\"n\": 10638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.89, \"learn_time_ms\": 9963.298, \"total_train_time_s\": 13.573772192001343}", "{\"n\": 10639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.72, \"learn_time_ms\": 9952.383, \"total_train_time_s\": 13.271318435668945}", "{\"n\": 10640, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.53, \"learn_time_ms\": 10010.638, \"total_train_time_s\": 14.021613597869873}", "{\"n\": 10641, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.53, \"learn_time_ms\": 10068.994, \"total_train_time_s\": 13.557177543640137}", "{\"n\": 10642, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.53, \"learn_time_ms\": 10133.201, \"total_train_time_s\": 13.36332368850708}", "{\"n\": 10643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.2, \"learn_time_ms\": 10040.102, \"total_train_time_s\": 13.61198878288269}", "{\"n\": 10644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.09, \"learn_time_ms\": 9996.559, \"total_train_time_s\": 13.310527801513672}", "{\"n\": 10645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.09, \"learn_time_ms\": 9977.613, \"total_train_time_s\": 13.363756895065308}", "{\"n\": 10646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.09, \"learn_time_ms\": 9957.264, \"total_train_time_s\": 14.17647671699524}", "{\"n\": 10647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.47, \"learn_time_ms\": 9880.176, \"total_train_time_s\": 13.294610500335693}", "{\"n\": 10648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 9812.0, \"total_train_time_s\": 12.885555982589722}", "{\"n\": 10649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 9881.482, \"total_train_time_s\": 14.205461740493774}", "{\"n\": 10650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.55, \"learn_time_ms\": 9835.486, \"total_train_time_s\": 13.490919589996338}", "{\"n\": 10651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.55, \"learn_time_ms\": 9831.778, \"total_train_time_s\": 13.493869304656982}", "{\"n\": 10652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.19, \"learn_time_ms\": 9864.952, \"total_train_time_s\": 13.732618808746338}", "{\"n\": 10653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.9, \"learn_time_ms\": 9889.305, \"total_train_time_s\": 14.140824794769287}", "{\"n\": 10654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.67, \"learn_time_ms\": 9909.132, \"total_train_time_s\": 13.451863527297974}", "{\"n\": 10655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.88, \"learn_time_ms\": 9901.737, \"total_train_time_s\": 13.458302021026611}", "{\"n\": 10656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.27, \"learn_time_ms\": 9844.015, \"total_train_time_s\": 13.691314697265625}", "{\"n\": 10657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.49, \"learn_time_ms\": 9878.441, \"total_train_time_s\": 13.657704830169678}", "{\"n\": 10658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.49, \"learn_time_ms\": 10098.88, \"total_train_time_s\": 14.864058256149292}", "{\"n\": 10659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.07, \"learn_time_ms\": 10075.801, \"total_train_time_s\": 13.810344934463501}", "{\"n\": 10660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.52, \"learn_time_ms\": 10110.977, \"total_train_time_s\": 14.047729015350342}", "{\"n\": 10661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.58, \"learn_time_ms\": 10100.041, \"total_train_time_s\": 13.533129453659058}", "{\"n\": 10662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.44, \"learn_time_ms\": 10102.419, \"total_train_time_s\": 13.870006084442139}", "{\"n\": 10663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.15, \"learn_time_ms\": 10012.678, \"total_train_time_s\": 12.974215269088745}", "{\"n\": 10664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.41, \"learn_time_ms\": 9988.23, \"total_train_time_s\": 13.212271690368652}", "{\"n\": 10665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.03, \"learn_time_ms\": 10027.05, \"total_train_time_s\": 13.788461446762085}", "{\"n\": 10666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.18, \"learn_time_ms\": 10137.141, \"total_train_time_s\": 14.769692420959473}", "{\"n\": 10667, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.42, \"learn_time_ms\": 10105.347, \"total_train_time_s\": 13.32381010055542}", "{\"n\": 10668, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.07, \"learn_time_ms\": 9862.898, \"total_train_time_s\": 12.39165711402893}", "{\"n\": 10669, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.07, \"learn_time_ms\": 9810.166, \"total_train_time_s\": 13.165302515029907}", "{\"n\": 10670, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.4, \"learn_time_ms\": 9689.404, \"total_train_time_s\": 12.735422372817993}", "{\"n\": 10671, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.02, \"learn_time_ms\": 9689.798, \"total_train_time_s\": 13.403723001480103}", "{\"n\": 10672, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.34, \"learn_time_ms\": 9666.632, \"total_train_time_s\": 13.648014307022095}", "{\"n\": 10673, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.34, \"learn_time_ms\": 9657.349, \"total_train_time_s\": 13.033584117889404}", "{\"n\": 10674, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.13, \"learn_time_ms\": 9710.82, \"total_train_time_s\": 13.704801559448242}", "{\"n\": 10675, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.9, \"learn_time_ms\": 9631.68, \"total_train_time_s\": 12.953139305114746}", "{\"n\": 10676, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.9, \"learn_time_ms\": 9490.69, \"total_train_time_s\": 13.104169368743896}", "{\"n\": 10677, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.9, \"learn_time_ms\": 9438.992, \"total_train_time_s\": 13.142291069030762}", "{\"n\": 10678, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.13, \"learn_time_ms\": 9570.8, \"total_train_time_s\": 13.766069650650024}", "{\"n\": 10679, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.66, \"learn_time_ms\": 9563.161, \"total_train_time_s\": 13.115237951278687}", "{\"n\": 10680, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.66, \"learn_time_ms\": 9641.664, \"total_train_time_s\": 13.662065029144287}", "{\"n\": 10681, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.48, \"learn_time_ms\": 9733.085, \"total_train_time_s\": 14.236254692077637}", "{\"n\": 10682, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.97, \"learn_time_ms\": 9768.547, \"total_train_time_s\": 14.052819967269897}", "{\"n\": 10683, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.97, \"learn_time_ms\": 9846.997, \"total_train_time_s\": 13.654902935028076}", "{\"n\": 10684, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.97, \"learn_time_ms\": 9775.14, \"total_train_time_s\": 13.320827960968018}", "{\"n\": 10685, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.04, \"learn_time_ms\": 9817.412, \"total_train_time_s\": 13.448656797409058}", "{\"n\": 10686, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.46, \"learn_time_ms\": 9824.469, \"total_train_time_s\": 13.193686485290527}", "{\"n\": 10687, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.46, \"learn_time_ms\": 9894.987, \"total_train_time_s\": 13.475643396377563}", "{\"n\": 10688, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.7, \"learn_time_ms\": 9950.542, \"total_train_time_s\": 14.414394855499268}", "{\"n\": 10689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.72, \"learn_time_ms\": 10142.727, \"total_train_time_s\": 15.165520668029785}", "{\"n\": 10690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 10098.103, \"total_train_time_s\": 13.007916927337646}", "{\"n\": 10691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 10080.861, \"total_train_time_s\": 14.228094100952148}", "{\"n\": 10692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.25, \"learn_time_ms\": 10034.804, \"total_train_time_s\": 13.516921520233154}", "{\"n\": 10693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.14, \"learn_time_ms\": 10061.557, \"total_train_time_s\": 14.146966695785522}", "{\"n\": 10694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.5, \"learn_time_ms\": 10118.37, \"total_train_time_s\": 13.793915510177612}", "{\"n\": 10695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.5, \"learn_time_ms\": 10155.525, \"total_train_time_s\": 13.994996309280396}", "{\"n\": 10696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.82, \"learn_time_ms\": 10331.541, \"total_train_time_s\": 14.986809015274048}", "{\"n\": 10697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.66, \"learn_time_ms\": 10341.099, \"total_train_time_s\": 13.592614889144897}", "{\"n\": 10698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.66, \"learn_time_ms\": 10224.96, \"total_train_time_s\": 13.341612815856934}", "{\"n\": 10699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.78, \"learn_time_ms\": 10078.734, \"total_train_time_s\": 13.664761543273926}", "{\"n\": 10700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.08, \"learn_time_ms\": 10104.553, \"total_train_time_s\": 13.3437020778656}", "{\"n\": 10701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.08, \"learn_time_ms\": 10044.982, \"total_train_time_s\": 13.459465026855469}", "{\"n\": 10702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.08, \"learn_time_ms\": 10127.23, \"total_train_time_s\": 14.547815561294556}", "{\"n\": 10703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.67, \"learn_time_ms\": 10041.724, \"total_train_time_s\": 13.216541528701782}", "{\"n\": 10704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.68, \"learn_time_ms\": 9990.868, \"total_train_time_s\": 13.25866436958313}", "{\"n\": 10705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.07, \"learn_time_ms\": 9974.723, \"total_train_time_s\": 13.513103246688843}", "{\"n\": 10706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.07, \"learn_time_ms\": 9826.079, \"total_train_time_s\": 13.643546104431152}", "{\"n\": 10707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.0, \"learn_time_ms\": 9724.168, \"total_train_time_s\": 12.542285442352295}", "{\"n\": 10708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.89, \"learn_time_ms\": 9743.723, \"total_train_time_s\": 13.364325523376465}", "{\"n\": 10709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.31, \"learn_time_ms\": 9797.053, \"total_train_time_s\": 14.198131561279297}", "{\"n\": 10710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.73, \"learn_time_ms\": 9811.757, \"total_train_time_s\": 13.404820442199707}", "{\"n\": 10711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.73, \"learn_time_ms\": 9800.139, \"total_train_time_s\": 13.616195440292358}", "{\"n\": 10712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.73, \"learn_time_ms\": 9844.594, \"total_train_time_s\": 14.67142915725708}", "{\"n\": 10713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.88, \"learn_time_ms\": 9838.819, \"total_train_time_s\": 13.322822570800781}", "{\"n\": 10714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.7, \"learn_time_ms\": 9845.173, \"total_train_time_s\": 13.193803787231445}", "{\"n\": 10715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.89, \"learn_time_ms\": 9753.677, \"total_train_time_s\": 12.68287444114685}", "{\"n\": 10716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.82, \"learn_time_ms\": 9801.131, \"total_train_time_s\": 13.95059585571289}", "{\"n\": 10717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.99, \"learn_time_ms\": 9768.305, \"total_train_time_s\": 12.294566631317139}", "{\"n\": 10718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.9, \"learn_time_ms\": 9800.312, \"total_train_time_s\": 13.7009596824646}", "{\"n\": 10719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.74, \"learn_time_ms\": 9674.418, \"total_train_time_s\": 13.004793167114258}", "{\"n\": 10720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.11, \"learn_time_ms\": 9665.723, \"total_train_time_s\": 13.411138772964478}", "{\"n\": 10721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.11, \"learn_time_ms\": 9808.885, \"total_train_time_s\": 15.158358335494995}", "{\"n\": 10722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.39, \"learn_time_ms\": 9680.603, \"total_train_time_s\": 13.507418394088745}", "{\"n\": 10723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.61, \"learn_time_ms\": 9766.775, \"total_train_time_s\": 14.055544376373291}", "{\"n\": 10724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.61, \"learn_time_ms\": 9706.637, \"total_train_time_s\": 12.666566848754883}", "{\"n\": 10725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.61, \"learn_time_ms\": 9734.14, \"total_train_time_s\": 12.917552709579468}", "{\"n\": 10726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.3, \"learn_time_ms\": 9766.715, \"total_train_time_s\": 14.400022029876709}", "{\"n\": 10727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.38, \"learn_time_ms\": 9908.986, \"total_train_time_s\": 13.627249002456665}", "{\"n\": 10728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.38, \"learn_time_ms\": 9952.3, \"total_train_time_s\": 14.052117347717285}", "{\"n\": 10729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.85, \"learn_time_ms\": 9965.612, \"total_train_time_s\": 13.086374044418335}", "{\"n\": 10730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.31, \"learn_time_ms\": 9999.864, \"total_train_time_s\": 13.583990097045898}", "{\"n\": 10731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.31, \"learn_time_ms\": 9947.19, \"total_train_time_s\": 14.513308763504028}", "{\"n\": 10732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.51, \"learn_time_ms\": 9993.802, \"total_train_time_s\": 13.90591049194336}", "{\"n\": 10733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.51, \"learn_time_ms\": 9951.572, \"total_train_time_s\": 13.466854810714722}", "{\"n\": 10734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.76, \"learn_time_ms\": 10061.211, \"total_train_time_s\": 13.83940601348877}", "{\"n\": 10735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 10093.76, \"total_train_time_s\": 13.308850765228271}", "{\"n\": 10736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 10039.11, \"total_train_time_s\": 13.947067022323608}", "{\"n\": 10737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 9938.816, \"total_train_time_s\": 12.773654699325562}", "{\"n\": 10738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.07, \"learn_time_ms\": 9920.688, \"total_train_time_s\": 13.972829103469849}", "{\"n\": 10739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.06, \"learn_time_ms\": 10070.624, \"total_train_time_s\": 14.41071105003357}", "{\"n\": 10740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.06, \"learn_time_ms\": 10069.02, \"total_train_time_s\": 13.738406896591187}", "{\"n\": 10741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.09, \"learn_time_ms\": 10018.638, \"total_train_time_s\": 13.988367080688477}", "{\"n\": 10742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.78, \"learn_time_ms\": 9949.099, \"total_train_time_s\": 13.106489658355713}", "{\"n\": 10743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.78, \"learn_time_ms\": 9938.948, \"total_train_time_s\": 13.312489032745361}", "{\"n\": 10744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.78, \"learn_time_ms\": 9945.663, \"total_train_time_s\": 14.045137643814087}", "{\"n\": 10745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.19, \"learn_time_ms\": 10013.424, \"total_train_time_s\": 13.946529388427734}", "{\"n\": 10746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.31, \"learn_time_ms\": 9997.344, \"total_train_time_s\": 13.676868200302124}", "{\"n\": 10747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.31, \"learn_time_ms\": 10057.128, \"total_train_time_s\": 13.414428949356079}", "{\"n\": 10748, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.53, \"learn_time_ms\": 10018.55, \"total_train_time_s\": 13.507720947265625}", "{\"n\": 10749, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.75, \"learn_time_ms\": 9834.948, \"total_train_time_s\": 12.798566579818726}", "{\"n\": 10750, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 9799.692, \"total_train_time_s\": 13.274905443191528}", "{\"n\": 10751, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 9741.584, \"total_train_time_s\": 13.352323770523071}", "{\"n\": 10752, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.96, \"learn_time_ms\": 9786.844, \"total_train_time_s\": 13.648616075515747}", "{\"n\": 10753, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 9839.927, \"total_train_time_s\": 14.14125943183899}", "{\"n\": 10754, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 9767.093, \"total_train_time_s\": 13.303502321243286}", "{\"n\": 10755, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.77, \"learn_time_ms\": 9739.873, \"total_train_time_s\": 13.991719961166382}", "{\"n\": 10756, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.54, \"learn_time_ms\": 9714.707, \"total_train_time_s\": 13.29142689704895}", "{\"n\": 10757, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.28, \"learn_time_ms\": 9752.561, \"total_train_time_s\": 13.697851181030273}", "{\"n\": 10758, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.28, \"learn_time_ms\": 9721.51, \"total_train_time_s\": 13.470045328140259}", "{\"n\": 10759, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.54, \"learn_time_ms\": 9766.179, \"total_train_time_s\": 13.197553873062134}", "{\"n\": 10760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.27, \"learn_time_ms\": 9824.388, \"total_train_time_s\": 14.23464822769165}", "{\"n\": 10761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.05, \"learn_time_ms\": 9787.175, \"total_train_time_s\": 12.814618110656738}", "{\"n\": 10762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.04, \"learn_time_ms\": 9758.626, \"total_train_time_s\": 13.437608242034912}", "{\"n\": 10763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.62, \"learn_time_ms\": 9671.205, \"total_train_time_s\": 13.017320156097412}", "{\"n\": 10764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.23, \"learn_time_ms\": 9765.54, \"total_train_time_s\": 13.954349517822266}", "{\"n\": 10765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.23, \"learn_time_ms\": 9725.126, \"total_train_time_s\": 13.49006175994873}", "{\"n\": 10766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.37, \"learn_time_ms\": 9643.454, \"total_train_time_s\": 12.492308139801025}", "{\"n\": 10767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.49, \"learn_time_ms\": 9640.936, \"total_train_time_s\": 13.695553541183472}", "{\"n\": 10768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.43, \"learn_time_ms\": 9619.124, \"total_train_time_s\": 13.022636651992798}", "{\"n\": 10769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.35, \"learn_time_ms\": 9679.974, \"total_train_time_s\": 13.672394752502441}", "{\"n\": 10770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.35, \"learn_time_ms\": 9637.152, \"total_train_time_s\": 13.37512731552124}", "{\"n\": 10771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.28, \"learn_time_ms\": 9661.462, \"total_train_time_s\": 13.177464723587036}", "{\"n\": 10772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.23, \"learn_time_ms\": 9699.885, \"total_train_time_s\": 13.822248458862305}", "{\"n\": 10773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.23, \"learn_time_ms\": 9691.988, \"total_train_time_s\": 12.964466094970703}", "{\"n\": 10774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.04, \"learn_time_ms\": 9593.144, \"total_train_time_s\": 13.143960237503052}", "{\"n\": 10775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.66, \"learn_time_ms\": 9619.418, \"total_train_time_s\": 13.501587867736816}", "{\"n\": 10776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 9769.028, \"total_train_time_s\": 13.9835684299469}", "{\"n\": 10777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 9721.449, \"total_train_time_s\": 13.360490322113037}", "{\"n\": 10778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.7, \"learn_time_ms\": 9719.87, \"total_train_time_s\": 12.969859600067139}", "{\"n\": 10779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.14, \"learn_time_ms\": 9743.934, \"total_train_time_s\": 13.858458518981934}", "{\"n\": 10780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.14, \"learn_time_ms\": 9812.23, \"total_train_time_s\": 14.005001783370972}", "{\"n\": 10781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.77, \"learn_time_ms\": 9874.413, \"total_train_time_s\": 14.00474214553833}", "{\"n\": 10782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.28, \"learn_time_ms\": 9933.354, \"total_train_time_s\": 14.561795949935913}", "{\"n\": 10783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.28, \"learn_time_ms\": 10030.061, \"total_train_time_s\": 13.905157566070557}", "{\"n\": 10784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.27, \"learn_time_ms\": 10073.296, \"total_train_time_s\": 13.351197242736816}", "{\"n\": 10785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.49, \"learn_time_ms\": 10046.364, \"total_train_time_s\": 13.275467157363892}", "{\"n\": 10786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.4, \"learn_time_ms\": 9983.338, \"total_train_time_s\": 13.468904495239258}", "{\"n\": 10787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.4, \"learn_time_ms\": 10087.256, \"total_train_time_s\": 14.413387298583984}", "{\"n\": 10788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.02, \"learn_time_ms\": 10154.498, \"total_train_time_s\": 13.701596021652222}", "{\"n\": 10789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.53, \"learn_time_ms\": 10218.396, \"total_train_time_s\": 14.672853469848633}", "{\"n\": 10790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.68, \"learn_time_ms\": 10225.178, \"total_train_time_s\": 14.371994495391846}", "{\"n\": 10791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.68, \"learn_time_ms\": 10217.306, \"total_train_time_s\": 14.033011198043823}", "{\"n\": 10792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.47, \"learn_time_ms\": 10098.41, \"total_train_time_s\": 13.262825012207031}", "{\"n\": 10793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.94, \"learn_time_ms\": 10048.939, \"total_train_time_s\": 13.449991703033447}", "{\"n\": 10794, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.39, \"learn_time_ms\": 9972.959, \"total_train_time_s\": 12.774854183197021}", "{\"n\": 10795, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.98, \"learn_time_ms\": 9929.224, \"total_train_time_s\": 13.102701902389526}", "{\"n\": 10796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.28, \"learn_time_ms\": 10080.692, \"total_train_time_s\": 15.021050930023193}", "{\"n\": 10797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.28, \"learn_time_ms\": 9917.42, \"total_train_time_s\": 12.778167247772217}", "{\"n\": 10798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.33, \"learn_time_ms\": 9938.816, \"total_train_time_s\": 13.862274885177612}", "{\"n\": 10799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.33, \"learn_time_ms\": 9931.09, \"total_train_time_s\": 14.640943050384521}", "{\"n\": 10800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.33, \"learn_time_ms\": 9826.322, \"total_train_time_s\": 13.275957345962524}", "{\"n\": 10801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.27, \"learn_time_ms\": 9844.308, \"total_train_time_s\": 13.779574155807495}", "{\"n\": 10802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.85, \"learn_time_ms\": 9896.566, \"total_train_time_s\": 13.86490273475647}", "{\"n\": 10803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.07, \"learn_time_ms\": 9899.58, \"total_train_time_s\": 13.507404327392578}", "{\"n\": 10804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.07, \"learn_time_ms\": 9941.612, \"total_train_time_s\": 13.091918230056763}", "{\"n\": 10805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.14, \"learn_time_ms\": 9985.298, \"total_train_time_s\": 13.278449296951294}", "{\"n\": 10806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.14, \"learn_time_ms\": 9853.796, \"total_train_time_s\": 13.771426916122437}", "{\"n\": 10807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.7, \"learn_time_ms\": 9938.301, \"total_train_time_s\": 13.432824850082397}", "{\"n\": 10808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.7, \"learn_time_ms\": 9979.653, \"total_train_time_s\": 14.560635805130005}", "{\"n\": 10809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.79, \"learn_time_ms\": 9862.854, \"total_train_time_s\": 13.266798734664917}", "{\"n\": 10810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.65, \"learn_time_ms\": 9911.884, \"total_train_time_s\": 13.542573690414429}", "{\"n\": 10811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.65, \"learn_time_ms\": 9929.524, \"total_train_time_s\": 14.07375955581665}", "{\"n\": 10812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.32, \"learn_time_ms\": 9977.701, \"total_train_time_s\": 14.202746868133545}", "{\"n\": 10813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.32, \"learn_time_ms\": 10009.57, \"total_train_time_s\": 14.043869256973267}", "{\"n\": 10814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.32, \"learn_time_ms\": 10058.059, \"total_train_time_s\": 13.711938381195068}", "{\"n\": 10815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 10053.418, \"total_train_time_s\": 13.544363021850586}", "{\"n\": 10816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 10048.187, \"total_train_time_s\": 13.589613676071167}", "{\"n\": 10817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.81, \"learn_time_ms\": 10060.709, \"total_train_time_s\": 13.661154985427856}", "{\"n\": 10818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.83, \"learn_time_ms\": 9970.499, \"total_train_time_s\": 13.392184019088745}", "{\"n\": 10819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.04, \"learn_time_ms\": 9970.654, \"total_train_time_s\": 13.329431295394897}", "{\"n\": 10820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.04, \"learn_time_ms\": 9899.356, \"total_train_time_s\": 12.991127014160156}", "{\"n\": 10821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.02, \"learn_time_ms\": 9892.381, \"total_train_time_s\": 13.996373891830444}", "{\"n\": 10822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.72, \"learn_time_ms\": 9923.194, \"total_train_time_s\": 14.393080472946167}", "{\"n\": 10823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.75, \"learn_time_ms\": 9863.514, \"total_train_time_s\": 13.315206289291382}", "{\"n\": 10824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.89, \"learn_time_ms\": 9913.859, \"total_train_time_s\": 14.036713123321533}", "{\"n\": 10825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.89, \"learn_time_ms\": 9951.584, \"total_train_time_s\": 13.799744367599487}", "{\"n\": 10826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.86, \"learn_time_ms\": 9979.272, \"total_train_time_s\": 13.789095163345337}", "{\"n\": 10827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.86, \"learn_time_ms\": 9970.605, \"total_train_time_s\": 13.436362504959106}", "{\"n\": 10828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.89, \"learn_time_ms\": 10050.773, \"total_train_time_s\": 14.27114987373352}", "{\"n\": 10829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.6, \"learn_time_ms\": 10052.462, \"total_train_time_s\": 13.326924562454224}", "{\"n\": 10830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.6, \"learn_time_ms\": 10099.958, \"total_train_time_s\": 13.55152702331543}", "{\"n\": 10831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.6, \"learn_time_ms\": 10050.495, \"total_train_time_s\": 13.429291009902954}", "{\"n\": 10832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.27, \"learn_time_ms\": 9910.649, \"total_train_time_s\": 12.93230128288269}", "{\"n\": 10833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.33, \"learn_time_ms\": 9874.319, \"total_train_time_s\": 12.968836069107056}", "{\"n\": 10834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.33, \"learn_time_ms\": 9829.825, \"total_train_time_s\": 14.063217163085938}", "{\"n\": 10835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.87, \"learn_time_ms\": 9850.391, \"total_train_time_s\": 13.903975009918213}", "{\"n\": 10836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.02, \"learn_time_ms\": 9807.771, \"total_train_time_s\": 13.362840175628662}", "{\"n\": 10837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.02, \"learn_time_ms\": 9790.658, \"total_train_time_s\": 13.447231531143188}", "{\"n\": 10838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.02, \"learn_time_ms\": 9733.544, \"total_train_time_s\": 13.853711366653442}", "{\"n\": 10839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.66, \"learn_time_ms\": 9750.164, \"total_train_time_s\": 13.431619644165039}", "{\"n\": 10840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.32, \"learn_time_ms\": 9952.665, \"total_train_time_s\": 15.508663177490234}", "{\"n\": 10841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.32, \"learn_time_ms\": 9900.92, \"total_train_time_s\": 13.357446908950806}", "{\"n\": 10842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.44, \"learn_time_ms\": 9999.431, \"total_train_time_s\": 13.903802156448364}", "{\"n\": 10843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10125.181, \"total_train_time_s\": 14.148025751113892}", "{\"n\": 10844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10152.587, \"total_train_time_s\": 14.054355382919312}", "{\"n\": 10845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10186.096, \"total_train_time_s\": 14.447936534881592}", "{\"n\": 10846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.99, \"learn_time_ms\": 10191.214, \"total_train_time_s\": 13.488909482955933}", "{\"n\": 10847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.99, \"learn_time_ms\": 10240.873, \"total_train_time_s\": 13.670292854309082}", "{\"n\": 10848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.99, \"learn_time_ms\": 10179.937, \"total_train_time_s\": 13.035134553909302}", "{\"n\": 10849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.25, \"learn_time_ms\": 10143.872, \"total_train_time_s\": 13.109276533126831}", "{\"n\": 10850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.67, \"learn_time_ms\": 9991.327, \"total_train_time_s\": 13.88108777999878}", "{\"n\": 10851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.67, \"learn_time_ms\": 10067.632, \"total_train_time_s\": 13.58514404296875}", "{\"n\": 10852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.58, \"learn_time_ms\": 9949.193, \"total_train_time_s\": 12.758934259414673}", "{\"n\": 10853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.96, \"learn_time_ms\": 9941.994, \"total_train_time_s\": 13.943910837173462}", "{\"n\": 10854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.04, \"learn_time_ms\": 9883.309, \"total_train_time_s\": 13.492400407791138}", "{\"n\": 10855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.25, \"learn_time_ms\": 9803.036, \"total_train_time_s\": 13.39829969406128}", "{\"n\": 10856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.25, \"learn_time_ms\": 9828.904, \"total_train_time_s\": 14.024533748626709}", "{\"n\": 10857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.11, \"learn_time_ms\": 9838.697, \"total_train_time_s\": 13.845254898071289}", "{\"n\": 10858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.88, \"learn_time_ms\": 9892.614, \"total_train_time_s\": 13.725305318832397}", "{\"n\": 10859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.88, \"learn_time_ms\": 9881.431, \"total_train_time_s\": 13.311461210250854}", "{\"n\": 10860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.99, \"learn_time_ms\": 9908.387, \"total_train_time_s\": 14.194440126419067}", "{\"n\": 10861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.13, \"learn_time_ms\": 9943.49, \"total_train_time_s\": 14.093516111373901}", "{\"n\": 10862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.13, \"learn_time_ms\": 9960.508, \"total_train_time_s\": 13.092119216918945}", "{\"n\": 10863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.47, \"learn_time_ms\": 9835.751, \"total_train_time_s\": 12.816636323928833}", "{\"n\": 10864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.47, \"learn_time_ms\": 9884.961, \"total_train_time_s\": 14.115466356277466}", "{\"n\": 10865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.39, \"learn_time_ms\": 9972.081, \"total_train_time_s\": 14.306749105453491}", "{\"n\": 10866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.0, \"learn_time_ms\": 9972.446, \"total_train_time_s\": 13.688805341720581}", "{\"n\": 10867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.0, \"learn_time_ms\": 10044.421, \"total_train_time_s\": 14.608591318130493}", "{\"n\": 10868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.41, \"learn_time_ms\": 10098.52, \"total_train_time_s\": 14.086807012557983}", "{\"n\": 10869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.78, \"learn_time_ms\": 10143.276, \"total_train_time_s\": 13.494724750518799}", "{\"n\": 10870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.78, \"learn_time_ms\": 10038.737, \"total_train_time_s\": 13.15224313735962}", "{\"n\": 10871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.58, \"learn_time_ms\": 10065.955, \"total_train_time_s\": 14.25877833366394}", "{\"n\": 10872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 10079.1, \"total_train_time_s\": 13.421477317810059}", "{\"n\": 10873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.39, \"learn_time_ms\": 10116.158, \"total_train_time_s\": 13.10859489440918}", "{\"n\": 10874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.39, \"learn_time_ms\": 10082.363, \"total_train_time_s\": 13.46216344833374}", "{\"n\": 10875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.56, \"learn_time_ms\": 10067.835, \"total_train_time_s\": 14.057369232177734}", "{\"n\": 10876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.56, \"learn_time_ms\": 10038.688, \"total_train_time_s\": 13.727302312850952}", "{\"n\": 10877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.66, \"learn_time_ms\": 9932.522, \"total_train_time_s\": 13.667727947235107}", "{\"n\": 10878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.66, \"learn_time_ms\": 9875.603, \"total_train_time_s\": 13.906322717666626}", "{\"n\": 10879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.52, \"learn_time_ms\": 9857.267, \"total_train_time_s\": 13.374065160751343}", "{\"n\": 10880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.36, \"learn_time_ms\": 9874.657, \"total_train_time_s\": 13.22731876373291}", "{\"n\": 10881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.87, \"learn_time_ms\": 9826.402, \"total_train_time_s\": 14.114264726638794}", "{\"n\": 10882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.81, \"learn_time_ms\": 9803.111, \"total_train_time_s\": 12.849194288253784}", "{\"n\": 10883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.81, \"learn_time_ms\": 9842.05, \"total_train_time_s\": 13.706080436706543}", "{\"n\": 10884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.7, \"learn_time_ms\": 9984.36, \"total_train_time_s\": 15.03386116027832}", "{\"n\": 10885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.8, \"learn_time_ms\": 9959.85, \"total_train_time_s\": 13.908339500427246}", "{\"n\": 10886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.29, \"learn_time_ms\": 9982.28, \"total_train_time_s\": 13.547406911849976}", "{\"n\": 10887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.22, \"learn_time_ms\": 9993.625, \"total_train_time_s\": 13.772323846817017}", "{\"n\": 10888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.88, \"learn_time_ms\": 10037.746, \"total_train_time_s\": 14.369284391403198}", "{\"n\": 10889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.88, \"learn_time_ms\": 10084.816, \"total_train_time_s\": 13.750635147094727}", "{\"n\": 10890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.52, \"learn_time_ms\": 10144.692, \"total_train_time_s\": 13.89997124671936}", "{\"n\": 10891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.03, \"learn_time_ms\": 10076.758, \"total_train_time_s\": 13.292576313018799}", "{\"n\": 10892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.21, \"learn_time_ms\": 10168.958, \"total_train_time_s\": 14.08812403678894}", "{\"n\": 10893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.4, \"learn_time_ms\": 10276.992, \"total_train_time_s\": 14.582786560058594}", "{\"n\": 10894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.88, \"learn_time_ms\": 10143.491, \"total_train_time_s\": 13.548134088516235}", "{\"n\": 10895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.77, \"learn_time_ms\": 10096.86, \"total_train_time_s\": 13.570024728775024}", "{\"n\": 10896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.77, \"learn_time_ms\": 10158.467, \"total_train_time_s\": 14.524699449539185}", "{\"n\": 10897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.63, \"learn_time_ms\": 10086.336, \"total_train_time_s\": 13.152289628982544}", "{\"n\": 10898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.63, \"learn_time_ms\": 10036.526, \"total_train_time_s\": 13.604011535644531}", "{\"n\": 10899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.52, \"learn_time_ms\": 9993.51, \"total_train_time_s\": 13.440134763717651}", "{\"n\": 10900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.02, \"learn_time_ms\": 10041.947, \"total_train_time_s\": 14.411724328994751}", "{\"n\": 10901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.56, \"learn_time_ms\": 10089.214, \"total_train_time_s\": 13.803729057312012}", "{\"n\": 10902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.56, \"learn_time_ms\": 10151.475, \"total_train_time_s\": 14.34558653831482}", "{\"n\": 10903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.74, \"learn_time_ms\": 10097.599, \"total_train_time_s\": 14.180968523025513}", "{\"n\": 10904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.21, \"learn_time_ms\": 10061.922, \"total_train_time_s\": 13.12899661064148}", "{\"n\": 10905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.22, \"learn_time_ms\": 9979.134, \"total_train_time_s\": 12.833131074905396}", "{\"n\": 10906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.25, \"learn_time_ms\": 9928.221, \"total_train_time_s\": 13.693998336791992}", "{\"n\": 10907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.27, \"learn_time_ms\": 9924.779, \"total_train_time_s\": 13.134345293045044}", "{\"n\": 10908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.07, \"learn_time_ms\": 9883.796, \"total_train_time_s\": 13.283699989318848}", "{\"n\": 10909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.07, \"learn_time_ms\": 9977.05, \"total_train_time_s\": 14.637191772460938}", "{\"n\": 10910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.16, \"learn_time_ms\": 9832.819, \"total_train_time_s\": 12.920298099517822}", "{\"n\": 10911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.09, \"learn_time_ms\": 9788.1, \"total_train_time_s\": 13.188180446624756}", "{\"n\": 10912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.84, \"learn_time_ms\": 9806.594, \"total_train_time_s\": 14.9257173538208}", "{\"n\": 10913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.84, \"learn_time_ms\": 9745.847, \"total_train_time_s\": 13.504698753356934}", "{\"n\": 10914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.72, \"learn_time_ms\": 9734.813, \"total_train_time_s\": 13.275875806808472}", "{\"n\": 10915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.08, \"learn_time_ms\": 9864.89, \"total_train_time_s\": 13.778599739074707}", "{\"n\": 10916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.08, \"learn_time_ms\": 9886.711, \"total_train_time_s\": 14.05338716506958}", "{\"n\": 10917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.91, \"learn_time_ms\": 9937.808, \"total_train_time_s\": 13.444223165512085}", "{\"n\": 10918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.15, \"learn_time_ms\": 9970.15, \"total_train_time_s\": 13.36371374130249}", "{\"n\": 10919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.88, \"learn_time_ms\": 9933.287, \"total_train_time_s\": 14.001070261001587}", "{\"n\": 10920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.96, \"learn_time_ms\": 9889.797, \"total_train_time_s\": 12.534957647323608}", "{\"n\": 10921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.07, \"learn_time_ms\": 9941.656, \"total_train_time_s\": 13.783449649810791}", "{\"n\": 10922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.2, \"learn_time_ms\": 9841.059, \"total_train_time_s\": 13.699403285980225}", "{\"n\": 10923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.2, \"learn_time_ms\": 9904.62, \"total_train_time_s\": 14.216769695281982}", "{\"n\": 10924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.71, \"learn_time_ms\": 9968.818, \"total_train_time_s\": 13.634958028793335}", "{\"n\": 10925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3534.68, \"learn_time_ms\": 9977.103, \"total_train_time_s\": 13.849019527435303}", "{\"n\": 10926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3536.52, \"learn_time_ms\": 9863.781, \"total_train_time_s\": 12.980331420898438}", "{\"n\": 10927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.48, \"learn_time_ms\": 9834.632, \"total_train_time_s\": 13.122454643249512}", "{\"n\": 10928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.8, \"learn_time_ms\": 9822.693, \"total_train_time_s\": 13.46783709526062}", "{\"n\": 10929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.11, \"learn_time_ms\": 9893.574, \"total_train_time_s\": 14.52711796760559}", "{\"n\": 10930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.48, \"learn_time_ms\": 10040.841, \"total_train_time_s\": 14.054934740066528}", "{\"n\": 10931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.35, \"learn_time_ms\": 10078.568, \"total_train_time_s\": 14.416351318359375}", "{\"n\": 10932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.88, \"learn_time_ms\": 10121.627, \"total_train_time_s\": 13.992365837097168}", "{\"n\": 10933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.88, \"learn_time_ms\": 10178.505, \"total_train_time_s\": 14.735997438430786}", "{\"n\": 10934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.38, \"learn_time_ms\": 10203.531, \"total_train_time_s\": 14.059446096420288}", "{\"n\": 10935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.46, \"learn_time_ms\": 10182.57, \"total_train_time_s\": 13.852668762207031}", "{\"n\": 10936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.3, \"learn_time_ms\": 10212.837, \"total_train_time_s\": 13.080198287963867}", "{\"n\": 10937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.64, \"learn_time_ms\": 10338.072, \"total_train_time_s\": 14.539141654968262}", "{\"n\": 10938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.86, \"learn_time_ms\": 10328.118, \"total_train_time_s\": 13.265048027038574}", "{\"n\": 10939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.93, \"learn_time_ms\": 10217.77, \"total_train_time_s\": 13.578842878341675}", "{\"n\": 10940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.93, \"learn_time_ms\": 10166.409, \"total_train_time_s\": 13.38707685470581}", "{\"n\": 10941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.17, \"learn_time_ms\": 10109.223, \"total_train_time_s\": 13.559531688690186}", "{\"n\": 10942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.37, \"learn_time_ms\": 10046.198, \"total_train_time_s\": 13.423748254776001}", "{\"n\": 10943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.91, \"learn_time_ms\": 9954.411, \"total_train_time_s\": 13.650095701217651}", "{\"n\": 10944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.5, \"learn_time_ms\": 9789.028, \"total_train_time_s\": 12.45163106918335}", "{\"n\": 10945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.15, \"learn_time_ms\": 9846.668, \"total_train_time_s\": 14.24977421760559}", "{\"n\": 10946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.63, \"learn_time_ms\": 9945.646, \"total_train_time_s\": 14.08060097694397}", "{\"n\": 10947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.63, \"learn_time_ms\": 9857.885, \"total_train_time_s\": 13.549535989761353}", "{\"n\": 10948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.54, \"learn_time_ms\": 9963.456, \"total_train_time_s\": 14.18319582939148}", "{\"n\": 10949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.05, \"learn_time_ms\": 10000.752, \"total_train_time_s\": 13.960501909255981}", "{\"n\": 10950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.22, \"learn_time_ms\": 9941.435, \"total_train_time_s\": 12.805770635604858}", "{\"n\": 10951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.72, \"learn_time_ms\": 9986.967, \"total_train_time_s\": 14.074844121932983}", "{\"n\": 10952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.15, \"learn_time_ms\": 10019.808, \"total_train_time_s\": 13.716920614242554}", "{\"n\": 10953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.45, \"learn_time_ms\": 10038.251, \"total_train_time_s\": 14.039799690246582}", "{\"n\": 10954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.45, \"learn_time_ms\": 10146.228, \"total_train_time_s\": 13.546660900115967}", "{\"n\": 10955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.89, \"learn_time_ms\": 10029.233, \"total_train_time_s\": 13.302335262298584}", "{\"n\": 10956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3546.89, \"learn_time_ms\": 9934.483, \"total_train_time_s\": 13.078354358673096}", "{\"n\": 10957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.8, \"learn_time_ms\": 9878.074, \"total_train_time_s\": 12.96459174156189}", "{\"n\": 10958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.1, \"learn_time_ms\": 9837.12, \"total_train_time_s\": 13.784356832504272}", "{\"n\": 10959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.94, \"learn_time_ms\": 9760.097, \"total_train_time_s\": 13.209218740463257}", "{\"n\": 10960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.94, \"learn_time_ms\": 9839.883, \"total_train_time_s\": 13.796712398529053}", "{\"n\": 10961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.95, \"learn_time_ms\": 9786.205, \"total_train_time_s\": 13.615254402160645}", "{\"n\": 10962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.19, \"learn_time_ms\": 9790.864, \"total_train_time_s\": 13.849947214126587}", "{\"n\": 10963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.57, \"learn_time_ms\": 9797.692, \"total_train_time_s\": 14.013404607772827}", "{\"n\": 10964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.57, \"learn_time_ms\": 9702.446, \"total_train_time_s\": 12.393880605697632}", "{\"n\": 10965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.49, \"learn_time_ms\": 9767.107, \"total_train_time_s\": 13.714351654052734}", "{\"n\": 10966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.8, \"learn_time_ms\": 9761.606, \"total_train_time_s\": 13.37257432937622}", "{\"n\": 10967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.39, \"learn_time_ms\": 9808.768, \"total_train_time_s\": 13.459547519683838}", "{\"n\": 10968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.98, \"learn_time_ms\": 9818.463, \"total_train_time_s\": 13.948007822036743}", "{\"n\": 10969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.98, \"learn_time_ms\": 9827.65, \"total_train_time_s\": 13.32027816772461}", "{\"n\": 10970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.98, \"learn_time_ms\": 9745.164, \"total_train_time_s\": 12.862694025039673}", "{\"n\": 10971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.69, \"learn_time_ms\": 9695.282, \"total_train_time_s\": 12.96397876739502}", "{\"n\": 10972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.69, \"learn_time_ms\": 9604.72, \"total_train_time_s\": 12.814461946487427}", "{\"n\": 10973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.35, \"learn_time_ms\": 9618.173, \"total_train_time_s\": 14.150848388671875}", "{\"n\": 10974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.74, \"learn_time_ms\": 9776.519, \"total_train_time_s\": 14.101139307022095}", "{\"n\": 10975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.02, \"learn_time_ms\": 9836.19, \"total_train_time_s\": 14.347516536712646}", "{\"n\": 10976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.04, \"learn_time_ms\": 9869.3, \"total_train_time_s\": 13.626623392105103}", "{\"n\": 10977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.73, \"learn_time_ms\": 9874.882, \"total_train_time_s\": 13.527829647064209}", "{\"n\": 10978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.73, \"learn_time_ms\": 9813.366, \"total_train_time_s\": 13.399929523468018}", "{\"n\": 10979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.9, \"learn_time_ms\": 9906.666, \"total_train_time_s\": 14.199524641036987}", "{\"n\": 10980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.19, \"learn_time_ms\": 10059.54, \"total_train_time_s\": 14.266893148422241}", "{\"n\": 10981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 10172.717, \"total_train_time_s\": 14.03706169128418}", "{\"n\": 10982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 10188.692, \"total_train_time_s\": 13.024874687194824}", "{\"n\": 10983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 10146.801, \"total_train_time_s\": 13.970206022262573}", "{\"n\": 10984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.81, \"learn_time_ms\": 10145.29, \"total_train_time_s\": 14.053000926971436}", "{\"n\": 10985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.79, \"learn_time_ms\": 10035.724, \"total_train_time_s\": 13.607056617736816}", "{\"n\": 10986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.79, \"learn_time_ms\": 9996.452, \"total_train_time_s\": 13.038439273834229}", "{\"n\": 10987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.85, \"learn_time_ms\": 9974.451, \"total_train_time_s\": 13.160201072692871}", "{\"n\": 10988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.45, \"learn_time_ms\": 10069.373, \"total_train_time_s\": 14.362800359725952}", "{\"n\": 10989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.26, \"learn_time_ms\": 10016.111, \"total_train_time_s\": 13.503554821014404}", "{\"n\": 10990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.68, \"learn_time_ms\": 9814.412, \"total_train_time_s\": 12.35549807548523}", "{\"n\": 10991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.4, \"learn_time_ms\": 9703.611, \"total_train_time_s\": 13.226231098175049}", "{\"n\": 10992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.8, \"learn_time_ms\": 9794.702, \"total_train_time_s\": 13.94891619682312}", "{\"n\": 10993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.25, \"learn_time_ms\": 9737.191, \"total_train_time_s\": 13.074408292770386}", "{\"n\": 10994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.68, \"learn_time_ms\": 9726.238, \"total_train_time_s\": 13.961203336715698}", "{\"n\": 10995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.68, \"learn_time_ms\": 9769.789, \"total_train_time_s\": 13.916640996932983}", "{\"n\": 10996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.16, \"learn_time_ms\": 9848.455, \"total_train_time_s\": 13.922011375427246}", "{\"n\": 10997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.03, \"learn_time_ms\": 9932.612, \"total_train_time_s\": 14.320712089538574}", "{\"n\": 10998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.94, \"learn_time_ms\": 9847.322, \"total_train_time_s\": 13.526020288467407}", "{\"n\": 10999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.94, \"learn_time_ms\": 9876.946, \"total_train_time_s\": 13.937623023986816}", "{\"n\": 11000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.23, \"learn_time_ms\": 10031.766, \"total_train_time_s\": 13.867901086807251}", "{\"n\": 11001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.07, \"learn_time_ms\": 10181.371, \"total_train_time_s\": 14.36677598953247}", "{\"n\": 11002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.6, \"learn_time_ms\": 10065.133, \"total_train_time_s\": 12.686121225357056}", "{\"n\": 11003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.28, \"learn_time_ms\": 10068.471, \"total_train_time_s\": 13.140585660934448}", "{\"n\": 11004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.08, \"learn_time_ms\": 10073.42, \"total_train_time_s\": 14.075408935546875}", "{\"n\": 11005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.15, \"learn_time_ms\": 10043.275, \"total_train_time_s\": 13.467995643615723}", "{\"n\": 11006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.34, \"learn_time_ms\": 10035.273, \"total_train_time_s\": 13.674293994903564}", "{\"n\": 11007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 9933.723, \"total_train_time_s\": 13.10931658744812}", "{\"n\": 11008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 9852.813, \"total_train_time_s\": 12.574188709259033}", "{\"n\": 11009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 9801.51, \"total_train_time_s\": 13.640892028808594}", "{\"n\": 11010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.02, \"learn_time_ms\": 9754.599, \"total_train_time_s\": 13.446704149246216}", "{\"n\": 11011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.02, \"learn_time_ms\": 9572.43, \"total_train_time_s\": 12.860570430755615}", "{\"n\": 11012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.02, \"learn_time_ms\": 9623.554, \"total_train_time_s\": 13.463127851486206}", "{\"n\": 11013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.33, \"learn_time_ms\": 9671.095, \"total_train_time_s\": 13.685710668563843}", "{\"n\": 11014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.72, \"learn_time_ms\": 9565.918, \"total_train_time_s\": 12.82827377319336}", "{\"n\": 11015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.72, \"learn_time_ms\": 9626.313, \"total_train_time_s\": 14.205354928970337}", "{\"n\": 11016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.56, \"learn_time_ms\": 9625.788, \"total_train_time_s\": 13.80671739578247}", "{\"n\": 11017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.56, \"learn_time_ms\": 9647.023, \"total_train_time_s\": 13.356735229492188}", "{\"n\": 11018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3536.12, \"learn_time_ms\": 9682.121, \"total_train_time_s\": 12.895140409469604}", "{\"n\": 11019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3534.16, \"learn_time_ms\": 9642.026, \"total_train_time_s\": 13.11418104171753}", "{\"n\": 11020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.06, \"learn_time_ms\": 9609.489, \"total_train_time_s\": 13.225048780441284}", "{\"n\": 11021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.06, \"learn_time_ms\": 9655.14, \"total_train_time_s\": 13.00075364112854}", "{\"n\": 11022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3520.22, \"learn_time_ms\": 9647.019, \"total_train_time_s\": 13.20578122138977}", "{\"n\": 11023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3515.91, \"learn_time_ms\": 9670.357, \"total_train_time_s\": 14.076305866241455}", "{\"n\": 11024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3523.36, \"learn_time_ms\": 9649.005, \"total_train_time_s\": 12.950670719146729}", "{\"n\": 11025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.31, \"learn_time_ms\": 9614.055, \"total_train_time_s\": 13.60627794265747}", "{\"n\": 11026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.74, \"learn_time_ms\": 9688.091, \"total_train_time_s\": 14.537754535675049}", "{\"n\": 11027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3534.33, \"learn_time_ms\": 9686.83, \"total_train_time_s\": 13.309202671051025}", "{\"n\": 11028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.83, \"learn_time_ms\": 9816.267, \"total_train_time_s\": 14.536331176757812}", "{\"n\": 11029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.34, \"learn_time_ms\": 9954.579, \"total_train_time_s\": 14.348732709884644}", "{\"n\": 11030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.53, \"learn_time_ms\": 10022.863, \"total_train_time_s\": 13.943103075027466}", "{\"n\": 11031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.53, \"learn_time_ms\": 10068.935, \"total_train_time_s\": 13.706737756729126}", "{\"n\": 11032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.87, \"learn_time_ms\": 10097.03, \"total_train_time_s\": 13.59935998916626}", "{\"n\": 11033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.85, \"learn_time_ms\": 10025.369, \"total_train_time_s\": 13.256808757781982}", "{\"n\": 11034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.0, \"learn_time_ms\": 10039.854, \"total_train_time_s\": 12.746324300765991}", "{\"n\": 11035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.12, \"learn_time_ms\": 9996.979, \"total_train_time_s\": 13.12724757194519}", "{\"n\": 11036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.06, \"learn_time_ms\": 9950.539, \"total_train_time_s\": 14.008461236953735}", "{\"n\": 11037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.97, \"learn_time_ms\": 9956.101, \"total_train_time_s\": 13.289714336395264}", "{\"n\": 11038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.59, \"learn_time_ms\": 9943.884, \"total_train_time_s\": 14.113996982574463}", "{\"n\": 11039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.15, \"learn_time_ms\": 9857.636, \"total_train_time_s\": 13.635563135147095}", "{\"n\": 11040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.12, \"learn_time_ms\": 9840.29, \"total_train_time_s\": 13.57870602607727}", "{\"n\": 11041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.43, \"learn_time_ms\": 9875.845, \"total_train_time_s\": 13.873390674591064}", "{\"n\": 11042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.53, \"learn_time_ms\": 9893.557, \"total_train_time_s\": 13.681582689285278}", "{\"n\": 11043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.38, \"learn_time_ms\": 9926.042, \"total_train_time_s\": 13.603949069976807}", "{\"n\": 11044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.38, \"learn_time_ms\": 10115.392, \"total_train_time_s\": 14.865834474563599}", "{\"n\": 11045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.04, \"learn_time_ms\": 10110.62, \"total_train_time_s\": 13.277303457260132}", "{\"n\": 11046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.45, \"learn_time_ms\": 10116.489, \"total_train_time_s\": 14.107540369033813}", "{\"n\": 11047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.87, \"learn_time_ms\": 10146.509, \"total_train_time_s\": 13.850881814956665}", "{\"n\": 11048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.41, \"learn_time_ms\": 10051.79, \"total_train_time_s\": 13.156515836715698}", "{\"n\": 11049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10152.224, \"total_train_time_s\": 14.638851642608643}", "{\"n\": 11050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10174.375, \"total_train_time_s\": 13.907578945159912}", "{\"n\": 11051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.06, \"learn_time_ms\": 10117.402, \"total_train_time_s\": 13.294101476669312}", "{\"n\": 11052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.06, \"learn_time_ms\": 10109.069, \"total_train_time_s\": 13.726907730102539}", "{\"n\": 11053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.94, \"learn_time_ms\": 10132.143, \"total_train_time_s\": 13.852763414382935}", "{\"n\": 11054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.5, \"learn_time_ms\": 10033.955, \"total_train_time_s\": 13.996486902236938}", "{\"n\": 11055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.64, \"learn_time_ms\": 9994.36, \"total_train_time_s\": 12.813068866729736}", "{\"n\": 11056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.48, \"learn_time_ms\": 9869.946, \"total_train_time_s\": 12.891082763671875}", "{\"n\": 11057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.18, \"learn_time_ms\": 9897.992, \"total_train_time_s\": 13.998995065689087}", "{\"n\": 11058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.03, \"learn_time_ms\": 9966.024, \"total_train_time_s\": 13.839357852935791}", "{\"n\": 11059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.03, \"learn_time_ms\": 9780.237, \"total_train_time_s\": 12.692372798919678}", "{\"n\": 11060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.62, \"learn_time_ms\": 9721.243, \"total_train_time_s\": 13.207703113555908}", "{\"n\": 11061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.12, \"learn_time_ms\": 9754.16, \"total_train_time_s\": 13.69705843925476}", "{\"n\": 11062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.71, \"learn_time_ms\": 9798.541, \"total_train_time_s\": 14.135079622268677}", "{\"n\": 11063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.16, \"learn_time_ms\": 9827.388, \"total_train_time_s\": 13.960302591323853}", "{\"n\": 11064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.16, \"learn_time_ms\": 9851.311, \"total_train_time_s\": 14.129579544067383}", "{\"n\": 11065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.83, \"learn_time_ms\": 10040.81, \"total_train_time_s\": 14.70020866394043}", "{\"n\": 11066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.23, \"learn_time_ms\": 10070.297, \"total_train_time_s\": 13.119860887527466}", "{\"n\": 11067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.23, \"learn_time_ms\": 10043.234, \"total_train_time_s\": 13.59768033027649}", "{\"n\": 11068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.07, \"learn_time_ms\": 10005.634, \"total_train_time_s\": 13.69493293762207}", "{\"n\": 11069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.53, \"learn_time_ms\": 10174.529, \"total_train_time_s\": 14.419726371765137}", "{\"n\": 11070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.69, \"learn_time_ms\": 10262.649, \"total_train_time_s\": 14.556299924850464}", "{\"n\": 11071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.69, \"learn_time_ms\": 10254.782, \"total_train_time_s\": 13.87496018409729}", "{\"n\": 11072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.66, \"learn_time_ms\": 10199.311, \"total_train_time_s\": 13.608686208724976}", "{\"n\": 11073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.65, \"learn_time_ms\": 10187.793, \"total_train_time_s\": 13.929286003112793}", "{\"n\": 11074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.85, \"learn_time_ms\": 10249.504, \"total_train_time_s\": 14.673832893371582}", "{\"n\": 11075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.85, \"learn_time_ms\": 10179.766, \"total_train_time_s\": 13.979812145233154}", "{\"n\": 11076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.42, \"learn_time_ms\": 10208.357, \"total_train_time_s\": 13.336193561553955}", "{\"n\": 11077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.42, \"learn_time_ms\": 10205.472, \"total_train_time_s\": 14.042573690414429}", "{\"n\": 11078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.02, \"learn_time_ms\": 10273.474, \"total_train_time_s\": 14.286783933639526}", "{\"n\": 11079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.02, \"learn_time_ms\": 10245.88, \"total_train_time_s\": 14.023743867874146}", "{\"n\": 11080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.88, \"learn_time_ms\": 10202.677, \"total_train_time_s\": 13.666017532348633}", "{\"n\": 11081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.33, \"learn_time_ms\": 10192.146, \"total_train_time_s\": 13.420662879943848}", "{\"n\": 11082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.51, \"learn_time_ms\": 10192.498, \"total_train_time_s\": 13.45200252532959}", "{\"n\": 11083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.51, \"learn_time_ms\": 10184.768, \"total_train_time_s\": 14.043288946151733}", "{\"n\": 11084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.72, \"learn_time_ms\": 10083.92, \"total_train_time_s\": 13.65455436706543}", "{\"n\": 11085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.19, \"learn_time_ms\": 10064.485, \"total_train_time_s\": 13.814632177352905}", "{\"n\": 11086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.11, \"learn_time_ms\": 10091.939, \"total_train_time_s\": 13.849342346191406}", "{\"n\": 11087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.73, \"learn_time_ms\": 10067.204, \"total_train_time_s\": 13.616970539093018}", "{\"n\": 11088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.31, \"learn_time_ms\": 9945.223, \"total_train_time_s\": 12.930752992630005}", "{\"n\": 11089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.8, \"learn_time_ms\": 9816.629, \"total_train_time_s\": 12.845366954803467}", "{\"n\": 11090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.36, \"learn_time_ms\": 9770.728, \"total_train_time_s\": 13.481707334518433}", "{\"n\": 11091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 9759.977, \"total_train_time_s\": 13.434125185012817}", "{\"n\": 11092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 9836.912, \"total_train_time_s\": 14.313812971115112}", "{\"n\": 11093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.26, \"learn_time_ms\": 9855.959, \"total_train_time_s\": 13.919434309005737}", "{\"n\": 11094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.3, \"learn_time_ms\": 9854.158, \"total_train_time_s\": 13.748429536819458}", "{\"n\": 11095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.31, \"learn_time_ms\": 9813.836, \"total_train_time_s\": 13.405719995498657}", "{\"n\": 11096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.31, \"learn_time_ms\": 9791.425, \"total_train_time_s\": 13.560930728912354}", "{\"n\": 11097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.01, \"learn_time_ms\": 9747.164, \"total_train_time_s\": 12.965335607528687}", "{\"n\": 11098, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.0, \"learn_time_ms\": 9901.644, \"total_train_time_s\": 14.45966649055481}", "{\"n\": 11099, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.84, \"learn_time_ms\": 9964.212, \"total_train_time_s\": 13.56241774559021}", "{\"n\": 11100, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.75, \"learn_time_ms\": 10039.24, \"total_train_time_s\": 13.944374084472656}", "{\"n\": 11101, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.73, \"learn_time_ms\": 10030.389, \"total_train_time_s\": 13.289690256118774}", "{\"n\": 11102, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.34, \"learn_time_ms\": 9919.872, \"total_train_time_s\": 13.081798553466797}", "{\"n\": 11103, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.82, \"learn_time_ms\": 9944.944, \"total_train_time_s\": 14.19248652458191}", "{\"n\": 11104, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.82, \"learn_time_ms\": 9938.67, \"total_train_time_s\": 13.500969886779785}", "{\"n\": 11105, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.48, \"learn_time_ms\": 9929.457, \"total_train_time_s\": 13.29314136505127}", "{\"n\": 11106, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.25, \"learn_time_ms\": 9971.947, \"total_train_time_s\": 13.82812213897705}", "{\"n\": 11107, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.25, \"learn_time_ms\": 10035.835, \"total_train_time_s\": 13.649702072143555}", "{\"n\": 11108, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.4, \"learn_time_ms\": 10006.709, \"total_train_time_s\": 14.589213132858276}", "{\"n\": 11109, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.3, \"learn_time_ms\": 10038.474, \"total_train_time_s\": 13.972548246383667}", "{\"n\": 11110, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.3, \"learn_time_ms\": 10112.235, \"total_train_time_s\": 14.97985577583313}", "{\"n\": 11111, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.3, \"learn_time_ms\": 10065.76, \"total_train_time_s\": 12.90828800201416}", "{\"n\": 11112, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.52, \"learn_time_ms\": 10156.2, \"total_train_time_s\": 14.097571849822998}", "{\"n\": 11113, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.34, \"learn_time_ms\": 10043.23, \"total_train_time_s\": 13.13779592514038}", "{\"n\": 11114, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.34, \"learn_time_ms\": 10025.027, \"total_train_time_s\": 13.338698387145996}", "{\"n\": 11115, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.27, \"learn_time_ms\": 9966.958, \"total_train_time_s\": 12.67859411239624}", "{\"n\": 11116, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.66, \"learn_time_ms\": 9913.956, \"total_train_time_s\": 13.480923175811768}", "{\"n\": 11117, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.52, \"learn_time_ms\": 9868.088, \"total_train_time_s\": 13.264250755310059}", "{\"n\": 11118, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.52, \"learn_time_ms\": 9811.703, \"total_train_time_s\": 13.631455421447754}", "{\"n\": 11119, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.1, \"learn_time_ms\": 9904.457, \"total_train_time_s\": 14.686032772064209}", "{\"n\": 11120, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.01, \"learn_time_ms\": 9880.633, \"total_train_time_s\": 14.380972623825073}", "{\"n\": 11121, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.01, \"learn_time_ms\": 9912.97, \"total_train_time_s\": 13.11377763748169}", "{\"n\": 11122, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.01, \"learn_time_ms\": 9780.528, \"total_train_time_s\": 12.74865436553955}", "{\"n\": 11123, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.33, \"learn_time_ms\": 9770.816, \"total_train_time_s\": 12.964826583862305}", "{\"n\": 11124, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.29, \"learn_time_ms\": 9868.105, \"total_train_time_s\": 14.277221918106079}", "{\"n\": 11125, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.29, \"learn_time_ms\": 10001.464, \"total_train_time_s\": 14.145509481430054}", "{\"n\": 11126, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.85, \"learn_time_ms\": 10047.157, \"total_train_time_s\": 13.79372262954712}", "{\"n\": 11127, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.4, \"learn_time_ms\": 10152.916, \"total_train_time_s\": 14.10188341140747}", "{\"n\": 11128, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.4, \"learn_time_ms\": 10202.493, \"total_train_time_s\": 14.105924129486084}", "{\"n\": 11129, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.4, \"learn_time_ms\": 10154.292, \"total_train_time_s\": 14.292568445205688}", "{\"n\": 11130, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.17, \"learn_time_ms\": 10057.401, \"total_train_time_s\": 13.662781715393066}", "{\"n\": 11131, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.15, \"learn_time_ms\": 10146.228, \"total_train_time_s\": 14.035032987594604}", "{\"n\": 11132, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.15, \"learn_time_ms\": 10238.501, \"total_train_time_s\": 13.620294332504272}", "{\"n\": 11133, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.47, \"learn_time_ms\": 10295.99, \"total_train_time_s\": 13.790581703186035}", "{\"n\": 11134, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.73, \"learn_time_ms\": 10309.306, \"total_train_time_s\": 14.426251411437988}", "{\"n\": 11135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.07, \"learn_time_ms\": 10306.931, \"total_train_time_s\": 14.006437301635742}", "{\"n\": 11136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.07, \"learn_time_ms\": 10263.872, \"total_train_time_s\": 13.486276626586914}", "{\"n\": 11137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.04, \"learn_time_ms\": 10187.439, \"total_train_time_s\": 13.551421165466309}", "{\"n\": 11138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.06, \"learn_time_ms\": 10131.503, \"total_train_time_s\": 13.55878233909607}", "{\"n\": 11139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.06, \"learn_time_ms\": 10072.931, \"total_train_time_s\": 13.890595197677612}", "{\"n\": 11140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.49, \"learn_time_ms\": 10004.961, \"total_train_time_s\": 13.161336660385132}", "{\"n\": 11141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.17, \"learn_time_ms\": 9900.288, \"total_train_time_s\": 12.975739002227783}", "{\"n\": 11142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.67, \"learn_time_ms\": 9891.823, \"total_train_time_s\": 13.504709959030151}", "{\"n\": 11143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.48, \"learn_time_ms\": 9937.274, \"total_train_time_s\": 14.215260744094849}", "{\"n\": 11144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.32, \"learn_time_ms\": 9909.884, \"total_train_time_s\": 14.249989986419678}", "{\"n\": 11145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.54, \"learn_time_ms\": 9799.261, \"total_train_time_s\": 13.201411724090576}", "{\"n\": 11146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.62, \"learn_time_ms\": 9891.518, \"total_train_time_s\": 14.405574321746826}", "{\"n\": 11147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.39, \"learn_time_ms\": 9891.068, \"total_train_time_s\": 13.459684371948242}", "{\"n\": 11148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.32, \"learn_time_ms\": 9874.983, \"total_train_time_s\": 13.506039142608643}", "{\"n\": 11149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.82, \"learn_time_ms\": 9896.404, \"total_train_time_s\": 13.724868774414062}", "{\"n\": 11150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.97, \"learn_time_ms\": 9956.536, \"total_train_time_s\": 13.487464427947998}", "{\"n\": 11151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.71, \"learn_time_ms\": 10062.84, \"total_train_time_s\": 14.306413650512695}", "{\"n\": 11152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.29, \"learn_time_ms\": 9986.276, \"total_train_time_s\": 13.057333946228027}", "{\"n\": 11153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.95, \"learn_time_ms\": 9946.415, \"total_train_time_s\": 13.763683795928955}", "{\"n\": 11154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.95, \"learn_time_ms\": 9797.222, \"total_train_time_s\": 12.571932315826416}", "{\"n\": 11155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.86, \"learn_time_ms\": 9829.621, \"total_train_time_s\": 13.198999881744385}", "{\"n\": 11156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.07, \"learn_time_ms\": 9690.312, \"total_train_time_s\": 13.107625484466553}", "{\"n\": 11157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.07, \"learn_time_ms\": 9693.463, \"total_train_time_s\": 13.488328218460083}", "{\"n\": 11158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.07, \"learn_time_ms\": 9838.498, \"total_train_time_s\": 14.812029123306274}", "{\"n\": 11159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.19, \"learn_time_ms\": 9903.607, \"total_train_time_s\": 14.391748428344727}", "{\"n\": 11160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 9860.712, \"total_train_time_s\": 13.118021965026855}", "{\"n\": 11161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 9818.566, \"total_train_time_s\": 13.876818180084229}", "{\"n\": 11162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.96, \"learn_time_ms\": 10000.438, \"total_train_time_s\": 14.547024011611938}", "{\"n\": 11163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.96, \"learn_time_ms\": 10055.16, \"total_train_time_s\": 14.182511568069458}", "{\"n\": 11164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10171.833, \"total_train_time_s\": 13.956580638885498}", "{\"n\": 11165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10162.987, \"total_train_time_s\": 13.377531051635742}", "{\"n\": 11166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.68, \"learn_time_ms\": 10237.603, \"total_train_time_s\": 13.6445791721344}", "{\"n\": 11167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.01, \"learn_time_ms\": 10275.784, \"total_train_time_s\": 13.875136852264404}", "{\"n\": 11168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.01, \"learn_time_ms\": 10120.648, \"total_train_time_s\": 13.3398597240448}", "{\"n\": 11169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.71, \"learn_time_ms\": 10036.046, \"total_train_time_s\": 13.64218783378601}", "{\"n\": 11170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.7, \"learn_time_ms\": 10061.559, \"total_train_time_s\": 13.446843385696411}", "{\"n\": 11171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.79, \"learn_time_ms\": 9977.343, \"total_train_time_s\": 12.809863328933716}", "{\"n\": 11172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.79, \"learn_time_ms\": 9814.81, \"total_train_time_s\": 12.937294244766235}", "{\"n\": 11173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.32, \"learn_time_ms\": 9768.433, \"total_train_time_s\": 13.781158924102783}", "{\"n\": 11174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.75, \"learn_time_ms\": 9720.482, \"total_train_time_s\": 13.361887216567993}", "{\"n\": 11175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.43, \"learn_time_ms\": 9870.439, \"total_train_time_s\": 14.910826444625854}", "{\"n\": 11176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.0, \"learn_time_ms\": 9865.944, \"total_train_time_s\": 13.592498540878296}", "{\"n\": 11177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.38, \"learn_time_ms\": 9750.145, \"total_train_time_s\": 12.709121704101562}", "{\"n\": 11178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.54, \"learn_time_ms\": 9788.177, \"total_train_time_s\": 13.801587343215942}", "{\"n\": 11179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.94, \"learn_time_ms\": 9829.775, \"total_train_time_s\": 14.096125364303589}", "{\"n\": 11180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.94, \"learn_time_ms\": 9994.956, \"total_train_time_s\": 15.00183367729187}", "{\"n\": 11181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.76, \"learn_time_ms\": 10030.71, \"total_train_time_s\": 13.189508438110352}", "{\"n\": 11182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.45, \"learn_time_ms\": 9962.282, \"total_train_time_s\": 12.336841106414795}", "{\"n\": 11183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.33, \"learn_time_ms\": 9923.411, \"total_train_time_s\": 13.349710464477539}", "{\"n\": 11184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.89, \"learn_time_ms\": 10019.201, \"total_train_time_s\": 14.280741214752197}", "{\"n\": 11185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10005.942, \"total_train_time_s\": 14.610246419906616}", "{\"n\": 11186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 9962.557, \"total_train_time_s\": 13.507940769195557}", "{\"n\": 11187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 10023.358, \"total_train_time_s\": 13.290873527526855}", "{\"n\": 11188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.54, \"learn_time_ms\": 10059.304, \"total_train_time_s\": 14.165448665618896}", "{\"n\": 11189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.25, \"learn_time_ms\": 10026.385, \"total_train_time_s\": 13.89086127281189}", "{\"n\": 11190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.25, \"learn_time_ms\": 9881.517, \"total_train_time_s\": 13.36113452911377}", "{\"n\": 11191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.46, \"learn_time_ms\": 10001.745, \"total_train_time_s\": 14.532155513763428}", "{\"n\": 11192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.64, \"learn_time_ms\": 10147.259, \"total_train_time_s\": 13.717123031616211}", "{\"n\": 11193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.64, \"learn_time_ms\": 10175.785, \"total_train_time_s\": 13.497332572937012}", "{\"n\": 11194, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.85, \"learn_time_ms\": 10083.349, \"total_train_time_s\": 13.640260934829712}", "{\"n\": 11195, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.81, \"learn_time_ms\": 10006.998, \"total_train_time_s\": 13.771875143051147}", "{\"n\": 11196, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.59, \"learn_time_ms\": 10091.395, \"total_train_time_s\": 14.082282304763794}", "{\"n\": 11197, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.59, \"learn_time_ms\": 10150.962, \"total_train_time_s\": 13.75711178779602}", "{\"n\": 11198, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.22, \"learn_time_ms\": 10246.938, \"total_train_time_s\": 15.105299234390259}", "{\"n\": 11199, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.47, \"learn_time_ms\": 10208.945, \"total_train_time_s\": 13.275344371795654}", "{\"n\": 11200, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.41, \"learn_time_ms\": 10281.753, \"total_train_time_s\": 14.53380560874939}", "{\"n\": 11201, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.46, \"learn_time_ms\": 10113.629, \"total_train_time_s\": 12.572622776031494}", "{\"n\": 11202, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.67, \"learn_time_ms\": 10096.171, \"total_train_time_s\": 13.896524906158447}", "{\"n\": 11203, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.1, \"learn_time_ms\": 10001.302, \"total_train_time_s\": 12.75448989868164}", "{\"n\": 11204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.1, \"learn_time_ms\": 10039.028, \"total_train_time_s\": 13.876238346099854}", "{\"n\": 11205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.95, \"learn_time_ms\": 9968.987, \"total_train_time_s\": 13.129886150360107}", "{\"n\": 11206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.81, \"learn_time_ms\": 9932.322, \"total_train_time_s\": 14.009832382202148}", "{\"n\": 11207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.2, \"learn_time_ms\": 9930.66, \"total_train_time_s\": 13.808561086654663}", "{\"n\": 11208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.82, \"learn_time_ms\": 9852.105, \"total_train_time_s\": 14.223060607910156}", "{\"n\": 11209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.01, \"learn_time_ms\": 9919.511, \"total_train_time_s\": 14.096801280975342}", "{\"n\": 11210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.38, \"learn_time_ms\": 9835.162, \"total_train_time_s\": 13.494972467422485}", "{\"n\": 11211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.38, \"learn_time_ms\": 9854.303, \"total_train_time_s\": 12.760512113571167}", "{\"n\": 11212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.13, \"learn_time_ms\": 9826.744, \"total_train_time_s\": 13.277449131011963}", "{\"n\": 11213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.13, \"learn_time_ms\": 9815.105, \"total_train_time_s\": 12.780742883682251}", "{\"n\": 11214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.51, \"learn_time_ms\": 9863.784, \"total_train_time_s\": 14.684191703796387}", "{\"n\": 11215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.38, \"learn_time_ms\": 9890.429, \"total_train_time_s\": 13.310562372207642}", "{\"n\": 11216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.38, \"learn_time_ms\": 9842.447, \"total_train_time_s\": 13.107583999633789}", "{\"n\": 11217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.51, \"learn_time_ms\": 9791.117, \"total_train_time_s\": 13.431304454803467}", "{\"n\": 11218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.62, \"learn_time_ms\": 9739.642, \"total_train_time_s\": 13.846604347229004}", "{\"n\": 11219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.62, \"learn_time_ms\": 9634.484, \"total_train_time_s\": 13.118274211883545}", "{\"n\": 11220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.62, \"learn_time_ms\": 9706.837, \"total_train_time_s\": 14.058367013931274}", "{\"n\": 11221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.9, \"learn_time_ms\": 9963.966, \"total_train_time_s\": 15.411436796188354}", "{\"n\": 11222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.03, \"learn_time_ms\": 10005.89, \"total_train_time_s\": 13.722879409790039}", "{\"n\": 11223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.46, \"learn_time_ms\": 10034.449, \"total_train_time_s\": 12.967631101608276}", "{\"n\": 11224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.46, \"learn_time_ms\": 10115.69, \"total_train_time_s\": 15.1048002243042}", "{\"n\": 11225, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.05, \"learn_time_ms\": 10158.664, \"total_train_time_s\": 13.707465171813965}", "{\"n\": 11226, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.26, \"learn_time_ms\": 10334.943, \"total_train_time_s\": 15.013531684875488}", "{\"n\": 11227, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.26, \"learn_time_ms\": 10289.457, \"total_train_time_s\": 12.824892044067383}", "{\"n\": 11228, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.26, \"learn_time_ms\": 10250.932, \"total_train_time_s\": 13.356273889541626}", "{\"n\": 11229, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.35, \"learn_time_ms\": 10277.117, \"total_train_time_s\": 13.339950799942017}", "{\"n\": 11230, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.56, \"learn_time_ms\": 10208.024, \"total_train_time_s\": 13.479711055755615}", "{\"n\": 11231, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.56, \"learn_time_ms\": 10008.875, \"total_train_time_s\": 13.40150260925293}", "{\"n\": 11232, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.56, \"learn_time_ms\": 9896.279, \"total_train_time_s\": 12.623592138290405}", "{\"n\": 11233, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.55, \"learn_time_ms\": 9944.076, \"total_train_time_s\": 13.403923749923706}", "{\"n\": 11234, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.06, \"learn_time_ms\": 9762.55, \"total_train_time_s\": 13.546958923339844}", "{\"n\": 11235, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.06, \"learn_time_ms\": 9708.615, \"total_train_time_s\": 13.16188669204712}", "{\"n\": 11236, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.08, \"learn_time_ms\": 9573.807, \"total_train_time_s\": 13.610088348388672}", "{\"n\": 11237, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.08, \"learn_time_ms\": 9637.064, \"total_train_time_s\": 13.518927097320557}", "{\"n\": 11238, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.79, \"learn_time_ms\": 9591.839, \"total_train_time_s\": 12.886090755462646}", "{\"n\": 11239, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.79, \"learn_time_ms\": 9758.956, \"total_train_time_s\": 14.809618949890137}", "{\"n\": 11240, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.7, \"learn_time_ms\": 9781.168, \"total_train_time_s\": 13.579904317855835}", "{\"n\": 11241, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.15, \"learn_time_ms\": 9741.876, \"total_train_time_s\": 13.061872720718384}", "{\"n\": 11242, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.15, \"learn_time_ms\": 9779.806, \"total_train_time_s\": 13.233391761779785}", "{\"n\": 11243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.15, \"learn_time_ms\": 9797.16, \"total_train_time_s\": 13.665465116500854}", "{\"n\": 11244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.19, \"learn_time_ms\": 9827.684, \"total_train_time_s\": 13.736665964126587}", "{\"n\": 11245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.03, \"learn_time_ms\": 9899.453, \"total_train_time_s\": 13.901188850402832}", "{\"n\": 11246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.03, \"learn_time_ms\": 9836.275, \"total_train_time_s\": 12.879390954971313}", "{\"n\": 11247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.65, \"learn_time_ms\": 9898.374, \"total_train_time_s\": 14.380428075790405}", "{\"n\": 11248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.26, \"learn_time_ms\": 10015.547, \"total_train_time_s\": 13.952056169509888}", "{\"n\": 11249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.88, \"learn_time_ms\": 9990.92, \"total_train_time_s\": 14.626798391342163}", "{\"n\": 11250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.4, \"learn_time_ms\": 9910.771, \"total_train_time_s\": 13.046874523162842}", "{\"n\": 11251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.16, \"learn_time_ms\": 9870.944, \"total_train_time_s\": 12.586649894714355}", "{\"n\": 11252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.71, \"learn_time_ms\": 9924.709, \"total_train_time_s\": 13.764824151992798}", "{\"n\": 11253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.71, \"learn_time_ms\": 9963.945, \"total_train_time_s\": 14.127501487731934}", "{\"n\": 11254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.8, \"learn_time_ms\": 9949.652, \"total_train_time_s\": 13.574538469314575}", "{\"n\": 11255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.38, \"learn_time_ms\": 9839.849, \"total_train_time_s\": 12.92478895187378}", "{\"n\": 11256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.45, \"learn_time_ms\": 9946.297, \"total_train_time_s\": 14.03008508682251}", "{\"n\": 11257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.45, \"learn_time_ms\": 9880.905, \"total_train_time_s\": 13.418036699295044}", "{\"n\": 11258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.02, \"learn_time_ms\": 9859.608, \"total_train_time_s\": 13.886691570281982}", "{\"n\": 11259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.96, \"learn_time_ms\": 9731.327, \"total_train_time_s\": 13.3784499168396}", "{\"n\": 11260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.01, \"learn_time_ms\": 9831.918, \"total_train_time_s\": 13.97366738319397}", "{\"n\": 11261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.02, \"learn_time_ms\": 9895.833, \"total_train_time_s\": 13.246431589126587}", "{\"n\": 11262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.33, \"learn_time_ms\": 9928.359, \"total_train_time_s\": 14.135857343673706}", "{\"n\": 11263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.33, \"learn_time_ms\": 9976.6, \"total_train_time_s\": 14.468663215637207}", "{\"n\": 11264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.16, \"learn_time_ms\": 9896.949, \"total_train_time_s\": 12.745269298553467}", "{\"n\": 11265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.86, \"learn_time_ms\": 10123.427, \"total_train_time_s\": 15.16003131866455}", "{\"n\": 11266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.5, \"learn_time_ms\": 10163.627, \"total_train_time_s\": 14.470634460449219}", "{\"n\": 11267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.5, \"learn_time_ms\": 10122.212, \"total_train_time_s\": 13.275460243225098}", "{\"n\": 11268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.13, \"learn_time_ms\": 10086.836, \"total_train_time_s\": 13.572989702224731}", "{\"n\": 11269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.13, \"learn_time_ms\": 9998.545, \"total_train_time_s\": 12.639672040939331}", "{\"n\": 11270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.52, \"learn_time_ms\": 9962.7, \"total_train_time_s\": 13.685180187225342}", "{\"n\": 11271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.74, \"learn_time_ms\": 9992.076, \"total_train_time_s\": 13.585520029067993}", "{\"n\": 11272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.86, \"learn_time_ms\": 9943.786, \"total_train_time_s\": 13.345205068588257}", "{\"n\": 11273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.79, \"learn_time_ms\": 9806.607, \"total_train_time_s\": 12.935849666595459}", "{\"n\": 11274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.79, \"learn_time_ms\": 9852.606, \"total_train_time_s\": 13.263429403305054}", "{\"n\": 11275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.52, \"learn_time_ms\": 9694.332, \"total_train_time_s\": 13.656562566757202}", "{\"n\": 11276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.57, \"learn_time_ms\": 9616.736, \"total_train_time_s\": 13.651105165481567}", "{\"n\": 11277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.57, \"learn_time_ms\": 9648.695, \"total_train_time_s\": 13.613547086715698}", "{\"n\": 11278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.35, \"learn_time_ms\": 9653.406, \"total_train_time_s\": 13.762186288833618}", "{\"n\": 11279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.18, \"learn_time_ms\": 9764.282, \"total_train_time_s\": 13.508806467056274}", "{\"n\": 11280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.72, \"learn_time_ms\": 9838.982, \"total_train_time_s\": 14.345383167266846}", "{\"n\": 11281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.72, \"learn_time_ms\": 9829.161, \"total_train_time_s\": 13.635740518569946}", "{\"n\": 11282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.71, \"learn_time_ms\": 9924.256, \"total_train_time_s\": 14.286604404449463}", "{\"n\": 11283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.13, \"learn_time_ms\": 10037.987, \"total_train_time_s\": 14.396016359329224}", "{\"n\": 11284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.13, \"learn_time_ms\": 10062.058, \"total_train_time_s\": 13.604242324829102}", "{\"n\": 11285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.13, \"learn_time_ms\": 10064.67, \"total_train_time_s\": 13.55784559249878}", "{\"n\": 11286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.94, \"learn_time_ms\": 10063.307, \"total_train_time_s\": 13.708873510360718}", "{\"n\": 11287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.75, \"learn_time_ms\": 10118.041, \"total_train_time_s\": 14.079127073287964}", "{\"n\": 11288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.56, \"learn_time_ms\": 10321.187, \"total_train_time_s\": 15.549692392349243}", "{\"n\": 11289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.56, \"learn_time_ms\": 10322.976, \"total_train_time_s\": 13.514472961425781}", "{\"n\": 11290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.66, \"learn_time_ms\": 10258.272, \"total_train_time_s\": 13.738295793533325}", "{\"n\": 11291, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.3, \"learn_time_ms\": 10360.612, \"total_train_time_s\": 14.491114616394043}", "{\"n\": 11292, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.42, \"learn_time_ms\": 10290.352, \"total_train_time_s\": 13.553910732269287}", "{\"n\": 11293, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.42, \"learn_time_ms\": 10155.594, \"total_train_time_s\": 13.10123872756958}", "{\"n\": 11294, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.91, \"learn_time_ms\": 10099.669, \"total_train_time_s\": 12.869699954986572}", "{\"n\": 11295, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 10053.746, \"total_train_time_s\": 13.160508871078491}", "{\"n\": 11296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 10012.029, \"total_train_time_s\": 13.622754573822021}", "{\"n\": 11297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 9958.967, \"total_train_time_s\": 13.507636547088623}", "{\"n\": 11298, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.51, \"learn_time_ms\": 9835.848, \"total_train_time_s\": 14.446678638458252}", "{\"n\": 11299, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.11, \"learn_time_ms\": 9957.705, \"total_train_time_s\": 14.721560955047607}", "{\"n\": 11300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.11, \"learn_time_ms\": 9946.503, \"total_train_time_s\": 13.448503017425537}", "{\"n\": 11301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.11, \"learn_time_ms\": 9821.759, \"total_train_time_s\": 13.39505124092102}", "{\"n\": 11302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.0, \"learn_time_ms\": 9754.76, \"total_train_time_s\": 12.994034051895142}", "{\"n\": 11303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.89, \"learn_time_ms\": 9817.202, \"total_train_time_s\": 13.731476068496704}", "{\"n\": 11304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.89, \"learn_time_ms\": 9832.09, \"total_train_time_s\": 13.072151184082031}", "{\"n\": 11305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.34, \"learn_time_ms\": 9813.801, \"total_train_time_s\": 13.020686626434326}", "{\"n\": 11306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.03, \"learn_time_ms\": 9805.903, \"total_train_time_s\": 13.137218952178955}", "{\"n\": 11307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.03, \"learn_time_ms\": 9897.494, \"total_train_time_s\": 14.460851907730103}", "{\"n\": 11308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.03, \"learn_time_ms\": 9794.117, \"total_train_time_s\": 13.28610634803772}", "{\"n\": 11309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.56, \"learn_time_ms\": 9635.524, \"total_train_time_s\": 13.24628472328186}", "{\"n\": 11310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.12, \"learn_time_ms\": 9659.218, \"total_train_time_s\": 13.546833753585815}", "{\"n\": 11311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.12, \"learn_time_ms\": 9701.748, \"total_train_time_s\": 13.605549812316895}", "{\"n\": 11312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.63, \"learn_time_ms\": 9750.029, \"total_train_time_s\": 13.645404577255249}", "{\"n\": 11313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.42, \"learn_time_ms\": 9758.253, \"total_train_time_s\": 13.72581672668457}", "{\"n\": 11314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.27, \"learn_time_ms\": 9831.904, \"total_train_time_s\": 13.646775007247925}", "{\"n\": 11315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.52, \"learn_time_ms\": 9890.534, \"total_train_time_s\": 13.431678295135498}", "{\"n\": 11316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.22, \"learn_time_ms\": 9893.486, \"total_train_time_s\": 13.292747735977173}", "{\"n\": 11317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.69, \"learn_time_ms\": 9865.458, \"total_train_time_s\": 14.145347118377686}", "{\"n\": 11318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.08, \"learn_time_ms\": 9856.417, \"total_train_time_s\": 13.333341836929321}", "{\"n\": 11319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.21, \"learn_time_ms\": 9890.168, \"total_train_time_s\": 13.643422842025757}", "{\"n\": 11320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.32, \"learn_time_ms\": 9920.725, \"total_train_time_s\": 13.912415266036987}", "{\"n\": 11321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3707.32, \"learn_time_ms\": 9942.566, \"total_train_time_s\": 13.892245054244995}", "{\"n\": 11322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.04, \"learn_time_ms\": 10106.722, \"total_train_time_s\": 15.027670621871948}", "{\"n\": 11323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.61, \"learn_time_ms\": 10057.13, \"total_train_time_s\": 12.995104551315308}", "{\"n\": 11324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.66, \"learn_time_ms\": 10029.755, \"total_train_time_s\": 13.358550786972046}", "{\"n\": 11325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.86, \"learn_time_ms\": 10041.067, \"total_train_time_s\": 13.555785655975342}", "{\"n\": 11326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.66, \"learn_time_ms\": 10068.314, \"total_train_time_s\": 13.679707050323486}", "{\"n\": 11327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.07, \"learn_time_ms\": 9971.923, \"total_train_time_s\": 13.069489002227783}", "{\"n\": 11328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.44, \"learn_time_ms\": 10020.633, \"total_train_time_s\": 13.663621425628662}", "{\"n\": 11329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.08, \"learn_time_ms\": 10070.339, \"total_train_time_s\": 13.9602632522583}", "{\"n\": 11330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.08, \"learn_time_ms\": 10014.522, \"total_train_time_s\": 13.615296840667725}", "{\"n\": 11331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.21, \"learn_time_ms\": 9916.001, \"total_train_time_s\": 12.909789085388184}", "{\"n\": 11332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.97, \"learn_time_ms\": 9757.93, \"total_train_time_s\": 13.582939386367798}", "{\"n\": 11333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.61, \"learn_time_ms\": 9795.884, \"total_train_time_s\": 13.379227876663208}", "{\"n\": 11334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.61, \"learn_time_ms\": 9814.609, \"total_train_time_s\": 13.530389785766602}", "{\"n\": 11335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.22, \"learn_time_ms\": 9819.681, \"total_train_time_s\": 13.633214235305786}", "{\"n\": 11336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.48, \"learn_time_ms\": 9815.426, \"total_train_time_s\": 13.530780792236328}", "{\"n\": 11337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.48, \"learn_time_ms\": 9845.596, \"total_train_time_s\": 13.571620225906372}", "{\"n\": 11338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.48, \"learn_time_ms\": 9744.556, \"total_train_time_s\": 12.599295616149902}", "{\"n\": 11339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.62, \"learn_time_ms\": 9798.749, \"total_train_time_s\": 14.57854962348938}", "{\"n\": 11340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.84, \"learn_time_ms\": 9771.59, \"total_train_time_s\": 13.275126695632935}", "{\"n\": 11341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.84, \"learn_time_ms\": 9953.856, \"total_train_time_s\": 14.658458471298218}", "{\"n\": 11342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.81, \"learn_time_ms\": 9984.939, \"total_train_time_s\": 13.853720426559448}", "{\"n\": 11343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.34, \"learn_time_ms\": 10004.853, \"total_train_time_s\": 13.545926809310913}", "{\"n\": 11344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.51, \"learn_time_ms\": 10001.134, \"total_train_time_s\": 13.606088399887085}", "{\"n\": 11345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.51, \"learn_time_ms\": 9964.901, \"total_train_time_s\": 13.378833770751953}", "{\"n\": 11346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.27, \"learn_time_ms\": 10015.133, \"total_train_time_s\": 14.045382738113403}", "{\"n\": 11347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.94, \"learn_time_ms\": 10070.618, \"total_train_time_s\": 13.987202644348145}", "{\"n\": 11348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.13, \"learn_time_ms\": 10198.437, \"total_train_time_s\": 13.987627029418945}", "{\"n\": 11349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.13, \"learn_time_ms\": 10124.011, \"total_train_time_s\": 13.91688060760498}", "{\"n\": 11350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.22, \"learn_time_ms\": 10139.096, \"total_train_time_s\": 13.37425446510315}", "{\"n\": 11351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.04, \"learn_time_ms\": 10146.084, \"total_train_time_s\": 14.785605430603027}", "{\"n\": 11352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.04, \"learn_time_ms\": 10186.208, \"total_train_time_s\": 14.28947138786316}", "{\"n\": 11353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.28, \"learn_time_ms\": 10252.42, \"total_train_time_s\": 14.402939796447754}", "{\"n\": 11354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.28, \"learn_time_ms\": 10210.889, \"total_train_time_s\": 13.266965866088867}", "{\"n\": 11355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.98, \"learn_time_ms\": 10187.289, \"total_train_time_s\": 12.956894874572754}", "{\"n\": 11356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.98, \"learn_time_ms\": 10090.895, \"total_train_time_s\": 13.146334171295166}", "{\"n\": 11357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.18, \"learn_time_ms\": 9982.812, \"total_train_time_s\": 12.972873449325562}", "{\"n\": 11358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.18, \"learn_time_ms\": 10036.47, \"total_train_time_s\": 14.544045448303223}", "{\"n\": 11359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.64, \"learn_time_ms\": 9959.723, \"total_train_time_s\": 13.046903133392334}", "{\"n\": 11360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.47, \"learn_time_ms\": 9905.077, \"total_train_time_s\": 12.779889345169067}", "{\"n\": 11361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.94, \"learn_time_ms\": 9704.537, \"total_train_time_s\": 12.929401874542236}", "{\"n\": 11362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.94, \"learn_time_ms\": 9611.294, \"total_train_time_s\": 13.45956039428711}", "{\"n\": 11363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.79, \"learn_time_ms\": 9643.658, \"total_train_time_s\": 14.499290466308594}", "{\"n\": 11364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.92, \"learn_time_ms\": 9649.741, \"total_train_time_s\": 13.264358758926392}", "{\"n\": 11365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.17, \"learn_time_ms\": 9680.01, \"total_train_time_s\": 13.332018375396729}", "{\"n\": 11366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.89, \"learn_time_ms\": 9802.836, \"total_train_time_s\": 14.557295083999634}", "{\"n\": 11367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.07, \"learn_time_ms\": 9751.513, \"total_train_time_s\": 12.418574094772339}", "{\"n\": 11368, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.89, \"learn_time_ms\": 9704.907, \"total_train_time_s\": 14.07759141921997}", "{\"n\": 11369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.89, \"learn_time_ms\": 9787.621, \"total_train_time_s\": 14.152270793914795}", "{\"n\": 11370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.85, \"learn_time_ms\": 9860.435, \"total_train_time_s\": 13.400956392288208}", "{\"n\": 11371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.22, \"learn_time_ms\": 9972.614, \"total_train_time_s\": 13.971109390258789}", "{\"n\": 11372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.41, \"learn_time_ms\": 9970.862, \"total_train_time_s\": 13.497407913208008}", "{\"n\": 11373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.41, \"learn_time_ms\": 9996.457, \"total_train_time_s\": 15.120471954345703}", "{\"n\": 11374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.0, \"learn_time_ms\": 10089.139, \"total_train_time_s\": 14.139466524124146}", "{\"n\": 11375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.11, \"learn_time_ms\": 10113.217, \"total_train_time_s\": 13.757948637008667}", "{\"n\": 11376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.11, \"learn_time_ms\": 9996.896, \"total_train_time_s\": 13.059778213500977}", "{\"n\": 11377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.11, \"learn_time_ms\": 10082.892, \"total_train_time_s\": 13.365832328796387}", "{\"n\": 11378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.19, \"learn_time_ms\": 10159.541, \"total_train_time_s\": 14.872695922851562}", "{\"n\": 11379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.48, \"learn_time_ms\": 10200.336, \"total_train_time_s\": 14.533587455749512}", "{\"n\": 11380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.48, \"learn_time_ms\": 10148.884, \"total_train_time_s\": 13.101853370666504}", "{\"n\": 11381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.48, \"learn_time_ms\": 10107.654, \"total_train_time_s\": 13.63975214958191}", "{\"n\": 11382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.18, \"learn_time_ms\": 10069.735, \"total_train_time_s\": 12.787854194641113}", "{\"n\": 11383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.49, \"learn_time_ms\": 9975.305, \"total_train_time_s\": 13.795929193496704}", "{\"n\": 11384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.49, \"learn_time_ms\": 9869.324, \"total_train_time_s\": 12.950978755950928}", "{\"n\": 11385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.49, \"learn_time_ms\": 9845.488, \"total_train_time_s\": 13.263880014419556}", "{\"n\": 11386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.24, \"learn_time_ms\": 9894.622, \"total_train_time_s\": 13.612787961959839}", "{\"n\": 11387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.24, \"learn_time_ms\": 9911.123, \"total_train_time_s\": 13.35484790802002}", "{\"n\": 11388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.24, \"learn_time_ms\": 9909.298, \"total_train_time_s\": 14.691751956939697}", "{\"n\": 11389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.66, \"learn_time_ms\": 9876.042, \"total_train_time_s\": 14.250848054885864}", "{\"n\": 11390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.32, \"learn_time_ms\": 9977.655, \"total_train_time_s\": 13.911276817321777}", "{\"n\": 11391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.32, \"learn_time_ms\": 9964.681, \"total_train_time_s\": 13.287256956100464}", "{\"n\": 11392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.45, \"learn_time_ms\": 9973.367, \"total_train_time_s\": 13.059360980987549}", "{\"n\": 11393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.6, \"learn_time_ms\": 9946.343, \"total_train_time_s\": 13.579642534255981}", "{\"n\": 11394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.91, \"learn_time_ms\": 10046.436, \"total_train_time_s\": 14.059168338775635}", "{\"n\": 11395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.91, \"learn_time_ms\": 10033.981, \"total_train_time_s\": 13.20903754234314}", "{\"n\": 11396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.88, \"learn_time_ms\": 9952.089, \"total_train_time_s\": 12.81782865524292}", "{\"n\": 11397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.18, \"learn_time_ms\": 9973.924, \"total_train_time_s\": 13.748108148574829}", "{\"n\": 11398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.18, \"learn_time_ms\": 9880.159, \"total_train_time_s\": 13.820438861846924}", "{\"n\": 11399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.18, \"learn_time_ms\": 9822.718, \"total_train_time_s\": 13.639153480529785}", "{\"n\": 11400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.31, \"learn_time_ms\": 9768.468, \"total_train_time_s\": 13.387690544128418}", "{\"n\": 11401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.99, \"learn_time_ms\": 9737.377, \"total_train_time_s\": 13.040862798690796}", "{\"n\": 11402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.99, \"learn_time_ms\": 9719.442, \"total_train_time_s\": 12.845122337341309}", "{\"n\": 11403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.99, \"learn_time_ms\": 9675.794, \"total_train_time_s\": 13.23172378540039}", "{\"n\": 11404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.09, \"learn_time_ms\": 9638.608, \"total_train_time_s\": 13.69658899307251}", "{\"n\": 11405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.62, \"learn_time_ms\": 9649.887, \"total_train_time_s\": 13.328666925430298}", "{\"n\": 11406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.62, \"learn_time_ms\": 9738.009, \"total_train_time_s\": 13.829696655273438}", "{\"n\": 11407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.62, \"learn_time_ms\": 9817.493, \"total_train_time_s\": 14.36935019493103}", "{\"n\": 11408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.16, \"learn_time_ms\": 9864.183, \"total_train_time_s\": 14.49903130531311}", "{\"n\": 11409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.16, \"learn_time_ms\": 9860.857, \"total_train_time_s\": 13.564295768737793}", "{\"n\": 11410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.16, \"learn_time_ms\": 9807.591, \"total_train_time_s\": 12.880639791488647}", "{\"n\": 11411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.22, \"learn_time_ms\": 9898.297, \"total_train_time_s\": 14.027444839477539}", "{\"n\": 11412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.78, \"learn_time_ms\": 9973.354, \"total_train_time_s\": 13.488536834716797}", "{\"n\": 11413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.78, \"learn_time_ms\": 9978.772, \"total_train_time_s\": 13.367563962936401}", "{\"n\": 11414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.78, \"learn_time_ms\": 9995.985, \"total_train_time_s\": 13.727378129959106}", "{\"n\": 11415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.24, \"learn_time_ms\": 10039.27, \"total_train_time_s\": 13.78672480583191}", "{\"n\": 11416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.89, \"learn_time_ms\": 10077.361, \"total_train_time_s\": 14.216397762298584}", "{\"n\": 11417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.89, \"learn_time_ms\": 9963.881, \"total_train_time_s\": 13.267543077468872}", "{\"n\": 11418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.89, \"learn_time_ms\": 9945.719, \"total_train_time_s\": 14.445564270019531}", "{\"n\": 11419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.96, \"learn_time_ms\": 10095.334, \"total_train_time_s\": 14.917403936386108}", "{\"n\": 11420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.13, \"learn_time_ms\": 10158.572, \"total_train_time_s\": 13.570268630981445}", "{\"n\": 11421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.92, \"learn_time_ms\": 10142.648, \"total_train_time_s\": 14.196886777877808}", "{\"n\": 11422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.15, \"learn_time_ms\": 10082.311, \"total_train_time_s\": 13.126457452774048}", "{\"n\": 11423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.02, \"learn_time_ms\": 10097.094, \"total_train_time_s\": 13.285242080688477}", "{\"n\": 11424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3721.11, \"learn_time_ms\": 10032.984, \"total_train_time_s\": 13.148178577423096}", "{\"n\": 11425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.97, \"learn_time_ms\": 10056.782, \"total_train_time_s\": 14.179965257644653}", "{\"n\": 11426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.28, \"learn_time_ms\": 10038.137, \"total_train_time_s\": 13.724460124969482}", "{\"n\": 11427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.28, \"learn_time_ms\": 10123.691, \"total_train_time_s\": 14.169803619384766}", "{\"n\": 11428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.24, \"learn_time_ms\": 9923.316, \"total_train_time_s\": 12.084258794784546}", "{\"n\": 11429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.16, \"learn_time_ms\": 9784.505, \"total_train_time_s\": 13.489576578140259}", "{\"n\": 11430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.52, \"learn_time_ms\": 9869.338, \"total_train_time_s\": 14.308101892471313}", "{\"n\": 11431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.52, \"learn_time_ms\": 9832.691, \"total_train_time_s\": 13.556314706802368}", "{\"n\": 11432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.31, \"learn_time_ms\": 9942.983, \"total_train_time_s\": 13.954366445541382}", "{\"n\": 11433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.09, \"learn_time_ms\": 9944.497, \"total_train_time_s\": 13.476696729660034}", "{\"n\": 11434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.09, \"learn_time_ms\": 9967.252, \"total_train_time_s\": 13.429203748703003}", "{\"n\": 11435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.4, \"learn_time_ms\": 9875.877, \"total_train_time_s\": 13.166203260421753}", "{\"n\": 11436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.03, \"learn_time_ms\": 9864.223, \"total_train_time_s\": 14.048898220062256}", "{\"n\": 11437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 9880.072, \"total_train_time_s\": 14.241431713104248}", "{\"n\": 11438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.37, \"learn_time_ms\": 9948.286, \"total_train_time_s\": 12.717768430709839}", "{\"n\": 11439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.59, \"learn_time_ms\": 9902.878, \"total_train_time_s\": 13.17999529838562}", "{\"n\": 11440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.57, \"learn_time_ms\": 9808.772, \"total_train_time_s\": 13.466266870498657}", "{\"n\": 11441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.57, \"learn_time_ms\": 9872.078, \"total_train_time_s\": 14.304949522018433}", "{\"n\": 11442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.19, \"learn_time_ms\": 9844.933, \"total_train_time_s\": 13.793398141860962}", "{\"n\": 11443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 9802.47, \"total_train_time_s\": 13.001079559326172}", "{\"n\": 11444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.02, \"learn_time_ms\": 9880.014, \"total_train_time_s\": 14.246344327926636}", "{\"n\": 11445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.02, \"learn_time_ms\": 9892.252, \"total_train_time_s\": 13.144151449203491}", "{\"n\": 11446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.9, \"learn_time_ms\": 9986.512, \"total_train_time_s\": 14.510551452636719}", "{\"n\": 11447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.44, \"learn_time_ms\": 10029.826, \"total_train_time_s\": 14.57253384590149}", "{\"n\": 11448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.2, \"learn_time_ms\": 10003.089, \"total_train_time_s\": 12.508513689041138}", "{\"n\": 11449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.2, \"learn_time_ms\": 10173.034, \"total_train_time_s\": 14.86788272857666}", "{\"n\": 11450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.83, \"learn_time_ms\": 10134.564, \"total_train_time_s\": 13.178494930267334}", "{\"n\": 11451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.97, \"learn_time_ms\": 10079.479, \"total_train_time_s\": 13.513242483139038}", "{\"n\": 11452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.97, \"learn_time_ms\": 10087.649, \"total_train_time_s\": 14.071380615234375}", "{\"n\": 11453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.85, \"learn_time_ms\": 10253.617, \"total_train_time_s\": 14.58634090423584}", "{\"n\": 11454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.76, \"learn_time_ms\": 10066.778, \"total_train_time_s\": 12.543191909790039}", "{\"n\": 11455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.76, \"learn_time_ms\": 10031.929, \"total_train_time_s\": 12.927278518676758}", "{\"n\": 11456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.76, \"learn_time_ms\": 9975.74, \"total_train_time_s\": 14.314752578735352}", "{\"n\": 11457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.44, \"learn_time_ms\": 9868.22, \"total_train_time_s\": 13.53179407119751}", "{\"n\": 11458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.89, \"learn_time_ms\": 10027.193, \"total_train_time_s\": 14.07182240486145}", "{\"n\": 11459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.89, \"learn_time_ms\": 9967.13, \"total_train_time_s\": 14.184705257415771}", "{\"n\": 11460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.93, \"learn_time_ms\": 9933.059, \"total_train_time_s\": 12.781136512756348}", "{\"n\": 11461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.88, \"learn_time_ms\": 9819.842, \"total_train_time_s\": 12.522948503494263}", "{\"n\": 11462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.18, \"learn_time_ms\": 9797.788, \"total_train_time_s\": 13.521996974945068}", "{\"n\": 11463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.18, \"learn_time_ms\": 9792.754, \"total_train_time_s\": 14.747040271759033}", "{\"n\": 11464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.82, \"learn_time_ms\": 9864.626, \"total_train_time_s\": 13.203103065490723}", "{\"n\": 11465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.61, \"learn_time_ms\": 9948.323, \"total_train_time_s\": 13.799079895019531}", "{\"n\": 11466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.52, \"learn_time_ms\": 10034.864, \"total_train_time_s\": 14.835407733917236}", "{\"n\": 11467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.52, \"learn_time_ms\": 10027.394, \"total_train_time_s\": 13.856321096420288}", "{\"n\": 11468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.32, \"learn_time_ms\": 9952.232, \"total_train_time_s\": 13.338451147079468}", "{\"n\": 11469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.08, \"learn_time_ms\": 9843.82, \"total_train_time_s\": 13.184415578842163}", "{\"n\": 11470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.8, \"learn_time_ms\": 9977.913, \"total_train_time_s\": 14.102093935012817}", "{\"n\": 11471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.8, \"learn_time_ms\": 10173.181, \"total_train_time_s\": 14.58031415939331}", "{\"n\": 11472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.54, \"learn_time_ms\": 10115.169, \"total_train_time_s\": 12.964398622512817}", "{\"n\": 11473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.92, \"learn_time_ms\": 9984.822, \"total_train_time_s\": 13.306007146835327}", "{\"n\": 11474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.68, \"learn_time_ms\": 9972.29, \"total_train_time_s\": 12.940512657165527}", "{\"n\": 11475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.85, \"learn_time_ms\": 10006.169, \"total_train_time_s\": 14.047343969345093}", "{\"n\": 11476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.04, \"learn_time_ms\": 9926.186, \"total_train_time_s\": 14.018131256103516}", "{\"n\": 11477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.22, \"learn_time_ms\": 9925.726, \"total_train_time_s\": 13.570753335952759}", "{\"n\": 11478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 9870.371, \"total_train_time_s\": 12.737591743469238}", "{\"n\": 11479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.12, \"learn_time_ms\": 9870.464, \"total_train_time_s\": 13.039295196533203}", "{\"n\": 11480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.69, \"learn_time_ms\": 9921.874, \"total_train_time_s\": 14.795127630233765}", "{\"n\": 11481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.51, \"learn_time_ms\": 9922.78, \"total_train_time_s\": 14.43687629699707}", "{\"n\": 11482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.51, \"learn_time_ms\": 9988.147, \"total_train_time_s\": 13.791229963302612}", "{\"n\": 11483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.62, \"learn_time_ms\": 9987.394, \"total_train_time_s\": 13.205068826675415}", "{\"n\": 11484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.62, \"learn_time_ms\": 10102.26, \"total_train_time_s\": 14.158381938934326}", "{\"n\": 11485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.42, \"learn_time_ms\": 10142.975, \"total_train_time_s\": 14.53172492980957}", "{\"n\": 11486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.21, \"learn_time_ms\": 10105.221, \"total_train_time_s\": 13.894827842712402}", "{\"n\": 11487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.03, \"learn_time_ms\": 10054.12, \"total_train_time_s\": 12.952704429626465}", "{\"n\": 11488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.55, \"learn_time_ms\": 10070.81, \"total_train_time_s\": 12.881086349487305}", "{\"n\": 11489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.57, \"learn_time_ms\": 10164.091, \"total_train_time_s\": 14.190516233444214}", "{\"n\": 11490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.51, \"learn_time_ms\": 9979.454, \"total_train_time_s\": 12.730730772018433}", "{\"n\": 11491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.07, \"learn_time_ms\": 9842.55, \"total_train_time_s\": 13.01132607460022}", "{\"n\": 11492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.07, \"learn_time_ms\": 9812.037, \"total_train_time_s\": 13.424307823181152}", "{\"n\": 11493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.31, \"learn_time_ms\": 9847.801, \"total_train_time_s\": 13.788850545883179}", "{\"n\": 11494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.21, \"learn_time_ms\": 9770.726, \"total_train_time_s\": 13.368094205856323}", "{\"n\": 11495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.21, \"learn_time_ms\": 9676.405, \"total_train_time_s\": 13.570246458053589}", "{\"n\": 11496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.21, \"learn_time_ms\": 9697.435, \"total_train_time_s\": 14.068675994873047}", "{\"n\": 11497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.29, \"learn_time_ms\": 9759.752, \"total_train_time_s\": 13.66773796081543}", "{\"n\": 11498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.63, \"learn_time_ms\": 9778.055, \"total_train_time_s\": 13.25287413597107}", "{\"n\": 11499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.63, \"learn_time_ms\": 9762.973, \"total_train_time_s\": 14.00386643409729}", "{\"n\": 11500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.08, \"learn_time_ms\": 9777.649, \"total_train_time_s\": 12.98005223274231}", "{\"n\": 11501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.03, \"learn_time_ms\": 9836.272, \"total_train_time_s\": 13.468315601348877}", "{\"n\": 11502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.82, \"learn_time_ms\": 9944.174, \"total_train_time_s\": 14.480033874511719}", "{\"n\": 11503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.82, \"learn_time_ms\": 10016.2, \"total_train_time_s\": 14.613148927688599}", "{\"n\": 11504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.07, \"learn_time_ms\": 10084.747, \"total_train_time_s\": 14.028760433197021}", "{\"n\": 11505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.81, \"learn_time_ms\": 10045.545, \"total_train_time_s\": 13.265085697174072}", "{\"n\": 11506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.81, \"learn_time_ms\": 9966.674, \"total_train_time_s\": 13.504390954971313}", "{\"n\": 11507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.27, \"learn_time_ms\": 10066.712, \"total_train_time_s\": 14.533254146575928}", "{\"n\": 11508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.95, \"learn_time_ms\": 10142.709, \"total_train_time_s\": 14.086137533187866}", "{\"n\": 11509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.38, \"learn_time_ms\": 10066.346, \"total_train_time_s\": 13.229052066802979}", "{\"n\": 11510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.38, \"learn_time_ms\": 10171.294, \"total_train_time_s\": 13.886622667312622}", "{\"n\": 11511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.94, \"learn_time_ms\": 10231.05, \"total_train_time_s\": 14.153478622436523}", "{\"n\": 11512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.88, \"learn_time_ms\": 10161.421, \"total_train_time_s\": 13.95561957359314}", "{\"n\": 11513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.88, \"learn_time_ms\": 10015.683, \"total_train_time_s\": 13.191247463226318}", "{\"n\": 11514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.88, \"learn_time_ms\": 9963.29, \"total_train_time_s\": 13.564452171325684}", "{\"n\": 11515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.08, \"learn_time_ms\": 10008.489, \"total_train_time_s\": 13.527044296264648}", "{\"n\": 11516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.08, \"learn_time_ms\": 9964.074, \"total_train_time_s\": 12.88191556930542}", "{\"n\": 11517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.08, \"learn_time_ms\": 9725.833, \"total_train_time_s\": 12.523611783981323}", "{\"n\": 11518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.43, \"learn_time_ms\": 9711.062, \"total_train_time_s\": 13.749816656112671}", "{\"n\": 11519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.84, \"learn_time_ms\": 9832.356, \"total_train_time_s\": 14.204461336135864}", "{\"n\": 11520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.75, \"learn_time_ms\": 9770.715, \"total_train_time_s\": 13.476664781570435}", "{\"n\": 11521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.75, \"learn_time_ms\": 9726.513, \"total_train_time_s\": 13.825998783111572}", "{\"n\": 11522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.18, \"learn_time_ms\": 9737.235, \"total_train_time_s\": 13.887558937072754}", "{\"n\": 11523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.71, \"learn_time_ms\": 9820.312, \"total_train_time_s\": 13.872190952301025}", "{\"n\": 11524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.71, \"learn_time_ms\": 9774.514, \"total_train_time_s\": 13.05437707901001}", "{\"n\": 11525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.71, \"learn_time_ms\": 9800.671, \"total_train_time_s\": 14.073805570602417}", "{\"n\": 11526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.2, \"learn_time_ms\": 9862.842, \"total_train_time_s\": 13.403335809707642}", "{\"n\": 11527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 9992.622, \"total_train_time_s\": 13.583815813064575}", "{\"n\": 11528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 9928.669, \"total_train_time_s\": 13.334590435028076}", "{\"n\": 11529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 9820.638, \"total_train_time_s\": 13.122812747955322}", "{\"n\": 11530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.15, \"learn_time_ms\": 9847.832, \"total_train_time_s\": 13.770433187484741}", "{\"n\": 11531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.35, \"learn_time_ms\": 9708.007, \"total_train_time_s\": 12.34883165359497}", "{\"n\": 11532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.35, \"learn_time_ms\": 9788.352, \"total_train_time_s\": 14.664562225341797}", "{\"n\": 11533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.11, \"learn_time_ms\": 9755.738, \"total_train_time_s\": 13.493206977844238}", "{\"n\": 11534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.18, \"learn_time_ms\": 9821.391, \"total_train_time_s\": 13.741468906402588}", "{\"n\": 11535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.18, \"learn_time_ms\": 9881.707, \"total_train_time_s\": 14.493588924407959}", "{\"n\": 11536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.18, \"learn_time_ms\": 9908.25, \"total_train_time_s\": 13.462285041809082}", "{\"n\": 11537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.79, \"learn_time_ms\": 9883.186, \"total_train_time_s\": 13.391982316970825}", "{\"n\": 11538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.86, \"learn_time_ms\": 9883.586, \"total_train_time_s\": 13.071946620941162}", "{\"n\": 11539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.86, \"learn_time_ms\": 9915.852, \"total_train_time_s\": 13.847347736358643}", "{\"n\": 11540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.86, \"learn_time_ms\": 10030.055, \"total_train_time_s\": 14.740097522735596}", "{\"n\": 11541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.86, \"learn_time_ms\": 10092.989, \"total_train_time_s\": 13.005858898162842}", "{\"n\": 11542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.83, \"learn_time_ms\": 10025.369, \"total_train_time_s\": 14.111618995666504}", "{\"n\": 11543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.83, \"learn_time_ms\": 10120.966, \"total_train_time_s\": 14.362905979156494}", "{\"n\": 11544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.83, \"learn_time_ms\": 10092.475, \"total_train_time_s\": 13.641571283340454}", "{\"n\": 11545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.43, \"learn_time_ms\": 9964.113, \"total_train_time_s\": 13.110708236694336}", "{\"n\": 11546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.43, \"learn_time_ms\": 10024.351, \"total_train_time_s\": 14.120567321777344}", "{\"n\": 11547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.43, \"learn_time_ms\": 10012.98, \"total_train_time_s\": 13.321613788604736}", "{\"n\": 11548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.86, \"learn_time_ms\": 10091.753, \"total_train_time_s\": 13.850850105285645}", "{\"n\": 11549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.04, \"learn_time_ms\": 10067.194, \"total_train_time_s\": 13.241851806640625}", "{\"n\": 11550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.04, \"learn_time_ms\": 9934.742, \"total_train_time_s\": 13.509910106658936}", "{\"n\": 11551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.63, \"learn_time_ms\": 10007.612, \"total_train_time_s\": 13.711254119873047}", "{\"n\": 11552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.04, \"learn_time_ms\": 9928.859, \"total_train_time_s\": 13.337027072906494}", "{\"n\": 11553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.04, \"learn_time_ms\": 9859.563, \"total_train_time_s\": 13.780493021011353}", "{\"n\": 11554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.04, \"learn_time_ms\": 9853.969, \"total_train_time_s\": 13.233577013015747}", "{\"n\": 11555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.75, \"learn_time_ms\": 9917.424, \"total_train_time_s\": 13.881433486938477}", "{\"n\": 11556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.75, \"learn_time_ms\": 9874.12, \"total_train_time_s\": 13.74228286743164}", "{\"n\": 11557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.75, \"learn_time_ms\": 9958.563, \"total_train_time_s\": 14.023956775665283}", "{\"n\": 11558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.77, \"learn_time_ms\": 9860.598, \"total_train_time_s\": 12.856184959411621}", "{\"n\": 11559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 9848.3, \"total_train_time_s\": 13.166998624801636}", "{\"n\": 11560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 9805.2, \"total_train_time_s\": 12.825907468795776}", "{\"n\": 11561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.74, \"learn_time_ms\": 9769.105, \"total_train_time_s\": 13.537368059158325}", "{\"n\": 11562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 9785.929, \"total_train_time_s\": 13.506796598434448}", "{\"n\": 11563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.85, \"learn_time_ms\": 9806.892, \"total_train_time_s\": 14.04043960571289}", "{\"n\": 11564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.67, \"learn_time_ms\": 9887.81, \"total_train_time_s\": 14.095285177230835}", "{\"n\": 11565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.43, \"learn_time_ms\": 9920.968, \"total_train_time_s\": 14.136162757873535}", "{\"n\": 11566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.47, \"learn_time_ms\": 9909.907, \"total_train_time_s\": 13.824944496154785}", "{\"n\": 11567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.47, \"learn_time_ms\": 9941.093, \"total_train_time_s\": 14.621641635894775}", "{\"n\": 11568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.35, \"learn_time_ms\": 9984.872, \"total_train_time_s\": 13.449567794799805}", "{\"n\": 11569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.35, \"learn_time_ms\": 10059.834, \"total_train_time_s\": 14.00746464729309}", "{\"n\": 11570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.31, \"learn_time_ms\": 10070.189, \"total_train_time_s\": 13.004381656646729}", "{\"n\": 11571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.25, \"learn_time_ms\": 10125.357, \"total_train_time_s\": 14.003397226333618}", "{\"n\": 11572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 10132.221, \"total_train_time_s\": 13.652698516845703}", "{\"n\": 11573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.12, \"learn_time_ms\": 10150.766, \"total_train_time_s\": 14.218961238861084}", "{\"n\": 11574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.17, \"learn_time_ms\": 10130.414, \"total_train_time_s\": 14.137794733047485}", "{\"n\": 11575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.06, \"learn_time_ms\": 10196.78, \"total_train_time_s\": 14.80331802368164}", "{\"n\": 11576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.06, \"learn_time_ms\": 10185.475, \"total_train_time_s\": 13.8048574924469}", "{\"n\": 11577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.87, \"learn_time_ms\": 10053.742, \"total_train_time_s\": 13.046481609344482}", "{\"n\": 11578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.87, \"learn_time_ms\": 10092.044, \"total_train_time_s\": 13.79934048652649}", "{\"n\": 11579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.06, \"learn_time_ms\": 10068.445, \"total_train_time_s\": 13.726929903030396}", "{\"n\": 11580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.38, \"learn_time_ms\": 10128.815, \"total_train_time_s\": 14.04337477684021}", "{\"n\": 11581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.3, \"learn_time_ms\": 9987.174, \"total_train_time_s\": 12.686383485794067}", "{\"n\": 11582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.29, \"learn_time_ms\": 9957.541, \"total_train_time_s\": 13.230418920516968}", "{\"n\": 11583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.75, \"learn_time_ms\": 9845.027, \"total_train_time_s\": 12.826052188873291}", "{\"n\": 11584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.46, \"learn_time_ms\": 9783.505, \"total_train_time_s\": 13.533403158187866}", "{\"n\": 11585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.87, \"learn_time_ms\": 9570.693, \"total_train_time_s\": 12.5933096408844}", "{\"n\": 11586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.61, \"learn_time_ms\": 9604.66, \"total_train_time_s\": 13.937179327011108}", "{\"n\": 11587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.03, \"learn_time_ms\": 9785.199, \"total_train_time_s\": 14.936675786972046}", "{\"n\": 11588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.87, \"learn_time_ms\": 9769.662, \"total_train_time_s\": 13.548463582992554}", "{\"n\": 11589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.16, \"learn_time_ms\": 9767.735, \"total_train_time_s\": 13.643290042877197}", "{\"n\": 11590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.16, \"learn_time_ms\": 9827.605, \"total_train_time_s\": 14.193671464920044}", "{\"n\": 11591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.82, \"learn_time_ms\": 9943.038, \"total_train_time_s\": 13.61241364479065}", "{\"n\": 11592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.99, \"learn_time_ms\": 9975.896, \"total_train_time_s\": 13.453142881393433}", "{\"n\": 11593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.86, \"learn_time_ms\": 9954.945, \"total_train_time_s\": 12.747865915298462}", "{\"n\": 11594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.08, \"learn_time_ms\": 9940.405, \"total_train_time_s\": 13.172163963317871}", "{\"n\": 11595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.55, \"learn_time_ms\": 10056.224, \"total_train_time_s\": 13.719759225845337}", "{\"n\": 11596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.55, \"learn_time_ms\": 10058.77, \"total_train_time_s\": 14.1427640914917}", "{\"n\": 11597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.09, \"learn_time_ms\": 9935.084, \"total_train_time_s\": 13.704405784606934}", "{\"n\": 11598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.94, \"learn_time_ms\": 9978.44, \"total_train_time_s\": 14.166660070419312}", "{\"n\": 11599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.94, \"learn_time_ms\": 10017.879, \"total_train_time_s\": 14.095752716064453}", "{\"n\": 11600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.68, \"learn_time_ms\": 9890.483, \"total_train_time_s\": 13.180666208267212}", "{\"n\": 11601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 9909.089, \"total_train_time_s\": 13.839863300323486}", "{\"n\": 11602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.19, \"learn_time_ms\": 9993.189, \"total_train_time_s\": 14.400701999664307}", "{\"n\": 11603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.71, \"learn_time_ms\": 10152.903, \"total_train_time_s\": 14.396142482757568}", "{\"n\": 11604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.66, \"learn_time_ms\": 10238.912, \"total_train_time_s\": 14.00283694267273}", "{\"n\": 11605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.1, \"learn_time_ms\": 10164.188, \"total_train_time_s\": 13.16120457649231}", "{\"n\": 11606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.27, \"learn_time_ms\": 10124.962, \"total_train_time_s\": 13.539225816726685}", "{\"n\": 11607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.36, \"learn_time_ms\": 10151.936, \"total_train_time_s\": 13.7879638671875}", "{\"n\": 11608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.11, \"learn_time_ms\": 10072.763, \"total_train_time_s\": 13.524278402328491}", "{\"n\": 11609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.11, \"learn_time_ms\": 10024.901, \"total_train_time_s\": 13.699779987335205}", "{\"n\": 11610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.13, \"learn_time_ms\": 10059.478, \"total_train_time_s\": 13.273817777633667}", "{\"n\": 11611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.14, \"learn_time_ms\": 10118.43, \"total_train_time_s\": 14.358550310134888}", "{\"n\": 11612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.27, \"learn_time_ms\": 10052.735, \"total_train_time_s\": 13.732739210128784}", "{\"n\": 11613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.68, \"learn_time_ms\": 9987.365, \"total_train_time_s\": 13.611105918884277}", "{\"n\": 11614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.68, \"learn_time_ms\": 9838.389, \"total_train_time_s\": 12.65282654762268}", "{\"n\": 11615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.21, \"learn_time_ms\": 9901.983, \"total_train_time_s\": 13.60535717010498}", "{\"n\": 11616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.06, \"learn_time_ms\": 9878.651, \"total_train_time_s\": 13.23433256149292}", "{\"n\": 11617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.11, \"learn_time_ms\": 9803.982, \"total_train_time_s\": 13.178642272949219}", "{\"n\": 11618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.11, \"learn_time_ms\": 9980.851, \"total_train_time_s\": 14.975781679153442}", "{\"n\": 11619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.59, \"learn_time_ms\": 10020.82, \"total_train_time_s\": 13.925289869308472}", "{\"n\": 11620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.63, \"learn_time_ms\": 10067.395, \"total_train_time_s\": 13.836383581161499}", "{\"n\": 11621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.45, \"learn_time_ms\": 9978.789, \"total_train_time_s\": 13.686909437179565}", "{\"n\": 11622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.45, \"learn_time_ms\": 9916.09, \"total_train_time_s\": 13.025348424911499}", "{\"n\": 11623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.45, \"learn_time_ms\": 9907.229, \"total_train_time_s\": 13.503988027572632}", "{\"n\": 11624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.06, \"learn_time_ms\": 9981.993, \"total_train_time_s\": 13.41085410118103}", "{\"n\": 11625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.06, \"learn_time_ms\": 10028.106, \"total_train_time_s\": 14.235148906707764}", "{\"n\": 11626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.0, \"learn_time_ms\": 9980.709, \"total_train_time_s\": 12.743772745132446}", "{\"n\": 11627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.0, \"learn_time_ms\": 9951.02, \"total_train_time_s\": 12.846591711044312}", "{\"n\": 11628, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.37, \"learn_time_ms\": 9747.351, \"total_train_time_s\": 13.21458888053894}", "{\"n\": 11629, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.6, \"learn_time_ms\": 9736.635, \"total_train_time_s\": 14.029829263687134}", "{\"n\": 11630, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.81, \"learn_time_ms\": 9594.341, \"total_train_time_s\": 12.413325309753418}", "{\"n\": 11631, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.0, \"learn_time_ms\": 9531.645, \"total_train_time_s\": 12.846537351608276}", "{\"n\": 11632, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.56, \"learn_time_ms\": 9521.456, \"total_train_time_s\": 12.903148412704468}", "{\"n\": 11633, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.45, \"learn_time_ms\": 9624.895, \"total_train_time_s\": 14.775283813476562}", "{\"n\": 11634, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.45, \"learn_time_ms\": 9560.986, \"total_train_time_s\": 12.872681617736816}", "{\"n\": 11635, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.01, \"learn_time_ms\": 9533.909, \"total_train_time_s\": 13.795323371887207}", "{\"n\": 11636, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.88, \"learn_time_ms\": 9549.378, \"total_train_time_s\": 12.829160451889038}", "{\"n\": 11637, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.01, \"learn_time_ms\": 9681.253, \"total_train_time_s\": 14.275930881500244}", "{\"n\": 11638, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.92, \"learn_time_ms\": 9754.87, \"total_train_time_s\": 13.74506163597107}", "{\"n\": 11639, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 9688.998, \"total_train_time_s\": 13.40743899345398}", "{\"n\": 11640, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.43, \"learn_time_ms\": 9876.201, \"total_train_time_s\": 14.237532377243042}", "{\"n\": 11641, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.43, \"learn_time_ms\": 9983.492, \"total_train_time_s\": 14.21483039855957}", "{\"n\": 11642, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.0, \"learn_time_ms\": 10018.221, \"total_train_time_s\": 13.308273077011108}", "{\"n\": 11643, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.1, \"learn_time_ms\": 9884.271, \"total_train_time_s\": 13.235729455947876}", "{\"n\": 11644, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.25, \"learn_time_ms\": 9878.121, \"total_train_time_s\": 12.593967914581299}", "{\"n\": 11645, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.25, \"learn_time_ms\": 9839.675, \"total_train_time_s\": 13.562363147735596}", "{\"n\": 11646, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.69, \"learn_time_ms\": 9942.182, \"total_train_time_s\": 14.010374546051025}", "{\"n\": 11647, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.2, \"learn_time_ms\": 9942.697, \"total_train_time_s\": 14.277384757995605}", "{\"n\": 11648, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.32, \"learn_time_ms\": 9914.847, \"total_train_time_s\": 13.343016147613525}", "{\"n\": 11649, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.32, \"learn_time_ms\": 9885.288, \"total_train_time_s\": 12.793500423431396}", "{\"n\": 11650, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 9818.891, \"total_train_time_s\": 13.588616371154785}", "{\"n\": 11651, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 9799.294, \"total_train_time_s\": 13.7161705493927}", "{\"n\": 11652, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 9850.917, \"total_train_time_s\": 13.857482194900513}", "{\"n\": 11653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.55, \"learn_time_ms\": 9800.033, \"total_train_time_s\": 12.998146057128906}", "{\"n\": 11654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.25, \"learn_time_ms\": 9896.196, \"total_train_time_s\": 13.945960998535156}", "{\"n\": 11655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.25, \"learn_time_ms\": 9920.579, \"total_train_time_s\": 13.70674991607666}", "{\"n\": 11656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 9874.487, \"total_train_time_s\": 13.559539556503296}", "{\"n\": 11657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.08, \"learn_time_ms\": 9784.177, \"total_train_time_s\": 13.238129615783691}", "{\"n\": 11658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.16, \"learn_time_ms\": 9885.986, \"total_train_time_s\": 14.49006986618042}", "{\"n\": 11659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.16, \"learn_time_ms\": 9932.72, \"total_train_time_s\": 13.283560037612915}", "{\"n\": 11660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.16, \"learn_time_ms\": 9993.918, \"total_train_time_s\": 14.133068084716797}", "{\"n\": 11661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.63, \"learn_time_ms\": 9925.771, \"total_train_time_s\": 13.036976099014282}", "{\"n\": 11662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.69, \"learn_time_ms\": 9920.712, \"total_train_time_s\": 13.931060791015625}", "{\"n\": 11663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.69, \"learn_time_ms\": 9944.085, \"total_train_time_s\": 12.910192728042603}", "{\"n\": 11664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.97, \"learn_time_ms\": 9990.316, \"total_train_time_s\": 14.178358793258667}", "{\"n\": 11665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.8, \"learn_time_ms\": 9998.477, \"total_train_time_s\": 13.787683486938477}", "{\"n\": 11666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.57, \"learn_time_ms\": 10074.753, \"total_train_time_s\": 14.437392234802246}", "{\"n\": 11667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.82, \"learn_time_ms\": 10053.618, \"total_train_time_s\": 13.20749807357788}", "{\"n\": 11668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 9949.627, \"total_train_time_s\": 13.321940422058105}", "{\"n\": 11669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.59, \"learn_time_ms\": 10049.945, \"total_train_time_s\": 14.38604474067688}", "{\"n\": 11670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 9929.161, \"total_train_time_s\": 12.941421031951904}", "{\"n\": 11671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.78, \"learn_time_ms\": 9851.974, \"total_train_time_s\": 12.407507181167603}", "{\"n\": 11672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.24, \"learn_time_ms\": 9795.672, \"total_train_time_s\": 13.13783860206604}", "{\"n\": 11673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.67, \"learn_time_ms\": 9867.142, \"total_train_time_s\": 13.914856433868408}", "{\"n\": 11674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.67, \"learn_time_ms\": 9737.4, \"total_train_time_s\": 13.070119142532349}", "{\"n\": 11675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.93, \"learn_time_ms\": 9719.247, \"total_train_time_s\": 13.7152578830719}", "{\"n\": 11676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.22, \"learn_time_ms\": 9608.783, \"total_train_time_s\": 13.197650671005249}", "{\"n\": 11677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.82, \"learn_time_ms\": 9583.804, \"total_train_time_s\": 13.040231466293335}", "{\"n\": 11678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.56, \"learn_time_ms\": 9585.181, \"total_train_time_s\": 13.503833770751953}", "{\"n\": 11679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.28, \"learn_time_ms\": 9439.428, \"total_train_time_s\": 12.857865810394287}", "{\"n\": 11680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.07, \"learn_time_ms\": 9413.863, \"total_train_time_s\": 12.757390975952148}", "{\"n\": 11681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.35, \"learn_time_ms\": 9483.191, \"total_train_time_s\": 12.94989538192749}", "{\"n\": 11682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.39, \"learn_time_ms\": 9525.463, \"total_train_time_s\": 13.566354513168335}", "{\"n\": 11683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.74, \"learn_time_ms\": 9526.521, \"total_train_time_s\": 13.947640895843506}", "{\"n\": 11684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.39, \"learn_time_ms\": 9590.739, \"total_train_time_s\": 13.513987302780151}", "{\"n\": 11685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.62, \"learn_time_ms\": 9682.915, \"total_train_time_s\": 14.71730899810791}", "{\"n\": 11686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.58, \"learn_time_ms\": 9727.172, \"total_train_time_s\": 13.541574716567993}", "{\"n\": 11687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.58, \"learn_time_ms\": 9789.106, \"total_train_time_s\": 13.378906726837158}", "{\"n\": 11688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.73, \"learn_time_ms\": 9874.869, \"total_train_time_s\": 14.374657392501831}", "{\"n\": 11689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.74, \"learn_time_ms\": 9942.364, \"total_train_time_s\": 13.697308778762817}", "{\"n\": 11690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.74, \"learn_time_ms\": 10003.779, \"total_train_time_s\": 13.409197807312012}", "{\"n\": 11691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.74, \"learn_time_ms\": 10024.006, \"total_train_time_s\": 13.454057455062866}", "{\"n\": 11692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.64, \"learn_time_ms\": 10001.919, \"total_train_time_s\": 13.489147901535034}", "{\"n\": 11693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10062.391, \"total_train_time_s\": 14.40866732597351}", "{\"n\": 11694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10133.013, \"total_train_time_s\": 14.278200626373291}", "{\"n\": 11695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10040.089, \"total_train_time_s\": 13.609012842178345}", "{\"n\": 11696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.07, \"learn_time_ms\": 9991.383, \"total_train_time_s\": 13.136932134628296}", "{\"n\": 11697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 10005.978, \"total_train_time_s\": 13.483247995376587}", "{\"n\": 11698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 9962.778, \"total_train_time_s\": 13.8438081741333}", "{\"n\": 11699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 10010.216, \"total_train_time_s\": 14.34852647781372}", "{\"n\": 11700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.22, \"learn_time_ms\": 9999.648, \"total_train_time_s\": 13.252324104309082}", "{\"n\": 11701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.5, \"learn_time_ms\": 10110.951, \"total_train_time_s\": 14.235945701599121}", "{\"n\": 11702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.5, \"learn_time_ms\": 10117.773, \"total_train_time_s\": 13.513677597045898}", "{\"n\": 11703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.5, \"learn_time_ms\": 10068.258, \"total_train_time_s\": 13.937081575393677}", "{\"n\": 11704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.79, \"learn_time_ms\": 10052.251, \"total_train_time_s\": 13.991755485534668}", "{\"n\": 11705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.49, \"learn_time_ms\": 10016.452, \"total_train_time_s\": 13.198942184448242}", "{\"n\": 11706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.49, \"learn_time_ms\": 10026.852, \"total_train_time_s\": 13.326923370361328}", "{\"n\": 11707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.89, \"learn_time_ms\": 10111.893, \"total_train_time_s\": 14.890735149383545}", "{\"n\": 11708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.01, \"learn_time_ms\": 10157.764, \"total_train_time_s\": 14.407279968261719}", "{\"n\": 11709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.07, \"learn_time_ms\": 10134.441, \"total_train_time_s\": 13.780887365341187}", "{\"n\": 11710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.17, \"learn_time_ms\": 10206.791, \"total_train_time_s\": 14.105230331420898}", "{\"n\": 11711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.05, \"learn_time_ms\": 10108.686, \"total_train_time_s\": 13.4602530002594}", "{\"n\": 11712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.57, \"learn_time_ms\": 10109.305, \"total_train_time_s\": 13.456432342529297}", "{\"n\": 11713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.57, \"learn_time_ms\": 10182.101, \"total_train_time_s\": 14.698665618896484}", "{\"n\": 11714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 10132.129, \"total_train_time_s\": 13.35599684715271}", "{\"n\": 11715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.1, \"learn_time_ms\": 10182.376, \"total_train_time_s\": 13.765450954437256}", "{\"n\": 11716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.78, \"learn_time_ms\": 10275.553, \"total_train_time_s\": 14.048629760742188}", "{\"n\": 11717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.78, \"learn_time_ms\": 10126.193, \"total_train_time_s\": 13.248178958892822}", "{\"n\": 11718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.5, \"learn_time_ms\": 10093.55, \"total_train_time_s\": 14.066706895828247}", "{\"n\": 11719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.71, \"learn_time_ms\": 9999.402, \"total_train_time_s\": 12.85536503791809}", "{\"n\": 11720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.38, \"learn_time_ms\": 9938.322, \"total_train_time_s\": 13.477279424667358}", "{\"n\": 11721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.39, \"learn_time_ms\": 9954.914, \"total_train_time_s\": 13.70189642906189}", "{\"n\": 11722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.91, \"learn_time_ms\": 9910.985, \"total_train_time_s\": 12.94989538192749}", "{\"n\": 11723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.77, \"learn_time_ms\": 9724.863, \"total_train_time_s\": 12.92326545715332}", "{\"n\": 11724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.34, \"learn_time_ms\": 9677.845, \"total_train_time_s\": 12.87495493888855}", "{\"n\": 11725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.69, \"learn_time_ms\": 9741.83, \"total_train_time_s\": 14.391964435577393}", "{\"n\": 11726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.62, \"learn_time_ms\": 9800.181, \"total_train_time_s\": 14.80728793144226}", "{\"n\": 11727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.58, \"learn_time_ms\": 9857.19, \"total_train_time_s\": 13.875442504882812}", "{\"n\": 11728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.06, \"learn_time_ms\": 9791.752, \"total_train_time_s\": 13.323638439178467}", "{\"n\": 11729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.06, \"learn_time_ms\": 9844.517, \"total_train_time_s\": 13.528857707977295}", "{\"n\": 11730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.81, \"learn_time_ms\": 9983.976, \"total_train_time_s\": 14.689701318740845}", "{\"n\": 11731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.28, \"learn_time_ms\": 9969.44, \"total_train_time_s\": 13.378814697265625}", "{\"n\": 11732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.15, \"learn_time_ms\": 10152.721, \"total_train_time_s\": 14.938363552093506}", "{\"n\": 11733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.15, \"learn_time_ms\": 10306.59, \"total_train_time_s\": 14.30719256401062}", "{\"n\": 11734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.38, \"learn_time_ms\": 10333.828, \"total_train_time_s\": 13.39075517654419}", "{\"n\": 11735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.75, \"learn_time_ms\": 10277.9, \"total_train_time_s\": 13.951062440872192}", "{\"n\": 11736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.38, \"learn_time_ms\": 10083.636, \"total_train_time_s\": 12.944205045700073}", "{\"n\": 11737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.38, \"learn_time_ms\": 10049.355, \"total_train_time_s\": 13.505978107452393}", "{\"n\": 11738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.16, \"learn_time_ms\": 10099.604, \"total_train_time_s\": 14.030605554580688}", "{\"n\": 11739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.47, \"learn_time_ms\": 10043.622, \"total_train_time_s\": 13.002380847930908}", "{\"n\": 11740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.47, \"learn_time_ms\": 9899.15, \"total_train_time_s\": 13.199377536773682}", "{\"n\": 11741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.47, \"learn_time_ms\": 9950.59, \"total_train_time_s\": 13.764326572418213}", "{\"n\": 11742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.89, \"learn_time_ms\": 9853.548, \"total_train_time_s\": 13.921642303466797}", "{\"n\": 11743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.92, \"learn_time_ms\": 9718.521, \"total_train_time_s\": 13.057253122329712}", "{\"n\": 11744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.92, \"learn_time_ms\": 9773.235, \"total_train_time_s\": 14.007243156433105}", "{\"n\": 11745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.91, \"learn_time_ms\": 9743.099, \"total_train_time_s\": 13.507800102233887}", "{\"n\": 11746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.92, \"learn_time_ms\": 9766.649, \"total_train_time_s\": 13.194677829742432}", "{\"n\": 11747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.92, \"learn_time_ms\": 9782.592, \"total_train_time_s\": 13.558152437210083}", "{\"n\": 11748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.43, \"learn_time_ms\": 9831.859, \"total_train_time_s\": 14.506962060928345}", "{\"n\": 11749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.43, \"learn_time_ms\": 9886.012, \"total_train_time_s\": 13.36174988746643}", "{\"n\": 11750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.34, \"learn_time_ms\": 9910.0, \"total_train_time_s\": 13.567944288253784}", "{\"n\": 11751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.92, \"learn_time_ms\": 9931.757, \"total_train_time_s\": 14.023905754089355}", "{\"n\": 11752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.57, \"learn_time_ms\": 9901.646, \"total_train_time_s\": 13.499484300613403}", "{\"n\": 11753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.92, \"learn_time_ms\": 9968.587, \"total_train_time_s\": 13.599521160125732}", "{\"n\": 11754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.92, \"learn_time_ms\": 9946.989, \"total_train_time_s\": 13.517427444458008}", "{\"n\": 11755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.02, \"learn_time_ms\": 9892.122, \"total_train_time_s\": 13.16983938217163}", "{\"n\": 11756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.56, \"learn_time_ms\": 9910.451, \"total_train_time_s\": 13.229705810546875}", "{\"n\": 11757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.64, \"learn_time_ms\": 9897.24, \"total_train_time_s\": 13.359569787979126}", "{\"n\": 11758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.39, \"learn_time_ms\": 9852.052, \"total_train_time_s\": 13.91966199874878}", "{\"n\": 11759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.39, \"learn_time_ms\": 9834.458, \"total_train_time_s\": 13.437742948532104}", "{\"n\": 11760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.02, \"learn_time_ms\": 9886.235, \"total_train_time_s\": 14.323408365249634}", "{\"n\": 11761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.02, \"learn_time_ms\": 9817.521, \"total_train_time_s\": 13.384831190109253}", "{\"n\": 11762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.35, \"learn_time_ms\": 9808.957, \"total_train_time_s\": 13.49354600906372}", "{\"n\": 11763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.35, \"learn_time_ms\": 9823.445, \"total_train_time_s\": 13.759411096572876}", "{\"n\": 11764, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.27, \"learn_time_ms\": 9797.454, \"total_train_time_s\": 13.24047589302063}", "{\"n\": 11765, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.27, \"learn_time_ms\": 9744.126, \"total_train_time_s\": 12.53489875793457}", "{\"n\": 11766, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.73, \"learn_time_ms\": 9734.37, \"total_train_time_s\": 13.05980658531189}", "{\"n\": 11767, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.73, \"learn_time_ms\": 9752.026, \"total_train_time_s\": 13.433998584747314}", "{\"n\": 11768, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.05, \"learn_time_ms\": 9732.096, \"total_train_time_s\": 13.683844327926636}", "{\"n\": 11769, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3741.07, \"learn_time_ms\": 9809.885, \"total_train_time_s\": 14.181458234786987}", "{\"n\": 11770, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3741.07, \"learn_time_ms\": 9774.627, \"total_train_time_s\": 13.699949264526367}", "{\"n\": 11771, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3754.9, \"learn_time_ms\": 9736.506, \"total_train_time_s\": 13.055572509765625}", "{\"n\": 11772, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3754.9, \"learn_time_ms\": 9820.791, \"total_train_time_s\": 14.406962871551514}", "{\"n\": 11773, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3749.62, \"learn_time_ms\": 9788.908, \"total_train_time_s\": 13.34086298942566}", "{\"n\": 11774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3738.5, \"learn_time_ms\": 9813.048, \"total_train_time_s\": 13.697055101394653}", "{\"n\": 11775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3729.3, \"learn_time_ms\": 9870.348, \"total_train_time_s\": 13.069455862045288}", "{\"n\": 11776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3729.3, \"learn_time_ms\": 9929.213, \"total_train_time_s\": 13.743911504745483}", "{\"n\": 11777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3724.72, \"learn_time_ms\": 9890.959, \"total_train_time_s\": 12.973820924758911}", "{\"n\": 11778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3725.26, \"learn_time_ms\": 9846.294, \"total_train_time_s\": 13.419937133789062}", "{\"n\": 11779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.65, \"learn_time_ms\": 9909.75, \"total_train_time_s\": 14.54578185081482}", "{\"n\": 11780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.94, \"learn_time_ms\": 9929.317, \"total_train_time_s\": 13.94447636604309}", "{\"n\": 11781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.45, \"learn_time_ms\": 10033.243, \"total_train_time_s\": 13.969319581985474}", "{\"n\": 11782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.95, \"learn_time_ms\": 9863.841, \"total_train_time_s\": 12.621252059936523}", "{\"n\": 11783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3719.18, \"learn_time_ms\": 9882.031, \"total_train_time_s\": 13.80617618560791}", "{\"n\": 11784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.19, \"learn_time_ms\": 9800.784, \"total_train_time_s\": 12.971110582351685}", "{\"n\": 11785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.06, \"learn_time_ms\": 9942.908, \"total_train_time_s\": 14.500646114349365}", "{\"n\": 11786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.34, \"learn_time_ms\": 9842.964, \"total_train_time_s\": 12.850507259368896}", "{\"n\": 11787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.67, \"learn_time_ms\": 9815.194, \"total_train_time_s\": 12.741583108901978}", "{\"n\": 11788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3729.94, \"learn_time_ms\": 9793.68, \"total_train_time_s\": 13.058494329452515}", "{\"n\": 11789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3729.94, \"learn_time_ms\": 9643.283, \"total_train_time_s\": 13.132275342941284}", "{\"n\": 11790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3733.14, \"learn_time_ms\": 9553.423, \"total_train_time_s\": 12.934213161468506}", "{\"n\": 11791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3723.04, \"learn_time_ms\": 9466.397, \"total_train_time_s\": 13.351842403411865}", "{\"n\": 11792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.56, \"learn_time_ms\": 9497.332, \"total_train_time_s\": 12.933945894241333}", "{\"n\": 11793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.21, \"learn_time_ms\": 9542.176, \"total_train_time_s\": 14.210492372512817}", "{\"n\": 11794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.21, \"learn_time_ms\": 9663.709, \"total_train_time_s\": 14.141788244247437}", "{\"n\": 11795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.46, \"learn_time_ms\": 9558.89, \"total_train_time_s\": 13.330223560333252}", "{\"n\": 11796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.33, \"learn_time_ms\": 9575.645, \"total_train_time_s\": 12.791378259658813}", "{\"n\": 11797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.75, \"learn_time_ms\": 9659.391, \"total_train_time_s\": 13.456006050109863}", "{\"n\": 11798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.4, \"learn_time_ms\": 9614.552, \"total_train_time_s\": 12.788482666015625}", "{\"n\": 11799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.32, \"learn_time_ms\": 9511.252, \"total_train_time_s\": 12.177412509918213}", "{\"n\": 11800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.99, \"learn_time_ms\": 9562.47, \"total_train_time_s\": 13.692298412322998}", "{\"n\": 11801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.16, \"learn_time_ms\": 9457.749, \"total_train_time_s\": 12.068662405014038}", "{\"n\": 11802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3716.17, \"learn_time_ms\": 9574.113, \"total_train_time_s\": 14.253565073013306}", "{\"n\": 11803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3716.17, \"learn_time_ms\": 9488.651, \"total_train_time_s\": 13.034327745437622}", "{\"n\": 11804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.45, \"learn_time_ms\": 9452.866, \"total_train_time_s\": 13.790396928787231}", "{\"n\": 11805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.16, \"learn_time_ms\": 9449.427, \"total_train_time_s\": 13.415440082550049}", "{\"n\": 11806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.16, \"learn_time_ms\": 9553.068, \"total_train_time_s\": 14.302833795547485}", "{\"n\": 11807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.55, \"learn_time_ms\": 9510.027, \"total_train_time_s\": 13.139420747756958}", "{\"n\": 11808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3716.16, \"learn_time_ms\": 9600.4, \"total_train_time_s\": 13.713168859481812}", "{\"n\": 11809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.08, \"learn_time_ms\": 9847.943, \"total_train_time_s\": 14.50307822227478}", "{\"n\": 11810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.78, \"learn_time_ms\": 9826.391, \"total_train_time_s\": 13.254545450210571}", "{\"n\": 11811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.11, \"learn_time_ms\": 9920.76, \"total_train_time_s\": 13.070480346679688}", "{\"n\": 11812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.05, \"learn_time_ms\": 9903.072, \"total_train_time_s\": 14.02741003036499}", "{\"n\": 11813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.38, \"learn_time_ms\": 9976.067, \"total_train_time_s\": 14.17815089225769}", "{\"n\": 11814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.53, \"learn_time_ms\": 9991.51, \"total_train_time_s\": 13.821672916412354}", "{\"n\": 11815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.39, \"learn_time_ms\": 9976.245, \"total_train_time_s\": 13.185232400894165}", "{\"n\": 11816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.34, \"learn_time_ms\": 9911.845, \"total_train_time_s\": 13.378417491912842}", "{\"n\": 11817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.34, \"learn_time_ms\": 10010.6, \"total_train_time_s\": 14.216975927352905}", "{\"n\": 11818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.66, \"learn_time_ms\": 10044.033, \"total_train_time_s\": 13.818867921829224}", "{\"n\": 11819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.19, \"learn_time_ms\": 9915.72, \"total_train_time_s\": 13.40146780014038}", "{\"n\": 11820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.19, \"learn_time_ms\": 10025.652, \"total_train_time_s\": 14.384832620620728}", "{\"n\": 11821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.3, \"learn_time_ms\": 10062.066, \"total_train_time_s\": 13.796030521392822}", "{\"n\": 11822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.43, \"learn_time_ms\": 10079.97, \"total_train_time_s\": 14.219611883163452}", "{\"n\": 11823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.19, \"learn_time_ms\": 10052.37, \"total_train_time_s\": 13.650012969970703}", "{\"n\": 11824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.19, \"learn_time_ms\": 9951.18, \"total_train_time_s\": 12.841980218887329}", "{\"n\": 11825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 9970.854, \"total_train_time_s\": 13.348379611968994}", "{\"n\": 11826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.05, \"learn_time_ms\": 10080.572, \"total_train_time_s\": 14.275590896606445}", "{\"n\": 11827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.2, \"learn_time_ms\": 10010.738, \"total_train_time_s\": 13.652084112167358}", "{\"n\": 11828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.2, \"learn_time_ms\": 10002.69, \"total_train_time_s\": 13.804644346237183}", "{\"n\": 11829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.94, \"learn_time_ms\": 10059.274, \"total_train_time_s\": 13.861675024032593}", "{\"n\": 11830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.94, \"learn_time_ms\": 9980.626, \"total_train_time_s\": 13.987666845321655}", "{\"n\": 11831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.63, \"learn_time_ms\": 9962.522, \"total_train_time_s\": 13.24513292312622}", "{\"n\": 11832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.67, \"learn_time_ms\": 9929.807, \"total_train_time_s\": 13.895309925079346}", "{\"n\": 11833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.38, \"learn_time_ms\": 9927.749, \"total_train_time_s\": 13.708327770233154}", "{\"n\": 11834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.48, \"learn_time_ms\": 10059.921, \"total_train_time_s\": 14.232895851135254}", "{\"n\": 11835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.02, \"learn_time_ms\": 10095.856, \"total_train_time_s\": 13.770447492599487}", "{\"n\": 11836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.78, \"learn_time_ms\": 10009.087, \"total_train_time_s\": 13.510040760040283}", "{\"n\": 11837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10028.93, \"total_train_time_s\": 13.633044004440308}", "{\"n\": 11838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10074.079, \"total_train_time_s\": 14.410331726074219}", "{\"n\": 11839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.1, \"learn_time_ms\": 10053.0, \"total_train_time_s\": 13.916670799255371}", "{\"n\": 11840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.57, \"learn_time_ms\": 10138.444, \"total_train_time_s\": 14.506049156188965}", "{\"n\": 11841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.57, \"learn_time_ms\": 10229.8, \"total_train_time_s\": 14.47151255607605}", "{\"n\": 11842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.04, \"learn_time_ms\": 10220.937, \"total_train_time_s\": 13.896564960479736}", "{\"n\": 11843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.44, \"learn_time_ms\": 10228.949, \"total_train_time_s\": 13.730199337005615}", "{\"n\": 11844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.01, \"learn_time_ms\": 10110.734, \"total_train_time_s\": 12.930700063705444}", "{\"n\": 11845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.01, \"learn_time_ms\": 10133.204, \"total_train_time_s\": 13.968477725982666}", "{\"n\": 11846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.72, \"learn_time_ms\": 10093.551, \"total_train_time_s\": 13.180770874023438}", "{\"n\": 11847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10179.961, \"total_train_time_s\": 14.405580282211304}", "{\"n\": 11848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.1, \"learn_time_ms\": 10116.372, \"total_train_time_s\": 13.55661678314209}", "{\"n\": 11849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.66, \"learn_time_ms\": 10080.462, \"total_train_time_s\": 13.17204475402832}", "{\"n\": 11850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.78, \"learn_time_ms\": 9934.124, \"total_train_time_s\": 13.025787353515625}", "{\"n\": 11851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.69, \"learn_time_ms\": 10003.077, \"total_train_time_s\": 14.79288625717163}", "{\"n\": 11852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.69, \"learn_time_ms\": 9960.164, \"total_train_time_s\": 13.295313596725464}", "{\"n\": 11853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.67, \"learn_time_ms\": 9976.45, \"total_train_time_s\": 13.793525457382202}", "{\"n\": 11854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.23, \"learn_time_ms\": 9982.613, \"total_train_time_s\": 12.926724672317505}", "{\"n\": 11855, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.19, \"learn_time_ms\": 9883.791, \"total_train_time_s\": 12.962582111358643}", "{\"n\": 11856, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.54, \"learn_time_ms\": 9951.025, \"total_train_time_s\": 13.953099012374878}", "{\"n\": 11857, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.08, \"learn_time_ms\": 9873.568, \"total_train_time_s\": 13.840689182281494}", "{\"n\": 11858, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.87, \"learn_time_ms\": 9884.82, \"total_train_time_s\": 13.704342603683472}", "{\"n\": 11859, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.49, \"learn_time_ms\": 9982.558, \"total_train_time_s\": 14.390509366989136}", "{\"n\": 11860, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.78, \"learn_time_ms\": 10039.128, \"total_train_time_s\": 13.638452529907227}", "{\"n\": 11861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.35, \"learn_time_ms\": 9931.212, \"total_train_time_s\": 13.750708818435669}", "{\"n\": 11862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.96, \"learn_time_ms\": 9955.515, \"total_train_time_s\": 13.509055614471436}", "{\"n\": 11863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.72, \"learn_time_ms\": 9912.407, \"total_train_time_s\": 13.48929738998413}", "{\"n\": 11864, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.22, \"learn_time_ms\": 9946.124, \"total_train_time_s\": 13.366339921951294}", "{\"n\": 11865, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.22, \"learn_time_ms\": 10109.187, \"total_train_time_s\": 14.86656141281128}", "{\"n\": 11866, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.94, \"learn_time_ms\": 10027.161, \"total_train_time_s\": 12.829452276229858}", "{\"n\": 11867, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.76, \"learn_time_ms\": 9971.24, \"total_train_time_s\": 13.065402746200562}", "{\"n\": 11868, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.53, \"learn_time_ms\": 9933.915, \"total_train_time_s\": 13.536870241165161}", "{\"n\": 11869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.53, \"learn_time_ms\": 9857.61, \"total_train_time_s\": 13.439491748809814}", "{\"n\": 11870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.06, \"learn_time_ms\": 9915.02, \"total_train_time_s\": 14.278345823287964}", "{\"n\": 11871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.54, \"learn_time_ms\": 9875.362, \"total_train_time_s\": 13.33797836303711}", "{\"n\": 11872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.54, \"learn_time_ms\": 9809.802, \"total_train_time_s\": 13.105552434921265}", "{\"n\": 11873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.3, \"learn_time_ms\": 9827.852, \"total_train_time_s\": 13.522300243377686}", "{\"n\": 11874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.05, \"learn_time_ms\": 9857.185, \"total_train_time_s\": 13.79722809791565}", "{\"n\": 11875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.34, \"learn_time_ms\": 9755.963, \"total_train_time_s\": 13.794572114944458}", "{\"n\": 11876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.15, \"learn_time_ms\": 9775.755, \"total_train_time_s\": 13.37462067604065}", "{\"n\": 11877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.8, \"learn_time_ms\": 9808.941, \"total_train_time_s\": 13.428219318389893}", "{\"n\": 11878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.75, \"learn_time_ms\": 9736.476, \"total_train_time_s\": 12.516825199127197}", "{\"n\": 11879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 9789.283, \"total_train_time_s\": 14.165451049804688}", "{\"n\": 11880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.14, \"learn_time_ms\": 9736.186, \"total_train_time_s\": 13.642664670944214}", "{\"n\": 11881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.37, \"learn_time_ms\": 9772.85, \"total_train_time_s\": 13.952446699142456}", "{\"n\": 11882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.45, \"learn_time_ms\": 9875.382, \"total_train_time_s\": 14.138563871383667}", "{\"n\": 11883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.12, \"learn_time_ms\": 9885.168, \"total_train_time_s\": 13.717248439788818}", "{\"n\": 11884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.01, \"learn_time_ms\": 9900.068, \"total_train_time_s\": 13.822111129760742}", "{\"n\": 11885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.01, \"learn_time_ms\": 9947.429, \"total_train_time_s\": 14.38395357131958}", "{\"n\": 11886, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.6, \"learn_time_ms\": 9970.105, \"total_train_time_s\": 13.269040822982788}", "{\"n\": 11887, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 10076.353, \"total_train_time_s\": 14.759190320968628}", "{\"n\": 11888, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.68, \"learn_time_ms\": 10134.326, \"total_train_time_s\": 13.280320882797241}", "{\"n\": 11889, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.68, \"learn_time_ms\": 10240.922, \"total_train_time_s\": 14.981807470321655}", "{\"n\": 11890, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.24, \"learn_time_ms\": 10276.654, \"total_train_time_s\": 13.942521333694458}", "{\"n\": 11891, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.73, \"learn_time_ms\": 10260.531, \"total_train_time_s\": 13.870102405548096}", "{\"n\": 11892, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.15, \"learn_time_ms\": 10195.949, \"total_train_time_s\": 13.366327047348022}", "{\"n\": 11893, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.64, \"learn_time_ms\": 10214.133, \"total_train_time_s\": 13.924168348312378}", "{\"n\": 11894, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.51, \"learn_time_ms\": 10310.734, \"total_train_time_s\": 14.853951692581177}", "{\"n\": 11895, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.97, \"learn_time_ms\": 10230.683, \"total_train_time_s\": 13.369358539581299}", "{\"n\": 11896, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.48, \"learn_time_ms\": 10254.331, \"total_train_time_s\": 13.546871900558472}", "{\"n\": 11897, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.93, \"learn_time_ms\": 10121.173, \"total_train_time_s\": 13.158514499664307}", "{\"n\": 11898, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.37, \"learn_time_ms\": 10277.876, \"total_train_time_s\": 14.567986965179443}", "{\"n\": 11899, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.41, \"learn_time_ms\": 10174.956, \"total_train_time_s\": 14.061440229415894}", "{\"n\": 11900, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.31, \"learn_time_ms\": 10082.01, \"total_train_time_s\": 13.146432638168335}", "{\"n\": 11901, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.29, \"learn_time_ms\": 10048.722, \"total_train_time_s\": 13.49313497543335}", "{\"n\": 11902, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.67, \"learn_time_ms\": 10063.715, \"total_train_time_s\": 13.376147747039795}", "{\"n\": 11903, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.67, \"learn_time_ms\": 9898.552, \"total_train_time_s\": 12.339317560195923}", "{\"n\": 11904, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.09, \"learn_time_ms\": 9714.494, \"total_train_time_s\": 12.761594772338867}", "{\"n\": 11905, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.17, \"learn_time_ms\": 9677.04, \"total_train_time_s\": 13.001995086669922}", "{\"n\": 11906, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 9675.175, \"total_train_time_s\": 13.656150579452515}", "{\"n\": 11907, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.4, \"learn_time_ms\": 9777.039, \"total_train_time_s\": 14.256292819976807}", "{\"n\": 11908, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.49, \"learn_time_ms\": 9770.677, \"total_train_time_s\": 14.65882396697998}", "{\"n\": 11909, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.93, \"learn_time_ms\": 9672.512, \"total_train_time_s\": 13.249879360198975}", "{\"n\": 11910, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.93, \"learn_time_ms\": 9748.554, \"total_train_time_s\": 14.007255792617798}", "{\"n\": 11911, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.92, \"learn_time_ms\": 9688.773, \"total_train_time_s\": 12.593705177307129}", "{\"n\": 11912, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.74, \"learn_time_ms\": 9658.144, \"total_train_time_s\": 13.11452865600586}", "{\"n\": 11913, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.78, \"learn_time_ms\": 9763.537, \"total_train_time_s\": 13.451377153396606}", "{\"n\": 11914, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.76, \"learn_time_ms\": 9902.291, \"total_train_time_s\": 14.197822332382202}", "{\"n\": 11915, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.76, \"learn_time_ms\": 9982.625, \"total_train_time_s\": 14.048505306243896}", "{\"n\": 11916, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.56, \"learn_time_ms\": 9949.396, \"total_train_time_s\": 13.418139696121216}", "{\"n\": 11917, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.71, \"learn_time_ms\": 9984.671, \"total_train_time_s\": 14.672400712966919}", "{\"n\": 11918, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.71, \"learn_time_ms\": 9848.944, \"total_train_time_s\": 13.2332603931427}", "{\"n\": 11919, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.99, \"learn_time_ms\": 9868.048, \"total_train_time_s\": 13.47045111656189}", "{\"n\": 11920, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.78, \"learn_time_ms\": 9830.842, \"total_train_time_s\": 13.950482606887817}", "{\"n\": 11921, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.28, \"learn_time_ms\": 9992.306, \"total_train_time_s\": 14.25122880935669}", "{\"n\": 11922, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.28, \"learn_time_ms\": 10045.69, \"total_train_time_s\": 13.715248823165894}", "{\"n\": 11923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.18, \"learn_time_ms\": 10107.393, \"total_train_time_s\": 13.898346185684204}", "{\"n\": 11924, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.78, \"learn_time_ms\": 10135.219, \"total_train_time_s\": 14.618019819259644}", "{\"n\": 11925, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 10045.125, \"total_train_time_s\": 12.96426248550415}", "{\"n\": 11926, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 10074.051, \"total_train_time_s\": 13.432595491409302}", "{\"n\": 11927, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.92, \"learn_time_ms\": 10013.408, \"total_train_time_s\": 13.881998300552368}", "{\"n\": 11928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 10106.517, \"total_train_time_s\": 14.48415493965149}", "{\"n\": 11929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.03, \"learn_time_ms\": 10252.035, \"total_train_time_s\": 14.757834672927856}", "{\"n\": 11930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.03, \"learn_time_ms\": 10312.72, \"total_train_time_s\": 14.178064107894897}", "{\"n\": 11931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.51, \"learn_time_ms\": 10267.69, \"total_train_time_s\": 13.947562456130981}", "{\"n\": 11932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.95, \"learn_time_ms\": 10226.316, \"total_train_time_s\": 13.371182203292847}", "{\"n\": 11933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.95, \"learn_time_ms\": 10256.046, \"total_train_time_s\": 14.112994909286499}", "{\"n\": 11934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.95, \"learn_time_ms\": 10146.631, \"total_train_time_s\": 13.634305715560913}", "{\"n\": 11935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.27, \"learn_time_ms\": 10187.944, \"total_train_time_s\": 13.29614806175232}", "{\"n\": 11936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.22, \"learn_time_ms\": 10142.497, \"total_train_time_s\": 13.457373857498169}", "{\"n\": 11937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.22, \"learn_time_ms\": 10139.045, \"total_train_time_s\": 13.785730600357056}", "{\"n\": 11938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.04, \"learn_time_ms\": 10116.35, \"total_train_time_s\": 14.008849620819092}", "{\"n\": 11939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 9934.812, \"total_train_time_s\": 13.03559398651123}", "{\"n\": 11940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.34, \"learn_time_ms\": 9873.743, \"total_train_time_s\": 13.530634880065918}", "{\"n\": 11941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.32, \"learn_time_ms\": 9930.452, \"total_train_time_s\": 14.599951028823853}", "{\"n\": 11942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.6, \"learn_time_ms\": 9883.183, \"total_train_time_s\": 12.647289752960205}", "{\"n\": 11943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.58, \"learn_time_ms\": 9816.883, \"total_train_time_s\": 13.520521402359009}", "{\"n\": 11944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.58, \"learn_time_ms\": 9818.636, \"total_train_time_s\": 13.455811023712158}", "{\"n\": 11945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.99, \"learn_time_ms\": 9864.489, \"total_train_time_s\": 13.790184020996094}", "{\"n\": 11946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.62, \"learn_time_ms\": 9900.658, \"total_train_time_s\": 13.502874612808228}", "{\"n\": 11947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.76, \"learn_time_ms\": 9818.842, \"total_train_time_s\": 13.26346230506897}", "{\"n\": 11948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.76, \"learn_time_ms\": 9775.034, \"total_train_time_s\": 13.722899436950684}", "{\"n\": 11949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.11, \"learn_time_ms\": 9882.51, \"total_train_time_s\": 13.866321325302124}", "{\"n\": 11950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.69, \"learn_time_ms\": 9791.072, \"total_train_time_s\": 12.448373079299927}", "{\"n\": 11951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.69, \"learn_time_ms\": 9638.345, \"total_train_time_s\": 12.853802919387817}", "{\"n\": 11952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 9737.287, \"total_train_time_s\": 13.767383337020874}", "{\"n\": 11953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 9771.166, \"total_train_time_s\": 14.14529299736023}", "{\"n\": 11954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.82, \"learn_time_ms\": 9837.975, \"total_train_time_s\": 14.134263753890991}", "{\"n\": 11955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.17, \"learn_time_ms\": 9762.523, \"total_train_time_s\": 13.007249355316162}", "{\"n\": 11956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.18, \"learn_time_ms\": 9764.71, \"total_train_time_s\": 13.435067653656006}", "{\"n\": 11957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.65, \"learn_time_ms\": 9827.38, \"total_train_time_s\": 13.706851482391357}", "{\"n\": 11958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.21, \"learn_time_ms\": 9836.728, \"total_train_time_s\": 13.84827995300293}", "{\"n\": 11959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.21, \"learn_time_ms\": 9803.741, \"total_train_time_s\": 13.777154684066772}", "{\"n\": 11960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.1, \"learn_time_ms\": 9941.096, \"total_train_time_s\": 13.777091264724731}", "{\"n\": 11961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.1, \"learn_time_ms\": 10018.715, \"total_train_time_s\": 13.575130462646484}", "{\"n\": 11962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.52, \"learn_time_ms\": 9939.198, \"total_train_time_s\": 12.860960960388184}", "{\"n\": 11963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.59, \"learn_time_ms\": 9926.065, \"total_train_time_s\": 13.920357942581177}", "{\"n\": 11964, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 9909.132, \"total_train_time_s\": 14.010408878326416}", "{\"n\": 11965, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.6, \"learn_time_ms\": 9993.959, \"total_train_time_s\": 13.873175144195557}", "{\"n\": 11966, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.75, \"learn_time_ms\": 9995.01, \"total_train_time_s\": 13.467751264572144}", "{\"n\": 11967, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.73, \"learn_time_ms\": 10005.771, \"total_train_time_s\": 14.01225996017456}", "{\"n\": 11968, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.73, \"learn_time_ms\": 9999.381, \"total_train_time_s\": 13.490648984909058}", "{\"n\": 11969, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.37, \"learn_time_ms\": 10085.48, \"total_train_time_s\": 14.742120265960693}", "{\"n\": 11970, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.37, \"learn_time_ms\": 10110.233, \"total_train_time_s\": 14.463805675506592}", "{\"n\": 11971, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.35, \"learn_time_ms\": 10076.28, \"total_train_time_s\": 13.41686224937439}", "{\"n\": 11972, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.35, \"learn_time_ms\": 10129.953, \"total_train_time_s\": 13.37617802619934}", "{\"n\": 11973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 10124.563, \"total_train_time_s\": 13.68397831916809}", "{\"n\": 11974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.46, \"learn_time_ms\": 10123.892, \"total_train_time_s\": 14.134460687637329}", "{\"n\": 11975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.46, \"learn_time_ms\": 10066.054, \"total_train_time_s\": 13.162587881088257}", "{\"n\": 11976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.37, \"learn_time_ms\": 10056.749, \"total_train_time_s\": 13.323211669921875}", "{\"n\": 11977, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.89, \"learn_time_ms\": 10000.585, \"total_train_time_s\": 13.243241310119629}", "{\"n\": 11978, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.49, \"learn_time_ms\": 10034.035, \"total_train_time_s\": 14.100745677947998}", "{\"n\": 11979, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.49, \"learn_time_ms\": 9856.853, \"total_train_time_s\": 12.844162225723267}", "{\"n\": 11980, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.37, \"learn_time_ms\": 9896.975, \"total_train_time_s\": 14.614395380020142}", "{\"n\": 11981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.37, \"learn_time_ms\": 9945.247, \"total_train_time_s\": 13.723545789718628}", "{\"n\": 11982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.14, \"learn_time_ms\": 9866.733, \"total_train_time_s\": 12.86230182647705}", "{\"n\": 11983, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.03, \"learn_time_ms\": 9905.042, \"total_train_time_s\": 14.000917434692383}", "{\"n\": 11984, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 9879.234, \"total_train_time_s\": 13.53787350654602}", "{\"n\": 11985, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 9919.54, \"total_train_time_s\": 13.56660532951355}", "{\"n\": 11986, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.16, \"learn_time_ms\": 9953.193, \"total_train_time_s\": 13.739014863967896}", "{\"n\": 11987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 10052.48, \"total_train_time_s\": 14.393075227737427}", "{\"n\": 11988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 10077.78, \"total_train_time_s\": 14.461388111114502}", "{\"n\": 11989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.82, \"learn_time_ms\": 10156.778, \"total_train_time_s\": 13.505183935165405}", "{\"n\": 11990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.72, \"learn_time_ms\": 10116.287, \"total_train_time_s\": 14.13623595237732}", "{\"n\": 11991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.07, \"learn_time_ms\": 10257.018, \"total_train_time_s\": 15.4239661693573}", "{\"n\": 11992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.75, \"learn_time_ms\": 10380.859, \"total_train_time_s\": 13.8590669631958}", "{\"n\": 11993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.75, \"learn_time_ms\": 10343.296, \"total_train_time_s\": 13.642271995544434}", "{\"n\": 11994, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.76, \"learn_time_ms\": 10378.851, \"total_train_time_s\": 13.9889395236969}", "{\"n\": 11995, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.95, \"learn_time_ms\": 10412.0, \"total_train_time_s\": 13.964956760406494}", "{\"n\": 11996, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.72, \"learn_time_ms\": 10431.596, \"total_train_time_s\": 14.252538204193115}", "{\"n\": 11997, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.1, \"learn_time_ms\": 10285.214, \"total_train_time_s\": 12.835395812988281}", "{\"n\": 11998, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.67, \"learn_time_ms\": 10155.622, \"total_train_time_s\": 12.956414461135864}", "{\"n\": 11999, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.76, \"learn_time_ms\": 10168.442, \"total_train_time_s\": 13.616212129592896}", "{\"n\": 12000, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.76, \"learn_time_ms\": 10135.094, \"total_train_time_s\": 13.88558578491211}", "{\"n\": 12001, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.43, \"learn_time_ms\": 9975.473, \"total_train_time_s\": 13.556488037109375}", "{\"n\": 12002, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.5, \"learn_time_ms\": 9934.347, \"total_train_time_s\": 13.534000635147095}", "{\"n\": 12003, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.5, \"learn_time_ms\": 9926.6, \"total_train_time_s\": 13.80561351776123}", "{\"n\": 12004, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.57, \"learn_time_ms\": 9925.892, \"total_train_time_s\": 13.861092329025269}", "{\"n\": 12005, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.41, \"learn_time_ms\": 9964.092, \"total_train_time_s\": 14.264690637588501}", "{\"n\": 12006, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.72, \"learn_time_ms\": 9904.22, \"total_train_time_s\": 13.393968105316162}", "{\"n\": 12007, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.72, \"learn_time_ms\": 9945.984, \"total_train_time_s\": 13.496129989624023}", "{\"n\": 12008, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.92, \"learn_time_ms\": 10026.255, \"total_train_time_s\": 13.603329420089722}", "{\"n\": 12009, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.3, \"learn_time_ms\": 10016.191, \"total_train_time_s\": 13.665132761001587}", "{\"n\": 12010, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.3, \"learn_time_ms\": 9987.804, \"total_train_time_s\": 13.725208759307861}", "{\"n\": 12011, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.68, \"learn_time_ms\": 9906.322, \"total_train_time_s\": 12.827252864837646}", "{\"n\": 12012, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.97, \"learn_time_ms\": 9887.187, \"total_train_time_s\": 13.223692893981934}", "{\"n\": 12013, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.53, \"learn_time_ms\": 9835.838, \"total_train_time_s\": 13.172529935836792}", "{\"n\": 12014, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.53, \"learn_time_ms\": 9761.531, \"total_train_time_s\": 13.345141410827637}", "{\"n\": 12015, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.32, \"learn_time_ms\": 9741.287, \"total_train_time_s\": 14.099133253097534}", "{\"n\": 12016, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.61, \"learn_time_ms\": 9694.34, \"total_train_time_s\": 12.837986946105957}", "{\"n\": 12017, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.61, \"learn_time_ms\": 9785.487, \"total_train_time_s\": 14.068321704864502}", "{\"n\": 12018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.48, \"learn_time_ms\": 9845.628, \"total_train_time_s\": 14.56562876701355}", "{\"n\": 12019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.64, \"learn_time_ms\": 9922.786, \"total_train_time_s\": 14.468616962432861}", "{\"n\": 12020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.94, \"learn_time_ms\": 9986.318, \"total_train_time_s\": 14.350060939788818}", "{\"n\": 12021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.94, \"learn_time_ms\": 10047.902, \"total_train_time_s\": 13.436050653457642}", "{\"n\": 12022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.67, \"learn_time_ms\": 10037.834, \"total_train_time_s\": 13.153567552566528}", "{\"n\": 12023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.49, \"learn_time_ms\": 10020.365, \"total_train_time_s\": 12.942897319793701}", "{\"n\": 12024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3599.21, \"learn_time_ms\": 10083.229, \"total_train_time_s\": 13.94028615951538}", "{\"n\": 12025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.21, \"learn_time_ms\": 9939.206, \"total_train_time_s\": 12.965275287628174}", "{\"n\": 12026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.34, \"learn_time_ms\": 10105.026, \"total_train_time_s\": 14.595296144485474}", "{\"n\": 12027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.0, \"learn_time_ms\": 10055.822, \"total_train_time_s\": 13.810373306274414}", "{\"n\": 12028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.19, \"learn_time_ms\": 9990.243, \"total_train_time_s\": 13.773869037628174}", "{\"n\": 12029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 9857.74, \"total_train_time_s\": 12.912055015563965}", "{\"n\": 12030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.51, \"learn_time_ms\": 9763.13, \"total_train_time_s\": 13.52943754196167}", "{\"n\": 12031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.51, \"learn_time_ms\": 9808.291, \"total_train_time_s\": 13.9775071144104}", "{\"n\": 12032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.55, \"learn_time_ms\": 9890.529, \"total_train_time_s\": 14.0507173538208}", "{\"n\": 12033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.9, \"learn_time_ms\": 9884.535, \"total_train_time_s\": 12.908221244812012}", "{\"n\": 12034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.82, \"learn_time_ms\": 9804.817, \"total_train_time_s\": 13.117501258850098}", "{\"n\": 12035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.78, \"learn_time_ms\": 9843.862, \"total_train_time_s\": 13.255165815353394}", "{\"n\": 12036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.44, \"learn_time_ms\": 9697.617, \"total_train_time_s\": 13.096715211868286}", "{\"n\": 12037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.44, \"learn_time_ms\": 9746.065, \"total_train_time_s\": 14.272207498550415}", "{\"n\": 12038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3583.25, \"learn_time_ms\": 9727.953, \"total_train_time_s\": 13.378140687942505}", "{\"n\": 12039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3573.45, \"learn_time_ms\": 9804.321, \"total_train_time_s\": 13.762276411056519}", "{\"n\": 12040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3573.45, \"learn_time_ms\": 9794.144, \"total_train_time_s\": 13.161096572875977}", "{\"n\": 12041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3575.69, \"learn_time_ms\": 9692.307, \"total_train_time_s\": 12.77419376373291}", "{\"n\": 12042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.03, \"learn_time_ms\": 9606.329, \"total_train_time_s\": 13.273819208145142}", "{\"n\": 12043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.57, \"learn_time_ms\": 9700.299, \"total_train_time_s\": 14.002648115158081}", "{\"n\": 12044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.57, \"learn_time_ms\": 9661.271, \"total_train_time_s\": 12.64758849143982}", "{\"n\": 12045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.89, \"learn_time_ms\": 9662.761, \"total_train_time_s\": 13.2135591506958}", "{\"n\": 12046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.37, \"learn_time_ms\": 9791.923, \"total_train_time_s\": 14.471242904663086}", "{\"n\": 12047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.48, \"learn_time_ms\": 9760.14, \"total_train_time_s\": 13.80152440071106}", "{\"n\": 12048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.48, \"learn_time_ms\": 9754.408, \"total_train_time_s\": 13.530885219573975}", "{\"n\": 12049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.26, \"learn_time_ms\": 9699.014, \"total_train_time_s\": 13.271307229995728}", "{\"n\": 12050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.89, \"learn_time_ms\": 9728.222, \"total_train_time_s\": 13.554413080215454}", "{\"n\": 12051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.89, \"learn_time_ms\": 9778.216, \"total_train_time_s\": 13.439564943313599}", "{\"n\": 12052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.23, \"learn_time_ms\": 9836.188, \"total_train_time_s\": 13.893216609954834}", "{\"n\": 12053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.36, \"learn_time_ms\": 9861.694, \"total_train_time_s\": 14.134001016616821}", "{\"n\": 12054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.36, \"learn_time_ms\": 9897.161, \"total_train_time_s\": 13.19762921333313}", "{\"n\": 12055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.36, \"learn_time_ms\": 9947.525, \"total_train_time_s\": 13.552186489105225}", "{\"n\": 12056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.57, \"learn_time_ms\": 9824.728, \"total_train_time_s\": 13.11811876296997}", "{\"n\": 12057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.4, \"learn_time_ms\": 9779.704, \"total_train_time_s\": 13.260602951049805}", "{\"n\": 12058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.4, \"learn_time_ms\": 9913.337, \"total_train_time_s\": 14.67598581314087}", "{\"n\": 12059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.58, \"learn_time_ms\": 9949.822, \"total_train_time_s\": 13.634466171264648}", "{\"n\": 12060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.24, \"learn_time_ms\": 9978.136, \"total_train_time_s\": 13.697021961212158}", "{\"n\": 12061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.24, \"learn_time_ms\": 10008.045, \"total_train_time_s\": 13.687527418136597}", "{\"n\": 12062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.24, \"learn_time_ms\": 9953.769, \"total_train_time_s\": 13.460258960723877}", "{\"n\": 12063, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.69, \"learn_time_ms\": 9908.163, \"total_train_time_s\": 13.559946298599243}", "{\"n\": 12064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.96, \"learn_time_ms\": 9950.601, \"total_train_time_s\": 13.446853876113892}", "{\"n\": 12065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.96, \"learn_time_ms\": 9941.679, \"total_train_time_s\": 13.616963386535645}", "{\"n\": 12066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.96, \"learn_time_ms\": 9951.695, \"total_train_time_s\": 13.2088623046875}", "{\"n\": 12067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.44, \"learn_time_ms\": 9895.908, \"total_train_time_s\": 12.931648015975952}", "{\"n\": 12068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.44, \"learn_time_ms\": 9858.747, \"total_train_time_s\": 14.573276281356812}", "{\"n\": 12069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.44, \"learn_time_ms\": 9916.707, \"total_train_time_s\": 14.265244007110596}", "{\"n\": 12070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.44, \"learn_time_ms\": 9889.703, \"total_train_time_s\": 13.608507871627808}", "{\"n\": 12071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.64, \"learn_time_ms\": 9902.36, \"total_train_time_s\": 13.811585664749146}", "{\"n\": 12072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.82, \"learn_time_ms\": 9963.82, \"total_train_time_s\": 14.013524770736694}", "{\"n\": 12073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.82, \"learn_time_ms\": 9985.161, \"total_train_time_s\": 13.731464624404907}", "{\"n\": 12074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.51, \"learn_time_ms\": 10110.709, \"total_train_time_s\": 14.70399284362793}", "{\"n\": 12075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.63, \"learn_time_ms\": 10070.046, \"total_train_time_s\": 13.268114805221558}", "{\"n\": 12076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.63, \"learn_time_ms\": 10160.501, \"total_train_time_s\": 14.273800373077393}", "{\"n\": 12077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.49, \"learn_time_ms\": 10199.977, \"total_train_time_s\": 13.556679010391235}", "{\"n\": 12078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.86, \"learn_time_ms\": 10048.879, \"total_train_time_s\": 12.98332953453064}", "{\"n\": 12079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.57, \"learn_time_ms\": 10030.007, \"total_train_time_s\": 14.049214363098145}", "{\"n\": 12080, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.57, \"learn_time_ms\": 10035.595, \"total_train_time_s\": 13.738300085067749}", "{\"n\": 12081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.19, \"learn_time_ms\": 10028.555, \"total_train_time_s\": 13.791448831558228}", "{\"n\": 12082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.32, \"learn_time_ms\": 9938.157, \"total_train_time_s\": 12.931522607803345}", "{\"n\": 12083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.58, \"learn_time_ms\": 9916.018, \"total_train_time_s\": 13.57200312614441}", "{\"n\": 12084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.78, \"learn_time_ms\": 9804.253, \"total_train_time_s\": 13.698715209960938}", "{\"n\": 12085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.49, \"learn_time_ms\": 9854.323, \"total_train_time_s\": 13.644361019134521}", "{\"n\": 12086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.51, \"learn_time_ms\": 9724.813, \"total_train_time_s\": 12.839020490646362}", "{\"n\": 12087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.35, \"learn_time_ms\": 9868.897, \"total_train_time_s\": 14.765750885009766}", "{\"n\": 12088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.06, \"learn_time_ms\": 9906.075, \"total_train_time_s\": 13.130488157272339}", "{\"n\": 12089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.64, \"learn_time_ms\": 9878.497, \"total_train_time_s\": 13.904669046401978}", "{\"n\": 12090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.64, \"learn_time_ms\": 9873.821, \"total_train_time_s\": 13.529483318328857}", "{\"n\": 12091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.76, \"learn_time_ms\": 9793.44, \"total_train_time_s\": 12.843613862991333}", "{\"n\": 12092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.41, \"learn_time_ms\": 9828.02, \"total_train_time_s\": 13.262197732925415}", "{\"n\": 12093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.45, \"learn_time_ms\": 9872.446, \"total_train_time_s\": 14.092304468154907}", "{\"n\": 12094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.45, \"learn_time_ms\": 9923.683, \"total_train_time_s\": 14.206362962722778}", "{\"n\": 12095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.34, \"learn_time_ms\": 9939.711, \"total_train_time_s\": 13.690100193023682}", "{\"n\": 12096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.29, \"learn_time_ms\": 9935.062, \"total_train_time_s\": 13.01448369026184}", "{\"n\": 12097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.79, \"learn_time_ms\": 9805.776, \"total_train_time_s\": 13.321035385131836}", "{\"n\": 12098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.25, \"learn_time_ms\": 9820.504, \"total_train_time_s\": 13.503070592880249}", "{\"n\": 12099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.8, \"learn_time_ms\": 9782.714, \"total_train_time_s\": 13.503410816192627}", "{\"n\": 12100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.76, \"learn_time_ms\": 9750.803, \"total_train_time_s\": 13.029136896133423}", "{\"n\": 12101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.76, \"learn_time_ms\": 9754.386, \"total_train_time_s\": 12.804406642913818}", "{\"n\": 12102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.45, \"learn_time_ms\": 9759.909, \"total_train_time_s\": 13.33290147781372}", "{\"n\": 12103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.65, \"learn_time_ms\": 9775.01, \"total_train_time_s\": 14.074966669082642}", "{\"n\": 12104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.29, \"learn_time_ms\": 9705.608, \"total_train_time_s\": 13.447585821151733}", "{\"n\": 12105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.93, \"learn_time_ms\": 9612.136, \"total_train_time_s\": 12.754124879837036}", "{\"n\": 12106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.19, \"learn_time_ms\": 9658.36, \"total_train_time_s\": 13.444199085235596}", "{\"n\": 12107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.11, \"learn_time_ms\": 9591.914, \"total_train_time_s\": 12.853545188903809}", "{\"n\": 12108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.11, \"learn_time_ms\": 9575.755, \"total_train_time_s\": 13.430562019348145}", "{\"n\": 12109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.61, \"learn_time_ms\": 9593.761, \"total_train_time_s\": 13.62563705444336}", "{\"n\": 12110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.95, \"learn_time_ms\": 9756.745, \"total_train_time_s\": 14.739304065704346}", "{\"n\": 12111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.82, \"learn_time_ms\": 9861.369, \"total_train_time_s\": 13.882846117019653}", "{\"n\": 12112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.82, \"learn_time_ms\": 9954.096, \"total_train_time_s\": 14.172800064086914}", "{\"n\": 12113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.36, \"learn_time_ms\": 9858.884, \"total_train_time_s\": 13.306163549423218}", "{\"n\": 12114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.42, \"learn_time_ms\": 9909.433, \"total_train_time_s\": 14.076253414154053}", "{\"n\": 12115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.42, \"learn_time_ms\": 9972.218, \"total_train_time_s\": 13.374637126922607}", "{\"n\": 12116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.42, \"learn_time_ms\": 9965.138, \"total_train_time_s\": 13.262356281280518}", "{\"n\": 12117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.07, \"learn_time_ms\": 10024.62, \"total_train_time_s\": 13.245126962661743}", "{\"n\": 12118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.07, \"learn_time_ms\": 10067.084, \"total_train_time_s\": 13.798759937286377}", "{\"n\": 12119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.07, \"learn_time_ms\": 9981.501, \"total_train_time_s\": 12.617421865463257}", "{\"n\": 12120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.41, \"learn_time_ms\": 9874.717, \"total_train_time_s\": 13.73565936088562}", "{\"n\": 12121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.51, \"learn_time_ms\": 9807.378, \"total_train_time_s\": 13.308760404586792}", "{\"n\": 12122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.51, \"learn_time_ms\": 9697.655, \"total_train_time_s\": 13.211417198181152}", "{\"n\": 12123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.51, \"learn_time_ms\": 9769.335, \"total_train_time_s\": 14.241573095321655}", "{\"n\": 12124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.71, \"learn_time_ms\": 9667.813, \"total_train_time_s\": 13.024275064468384}", "{\"n\": 12125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.34, \"learn_time_ms\": 9712.377, \"total_train_time_s\": 14.115050315856934}", "{\"n\": 12126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.34, \"learn_time_ms\": 9829.18, \"total_train_time_s\": 14.39836573600769}", "{\"n\": 12127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.34, \"learn_time_ms\": 9814.534, \"total_train_time_s\": 13.03011965751648}", "{\"n\": 12128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.88, \"learn_time_ms\": 9910.572, \"total_train_time_s\": 14.577543020248413}", "{\"n\": 12129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 9966.458, \"total_train_time_s\": 13.15381669998169}", "{\"n\": 12130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10040.313, \"total_train_time_s\": 14.498001098632812}", "{\"n\": 12131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10001.57, \"total_train_time_s\": 13.047640323638916}", "{\"n\": 12132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10073.029, \"total_train_time_s\": 13.96078896522522}", "{\"n\": 12133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10014.777, \"total_train_time_s\": 13.609853982925415}", "{\"n\": 12134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.3, \"learn_time_ms\": 9998.964, \"total_train_time_s\": 12.876405000686646}", "{\"n\": 12135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.55, \"learn_time_ms\": 9936.665, \"total_train_time_s\": 13.335819721221924}", "{\"n\": 12136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.55, \"learn_time_ms\": 9865.689, \"total_train_time_s\": 13.695924758911133}", "{\"n\": 12137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.13, \"learn_time_ms\": 9995.937, \"total_train_time_s\": 14.369438409805298}", "{\"n\": 12138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 9892.262, \"total_train_time_s\": 13.529295444488525}", "{\"n\": 12139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.8, \"learn_time_ms\": 9949.245, \"total_train_time_s\": 13.877372741699219}", "{\"n\": 12140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.8, \"learn_time_ms\": 9834.305, \"total_train_time_s\": 13.474254846572876}", "{\"n\": 12141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.05, \"learn_time_ms\": 9911.827, \"total_train_time_s\": 13.64332103729248}", "{\"n\": 12142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.82, \"learn_time_ms\": 9892.285, \"total_train_time_s\": 13.788282632827759}", "{\"n\": 12143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.19, \"learn_time_ms\": 9868.536, \"total_train_time_s\": 13.36231279373169}", "{\"n\": 12144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.26, \"learn_time_ms\": 9985.665, \"total_train_time_s\": 14.004425764083862}", "{\"n\": 12145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.29, \"learn_time_ms\": 10040.575, \"total_train_time_s\": 13.919459342956543}", "{\"n\": 12146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.95, \"learn_time_ms\": 10010.149, \"total_train_time_s\": 13.614094257354736}", "{\"n\": 12147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.95, \"learn_time_ms\": 9930.003, \"total_train_time_s\": 13.49354863166809}", "{\"n\": 12148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.33, \"learn_time_ms\": 10013.134, \"total_train_time_s\": 14.4131760597229}", "{\"n\": 12149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.59, \"learn_time_ms\": 9968.595, \"total_train_time_s\": 13.42660117149353}", "{\"n\": 12150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.96, \"learn_time_ms\": 10043.53, \"total_train_time_s\": 14.15741753578186}", "{\"n\": 12151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.96, \"learn_time_ms\": 9973.933, \"total_train_time_s\": 12.937325239181519}", "{\"n\": 12152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.6, \"learn_time_ms\": 10008.044, \"total_train_time_s\": 14.153831958770752}", "{\"n\": 12153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.32, \"learn_time_ms\": 10013.498, \"total_train_time_s\": 13.366270780563354}", "{\"n\": 12154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.43, \"learn_time_ms\": 9929.305, \"total_train_time_s\": 12.987764835357666}", "{\"n\": 12155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.43, \"learn_time_ms\": 9799.675, \"total_train_time_s\": 12.648848533630371}", "{\"n\": 12156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.65, \"learn_time_ms\": 9784.134, \"total_train_time_s\": 13.257243871688843}", "{\"n\": 12157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.38, \"learn_time_ms\": 9828.668, \"total_train_time_s\": 13.955363273620605}", "{\"n\": 12158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.38, \"learn_time_ms\": 9684.339, \"total_train_time_s\": 13.276323795318604}", "{\"n\": 12159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.38, \"learn_time_ms\": 9733.172, \"total_train_time_s\": 13.776125431060791}", "{\"n\": 12160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.56, \"learn_time_ms\": 9694.218, \"total_train_time_s\": 13.783868551254272}", "{\"n\": 12161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.24, \"learn_time_ms\": 9792.59, \"total_train_time_s\": 13.930001497268677}", "{\"n\": 12162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.02, \"learn_time_ms\": 9823.864, \"total_train_time_s\": 14.349610328674316}", "{\"n\": 12163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.02, \"learn_time_ms\": 9887.858, \"total_train_time_s\": 13.944892644882202}", "{\"n\": 12164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.66, \"learn_time_ms\": 9923.872, \"total_train_time_s\": 13.473756790161133}", "{\"n\": 12165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.91, \"learn_time_ms\": 10042.116, \"total_train_time_s\": 13.912312507629395}", "{\"n\": 12166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.91, \"learn_time_ms\": 10118.553, \"total_train_time_s\": 13.992814302444458}", "{\"n\": 12167, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.86, \"learn_time_ms\": 10006.267, \"total_train_time_s\": 12.924758434295654}", "{\"n\": 12168, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 10146.422, \"total_train_time_s\": 14.422749519348145}", "{\"n\": 12169, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.21, \"learn_time_ms\": 10122.774, \"total_train_time_s\": 13.50617265701294}", "{\"n\": 12170, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.21, \"learn_time_ms\": 10042.276, \"total_train_time_s\": 12.830376863479614}", "{\"n\": 12171, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.68, \"learn_time_ms\": 9955.535, \"total_train_time_s\": 13.00630235671997}", "{\"n\": 12172, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.59, \"learn_time_ms\": 9929.49, \"total_train_time_s\": 14.055968284606934}", "{\"n\": 12173, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.82, \"learn_time_ms\": 9919.833, \"total_train_time_s\": 13.707823276519775}", "{\"n\": 12174, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.82, \"learn_time_ms\": 9922.698, \"total_train_time_s\": 13.627543449401855}", "{\"n\": 12175, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.83, \"learn_time_ms\": 9954.764, \"total_train_time_s\": 14.225762605667114}", "{\"n\": 12176, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.32, \"learn_time_ms\": 9902.377, \"total_train_time_s\": 13.733189582824707}", "{\"n\": 12177, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.22, \"learn_time_ms\": 10023.483, \"total_train_time_s\": 14.26794171333313}", "{\"n\": 12178, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.77, \"learn_time_ms\": 9932.343, \"total_train_time_s\": 13.365839004516602}", "{\"n\": 12179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.94, \"learn_time_ms\": 10003.387, \"total_train_time_s\": 14.496710300445557}", "{\"n\": 12180, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.94, \"learn_time_ms\": 9964.419, \"total_train_time_s\": 12.484073162078857}", "{\"n\": 12181, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.89, \"learn_time_ms\": 9949.495, \"total_train_time_s\": 12.92634916305542}", "{\"n\": 12182, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.64, \"learn_time_ms\": 9944.2, \"total_train_time_s\": 14.235088109970093}", "{\"n\": 12183, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.77, \"learn_time_ms\": 9813.095, \"total_train_time_s\": 12.577340364456177}", "{\"n\": 12184, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.77, \"learn_time_ms\": 9800.063, \"total_train_time_s\": 13.197710037231445}", "{\"n\": 12185, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.02, \"learn_time_ms\": 9829.465, \"total_train_time_s\": 14.25225830078125}", "{\"n\": 12186, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.95, \"learn_time_ms\": 9793.257, \"total_train_time_s\": 13.175413608551025}", "{\"n\": 12187, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.98, \"learn_time_ms\": 9729.408, \"total_train_time_s\": 13.456590175628662}", "{\"n\": 12188, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.07, \"learn_time_ms\": 9667.781, \"total_train_time_s\": 12.899244785308838}", "{\"n\": 12189, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.66, \"learn_time_ms\": 9641.032, \"total_train_time_s\": 14.3255295753479}", "{\"n\": 12190, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.63, \"learn_time_ms\": 9706.765, \"total_train_time_s\": 13.245713233947754}", "{\"n\": 12191, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.28, \"learn_time_ms\": 9781.408, \"total_train_time_s\": 13.831010341644287}", "{\"n\": 12192, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.45, \"learn_time_ms\": 9758.092, \"total_train_time_s\": 13.835484266281128}", "{\"n\": 12193, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.05, \"learn_time_ms\": 9810.851, \"total_train_time_s\": 12.994242668151855}", "{\"n\": 12194, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.37, \"learn_time_ms\": 9870.212, \"total_train_time_s\": 13.870265483856201}", "{\"n\": 12195, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.92, \"learn_time_ms\": 9818.75, \"total_train_time_s\": 13.800736665725708}", "{\"n\": 12196, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.92, \"learn_time_ms\": 9886.099, \"total_train_time_s\": 14.000822067260742}", "{\"n\": 12197, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.5, \"learn_time_ms\": 9866.69, \"total_train_time_s\": 13.282017707824707}", "{\"n\": 12198, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.51, \"learn_time_ms\": 9884.471, \"total_train_time_s\": 12.9533531665802}", "{\"n\": 12199, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.77, \"learn_time_ms\": 9874.791, \"total_train_time_s\": 14.095592498779297}", "{\"n\": 12200, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.77, \"learn_time_ms\": 9983.199, \"total_train_time_s\": 14.466605186462402}", "{\"n\": 12201, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.61, \"learn_time_ms\": 10006.485, \"total_train_time_s\": 13.971391439437866}", "{\"n\": 12202, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.61, \"learn_time_ms\": 9982.183, \"total_train_time_s\": 13.641756057739258}", "{\"n\": 12203, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.61, \"learn_time_ms\": 9978.41, \"total_train_time_s\": 13.098512411117554}", "{\"n\": 12204, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.39, \"learn_time_ms\": 9962.739, \"total_train_time_s\": 13.717471361160278}", "{\"n\": 12205, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.0, \"learn_time_ms\": 9890.1, \"total_train_time_s\": 13.102218627929688}", "{\"n\": 12206, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.0, \"learn_time_ms\": 9802.182, \"total_train_time_s\": 12.922861337661743}", "{\"n\": 12207, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.2, \"learn_time_ms\": 9865.253, \"total_train_time_s\": 13.967101097106934}", "{\"n\": 12208, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3735.41, \"learn_time_ms\": 9958.369, \"total_train_time_s\": 13.990722894668579}", "{\"n\": 12209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3735.41, \"learn_time_ms\": 9952.068, \"total_train_time_s\": 14.062049865722656}", "{\"n\": 12210, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3735.41, \"learn_time_ms\": 9861.446, \"total_train_time_s\": 13.17384648323059}", "{\"n\": 12211, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.44, \"learn_time_ms\": 9869.87, \"total_train_time_s\": 14.162307739257812}", "{\"n\": 12212, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.2, \"learn_time_ms\": 9931.648, \"total_train_time_s\": 14.083825826644897}", "{\"n\": 12213, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.2, \"learn_time_ms\": 9992.498, \"total_train_time_s\": 13.568732976913452}", "{\"n\": 12214, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.98, \"learn_time_ms\": 9996.653, \"total_train_time_s\": 13.995632648468018}", "{\"n\": 12215, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.38, \"learn_time_ms\": 9978.777, \"total_train_time_s\": 13.004673957824707}", "{\"n\": 12216, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3734.14, \"learn_time_ms\": 10001.003, \"total_train_time_s\": 13.12237024307251}", "{\"n\": 12217, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.58, \"learn_time_ms\": 9999.116, \"total_train_time_s\": 14.023255825042725}", "{\"n\": 12218, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.05, \"learn_time_ms\": 9893.908, \"total_train_time_s\": 12.829670429229736}", "{\"n\": 12219, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.61, \"learn_time_ms\": 9806.813, \"total_train_time_s\": 12.940883159637451}", "{\"n\": 12220, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.33, \"learn_time_ms\": 9889.467, \"total_train_time_s\": 14.062660455703735}", "{\"n\": 12221, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3725.25, \"learn_time_ms\": 9913.884, \"total_train_time_s\": 14.347399473190308}", "{\"n\": 12222, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.31, \"learn_time_ms\": 9861.048, \"total_train_time_s\": 13.533875465393066}", "{\"n\": 12223, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.97, \"learn_time_ms\": 9830.497, \"total_train_time_s\": 13.363572359085083}", "{\"n\": 12224, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.97, \"learn_time_ms\": 9877.566, \"total_train_time_s\": 14.588146686553955}", "{\"n\": 12225, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.74, \"learn_time_ms\": 10008.085, \"total_train_time_s\": 14.174492359161377}", "{\"n\": 12226, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3716.78, \"learn_time_ms\": 10233.511, \"total_train_time_s\": 15.343762874603271}", "{\"n\": 12227, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.99, \"learn_time_ms\": 10163.481, \"total_train_time_s\": 13.306503772735596}", "{\"n\": 12228, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.22, \"learn_time_ms\": 10173.771, \"total_train_time_s\": 13.180567026138306}", "{\"n\": 12229, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.22, \"learn_time_ms\": 10191.026, \"total_train_time_s\": 13.35918641090393}", "{\"n\": 12230, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.25, \"learn_time_ms\": 10050.769, \"total_train_time_s\": 12.618710994720459}", "{\"n\": 12231, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.25, \"learn_time_ms\": 10012.214, \"total_train_time_s\": 13.78669810295105}", "{\"n\": 12232, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.18, \"learn_time_ms\": 9988.913, \"total_train_time_s\": 13.525017499923706}", "{\"n\": 12233, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3728.97, \"learn_time_ms\": 9999.393, \"total_train_time_s\": 13.296313762664795}", "{\"n\": 12234, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 9913.846, \"total_train_time_s\": 13.394948482513428}", "{\"n\": 12235, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 9878.164, \"total_train_time_s\": 14.228236198425293}", "{\"n\": 12236, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.87, \"learn_time_ms\": 9675.461, \"total_train_time_s\": 13.496521711349487}", "{\"n\": 12237, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3722.88, \"learn_time_ms\": 9659.729, \"total_train_time_s\": 13.027232885360718}", "{\"n\": 12238, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.18, \"learn_time_ms\": 9765.641, \"total_train_time_s\": 14.002094507217407}", "{\"n\": 12239, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.18, \"learn_time_ms\": 9817.846, \"total_train_time_s\": 13.577445030212402}", "{\"n\": 12240, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.62, \"learn_time_ms\": 9915.524, \"total_train_time_s\": 13.719265699386597}", "{\"n\": 12241, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.34, \"learn_time_ms\": 9964.291, \"total_train_time_s\": 14.410268783569336}", "{\"n\": 12242, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.4, \"learn_time_ms\": 9952.374, \"total_train_time_s\": 13.227910041809082}", "{\"n\": 12243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.16, \"learn_time_ms\": 9965.752, \"total_train_time_s\": 13.677803039550781}", "{\"n\": 12244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.75, \"learn_time_ms\": 9956.217, \"total_train_time_s\": 13.384823322296143}", "{\"n\": 12245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.58, \"learn_time_ms\": 9934.642, \"total_train_time_s\": 13.634780883789062}", "{\"n\": 12246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.58, \"learn_time_ms\": 9935.558, \"total_train_time_s\": 13.223103046417236}", "{\"n\": 12247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.68, \"learn_time_ms\": 9946.429, \"total_train_time_s\": 13.104056596755981}", "{\"n\": 12248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.51, \"learn_time_ms\": 9944.417, \"total_train_time_s\": 14.276708126068115}", "{\"n\": 12249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.57, \"learn_time_ms\": 9902.105, \"total_train_time_s\": 13.427400827407837}", "{\"n\": 12250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 9878.753, \"total_train_time_s\": 13.523595333099365}", "{\"n\": 12251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.54, \"learn_time_ms\": 9687.606, \"total_train_time_s\": 12.33050012588501}", "{\"n\": 12252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.56, \"learn_time_ms\": 9721.448, \"total_train_time_s\": 13.714555978775024}", "{\"n\": 12253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.56, \"learn_time_ms\": 9805.699, \"total_train_time_s\": 14.478922605514526}", "{\"n\": 12254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.86, \"learn_time_ms\": 9850.547, \"total_train_time_s\": 13.902972936630249}", "{\"n\": 12255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.58, \"learn_time_ms\": 9833.862, \"total_train_time_s\": 13.582385540008545}", "{\"n\": 12256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.22, \"learn_time_ms\": 9866.616, \"total_train_time_s\": 13.590492725372314}", "{\"n\": 12257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.03, \"learn_time_ms\": 9939.159, \"total_train_time_s\": 13.97147798538208}", "{\"n\": 12258, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.9, \"learn_time_ms\": 9846.72, \"total_train_time_s\": 13.22804069519043}", "{\"n\": 12259, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.29, \"learn_time_ms\": 9818.268, \"total_train_time_s\": 13.014422178268433}", "{\"n\": 12260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.09, \"learn_time_ms\": 9854.224, \"total_train_time_s\": 13.747763395309448}", "{\"n\": 12261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.09, \"learn_time_ms\": 9952.53, \"total_train_time_s\": 13.736378908157349}", "{\"n\": 12262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.68, \"learn_time_ms\": 9929.842, \"total_train_time_s\": 13.448247194290161}", "{\"n\": 12263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.72, \"learn_time_ms\": 9850.766, \"total_train_time_s\": 13.460439205169678}", "{\"n\": 12264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.72, \"learn_time_ms\": 9877.134, \"total_train_time_s\": 14.167232036590576}", "{\"n\": 12265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.31, \"learn_time_ms\": 9868.89, \"total_train_time_s\": 13.442644357681274}", "{\"n\": 12266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.49, \"learn_time_ms\": 9936.536, \"total_train_time_s\": 14.435805797576904}", "{\"n\": 12267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.49, \"learn_time_ms\": 9897.884, \"total_train_time_s\": 13.427468061447144}", "{\"n\": 12268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.49, \"learn_time_ms\": 9870.882, \"total_train_time_s\": 13.13962435722351}", "{\"n\": 12269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.8, \"learn_time_ms\": 9994.934, \"total_train_time_s\": 14.369836568832397}", "{\"n\": 12270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.72, \"learn_time_ms\": 9946.537, \"total_train_time_s\": 13.397675037384033}", "{\"n\": 12271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.72, \"learn_time_ms\": 10028.238, \"total_train_time_s\": 14.441980123519897}", "{\"n\": 12272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.72, \"learn_time_ms\": 10091.555, \"total_train_time_s\": 14.365072250366211}", "{\"n\": 12273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 10028.607, \"total_train_time_s\": 12.901256084442139}", "{\"n\": 12274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.11, \"learn_time_ms\": 10017.414, \"total_train_time_s\": 13.991875410079956}", "{\"n\": 12275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.11, \"learn_time_ms\": 9994.847, \"total_train_time_s\": 13.543644428253174}", "{\"n\": 12276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.11, \"learn_time_ms\": 9946.491, \"total_train_time_s\": 14.12533187866211}", "{\"n\": 12277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.99, \"learn_time_ms\": 9977.759, \"total_train_time_s\": 13.930114507675171}", "{\"n\": 12278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.32, \"learn_time_ms\": 10084.314, \"total_train_time_s\": 14.083225965499878}", "{\"n\": 12279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.32, \"learn_time_ms\": 9980.066, \"total_train_time_s\": 13.109829187393188}", "{\"n\": 12280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.06, \"learn_time_ms\": 10005.999, \"total_train_time_s\": 13.775267839431763}", "{\"n\": 12281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 9860.697, \"total_train_time_s\": 12.858830451965332}", "{\"n\": 12282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 9808.064, \"total_train_time_s\": 13.791409969329834}", "{\"n\": 12283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 9956.821, \"total_train_time_s\": 14.708143949508667}", "{\"n\": 12284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.46, \"learn_time_ms\": 9912.431, \"total_train_time_s\": 13.503656387329102}", "{\"n\": 12285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.65, \"learn_time_ms\": 9927.319, \"total_train_time_s\": 13.362947940826416}", "{\"n\": 12286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.65, \"learn_time_ms\": 9846.453, \"total_train_time_s\": 12.95788311958313}", "{\"n\": 12287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.57, \"learn_time_ms\": 9871.818, \"total_train_time_s\": 14.218174934387207}", "{\"n\": 12288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.85, \"learn_time_ms\": 9725.555, \"total_train_time_s\": 12.32664155960083}", "{\"n\": 12289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.71, \"learn_time_ms\": 9801.633, \"total_train_time_s\": 14.095857381820679}", "{\"n\": 12290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.71, \"learn_time_ms\": 9685.141, \"total_train_time_s\": 12.53787612915039}", "{\"n\": 12291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.62, \"learn_time_ms\": 9783.875, \"total_train_time_s\": 13.812278032302856}", "{\"n\": 12292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.39, \"learn_time_ms\": 9763.033, \"total_train_time_s\": 13.478383779525757}", "{\"n\": 12293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.31, \"learn_time_ms\": 9664.696, \"total_train_time_s\": 13.32377552986145}", "{\"n\": 12294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 9768.824, \"total_train_time_s\": 14.422463417053223}", "{\"n\": 12295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 9756.877, \"total_train_time_s\": 13.30409574508667}", "{\"n\": 12296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.7, \"learn_time_ms\": 9815.489, \"total_train_time_s\": 13.824065446853638}", "{\"n\": 12297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.76, \"learn_time_ms\": 9693.79, \"total_train_time_s\": 12.86302638053894}", "{\"n\": 12298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.76, \"learn_time_ms\": 9850.894, \"total_train_time_s\": 13.944947719573975}", "{\"n\": 12299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.37, \"learn_time_ms\": 9848.996, \"total_train_time_s\": 14.00936484336853}", "{\"n\": 12300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.5, \"learn_time_ms\": 9889.645, \"total_train_time_s\": 12.6981680393219}", "{\"n\": 12301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.18, \"learn_time_ms\": 9812.142, \"total_train_time_s\": 13.13275957107544}", "{\"n\": 12302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.18, \"learn_time_ms\": 9886.012, \"total_train_time_s\": 14.150784015655518}", "{\"n\": 12303, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.45, \"learn_time_ms\": 9908.683, \"total_train_time_s\": 13.747833490371704}", "{\"n\": 12304, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.63, \"learn_time_ms\": 9859.078, \"total_train_time_s\": 14.032833337783813}", "{\"n\": 12305, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.63, \"learn_time_ms\": 9807.041, \"total_train_time_s\": 12.610415697097778}", "{\"n\": 12306, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.08, \"learn_time_ms\": 9897.016, \"total_train_time_s\": 14.41955852508545}", "{\"n\": 12307, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.67, \"learn_time_ms\": 9921.708, \"total_train_time_s\": 13.252491474151611}", "{\"n\": 12308, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.63, \"learn_time_ms\": 9834.646, \"total_train_time_s\": 13.261293172836304}", "{\"n\": 12309, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.63, \"learn_time_ms\": 9870.71, \"total_train_time_s\": 14.6600022315979}", "{\"n\": 12310, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.63, \"learn_time_ms\": 9966.872, \"total_train_time_s\": 13.729229211807251}", "{\"n\": 12311, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.16, \"learn_time_ms\": 9999.073, \"total_train_time_s\": 13.395647287368774}", "{\"n\": 12312, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.16, \"learn_time_ms\": 9875.55, \"total_train_time_s\": 12.988285303115845}", "{\"n\": 12313, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.16, \"learn_time_ms\": 9868.736, \"total_train_time_s\": 13.480183362960815}", "{\"n\": 12314, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.21, \"learn_time_ms\": 9873.49, \"total_train_time_s\": 14.015987396240234}", "{\"n\": 12315, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.05, \"learn_time_ms\": 9899.561, \"total_train_time_s\": 12.937655210494995}", "{\"n\": 12316, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.05, \"learn_time_ms\": 9846.14, \"total_train_time_s\": 13.872170209884644}", "{\"n\": 12317, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.47, \"learn_time_ms\": 9894.593, \"total_train_time_s\": 13.759087085723877}", "{\"n\": 12318, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.47, \"learn_time_ms\": 10017.196, \"total_train_time_s\": 14.401249408721924}", "{\"n\": 12319, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.32, \"learn_time_ms\": 9942.47, \"total_train_time_s\": 13.83926272392273}", "{\"n\": 12320, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.32, \"learn_time_ms\": 9866.327, \"total_train_time_s\": 13.105976104736328}", "{\"n\": 12321, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.01, \"learn_time_ms\": 9910.007, \"total_train_time_s\": 13.917504787445068}", "{\"n\": 12322, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.01, \"learn_time_ms\": 10010.52, \"total_train_time_s\": 13.846583127975464}", "{\"n\": 12323, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.28, \"learn_time_ms\": 9999.435, \"total_train_time_s\": 13.410254955291748}", "{\"n\": 12324, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.36, \"learn_time_ms\": 9929.442, \"total_train_time_s\": 13.365017175674438}", "{\"n\": 12325, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.51, \"learn_time_ms\": 9950.035, \"total_train_time_s\": 13.155497074127197}", "{\"n\": 12326, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.51, \"learn_time_ms\": 9822.071, \"total_train_time_s\": 12.61506700515747}", "{\"n\": 12327, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.58, \"learn_time_ms\": 9807.089, \"total_train_time_s\": 13.363226652145386}", "{\"n\": 12328, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.39, \"learn_time_ms\": 9667.885, \"total_train_time_s\": 13.09873342514038}", "{\"n\": 12329, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.39, \"learn_time_ms\": 9705.306, \"total_train_time_s\": 13.8748300075531}", "{\"n\": 12330, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.82, \"learn_time_ms\": 9806.197, \"total_train_time_s\": 14.165279388427734}", "{\"n\": 12331, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.82, \"learn_time_ms\": 9792.022, \"total_train_time_s\": 13.637918710708618}", "{\"n\": 12332, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.29, \"learn_time_ms\": 9933.938, \"total_train_time_s\": 15.22464919090271}", "{\"n\": 12333, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.67, \"learn_time_ms\": 9828.338, \"total_train_time_s\": 12.489832162857056}", "{\"n\": 12334, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.67, \"learn_time_ms\": 9879.46, \"total_train_time_s\": 13.982126951217651}", "{\"n\": 12335, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.25, \"learn_time_ms\": 9945.216, \"total_train_time_s\": 13.821906089782715}", "{\"n\": 12336, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.2, \"learn_time_ms\": 10077.335, \"total_train_time_s\": 14.039948225021362}", "{\"n\": 12337, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.2, \"learn_time_ms\": 10085.535, \"total_train_time_s\": 13.62161636352539}", "{\"n\": 12338, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.66, \"learn_time_ms\": 10125.539, \"total_train_time_s\": 13.412404298782349}", "{\"n\": 12339, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.91, \"learn_time_ms\": 10062.682, \"total_train_time_s\": 13.217447280883789}", "{\"n\": 12340, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.3, \"learn_time_ms\": 9969.193, \"total_train_time_s\": 13.150854349136353}", "{\"n\": 12341, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.3, \"learn_time_ms\": 9926.843, \"total_train_time_s\": 13.444342851638794}", "{\"n\": 12342, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.28, \"learn_time_ms\": 9753.25, \"total_train_time_s\": 13.386258363723755}", "{\"n\": 12343, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.03, \"learn_time_ms\": 9769.33, \"total_train_time_s\": 12.540226936340332}", "{\"n\": 12344, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.03, \"learn_time_ms\": 9699.956, \"total_train_time_s\": 13.058449029922485}", "{\"n\": 12345, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.41, \"learn_time_ms\": 9610.858, \"total_train_time_s\": 12.81749415397644}", "{\"n\": 12346, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.64, \"learn_time_ms\": 9608.179, \"total_train_time_s\": 14.10803484916687}", "{\"n\": 12347, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.0, \"learn_time_ms\": 9569.702, \"total_train_time_s\": 13.050959348678589}", "{\"n\": 12348, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.94, \"learn_time_ms\": 9518.209, \"total_train_time_s\": 13.000664710998535}", "{\"n\": 12349, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.94, \"learn_time_ms\": 9477.123, \"total_train_time_s\": 13.04849886894226}", "{\"n\": 12350, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.34, \"learn_time_ms\": 9549.966, \"total_train_time_s\": 13.846405506134033}", "{\"n\": 12351, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.34, \"learn_time_ms\": 9494.995, \"total_train_time_s\": 12.717531681060791}", "{\"n\": 12352, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.79, \"learn_time_ms\": 9563.651, \"total_train_time_s\": 14.158021926879883}", "{\"n\": 12353, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.45, \"learn_time_ms\": 9689.255, \"total_train_time_s\": 13.967484712600708}", "{\"n\": 12354, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.87, \"learn_time_ms\": 9662.2, \"total_train_time_s\": 13.038729667663574}", "{\"n\": 12355, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.84, \"learn_time_ms\": 9688.486, \"total_train_time_s\": 13.424062013626099}", "{\"n\": 12356, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.84, \"learn_time_ms\": 9698.547, \"total_train_time_s\": 14.41115689277649}", "{\"n\": 12357, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.17, \"learn_time_ms\": 9676.939, \"total_train_time_s\": 12.971975326538086}", "{\"n\": 12358, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.17, \"learn_time_ms\": 9707.999, \"total_train_time_s\": 13.473520517349243}", "{\"n\": 12359, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3583.98, \"learn_time_ms\": 9744.921, \"total_train_time_s\": 13.191999912261963}", "{\"n\": 12360, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3587.51, \"learn_time_ms\": 9646.121, \"total_train_time_s\": 12.700912237167358}", "{\"n\": 12361, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.83, \"learn_time_ms\": 9703.141, \"total_train_time_s\": 13.245048999786377}", "{\"n\": 12362, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 9662.57, \"total_train_time_s\": 13.650448560714722}", "{\"n\": 12363, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 9596.601, \"total_train_time_s\": 13.156528949737549}", "{\"n\": 12364, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.96, \"learn_time_ms\": 9735.322, \"total_train_time_s\": 14.363901376724243}", "{\"n\": 12365, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.22, \"learn_time_ms\": 9766.739, \"total_train_time_s\": 13.504618644714355}", "{\"n\": 12366, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.33, \"learn_time_ms\": 9789.266, \"total_train_time_s\": 14.279820680618286}", "{\"n\": 12367, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.33, \"learn_time_ms\": 9836.19, \"total_train_time_s\": 13.64721393585205}", "{\"n\": 12368, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.33, \"learn_time_ms\": 9909.837, \"total_train_time_s\": 13.905051708221436}", "{\"n\": 12369, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3552.52, \"learn_time_ms\": 9934.064, \"total_train_time_s\": 13.531486749649048}", "{\"n\": 12370, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3552.52, \"learn_time_ms\": 10042.069, \"total_train_time_s\": 14.289570331573486}", "{\"n\": 12371, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3552.52, \"learn_time_ms\": 10020.322, \"total_train_time_s\": 12.969041585922241}", "{\"n\": 12372, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.11, \"learn_time_ms\": 9953.043, \"total_train_time_s\": 13.150232553482056}", "{\"n\": 12373, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.11, \"learn_time_ms\": 9973.629, \"total_train_time_s\": 13.502233982086182}", "{\"n\": 12374, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.11, \"learn_time_ms\": 9924.544, \"total_train_time_s\": 13.910618782043457}", "{\"n\": 12375, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.11, \"learn_time_ms\": 9975.644, \"total_train_time_s\": 14.213826656341553}", "{\"n\": 12376, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.05, \"learn_time_ms\": 9959.749, \"total_train_time_s\": 14.411888837814331}", "{\"n\": 12377, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.05, \"learn_time_ms\": 9908.371, \"total_train_time_s\": 12.832074403762817}", "{\"n\": 12378, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.05, \"learn_time_ms\": 9817.495, \"total_train_time_s\": 12.896445035934448}", "{\"n\": 12379, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.32, \"learn_time_ms\": 9813.11, \"total_train_time_s\": 13.492056369781494}", "{\"n\": 12380, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.2, \"learn_time_ms\": 9796.609, \"total_train_time_s\": 13.811885833740234}", "{\"n\": 12381, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.2, \"learn_time_ms\": 9697.039, \"total_train_time_s\": 12.114341497421265}", "{\"n\": 12382, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.2, \"learn_time_ms\": 9727.207, \"total_train_time_s\": 13.34970211982727}", "{\"n\": 12383, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.2, \"learn_time_ms\": 9857.795, \"total_train_time_s\": 14.843087434768677}", "{\"n\": 12384, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.24, \"learn_time_ms\": 9889.022, \"total_train_time_s\": 14.215514421463013}", "{\"n\": 12385, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.24, \"learn_time_ms\": 9810.58, \"total_train_time_s\": 13.4185311794281}", "{\"n\": 12386, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.48, \"learn_time_ms\": 9744.241, \"total_train_time_s\": 13.51107406616211}", "{\"n\": 12387, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3542.79, \"learn_time_ms\": 9904.118, \"total_train_time_s\": 14.55734133720398}", "{\"n\": 12388, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.85, \"learn_time_ms\": 9890.641, \"total_train_time_s\": 12.724475145339966}", "{\"n\": 12389, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.49, \"learn_time_ms\": 9868.624, \"total_train_time_s\": 13.329923629760742}", "{\"n\": 12390, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.06, \"learn_time_ms\": 9897.368, \"total_train_time_s\": 14.206071615219116}", "{\"n\": 12391, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.06, \"learn_time_ms\": 10075.697, \"total_train_time_s\": 13.818970203399658}", "{\"n\": 12392, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.53, \"learn_time_ms\": 10164.969, \"total_train_time_s\": 14.23145055770874}", "{\"n\": 12393, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.36, \"learn_time_ms\": 10068.667, \"total_train_time_s\": 13.564867734909058}", "{\"n\": 12394, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.88, \"learn_time_ms\": 10029.944, \"total_train_time_s\": 13.680525779724121}", "{\"n\": 12395, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.88, \"learn_time_ms\": 10047.747, \"total_train_time_s\": 13.308714151382446}", "{\"n\": 12396, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.99, \"learn_time_ms\": 10062.931, \"total_train_time_s\": 13.586616277694702}", "{\"n\": 12397, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3561.37, \"learn_time_ms\": 10058.359, \"total_train_time_s\": 14.560776710510254}", "{\"n\": 12398, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3569.72, \"learn_time_ms\": 10166.555, \"total_train_time_s\": 13.973938465118408}", "{\"n\": 12399, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.59, \"learn_time_ms\": 10228.383, \"total_train_time_s\": 13.802963018417358}", "{\"n\": 12400, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.59, \"learn_time_ms\": 10247.986, \"total_train_time_s\": 14.337690353393555}", "{\"n\": 12401, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 10167.635, \"total_train_time_s\": 12.902819156646729}", "{\"n\": 12402, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 10053.946, \"total_train_time_s\": 13.251238346099854}", "{\"n\": 12403, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3576.62, \"learn_time_ms\": 9997.885, \"total_train_time_s\": 13.121970891952515}", "{\"n\": 12404, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3576.62, \"learn_time_ms\": 10042.266, \"total_train_time_s\": 14.197126626968384}", "{\"n\": 12405, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3580.23, \"learn_time_ms\": 10065.435, \"total_train_time_s\": 13.686523914337158}", "{\"n\": 12406, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.67, \"learn_time_ms\": 10062.089, \"total_train_time_s\": 13.785884380340576}", "{\"n\": 12407, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.7, \"learn_time_ms\": 9925.317, \"total_train_time_s\": 13.0973379611969}", "{\"n\": 12408, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.7, \"learn_time_ms\": 9843.143, \"total_train_time_s\": 13.068307399749756}", "{\"n\": 12409, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.68, \"learn_time_ms\": 9788.758, \"total_train_time_s\": 13.214889287948608}", "{\"n\": 12410, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.04, \"learn_time_ms\": 9697.269, \"total_train_time_s\": 13.343236446380615}", "{\"n\": 12411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.42, \"learn_time_ms\": 9792.489, \"total_train_time_s\": 14.12646222114563}", "{\"n\": 12412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.39, \"learn_time_ms\": 9851.512, \"total_train_time_s\": 13.63497519493103}", "{\"n\": 12413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 9906.521, \"total_train_time_s\": 13.759165287017822}", "{\"n\": 12414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 9802.437, \"total_train_time_s\": 13.545321941375732}", "{\"n\": 12415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 9744.287, \"total_train_time_s\": 13.090125799179077}", "{\"n\": 12416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 9746.013, \"total_train_time_s\": 13.743794202804565}", "{\"n\": 12417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.69, \"learn_time_ms\": 9792.905, \"total_train_time_s\": 13.6724271774292}", "{\"n\": 12418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.69, \"learn_time_ms\": 9747.198, \"total_train_time_s\": 12.768506288528442}", "{\"n\": 12419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.24, \"learn_time_ms\": 9838.146, \"total_train_time_s\": 14.226893186569214}", "{\"n\": 12420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.24, \"learn_time_ms\": 9788.729, \"total_train_time_s\": 12.853379487991333}", "{\"n\": 12421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.11, \"learn_time_ms\": 9885.191, \"total_train_time_s\": 14.84075117111206}", "{\"n\": 12422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.11, \"learn_time_ms\": 9818.036, \"total_train_time_s\": 13.088770627975464}", "{\"n\": 12423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.31, \"learn_time_ms\": 9811.406, \"total_train_time_s\": 13.549643754959106}", "{\"n\": 12424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.31, \"learn_time_ms\": 9913.066, \"total_train_time_s\": 14.363041400909424}", "{\"n\": 12425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.33, \"learn_time_ms\": 9914.682, \"total_train_time_s\": 13.071150541305542}", "{\"n\": 12426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3600.7, \"learn_time_ms\": 9860.289, \"total_train_time_s\": 13.028685331344604}", "{\"n\": 12427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.37, \"learn_time_ms\": 9966.812, \"total_train_time_s\": 14.85383677482605}", "{\"n\": 12428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3613.44, \"learn_time_ms\": 10083.374, \"total_train_time_s\": 13.774122476577759}", "{\"n\": 12429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.14, \"learn_time_ms\": 10045.8, \"total_train_time_s\": 13.847676277160645}", "{\"n\": 12430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.25, \"learn_time_ms\": 10116.769, \"total_train_time_s\": 13.75725531578064}", "{\"n\": 12431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.25, \"learn_time_ms\": 10000.021, \"total_train_time_s\": 13.664358139038086}", "{\"n\": 12432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3617.65, \"learn_time_ms\": 10053.659, \"total_train_time_s\": 13.62750506401062}", "{\"n\": 12433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.72, \"learn_time_ms\": 10050.809, \"total_train_time_s\": 13.767474174499512}", "{\"n\": 12434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.72, \"learn_time_ms\": 10093.366, \"total_train_time_s\": 14.591402292251587}", "{\"n\": 12435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.96, \"learn_time_ms\": 10189.028, \"total_train_time_s\": 13.913793802261353}", "{\"n\": 12436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.58, \"learn_time_ms\": 10186.287, \"total_train_time_s\": 12.979623794555664}", "{\"n\": 12437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.38, \"learn_time_ms\": 10056.986, \"total_train_time_s\": 13.428472757339478}", "{\"n\": 12438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.31, \"learn_time_ms\": 10004.811, \"total_train_time_s\": 13.179682731628418}", "{\"n\": 12439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.31, \"learn_time_ms\": 9970.906, \"total_train_time_s\": 13.669918537139893}", "{\"n\": 12440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.92, \"learn_time_ms\": 10006.752, \"total_train_time_s\": 13.84540581703186}", "{\"n\": 12441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.92, \"learn_time_ms\": 10006.895, \"total_train_time_s\": 13.954123497009277}", "{\"n\": 12442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.23, \"learn_time_ms\": 10044.1, \"total_train_time_s\": 14.017777681350708}", "{\"n\": 12443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.68, \"learn_time_ms\": 10101.516, \"total_train_time_s\": 14.243804693222046}", "{\"n\": 12444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.87, \"learn_time_ms\": 10150.585, \"total_train_time_s\": 15.033802270889282}", "{\"n\": 12445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.9, \"learn_time_ms\": 10129.069, \"total_train_time_s\": 13.807092428207397}", "{\"n\": 12446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 10168.779, \"total_train_time_s\": 13.584042310714722}", "{\"n\": 12447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.08, \"learn_time_ms\": 10194.884, \"total_train_time_s\": 13.616469860076904}", "{\"n\": 12448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.08, \"learn_time_ms\": 10194.801, \"total_train_time_s\": 13.284357786178589}", "{\"n\": 12449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.6, \"learn_time_ms\": 10334.439, \"total_train_time_s\": 14.833820819854736}", "{\"n\": 12450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.89, \"learn_time_ms\": 10287.731, \"total_train_time_s\": 13.330448627471924}", "{\"n\": 12451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3598.26, \"learn_time_ms\": 10327.041, \"total_train_time_s\": 14.22995901107788}", "{\"n\": 12452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.44, \"learn_time_ms\": 10301.461, \"total_train_time_s\": 13.851680278778076}", "{\"n\": 12453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.44, \"learn_time_ms\": 10251.633, \"total_train_time_s\": 13.963143825531006}", "{\"n\": 12454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3609.0, \"learn_time_ms\": 10028.269, \"total_train_time_s\": 12.784207344055176}", "{\"n\": 12455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.4, \"learn_time_ms\": 9995.314, \"total_train_time_s\": 13.437194108963013}", "{\"n\": 12456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.4, \"learn_time_ms\": 9982.968, \"total_train_time_s\": 13.392738580703735}", "{\"n\": 12457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.28, \"learn_time_ms\": 10070.102, \"total_train_time_s\": 14.367100715637207}", "{\"n\": 12458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.28, \"learn_time_ms\": 10021.253, \"total_train_time_s\": 12.872712135314941}", "{\"n\": 12459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.85, \"learn_time_ms\": 9935.145, \"total_train_time_s\": 13.99027132987976}", "{\"n\": 12460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.08, \"learn_time_ms\": 10052.288, \"total_train_time_s\": 14.642427682876587}", "{\"n\": 12461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.08, \"learn_time_ms\": 10045.54, \"total_train_time_s\": 14.332317352294922}", "{\"n\": 12462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.08, \"learn_time_ms\": 9955.157, \"total_train_time_s\": 12.662439107894897}", "{\"n\": 12463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.32, \"learn_time_ms\": 9996.084, \"total_train_time_s\": 14.066522598266602}", "{\"n\": 12464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.26, \"learn_time_ms\": 10107.916, \"total_train_time_s\": 13.972630500793457}", "{\"n\": 12465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.26, \"learn_time_ms\": 10037.336, \"total_train_time_s\": 13.044418334960938}", "{\"n\": 12466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3583.48, \"learn_time_ms\": 10003.642, \"total_train_time_s\": 13.239081144332886}", "{\"n\": 12467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.39, \"learn_time_ms\": 9927.11, \"total_train_time_s\": 13.653914451599121}", "{\"n\": 12468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.59, \"learn_time_ms\": 10007.807, \"total_train_time_s\": 13.74711012840271}", "{\"n\": 12469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.59, \"learn_time_ms\": 9935.016, \"total_train_time_s\": 13.634586572647095}", "{\"n\": 12470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.06, \"learn_time_ms\": 9872.829, \"total_train_time_s\": 13.97252631187439}", "{\"n\": 12471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.52, \"learn_time_ms\": 9803.602, \"total_train_time_s\": 13.268833637237549}", "{\"n\": 12472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.52, \"learn_time_ms\": 9840.722, \"total_train_time_s\": 13.506124019622803}", "{\"n\": 12473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.17, \"learn_time_ms\": 9744.956, \"total_train_time_s\": 13.391364812850952}", "{\"n\": 12474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.96, \"learn_time_ms\": 9803.34, \"total_train_time_s\": 14.482572317123413}", "{\"n\": 12475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.72, \"learn_time_ms\": 9870.491, \"total_train_time_s\": 13.596376419067383}", "{\"n\": 12476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.72, \"learn_time_ms\": 9888.669, \"total_train_time_s\": 13.23047399520874}", "{\"n\": 12477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.19, \"learn_time_ms\": 9939.43, \"total_train_time_s\": 14.07532024383545}", "{\"n\": 12478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.59, \"learn_time_ms\": 9957.648, \"total_train_time_s\": 13.781978368759155}", "{\"n\": 12479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.55, \"learn_time_ms\": 9933.093, \"total_train_time_s\": 13.176190853118896}", "{\"n\": 12480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 9942.405, \"total_train_time_s\": 14.101755857467651}", "{\"n\": 12481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.54, \"learn_time_ms\": 9894.485, \"total_train_time_s\": 12.819869995117188}", "{\"n\": 12482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.27, \"learn_time_ms\": 10024.613, \"total_train_time_s\": 14.609076738357544}", "{\"n\": 12483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.76, \"learn_time_ms\": 10074.467, \"total_train_time_s\": 13.601247310638428}", "{\"n\": 12484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.55, \"learn_time_ms\": 10010.726, \"total_train_time_s\": 14.144835948944092}", "{\"n\": 12485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.43, \"learn_time_ms\": 10049.72, \"total_train_time_s\": 13.994769096374512}", "{\"n\": 12486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.75, \"learn_time_ms\": 10079.559, \"total_train_time_s\": 13.654391765594482}", "{\"n\": 12487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.75, \"learn_time_ms\": 10040.255, \"total_train_time_s\": 13.75455379486084}", "{\"n\": 12488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.65, \"learn_time_ms\": 10031.951, \"total_train_time_s\": 14.08847975730896}", "{\"n\": 12489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.61, \"learn_time_ms\": 10098.274, \"total_train_time_s\": 13.796341180801392}", "{\"n\": 12490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.61, \"learn_time_ms\": 10162.36, \"total_train_time_s\": 14.761931419372559}", "{\"n\": 12491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.61, \"learn_time_ms\": 10260.443, \"total_train_time_s\": 13.862544298171997}", "{\"n\": 12492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.09, \"learn_time_ms\": 10185.833, \"total_train_time_s\": 13.764066457748413}", "{\"n\": 12493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.5, \"learn_time_ms\": 10269.11, \"total_train_time_s\": 14.427642345428467}", "{\"n\": 12494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.5, \"learn_time_ms\": 10328.862, \"total_train_time_s\": 14.589739084243774}", "{\"n\": 12495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.72, \"learn_time_ms\": 10316.706, \"total_train_time_s\": 13.821721315383911}", "{\"n\": 12496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.72, \"learn_time_ms\": 10420.638, \"total_train_time_s\": 14.421330451965332}", "{\"n\": 12497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.21, \"learn_time_ms\": 10428.683, \"total_train_time_s\": 13.755791425704956}", "{\"n\": 12498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.21, \"learn_time_ms\": 10364.092, \"total_train_time_s\": 13.135890007019043}", "{\"n\": 12499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.52, \"learn_time_ms\": 10460.132, \"total_train_time_s\": 14.647708415985107}", "{\"n\": 12500, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.78, \"learn_time_ms\": 10423.163, \"total_train_time_s\": 14.340686559677124}", "{\"n\": 12501, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.78, \"learn_time_ms\": 10446.184, \"total_train_time_s\": 14.003782749176025}", "{\"n\": 12502, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3609.85, \"learn_time_ms\": 10351.87, \"total_train_time_s\": 12.872793674468994}", "{\"n\": 12503, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.26, \"learn_time_ms\": 10306.36, \"total_train_time_s\": 13.940246820449829}", "{\"n\": 12504, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.74, \"learn_time_ms\": 10184.134, \"total_train_time_s\": 13.239697217941284}", "{\"n\": 12505, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.38, \"learn_time_ms\": 10138.715, \"total_train_time_s\": 13.33090329170227}", "{\"n\": 12506, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.64, \"learn_time_ms\": 10056.711, \"total_train_time_s\": 13.723668813705444}", "{\"n\": 12507, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.48, \"learn_time_ms\": 9934.906, \"total_train_time_s\": 12.64999008178711}", "{\"n\": 12508, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.32, \"learn_time_ms\": 10007.664, \"total_train_time_s\": 13.696822881698608}", "{\"n\": 12509, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.9, \"learn_time_ms\": 9971.704, \"total_train_time_s\": 14.313254117965698}", "{\"n\": 12510, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.71, \"learn_time_ms\": 9919.445, \"total_train_time_s\": 13.743507146835327}", "{\"n\": 12511, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.71, \"learn_time_ms\": 9889.127, \"total_train_time_s\": 13.806575775146484}", "{\"n\": 12512, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.39, \"learn_time_ms\": 10010.125, \"total_train_time_s\": 13.913025617599487}", "{\"n\": 12513, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.39, \"learn_time_ms\": 9870.574, \"total_train_time_s\": 12.457313060760498}", "{\"n\": 12514, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.8, \"learn_time_ms\": 9855.68, \"total_train_time_s\": 13.0184645652771}", "{\"n\": 12515, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.89, \"learn_time_ms\": 9848.967, \"total_train_time_s\": 13.149904727935791}", "{\"n\": 12516, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.61, \"learn_time_ms\": 9906.322, \"total_train_time_s\": 14.223125457763672}", "{\"n\": 12517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.61, \"learn_time_ms\": 10070.45, \"total_train_time_s\": 14.488616704940796}", "{\"n\": 12518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.61, \"learn_time_ms\": 10080.993, \"total_train_time_s\": 13.891049146652222}", "{\"n\": 12519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3552.74, \"learn_time_ms\": 9911.824, \"total_train_time_s\": 12.936662197113037}", "{\"n\": 12520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.45, \"learn_time_ms\": 9864.593, \"total_train_time_s\": 13.272627353668213}", "{\"n\": 12521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.56, \"learn_time_ms\": 9763.579, \"total_train_time_s\": 12.909058570861816}", "{\"n\": 12522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.24, \"learn_time_ms\": 9752.673, \"total_train_time_s\": 13.944751977920532}", "{\"n\": 12523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3565.61, \"learn_time_ms\": 9783.146, \"total_train_time_s\": 13.022220373153687}", "{\"n\": 12524, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3574.19, \"learn_time_ms\": 9771.513, \"total_train_time_s\": 12.996057987213135}", "{\"n\": 12525, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.26, \"learn_time_ms\": 9739.183, \"total_train_time_s\": 12.849524736404419}", "{\"n\": 12526, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.46, \"learn_time_ms\": 9625.331, \"total_train_time_s\": 13.12154221534729}", "{\"n\": 12527, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.46, \"learn_time_ms\": 9516.217, \"total_train_time_s\": 13.148463010787964}", "{\"n\": 12528, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3577.85, \"learn_time_ms\": 9578.545, \"total_train_time_s\": 14.464178562164307}", "{\"n\": 12529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.76, \"learn_time_ms\": 9653.212, \"total_train_time_s\": 13.353522539138794}", "{\"n\": 12530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.76, \"learn_time_ms\": 9686.413, \"total_train_time_s\": 13.624129295349121}", "{\"n\": 12531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.11, \"learn_time_ms\": 9725.527, \"total_train_time_s\": 13.364657163619995}", "{\"n\": 12532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3575.7, \"learn_time_ms\": 9619.667, \"total_train_time_s\": 12.779193878173828}", "{\"n\": 12533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.09, \"learn_time_ms\": 9648.311, \"total_train_time_s\": 13.130579471588135}", "{\"n\": 12534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3569.92, \"learn_time_ms\": 9774.136, \"total_train_time_s\": 14.326628923416138}", "{\"n\": 12535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3569.92, \"learn_time_ms\": 9831.972, \"total_train_time_s\": 13.623647689819336}", "{\"n\": 12536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.14, \"learn_time_ms\": 9881.672, \"total_train_time_s\": 13.584070920944214}", "{\"n\": 12537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.97, \"learn_time_ms\": 9876.7, \"total_train_time_s\": 13.155600547790527}", "{\"n\": 12538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.29, \"learn_time_ms\": 9758.113, \"total_train_time_s\": 13.412348508834839}", "{\"n\": 12539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.6, \"learn_time_ms\": 9732.242, \"total_train_time_s\": 13.085118055343628}", "{\"n\": 12540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.4, \"learn_time_ms\": 9751.577, \"total_train_time_s\": 14.041911125183105}", "{\"n\": 12541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.4, \"learn_time_ms\": 9806.636, \"total_train_time_s\": 13.691020965576172}", "{\"n\": 12542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.87, \"learn_time_ms\": 9843.912, \"total_train_time_s\": 13.108445405960083}", "{\"n\": 12543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.76, \"learn_time_ms\": 9881.169, \"total_train_time_s\": 13.440096616744995}", "{\"n\": 12544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.61, \"learn_time_ms\": 9749.067, \"total_train_time_s\": 13.03887677192688}", "{\"n\": 12545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.73, \"learn_time_ms\": 9717.682, \"total_train_time_s\": 13.14941954612732}", "{\"n\": 12546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.78, \"learn_time_ms\": 9624.623, \"total_train_time_s\": 12.849844455718994}", "{\"n\": 12547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.62, \"learn_time_ms\": 9645.903, \"total_train_time_s\": 13.313969373703003}", "{\"n\": 12548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.14, \"learn_time_ms\": 9707.825, \"total_train_time_s\": 14.070493459701538}", "{\"n\": 12549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.14, \"learn_time_ms\": 9656.676, \"total_train_time_s\": 12.671990871429443}", "{\"n\": 12550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.8, \"learn_time_ms\": 9583.094, \"total_train_time_s\": 12.986296892166138}", "{\"n\": 12551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.29, \"learn_time_ms\": 9630.072, \"total_train_time_s\": 14.140558242797852}", "{\"n\": 12552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.33, \"learn_time_ms\": 9577.9, \"total_train_time_s\": 12.76141881942749}", "{\"n\": 12553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.57, \"learn_time_ms\": 9542.641, \"total_train_time_s\": 13.113143920898438}", "{\"n\": 12554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.95, \"learn_time_ms\": 9626.529, \"total_train_time_s\": 13.823651313781738}", "{\"n\": 12555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.82, \"learn_time_ms\": 9725.135, \"total_train_time_s\": 14.423533916473389}", "{\"n\": 12556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.23, \"learn_time_ms\": 9771.496, \"total_train_time_s\": 13.084902286529541}", "{\"n\": 12557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.67, \"learn_time_ms\": 9854.338, \"total_train_time_s\": 14.190414190292358}", "{\"n\": 12558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.46, \"learn_time_ms\": 9718.252, \"total_train_time_s\": 12.51589059829712}", "{\"n\": 12559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.84, \"learn_time_ms\": 9849.054, \"total_train_time_s\": 13.853679180145264}", "{\"n\": 12560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.95, \"learn_time_ms\": 9905.115, \"total_train_time_s\": 13.625090599060059}", "{\"n\": 12561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.97, \"learn_time_ms\": 9938.937, \"total_train_time_s\": 14.492980241775513}", "{\"n\": 12562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.97, \"learn_time_ms\": 10139.475, \"total_train_time_s\": 14.573413372039795}", "{\"n\": 12563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.33, \"learn_time_ms\": 10143.271, \"total_train_time_s\": 13.234894037246704}", "{\"n\": 12564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.33, \"learn_time_ms\": 10117.244, \"total_train_time_s\": 13.54877519607544}", "{\"n\": 12565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.89, \"learn_time_ms\": 10077.51, \"total_train_time_s\": 13.668715476989746}", "{\"n\": 12566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.89, \"learn_time_ms\": 10210.799, \"total_train_time_s\": 14.527751922607422}", "{\"n\": 12567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.33, \"learn_time_ms\": 10127.94, \"total_train_time_s\": 13.336148023605347}", "{\"n\": 12568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.32, \"learn_time_ms\": 10163.944, \"total_train_time_s\": 12.928670167922974}", "{\"n\": 12569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.96, \"learn_time_ms\": 10071.713, \"total_train_time_s\": 12.97944450378418}", "{\"n\": 12570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.28, \"learn_time_ms\": 10052.632, \"total_train_time_s\": 13.425448894500732}", "{\"n\": 12571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.28, \"learn_time_ms\": 9904.415, \"total_train_time_s\": 13.17447280883789}", "{\"n\": 12572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.18, \"learn_time_ms\": 9759.051, \"total_train_time_s\": 13.401357173919678}", "{\"n\": 12573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.47, \"learn_time_ms\": 9832.381, \"total_train_time_s\": 14.04307746887207}", "{\"n\": 12574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.43, \"learn_time_ms\": 9803.99, \"total_train_time_s\": 13.651668071746826}", "{\"n\": 12575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.43, \"learn_time_ms\": 9834.317, \"total_train_time_s\": 13.969000339508057}", "{\"n\": 12576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.78, \"learn_time_ms\": 9724.13, \"total_train_time_s\": 13.593107461929321}", "{\"n\": 12577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.86, \"learn_time_ms\": 9724.383, \"total_train_time_s\": 13.426538228988647}", "{\"n\": 12578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.51, \"learn_time_ms\": 9734.09, \"total_train_time_s\": 12.937153816223145}", "{\"n\": 12579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.08, \"learn_time_ms\": 9783.939, \"total_train_time_s\": 13.525083303451538}", "{\"n\": 12580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.08, \"learn_time_ms\": 9944.515, \"total_train_time_s\": 15.51839303970337}", "{\"n\": 12581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.97, \"learn_time_ms\": 9960.175, \"total_train_time_s\": 13.31444001197815}", "{\"n\": 12582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.91, \"learn_time_ms\": 10045.479, \"total_train_time_s\": 14.41461992263794}", "{\"n\": 12583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.57, \"learn_time_ms\": 9964.524, \"total_train_time_s\": 13.200114250183105}", "{\"n\": 12584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.14, \"learn_time_ms\": 9883.089, \"total_train_time_s\": 12.445937156677246}", "{\"n\": 12585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.19, \"learn_time_ms\": 9810.068, \"total_train_time_s\": 13.559991598129272}", "{\"n\": 12586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.19, \"learn_time_ms\": 9826.072, \"total_train_time_s\": 13.58812165260315}", "{\"n\": 12587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.2, \"learn_time_ms\": 9859.398, \"total_train_time_s\": 13.841864109039307}", "{\"n\": 12588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.2, \"learn_time_ms\": 9947.617, \"total_train_time_s\": 14.137666702270508}", "{\"n\": 12589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.88, \"learn_time_ms\": 9875.056, \"total_train_time_s\": 12.922654390335083}", "{\"n\": 12590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.88, \"learn_time_ms\": 9685.189, \"total_train_time_s\": 13.534017562866211}", "{\"n\": 12591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.25, \"learn_time_ms\": 9672.839, \"total_train_time_s\": 13.180511474609375}", "{\"n\": 12592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.25, \"learn_time_ms\": 9739.951, \"total_train_time_s\": 14.689916849136353}", "{\"n\": 12593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.35, \"learn_time_ms\": 9764.004, \"total_train_time_s\": 13.487316846847534}", "{\"n\": 12594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.35, \"learn_time_ms\": 9909.747, \"total_train_time_s\": 13.953468561172485}", "{\"n\": 12595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.22, \"learn_time_ms\": 10030.227, \"total_train_time_s\": 14.452179908752441}", "{\"n\": 12596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.68, \"learn_time_ms\": 10053.487, \"total_train_time_s\": 13.684298753738403}", "{\"n\": 12597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.68, \"learn_time_ms\": 10007.832, \"total_train_time_s\": 13.394161462783813}", "{\"n\": 12598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.39, \"learn_time_ms\": 9942.113, \"total_train_time_s\": 13.336153745651245}", "{\"n\": 12599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.48, \"learn_time_ms\": 10037.478, \"total_train_time_s\": 13.823570966720581}", "{\"n\": 12600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.38, \"learn_time_ms\": 10172.926, \"total_train_time_s\": 14.46570086479187}", "{\"n\": 12601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.69, \"learn_time_ms\": 10238.174, \"total_train_time_s\": 13.64391016960144}", "{\"n\": 12602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.7, \"learn_time_ms\": 10234.842, \"total_train_time_s\": 14.774580478668213}", "{\"n\": 12603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.41, \"learn_time_ms\": 10163.513, \"total_train_time_s\": 12.613283157348633}", "{\"n\": 12604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.49, \"learn_time_ms\": 10119.871, \"total_train_time_s\": 13.401192665100098}", "{\"n\": 12605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.72, \"learn_time_ms\": 9946.03, \"total_train_time_s\": 12.68707013130188}", "{\"n\": 12606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.25, \"learn_time_ms\": 9983.092, \"total_train_time_s\": 14.09444546699524}", "{\"n\": 12607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.25, \"learn_time_ms\": 10004.219, \"total_train_time_s\": 13.445067882537842}", "{\"n\": 12608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.86, \"learn_time_ms\": 9996.285, \"total_train_time_s\": 13.151128768920898}", "{\"n\": 12609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.76, \"learn_time_ms\": 9944.708, \"total_train_time_s\": 13.35119342803955}", "{\"n\": 12610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.62, \"learn_time_ms\": 9746.686, \"total_train_time_s\": 12.476394653320312}", "{\"n\": 12611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.07, \"learn_time_ms\": 9709.585, \"total_train_time_s\": 13.727271556854248}", "{\"n\": 12612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.85, \"learn_time_ms\": 9543.459, \"total_train_time_s\": 13.29152774810791}", "{\"n\": 12613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.57, \"learn_time_ms\": 9592.07, \"total_train_time_s\": 13.574479341506958}", "{\"n\": 12614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.15, \"learn_time_ms\": 9548.515, \"total_train_time_s\": 12.9832603931427}", "{\"n\": 12615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.15, \"learn_time_ms\": 9593.555, \"total_train_time_s\": 13.387511014938354}", "{\"n\": 12616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.04, \"learn_time_ms\": 9577.063, \"total_train_time_s\": 14.046437740325928}", "{\"n\": 12617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.59, \"learn_time_ms\": 9638.289, \"total_train_time_s\": 14.223819732666016}", "{\"n\": 12618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.16, \"learn_time_ms\": 9621.059, \"total_train_time_s\": 12.978203296661377}", "{\"n\": 12619, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.71, \"learn_time_ms\": 9721.261, \"total_train_time_s\": 14.489976406097412}", "{\"n\": 12620, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.58, \"learn_time_ms\": 9837.718, \"total_train_time_s\": 13.669786214828491}", "{\"n\": 12621, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.63, \"learn_time_ms\": 9805.901, \"total_train_time_s\": 12.99980354309082}", "{\"n\": 12622, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.63, \"learn_time_ms\": 9842.458, \"total_train_time_s\": 13.507043361663818}", "{\"n\": 12623, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.11, \"learn_time_ms\": 9857.802, \"total_train_time_s\": 13.259113311767578}", "{\"n\": 12624, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.67, \"learn_time_ms\": 9961.832, \"total_train_time_s\": 14.166310787200928}", "{\"n\": 12625, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.67, \"learn_time_ms\": 9950.011, \"total_train_time_s\": 13.111716032028198}", "{\"n\": 12626, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.67, \"learn_time_ms\": 9869.782, \"total_train_time_s\": 13.283553123474121}", "{\"n\": 12627, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.99, \"learn_time_ms\": 9775.229, \"total_train_time_s\": 13.32118034362793}", "{\"n\": 12628, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.06, \"learn_time_ms\": 9806.56, \"total_train_time_s\": 13.518161058425903}", "{\"n\": 12629, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.06, \"learn_time_ms\": 9679.79, \"total_train_time_s\": 13.030928134918213}", "{\"n\": 12630, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.92, \"learn_time_ms\": 9675.408, \"total_train_time_s\": 13.61875581741333}", "{\"n\": 12631, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.59, \"learn_time_ms\": 9758.167, \"total_train_time_s\": 13.96092176437378}", "{\"n\": 12632, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.59, \"learn_time_ms\": 9740.266, \"total_train_time_s\": 13.357887029647827}", "{\"n\": 12633, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.59, \"learn_time_ms\": 9773.09, \"total_train_time_s\": 13.726229429244995}", "{\"n\": 12634, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.67, \"learn_time_ms\": 9741.19, \"total_train_time_s\": 13.826937437057495}", "{\"n\": 12635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.25, \"learn_time_ms\": 9729.507, \"total_train_time_s\": 12.986368894577026}", "{\"n\": 12636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.25, \"learn_time_ms\": 9727.355, \"total_train_time_s\": 13.325489521026611}", "{\"n\": 12637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.25, \"learn_time_ms\": 9712.385, \"total_train_time_s\": 13.031861066818237}", "{\"n\": 12638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 9683.993, \"total_train_time_s\": 12.949815034866333}", "{\"n\": 12639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 9702.491, \"total_train_time_s\": 13.129173755645752}", "{\"n\": 12640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 9685.977, \"total_train_time_s\": 13.518362522125244}", "{\"n\": 12641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 9707.85, \"total_train_time_s\": 14.504914045333862}", "{\"n\": 12642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.84, \"learn_time_ms\": 9788.338, \"total_train_time_s\": 14.038251638412476}", "{\"n\": 12643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.84, \"learn_time_ms\": 9778.356, \"total_train_time_s\": 13.40093994140625}", "{\"n\": 12644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.84, \"learn_time_ms\": 9721.691, \"total_train_time_s\": 13.261091947555542}", "{\"n\": 12645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.13, \"learn_time_ms\": 9877.722, \"total_train_time_s\": 14.451948404312134}", "{\"n\": 12646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9881.178, \"total_train_time_s\": 13.142043828964233}", "{\"n\": 12647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9944.877, \"total_train_time_s\": 13.598551988601685}", "{\"n\": 12648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9947.11, \"total_train_time_s\": 13.403567790985107}", "{\"n\": 12649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.81, \"learn_time_ms\": 10010.37, \"total_train_time_s\": 13.861555337905884}", "{\"n\": 12650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.92, \"learn_time_ms\": 10061.188, \"total_train_time_s\": 14.002821683883667}", "{\"n\": 12651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.92, \"learn_time_ms\": 9955.123, \"total_train_time_s\": 13.262593746185303}", "{\"n\": 12652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.53, \"learn_time_ms\": 9942.89, \"total_train_time_s\": 14.262072086334229}", "{\"n\": 12653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.46, \"learn_time_ms\": 9916.068, \"total_train_time_s\": 13.381873369216919}", "{\"n\": 12654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.46, \"learn_time_ms\": 9904.1, \"total_train_time_s\": 13.292378425598145}", "{\"n\": 12655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 9855.536, \"total_train_time_s\": 14.12636137008667}", "{\"n\": 12656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 9841.673, \"total_train_time_s\": 13.264183759689331}", "{\"n\": 12657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.52, \"learn_time_ms\": 9887.303, \"total_train_time_s\": 14.013171434402466}", "{\"n\": 12658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.52, \"learn_time_ms\": 9980.676, \"total_train_time_s\": 13.997572183609009}", "{\"n\": 12659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 9981.84, \"total_train_time_s\": 13.784997940063477}", "{\"n\": 12660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9931.207, \"total_train_time_s\": 13.508647918701172}", "{\"n\": 12661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9982.801, \"total_train_time_s\": 13.809418678283691}", "{\"n\": 12662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9914.25, \"total_train_time_s\": 13.170007944107056}", "{\"n\": 12663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.29, \"learn_time_ms\": 9926.46, \"total_train_time_s\": 13.432523727416992}", "{\"n\": 12664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.47, \"learn_time_ms\": 10078.375, \"total_train_time_s\": 14.689193964004517}", "{\"n\": 12665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.47, \"learn_time_ms\": 10033.537, \"total_train_time_s\": 13.53563928604126}", "{\"n\": 12666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.47, \"learn_time_ms\": 10040.913, \"total_train_time_s\": 13.191569089889526}", "{\"n\": 12667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.9, \"learn_time_ms\": 10029.604, \"total_train_time_s\": 13.89597463607788}", "{\"n\": 12668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.05, \"learn_time_ms\": 9994.721, \"total_train_time_s\": 13.603041887283325}", "{\"n\": 12669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.05, \"learn_time_ms\": 10031.08, \"total_train_time_s\": 14.382209777832031}", "{\"n\": 12670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.18, \"learn_time_ms\": 10048.824, \"total_train_time_s\": 14.017694234848022}", "{\"n\": 12671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.8, \"learn_time_ms\": 10046.365, \"total_train_time_s\": 13.65529990196228}", "{\"n\": 12672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.8, \"learn_time_ms\": 10088.948, \"total_train_time_s\": 13.62335753440857}", "{\"n\": 12673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.21, \"learn_time_ms\": 10104.044, \"total_train_time_s\": 13.864324808120728}", "{\"n\": 12674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.52, \"learn_time_ms\": 9987.9, \"total_train_time_s\": 13.351523399353027}", "{\"n\": 12675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.52, \"learn_time_ms\": 9965.394, \"total_train_time_s\": 13.298356056213379}", "{\"n\": 12676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.19, \"learn_time_ms\": 10040.576, \"total_train_time_s\": 13.94386076927185}", "{\"n\": 12677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.19, \"learn_time_ms\": 9966.57, \"total_train_time_s\": 13.159604787826538}", "{\"n\": 12678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.9, \"learn_time_ms\": 9932.039, \"total_train_time_s\": 13.392390251159668}", "{\"n\": 12679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.9, \"learn_time_ms\": 9757.613, \"total_train_time_s\": 12.757836818695068}", "{\"n\": 12680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3589.32, \"learn_time_ms\": 9745.304, \"total_train_time_s\": 13.666254997253418}", "{\"n\": 12681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.19, \"learn_time_ms\": 9716.314, \"total_train_time_s\": 13.337199687957764}", "{\"n\": 12682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.19, \"learn_time_ms\": 9735.575, \"total_train_time_s\": 13.861260175704956}", "{\"n\": 12683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.19, \"learn_time_ms\": 9797.581, \"total_train_time_s\": 14.418018102645874}", "{\"n\": 12684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.41, \"learn_time_ms\": 9784.767, \"total_train_time_s\": 13.26261305809021}", "{\"n\": 12685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3579.61, \"learn_time_ms\": 9754.98, \"total_train_time_s\": 13.104634046554565}", "{\"n\": 12686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3579.61, \"learn_time_ms\": 9764.42, \"total_train_time_s\": 14.126587629318237}", "{\"n\": 12687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.75, \"learn_time_ms\": 9878.286, \"total_train_time_s\": 14.484739780426025}", "{\"n\": 12688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 9879.037, \"total_train_time_s\": 13.346299409866333}", "{\"n\": 12689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.39, \"learn_time_ms\": 10013.619, \"total_train_time_s\": 13.849771738052368}", "{\"n\": 12690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.39, \"learn_time_ms\": 9958.384, \"total_train_time_s\": 13.397374391555786}", "{\"n\": 12691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3582.33, \"learn_time_ms\": 9991.009, \"total_train_time_s\": 13.5715811252594}", "{\"n\": 12692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.83, \"learn_time_ms\": 9934.61, \"total_train_time_s\": 13.2192862033844}", "{\"n\": 12693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.83, \"learn_time_ms\": 9943.058, \"total_train_time_s\": 14.219316959381104}", "{\"n\": 12694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.96, \"learn_time_ms\": 9942.799, \"total_train_time_s\": 13.386609315872192}", "{\"n\": 12695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.14, \"learn_time_ms\": 9979.127, \"total_train_time_s\": 13.576079845428467}", "{\"n\": 12696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.58, \"learn_time_ms\": 10034.977, \"total_train_time_s\": 14.60331106185913}", "{\"n\": 12697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3574.83, \"learn_time_ms\": 9994.334, \"total_train_time_s\": 14.093837976455688}", "{\"n\": 12698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.05, \"learn_time_ms\": 9921.0, \"total_train_time_s\": 12.66852855682373}", "{\"n\": 12699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3577.78, \"learn_time_ms\": 9808.24, \"total_train_time_s\": 12.554040431976318}", "{\"n\": 12700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3577.78, \"learn_time_ms\": 9803.946, \"total_train_time_s\": 13.083719253540039}", "{\"n\": 12701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3571.64, \"learn_time_ms\": 9855.752, \"total_train_time_s\": 14.168580293655396}", "{\"n\": 12702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3578.92, \"learn_time_ms\": 9902.427, \"total_train_time_s\": 13.877151727676392}", "{\"n\": 12703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.87, \"learn_time_ms\": 9825.456, \"total_train_time_s\": 13.470988035202026}", "{\"n\": 12704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.04, \"learn_time_ms\": 9865.59, \"total_train_time_s\": 14.017930269241333}", "{\"n\": 12705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.85, \"learn_time_ms\": 9839.797, \"total_train_time_s\": 13.152695417404175}", "{\"n\": 12706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.9, \"learn_time_ms\": 9775.679, \"total_train_time_s\": 13.98843502998352}", "{\"n\": 12707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.9, \"learn_time_ms\": 9796.446, \"total_train_time_s\": 14.387746334075928}", "{\"n\": 12708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.79, \"learn_time_ms\": 9919.858, \"total_train_time_s\": 13.952911615371704}", "{\"n\": 12709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.95, \"learn_time_ms\": 9977.428, \"total_train_time_s\": 13.312155485153198}", "{\"n\": 12710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 10021.134, \"total_train_time_s\": 13.307361364364624}", "{\"n\": 12711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3574.94, \"learn_time_ms\": 10076.597, \"total_train_time_s\": 14.903366327285767}", "{\"n\": 12712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3574.94, \"learn_time_ms\": 10084.501, \"total_train_time_s\": 14.36996340751648}", "{\"n\": 12713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.2, \"learn_time_ms\": 9985.771, \"total_train_time_s\": 12.401364088058472}", "{\"n\": 12714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.63, \"learn_time_ms\": 9987.865, \"total_train_time_s\": 13.627220630645752}", "{\"n\": 12715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3587.74, \"learn_time_ms\": 9914.866, \"total_train_time_s\": 12.46426010131836}", "{\"n\": 12716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.78, \"learn_time_ms\": 9801.85, \"total_train_time_s\": 12.691753625869751}", "{\"n\": 12717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.15, \"learn_time_ms\": 9719.583, \"total_train_time_s\": 13.475243091583252}", "{\"n\": 12718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.15, \"learn_time_ms\": 9695.261, \"total_train_time_s\": 13.63523817062378}", "{\"n\": 12719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.62, \"learn_time_ms\": 9806.342, \"total_train_time_s\": 14.273786544799805}", "{\"n\": 12720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.32, \"learn_time_ms\": 9876.829, \"total_train_time_s\": 14.191359043121338}", "{\"n\": 12721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.39, \"learn_time_ms\": 9889.578, \"total_train_time_s\": 15.098793745040894}", "{\"n\": 12722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.08, \"learn_time_ms\": 9790.489, \"total_train_time_s\": 13.215972423553467}", "{\"n\": 12723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3550.24, \"learn_time_ms\": 9856.372, \"total_train_time_s\": 13.174569129943848}", "{\"n\": 12724, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3561.11, \"learn_time_ms\": 9738.145, \"total_train_time_s\": 12.589917421340942}", "{\"n\": 12725, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3556.98, \"learn_time_ms\": 9857.207, \"total_train_time_s\": 13.779194593429565}", "{\"n\": 12726, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.41, \"learn_time_ms\": 10002.863, \"total_train_time_s\": 14.087496280670166}", "{\"n\": 12727, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3535.98, \"learn_time_ms\": 9989.769, \"total_train_time_s\": 13.209070444107056}", "{\"n\": 12728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3519.54, \"learn_time_ms\": 9944.042, \"total_train_time_s\": 13.002765417098999}", "{\"n\": 12729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.49, \"learn_time_ms\": 9812.22, \"total_train_time_s\": 13.092162132263184}", "{\"n\": 12730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.49, \"learn_time_ms\": 9839.03, \"total_train_time_s\": 14.366492986679077}", "{\"n\": 12731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.68, \"learn_time_ms\": 9661.153, \"total_train_time_s\": 13.192666292190552}", "{\"n\": 12732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3515.7, \"learn_time_ms\": 9723.627, \"total_train_time_s\": 13.737244844436646}", "{\"n\": 12733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.06, \"learn_time_ms\": 9726.542, \"total_train_time_s\": 13.224119663238525}", "{\"n\": 12734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3512.19, \"learn_time_ms\": 9835.517, \"total_train_time_s\": 13.830211639404297}", "{\"n\": 12735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.15, \"learn_time_ms\": 9887.899, \"total_train_time_s\": 14.174010276794434}", "{\"n\": 12736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.08, \"learn_time_ms\": 9766.287, \"total_train_time_s\": 12.936392545700073}", "{\"n\": 12737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.08, \"learn_time_ms\": 9828.756, \"total_train_time_s\": 13.7920560836792}", "{\"n\": 12738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.21, \"learn_time_ms\": 9883.21, \"total_train_time_s\": 13.540421962738037}", "{\"n\": 12739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3487.3, \"learn_time_ms\": 9907.691, \"total_train_time_s\": 13.126142501831055}", "{\"n\": 12740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3487.3, \"learn_time_ms\": 9823.632, \"total_train_time_s\": 13.944549560546875}", "{\"n\": 12741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3486.48, \"learn_time_ms\": 9961.393, \"total_train_time_s\": 14.680055618286133}", "{\"n\": 12742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.55, \"learn_time_ms\": 9999.07, \"total_train_time_s\": 13.997296333312988}", "{\"n\": 12743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.07, \"learn_time_ms\": 10151.095, \"total_train_time_s\": 14.685781002044678}", "{\"n\": 12744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.07, \"learn_time_ms\": 10183.276, \"total_train_time_s\": 14.071407556533813}", "{\"n\": 12745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.12, \"learn_time_ms\": 10168.902, \"total_train_time_s\": 14.160375118255615}", "{\"n\": 12746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3498.37, \"learn_time_ms\": 10203.269, \"total_train_time_s\": 13.264447450637817}", "{\"n\": 12747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.59, \"learn_time_ms\": 10256.388, \"total_train_time_s\": 14.243977069854736}", "{\"n\": 12748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.67, \"learn_time_ms\": 10237.705, \"total_train_time_s\": 13.518310785293579}", "{\"n\": 12749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.12, \"learn_time_ms\": 10180.249, \"total_train_time_s\": 12.77689814567566}", "{\"n\": 12750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.12, \"learn_time_ms\": 10157.373, \"total_train_time_s\": 13.516553401947021}", "{\"n\": 12751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.12, \"learn_time_ms\": 10151.638, \"total_train_time_s\": 14.333816051483154}", "{\"n\": 12752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.12, \"learn_time_ms\": 10076.653, \"total_train_time_s\": 13.27783751487732}", "{\"n\": 12753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.79, \"learn_time_ms\": 9942.371, \"total_train_time_s\": 13.468877077102661}", "{\"n\": 12754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.79, \"learn_time_ms\": 9858.991, \"total_train_time_s\": 13.009016990661621}", "{\"n\": 12755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.43, \"learn_time_ms\": 9932.132, \"total_train_time_s\": 14.7255277633667}", "{\"n\": 12756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3501.94, \"learn_time_ms\": 9877.859, \"total_train_time_s\": 12.924331665039062}", "{\"n\": 12757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3493.75, \"learn_time_ms\": 9787.779, \"total_train_time_s\": 13.64745831489563}", "{\"n\": 12758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.08, \"learn_time_ms\": 9780.388, \"total_train_time_s\": 13.290529012680054}", "{\"n\": 12759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3497.08, \"learn_time_ms\": 9795.889, \"total_train_time_s\": 12.895639896392822}", "{\"n\": 12760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.78, \"learn_time_ms\": 9705.875, \"total_train_time_s\": 12.499751091003418}", "{\"n\": 12761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.98, \"learn_time_ms\": 9639.869, \"total_train_time_s\": 13.841972827911377}", "{\"n\": 12762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.98, \"learn_time_ms\": 9609.241, \"total_train_time_s\": 12.773783206939697}", "{\"n\": 12763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.98, \"learn_time_ms\": 9608.098, \"total_train_time_s\": 13.310630083084106}", "{\"n\": 12764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3511.34, \"learn_time_ms\": 9647.084, \"total_train_time_s\": 13.401750564575195}", "{\"n\": 12765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.81, \"learn_time_ms\": 9500.05, \"total_train_time_s\": 13.251483678817749}", "{\"n\": 12766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.81, \"learn_time_ms\": 9584.346, \"total_train_time_s\": 13.7744140625}", "{\"n\": 12767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.81, \"learn_time_ms\": 9575.113, \"total_train_time_s\": 13.279486656188965}", "{\"n\": 12768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.57, \"learn_time_ms\": 9657.767, \"total_train_time_s\": 14.249629735946655}", "{\"n\": 12769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.57, \"learn_time_ms\": 9721.743, \"total_train_time_s\": 13.363834857940674}", "{\"n\": 12770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.57, \"learn_time_ms\": 9814.463, \"total_train_time_s\": 13.529142618179321}", "{\"n\": 12771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.71, \"learn_time_ms\": 9763.371, \"total_train_time_s\": 13.134621381759644}", "{\"n\": 12772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 9862.365, \"total_train_time_s\": 13.831049919128418}", "{\"n\": 12773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 9898.961, \"total_train_time_s\": 13.61479377746582}", "{\"n\": 12774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 9894.535, \"total_train_time_s\": 13.533242464065552}", "{\"n\": 12775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.1, \"learn_time_ms\": 9861.11, \"total_train_time_s\": 13.242350339889526}", "{\"n\": 12776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.74, \"learn_time_ms\": 9914.214, \"total_train_time_s\": 14.138982057571411}", "{\"n\": 12777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.74, \"learn_time_ms\": 9934.979, \"total_train_time_s\": 13.519200563430786}", "{\"n\": 12778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.74, \"learn_time_ms\": 9785.803, \"total_train_time_s\": 12.705249071121216}", "{\"n\": 12779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.34, \"learn_time_ms\": 9845.054, \"total_train_time_s\": 14.060947895050049}", "{\"n\": 12780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.34, \"learn_time_ms\": 9811.007, \"total_train_time_s\": 13.160029649734497}", "{\"n\": 12781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.34, \"learn_time_ms\": 9845.759, \"total_train_time_s\": 13.38402509689331}", "{\"n\": 12782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.18, \"learn_time_ms\": 9770.685, \"total_train_time_s\": 13.219414234161377}", "{\"n\": 12783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.84, \"learn_time_ms\": 9898.866, \"total_train_time_s\": 15.063279867172241}", "{\"n\": 12784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.84, \"learn_time_ms\": 9894.767, \"total_train_time_s\": 13.330031156539917}", "{\"n\": 12785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.84, \"learn_time_ms\": 9952.15, \"total_train_time_s\": 13.459276676177979}", "{\"n\": 12786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.9, \"learn_time_ms\": 9886.009, \"total_train_time_s\": 13.462849617004395}", "{\"n\": 12787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.14, \"learn_time_ms\": 9822.899, \"total_train_time_s\": 13.070751428604126}", "{\"n\": 12788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.14, \"learn_time_ms\": 9909.49, \"total_train_time_s\": 13.656943321228027}", "{\"n\": 12789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.5, \"learn_time_ms\": 9825.64, \"total_train_time_s\": 13.24232006072998}", "{\"n\": 12790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.7, \"learn_time_ms\": 9846.159, \"total_train_time_s\": 13.483474493026733}", "{\"n\": 12791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.48, \"learn_time_ms\": 9835.644, \"total_train_time_s\": 13.410655975341797}", "{\"n\": 12792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.48, \"learn_time_ms\": 9855.18, \"total_train_time_s\": 13.181034326553345}", "{\"n\": 12793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.86, \"learn_time_ms\": 9701.485, \"total_train_time_s\": 13.604262590408325}", "{\"n\": 12794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.49, \"learn_time_ms\": 9726.075, \"total_train_time_s\": 13.598421096801758}", "{\"n\": 12795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.49, \"learn_time_ms\": 9742.22, \"total_train_time_s\": 13.782505512237549}", "{\"n\": 12796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.49, \"learn_time_ms\": 9744.934, \"total_train_time_s\": 13.504567623138428}", "{\"n\": 12797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.56, \"learn_time_ms\": 9720.678, \"total_train_time_s\": 12.59707498550415}", "{\"n\": 12798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.03, \"learn_time_ms\": 9624.538, \"total_train_time_s\": 12.683861017227173}", "{\"n\": 12799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.03, \"learn_time_ms\": 9671.078, \"total_train_time_s\": 13.686832666397095}", "{\"n\": 12800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.03, \"learn_time_ms\": 9644.735, \"total_train_time_s\": 13.01242971420288}", "{\"n\": 12801, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.57, \"learn_time_ms\": 9685.506, \"total_train_time_s\": 13.884388446807861}", "{\"n\": 12802, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.57, \"learn_time_ms\": 9716.923, \"total_train_time_s\": 13.594638347625732}", "{\"n\": 12803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.57, \"learn_time_ms\": 9826.327, \"total_train_time_s\": 14.436047315597534}", "{\"n\": 12804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.77, \"learn_time_ms\": 9760.148, \"total_train_time_s\": 13.074976682662964}", "{\"n\": 12805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.41, \"learn_time_ms\": 9819.976, \"total_train_time_s\": 14.353098630905151}", "{\"n\": 12806, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.41, \"learn_time_ms\": 9773.845, \"total_train_time_s\": 13.110276460647583}", "{\"n\": 12807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.41, \"learn_time_ms\": 9942.201, \"total_train_time_s\": 14.329127311706543}", "{\"n\": 12808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.3, \"learn_time_ms\": 9991.868, \"total_train_time_s\": 13.167822122573853}", "{\"n\": 12809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.3, \"learn_time_ms\": 10000.137, \"total_train_time_s\": 13.612367630004883}", "{\"n\": 12810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.3, \"learn_time_ms\": 10164.662, \"total_train_time_s\": 14.555116176605225}", "{\"n\": 12811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.3, \"learn_time_ms\": 10233.527, \"total_train_time_s\": 14.403861999511719}", "{\"n\": 12812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.68, \"learn_time_ms\": 10142.483, \"total_train_time_s\": 12.613683938980103}", "{\"n\": 12813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.68, \"learn_time_ms\": 10020.32, \"total_train_time_s\": 13.664246320724487}", "{\"n\": 12814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.68, \"learn_time_ms\": 10069.279, \"total_train_time_s\": 13.734910488128662}", "{\"n\": 12815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.73, \"learn_time_ms\": 9964.053, \"total_train_time_s\": 13.154582738876343}", "{\"n\": 12816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.65, \"learn_time_ms\": 9983.417, \"total_train_time_s\": 13.402629137039185}", "{\"n\": 12817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.65, \"learn_time_ms\": 9890.06, \"total_train_time_s\": 13.439969062805176}", "{\"n\": 12818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.47, \"learn_time_ms\": 10092.595, \"total_train_time_s\": 15.083002805709839}", "{\"n\": 12819, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.11, \"learn_time_ms\": 10021.763, \"total_train_time_s\": 12.991215705871582}", "{\"n\": 12820, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 9918.597, \"total_train_time_s\": 13.506934881210327}", "{\"n\": 12821, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 9744.445, \"total_train_time_s\": 12.755890369415283}", "{\"n\": 12822, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.59, \"learn_time_ms\": 9887.289, \"total_train_time_s\": 13.993937969207764}", "{\"n\": 12823, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.02, \"learn_time_ms\": 9937.35, \"total_train_time_s\": 13.815646171569824}", "{\"n\": 12824, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.26, \"learn_time_ms\": 9883.524, \"total_train_time_s\": 12.969078063964844}", "{\"n\": 12825, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.26, \"learn_time_ms\": 9926.616, \"total_train_time_s\": 13.701890707015991}", "{\"n\": 12826, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.53, \"learn_time_ms\": 9970.046, \"total_train_time_s\": 13.605590343475342}", "{\"n\": 12827, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.19, \"learn_time_ms\": 9982.362, \"total_train_time_s\": 13.825723648071289}", "{\"n\": 12828, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.19, \"learn_time_ms\": 9791.193, \"total_train_time_s\": 13.375051736831665}", "{\"n\": 12829, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.2, \"learn_time_ms\": 9891.672, \"total_train_time_s\": 13.909083127975464}", "{\"n\": 12830, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.66, \"learn_time_ms\": 9854.621, \"total_train_time_s\": 13.05345869064331}", "{\"n\": 12831, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.82, \"learn_time_ms\": 10013.321, \"total_train_time_s\": 14.228804111480713}", "{\"n\": 12832, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.26, \"learn_time_ms\": 9874.329, \"total_train_time_s\": 12.742169857025146}", "{\"n\": 12833, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.26, \"learn_time_ms\": 9867.657, \"total_train_time_s\": 13.640240907669067}", "{\"n\": 12834, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.7, \"learn_time_ms\": 9918.043, \"total_train_time_s\": 13.510717868804932}", "{\"n\": 12835, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.22, \"learn_time_ms\": 9879.397, \"total_train_time_s\": 13.37723970413208}", "{\"n\": 12836, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.08, \"learn_time_ms\": 10014.439, \"total_train_time_s\": 14.977807760238647}", "{\"n\": 12837, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.08, \"learn_time_ms\": 10027.026, \"total_train_time_s\": 13.669574737548828}", "{\"n\": 12838, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.87, \"learn_time_ms\": 10098.748, \"total_train_time_s\": 14.027063608169556}", "{\"n\": 12839, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.64, \"learn_time_ms\": 10085.221, \"total_train_time_s\": 13.808114290237427}", "{\"n\": 12840, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.35, \"learn_time_ms\": 10187.256, \"total_train_time_s\": 14.229371309280396}", "{\"n\": 12841, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.35, \"learn_time_ms\": 10063.29, \"total_train_time_s\": 13.248264789581299}", "{\"n\": 12842, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.37, \"learn_time_ms\": 10144.769, \"total_train_time_s\": 13.468512773513794}", "{\"n\": 12843, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.31, \"learn_time_ms\": 10132.692, \"total_train_time_s\": 13.601034879684448}", "{\"n\": 12844, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 10127.634, \"total_train_time_s\": 13.769500017166138}", "{\"n\": 12845, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 10150.634, \"total_train_time_s\": 13.907684087753296}", "{\"n\": 12846, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.59, \"learn_time_ms\": 9987.5, \"total_train_time_s\": 13.38327932357788}", "{\"n\": 12847, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 9965.511, \"total_train_time_s\": 13.418304681777954}", "{\"n\": 12848, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 9983.567, \"total_train_time_s\": 14.414863586425781}", "{\"n\": 12849, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.77, \"learn_time_ms\": 10031.935, \"total_train_time_s\": 14.351823091506958}", "{\"n\": 12850, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.3, \"learn_time_ms\": 9931.743, \"total_train_time_s\": 13.146750926971436}", "{\"n\": 12851, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.3, \"learn_time_ms\": 9905.813, \"total_train_time_s\": 13.067001104354858}", "{\"n\": 12852, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.3, \"learn_time_ms\": 9813.98, \"total_train_time_s\": 12.587809085845947}", "{\"n\": 12853, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.33, \"learn_time_ms\": 9739.13, \"total_train_time_s\": 13.012428522109985}", "{\"n\": 12854, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.33, \"learn_time_ms\": 9707.882, \"total_train_time_s\": 13.139880180358887}", "{\"n\": 12855, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.33, \"learn_time_ms\": 9715.552, \"total_train_time_s\": 13.766825437545776}", "{\"n\": 12856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9712.014, \"total_train_time_s\": 13.310807704925537}", "{\"n\": 12857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9749.306, \"total_train_time_s\": 13.980501413345337}", "{\"n\": 12858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 9667.936, \"total_train_time_s\": 13.672242164611816}", "{\"n\": 12859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.02, \"learn_time_ms\": 9510.44, \"total_train_time_s\": 12.851695775985718}", "{\"n\": 12860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.05, \"learn_time_ms\": 9541.147, \"total_train_time_s\": 13.384452819824219}", "{\"n\": 12861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.05, \"learn_time_ms\": 9554.354, \"total_train_time_s\": 13.277015447616577}", "{\"n\": 12862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.91, \"learn_time_ms\": 9607.868, \"total_train_time_s\": 13.138975381851196}", "{\"n\": 12863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.65, \"learn_time_ms\": 9659.133, \"total_train_time_s\": 13.364500284194946}", "{\"n\": 12864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.65, \"learn_time_ms\": 9792.745, \"total_train_time_s\": 14.893198013305664}", "{\"n\": 12865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.61, \"learn_time_ms\": 9710.169, \"total_train_time_s\": 12.999126195907593}", "{\"n\": 12866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.44, \"learn_time_ms\": 9624.765, \"total_train_time_s\": 12.553719997406006}", "{\"n\": 12867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.44, \"learn_time_ms\": 9584.441, \"total_train_time_s\": 13.424104928970337}", "{\"n\": 12868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.1, \"learn_time_ms\": 9592.211, \"total_train_time_s\": 13.613725662231445}", "{\"n\": 12869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.37, \"learn_time_ms\": 9641.984, \"total_train_time_s\": 13.275773763656616}", "{\"n\": 12870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.48, \"learn_time_ms\": 9640.493, \"total_train_time_s\": 13.630245447158813}", "{\"n\": 12871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.05, \"learn_time_ms\": 9718.709, \"total_train_time_s\": 13.790127754211426}", "{\"n\": 12872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.05, \"learn_time_ms\": 9742.754, \"total_train_time_s\": 13.308788061141968}", "{\"n\": 12873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.89, \"learn_time_ms\": 9761.493, \"total_train_time_s\": 13.684414386749268}", "{\"n\": 12874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.55, \"learn_time_ms\": 9573.019, \"total_train_time_s\": 12.655098676681519}", "{\"n\": 12875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.69, \"learn_time_ms\": 9618.625, \"total_train_time_s\": 13.391377925872803}", "{\"n\": 12876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.47, \"learn_time_ms\": 9779.058, \"total_train_time_s\": 14.391612768173218}", "{\"n\": 12877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.08, \"learn_time_ms\": 9796.095, \"total_train_time_s\": 13.703246593475342}", "{\"n\": 12878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.9, \"learn_time_ms\": 9798.761, \"total_train_time_s\": 13.696667194366455}", "{\"n\": 12879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.9, \"learn_time_ms\": 9848.009, \"total_train_time_s\": 14.13215970993042}", "{\"n\": 12880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.62, \"learn_time_ms\": 9863.987, \"total_train_time_s\": 13.669681310653687}", "{\"n\": 12881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.06, \"learn_time_ms\": 9814.472, \"total_train_time_s\": 13.383793115615845}", "{\"n\": 12882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.06, \"learn_time_ms\": 9818.246, \"total_train_time_s\": 13.722525358200073}", "{\"n\": 12883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.06, \"learn_time_ms\": 9842.911, \"total_train_time_s\": 13.73513674736023}", "{\"n\": 12884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.4, \"learn_time_ms\": 9979.469, \"total_train_time_s\": 14.019832849502563}", "{\"n\": 12885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.44, \"learn_time_ms\": 10044.843, \"total_train_time_s\": 13.896336317062378}", "{\"n\": 12886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.44, \"learn_time_ms\": 10030.065, \"total_train_time_s\": 14.154437065124512}", "{\"n\": 12887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.3, \"learn_time_ms\": 9977.18, \"total_train_time_s\": 13.014505624771118}", "{\"n\": 12888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.82, \"learn_time_ms\": 9951.058, \"total_train_time_s\": 13.136833190917969}", "{\"n\": 12889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.2, \"learn_time_ms\": 9950.235, \"total_train_time_s\": 13.904850244522095}", "{\"n\": 12890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.22, \"learn_time_ms\": 9930.826, \"total_train_time_s\": 13.51640510559082}", "{\"n\": 12891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3528.46, \"learn_time_ms\": 9866.489, \"total_train_time_s\": 12.522525548934937}", "{\"n\": 12892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3528.46, \"learn_time_ms\": 9789.3, \"total_train_time_s\": 12.858745336532593}", "{\"n\": 12893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3523.67, \"learn_time_ms\": 9790.059, \"total_train_time_s\": 13.752717018127441}", "{\"n\": 12894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3516.13, \"learn_time_ms\": 9825.189, \"total_train_time_s\": 14.295625925064087}", "{\"n\": 12895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.54, \"learn_time_ms\": 9737.599, \"total_train_time_s\": 13.082789421081543}", "{\"n\": 12896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3526.2, \"learn_time_ms\": 9594.211, \"total_train_time_s\": 12.808769941329956}", "{\"n\": 12897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3513.17, \"learn_time_ms\": 9550.506, \"total_train_time_s\": 12.81643009185791}", "{\"n\": 12898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3506.13, \"learn_time_ms\": 9449.307, \"total_train_time_s\": 12.076443672180176}", "{\"n\": 12899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3495.53, \"learn_time_ms\": 9424.701, \"total_train_time_s\": 13.581839561462402}", "{\"n\": 12900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.73, \"learn_time_ms\": 9497.338, \"total_train_time_s\": 14.195430994033813}", "{\"n\": 12901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3502.01, \"learn_time_ms\": 9567.138, \"total_train_time_s\": 13.280670642852783}", "{\"n\": 12902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3495.37, \"learn_time_ms\": 9693.142, \"total_train_time_s\": 13.928663730621338}", "{\"n\": 12903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3495.37, \"learn_time_ms\": 9671.921, \"total_train_time_s\": 13.661981582641602}", "{\"n\": 12904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.23, \"learn_time_ms\": 9552.372, \"total_train_time_s\": 13.163633346557617}", "{\"n\": 12905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3491.94, \"learn_time_ms\": 9548.959, \"total_train_time_s\": 13.004155158996582}", "{\"n\": 12906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3488.84, \"learn_time_ms\": 9565.282, \"total_train_time_s\": 12.669225454330444}", "{\"n\": 12907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3488.84, \"learn_time_ms\": 9630.162, \"total_train_time_s\": 13.392572164535522}", "{\"n\": 12908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3495.63, \"learn_time_ms\": 9775.429, \"total_train_time_s\": 13.749478816986084}", "{\"n\": 12909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.3, \"learn_time_ms\": 9925.295, \"total_train_time_s\": 15.019164800643921}", "{\"n\": 12910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.3, \"learn_time_ms\": 9904.675, \"total_train_time_s\": 14.066738843917847}", "{\"n\": 12911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.95, \"learn_time_ms\": 9930.322, \"total_train_time_s\": 13.533393621444702}", "{\"n\": 12912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.87, \"learn_time_ms\": 9896.805, \"total_train_time_s\": 13.490188598632812}", "{\"n\": 12913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.87, \"learn_time_ms\": 9918.785, \"total_train_time_s\": 13.865103960037231}", "{\"n\": 12914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.87, \"learn_time_ms\": 9958.735, \"total_train_time_s\": 13.448513746261597}", "{\"n\": 12915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.87, \"learn_time_ms\": 9960.959, \"total_train_time_s\": 13.123340845108032}", "{\"n\": 12916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3473.86, \"learn_time_ms\": 10003.559, \"total_train_time_s\": 13.099353551864624}", "{\"n\": 12917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3473.86, \"learn_time_ms\": 10035.65, \"total_train_time_s\": 13.871460437774658}", "{\"n\": 12918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3468.71, \"learn_time_ms\": 9963.589, \"total_train_time_s\": 12.787761449813843}", "{\"n\": 12919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3477.02, \"learn_time_ms\": 9801.419, \"total_train_time_s\": 13.578947067260742}", "{\"n\": 12920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3480.92, \"learn_time_ms\": 9749.721, \"total_train_time_s\": 13.432323217391968}", "{\"n\": 12921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3480.92, \"learn_time_ms\": 9666.481, \"total_train_time_s\": 12.948119163513184}", "{\"n\": 12922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.87, \"learn_time_ms\": 9673.841, \"total_train_time_s\": 13.788054704666138}", "{\"n\": 12923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.31, \"learn_time_ms\": 9694.463, \"total_train_time_s\": 14.223442316055298}", "{\"n\": 12924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.31, \"learn_time_ms\": 9699.289, \"total_train_time_s\": 13.887204885482788}", "{\"n\": 12925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.31, \"learn_time_ms\": 9783.592, \"total_train_time_s\": 13.975059509277344}", "{\"n\": 12926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3463.44, \"learn_time_ms\": 9760.563, \"total_train_time_s\": 12.95111608505249}", "{\"n\": 12927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.73, \"learn_time_ms\": 9709.542, \"total_train_time_s\": 13.094119787216187}", "{\"n\": 12928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3464.32, \"learn_time_ms\": 9851.557, \"total_train_time_s\": 14.27332067489624}", "{\"n\": 12929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3464.32, \"learn_time_ms\": 9831.391, \"total_train_time_s\": 13.212061166763306}", "{\"n\": 12930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3474.98, \"learn_time_ms\": 9866.508, \"total_train_time_s\": 13.866073846817017}", "{\"n\": 12931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3478.36, \"learn_time_ms\": 9978.641, \"total_train_time_s\": 13.819400072097778}", "{\"n\": 12932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.59, \"learn_time_ms\": 9916.084, \"total_train_time_s\": 12.963107824325562}", "{\"n\": 12933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.68, \"learn_time_ms\": 9813.714, \"total_train_time_s\": 13.036418676376343}", "{\"n\": 12934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.61, \"learn_time_ms\": 9789.511, \"total_train_time_s\": 13.177807331085205}", "{\"n\": 12935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.87, \"learn_time_ms\": 9779.847, \"total_train_time_s\": 13.80886459350586}", "{\"n\": 12936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3480.34, \"learn_time_ms\": 9855.393, \"total_train_time_s\": 13.771792650222778}", "{\"n\": 12937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.67, \"learn_time_ms\": 9939.461, \"total_train_time_s\": 14.21154260635376}", "{\"n\": 12938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.67, \"learn_time_ms\": 9773.058, \"total_train_time_s\": 12.91471815109253}", "{\"n\": 12939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3476.71, \"learn_time_ms\": 9890.927, \"total_train_time_s\": 14.322033882141113}", "{\"n\": 12940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3473.59, \"learn_time_ms\": 9966.459, \"total_train_time_s\": 14.457236051559448}", "{\"n\": 12941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3471.27, \"learn_time_ms\": 10001.392, \"total_train_time_s\": 14.218397378921509}", "{\"n\": 12942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3471.27, \"learn_time_ms\": 10089.071, \"total_train_time_s\": 13.862717390060425}", "{\"n\": 12943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.86, \"learn_time_ms\": 10288.606, \"total_train_time_s\": 15.006006717681885}", "{\"n\": 12944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.86, \"learn_time_ms\": 10257.775, \"total_train_time_s\": 12.919569730758667}", "{\"n\": 12945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.6, \"learn_time_ms\": 10285.178, \"total_train_time_s\": 13.930914163589478}", "{\"n\": 12946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.8, \"learn_time_ms\": 10276.575, \"total_train_time_s\": 13.822763919830322}", "{\"n\": 12947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3512.8, \"learn_time_ms\": 10219.0, \"total_train_time_s\": 13.315268278121948}", "{\"n\": 12948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3510.66, \"learn_time_ms\": 10250.458, \"total_train_time_s\": 13.321635484695435}", "{\"n\": 12949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.4, \"learn_time_ms\": 10109.132, \"total_train_time_s\": 12.98572826385498}", "{\"n\": 12950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3519.87, \"learn_time_ms\": 9950.996, \"total_train_time_s\": 13.179680824279785}", "{\"n\": 12951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.69, \"learn_time_ms\": 9890.537, \"total_train_time_s\": 13.511515855789185}", "{\"n\": 12952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3525.83, \"learn_time_ms\": 9885.219, \"total_train_time_s\": 13.982019662857056}", "{\"n\": 12953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3525.83, \"learn_time_ms\": 9829.278, \"total_train_time_s\": 14.453182458877563}", "{\"n\": 12954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3530.02, \"learn_time_ms\": 9839.579, \"total_train_time_s\": 13.00689172744751}", "{\"n\": 12955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3530.02, \"learn_time_ms\": 9787.698, \"total_train_time_s\": 13.489429473876953}", "{\"n\": 12956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.36, \"learn_time_ms\": 9772.801, \"total_train_time_s\": 13.400983333587646}", "{\"n\": 12957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.36, \"learn_time_ms\": 9837.604, \"total_train_time_s\": 14.18929934501648}", "{\"n\": 12958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.25, \"learn_time_ms\": 9806.124, \"total_train_time_s\": 12.821711778640747}", "{\"n\": 12959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.25, \"learn_time_ms\": 9840.636, \"total_train_time_s\": 13.485970258712769}", "{\"n\": 12960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.77, \"learn_time_ms\": 9883.166, \"total_train_time_s\": 13.301888227462769}", "{\"n\": 12961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3541.96, \"learn_time_ms\": 9760.331, \"total_train_time_s\": 12.324676990509033}", "{\"n\": 12962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3547.03, \"learn_time_ms\": 9753.786, \"total_train_time_s\": 13.679565668106079}", "{\"n\": 12963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3555.31, \"learn_time_ms\": 9630.472, \"total_train_time_s\": 13.231247901916504}", "{\"n\": 12964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3555.31, \"learn_time_ms\": 9732.703, \"total_train_time_s\": 13.98431396484375}", "{\"n\": 12965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.77, \"learn_time_ms\": 9759.319, \"total_train_time_s\": 13.992151021957397}", "{\"n\": 12966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.77, \"learn_time_ms\": 9786.532, \"total_train_time_s\": 14.120680332183838}", "{\"n\": 12967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.16, \"learn_time_ms\": 9740.488, \"total_train_time_s\": 13.457816362380981}", "{\"n\": 12968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.59, \"learn_time_ms\": 9918.012, \"total_train_time_s\": 14.325140953063965}", "{\"n\": 12969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.59, \"learn_time_ms\": 10046.162, \"total_train_time_s\": 14.852399587631226}", "{\"n\": 12970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.82, \"learn_time_ms\": 10055.505, \"total_train_time_s\": 13.645678520202637}", "{\"n\": 12971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.62, \"learn_time_ms\": 10152.034, \"total_train_time_s\": 13.53568983078003}", "{\"n\": 12972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.67, \"learn_time_ms\": 10039.478, \"total_train_time_s\": 12.723607540130615}", "{\"n\": 12973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.67, \"learn_time_ms\": 10025.011, \"total_train_time_s\": 13.00736379623413}", "{\"n\": 12974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.45, \"learn_time_ms\": 9987.125, \"total_train_time_s\": 13.780038118362427}", "{\"n\": 12975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.45, \"learn_time_ms\": 9961.381, \"total_train_time_s\": 13.375001192092896}", "{\"n\": 12976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.52, \"learn_time_ms\": 9957.617, \"total_train_time_s\": 13.660205841064453}", "{\"n\": 12977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3529.4, \"learn_time_ms\": 10024.714, \"total_train_time_s\": 14.403937339782715}", "{\"n\": 12978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3530.81, \"learn_time_ms\": 9982.299, \"total_train_time_s\": 14.00330138206482}", "{\"n\": 12979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.47, \"learn_time_ms\": 9770.43, \"total_train_time_s\": 12.372638940811157}", "{\"n\": 12980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.06, \"learn_time_ms\": 9836.405, \"total_train_time_s\": 14.230591297149658}", "{\"n\": 12981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3551.17, \"learn_time_ms\": 9853.568, \"total_train_time_s\": 13.835982322692871}", "{\"n\": 12982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3551.17, \"learn_time_ms\": 10015.712, \"total_train_time_s\": 14.53479552268982}", "{\"n\": 12983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3555.81, \"learn_time_ms\": 10005.646, \"total_train_time_s\": 12.923441886901855}", "{\"n\": 12984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3552.18, \"learn_time_ms\": 9894.246, \"total_train_time_s\": 12.565406560897827}", "{\"n\": 12985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3552.18, \"learn_time_ms\": 9962.426, \"total_train_time_s\": 14.297268390655518}", "{\"n\": 12986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3552.18, \"learn_time_ms\": 9945.871, \"total_train_time_s\": 13.480688333511353}", "{\"n\": 12987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3558.92, \"learn_time_ms\": 9905.384, \"total_train_time_s\": 13.82778286933899}", "{\"n\": 12988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3557.79, \"learn_time_ms\": 9856.861, \"total_train_time_s\": 13.539666652679443}", "{\"n\": 12989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3557.79, \"learn_time_ms\": 9928.33, \"total_train_time_s\": 13.350277423858643}", "{\"n\": 12990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3564.24, \"learn_time_ms\": 9844.246, \"total_train_time_s\": 13.702045440673828}", "{\"n\": 12991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3561.18, \"learn_time_ms\": 9825.677, \"total_train_time_s\": 13.287893056869507}", "{\"n\": 12992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.54, \"learn_time_ms\": 9779.71, \"total_train_time_s\": 13.672711849212646}", "{\"n\": 12993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3570.43, \"learn_time_ms\": 9803.97, \"total_train_time_s\": 13.427005052566528}", "{\"n\": 12994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3561.82, \"learn_time_ms\": 9920.118, \"total_train_time_s\": 13.699126243591309}", "{\"n\": 12995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.06, \"learn_time_ms\": 9743.449, \"total_train_time_s\": 12.31503438949585}", "{\"n\": 12996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.06, \"learn_time_ms\": 9728.904, \"total_train_time_s\": 13.344744205474854}", "{\"n\": 12997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3566.53, \"learn_time_ms\": 9716.45, \"total_train_time_s\": 13.654572486877441}", "{\"n\": 12998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3558.34, \"learn_time_ms\": 9571.514, \"total_train_time_s\": 12.200292110443115}", "{\"n\": 12999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3560.91, \"learn_time_ms\": 9617.328, \"total_train_time_s\": 13.664828300476074}", "{\"n\": 13000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3560.91, \"learn_time_ms\": 9611.589, \"total_train_time_s\": 13.262558460235596}", "{\"n\": 13001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3563.24, \"learn_time_ms\": 9642.459, \"total_train_time_s\": 13.641982078552246}", "{\"n\": 13002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3575.35, \"learn_time_ms\": 9663.848, \"total_train_time_s\": 13.983839273452759}", "{\"n\": 13003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3575.36, \"learn_time_ms\": 9739.151, \"total_train_time_s\": 14.060466289520264}", "{\"n\": 13004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3575.36, \"learn_time_ms\": 9689.938, \"total_train_time_s\": 13.19182562828064}", "{\"n\": 13005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3581.19, \"learn_time_ms\": 9809.215, \"total_train_time_s\": 13.5772545337677}", "{\"n\": 13006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3584.87, \"learn_time_ms\": 9959.916, \"total_train_time_s\": 15.020368814468384}", "{\"n\": 13007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3584.87, \"learn_time_ms\": 9926.024, \"total_train_time_s\": 13.415299415588379}", "{\"n\": 13008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3583.69, \"learn_time_ms\": 10107.659, \"total_train_time_s\": 13.84715223312378}", "{\"n\": 13009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3587.66, \"learn_time_ms\": 10013.334, \"total_train_time_s\": 12.612951755523682}", "{\"n\": 13010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3587.66, \"learn_time_ms\": 10031.685, \"total_train_time_s\": 13.341928720474243}", "{\"n\": 13011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3587.66, \"learn_time_ms\": 9980.523, \"total_train_time_s\": 12.971725225448608}", "{\"n\": 13012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3580.02, \"learn_time_ms\": 9959.186, \"total_train_time_s\": 13.750821113586426}", "{\"n\": 13013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.2, \"learn_time_ms\": 9957.4, \"total_train_time_s\": 14.065577030181885}", "{\"n\": 13014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.2, \"learn_time_ms\": 9939.692, \"total_train_time_s\": 13.276770830154419}", "{\"n\": 13015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3571.93, \"learn_time_ms\": 9918.554, \"total_train_time_s\": 13.339623928070068}", "{\"n\": 13016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3569.34, \"learn_time_ms\": 9773.256, \"total_train_time_s\": 13.401249408721924}", "{\"n\": 13017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3570.69, \"learn_time_ms\": 9814.334, \"total_train_time_s\": 13.731277704238892}", "{\"n\": 13018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.06, \"learn_time_ms\": 9849.119, \"total_train_time_s\": 14.387762784957886}", "{\"n\": 13019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3554.18, \"learn_time_ms\": 9897.789, \"total_train_time_s\": 13.249922037124634}", "{\"n\": 13020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3567.46, \"learn_time_ms\": 9975.542, \"total_train_time_s\": 14.214269161224365}", "{\"n\": 13021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3564.31, \"learn_time_ms\": 9964.351, \"total_train_time_s\": 13.267940521240234}", "{\"n\": 13022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3560.8, \"learn_time_ms\": 10066.389, \"total_train_time_s\": 14.83005690574646}", "{\"n\": 13023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3557.73, \"learn_time_ms\": 9979.028, \"total_train_time_s\": 13.136137962341309}", "{\"n\": 13024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3549.67, \"learn_time_ms\": 9971.663, \"total_train_time_s\": 12.952630758285522}", "{\"n\": 13025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3546.83, \"learn_time_ms\": 10007.53, \"total_train_time_s\": 13.736767292022705}", "{\"n\": 13026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3549.47, \"learn_time_ms\": 10010.608, \"total_train_time_s\": 13.35417127609253}", "{\"n\": 13027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3548.02, \"learn_time_ms\": 9977.383, \"total_train_time_s\": 13.563464403152466}", "{\"n\": 13028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3545.76, \"learn_time_ms\": 9894.313, \"total_train_time_s\": 13.337753772735596}", "{\"n\": 13029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3560.94, \"learn_time_ms\": 9940.54, \"total_train_time_s\": 13.817692279815674}", "{\"n\": 13030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3560.94, \"learn_time_ms\": 9843.742, \"total_train_time_s\": 13.592745780944824}", "{\"n\": 13031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3573.5, \"learn_time_ms\": 9874.119, \"total_train_time_s\": 13.543143272399902}", "{\"n\": 13032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3573.5, \"learn_time_ms\": 9740.819, \"total_train_time_s\": 13.781125783920288}", "{\"n\": 13033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3567.9, \"learn_time_ms\": 9678.014, \"total_train_time_s\": 12.43505048751831}", "{\"n\": 13034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3567.9, \"learn_time_ms\": 9685.686, \"total_train_time_s\": 13.084779739379883}", "{\"n\": 13035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3566.61, \"learn_time_ms\": 9628.112, \"total_train_time_s\": 13.078777551651001}", "{\"n\": 13036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3564.45, \"learn_time_ms\": 9628.628, \"total_train_time_s\": 13.435878276824951}", "{\"n\": 13037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3568.12, \"learn_time_ms\": 9680.423, \"total_train_time_s\": 14.168701410293579}", "{\"n\": 13038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.29, \"learn_time_ms\": 9724.259, \"total_train_time_s\": 13.88059949874878}", "{\"n\": 13039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3576.82, \"learn_time_ms\": 9675.016, \"total_train_time_s\": 13.178579568862915}", "{\"n\": 13040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3578.42, \"learn_time_ms\": 9707.29, \"total_train_time_s\": 13.926565170288086}", "{\"n\": 13041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3578.37, \"learn_time_ms\": 9722.843, \"total_train_time_s\": 13.553378105163574}", "{\"n\": 13042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3578.37, \"learn_time_ms\": 9817.513, \"total_train_time_s\": 14.530730485916138}", "{\"n\": 13043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 9881.13, \"total_train_time_s\": 13.041073322296143}", "{\"n\": 13044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.83, \"learn_time_ms\": 9934.944, \"total_train_time_s\": 13.788408756256104}", "{\"n\": 13045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3581.89, \"learn_time_ms\": 10029.976, \"total_train_time_s\": 14.254258871078491}", "{\"n\": 13046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3581.57, \"learn_time_ms\": 10024.657, \"total_train_time_s\": 13.495522260665894}", "{\"n\": 13047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3581.57, \"learn_time_ms\": 9997.267, \"total_train_time_s\": 13.782865524291992}", "{\"n\": 13048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.52, \"learn_time_ms\": 10014.999, \"total_train_time_s\": 13.95115613937378}", "{\"n\": 13049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.52, \"learn_time_ms\": 9978.62, \"total_train_time_s\": 13.145657300949097}", "{\"n\": 13050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.4, \"learn_time_ms\": 9993.213, \"total_train_time_s\": 13.672503471374512}", "{\"n\": 13051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3579.43, \"learn_time_ms\": 9955.953, \"total_train_time_s\": 13.003131628036499}", "{\"n\": 13052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3577.6, \"learn_time_ms\": 9925.773, \"total_train_time_s\": 14.21748685836792}", "{\"n\": 13053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3577.6, \"learn_time_ms\": 9933.557, \"total_train_time_s\": 13.466784477233887}", "{\"n\": 13054, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3583.6, \"learn_time_ms\": 9892.979, \"total_train_time_s\": 13.218436002731323}", "{\"n\": 13055, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3583.21, \"learn_time_ms\": 9861.324, \"total_train_time_s\": 14.10240125656128}", "{\"n\": 13056, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3582.22, \"learn_time_ms\": 9870.205, \"total_train_time_s\": 13.399218082427979}", "{\"n\": 13057, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3595.6, \"learn_time_ms\": 9878.186, \"total_train_time_s\": 13.769705772399902}", "{\"n\": 13058, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3595.6, \"learn_time_ms\": 9787.132, \"total_train_time_s\": 13.194208145141602}", "{\"n\": 13059, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3599.33, \"learn_time_ms\": 9853.979, \"total_train_time_s\": 13.767404556274414}", "{\"n\": 13060, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3608.01, \"learn_time_ms\": 9897.25, \"total_train_time_s\": 14.10945177078247}", "{\"n\": 13061, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3610.82, \"learn_time_ms\": 9905.393, \"total_train_time_s\": 13.185993671417236}", "{\"n\": 13062, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3615.48, \"learn_time_ms\": 9858.875, \"total_train_time_s\": 13.52556324005127}", "{\"n\": 13063, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3618.6, \"learn_time_ms\": 9832.522, \"total_train_time_s\": 13.006476879119873}", "{\"n\": 13064, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3626.37, \"learn_time_ms\": 9805.826, \"total_train_time_s\": 13.320699453353882}", "{\"n\": 13065, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3633.73, \"learn_time_ms\": 9786.369, \"total_train_time_s\": 13.59895372390747}", "{\"n\": 13066, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3629.77, \"learn_time_ms\": 9853.555, \"total_train_time_s\": 14.289897918701172}", "{\"n\": 13067, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3632.64, \"learn_time_ms\": 9931.97, \"total_train_time_s\": 14.669060468673706}", "{\"n\": 13068, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3632.64, \"learn_time_ms\": 9963.499, \"total_train_time_s\": 13.33128809928894}", "{\"n\": 13069, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3634.75, \"learn_time_ms\": 9943.751, \"total_train_time_s\": 13.166800260543823}", "{\"n\": 13070, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3634.75, \"learn_time_ms\": 9829.883, \"total_train_time_s\": 12.965060710906982}", "{\"n\": 13071, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3629.54, \"learn_time_ms\": 9896.004, \"total_train_time_s\": 13.893440246582031}", "{\"n\": 13072, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3634.74, \"learn_time_ms\": 9964.935, \"total_train_time_s\": 14.39990234375}", "{\"n\": 13073, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3633.73, \"learn_time_ms\": 10003.67, \"total_train_time_s\": 13.231900691986084}", "{\"n\": 13074, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3635.21, \"learn_time_ms\": 10055.167, \"total_train_time_s\": 13.476622819900513}", "{\"n\": 13075, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.65, \"learn_time_ms\": 10151.715, \"total_train_time_s\": 14.618963956832886}", "{\"n\": 13076, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.65, \"learn_time_ms\": 10117.752, \"total_train_time_s\": 14.010692596435547}", "{\"n\": 13077, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.73, \"learn_time_ms\": 10047.209, \"total_train_time_s\": 13.807116746902466}", "{\"n\": 13078, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.96, \"learn_time_ms\": 10074.476, \"total_train_time_s\": 13.659375190734863}", "{\"n\": 13079, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.24, \"learn_time_ms\": 10025.745, \"total_train_time_s\": 12.727846622467041}", "{\"n\": 13080, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.24, \"learn_time_ms\": 10176.431, \"total_train_time_s\": 14.457841396331787}", "{\"n\": 13081, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.39, \"learn_time_ms\": 10126.739, \"total_train_time_s\": 13.356961011886597}", "{\"n\": 13082, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.56, \"learn_time_ms\": 10032.178, \"total_train_time_s\": 13.569278478622437}", "{\"n\": 13083, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.6, \"learn_time_ms\": 10040.382, \"total_train_time_s\": 13.399696111679077}", "{\"n\": 13084, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.36, \"learn_time_ms\": 10039.63, \"total_train_time_s\": 13.506044387817383}", "{\"n\": 13085, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.36, \"learn_time_ms\": 9975.266, \"total_train_time_s\": 14.228240251541138}", "{\"n\": 13086, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.12, \"learn_time_ms\": 9952.857, \"total_train_time_s\": 13.530755758285522}", "{\"n\": 13087, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.2, \"learn_time_ms\": 9942.554, \"total_train_time_s\": 13.828706502914429}", "{\"n\": 13088, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.12, \"learn_time_ms\": 9890.422, \"total_train_time_s\": 13.12430453300476}", "{\"n\": 13089, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.17, \"learn_time_ms\": 9859.055, \"total_train_time_s\": 12.681966781616211}", "{\"n\": 13090, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.17, \"learn_time_ms\": 9714.685, \"total_train_time_s\": 13.237687110900879}", "{\"n\": 13091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.83, \"learn_time_ms\": 9718.91, \"total_train_time_s\": 13.456621170043945}", "{\"n\": 13092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.83, \"learn_time_ms\": 9838.732, \"total_train_time_s\": 14.520186424255371}", "{\"n\": 13093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.97, \"learn_time_ms\": 9927.518, \"total_train_time_s\": 14.274579048156738}", "{\"n\": 13094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.8, \"learn_time_ms\": 9842.21, \"total_train_time_s\": 12.796743631362915}", "{\"n\": 13095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.72, \"learn_time_ms\": 9733.846, \"total_train_time_s\": 13.093066930770874}", "{\"n\": 13096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.14, \"learn_time_ms\": 9717.49, \"total_train_time_s\": 13.557489156723022}", "{\"n\": 13097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.56, \"learn_time_ms\": 9621.169, \"total_train_time_s\": 12.74219536781311}", "{\"n\": 13098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 9640.986, \"total_train_time_s\": 13.444903373718262}", "{\"n\": 13099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.33, \"learn_time_ms\": 9735.719, \"total_train_time_s\": 13.440842866897583}", "{\"n\": 13100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.14, \"learn_time_ms\": 9830.738, \"total_train_time_s\": 14.189789772033691}", "{\"n\": 13101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.64, \"learn_time_ms\": 9780.764, \"total_train_time_s\": 13.106058835983276}", "{\"n\": 13102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.49, \"learn_time_ms\": 9569.547, \"total_train_time_s\": 12.545127391815186}", "{\"n\": 13103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.78, \"learn_time_ms\": 9488.482, \"total_train_time_s\": 13.424824953079224}", "{\"n\": 13104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.69, \"learn_time_ms\": 9499.444, \"total_train_time_s\": 12.804434061050415}", "{\"n\": 13105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 9623.932, \"total_train_time_s\": 14.038137912750244}", "{\"n\": 13106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 9595.535, \"total_train_time_s\": 13.247209072113037}", "{\"n\": 13107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 9723.399, \"total_train_time_s\": 14.275064706802368}", "{\"n\": 13108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.46, \"learn_time_ms\": 9755.838, \"total_train_time_s\": 13.64894151687622}", "{\"n\": 13109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 9781.839, \"total_train_time_s\": 13.578152179718018}", "{\"n\": 13110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 9734.133, \"total_train_time_s\": 13.584046125411987}", "{\"n\": 13111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.6, \"learn_time_ms\": 9736.605, \"total_train_time_s\": 13.127339601516724}", "{\"n\": 13112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.05, \"learn_time_ms\": 9876.268, \"total_train_time_s\": 13.815824031829834}", "{\"n\": 13113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.05, \"learn_time_ms\": 9896.092, \"total_train_time_s\": 13.684818983078003}", "{\"n\": 13114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.3, \"learn_time_ms\": 10006.703, \"total_train_time_s\": 14.087597608566284}", "{\"n\": 13115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.76, \"learn_time_ms\": 9916.428, \"total_train_time_s\": 13.260405778884888}", "{\"n\": 13116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.26, \"learn_time_ms\": 9970.38, \"total_train_time_s\": 13.723845958709717}", "{\"n\": 13117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.26, \"learn_time_ms\": 9875.907, \"total_train_time_s\": 13.023116111755371}", "{\"n\": 13118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.48, \"learn_time_ms\": 9904.159, \"total_train_time_s\": 14.049369812011719}", "{\"n\": 13119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.53, \"learn_time_ms\": 9846.595, \"total_train_time_s\": 13.021479606628418}", "{\"n\": 13120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.88, \"learn_time_ms\": 9825.791, \"total_train_time_s\": 13.244855880737305}", "{\"n\": 13121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.65, \"learn_time_ms\": 9758.43, \"total_train_time_s\": 12.26941728591919}", "{\"n\": 13122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.84, \"learn_time_ms\": 9755.066, \"total_train_time_s\": 13.747233629226685}", "{\"n\": 13123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.76, \"learn_time_ms\": 9745.004, \"total_train_time_s\": 13.72177505493164}", "{\"n\": 13124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.28, \"learn_time_ms\": 9615.428, \"total_train_time_s\": 12.453617572784424}", "{\"n\": 13125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.96, \"learn_time_ms\": 9623.722, \"total_train_time_s\": 13.64909029006958}", "{\"n\": 13126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.37, \"learn_time_ms\": 9562.654, \"total_train_time_s\": 13.017775058746338}", "{\"n\": 13127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.29, \"learn_time_ms\": 9540.378, \"total_train_time_s\": 12.952098369598389}", "{\"n\": 13128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.29, \"learn_time_ms\": 9593.588, \"total_train_time_s\": 14.593408107757568}", "{\"n\": 13129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.09, \"learn_time_ms\": 9600.008, \"total_train_time_s\": 13.38164210319519}", "{\"n\": 13130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.09, \"learn_time_ms\": 9596.026, \"total_train_time_s\": 13.684503078460693}", "{\"n\": 13131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.31, \"learn_time_ms\": 9858.546, \"total_train_time_s\": 15.192758321762085}", "{\"n\": 13132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.03, \"learn_time_ms\": 9794.154, \"total_train_time_s\": 13.46186351776123}", "{\"n\": 13133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.11, \"learn_time_ms\": 9746.636, \"total_train_time_s\": 13.00959587097168}", "{\"n\": 13134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.48, \"learn_time_ms\": 9799.85, \"total_train_time_s\": 13.001413345336914}", "{\"n\": 13135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.48, \"learn_time_ms\": 9716.424, \"total_train_time_s\": 12.758628845214844}", "{\"n\": 13136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3666.27, \"learn_time_ms\": 9762.094, \"total_train_time_s\": 13.529295206069946}", "{\"n\": 13137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3658.82, \"learn_time_ms\": 9840.509, \"total_train_time_s\": 13.609128713607788}", "{\"n\": 13138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3653.99, \"learn_time_ms\": 9741.379, \"total_train_time_s\": 13.457960605621338}", "{\"n\": 13139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3653.99, \"learn_time_ms\": 9808.553, \"total_train_time_s\": 13.784785270690918}", "{\"n\": 13140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3645.62, \"learn_time_ms\": 9821.817, \"total_train_time_s\": 13.666749238967896}", "{\"n\": 13141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.36, \"learn_time_ms\": 9604.859, \"total_train_time_s\": 12.710821390151978}", "{\"n\": 13142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3645.88, \"learn_time_ms\": 9666.404, \"total_train_time_s\": 14.104732513427734}", "{\"n\": 13143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.2, \"learn_time_ms\": 9719.866, \"total_train_time_s\": 13.674606561660767}", "{\"n\": 13144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.2, \"learn_time_ms\": 9846.284, \"total_train_time_s\": 14.701650142669678}", "{\"n\": 13145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3652.35, \"learn_time_ms\": 9965.778, \"total_train_time_s\": 13.587616205215454}", "{\"n\": 13146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3657.22, \"learn_time_ms\": 9849.158, \"total_train_time_s\": 12.298870086669922}", "{\"n\": 13147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.44, \"learn_time_ms\": 9805.862, \"total_train_time_s\": 13.141143560409546}", "{\"n\": 13148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.44, \"learn_time_ms\": 9738.432, \"total_train_time_s\": 13.124446392059326}", "{\"n\": 13149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3652.27, \"learn_time_ms\": 9702.084, \"total_train_time_s\": 13.66455864906311}", "{\"n\": 13150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.42, \"learn_time_ms\": 9598.54, \"total_train_time_s\": 12.347781896591187}", "{\"n\": 13151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.42, \"learn_time_ms\": 9687.372, \"total_train_time_s\": 13.486149549484253}", "{\"n\": 13152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.13, \"learn_time_ms\": 9571.492, \"total_train_time_s\": 12.65496015548706}", "{\"n\": 13153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.47, \"learn_time_ms\": 9551.086, \"total_train_time_s\": 13.53341269493103}", "{\"n\": 13154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.47, \"learn_time_ms\": 9498.956, \"total_train_time_s\": 13.941838026046753}", "{\"n\": 13155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.47, \"learn_time_ms\": 9466.551, \"total_train_time_s\": 13.278012990951538}", "{\"n\": 13156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.15, \"learn_time_ms\": 9649.074, \"total_train_time_s\": 14.276583433151245}", "{\"n\": 13157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3625.02, \"learn_time_ms\": 9599.375, \"total_train_time_s\": 12.776438236236572}", "{\"n\": 13158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3625.02, \"learn_time_ms\": 9676.117, \"total_train_time_s\": 13.604548692703247}", "{\"n\": 13159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3628.24, \"learn_time_ms\": 9736.843, \"total_train_time_s\": 14.119600772857666}", "{\"n\": 13160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3623.59, \"learn_time_ms\": 9787.74, \"total_train_time_s\": 12.919114589691162}", "{\"n\": 13161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.02, \"learn_time_ms\": 9670.892, \"total_train_time_s\": 12.306004047393799}", "{\"n\": 13162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.02, \"learn_time_ms\": 9703.928, \"total_train_time_s\": 13.059115648269653}", "{\"n\": 13163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.0, \"learn_time_ms\": 9681.482, \"total_train_time_s\": 13.11938214302063}", "{\"n\": 13164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.0, \"learn_time_ms\": 9742.36, \"total_train_time_s\": 14.54934549331665}", "{\"n\": 13165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3624.07, \"learn_time_ms\": 9761.354, \"total_train_time_s\": 13.619866371154785}", "{\"n\": 13166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.68, \"learn_time_ms\": 9660.926, \"total_train_time_s\": 13.360599040985107}", "{\"n\": 13167, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.88, \"learn_time_ms\": 9661.135, \"total_train_time_s\": 12.787532567977905}", "{\"n\": 13168, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.88, \"learn_time_ms\": 9677.14, \"total_train_time_s\": 13.739724159240723}", "{\"n\": 13169, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 9650.194, \"total_train_time_s\": 13.858906269073486}", "{\"n\": 13170, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.06, \"learn_time_ms\": 9587.844, \"total_train_time_s\": 12.208817958831787}", "{\"n\": 13171, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.27, \"learn_time_ms\": 9688.566, \"total_train_time_s\": 13.336221694946289}", "{\"n\": 13172, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.27, \"learn_time_ms\": 9748.095, \"total_train_time_s\": 13.88240933418274}", "{\"n\": 13173, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.53, \"learn_time_ms\": 9839.599, \"total_train_time_s\": 14.307223796844482}", "{\"n\": 13174, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.36, \"learn_time_ms\": 9728.969, \"total_train_time_s\": 13.647729396820068}", "{\"n\": 13175, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 9840.709, \"total_train_time_s\": 14.557680130004883}", "{\"n\": 13176, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 9875.761, \"total_train_time_s\": 13.874211311340332}", "{\"n\": 13177, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.97, \"learn_time_ms\": 9759.42, \"total_train_time_s\": 11.509869813919067}", "{\"n\": 13178, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.97, \"learn_time_ms\": 9774.087, \"total_train_time_s\": 13.990349769592285}", "{\"n\": 13179, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.21, \"learn_time_ms\": 9728.281, \"total_train_time_s\": 13.423253774642944}", "{\"n\": 13180, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.96, \"learn_time_ms\": 9831.197, \"total_train_time_s\": 13.50373649597168}", "{\"n\": 13181, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.99, \"learn_time_ms\": 9841.879, \"total_train_time_s\": 13.46285104751587}", "{\"n\": 13182, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.54, \"learn_time_ms\": 9841.946, \"total_train_time_s\": 13.545765399932861}", "{\"n\": 13183, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.54, \"learn_time_ms\": 9829.815, \"total_train_time_s\": 14.261491060256958}", "{\"n\": 13184, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.43, \"learn_time_ms\": 9827.085, \"total_train_time_s\": 13.423206329345703}", "{\"n\": 13185, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3636.76, \"learn_time_ms\": 9788.881, \"total_train_time_s\": 14.168976068496704}", "{\"n\": 13186, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3637.83, \"learn_time_ms\": 9731.119, \"total_train_time_s\": 12.961586475372314}", "{\"n\": 13187, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3637.83, \"learn_time_ms\": 9958.663, \"total_train_time_s\": 13.953635215759277}", "{\"n\": 13188, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3645.13, \"learn_time_ms\": 9939.254, \"total_train_time_s\": 13.63504958152771}", "{\"n\": 13189, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3642.66, \"learn_time_ms\": 10022.988, \"total_train_time_s\": 14.250411033630371}", "{\"n\": 13190, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3642.66, \"learn_time_ms\": 10099.123, \"total_train_time_s\": 14.179829597473145}", "{\"n\": 13191, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3633.77, \"learn_time_ms\": 10087.226, \"total_train_time_s\": 13.459959983825684}", "{\"n\": 13192, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3629.73, \"learn_time_ms\": 10140.543, \"total_train_time_s\": 14.003793716430664}", "{\"n\": 13193, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 10039.969, \"total_train_time_s\": 13.0037202835083}", "{\"n\": 13194, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 10049.054, \"total_train_time_s\": 13.63811731338501}", "{\"n\": 13195, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3633.64, \"learn_time_ms\": 9972.367, \"total_train_time_s\": 13.39682126045227}", "{\"n\": 13196, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3633.64, \"learn_time_ms\": 10022.108, \"total_train_time_s\": 13.554591178894043}", "{\"n\": 13197, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3636.72, \"learn_time_ms\": 10004.613, \"total_train_time_s\": 13.757489919662476}", "{\"n\": 13198, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3636.72, \"learn_time_ms\": 9963.384, \"total_train_time_s\": 13.481954097747803}", "{\"n\": 13199, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.32, \"learn_time_ms\": 10029.098, \"total_train_time_s\": 14.7351393699646}", "{\"n\": 13200, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 9942.445, \"total_train_time_s\": 13.525145292282104}", "{\"n\": 13201, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 9930.747, \"total_train_time_s\": 13.355778217315674}", "{\"n\": 13202, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.67, \"learn_time_ms\": 9839.708, \"total_train_time_s\": 13.346875429153442}", "{\"n\": 13203, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.63, \"learn_time_ms\": 9907.643, \"total_train_time_s\": 13.757266283035278}", "{\"n\": 13204, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.89, \"learn_time_ms\": 9981.308, \"total_train_time_s\": 14.44502329826355}", "{\"n\": 13205, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.89, \"learn_time_ms\": 9972.099, \"total_train_time_s\": 13.432441234588623}", "{\"n\": 13206, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.7, \"learn_time_ms\": 9972.626, \"total_train_time_s\": 13.412963390350342}", "{\"n\": 13207, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.17, \"learn_time_ms\": 9979.52, \"total_train_time_s\": 13.661815166473389}", "{\"n\": 13208, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.17, \"learn_time_ms\": 9965.761, \"total_train_time_s\": 13.231940984725952}", "{\"n\": 13209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.17, \"learn_time_ms\": 9867.612, \"total_train_time_s\": 14.074942827224731}", "{\"n\": 13210, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.18, \"learn_time_ms\": 9882.722, \"total_train_time_s\": 13.309231281280518}", "{\"n\": 13211, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.18, \"learn_time_ms\": 9902.768, \"total_train_time_s\": 13.640134572982788}", "{\"n\": 13212, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.18, \"learn_time_ms\": 9958.937, \"total_train_time_s\": 13.746803998947144}", "{\"n\": 13213, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.25, \"learn_time_ms\": 9895.301, \"total_train_time_s\": 12.950645685195923}", "{\"n\": 13214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 9875.738, \"total_train_time_s\": 13.877861976623535}", "{\"n\": 13215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 9959.52, \"total_train_time_s\": 14.216574668884277}", "{\"n\": 13216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 9911.332, \"total_train_time_s\": 13.029290199279785}", "{\"n\": 13217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.3, \"learn_time_ms\": 9956.212, \"total_train_time_s\": 14.233325958251953}", "{\"n\": 13218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.3, \"learn_time_ms\": 10013.942, \"total_train_time_s\": 13.996284246444702}", "{\"n\": 13219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.3, \"learn_time_ms\": 9975.174, \"total_train_time_s\": 13.470796823501587}", "{\"n\": 13220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.36, \"learn_time_ms\": 9969.245, \"total_train_time_s\": 13.450887441635132}", "{\"n\": 13221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.93, \"learn_time_ms\": 9984.784, \"total_train_time_s\": 13.581268787384033}", "{\"n\": 13222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.5, \"learn_time_ms\": 9986.98, \"total_train_time_s\": 13.865390062332153}", "{\"n\": 13223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.5, \"learn_time_ms\": 9980.014, \"total_train_time_s\": 12.882932424545288}", "{\"n\": 13224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.43, \"learn_time_ms\": 10041.154, \"total_train_time_s\": 14.580358028411865}", "{\"n\": 13225, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 9879.246, \"total_train_time_s\": 12.593328714370728}", "{\"n\": 13226, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 9867.078, \"total_train_time_s\": 13.074793815612793}", "{\"n\": 13227, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.8, \"learn_time_ms\": 9751.164, \"total_train_time_s\": 12.979389190673828}", "{\"n\": 13228, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3629.43, \"learn_time_ms\": 9727.424, \"total_train_time_s\": 13.399885177612305}", "{\"n\": 13229, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3635.28, \"learn_time_ms\": 9674.971, \"total_train_time_s\": 12.992860794067383}", "{\"n\": 13230, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3635.72, \"learn_time_ms\": 9715.266, \"total_train_time_s\": 13.886392831802368}", "{\"n\": 13231, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.61, \"learn_time_ms\": 9724.989, \"total_train_time_s\": 13.691223382949829}", "{\"n\": 13232, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3635.57, \"learn_time_ms\": 9666.889, \"total_train_time_s\": 13.225040435791016}", "{\"n\": 13233, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.39, \"learn_time_ms\": 9682.086, \"total_train_time_s\": 13.331198930740356}", "{\"n\": 13234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.72, \"learn_time_ms\": 9577.885, \"total_train_time_s\": 13.354575157165527}", "{\"n\": 13235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.76, \"learn_time_ms\": 9606.284, \"total_train_time_s\": 12.761022090911865}", "{\"n\": 13236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.05, \"learn_time_ms\": 9786.818, \"total_train_time_s\": 14.72689700126648}", "{\"n\": 13237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.05, \"learn_time_ms\": 9845.183, \"total_train_time_s\": 13.508711099624634}", "{\"n\": 13238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.42, \"learn_time_ms\": 9843.949, \"total_train_time_s\": 13.373008489608765}", "{\"n\": 13239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.76, \"learn_time_ms\": 9875.357, \"total_train_time_s\": 13.25092887878418}", "{\"n\": 13240, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.91, \"learn_time_ms\": 9850.065, \"total_train_time_s\": 13.533430337905884}", "{\"n\": 13241, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.91, \"learn_time_ms\": 9835.095, \"total_train_time_s\": 13.652391910552979}", "{\"n\": 13242, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 9935.179, \"total_train_time_s\": 14.233712673187256}", "{\"n\": 13243, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 9971.219, \"total_train_time_s\": 13.465856313705444}", "{\"n\": 13244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 9929.745, \"total_train_time_s\": 13.187161684036255}", "{\"n\": 13245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 10077.151, \"total_train_time_s\": 14.517599821090698}", "{\"n\": 13246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.91, \"learn_time_ms\": 9962.339, \"total_train_time_s\": 13.552478075027466}", "{\"n\": 13247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.91, \"learn_time_ms\": 9892.603, \"total_train_time_s\": 13.190454483032227}", "{\"n\": 13248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 9952.358, \"total_train_time_s\": 14.20415210723877}", "{\"n\": 13249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 9907.835, \"total_train_time_s\": 13.01594591140747}", "{\"n\": 13250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.29, \"learn_time_ms\": 9885.13, \"total_train_time_s\": 13.243093729019165}"]