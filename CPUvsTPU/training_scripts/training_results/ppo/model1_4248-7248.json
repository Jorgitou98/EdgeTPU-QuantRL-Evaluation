["{\"n\": 4248, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11323.339, \"total_train_time_s\": 15.081790447235107}", "{\"n\": 4249, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10791.369, \"total_train_time_s\": 13.800879001617432}", "{\"n\": 4250, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11150.134, \"total_train_time_s\": 15.727978467941284}", "{\"n\": 4251, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10824.698, \"total_train_time_s\": 13.606550455093384}", "{\"n\": 4252, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10603.99, \"total_train_time_s\": 13.385167837142944}", "{\"n\": 4253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2883.0, \"learn_time_ms\": 10523.715, \"total_train_time_s\": 13.67060661315918}", "{\"n\": 4254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 3139.0, \"learn_time_ms\": 10406.267, \"total_train_time_s\": 13.3555269241333}", "{\"n\": 4255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 3139.0, \"learn_time_ms\": 10528.758, \"total_train_time_s\": 15.274102926254272}", "{\"n\": 4256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3446.75, \"learn_time_ms\": 10390.851, \"total_train_time_s\": 13.055332660675049}", "{\"n\": 4257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3371.4, \"learn_time_ms\": 10354.454, \"total_train_time_s\": 13.779531240463257}", "{\"n\": 4258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.285714285714286, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3363.4285714285716, \"learn_time_ms\": 10331.64, \"total_train_time_s\": 14.876561641693115}", "{\"n\": 4259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.875, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3434.375, \"learn_time_ms\": 10385.194, \"total_train_time_s\": 14.904714107513428}", "{\"n\": 4260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.875, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3434.375, \"learn_time_ms\": 10134.826, \"total_train_time_s\": 13.100985765457153}", "{\"n\": 4261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3417.2, \"learn_time_ms\": 10148.646, \"total_train_time_s\": 13.601674795150757}", "{\"n\": 4262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.363636363636363, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3473.7272727272725, \"learn_time_ms\": 10217.928, \"total_train_time_s\": 13.995756387710571}", "{\"n\": 4263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.363636363636363, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3473.7272727272725, \"learn_time_ms\": 10253.663, \"total_train_time_s\": 14.067687273025513}", "{\"n\": 4264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.142857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3498.6428571428573, \"learn_time_ms\": 10314.256, \"total_train_time_s\": 13.922612190246582}", "{\"n\": 4265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.142857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3498.6428571428573, \"learn_time_ms\": 10222.117, \"total_train_time_s\": 14.048116683959961}", "{\"n\": 4266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.866666666666667, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3522.6, \"learn_time_ms\": 10287.346, \"total_train_time_s\": 13.65342092514038}", "{\"n\": 4267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.866666666666667, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3522.6, \"learn_time_ms\": 10316.952, \"total_train_time_s\": 14.045934915542603}", "{\"n\": 4268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.555555555555555, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3575.8333333333335, \"learn_time_ms\": 10228.004, \"total_train_time_s\": 13.833545923233032}", "{\"n\": 4269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.368421052631579, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3613.7368421052633, \"learn_time_ms\": 10187.604, \"total_train_time_s\": 14.27911114692688}", "{\"n\": 4270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.368421052631579, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3613.7368421052633, \"learn_time_ms\": 10304.68, \"total_train_time_s\": 14.369422912597656}", "{\"n\": 4271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.318181818181818, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3648.7727272727275, \"learn_time_ms\": 10346.733, \"total_train_time_s\": 14.17519760131836}", "{\"n\": 4272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.391304347826088, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3631.6521739130435, \"learn_time_ms\": 10389.704, \"total_train_time_s\": 14.761142015457153}", "{\"n\": 4273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.391304347826088, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3631.6521739130435, \"learn_time_ms\": 10446.065, \"total_train_time_s\": 14.657194375991821}", "{\"n\": 4274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.541666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3601.4166666666665, \"learn_time_ms\": 10457.48, \"total_train_time_s\": 14.3695809841156}", "{\"n\": 4275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3609.52, \"learn_time_ms\": 10467.257, \"total_train_time_s\": 14.346911191940308}", "{\"n\": 4276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.777777777777779, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3556.074074074074, \"learn_time_ms\": 10548.495, \"total_train_time_s\": 14.677544355392456}", "{\"n\": 4277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.777777777777779, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3556.074074074074, \"learn_time_ms\": 10568.625, \"total_train_time_s\": 14.1936514377594}", "{\"n\": 4278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.821428571428571, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3548.714285714286, \"learn_time_ms\": 10677.566, \"total_train_time_s\": 15.222620248794556}", "{\"n\": 4279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.862068965517242, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3544.896551724138, \"learn_time_ms\": 10627.799, \"total_train_time_s\": 13.906516551971436}", "{\"n\": 4280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.833333333333334, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3553.3333333333335, \"learn_time_ms\": 10564.641, \"total_train_time_s\": 13.720048189163208}", "{\"n\": 4281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.625, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.3125, \"learn_time_ms\": 10545.865, \"total_train_time_s\": 14.139341115951538}", "{\"n\": 4282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.625, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.3125, \"learn_time_ms\": 10488.203, \"total_train_time_s\": 14.304544687271118}", "{\"n\": 4283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.625, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.3125, \"learn_time_ms\": 10404.365, \"total_train_time_s\": 13.99674129486084}", "{\"n\": 4284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.264705882352942, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3655.735294117647, \"learn_time_ms\": 10306.384, \"total_train_time_s\": 13.065733432769775}", "{\"n\": 4285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.222222222222221, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3653.5833333333335, \"learn_time_ms\": 10330.3, \"total_train_time_s\": 14.617861270904541}", "{\"n\": 4286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.222222222222221, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3653.5833333333335, \"learn_time_ms\": 10240.694, \"total_train_time_s\": 13.561377763748169}", "{\"n\": 4287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.256410256410257, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3678.5897435897436, \"learn_time_ms\": 10234.142, \"total_train_time_s\": 14.268783569335938}", "{\"n\": 4288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.275, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3681.375, \"learn_time_ms\": 10161.336, \"total_train_time_s\": 14.180532217025757}", "{\"n\": 4289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.275, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3681.375, \"learn_time_ms\": 10290.887, \"total_train_time_s\": 14.947298526763916}", "{\"n\": 4290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.390243902439025, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3669.487804878049, \"learn_time_ms\": 10288.454, \"total_train_time_s\": 13.716222524642944}", "{\"n\": 4291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.522727272727273, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3638.818181818182, \"learn_time_ms\": 10325.653, \"total_train_time_s\": 14.23017406463623}", "{\"n\": 4292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.522727272727273, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3638.818181818182, \"learn_time_ms\": 10411.648, \"total_train_time_s\": 14.8196861743927}", "{\"n\": 4293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.533333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.3333333333335, \"learn_time_ms\": 10419.912, \"total_train_time_s\": 14.262811660766602}", "{\"n\": 4294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.574468085106384, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.978723404255, \"learn_time_ms\": 10484.783, \"total_train_time_s\": 13.886795282363892}", "{\"n\": 4295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.645833333333334, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.0416666666665, \"learn_time_ms\": 10443.178, \"total_train_time_s\": 14.181402921676636}", "{\"n\": 4296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.645833333333334, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.0416666666665, \"learn_time_ms\": 10481.322, \"total_train_time_s\": 13.869587182998657}", "{\"n\": 4297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.775510204081632, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3604.122448979592, \"learn_time_ms\": 10507.08, \"total_train_time_s\": 14.569989681243896}", "{\"n\": 4298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.711538461538462, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 10677.023, \"total_train_time_s\": 16.007718563079834}", "{\"n\": 4299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.711538461538462, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 10630.677, \"total_train_time_s\": 14.397024393081665}", "{\"n\": 4300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.711538461538462, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 10751.638, \"total_train_time_s\": 15.021510601043701}", "{\"n\": 4301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.678571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.160714285714, \"learn_time_ms\": 10706.869, \"total_train_time_s\": 13.870992422103882}", "{\"n\": 4302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.678571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.160714285714, \"learn_time_ms\": 10623.67, \"total_train_time_s\": 14.108490705490112}", "{\"n\": 4303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.678571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.160714285714, \"learn_time_ms\": 10618.764, \"total_train_time_s\": 14.17567777633667}", "{\"n\": 4304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.678571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.160714285714, \"learn_time_ms\": 10627.658, \"total_train_time_s\": 14.026205062866211}", "{\"n\": 4305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.783333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10520.472, \"total_train_time_s\": 13.147690057754517}", "{\"n\": 4306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.783333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10526.629, \"total_train_time_s\": 14.171470403671265}", "{\"n\": 4307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.783333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10565.328, \"total_train_time_s\": 14.746911525726318}", "{\"n\": 4308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.80327868852459, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.8032786885246, \"learn_time_ms\": 10404.074, \"total_train_time_s\": 14.42154335975647}", "{\"n\": 4309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.793650793650794, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.809523809524, \"learn_time_ms\": 10371.312, \"total_train_time_s\": 14.08028507232666}", "{\"n\": 4310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.171875, \"learn_time_ms\": 10473.264, \"total_train_time_s\": 16.149219274520874}", "{\"n\": 4311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.171875, \"learn_time_ms\": 10509.858, \"total_train_time_s\": 14.081143140792847}", "{\"n\": 4312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73134328358209, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.223880597015, \"learn_time_ms\": 10672.681, \"total_train_time_s\": 15.559380054473877}", "{\"n\": 4313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73134328358209, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.223880597015, \"learn_time_ms\": 10805.936, \"total_train_time_s\": 15.2118399143219}", "{\"n\": 4314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.661764705882353, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.705882352941, \"learn_time_ms\": 10870.544, \"total_train_time_s\": 14.5222327709198}", "{\"n\": 4315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.681159420289855, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.086956521739, \"learn_time_ms\": 11045.309, \"total_train_time_s\": 15.059363603591919}", "{\"n\": 4316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71830985915493, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.5915492957747, \"learn_time_ms\": 11036.231, \"total_train_time_s\": 13.873980522155762}", "{\"n\": 4317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71830985915493, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.5915492957747, \"learn_time_ms\": 10910.186, \"total_train_time_s\": 13.802211284637451}", "{\"n\": 4318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.712328767123287, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.3972602739727, \"learn_time_ms\": 10923.254, \"total_train_time_s\": 14.523650407791138}", "{\"n\": 4319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.44, \"learn_time_ms\": 10966.304, \"total_train_time_s\": 14.469358682632446}", "{\"n\": 4320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.44, \"learn_time_ms\": 10771.398, \"total_train_time_s\": 14.13359522819519}", "{\"n\": 4321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.44, \"learn_time_ms\": 10744.036, \"total_train_time_s\": 14.050897359848022}", "{\"n\": 4322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.753246753246753, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.155844155844, \"learn_time_ms\": 10597.349, \"total_train_time_s\": 14.265405178070068}", "{\"n\": 4323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.230769230769, \"learn_time_ms\": 10419.046, \"total_train_time_s\": 13.537535905838013}", "{\"n\": 4324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.683544303797468, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.012658227848, \"learn_time_ms\": 10352.257, \"total_train_time_s\": 13.923710823059082}", "{\"n\": 4325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.654320987654321, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.185185185185, \"learn_time_ms\": 10323.472, \"total_train_time_s\": 14.64018988609314}", "{\"n\": 4326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.609756097560975, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.756097560976, \"learn_time_ms\": 10467.031, \"total_train_time_s\": 15.342768907546997}", "{\"n\": 4327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.53012048192771, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3642.722891566265, \"learn_time_ms\": 10516.653, \"total_train_time_s\": 14.175816297531128}", "{\"n\": 4328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.3058823529414, \"learn_time_ms\": 10574.719, \"total_train_time_s\": 15.078476428985596}", "{\"n\": 4329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.662790697674419, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.5581395348836, \"learn_time_ms\": 10437.66, \"total_train_time_s\": 13.099549531936646}", "{\"n\": 4330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.662790697674419, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.5581395348836, \"learn_time_ms\": 10546.594, \"total_train_time_s\": 14.968905925750732}", "{\"n\": 4331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.738636363636363, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3617.590909090909, \"learn_time_ms\": 10574.673, \"total_train_time_s\": 14.390713453292847}", "{\"n\": 4332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.797752808988765, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.2696629213483, \"learn_time_ms\": 10447.135, \"total_train_time_s\": 13.06221079826355}", "{\"n\": 4333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.855555555555556, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.511111111111, \"learn_time_ms\": 10576.229, \"total_train_time_s\": 14.721990823745728}", "{\"n\": 4334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.868131868131869, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3594.6373626373625, \"learn_time_ms\": 10559.086, \"total_train_time_s\": 13.807976722717285}", "{\"n\": 4335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89247311827957, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.956989247312, \"learn_time_ms\": 10498.079, \"total_train_time_s\": 13.975119590759277}", "{\"n\": 4336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89247311827957, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.956989247312, \"learn_time_ms\": 10339.675, \"total_train_time_s\": 13.849816799163818}", "{\"n\": 4337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.947368421052632, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.4210526315787, \"learn_time_ms\": 10380.531, \"total_train_time_s\": 14.357910394668579}", "{\"n\": 4338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97938144329897, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.9690721649486, \"learn_time_ms\": 10425.097, \"total_train_time_s\": 15.715122938156128}", "{\"n\": 4339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97938144329897, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.9690721649486, \"learn_time_ms\": 10481.372, \"total_train_time_s\": 13.956319808959961}", "{\"n\": 4340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01010101010101, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.40404040404, \"learn_time_ms\": 10421.187, \"total_train_time_s\": 14.425447940826416}", "{\"n\": 4341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.23, \"learn_time_ms\": 10416.581, \"total_train_time_s\": 14.513999462127686}", "{\"n\": 4342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.27, \"learn_time_ms\": 10553.539, \"total_train_time_s\": 14.257028341293335}", "{\"n\": 4343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3588.48, \"learn_time_ms\": 10448.896, \"total_train_time_s\": 13.916093587875366}", "{\"n\": 4344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3589.71, \"learn_time_ms\": 10632.834, \"total_train_time_s\": 15.43926191329956}", "{\"n\": 4345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.4, \"learn_time_ms\": 10607.648, \"total_train_time_s\": 13.563966989517212}", "{\"n\": 4346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.4, \"learn_time_ms\": 10699.871, \"total_train_time_s\": 14.745025157928467}", "{\"n\": 4347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.4, \"learn_time_ms\": 10652.287, \"total_train_time_s\": 14.130030393600464}", "{\"n\": 4348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3583.72, \"learn_time_ms\": 10428.968, \"total_train_time_s\": 13.240287780761719}", "{\"n\": 4349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3586.1, \"learn_time_ms\": 10510.797, \"total_train_time_s\": 14.735516786575317}", "{\"n\": 4350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.42, \"learn_time_ms\": 10464.962, \"total_train_time_s\": 14.091012239456177}", "{\"n\": 4351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.42, \"learn_time_ms\": 10393.824, \"total_train_time_s\": 13.621687650680542}", "{\"n\": 4352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.83, \"learn_time_ms\": 10405.378, \"total_train_time_s\": 14.316644668579102}", "{\"n\": 4353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.56, \"learn_time_ms\": 10496.592, \"total_train_time_s\": 14.900408267974854}", "{\"n\": 4354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.34, \"learn_time_ms\": 10333.387, \"total_train_time_s\": 13.761411190032959}", "{\"n\": 4355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.34, \"learn_time_ms\": 10417.347, \"total_train_time_s\": 14.59307050704956}", "{\"n\": 4356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.78, \"learn_time_ms\": 10341.719, \"total_train_time_s\": 13.900829315185547}", "{\"n\": 4357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.28, \"learn_time_ms\": 10256.805, \"total_train_time_s\": 13.118443965911865}", "{\"n\": 4358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.28, \"learn_time_ms\": 10253.277, \"total_train_time_s\": 13.224952220916748}", "{\"n\": 4359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.89, \"learn_time_ms\": 10249.511, \"total_train_time_s\": 14.429225206375122}", "{\"n\": 4360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3551.81, \"learn_time_ms\": 10373.884, \"total_train_time_s\": 15.061698198318481}", "{\"n\": 4361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.35, \"learn_time_ms\": 10440.016, \"total_train_time_s\": 14.078180313110352}", "{\"n\": 4362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.35, \"learn_time_ms\": 10434.201, \"total_train_time_s\": 14.721467971801758}", "{\"n\": 4363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3543.35, \"learn_time_ms\": 10363.461, \"total_train_time_s\": 14.177934408187866}", "{\"n\": 4364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.59, \"learn_time_ms\": 10352.347, \"total_train_time_s\": 13.870137929916382}", "{\"n\": 4365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.59, \"learn_time_ms\": 10266.72, \"total_train_time_s\": 13.545632123947144}", "{\"n\": 4366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.59, \"learn_time_ms\": 10275.611, \"total_train_time_s\": 14.309887886047363}", "{\"n\": 4367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3569.89, \"learn_time_ms\": 10333.043, \"total_train_time_s\": 13.684576272964478}", "{\"n\": 4368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.01, \"learn_time_ms\": 10328.738, \"total_train_time_s\": 13.131284713745117}", "{\"n\": 4369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3551.35, \"learn_time_ms\": 10290.577, \"total_train_time_s\": 13.996976375579834}", "{\"n\": 4370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.2, \"learn_time_ms\": 10221.635, \"total_train_time_s\": 14.413803815841675}", "{\"n\": 4371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3532.85, \"learn_time_ms\": 10299.634, \"total_train_time_s\": 15.002257585525513}", "{\"n\": 4372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3523.86, \"learn_time_ms\": 10250.912, \"total_train_time_s\": 13.731707572937012}", "{\"n\": 4373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.29, \"learn_time_ms\": 10274.787, \"total_train_time_s\": 14.423465251922607}", "{\"n\": 4374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3526.82, \"learn_time_ms\": 10296.048, \"total_train_time_s\": 14.046667575836182}", "{\"n\": 4375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3542.81, \"learn_time_ms\": 10303.661, \"total_train_time_s\": 13.812469244003296}", "{\"n\": 4376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3526.26, \"learn_time_ms\": 10209.557, \"total_train_time_s\": 13.015458822250366}", "{\"n\": 4377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3526.94, \"learn_time_ms\": 10295.949, \"total_train_time_s\": 14.494361639022827}", "{\"n\": 4378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3526.94, \"learn_time_ms\": 10450.968, \"total_train_time_s\": 15.114025592803955}", "{\"n\": 4379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3544.82, \"learn_time_ms\": 10502.433, \"total_train_time_s\": 14.638866424560547}", "{\"n\": 4380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3541.83, \"learn_time_ms\": 10457.455, \"total_train_time_s\": 14.17815899848938}", "{\"n\": 4381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3548.18, \"learn_time_ms\": 10491.346, \"total_train_time_s\": 15.234464406967163}", "{\"n\": 4382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3558.15, \"learn_time_ms\": 10550.029, \"total_train_time_s\": 14.560672760009766}", "{\"n\": 4383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.97, \"learn_time_ms\": 10624.008, \"total_train_time_s\": 15.212162494659424}", "{\"n\": 4384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.97, \"learn_time_ms\": 10562.758, \"total_train_time_s\": 13.405258417129517}", "{\"n\": 4385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.09, \"learn_time_ms\": 10680.4, \"total_train_time_s\": 14.961426734924316}", "{\"n\": 4386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.96, \"learn_time_ms\": 10783.882, \"total_train_time_s\": 13.997137546539307}", "{\"n\": 4387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3556.84, \"learn_time_ms\": 10823.903, \"total_train_time_s\": 15.063328504562378}", "{\"n\": 4388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.7, \"learn_time_ms\": 10790.632, \"total_train_time_s\": 14.574794292449951}", "{\"n\": 4389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.7, \"learn_time_ms\": 10752.242, \"total_train_time_s\": 14.27635931968689}", "{\"n\": 4390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3555.04, \"learn_time_ms\": 10767.454, \"total_train_time_s\": 14.322444915771484}", "{\"n\": 4391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.81, \"learn_time_ms\": 10602.217, \"total_train_time_s\": 13.622845888137817}", "{\"n\": 4392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3558.79, \"learn_time_ms\": 10475.472, \"total_train_time_s\": 13.284047842025757}", "{\"n\": 4393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.28, \"learn_time_ms\": 10461.418, \"total_train_time_s\": 14.99717116355896}", "{\"n\": 4394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.28, \"learn_time_ms\": 10514.278, \"total_train_time_s\": 13.8103609085083}", "{\"n\": 4395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.51, \"learn_time_ms\": 10470.426, \"total_train_time_s\": 14.448169708251953}", "{\"n\": 4396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.51, \"learn_time_ms\": 10519.628, \"total_train_time_s\": 14.949243783950806}", "{\"n\": 4397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 10478.672, \"total_train_time_s\": 14.610806703567505}", "{\"n\": 4398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.16, \"learn_time_ms\": 10514.301, \"total_train_time_s\": 14.690747022628784}", "{\"n\": 4399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3543.65, \"learn_time_ms\": 10469.701, \"total_train_time_s\": 13.968560457229614}", "{\"n\": 4400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3528.6, \"learn_time_ms\": 10518.969, \"total_train_time_s\": 14.73979139328003}", "{\"n\": 4401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3528.6, \"learn_time_ms\": 10466.325, \"total_train_time_s\": 13.177290201187134}", "{\"n\": 4402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3521.36, \"learn_time_ms\": 10565.068, \"total_train_time_s\": 14.107300281524658}", "{\"n\": 4403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3505.49, \"learn_time_ms\": 10547.149, \"total_train_time_s\": 14.77545428276062}", "{\"n\": 4404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3501.93, \"learn_time_ms\": 10475.881, \"total_train_time_s\": 13.220656633377075}", "{\"n\": 4405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3496.01, \"learn_time_ms\": 10501.863, \"total_train_time_s\": 14.572820901870728}", "{\"n\": 4406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3476.38, \"learn_time_ms\": 10532.967, \"total_train_time_s\": 14.905519485473633}", "{\"n\": 4407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3475.19, \"learn_time_ms\": 10467.876, \"total_train_time_s\": 13.81341552734375}", "{\"n\": 4408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3452.4, \"learn_time_ms\": 10390.603, \"total_train_time_s\": 13.952514410018921}", "{\"n\": 4409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3454.03, \"learn_time_ms\": 10396.679, \"total_train_time_s\": 13.905596256256104}", "{\"n\": 4410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.1, \"learn_time_ms\": 10388.231, \"total_train_time_s\": 14.568916320800781}", "{\"n\": 4411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.21, \"learn_time_ms\": 10520.508, \"total_train_time_s\": 14.342793226242065}", "{\"n\": 4412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.21, \"learn_time_ms\": 10622.307, \"total_train_time_s\": 15.024036645889282}", "{\"n\": 4413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.71, \"learn_time_ms\": 10548.16, \"total_train_time_s\": 13.947973728179932}", "{\"n\": 4414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.71, \"learn_time_ms\": 10656.747, \"total_train_time_s\": 14.31623363494873}", "{\"n\": 4415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.8, \"learn_time_ms\": 10603.714, \"total_train_time_s\": 14.311171531677246}", "{\"n\": 4416, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.17, \"learn_time_ms\": 10553.059, \"total_train_time_s\": 14.442346334457397}", "{\"n\": 4417, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.96, \"learn_time_ms\": 10536.954, \"total_train_time_s\": 13.837647199630737}", "{\"n\": 4418, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.22, \"learn_time_ms\": 10633.681, \"total_train_time_s\": 15.097379922866821}", "{\"n\": 4419, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.49, \"learn_time_ms\": 10731.646, \"total_train_time_s\": 14.858261823654175}", "{\"n\": 4420, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.15, \"learn_time_ms\": 10828.766, \"total_train_time_s\": 15.602700233459473}", "{\"n\": 4421, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.48, \"learn_time_ms\": 10814.839, \"total_train_time_s\": 14.207372188568115}", "{\"n\": 4422, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.51, \"learn_time_ms\": 10757.202, \"total_train_time_s\": 14.649804592132568}", "{\"n\": 4423, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.99, \"learn_time_ms\": 10895.79, \"total_train_time_s\": 15.580376625061035}", "{\"n\": 4424, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.92, \"learn_time_ms\": 10888.876, \"total_train_time_s\": 14.310638666152954}", "{\"n\": 4425, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.95, \"learn_time_ms\": 10777.354, \"total_train_time_s\": 13.114307641983032}", "{\"n\": 4426, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.84, \"learn_time_ms\": 10793.955, \"total_train_time_s\": 14.77227783203125}", "{\"n\": 4427, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.13, \"learn_time_ms\": 10798.588, \"total_train_time_s\": 13.903882503509521}", "{\"n\": 4428, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.7, \"learn_time_ms\": 10657.802, \"total_train_time_s\": 13.742122173309326}", "{\"n\": 4429, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.2, \"learn_time_ms\": 10658.899, \"total_train_time_s\": 14.868041276931763}", "{\"n\": 4430, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.14, \"learn_time_ms\": 10522.621, \"total_train_time_s\": 14.135225534439087}", "{\"n\": 4431, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.72, \"learn_time_ms\": 10590.456, \"total_train_time_s\": 14.993083238601685}", "{\"n\": 4432, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.32, \"learn_time_ms\": 10620.562, \"total_train_time_s\": 15.237162828445435}", "{\"n\": 4433, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.97, \"learn_time_ms\": 10559.788, \"total_train_time_s\": 14.616122245788574}", "{\"n\": 4434, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.32, \"learn_time_ms\": 10569.448, \"total_train_time_s\": 14.318258285522461}", "{\"n\": 4435, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.29, \"learn_time_ms\": 10561.326, \"total_train_time_s\": 12.873109102249146}", "{\"n\": 4436, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.16, \"learn_time_ms\": 10485.458, \"total_train_time_s\": 13.75447678565979}", "{\"n\": 4437, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.38, \"learn_time_ms\": 10491.541, \"total_train_time_s\": 14.040616750717163}", "{\"n\": 4438, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.38, \"learn_time_ms\": 10572.174, \"total_train_time_s\": 14.505218744277954}", "{\"n\": 4439, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.82, \"learn_time_ms\": 10510.084, \"total_train_time_s\": 14.221096754074097}", "{\"n\": 4440, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.82, \"learn_time_ms\": 10379.841, \"total_train_time_s\": 12.938648700714111}", "{\"n\": 4441, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 10368.61, \"total_train_time_s\": 14.791178703308105}", "{\"n\": 4442, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.07, \"learn_time_ms\": 10330.062, \"total_train_time_s\": 14.58287262916565}", "{\"n\": 4443, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.52, \"learn_time_ms\": 10264.747, \"total_train_time_s\": 13.955065727233887}", "{\"n\": 4444, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.21, \"learn_time_ms\": 10338.405, \"total_train_time_s\": 15.112381219863892}", "{\"n\": 4445, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.21, \"learn_time_ms\": 10486.91, \"total_train_time_s\": 14.741041421890259}", "{\"n\": 4446, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.29, \"learn_time_ms\": 10545.922, \"total_train_time_s\": 14.340962409973145}", "{\"n\": 4447, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.53, \"learn_time_ms\": 10505.518, \"total_train_time_s\": 13.4524507522583}", "{\"n\": 4448, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.53, \"learn_time_ms\": 10536.002, \"total_train_time_s\": 14.582803726196289}", "{\"n\": 4449, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.88, \"learn_time_ms\": 10483.65, \"total_train_time_s\": 13.679286479949951}", "{\"n\": 4450, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.07, \"learn_time_ms\": 10639.558, \"total_train_time_s\": 14.641938209533691}", "{\"n\": 4451, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.71, \"learn_time_ms\": 10527.242, \"total_train_time_s\": 13.856401681900024}", "{\"n\": 4452, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.29, \"learn_time_ms\": 10470.175, \"total_train_time_s\": 13.993677616119385}", "{\"n\": 4453, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.64, \"learn_time_ms\": 10424.743, \"total_train_time_s\": 13.486274003982544}", "{\"n\": 4454, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.53, \"learn_time_ms\": 10330.077, \"total_train_time_s\": 14.416629552841187}", "{\"n\": 4455, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.34, \"learn_time_ms\": 10315.857, \"total_train_time_s\": 14.400649309158325}", "{\"n\": 4456, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.54, \"learn_time_ms\": 10345.271, \"total_train_time_s\": 14.722984552383423}", "{\"n\": 4457, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.02, \"learn_time_ms\": 10451.379, \"total_train_time_s\": 14.597251176834106}", "{\"n\": 4458, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.18, \"learn_time_ms\": 10393.527, \"total_train_time_s\": 14.357771396636963}", "{\"n\": 4459, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.69, \"learn_time_ms\": 10497.022, \"total_train_time_s\": 14.786966800689697}", "{\"n\": 4460, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.52, \"learn_time_ms\": 10457.414, \"total_train_time_s\": 14.147262811660767}", "{\"n\": 4461, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.52, \"learn_time_ms\": 10585.782, \"total_train_time_s\": 15.111738920211792}", "{\"n\": 4462, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.39, \"learn_time_ms\": 10627.776, \"total_train_time_s\": 14.531614780426025}", "{\"n\": 4463, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.74, \"learn_time_ms\": 10690.506, \"total_train_time_s\": 14.195837497711182}", "{\"n\": 4464, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.08, \"learn_time_ms\": 10600.161, \"total_train_time_s\": 13.21933889389038}", "{\"n\": 4465, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.08, \"learn_time_ms\": 10554.163, \"total_train_time_s\": 13.694850444793701}", "{\"n\": 4466, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3307.87, \"learn_time_ms\": 10453.009, \"total_train_time_s\": 13.977266073226929}", "{\"n\": 4467, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3320.11, \"learn_time_ms\": 10492.524, \"total_train_time_s\": 15.016872644424438}", "{\"n\": 4468, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3320.11, \"learn_time_ms\": 10503.011, \"total_train_time_s\": 14.376404285430908}", "{\"n\": 4469, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3320.11, \"learn_time_ms\": 10373.908, \"total_train_time_s\": 13.569542407989502}", "{\"n\": 4470, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3334.68, \"learn_time_ms\": 10423.514, \"total_train_time_s\": 14.54244589805603}", "{\"n\": 4471, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3322.17, \"learn_time_ms\": 10310.459, \"total_train_time_s\": 13.912199258804321}", "{\"n\": 4472, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3322.17, \"learn_time_ms\": 10297.593, \"total_train_time_s\": 14.217788934707642}", "{\"n\": 4473, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3312.43, \"learn_time_ms\": 10181.974, \"total_train_time_s\": 13.216146469116211}", "{\"n\": 4474, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3297.21, \"learn_time_ms\": 10269.62, \"total_train_time_s\": 13.970688581466675}", "{\"n\": 4475, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3297.21, \"learn_time_ms\": 10389.2, \"total_train_time_s\": 15.124372959136963}", "{\"n\": 4476, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3297.21, \"learn_time_ms\": 10484.407, \"total_train_time_s\": 14.718583345413208}", "{\"n\": 4477, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3302.28, \"learn_time_ms\": 10355.941, \"total_train_time_s\": 13.548344850540161}", "{\"n\": 4478, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 10322.267, \"total_train_time_s\": 13.771031379699707}", "{\"n\": 4479, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 10420.565, \"total_train_time_s\": 14.389564752578735}", "{\"n\": 4480, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3301.21, \"learn_time_ms\": 10385.105, \"total_train_time_s\": 14.180331468582153}", "{\"n\": 4481, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3307.93, \"learn_time_ms\": 10395.004, \"total_train_time_s\": 13.9414381980896}", "{\"n\": 4482, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3319.54, \"learn_time_ms\": 10371.076, \"total_train_time_s\": 14.010573625564575}", "{\"n\": 4483, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3319.19, \"learn_time_ms\": 10476.305, \"total_train_time_s\": 13.968491554260254}", "{\"n\": 4484, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3321.51, \"learn_time_ms\": 10526.387, \"total_train_time_s\": 14.534876346588135}", "{\"n\": 4485, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3318.37, \"learn_time_ms\": 10545.723, \"total_train_time_s\": 15.355262756347656}", "{\"n\": 4486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3320.29, \"learn_time_ms\": 10547.199, \"total_train_time_s\": 14.578742742538452}", "{\"n\": 4487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3322.19, \"learn_time_ms\": 10589.213, \"total_train_time_s\": 14.176269054412842}", "{\"n\": 4488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3320.53, \"learn_time_ms\": 10637.206, \"total_train_time_s\": 14.237134456634521}", "{\"n\": 4489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3331.7, \"learn_time_ms\": 10553.567, \"total_train_time_s\": 13.730334043502808}", "{\"n\": 4490, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3341.67, \"learn_time_ms\": 10574.758, \"total_train_time_s\": 14.335172414779663}", "{\"n\": 4491, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3345.61, \"learn_time_ms\": 10508.401, \"total_train_time_s\": 13.454621076583862}", "{\"n\": 4492, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3345.61, \"learn_time_ms\": 10499.126, \"total_train_time_s\": 13.772952795028687}", "{\"n\": 4493, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3334.52, \"learn_time_ms\": 10484.289, \"total_train_time_s\": 13.932142496109009}", "{\"n\": 4494, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3336.46, \"learn_time_ms\": 10415.895, \"total_train_time_s\": 14.156699657440186}", "{\"n\": 4495, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3336.46, \"learn_time_ms\": 10312.698, \"total_train_time_s\": 14.325055599212646}", "{\"n\": 4496, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3346.56, \"learn_time_ms\": 10348.375, \"total_train_time_s\": 15.087048292160034}", "{\"n\": 4497, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3339.0, \"learn_time_ms\": 10431.314, \"total_train_time_s\": 15.013640880584717}", "{\"n\": 4498, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3339.0, \"learn_time_ms\": 10407.551, \"total_train_time_s\": 14.19158387184143}", "{\"n\": 4499, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3334.59, \"learn_time_ms\": 10506.674, \"total_train_time_s\": 14.57807469367981}", "{\"n\": 4500, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3333.2, \"learn_time_ms\": 10373.322, \"total_train_time_s\": 13.156992673873901}", "{\"n\": 4501, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3330.51, \"learn_time_ms\": 10443.917, \"total_train_time_s\": 13.930391311645508}", "{\"n\": 4502, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3336.32, \"learn_time_ms\": 10427.492, \"total_train_time_s\": 13.74606204032898}", "{\"n\": 4503, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3323.34, \"learn_time_ms\": 10503.357, \"total_train_time_s\": 14.715076923370361}", "{\"n\": 4504, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3335.35, \"learn_time_ms\": 10516.098, \"total_train_time_s\": 14.108752250671387}", "{\"n\": 4505, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3330.61, \"learn_time_ms\": 10477.746, \"total_train_time_s\": 13.979319334030151}", "{\"n\": 4506, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3330.61, \"learn_time_ms\": 10334.045, \"total_train_time_s\": 13.472515344619751}", "{\"n\": 4507, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3351.6, \"learn_time_ms\": 10312.193, \"total_train_time_s\": 14.783395290374756}", "{\"n\": 4508, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3351.6, \"learn_time_ms\": 10367.093, \"total_train_time_s\": 14.870510816574097}", "{\"n\": 4509, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3347.99, \"learn_time_ms\": 10276.805, \"total_train_time_s\": 13.729484558105469}", "{\"n\": 4510, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3354.48, \"learn_time_ms\": 10370.524, \"total_train_time_s\": 13.997312068939209}", "{\"n\": 4511, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3352.24, \"learn_time_ms\": 10337.017, \"total_train_time_s\": 13.522802352905273}", "{\"n\": 4512, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3352.24, \"learn_time_ms\": 10384.094, \"total_train_time_s\": 14.078899145126343}", "{\"n\": 4513, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3358.37, \"learn_time_ms\": 10394.141, \"total_train_time_s\": 14.991802215576172}", "{\"n\": 4514, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3351.98, \"learn_time_ms\": 10436.21, \"total_train_time_s\": 14.484582662582397}", "{\"n\": 4515, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3354.4, \"learn_time_ms\": 10556.262, \"total_train_time_s\": 15.050642490386963}", "{\"n\": 4516, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3361.41, \"learn_time_ms\": 10497.005, \"total_train_time_s\": 13.148947954177856}", "{\"n\": 4517, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3373.9, \"learn_time_ms\": 10488.485, \"total_train_time_s\": 14.439000844955444}", "{\"n\": 4518, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3373.9, \"learn_time_ms\": 10438.903, \"total_train_time_s\": 14.042931318283081}", "{\"n\": 4519, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3385.27, \"learn_time_ms\": 10470.705, \"total_train_time_s\": 14.079980373382568}", "{\"n\": 4520, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3389.16, \"learn_time_ms\": 10489.561, \"total_train_time_s\": 14.172829627990723}", "{\"n\": 4521, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3385.23, \"learn_time_ms\": 10480.75, \"total_train_time_s\": 13.535122156143188}", "{\"n\": 4522, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3390.88, \"learn_time_ms\": 10517.325, \"total_train_time_s\": 14.679283857345581}", "{\"n\": 4523, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3398.92, \"learn_time_ms\": 10453.348, \"total_train_time_s\": 14.307426929473877}", "{\"n\": 4524, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3403.0, \"learn_time_ms\": 10491.035, \"total_train_time_s\": 15.060590028762817}", "{\"n\": 4525, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3403.0, \"learn_time_ms\": 10412.037, \"total_train_time_s\": 14.380290031433105}", "{\"n\": 4526, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3388.86, \"learn_time_ms\": 10479.569, \"total_train_time_s\": 13.881382703781128}", "{\"n\": 4527, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3384.41, \"learn_time_ms\": 10524.412, \"total_train_time_s\": 15.061359882354736}", "{\"n\": 4528, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3389.14, \"learn_time_ms\": 10469.434, \"total_train_time_s\": 13.8452467918396}", "{\"n\": 4529, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3389.14, \"learn_time_ms\": 10495.91, \"total_train_time_s\": 14.59642505645752}", "{\"n\": 4530, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3393.06, \"learn_time_ms\": 10455.542, \"total_train_time_s\": 13.94392466545105}", "{\"n\": 4531, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3388.2, \"learn_time_ms\": 10565.17, \"total_train_time_s\": 14.813825130462646}", "{\"n\": 4532, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3396.98, \"learn_time_ms\": 10542.397, \"total_train_time_s\": 14.490708827972412}", "{\"n\": 4533, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3414.44, \"learn_time_ms\": 10628.881, \"total_train_time_s\": 14.954890012741089}", "{\"n\": 4534, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3420.72, \"learn_time_ms\": 10588.42, \"total_train_time_s\": 14.361140727996826}", "{\"n\": 4535, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3431.9, \"learn_time_ms\": 10611.271, \"total_train_time_s\": 14.538362264633179}", "{\"n\": 4536, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3425.88, \"learn_time_ms\": 10642.711, \"total_train_time_s\": 13.922412633895874}", "{\"n\": 4537, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3425.88, \"learn_time_ms\": 10576.109, \"total_train_time_s\": 14.421774864196777}", "{\"n\": 4538, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3425.83, \"learn_time_ms\": 10575.708, \"total_train_time_s\": 13.695879697799683}", "{\"n\": 4539, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3422.79, \"learn_time_ms\": 10419.717, \"total_train_time_s\": 12.699430704116821}", "{\"n\": 4540, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3415.94, \"learn_time_ms\": 10483.326, \"total_train_time_s\": 14.878491401672363}", "{\"n\": 4541, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3428.86, \"learn_time_ms\": 10430.127, \"total_train_time_s\": 14.215855121612549}", "{\"n\": 4542, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3432.44, \"learn_time_ms\": 10363.546, \"total_train_time_s\": 13.773717880249023}", "{\"n\": 4543, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3432.44, \"learn_time_ms\": 10350.269, \"total_train_time_s\": 14.922680616378784}", "{\"n\": 4544, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3438.38, \"learn_time_ms\": 10282.884, \"total_train_time_s\": 13.965008735656738}", "{\"n\": 4545, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3435.23, \"learn_time_ms\": 10309.079, \"total_train_time_s\": 15.009013891220093}", "{\"n\": 4546, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3439.25, \"learn_time_ms\": 10228.308, \"total_train_time_s\": 13.283741474151611}", "{\"n\": 4547, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3437.47, \"learn_time_ms\": 10233.902, \"total_train_time_s\": 14.473417282104492}", "{\"n\": 4548, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3453.44, \"learn_time_ms\": 10256.0, \"total_train_time_s\": 13.906030416488647}", "{\"n\": 4549, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.48, \"learn_time_ms\": 10421.488, \"total_train_time_s\": 14.302206993103027}", "{\"n\": 4550, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3469.18, \"learn_time_ms\": 10474.943, \"total_train_time_s\": 15.142924308776855}", "{\"n\": 4551, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3469.18, \"learn_time_ms\": 10469.148, \"total_train_time_s\": 14.010987997055054}", "{\"n\": 4552, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3483.92, \"learn_time_ms\": 10515.863, \"total_train_time_s\": 14.299665451049805}", "{\"n\": 4553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3465.32, \"learn_time_ms\": 10481.554, \"total_train_time_s\": 14.493879318237305}", "{\"n\": 4554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3475.88, \"learn_time_ms\": 10575.95, \"total_train_time_s\": 14.562780380249023}", "{\"n\": 4555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3475.88, \"learn_time_ms\": 10570.757, \"total_train_time_s\": 14.946672677993774}", "{\"n\": 4556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3475.88, \"learn_time_ms\": 10607.603, \"total_train_time_s\": 13.842443704605103}", "{\"n\": 4557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3492.11, \"learn_time_ms\": 10502.056, \"total_train_time_s\": 13.309247016906738}", "{\"n\": 4558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3489.32, \"learn_time_ms\": 10591.792, \"total_train_time_s\": 14.759196519851685}", "{\"n\": 4559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.9, \"learn_time_ms\": 10620.575, \"total_train_time_s\": 14.596040487289429}", "{\"n\": 4560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3516.04, \"learn_time_ms\": 10492.585, \"total_train_time_s\": 13.679508209228516}", "{\"n\": 4561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3527.95, \"learn_time_ms\": 10492.444, \"total_train_time_s\": 14.202969789505005}", "{\"n\": 4562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3512.2, \"learn_time_ms\": 10523.613, \"total_train_time_s\": 14.761857032775879}", "{\"n\": 4563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3512.2, \"learn_time_ms\": 10508.841, \"total_train_time_s\": 14.59103012084961}", "{\"n\": 4564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3508.3, \"learn_time_ms\": 10559.933, \"total_train_time_s\": 15.163153409957886}", "{\"n\": 4565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3523.37, \"learn_time_ms\": 10424.189, \"total_train_time_s\": 13.261916637420654}", "{\"n\": 4566, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3515.28, \"learn_time_ms\": 10508.007, \"total_train_time_s\": 14.380429983139038}", "{\"n\": 4567, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.04, \"learn_time_ms\": 10724.177, \"total_train_time_s\": 15.711681842803955}", "{\"n\": 4568, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.04, \"learn_time_ms\": 10707.414, \"total_train_time_s\": 14.725811958312988}", "{\"n\": 4569, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3515.16, \"learn_time_ms\": 10674.583, \"total_train_time_s\": 14.303308486938477}", "{\"n\": 4570, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.07, \"learn_time_ms\": 10711.514, \"total_train_time_s\": 14.366254329681396}", "{\"n\": 4571, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.07, \"learn_time_ms\": 10698.261, \"total_train_time_s\": 14.03980541229248}", "{\"n\": 4572, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3543.76, \"learn_time_ms\": 10603.922, \"total_train_time_s\": 13.839759111404419}", "{\"n\": 4573, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3554.79, \"learn_time_ms\": 10513.013, \"total_train_time_s\": 13.493356466293335}", "{\"n\": 4574, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3554.79, \"learn_time_ms\": 10365.088, \"total_train_time_s\": 13.750974416732788}", "{\"n\": 4575, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3554.79, \"learn_time_ms\": 10492.262, \"total_train_time_s\": 14.620214939117432}", "{\"n\": 4576, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.04, \"learn_time_ms\": 10485.571, \"total_train_time_s\": 14.235869884490967}", "{\"n\": 4577, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.76, \"learn_time_ms\": 10339.984, \"total_train_time_s\": 14.28695034980774}", "{\"n\": 4578, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.76, \"learn_time_ms\": 10306.359, \"total_train_time_s\": 14.320373058319092}", "{\"n\": 4579, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.76, \"learn_time_ms\": 10285.369, \"total_train_time_s\": 14.11993408203125}", "{\"n\": 4580, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.9, \"learn_time_ms\": 10304.823, \"total_train_time_s\": 14.127533912658691}", "{\"n\": 4581, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3586.6, \"learn_time_ms\": 10300.947, \"total_train_time_s\": 13.872071981430054}", "{\"n\": 4582, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3586.6, \"learn_time_ms\": 10321.735, \"total_train_time_s\": 13.73572301864624}", "{\"n\": 4583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3593.81, \"learn_time_ms\": 10328.586, \"total_train_time_s\": 13.680344581604004}", "{\"n\": 4584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 10386.253, \"total_train_time_s\": 14.346358060836792}", "{\"n\": 4585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3623.04, \"learn_time_ms\": 10354.221, \"total_train_time_s\": 14.496682405471802}", "{\"n\": 4586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3627.46, \"learn_time_ms\": 10357.264, \"total_train_time_s\": 14.371810913085938}", "{\"n\": 4587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3632.53, \"learn_time_ms\": 10356.068, \"total_train_time_s\": 14.113423824310303}", "{\"n\": 4588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3632.53, \"learn_time_ms\": 10310.001, \"total_train_time_s\": 13.788859844207764}", "{\"n\": 4589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3646.37, \"learn_time_ms\": 10388.576, \"total_train_time_s\": 14.957551956176758}", "{\"n\": 4590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 10311.418, \"total_train_time_s\": 13.416520595550537}", "{\"n\": 4591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.32, \"learn_time_ms\": 10378.406, \"total_train_time_s\": 14.440640449523926}", "{\"n\": 4592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3651.1, \"learn_time_ms\": 10357.387, \"total_train_time_s\": 13.392847776412964}", "{\"n\": 4593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.92, \"learn_time_ms\": 10390.35, \"total_train_time_s\": 14.112217426300049}", "{\"n\": 4594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3638.51, \"learn_time_ms\": 10334.144, \"total_train_time_s\": 13.927463054656982}", "{\"n\": 4595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3639.95, \"learn_time_ms\": 10353.541, \"total_train_time_s\": 14.39046835899353}", "{\"n\": 4596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3641.37, \"learn_time_ms\": 10318.997, \"total_train_time_s\": 13.895314693450928}", "{\"n\": 4597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3634.17, \"learn_time_ms\": 10354.161, \"total_train_time_s\": 14.512876987457275}", "{\"n\": 4598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3634.17, \"learn_time_ms\": 10373.489, \"total_train_time_s\": 14.019607305526733}", "{\"n\": 4599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3636.37, \"learn_time_ms\": 10280.601, \"total_train_time_s\": 13.87992262840271}", "{\"n\": 4600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3636.37, \"learn_time_ms\": 10349.138, \"total_train_time_s\": 14.372189044952393}", "{\"n\": 4601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3635.52, \"learn_time_ms\": 10332.367, \"total_train_time_s\": 14.52120590209961}", "{\"n\": 4602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3659.45, \"learn_time_ms\": 10304.262, \"total_train_time_s\": 13.712242603302002}", "{\"n\": 4603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.15, \"learn_time_ms\": 10380.896, \"total_train_time_s\": 14.585623025894165}", "{\"n\": 4604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 10464.84, \"total_train_time_s\": 14.695374011993408}", "{\"n\": 4605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3665.07, \"learn_time_ms\": 10469.044, \"total_train_time_s\": 14.47112488746643}", "{\"n\": 4606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10459.011, \"total_train_time_s\": 13.939058780670166}", "{\"n\": 4607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3664.69, \"learn_time_ms\": 10403.116, \"total_train_time_s\": 13.732134819030762}", "{\"n\": 4608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3664.03, \"learn_time_ms\": 10417.259, \"total_train_time_s\": 14.095888376235962}", "{\"n\": 4609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3656.9, \"learn_time_ms\": 10448.588, \"total_train_time_s\": 14.321210384368896}", "{\"n\": 4610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.67, \"learn_time_ms\": 10483.523, \"total_train_time_s\": 14.5061776638031}", "{\"n\": 4611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.9, \"learn_time_ms\": 10493.562, \"total_train_time_s\": 14.625675916671753}", "{\"n\": 4612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3657.84, \"learn_time_ms\": 10483.504, \"total_train_time_s\": 13.157727718353271}", "{\"n\": 4613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.64, \"learn_time_ms\": 10395.015, \"total_train_time_s\": 13.71328592300415}", "{\"n\": 4614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3640.92, \"learn_time_ms\": 10390.079, \"total_train_time_s\": 14.713104248046875}", "{\"n\": 4615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3659.5, \"learn_time_ms\": 10165.926, \"total_train_time_s\": 12.187748432159424}", "{\"n\": 4616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3659.65, \"learn_time_ms\": 10144.852, \"total_train_time_s\": 13.843004941940308}", "{\"n\": 4617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3669.92, \"learn_time_ms\": 10094.194, \"total_train_time_s\": 13.39746642112732}", "{\"n\": 4618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3675.03, \"learn_time_ms\": 10074.982, \"total_train_time_s\": 14.008399248123169}", "{\"n\": 4619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3675.74, \"learn_time_ms\": 10058.349, \"total_train_time_s\": 14.4277503490448}", "{\"n\": 4620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3674.79, \"learn_time_ms\": 10010.509, \"total_train_time_s\": 14.302325248718262}", "{\"n\": 4621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3671.75, \"learn_time_ms\": 10046.49, \"total_train_time_s\": 14.784383773803711}", "{\"n\": 4622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3671.75, \"learn_time_ms\": 10157.527, \"total_train_time_s\": 14.279451847076416}", "{\"n\": 4623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3670.81, \"learn_time_ms\": 10206.246, \"total_train_time_s\": 14.170785188674927}", "{\"n\": 4624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3644.27, \"learn_time_ms\": 10116.518, \"total_train_time_s\": 13.764087915420532}", "{\"n\": 4625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3644.27, \"learn_time_ms\": 10262.179, \"total_train_time_s\": 13.897518634796143}", "{\"n\": 4626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3639.07, \"learn_time_ms\": 10339.221, \"total_train_time_s\": 14.507647037506104}", "{\"n\": 4627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3637.32, \"learn_time_ms\": 10367.338, \"total_train_time_s\": 13.534382104873657}", "{\"n\": 4628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.65, \"learn_time_ms\": 10273.945, \"total_train_time_s\": 12.890641927719116}", "{\"n\": 4629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.65, \"learn_time_ms\": 10300.176, \"total_train_time_s\": 14.350849628448486}", "{\"n\": 4630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.45, \"learn_time_ms\": 10353.2, \"total_train_time_s\": 14.709204196929932}", "{\"n\": 4631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10292.886, \"total_train_time_s\": 14.53770136833191}", "{\"n\": 4632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3658.29, \"learn_time_ms\": 10296.934, \"total_train_time_s\": 14.265488386154175}", "{\"n\": 4633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3667.91, \"learn_time_ms\": 10306.305, \"total_train_time_s\": 14.585723400115967}", "{\"n\": 4634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3670.93, \"learn_time_ms\": 10362.445, \"total_train_time_s\": 14.147291660308838}", "{\"n\": 4635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3682.76, \"learn_time_ms\": 10410.114, \"total_train_time_s\": 14.213957071304321}", "{\"n\": 4636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3682.76, \"learn_time_ms\": 10347.033, \"total_train_time_s\": 13.974990844726562}", "{\"n\": 4637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3678.83, \"learn_time_ms\": 10417.046, \"total_train_time_s\": 14.515077590942383}", "{\"n\": 4638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3674.3, \"learn_time_ms\": 10457.503, \"total_train_time_s\": 13.66236925125122}", "{\"n\": 4639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3655.54, \"learn_time_ms\": 10422.978, \"total_train_time_s\": 13.934005975723267}", "{\"n\": 4640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3655.54, \"learn_time_ms\": 10478.413, \"total_train_time_s\": 15.332860469818115}", "{\"n\": 4641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3664.7, \"learn_time_ms\": 10425.981, \"total_train_time_s\": 13.910890817642212}", "{\"n\": 4642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3645.84, \"learn_time_ms\": 10505.242, \"total_train_time_s\": 15.208918809890747}", "{\"n\": 4643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.74, \"learn_time_ms\": 10382.398, \"total_train_time_s\": 13.093554496765137}", "{\"n\": 4644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.74, \"learn_time_ms\": 10310.973, \"total_train_time_s\": 13.511313438415527}", "{\"n\": 4645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.02, \"learn_time_ms\": 10308.457, \"total_train_time_s\": 14.200979948043823}", "{\"n\": 4646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.9, \"learn_time_ms\": 10320.245, \"total_train_time_s\": 13.917003631591797}", "{\"n\": 4647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.9, \"learn_time_ms\": 10389.198, \"total_train_time_s\": 15.003016471862793}", "{\"n\": 4648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.39, \"learn_time_ms\": 10463.402, \"total_train_time_s\": 14.18971586227417}", "{\"n\": 4649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3640.18, \"learn_time_ms\": 10475.274, \"total_train_time_s\": 14.22151517868042}", "{\"n\": 4650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3625.8, \"learn_time_ms\": 10329.987, \"total_train_time_s\": 13.72568392753601}", "{\"n\": 4651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3625.8, \"learn_time_ms\": 10371.858, \"total_train_time_s\": 14.393106460571289}", "{\"n\": 4652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3631.85, \"learn_time_ms\": 10331.714, \"total_train_time_s\": 14.851044178009033}", "{\"n\": 4653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 10419.785, \"total_train_time_s\": 13.8967924118042}", "{\"n\": 4654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 10609.62, \"total_train_time_s\": 15.632694005966187}", "{\"n\": 4655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 10646.357, \"total_train_time_s\": 14.569668292999268}", "{\"n\": 4656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3638.55, \"learn_time_ms\": 10569.925, \"total_train_time_s\": 13.090592384338379}", "{\"n\": 4657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3630.84, \"learn_time_ms\": 10508.35, \"total_train_time_s\": 14.287399768829346}", "{\"n\": 4658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3630.84, \"learn_time_ms\": 10542.867, \"total_train_time_s\": 14.676937341690063}", "{\"n\": 4659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3633.07, \"learn_time_ms\": 10470.906, \"total_train_time_s\": 13.663667917251587}", "{\"n\": 4660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3629.3, \"learn_time_ms\": 10568.684, \"total_train_time_s\": 14.666681289672852}", "{\"n\": 4661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.58, \"learn_time_ms\": 10569.395, \"total_train_time_s\": 14.25405740737915}", "{\"n\": 4662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3610.66, \"learn_time_ms\": 10621.601, \"total_train_time_s\": 15.468442440032959}", "{\"n\": 4663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3621.01, \"learn_time_ms\": 10630.336, \"total_train_time_s\": 14.213231801986694}", "{\"n\": 4664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3620.74, \"learn_time_ms\": 10502.033, \"total_train_time_s\": 14.091086626052856}", "{\"n\": 4665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3606.9, \"learn_time_ms\": 10558.166, \"total_train_time_s\": 15.121380090713501}", "{\"n\": 4666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3606.9, \"learn_time_ms\": 10670.856, \"total_train_time_s\": 14.46592092514038}", "{\"n\": 4667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3597.88, \"learn_time_ms\": 10677.775, \"total_train_time_s\": 14.492070436477661}", "{\"n\": 4668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3597.88, \"learn_time_ms\": 10664.789, \"total_train_time_s\": 14.529147148132324}", "{\"n\": 4669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 10729.476, \"total_train_time_s\": 13.966957569122314}", "{\"n\": 4670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3599.63, \"learn_time_ms\": 10635.409, \"total_train_time_s\": 13.727514028549194}", "{\"n\": 4671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3606.21, \"learn_time_ms\": 10575.871, \"total_train_time_s\": 13.924333095550537}", "{\"n\": 4672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3606.21, \"learn_time_ms\": 10479.282, \"total_train_time_s\": 14.258116960525513}", "{\"n\": 4673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 10610.36, \"total_train_time_s\": 15.416820287704468}", "{\"n\": 4674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3576.02, \"learn_time_ms\": 10593.593, \"total_train_time_s\": 13.987831354141235}", "{\"n\": 4675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3577.64, \"learn_time_ms\": 10528.938, \"total_train_time_s\": 14.51297926902771}", "{\"n\": 4676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3586.18, \"learn_time_ms\": 10571.109, \"total_train_time_s\": 14.66339111328125}", "{\"n\": 4677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3586.18, \"learn_time_ms\": 10660.134, \"total_train_time_s\": 15.53896951675415}", "{\"n\": 4678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3586.57, \"learn_time_ms\": 10626.008, \"total_train_time_s\": 14.130687475204468}", "{\"n\": 4679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.13, \"learn_time_ms\": 10546.727, \"total_train_time_s\": 13.43690013885498}", "{\"n\": 4680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.13, \"learn_time_ms\": 10604.582, \"total_train_time_s\": 14.507038593292236}", "{\"n\": 4681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3585.25, \"learn_time_ms\": 10675.056, \"total_train_time_s\": 14.28367280960083}", "{\"n\": 4682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3590.72, \"learn_time_ms\": 10689.557, \"total_train_time_s\": 14.324504137039185}", "{\"n\": 4683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3590.72, \"learn_time_ms\": 10624.432, \"total_train_time_s\": 15.00831151008606}", "{\"n\": 4684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3592.95, \"learn_time_ms\": 10698.022, \"total_train_time_s\": 14.69253134727478}", "{\"n\": 4685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3592.95, \"learn_time_ms\": 10699.363, \"total_train_time_s\": 14.738870620727539}", "{\"n\": 4686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3611.09, \"learn_time_ms\": 10587.842, \"total_train_time_s\": 13.75624418258667}", "{\"n\": 4687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3611.09, \"learn_time_ms\": 10436.428, \"total_train_time_s\": 13.809460163116455}", "{\"n\": 4688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3591.14, \"learn_time_ms\": 10500.722, \"total_train_time_s\": 14.560036897659302}", "{\"n\": 4689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3598.12, \"learn_time_ms\": 10633.237, \"total_train_time_s\": 14.742677927017212}", "{\"n\": 4690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3598.12, \"learn_time_ms\": 10704.233, \"total_train_time_s\": 15.016347646713257}", "{\"n\": 4691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.13, \"learn_time_ms\": 10622.19, \"total_train_time_s\": 13.355783224105835}", "{\"n\": 4692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.22, \"learn_time_ms\": 10556.352, \"total_train_time_s\": 13.595290660858154}", "{\"n\": 4693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.94, \"learn_time_ms\": 10463.705, \"total_train_time_s\": 13.767531633377075}", "{\"n\": 4694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.94, \"learn_time_ms\": 10407.266, \"total_train_time_s\": 14.10868501663208}", "{\"n\": 4695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.94, \"learn_time_ms\": 10361.039, \"total_train_time_s\": 14.119774580001831}", "{\"n\": 4696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3576.27, \"learn_time_ms\": 10418.696, \"total_train_time_s\": 14.194376707077026}", "{\"n\": 4697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3576.27, \"learn_time_ms\": 10521.815, \"total_train_time_s\": 14.956478357315063}", "{\"n\": 4698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3576.07, \"learn_time_ms\": 10356.201, \"total_train_time_s\": 13.265089750289917}", "{\"n\": 4699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3567.75, \"learn_time_ms\": 10442.6, \"total_train_time_s\": 15.405537128448486}", "{\"n\": 4700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3575.38, \"learn_time_ms\": 10328.554, \"total_train_time_s\": 13.82724380493164}", "{\"n\": 4701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10301.513, \"total_train_time_s\": 13.236435890197754}", "{\"n\": 4702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10334.027, \"total_train_time_s\": 14.313454389572144}", "{\"n\": 4703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3592.28, \"learn_time_ms\": 10369.06, \"total_train_time_s\": 14.169621229171753}", "{\"n\": 4704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.12, \"learn_time_ms\": 10396.322, \"total_train_time_s\": 14.523592710494995}", "{\"n\": 4705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.12, \"learn_time_ms\": 10455.905, \"total_train_time_s\": 14.47601056098938}", "{\"n\": 4706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3585.69, \"learn_time_ms\": 10437.355, \"total_train_time_s\": 14.000653505325317}", "{\"n\": 4707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.73, \"learn_time_ms\": 10444.068, \"total_train_time_s\": 15.043947696685791}", "{\"n\": 4708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.73, \"learn_time_ms\": 10583.532, \"total_train_time_s\": 14.868385076522827}", "{\"n\": 4709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3587.89, \"learn_time_ms\": 10381.587, \"total_train_time_s\": 13.36205267906189}", "{\"n\": 4710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3584.53, \"learn_time_ms\": 10566.683, \"total_train_time_s\": 15.601442575454712}", "{\"n\": 4711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3580.38, \"learn_time_ms\": 10673.194, \"total_train_time_s\": 14.400844812393188}", "{\"n\": 4712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3585.21, \"learn_time_ms\": 10772.569, \"total_train_time_s\": 14.911183834075928}", "{\"n\": 4713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3585.21, \"learn_time_ms\": 10823.218, \"total_train_time_s\": 14.828720808029175}", "{\"n\": 4714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3597.94, \"learn_time_ms\": 10812.428, \"total_train_time_s\": 14.187995672225952}", "{\"n\": 4715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3613.32, \"learn_time_ms\": 10728.564, \"total_train_time_s\": 13.708213090896606}", "{\"n\": 4716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3613.32, \"learn_time_ms\": 10845.267, \"total_train_time_s\": 15.17580533027649}", "{\"n\": 4717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.4, \"learn_time_ms\": 10879.636, \"total_train_time_s\": 15.246262788772583}", "{\"n\": 4718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.4, \"learn_time_ms\": 10974.702, \"total_train_time_s\": 15.232423543930054}", "{\"n\": 4719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.08, \"learn_time_ms\": 11026.37, \"total_train_time_s\": 13.902418613433838}", "{\"n\": 4720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.08, \"learn_time_ms\": 10934.815, \"total_train_time_s\": 14.744293689727783}", "{\"n\": 4721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.01, \"learn_time_ms\": 10928.277, \"total_train_time_s\": 14.276539325714111}", "{\"n\": 4722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.01, \"learn_time_ms\": 10873.074, \"total_train_time_s\": 14.470054864883423}", "{\"n\": 4723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3571.84, \"learn_time_ms\": 10867.203, \"total_train_time_s\": 14.847806215286255}", "{\"n\": 4724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3563.96, \"learn_time_ms\": 10883.707, \"total_train_time_s\": 14.482107877731323}", "{\"n\": 4725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3562.13, \"learn_time_ms\": 10977.008, \"total_train_time_s\": 14.83920431137085}", "{\"n\": 4726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3562.13, \"learn_time_ms\": 10881.124, \"total_train_time_s\": 14.357908010482788}", "{\"n\": 4727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3568.07, \"learn_time_ms\": 10717.688, \"total_train_time_s\": 13.684915542602539}", "{\"n\": 4728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3566.26, \"learn_time_ms\": 10696.75, \"total_train_time_s\": 15.219146490097046}", "{\"n\": 4729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3563.19, \"learn_time_ms\": 10784.526, \"total_train_time_s\": 14.911693096160889}", "{\"n\": 4730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3563.19, \"learn_time_ms\": 10740.311, \"total_train_time_s\": 14.519179821014404}", "{\"n\": 4731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3563.19, \"learn_time_ms\": 10716.452, \"total_train_time_s\": 13.92071270942688}", "{\"n\": 4732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3570.79, \"learn_time_ms\": 10576.555, \"total_train_time_s\": 13.020020961761475}", "{\"n\": 4733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3570.79, \"learn_time_ms\": 10491.068, \"total_train_time_s\": 13.991349697113037}", "{\"n\": 4734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3570.79, \"learn_time_ms\": 10403.152, \"total_train_time_s\": 13.744198322296143}", "{\"n\": 4735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10355.521, \"total_train_time_s\": 14.387717008590698}", "{\"n\": 4736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3579.07, \"learn_time_ms\": 10453.283, \"total_train_time_s\": 15.37371039390564}", "{\"n\": 4737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3579.07, \"learn_time_ms\": 10590.188, \"total_train_time_s\": 14.981245756149292}", "{\"n\": 4738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3579.07, \"learn_time_ms\": 10498.616, \"total_train_time_s\": 14.097970962524414}", "{\"n\": 4739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.03, \"learn_time_ms\": 10523.934, \"total_train_time_s\": 15.259697914123535}", "{\"n\": 4740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3605.84, \"learn_time_ms\": 10544.182, \"total_train_time_s\": 14.593428134918213}", "{\"n\": 4741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3605.84, \"learn_time_ms\": 10571.099, \"total_train_time_s\": 14.436396837234497}", "{\"n\": 4742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3603.15, \"learn_time_ms\": 10599.211, \"total_train_time_s\": 13.601426839828491}", "{\"n\": 4743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3603.15, \"learn_time_ms\": 10600.76, \"total_train_time_s\": 13.979235410690308}", "{\"n\": 4744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3591.41, \"learn_time_ms\": 10609.381, \"total_train_time_s\": 13.51402735710144}", "{\"n\": 4745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3594.47, \"learn_time_ms\": 10686.865, \"total_train_time_s\": 14.880879878997803}", "{\"n\": 4746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3594.47, \"learn_time_ms\": 10568.083, \"total_train_time_s\": 14.372029304504395}", "{\"n\": 4747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3601.6, \"learn_time_ms\": 10497.384, \"total_train_time_s\": 14.367433309555054}", "{\"n\": 4748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3623.77, \"learn_time_ms\": 10484.68, \"total_train_time_s\": 14.099288940429688}", "{\"n\": 4749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3616.53, \"learn_time_ms\": 10307.095, \"total_train_time_s\": 13.440192699432373}", "{\"n\": 4750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3607.61, \"learn_time_ms\": 10294.092, \"total_train_time_s\": 14.313872814178467}", "{\"n\": 4751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3603.7, \"learn_time_ms\": 10256.79, \"total_train_time_s\": 14.30778980255127}", "{\"n\": 4752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3607.32, \"learn_time_ms\": 10384.87, \"total_train_time_s\": 14.873323202133179}", "{\"n\": 4753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.18, \"learn_time_ms\": 10434.149, \"total_train_time_s\": 14.23086166381836}", "{\"n\": 4754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3598.13, \"learn_time_ms\": 10456.071, \"total_train_time_s\": 13.985440254211426}", "{\"n\": 4755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3598.13, \"learn_time_ms\": 10436.437, \"total_train_time_s\": 14.874570608139038}", "{\"n\": 4756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3616.26, \"learn_time_ms\": 10535.009, \"total_train_time_s\": 14.965380430221558}", "{\"n\": 4757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.93, \"learn_time_ms\": 10523.716, \"total_train_time_s\": 14.09193229675293}", "{\"n\": 4758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.93, \"learn_time_ms\": 10638.071, \"total_train_time_s\": 15.45840311050415}", "{\"n\": 4759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3624.31, \"learn_time_ms\": 10706.214, \"total_train_time_s\": 14.342900037765503}", "{\"n\": 4760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3624.31, \"learn_time_ms\": 10720.493, \"total_train_time_s\": 14.846696376800537}", "{\"n\": 4761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3629.93, \"learn_time_ms\": 10853.173, \"total_train_time_s\": 15.158327102661133}", "{\"n\": 4762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 10699.502, \"total_train_time_s\": 13.118072748184204}", "{\"n\": 4763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 10645.312, \"total_train_time_s\": 13.699963569641113}", "{\"n\": 4764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3648.46, \"learn_time_ms\": 10657.378, \"total_train_time_s\": 14.110911846160889}", "{\"n\": 4765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3656.67, \"learn_time_ms\": 10584.423, \"total_train_time_s\": 13.991719961166382}", "{\"n\": 4766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3677.52, \"learn_time_ms\": 10405.509, \"total_train_time_s\": 13.354567050933838}", "{\"n\": 4767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3677.52, \"learn_time_ms\": 10342.494, \"total_train_time_s\": 13.603946447372437}", "{\"n\": 4768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.36, \"learn_time_ms\": 10198.82, \"total_train_time_s\": 13.906105518341064}", "{\"n\": 4769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3658.95, \"learn_time_ms\": 10198.444, \"total_train_time_s\": 14.062408685684204}", "{\"n\": 4770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.08, \"learn_time_ms\": 10128.455, \"total_train_time_s\": 14.002686500549316}", "{\"n\": 4771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.08, \"learn_time_ms\": 9983.789, \"total_train_time_s\": 13.857882976531982}", "{\"n\": 4772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3661.72, \"learn_time_ms\": 10081.79, \"total_train_time_s\": 14.04521632194519}", "{\"n\": 4773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3667.27, \"learn_time_ms\": 10116.469, \"total_train_time_s\": 14.005427837371826}", "{\"n\": 4774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3672.41, \"learn_time_ms\": 10088.782, \"total_train_time_s\": 13.853897333145142}", "{\"n\": 4775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.21, \"learn_time_ms\": 10064.388, \"total_train_time_s\": 13.687368869781494}", "{\"n\": 4776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3687.15, \"learn_time_ms\": 10097.724, \"total_train_time_s\": 13.87561321258545}", "{\"n\": 4777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3687.15, \"learn_time_ms\": 10081.446, \"total_train_time_s\": 13.692960500717163}", "{\"n\": 4778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3693.1, \"learn_time_ms\": 10172.551, \"total_train_time_s\": 14.83061933517456}", "{\"n\": 4779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3701.53, \"learn_time_ms\": 10223.831, \"total_train_time_s\": 14.459830522537231}", "{\"n\": 4780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3705.38, \"learn_time_ms\": 10393.019, \"total_train_time_s\": 15.593204736709595}", "{\"n\": 4781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3705.38, \"learn_time_ms\": 10512.721, \"total_train_time_s\": 14.905246019363403}", "{\"n\": 4782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3723.75, \"learn_time_ms\": 10493.839, \"total_train_time_s\": 13.85590124130249}", "{\"n\": 4783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3726.66, \"learn_time_ms\": 10531.906, \"total_train_time_s\": 14.557257890701294}", "{\"n\": 4784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3732.41, \"learn_time_ms\": 10538.374, \"total_train_time_s\": 13.678743839263916}", "{\"n\": 4785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3743.1, \"learn_time_ms\": 10557.696, \"total_train_time_s\": 14.002101182937622}", "{\"n\": 4786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3748.01, \"learn_time_ms\": 10634.323, \"total_train_time_s\": 14.36391019821167}", "{\"n\": 4787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3766.72, \"learn_time_ms\": 10583.529, \"total_train_time_s\": 12.829837083816528}", "{\"n\": 4788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3766.72, \"learn_time_ms\": 10587.973, \"total_train_time_s\": 14.848345279693604}", "{\"n\": 4789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3766.72, \"learn_time_ms\": 10499.652, \"total_train_time_s\": 13.878302812576294}", "{\"n\": 4790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3756.77, \"learn_time_ms\": 10289.632, \"total_train_time_s\": 13.443408727645874}", "{\"n\": 4791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3756.77, \"learn_time_ms\": 10245.252, \"total_train_time_s\": 14.834359645843506}", "{\"n\": 4792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3765.26, \"learn_time_ms\": 10287.896, \"total_train_time_s\": 14.372872829437256}", "{\"n\": 4793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3761.68, \"learn_time_ms\": 10269.967, \"total_train_time_s\": 14.27393388748169}", "{\"n\": 4794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3770.98, \"learn_time_ms\": 10349.09, \"total_train_time_s\": 14.903299808502197}", "{\"n\": 4795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3770.98, \"learn_time_ms\": 10297.339, \"total_train_time_s\": 13.583783626556396}", "{\"n\": 4796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3770.98, \"learn_time_ms\": 10271.001, \"total_train_time_s\": 14.118420362472534}", "{\"n\": 4797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3770.09, \"learn_time_ms\": 10344.565, \"total_train_time_s\": 13.558661222457886}", "{\"n\": 4798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3782.28, \"learn_time_ms\": 10369.112, \"total_train_time_s\": 14.996013164520264}", "{\"n\": 4799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3782.28, \"learn_time_ms\": 10372.62, \"total_train_time_s\": 13.795185089111328}", "{\"n\": 4800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3788.8, \"learn_time_ms\": 10522.731, \"total_train_time_s\": 14.929878234863281}", "{\"n\": 4801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3806.49, \"learn_time_ms\": 10499.137, \"total_train_time_s\": 14.444319009780884}", "{\"n\": 4802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3806.49, \"learn_time_ms\": 10544.566, \"total_train_time_s\": 14.868142366409302}", "{\"n\": 4803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3806.49, \"learn_time_ms\": 10563.076, \"total_train_time_s\": 14.64759612083435}", "{\"n\": 4804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3810.64, \"learn_time_ms\": 10472.971, \"total_train_time_s\": 13.581626653671265}", "{\"n\": 4805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3807.87, \"learn_time_ms\": 10486.024, \"total_train_time_s\": 13.537303686141968}", "{\"n\": 4806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3807.87, \"learn_time_ms\": 10585.632, \"total_train_time_s\": 15.061906576156616}", "{\"n\": 4807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3832.14, \"learn_time_ms\": 10595.416, \"total_train_time_s\": 13.793599128723145}", "{\"n\": 4808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3812.24, \"learn_time_ms\": 10528.11, \"total_train_time_s\": 14.334801435470581}", "{\"n\": 4809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3812.23, \"learn_time_ms\": 10681.821, \"total_train_time_s\": 15.19852900505066}", "{\"n\": 4810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3812.23, \"learn_time_ms\": 10640.042, \"total_train_time_s\": 14.552739381790161}", "{\"n\": 4811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3806.04, \"learn_time_ms\": 10575.858, \"total_train_time_s\": 13.76555871963501}", "{\"n\": 4812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3818.81, \"learn_time_ms\": 10507.597, \"total_train_time_s\": 14.054489850997925}", "{\"n\": 4813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3821.24, \"learn_time_ms\": 10459.5, \"total_train_time_s\": 13.98862886428833}", "{\"n\": 4814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3821.65, \"learn_time_ms\": 10443.422, \"total_train_time_s\": 13.468867301940918}", "{\"n\": 4815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3821.65, \"learn_time_ms\": 10534.723, \"total_train_time_s\": 14.754245042800903}", "{\"n\": 4816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3829.5, \"learn_time_ms\": 10439.967, \"total_train_time_s\": 14.038696050643921}", "{\"n\": 4817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3850.47, \"learn_time_ms\": 10401.498, \"total_train_time_s\": 13.434653043746948}", "{\"n\": 4818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3850.99, \"learn_time_ms\": 10359.19, \"total_train_time_s\": 13.986210823059082}", "{\"n\": 4819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3850.99, \"learn_time_ms\": 10146.056, \"total_train_time_s\": 13.034308910369873}", "{\"n\": 4820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3856.99, \"learn_time_ms\": 10099.064, \"total_train_time_s\": 14.179548025131226}", "{\"n\": 4821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3878.81, \"learn_time_ms\": 10126.019, \"total_train_time_s\": 13.847487688064575}", "{\"n\": 4822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3878.81, \"learn_time_ms\": 10134.01, \"total_train_time_s\": 14.243783235549927}", "{\"n\": 4823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3885.2, \"learn_time_ms\": 10225.905, \"total_train_time_s\": 14.942320108413696}", "{\"n\": 4824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3885.2, \"learn_time_ms\": 10290.569, \"total_train_time_s\": 14.41662073135376}", "{\"n\": 4825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3903.75, \"learn_time_ms\": 10300.453, \"total_train_time_s\": 14.491582155227661}", "{\"n\": 4826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3911.75, \"learn_time_ms\": 10284.187, \"total_train_time_s\": 13.945127010345459}", "{\"n\": 4827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3911.75, \"learn_time_ms\": 10422.842, \"total_train_time_s\": 15.139565229415894}", "{\"n\": 4828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3904.12, \"learn_time_ms\": 10465.206, \"total_train_time_s\": 14.452916622161865}", "{\"n\": 4829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.13, \"learn_time_ms\": 10477.927, \"total_train_time_s\": 13.311815023422241}", "{\"n\": 4830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3890.12, \"learn_time_ms\": 10530.004, \"total_train_time_s\": 14.459283828735352}", "{\"n\": 4831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3890.12, \"learn_time_ms\": 10653.888, \"total_train_time_s\": 15.164586782455444}", "{\"n\": 4832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3884.02, \"learn_time_ms\": 10546.487, \"total_train_time_s\": 13.208635568618774}", "{\"n\": 4833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3890.15, \"learn_time_ms\": 10502.116, \"total_train_time_s\": 14.697829961776733}", "{\"n\": 4834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3909.54, \"learn_time_ms\": 10504.029, \"total_train_time_s\": 14.063396453857422}", "{\"n\": 4835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3909.54, \"learn_time_ms\": 10528.826, \"total_train_time_s\": 14.979366540908813}", "{\"n\": 4836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3909.35, \"learn_time_ms\": 10608.953, \"total_train_time_s\": 14.684779644012451}", "{\"n\": 4837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3904.15, \"learn_time_ms\": 10555.326, \"total_train_time_s\": 14.268010139465332}", "{\"n\": 4838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3907.37, \"learn_time_ms\": 10562.738, \"total_train_time_s\": 14.388219594955444}", "{\"n\": 4839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3907.37, \"learn_time_ms\": 10745.433, \"total_train_time_s\": 15.326438188552856}", "{\"n\": 4840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3899.04, \"learn_time_ms\": 10690.178, \"total_train_time_s\": 14.019405841827393}", "{\"n\": 4841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3911.45, \"learn_time_ms\": 10580.684, \"total_train_time_s\": 14.035738468170166}", "{\"n\": 4842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3918.01, \"learn_time_ms\": 10668.176, \"total_train_time_s\": 13.890233516693115}", "{\"n\": 4843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3914.54, \"learn_time_ms\": 10723.901, \"total_train_time_s\": 14.883792400360107}", "{\"n\": 4844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.1, \"learn_time_ms\": 10812.273, \"total_train_time_s\": 15.09376573562622}", "{\"n\": 4845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.91, \"learn_time_ms\": 10817.566, \"total_train_time_s\": 15.270022630691528}", "{\"n\": 4846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.51, \"learn_time_ms\": 10781.303, \"total_train_time_s\": 14.487437725067139}", "{\"n\": 4847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3909.39, \"learn_time_ms\": 10822.306, \"total_train_time_s\": 14.93699312210083}", "{\"n\": 4848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3909.86, \"learn_time_ms\": 10924.489, \"total_train_time_s\": 15.278328657150269}", "{\"n\": 4849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3910.8, \"learn_time_ms\": 10796.795, \"total_train_time_s\": 13.661865472793579}", "{\"n\": 4850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.87, \"learn_time_ms\": 10832.957, \"total_train_time_s\": 14.418715238571167}", "{\"n\": 4851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3902.8, \"learn_time_ms\": 10904.719, \"total_train_time_s\": 14.92677092552185}", "{\"n\": 4852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3902.8, \"learn_time_ms\": 11045.767, \"total_train_time_s\": 15.522787094116211}", "{\"n\": 4853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.4, \"learn_time_ms\": 10943.076, \"total_train_time_s\": 13.951382398605347}", "{\"n\": 4854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.4, \"learn_time_ms\": 10868.946, \"total_train_time_s\": 14.267940521240234}", "{\"n\": 4855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3901.4, \"learn_time_ms\": 10796.478, \"total_train_time_s\": 14.455317735671997}", "{\"n\": 4856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3916.01, \"learn_time_ms\": 10722.628, \"total_train_time_s\": 13.718861818313599}", "{\"n\": 4857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3912.33, \"learn_time_ms\": 10671.609, \"total_train_time_s\": 14.29311990737915}", "{\"n\": 4858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3912.33, \"learn_time_ms\": 10535.875, \"total_train_time_s\": 14.425246715545654}", "{\"n\": 4859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3912.33, \"learn_time_ms\": 10552.892, \"total_train_time_s\": 14.02858567237854}", "{\"n\": 4860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3916.16, \"learn_time_ms\": 10545.408, \"total_train_time_s\": 14.239742994308472}", "{\"n\": 4861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3893.32, \"learn_time_ms\": 10413.233, \"total_train_time_s\": 13.320061206817627}", "{\"n\": 4862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3886.68, \"learn_time_ms\": 10282.906, \"total_train_time_s\": 14.280117750167847}", "{\"n\": 4863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3876.88, \"learn_time_ms\": 10336.294, \"total_train_time_s\": 14.472766637802124}", "{\"n\": 4864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3876.88, \"learn_time_ms\": 10371.809, \"total_train_time_s\": 14.757449626922607}", "{\"n\": 4865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3913.83, \"learn_time_ms\": 10370.224, \"total_train_time_s\": 14.177651405334473}", "{\"n\": 4866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3913.83, \"learn_time_ms\": 10430.584, \"total_train_time_s\": 14.297924757003784}", "{\"n\": 4867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3929.12, \"learn_time_ms\": 10500.756, \"total_train_time_s\": 14.946557760238647}", "{\"n\": 4868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3924.01, \"learn_time_ms\": 10433.793, \"total_train_time_s\": 13.539438962936401}", "{\"n\": 4869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3924.01, \"learn_time_ms\": 10353.431, \"total_train_time_s\": 13.401590347290039}", "{\"n\": 4870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3912.62, \"learn_time_ms\": 10301.05, \"total_train_time_s\": 13.75386095046997}", "{\"n\": 4871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3912.62, \"learn_time_ms\": 10445.43, \"total_train_time_s\": 14.897064447402954}", "{\"n\": 4872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3911.96, \"learn_time_ms\": 10501.29, \"total_train_time_s\": 14.600232601165771}", "{\"n\": 4873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3913.79, \"learn_time_ms\": 10483.393, \"total_train_time_s\": 14.365563154220581}", "{\"n\": 4874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3914.77, \"learn_time_ms\": 10361.449, \"total_train_time_s\": 13.432612657546997}", "{\"n\": 4875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3919.6, \"learn_time_ms\": 10447.018, \"total_train_time_s\": 15.26271915435791}", "{\"n\": 4876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3939.95, \"learn_time_ms\": 10460.284, \"total_train_time_s\": 14.771508693695068}", "{\"n\": 4877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3937.32, \"learn_time_ms\": 10362.639, \"total_train_time_s\": 13.91079592704773}", "{\"n\": 4878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3947.51, \"learn_time_ms\": 10479.481, \"total_train_time_s\": 14.87816834449768}", "{\"n\": 4879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3947.51, \"learn_time_ms\": 10596.271, \"total_train_time_s\": 14.206770896911621}", "{\"n\": 4880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3934.44, \"learn_time_ms\": 10593.494, \"total_train_time_s\": 13.875716924667358}", "{\"n\": 4881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3931.64, \"learn_time_ms\": 10559.957, \"total_train_time_s\": 14.713415145874023}", "{\"n\": 4882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3931.64, \"learn_time_ms\": 10440.526, \"total_train_time_s\": 13.572449922561646}", "{\"n\": 4883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3933.58, \"learn_time_ms\": 10411.569, \"total_train_time_s\": 14.02632761001587}", "{\"n\": 4884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3924.52, \"learn_time_ms\": 10478.484, \"total_train_time_s\": 14.13985276222229}", "{\"n\": 4885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3924.52, \"learn_time_ms\": 10329.882, \"total_train_time_s\": 13.86684775352478}", "{\"n\": 4886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3922.42, \"learn_time_ms\": 10354.318, \"total_train_time_s\": 14.50635552406311}", "{\"n\": 4887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3915.32, \"learn_time_ms\": 10397.446, \"total_train_time_s\": 14.463318347930908}", "{\"n\": 4888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3925.58, \"learn_time_ms\": 10315.529, \"total_train_time_s\": 14.001251697540283}", "{\"n\": 4889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3925.58, \"learn_time_ms\": 10270.589, \"total_train_time_s\": 13.795536279678345}", "{\"n\": 4890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3934.58, \"learn_time_ms\": 10282.988, \"total_train_time_s\": 13.947440147399902}", "{\"n\": 4891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3944.27, \"learn_time_ms\": 10313.208, \"total_train_time_s\": 15.09106731414795}", "{\"n\": 4892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3920.23, \"learn_time_ms\": 10441.701, \"total_train_time_s\": 14.672744989395142}", "{\"n\": 4893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3920.23, \"learn_time_ms\": 10406.279, \"total_train_time_s\": 13.94304084777832}", "{\"n\": 4894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3931.08, \"learn_time_ms\": 10317.542, \"total_train_time_s\": 13.299272298812866}", "{\"n\": 4895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3935.92, \"learn_time_ms\": 10555.718, \"total_train_time_s\": 16.134464740753174}", "{\"n\": 4896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3945.18, \"learn_time_ms\": 10451.798, \"total_train_time_s\": 13.699779272079468}", "{\"n\": 4897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3945.18, \"learn_time_ms\": 10471.647, \"total_train_time_s\": 14.345634698867798}", "{\"n\": 4898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3937.91, \"learn_time_ms\": 10527.056, \"total_train_time_s\": 14.591262102127075}", "{\"n\": 4899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3932.04, \"learn_time_ms\": 10471.905, \"total_train_time_s\": 13.423191547393799}", "{\"n\": 4900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3932.04, \"learn_time_ms\": 10512.275, \"total_train_time_s\": 14.593223810195923}", "{\"n\": 4901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3921.95, \"learn_time_ms\": 10480.033, \"total_train_time_s\": 14.686755418777466}", "{\"n\": 4902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3921.95, \"learn_time_ms\": 10466.209, \"total_train_time_s\": 14.844179153442383}", "{\"n\": 4903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3917.73, \"learn_time_ms\": 10483.16, \"total_train_time_s\": 13.844342708587646}", "{\"n\": 4904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3916.99, \"learn_time_ms\": 10550.339, \"total_train_time_s\": 13.899109840393066}", "{\"n\": 4905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3916.99, \"learn_time_ms\": 10265.547, \"total_train_time_s\": 13.044373035430908}", "{\"n\": 4906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3929.17, \"learn_time_ms\": 10367.169, \"total_train_time_s\": 14.51695728302002}", "{\"n\": 4907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3927.14, \"learn_time_ms\": 10222.22, \"total_train_time_s\": 13.038416862487793}", "{\"n\": 4908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3928.54, \"learn_time_ms\": 10303.544, \"total_train_time_s\": 14.999096632003784}", "{\"n\": 4909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3917.17, \"learn_time_ms\": 10481.144, \"total_train_time_s\": 14.967415809631348}", "{\"n\": 4910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3905.61, \"learn_time_ms\": 10485.986, \"total_train_time_s\": 14.249009847640991}", "{\"n\": 4911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3903.5, \"learn_time_ms\": 10442.839, \"total_train_time_s\": 14.273439168930054}", "{\"n\": 4912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3894.16, \"learn_time_ms\": 10380.117, \"total_train_time_s\": 14.164153575897217}", "{\"n\": 4913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3887.51, \"learn_time_ms\": 10355.386, \"total_train_time_s\": 13.624531984329224}", "{\"n\": 4914, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3887.51, \"learn_time_ms\": 10349.932, \"total_train_time_s\": 13.887871742248535}", "{\"n\": 4915, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3886.23, \"learn_time_ms\": 10461.776, \"total_train_time_s\": 14.390509128570557}", "{\"n\": 4916, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3895.74, \"learn_time_ms\": 10481.562, \"total_train_time_s\": 14.876675367355347}", "{\"n\": 4917, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3880.31, \"learn_time_ms\": 10588.673, \"total_train_time_s\": 14.266761064529419}", "{\"n\": 4918, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3880.31, \"learn_time_ms\": 10550.842, \"total_train_time_s\": 14.930301427841187}", "{\"n\": 4919, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3899.18, \"learn_time_ms\": 10544.858, \"total_train_time_s\": 15.120155811309814}", "{\"n\": 4920, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3899.18, \"learn_time_ms\": 10607.043, \"total_train_time_s\": 14.959096670150757}", "{\"n\": 4921, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3900.95, \"learn_time_ms\": 10613.74, \"total_train_time_s\": 14.050883293151855}", "{\"n\": 4922, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3886.15, \"learn_time_ms\": 10708.927, \"total_train_time_s\": 14.815988779067993}", "{\"n\": 4923, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3872.56, \"learn_time_ms\": 10743.607, \"total_train_time_s\": 14.176860809326172}", "{\"n\": 4924, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3874.16, \"learn_time_ms\": 10768.296, \"total_train_time_s\": 14.002518653869629}", "{\"n\": 4925, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3869.01, \"learn_time_ms\": 10858.083, \"total_train_time_s\": 15.040831089019775}", "{\"n\": 4926, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3869.01, \"learn_time_ms\": 10721.832, \"total_train_time_s\": 13.55294680595398}", "{\"n\": 4927, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3879.9, \"learn_time_ms\": 10754.627, \"total_train_time_s\": 14.49664831161499}", "{\"n\": 4928, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3880.62, \"learn_time_ms\": 10698.084, \"total_train_time_s\": 14.144855976104736}", "{\"n\": 4929, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.07, \"learn_time_ms\": 10558.614, \"total_train_time_s\": 13.572865009307861}", "{\"n\": 4930, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.07, \"learn_time_ms\": 10533.873, \"total_train_time_s\": 14.741493225097656}", "{\"n\": 4931, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.2, \"learn_time_ms\": 10533.127, \"total_train_time_s\": 14.035706520080566}", "{\"n\": 4932, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3870.71, \"learn_time_ms\": 10472.003, \"total_train_time_s\": 14.24290680885315}", "{\"n\": 4933, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3870.71, \"learn_time_ms\": 10386.042, \"total_train_time_s\": 13.093259811401367}", "{\"n\": 4934, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.18, \"learn_time_ms\": 10455.931, \"total_train_time_s\": 14.76093602180481}", "{\"n\": 4935, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.58, \"learn_time_ms\": 10464.083, \"total_train_time_s\": 15.234715700149536}", "{\"n\": 4936, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.58, \"learn_time_ms\": 10509.235, \"total_train_time_s\": 14.10244107246399}", "{\"n\": 4937, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.32, \"learn_time_ms\": 10522.832, \"total_train_time_s\": 14.651909589767456}", "{\"n\": 4938, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3837.32, \"learn_time_ms\": 10463.117, \"total_train_time_s\": 13.640724897384644}", "{\"n\": 4939, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.81, \"learn_time_ms\": 10454.567, \"total_train_time_s\": 13.58815622329712}", "{\"n\": 4940, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.81, \"learn_time_ms\": 10362.1, \"total_train_time_s\": 13.933591842651367}", "{\"n\": 4941, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.07, \"learn_time_ms\": 10396.26, \"total_train_time_s\": 14.419849872589111}", "{\"n\": 4942, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.07, \"learn_time_ms\": 10351.521, \"total_train_time_s\": 13.963876485824585}", "{\"n\": 4943, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.39, \"learn_time_ms\": 10418.334, \"total_train_time_s\": 13.73141074180603}", "{\"n\": 4944, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.39, \"learn_time_ms\": 10350.083, \"total_train_time_s\": 14.035495281219482}", "{\"n\": 4945, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3835.15, \"learn_time_ms\": 10377.191, \"total_train_time_s\": 15.539413452148438}", "{\"n\": 4946, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.79, \"learn_time_ms\": 10466.168, \"total_train_time_s\": 14.808859586715698}", "{\"n\": 4947, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3861.74, \"learn_time_ms\": 10335.598, \"total_train_time_s\": 13.219107151031494}", "{\"n\": 4948, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3861.74, \"learn_time_ms\": 10366.306, \"total_train_time_s\": 14.013391494750977}", "{\"n\": 4949, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.99, \"learn_time_ms\": 10347.983, \"total_train_time_s\": 13.460426568984985}", "{\"n\": 4950, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.57, \"learn_time_ms\": 10302.89, \"total_train_time_s\": 13.336567163467407}", "{\"n\": 4951, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.57, \"learn_time_ms\": 10328.238, \"total_train_time_s\": 14.74436640739441}", "{\"n\": 4952, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.57, \"learn_time_ms\": 10354.45, \"total_train_time_s\": 14.255841255187988}", "{\"n\": 4953, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3867.78, \"learn_time_ms\": 10518.935, \"total_train_time_s\": 15.652860403060913}", "{\"n\": 4954, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3871.36, \"learn_time_ms\": 10663.697, \"total_train_time_s\": 15.465256452560425}", "{\"n\": 4955, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3877.82, \"learn_time_ms\": 10633.641, \"total_train_time_s\": 15.121440172195435}", "{\"n\": 4956, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3877.82, \"learn_time_ms\": 10581.629, \"total_train_time_s\": 14.321738481521606}", "{\"n\": 4957, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3882.11, \"learn_time_ms\": 10769.423, \"total_train_time_s\": 15.251993894577026}", "{\"n\": 4958, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3887.79, \"learn_time_ms\": 10687.137, \"total_train_time_s\": 12.889042139053345}", "{\"n\": 4959, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3887.79, \"learn_time_ms\": 10875.096, \"total_train_time_s\": 15.157265663146973}", "{\"n\": 4960, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3892.72, \"learn_time_ms\": 10996.888, \"total_train_time_s\": 14.818728923797607}", "{\"n\": 4961, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.8, \"learn_time_ms\": 11072.655, \"total_train_time_s\": 15.432663440704346}", "{\"n\": 4962, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3858.04, \"learn_time_ms\": 11179.556, \"total_train_time_s\": 15.290871381759644}", "{\"n\": 4963, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3858.04, \"learn_time_ms\": 11161.117, \"total_train_time_s\": 15.223942279815674}", "{\"n\": 4964, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.87, \"learn_time_ms\": 10997.312, \"total_train_time_s\": 13.853504419326782}", "{\"n\": 4965, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3873.62, \"learn_time_ms\": 10905.607, \"total_train_time_s\": 14.531902074813843}", "{\"n\": 4966, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3886.51, \"learn_time_ms\": 10957.447, \"total_train_time_s\": 14.901498556137085}", "{\"n\": 4967, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3886.51, \"learn_time_ms\": 10810.692, \"total_train_time_s\": 13.767170906066895}", "{\"n\": 4968, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3885.76, \"learn_time_ms\": 10977.806, \"total_train_time_s\": 14.686334609985352}", "{\"n\": 4969, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3885.76, \"learn_time_ms\": 10943.914, \"total_train_time_s\": 14.987184047698975}", "{\"n\": 4970, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.68, \"learn_time_ms\": 10963.152, \"total_train_time_s\": 14.808604001998901}", "{\"n\": 4971, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3856.34, \"learn_time_ms\": 10820.108, \"total_train_time_s\": 13.936190366744995}", "{\"n\": 4972, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.87, \"learn_time_ms\": 10740.796, \"total_train_time_s\": 14.615896701812744}", "{\"n\": 4973, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.87, \"learn_time_ms\": 10668.516, \"total_train_time_s\": 14.613358497619629}", "{\"n\": 4974, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.87, \"learn_time_ms\": 10684.862, \"total_train_time_s\": 13.928365468978882}", "{\"n\": 4975, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3836.59, \"learn_time_ms\": 10711.358, \"total_train_time_s\": 14.579431295394897}", "{\"n\": 4976, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3842.89, \"learn_time_ms\": 10763.283, \"total_train_time_s\": 15.308367013931274}", "{\"n\": 4977, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3842.89, \"learn_time_ms\": 10718.711, \"total_train_time_s\": 13.33550763130188}", "{\"n\": 4978, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.1, \"learn_time_ms\": 10753.735, \"total_train_time_s\": 15.075860261917114}", "{\"n\": 4979, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.38, \"learn_time_ms\": 10697.183, \"total_train_time_s\": 14.649719715118408}", "{\"n\": 4980, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.38, \"learn_time_ms\": 10607.558, \"total_train_time_s\": 13.999374151229858}", "{\"n\": 4981, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.38, \"learn_time_ms\": 10591.836, \"total_train_time_s\": 13.959683895111084}", "{\"n\": 4982, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.38, \"learn_time_ms\": 10576.934, \"total_train_time_s\": 14.532670736312866}", "{\"n\": 4983, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3858.55, \"learn_time_ms\": 10576.447, \"total_train_time_s\": 14.600504636764526}", "{\"n\": 4984, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3851.67, \"learn_time_ms\": 10688.898, \"total_train_time_s\": 15.252831935882568}", "{\"n\": 4985, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3851.67, \"learn_time_ms\": 10757.326, \"total_train_time_s\": 15.422012090682983}", "{\"n\": 4986, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3851.67, \"learn_time_ms\": 10591.678, \"total_train_time_s\": 13.688291311264038}", "{\"n\": 4987, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.39, \"learn_time_ms\": 10771.724, \"total_train_time_s\": 15.133338451385498}", "{\"n\": 4988, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.39, \"learn_time_ms\": 10580.559, \"total_train_time_s\": 13.501379013061523}", "{\"n\": 4989, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.39, \"learn_time_ms\": 10572.822, \"total_train_time_s\": 14.555665493011475}", "{\"n\": 4990, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.39, \"learn_time_ms\": 10566.392, \"total_train_time_s\": 14.115294933319092}", "{\"n\": 4991, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3852.77, \"learn_time_ms\": 10499.118, \"total_train_time_s\": 13.181794166564941}", "{\"n\": 4992, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.74, \"learn_time_ms\": 10497.869, \"total_train_time_s\": 14.161285400390625}", "{\"n\": 4993, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.74, \"learn_time_ms\": 10364.799, \"total_train_time_s\": 13.202771663665771}", "{\"n\": 4994, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.74, \"learn_time_ms\": 10227.197, \"total_train_time_s\": 13.85640835762024}", "{\"n\": 4995, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.99, \"learn_time_ms\": 10167.085, \"total_train_time_s\": 14.564977407455444}", "{\"n\": 4996, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.71, \"learn_time_ms\": 10228.004, \"total_train_time_s\": 14.10153841972351}", "{\"n\": 4997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.71, \"learn_time_ms\": 10129.807, \"total_train_time_s\": 14.223262310028076}", "{\"n\": 4998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.71, \"learn_time_ms\": 10267.292, \"total_train_time_s\": 14.576992511749268}", "{\"n\": 4999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3852.59, \"learn_time_ms\": 10367.46, \"total_train_time_s\": 15.176764488220215}", "{\"n\": 5000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3871.12, \"learn_time_ms\": 10422.369, \"total_train_time_s\": 14.3091299533844}", "{\"n\": 5001, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3871.12, \"learn_time_ms\": 10495.411, \"total_train_time_s\": 13.851985454559326}", "{\"n\": 5002, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3871.12, \"learn_time_ms\": 10445.01, \"total_train_time_s\": 13.85067343711853}", "{\"n\": 5003, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3872.12, \"learn_time_ms\": 10614.902, \"total_train_time_s\": 15.0931715965271}", "{\"n\": 5004, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3884.03, \"learn_time_ms\": 10621.168, \"total_train_time_s\": 13.943894386291504}", "{\"n\": 5005, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3895.89, \"learn_time_ms\": 10508.999, \"total_train_time_s\": 13.479206323623657}", "{\"n\": 5006, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3895.89, \"learn_time_ms\": 10369.207, \"total_train_time_s\": 12.785729169845581}", "{\"n\": 5007, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3897.77, \"learn_time_ms\": 10332.403, \"total_train_time_s\": 13.571032047271729}", "{\"n\": 5008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3922.26, \"learn_time_ms\": 10307.118, \"total_train_time_s\": 14.179669618606567}", "{\"n\": 5009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3933.16, \"learn_time_ms\": 10154.3, \"total_train_time_s\": 13.855767726898193}", "{\"n\": 5010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3936.26, \"learn_time_ms\": 10066.255, \"total_train_time_s\": 13.563763618469238}", "{\"n\": 5011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3935.7, \"learn_time_ms\": 10083.276, \"total_train_time_s\": 14.379711627960205}", "{\"n\": 5012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3947.47, \"learn_time_ms\": 10089.814, \"total_train_time_s\": 13.856805801391602}", "{\"n\": 5013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3947.47, \"learn_time_ms\": 10041.838, \"total_train_time_s\": 14.39494252204895}", "{\"n\": 5014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3926.39, \"learn_time_ms\": 10073.177, \"total_train_time_s\": 14.381365060806274}", "{\"n\": 5015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3919.9, \"learn_time_ms\": 10142.256, \"total_train_time_s\": 14.084817886352539}", "{\"n\": 5016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3904.42, \"learn_time_ms\": 10297.484, \"total_train_time_s\": 14.371885061264038}", "{\"n\": 5017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3904.42, \"learn_time_ms\": 10450.125, \"total_train_time_s\": 15.342690706253052}", "{\"n\": 5018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3905.0, \"learn_time_ms\": 10466.908, \"total_train_time_s\": 14.595756530761719}", "{\"n\": 5019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3909.4, \"learn_time_ms\": 10590.337, \"total_train_time_s\": 14.849610805511475}", "{\"n\": 5020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3909.4, \"learn_time_ms\": 10635.274, \"total_train_time_s\": 13.838609457015991}", "{\"n\": 5021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3909.4, \"learn_time_ms\": 10646.661, \"total_train_time_s\": 14.417096614837646}", "{\"n\": 5022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3925.0, \"learn_time_ms\": 10659.456, \"total_train_time_s\": 13.86189079284668}", "{\"n\": 5023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3931.01, \"learn_time_ms\": 10582.373, \"total_train_time_s\": 13.77894926071167}", "{\"n\": 5024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3917.12, \"learn_time_ms\": 10537.946, \"total_train_time_s\": 13.631027698516846}", "{\"n\": 5025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3917.12, \"learn_time_ms\": 10528.41, \"total_train_time_s\": 14.281454801559448}", "{\"n\": 5026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3917.12, \"learn_time_ms\": 10507.356, \"total_train_time_s\": 14.458561658859253}", "{\"n\": 5027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3920.64, \"learn_time_ms\": 10394.401, \"total_train_time_s\": 14.072994470596313}", "{\"n\": 5028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3934.71, \"learn_time_ms\": 10332.604, \"total_train_time_s\": 13.887108087539673}", "{\"n\": 5029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3934.71, \"learn_time_ms\": 10355.67, \"total_train_time_s\": 15.319350719451904}", "{\"n\": 5030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3916.94, \"learn_time_ms\": 10349.026, \"total_train_time_s\": 13.943283557891846}", "{\"n\": 5031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3933.18, \"learn_time_ms\": 10387.882, \"total_train_time_s\": 14.720306873321533}", "{\"n\": 5032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3940.72, \"learn_time_ms\": 10441.988, \"total_train_time_s\": 14.645633697509766}", "{\"n\": 5033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3940.72, \"learn_time_ms\": 10468.856, \"total_train_time_s\": 14.300018787384033}", "{\"n\": 5034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3941.28, \"learn_time_ms\": 10554.28, \"total_train_time_s\": 14.6377432346344}", "{\"n\": 5035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3948.93, \"learn_time_ms\": 10545.67, \"total_train_time_s\": 14.228180408477783}", "{\"n\": 5036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3948.93, \"learn_time_ms\": 10543.064, \"total_train_time_s\": 14.005584001541138}", "{\"n\": 5037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3961.44, \"learn_time_ms\": 10591.173, \"total_train_time_s\": 14.458149671554565}", "{\"n\": 5038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3969.29, \"learn_time_ms\": 10617.417, \"total_train_time_s\": 14.186527013778687}", "{\"n\": 5039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3990.33, \"learn_time_ms\": 10427.175, \"total_train_time_s\": 13.174274921417236}", "{\"n\": 5040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3985.42, \"learn_time_ms\": 10367.581, \"total_train_time_s\": 13.391013383865356}", "{\"n\": 5041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3985.42, \"learn_time_ms\": 10294.646, \"total_train_time_s\": 13.898341178894043}", "{\"n\": 5042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3964.09, \"learn_time_ms\": 10264.938, \"total_train_time_s\": 14.126904964447021}", "{\"n\": 5043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3964.09, \"learn_time_ms\": 10344.067, \"total_train_time_s\": 14.70436978340149}", "{\"n\": 5044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3953.2, \"learn_time_ms\": 10217.359, \"total_train_time_s\": 13.278349161148071}", "{\"n\": 5045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3953.04, \"learn_time_ms\": 10247.327, \"total_train_time_s\": 14.482207298278809}", "{\"n\": 5046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3946.42, \"learn_time_ms\": 10302.287, \"total_train_time_s\": 14.63311219215393}", "{\"n\": 5047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3953.07, \"learn_time_ms\": 10231.315, \"total_train_time_s\": 13.725192785263062}", "{\"n\": 5048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3959.13, \"learn_time_ms\": 10229.662, \"total_train_time_s\": 14.132932901382446}", "{\"n\": 5049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3965.06, \"learn_time_ms\": 10285.114, \"total_train_time_s\": 13.98913049697876}", "{\"n\": 5050, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3961.85, \"learn_time_ms\": 10438.337, \"total_train_time_s\": 14.767893075942993}", "{\"n\": 5051, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3961.57, \"learn_time_ms\": 10533.262, \"total_train_time_s\": 14.95012617111206}", "{\"n\": 5052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3962.43, \"learn_time_ms\": 10540.472, \"total_train_time_s\": 14.394668340682983}", "{\"n\": 5053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3955.41, \"learn_time_ms\": 10459.925, \"total_train_time_s\": 13.82229995727539}", "{\"n\": 5054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3969.67, \"learn_time_ms\": 10476.829, \"total_train_time_s\": 13.571573734283447}", "{\"n\": 5055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3979.55, \"learn_time_ms\": 10361.412, \"total_train_time_s\": 13.14336633682251}", "{\"n\": 5056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3974.46, \"learn_time_ms\": 10357.972, \"total_train_time_s\": 14.63523530960083}", "{\"n\": 5057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3974.46, \"learn_time_ms\": 10383.915, \"total_train_time_s\": 13.939927339553833}", "{\"n\": 5058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3970.9, \"learn_time_ms\": 10385.22, \"total_train_time_s\": 14.27550983428955}", "{\"n\": 5059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3980.93, \"learn_time_ms\": 10416.201, \"total_train_time_s\": 14.429454326629639}", "{\"n\": 5060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3979.66, \"learn_time_ms\": 10456.273, \"total_train_time_s\": 15.29755711555481}", "{\"n\": 5061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3958.32, \"learn_time_ms\": 10288.941, \"total_train_time_s\": 13.535409450531006}", "{\"n\": 5062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3958.32, \"learn_time_ms\": 10289.608, \"total_train_time_s\": 14.480772495269775}", "{\"n\": 5063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3951.05, \"learn_time_ms\": 10331.225, \"total_train_time_s\": 14.232855319976807}", "{\"n\": 5064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3961.56, \"learn_time_ms\": 10380.377, \"total_train_time_s\": 14.152953863143921}", "{\"n\": 5065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3966.18, \"learn_time_ms\": 10602.337, \"total_train_time_s\": 15.351205348968506}", "{\"n\": 5066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3966.18, \"learn_time_ms\": 10581.078, \"total_train_time_s\": 14.598029136657715}", "{\"n\": 5067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3977.05, \"learn_time_ms\": 10570.747, \"total_train_time_s\": 14.079843997955322}", "{\"n\": 5068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3975.31, \"learn_time_ms\": 10589.408, \"total_train_time_s\": 14.33109450340271}", "{\"n\": 5069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3976.69, \"learn_time_ms\": 10589.68, \"total_train_time_s\": 14.226954221725464}", "{\"n\": 5070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3976.69, \"learn_time_ms\": 10507.938, \"total_train_time_s\": 14.476730585098267}", "{\"n\": 5071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3979.01, \"learn_time_ms\": 10633.661, \"total_train_time_s\": 14.330081224441528}", "{\"n\": 5072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3990.22, \"learn_time_ms\": 10664.818, \"total_train_time_s\": 14.493345260620117}", "{\"n\": 5073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3994.53, \"learn_time_ms\": 10645.612, \"total_train_time_s\": 14.351775646209717}", "{\"n\": 5074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3994.53, \"learn_time_ms\": 10613.272, \"total_train_time_s\": 13.693966388702393}", "{\"n\": 5075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 4010.17, \"learn_time_ms\": 10526.054, \"total_train_time_s\": 14.548970460891724}", "{\"n\": 5076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3997.8, \"learn_time_ms\": 10627.554, \"total_train_time_s\": 15.447338819503784}", "{\"n\": 5077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3997.8, \"learn_time_ms\": 10678.265, \"total_train_time_s\": 14.610206604003906}", "{\"n\": 5078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3996.48, \"learn_time_ms\": 10664.043, \"total_train_time_s\": 14.408198595046997}", "{\"n\": 5079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3997.77, \"learn_time_ms\": 10597.692, \"total_train_time_s\": 13.370535135269165}", "{\"n\": 5080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3996.16, \"learn_time_ms\": 10576.81, \"total_train_time_s\": 14.193106412887573}", "{\"n\": 5081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3996.16, \"learn_time_ms\": 10524.789, \"total_train_time_s\": 14.050202369689941}", "{\"n\": 5082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3994.38, \"learn_time_ms\": 10442.463, \"total_train_time_s\": 13.83078646659851}", "{\"n\": 5083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3983.95, \"learn_time_ms\": 10430.687, \"total_train_time_s\": 13.87490200996399}", "{\"n\": 5084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3983.95, \"learn_time_ms\": 10548.492, \"total_train_time_s\": 14.997621536254883}", "{\"n\": 5085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3971.27, \"learn_time_ms\": 10422.811, \"total_train_time_s\": 13.476766347885132}", "{\"n\": 5086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3962.16, \"learn_time_ms\": 10241.849, \"total_train_time_s\": 13.889171361923218}", "{\"n\": 5087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3963.65, \"learn_time_ms\": 10261.331, \"total_train_time_s\": 14.855258464813232}", "{\"n\": 5088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3963.65, \"learn_time_ms\": 10266.952, \"total_train_time_s\": 14.504780292510986}", "{\"n\": 5089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3957.86, \"learn_time_ms\": 10405.3, \"total_train_time_s\": 14.848505973815918}", "{\"n\": 5090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3950.85, \"learn_time_ms\": 10484.947, \"total_train_time_s\": 15.000400304794312}", "{\"n\": 5091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3937.57, \"learn_time_ms\": 10556.428, \"total_train_time_s\": 14.69719934463501}", "{\"n\": 5092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3927.35, \"learn_time_ms\": 10604.51, \"total_train_time_s\": 14.27578854560852}", "{\"n\": 5093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3927.35, \"learn_time_ms\": 10654.57, \"total_train_time_s\": 14.540388584136963}", "{\"n\": 5094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3941.42, \"learn_time_ms\": 10638.817, \"total_train_time_s\": 14.852748155593872}", "{\"n\": 5095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3941.42, \"learn_time_ms\": 10742.688, \"total_train_time_s\": 14.388982057571411}", "{\"n\": 5096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3941.42, \"learn_time_ms\": 10775.998, \"total_train_time_s\": 14.08249306678772}", "{\"n\": 5097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3935.8, \"learn_time_ms\": 10934.392, \"total_train_time_s\": 16.44622492790222}", "{\"n\": 5098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3926.12, \"learn_time_ms\": 10895.264, \"total_train_time_s\": 13.705078601837158}", "{\"n\": 5099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3911.83, \"learn_time_ms\": 10824.387, \"total_train_time_s\": 14.389972925186157}", "{\"n\": 5100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3915.81, \"learn_time_ms\": 10827.692, \"total_train_time_s\": 14.818926334381104}", "{\"n\": 5101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3915.81, \"learn_time_ms\": 10727.029, \"total_train_time_s\": 13.68440866470337}", "{\"n\": 5102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3889.18, \"learn_time_ms\": 10801.947, \"total_train_time_s\": 15.000125408172607}", "{\"n\": 5103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3889.18, \"learn_time_ms\": 10715.54, \"total_train_time_s\": 13.653953790664673}", "{\"n\": 5104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3877.19, \"learn_time_ms\": 10586.049, \"total_train_time_s\": 13.686769247055054}", "{\"n\": 5105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3872.01, \"learn_time_ms\": 10592.548, \"total_train_time_s\": 14.400297164916992}", "{\"n\": 5106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3871.88, \"learn_time_ms\": 10508.534, \"total_train_time_s\": 13.323050737380981}", "{\"n\": 5107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3883.56, \"learn_time_ms\": 10253.215, \"total_train_time_s\": 13.675027132034302}", "{\"n\": 5108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3887.31, \"learn_time_ms\": 10296.264, \"total_train_time_s\": 14.096762657165527}", "{\"n\": 5109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3880.29, \"learn_time_ms\": 10328.202, \"total_train_time_s\": 14.542384624481201}", "{\"n\": 5110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3880.06, \"learn_time_ms\": 10234.166, \"total_train_time_s\": 14.102079391479492}", "{\"n\": 5111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3888.1, \"learn_time_ms\": 10311.097, \"total_train_time_s\": 14.536357879638672}", "{\"n\": 5112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3888.1, \"learn_time_ms\": 10234.808, \"total_train_time_s\": 14.350003957748413}", "{\"n\": 5113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3890.27, \"learn_time_ms\": 10131.315, \"total_train_time_s\": 12.789402961730957}", "{\"n\": 5114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3892.12, \"learn_time_ms\": 10217.661, \"total_train_time_s\": 14.2771155834198}", "{\"n\": 5115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3897.44, \"learn_time_ms\": 10156.492, \"total_train_time_s\": 13.846034526824951}", "{\"n\": 5116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3904.58, \"learn_time_ms\": 10241.507, \"total_train_time_s\": 14.043068408966064}", "{\"n\": 5117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.74, \"learn_time_ms\": 10406.192, \"total_train_time_s\": 15.355193138122559}", "{\"n\": 5118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.74, \"learn_time_ms\": 10569.297, \"total_train_time_s\": 15.906491994857788}", "{\"n\": 5119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.74, \"learn_time_ms\": 10661.082, \"total_train_time_s\": 15.643496990203857}", "{\"n\": 5120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3891.35, \"learn_time_ms\": 10672.757, \"total_train_time_s\": 14.157029628753662}", "{\"n\": 5121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3906.19, \"learn_time_ms\": 10588.918, \"total_train_time_s\": 13.530613660812378}", "{\"n\": 5122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3906.19, \"learn_time_ms\": 10575.353, \"total_train_time_s\": 14.501771688461304}", "{\"n\": 5123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3906.19, \"learn_time_ms\": 10722.673, \"total_train_time_s\": 13.98928713798523}", "{\"n\": 5124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3931.63, \"learn_time_ms\": 10739.202, \"total_train_time_s\": 14.381497383117676}", "{\"n\": 5125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3919.91, \"learn_time_ms\": 10747.864, \"total_train_time_s\": 13.863218307495117}", "{\"n\": 5126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3919.09, \"learn_time_ms\": 10762.771, \"total_train_time_s\": 14.43680453300476}", "{\"n\": 5127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3919.09, \"learn_time_ms\": 10618.335, \"total_train_time_s\": 14.16699743270874}", "{\"n\": 5128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3908.56, \"learn_time_ms\": 10536.21, \"total_train_time_s\": 15.016211986541748}", "{\"n\": 5129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3909.66, \"learn_time_ms\": 10407.456, \"total_train_time_s\": 14.22961950302124}", "{\"n\": 5130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3902.88, \"learn_time_ms\": 10456.218, \"total_train_time_s\": 14.71253514289856}", "{\"n\": 5131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3902.88, \"learn_time_ms\": 10549.022, \"total_train_time_s\": 14.357728481292725}", "{\"n\": 5132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.01, \"learn_time_ms\": 10540.268, \"total_train_time_s\": 14.28631329536438}", "{\"n\": 5133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.87, \"learn_time_ms\": 10532.009, \"total_train_time_s\": 14.071051120758057}", "{\"n\": 5134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3900.6, \"learn_time_ms\": 10486.045, \"total_train_time_s\": 14.281505823135376}", "{\"n\": 5135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3900.6, \"learn_time_ms\": 10556.46, \"total_train_time_s\": 14.929009675979614}", "{\"n\": 5136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3902.4, \"learn_time_ms\": 10595.208, \"total_train_time_s\": 14.43667197227478}", "{\"n\": 5137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3885.98, \"learn_time_ms\": 10615.794, \"total_train_time_s\": 14.053405046463013}", "{\"n\": 5138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3891.6, \"learn_time_ms\": 10512.865, \"total_train_time_s\": 14.0032639503479}", "{\"n\": 5139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3891.6, \"learn_time_ms\": 10424.938, \"total_train_time_s\": 13.62234878540039}", "{\"n\": 5140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.15, \"learn_time_ms\": 10407.964, \"total_train_time_s\": 14.473750114440918}", "{\"n\": 5141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.15, \"learn_time_ms\": 10351.039, \"total_train_time_s\": 14.126659154891968}", "{\"n\": 5142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.15, \"learn_time_ms\": 10292.647, \"total_train_time_s\": 13.379714012145996}", "{\"n\": 5143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3916.2, \"learn_time_ms\": 10385.041, \"total_train_time_s\": 14.896785259246826}", "{\"n\": 5144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3905.63, \"learn_time_ms\": 10386.496, \"total_train_time_s\": 13.951247930526733}", "{\"n\": 5145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3910.31, \"learn_time_ms\": 10414.94, \"total_train_time_s\": 14.791875839233398}", "{\"n\": 5146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3896.56, \"learn_time_ms\": 10454.708, \"total_train_time_s\": 15.10144591331482}", "{\"n\": 5147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3893.96, \"learn_time_ms\": 10507.853, \"total_train_time_s\": 14.679033279418945}", "{\"n\": 5148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3899.73, \"learn_time_ms\": 10452.124, \"total_train_time_s\": 13.399430513381958}", "{\"n\": 5149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.32, \"learn_time_ms\": 10537.437, \"total_train_time_s\": 13.978208303451538}", "{\"n\": 5150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.32, \"learn_time_ms\": 10531.423, \"total_train_time_s\": 14.43991470336914}", "{\"n\": 5151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3871.5, \"learn_time_ms\": 10617.891, \"total_train_time_s\": 14.719755411148071}", "{\"n\": 5152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3871.5, \"learn_time_ms\": 10717.812, \"total_train_time_s\": 14.563494682312012}", "{\"n\": 5153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3871.5, \"learn_time_ms\": 10663.535, \"total_train_time_s\": 14.235849857330322}", "{\"n\": 5154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3862.97, \"learn_time_ms\": 10733.04, \"total_train_time_s\": 14.659508228302002}", "{\"n\": 5155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3868.19, \"learn_time_ms\": 10717.643, \"total_train_time_s\": 14.616858005523682}", "{\"n\": 5156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3869.56, \"learn_time_ms\": 10698.963, \"total_train_time_s\": 14.797201871871948}", "{\"n\": 5157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3874.13, \"learn_time_ms\": 10629.28, \"total_train_time_s\": 14.024239301681519}", "{\"n\": 5158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3876.31, \"learn_time_ms\": 10692.969, \"total_train_time_s\": 14.056731224060059}", "{\"n\": 5159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3873.79, \"learn_time_ms\": 10690.87, \"total_train_time_s\": 13.963000535964966}", "{\"n\": 5160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3873.79, \"learn_time_ms\": 10713.196, \"total_train_time_s\": 15.03140139579773}", "{\"n\": 5161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3846.33, \"learn_time_ms\": 10741.901, \"total_train_time_s\": 15.120077133178711}", "{\"n\": 5162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3846.33, \"learn_time_ms\": 10717.726, \"total_train_time_s\": 14.201940774917603}", "{\"n\": 5163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3846.33, \"learn_time_ms\": 10707.956, \"total_train_time_s\": 14.301380395889282}", "{\"n\": 5164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3835.66, \"learn_time_ms\": 10730.956, \"total_train_time_s\": 15.262669324874878}", "{\"n\": 5165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3836.97, \"learn_time_ms\": 10721.253, \"total_train_time_s\": 14.83431601524353}", "{\"n\": 5166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3833.62, \"learn_time_ms\": 10620.686, \"total_train_time_s\": 13.62230110168457}", "{\"n\": 5167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3833.62, \"learn_time_ms\": 10571.907, \"total_train_time_s\": 13.784486055374146}", "{\"n\": 5168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3857.27, \"learn_time_ms\": 10590.294, \"total_train_time_s\": 14.271277904510498}", "{\"n\": 5169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3853.78, \"learn_time_ms\": 10600.747, \"total_train_time_s\": 14.158954381942749}", "{\"n\": 5170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3853.78, \"learn_time_ms\": 10507.36, \"total_train_time_s\": 14.012006521224976}", "{\"n\": 5171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3834.2, \"learn_time_ms\": 10391.254, \"total_train_time_s\": 14.041593313217163}", "{\"n\": 5172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3834.2, \"learn_time_ms\": 10374.104, \"total_train_time_s\": 13.948543310165405}", "{\"n\": 5173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3854.13, \"learn_time_ms\": 10371.223, \"total_train_time_s\": 14.48993468284607}", "{\"n\": 5174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3854.13, \"learn_time_ms\": 10343.692, \"total_train_time_s\": 14.78924036026001}", "{\"n\": 5175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3849.91, \"learn_time_ms\": 10373.36, \"total_train_time_s\": 14.779031038284302}", "{\"n\": 5176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3849.91, \"learn_time_ms\": 10496.672, \"total_train_time_s\": 15.197510957717896}", "{\"n\": 5177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3849.91, \"learn_time_ms\": 10631.94, \"total_train_time_s\": 14.726043224334717}", "{\"n\": 5178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3863.14, \"learn_time_ms\": 10710.199, \"total_train_time_s\": 15.189828872680664}", "{\"n\": 5179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3865.97, \"learn_time_ms\": 10690.699, \"total_train_time_s\": 13.973880290985107}", "{\"n\": 5180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3865.97, \"learn_time_ms\": 10754.834, \"total_train_time_s\": 14.198719263076782}", "{\"n\": 5181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3883.34, \"learn_time_ms\": 10841.802, \"total_train_time_s\": 14.778873920440674}", "{\"n\": 5182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3881.22, \"learn_time_ms\": 10960.672, \"total_train_time_s\": 15.318719863891602}", "{\"n\": 5183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3881.22, \"learn_time_ms\": 11022.734, \"total_train_time_s\": 14.707643508911133}", "{\"n\": 5184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3868.48, \"learn_time_ms\": 10951.628, \"total_train_time_s\": 14.113037586212158}", "{\"n\": 5185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3872.6, \"learn_time_ms\": 10901.392, \"total_train_time_s\": 14.54182767868042}", "{\"n\": 5186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3861.61, \"learn_time_ms\": 10854.037, \"total_train_time_s\": 14.757349491119385}", "{\"n\": 5187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3861.61, \"learn_time_ms\": 10761.323, \"total_train_time_s\": 13.762707233428955}", "{\"n\": 5188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3864.43, \"learn_time_ms\": 10555.217, \"total_train_time_s\": 13.086295366287231}", "{\"n\": 5189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3863.03, \"learn_time_ms\": 10578.183, \"total_train_time_s\": 14.13627552986145}", "{\"n\": 5190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3856.2, \"learn_time_ms\": 10526.765, \"total_train_time_s\": 13.912612676620483}", "{\"n\": 5191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3856.2, \"learn_time_ms\": 10509.46, \"total_train_time_s\": 14.862104177474976}", "{\"n\": 5192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3855.04, \"learn_time_ms\": 10397.458, \"total_train_time_s\": 14.099715232849121}", "{\"n\": 5193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3867.81, \"learn_time_ms\": 10396.566, \"total_train_time_s\": 14.752631187438965}", "{\"n\": 5194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3868.34, \"learn_time_ms\": 10493.951, \"total_train_time_s\": 14.928346633911133}", "{\"n\": 5195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3866.05, \"learn_time_ms\": 10511.545, \"total_train_time_s\": 14.394024133682251}", "{\"n\": 5196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3866.05, \"learn_time_ms\": 10451.108, \"total_train_time_s\": 13.857559204101562}", "{\"n\": 5197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3847.2, \"learn_time_ms\": 10572.345, \"total_train_time_s\": 15.1508207321167}", "{\"n\": 5198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3852.36, \"learn_time_ms\": 10640.492, \"total_train_time_s\": 13.673104286193848}", "{\"n\": 5199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3872.4, \"learn_time_ms\": 10632.612, \"total_train_time_s\": 14.017667293548584}", "{\"n\": 5200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3871.15, \"learn_time_ms\": 10564.173, \"total_train_time_s\": 13.388181686401367}", "{\"n\": 5201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3888.89, \"learn_time_ms\": 10500.493, \"total_train_time_s\": 14.05131983757019}", "{\"n\": 5202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3898.29, \"learn_time_ms\": 10478.281, \"total_train_time_s\": 14.004239559173584}", "{\"n\": 5203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3898.29, \"learn_time_ms\": 10355.182, \"total_train_time_s\": 13.964648962020874}", "{\"n\": 5204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3898.29, \"learn_time_ms\": 10199.595, \"total_train_time_s\": 13.24568223953247}", "{\"n\": 5205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3910.2, \"learn_time_ms\": 10109.04, \"total_train_time_s\": 13.776737451553345}", "{\"n\": 5206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3910.48, \"learn_time_ms\": 10118.591, \"total_train_time_s\": 14.1762216091156}", "{\"n\": 5207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3901.28, \"learn_time_ms\": 10059.382, \"total_train_time_s\": 14.57398796081543}", "{\"n\": 5208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3901.28, \"learn_time_ms\": 10096.82, \"total_train_time_s\": 13.985476732254028}", "{\"n\": 5209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3898.72, \"learn_time_ms\": 10036.229, \"total_train_time_s\": 13.674143552780151}", "{\"n\": 5210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3906.2, \"learn_time_ms\": 10116.087, \"total_train_time_s\": 14.183863878250122}", "{\"n\": 5211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3920.02, \"learn_time_ms\": 10088.581, \"total_train_time_s\": 13.803622007369995}", "{\"n\": 5212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3920.02, \"learn_time_ms\": 10155.576, \"total_train_time_s\": 14.6663978099823}", "{\"n\": 5213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3921.55, \"learn_time_ms\": 10174.705, \"total_train_time_s\": 13.800630331039429}", "{\"n\": 5214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3917.54, \"learn_time_ms\": 10218.335, \"total_train_time_s\": 13.745216846466064}", "{\"n\": 5215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3922.19, \"learn_time_ms\": 10215.939, \"total_train_time_s\": 13.62694525718689}", "{\"n\": 5216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3922.19, \"learn_time_ms\": 10225.531, \"total_train_time_s\": 14.194518804550171}", "{\"n\": 5217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3931.57, \"learn_time_ms\": 10279.75, \"total_train_time_s\": 15.120596408843994}", "{\"n\": 5218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3931.57, \"learn_time_ms\": 10388.003, \"total_train_time_s\": 15.057210922241211}", "{\"n\": 5219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3931.57, \"learn_time_ms\": 10462.66, \"total_train_time_s\": 14.584044218063354}", "{\"n\": 5220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3905.2, \"learn_time_ms\": 10486.39, \"total_train_time_s\": 14.060604572296143}", "{\"n\": 5221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3894.29, \"learn_time_ms\": 10563.777, \"total_train_time_s\": 14.505141258239746}", "{\"n\": 5222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3892.32, \"learn_time_ms\": 10567.841, \"total_train_time_s\": 14.526318788528442}", "{\"n\": 5223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3906.58, \"learn_time_ms\": 10602.099, \"total_train_time_s\": 14.027339696884155}", "{\"n\": 5224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3906.58, \"learn_time_ms\": 10638.248, \"total_train_time_s\": 14.031935214996338}", "{\"n\": 5225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3909.56, \"learn_time_ms\": 10790.652, \"total_train_time_s\": 15.039490938186646}", "{\"n\": 5226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3909.56, \"learn_time_ms\": 10900.068, \"total_train_time_s\": 15.218981981277466}", "{\"n\": 5227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3909.56, \"learn_time_ms\": 10750.252, \"total_train_time_s\": 13.53934931755066}", "{\"n\": 5228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3910.44, \"learn_time_ms\": 10587.973, \"total_train_time_s\": 13.789430856704712}", "{\"n\": 5229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3912.49, \"learn_time_ms\": 10543.241, \"total_train_time_s\": 13.755333662033081}", "{\"n\": 5230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3912.49, \"learn_time_ms\": 10592.213, \"total_train_time_s\": 14.568371295928955}", "{\"n\": 5231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3913.12, \"learn_time_ms\": 10588.772, \"total_train_time_s\": 14.494208812713623}", "{\"n\": 5232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3907.75, \"learn_time_ms\": 10558.474, \"total_train_time_s\": 14.350829362869263}", "{\"n\": 5233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3913.29, \"learn_time_ms\": 10538.173, \"total_train_time_s\": 13.814362525939941}", "{\"n\": 5234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3913.29, \"learn_time_ms\": 10464.091, \"total_train_time_s\": 13.507142782211304}", "{\"n\": 5235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3902.09, \"learn_time_ms\": 10364.733, \"total_train_time_s\": 14.000227689743042}", "{\"n\": 5236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3918.19, \"learn_time_ms\": 10189.31, \"total_train_time_s\": 13.386869192123413}", "{\"n\": 5237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3908.19, \"learn_time_ms\": 10250.243, \"total_train_time_s\": 14.055449724197388}", "{\"n\": 5238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3912.19, \"learn_time_ms\": 10359.005, \"total_train_time_s\": 14.499393939971924}", "{\"n\": 5239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3909.97, \"learn_time_ms\": 10414.82, \"total_train_time_s\": 14.326952457427979}", "{\"n\": 5240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3904.88, \"learn_time_ms\": 10297.26, \"total_train_time_s\": 13.587118864059448}", "{\"n\": 5241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3907.38, \"learn_time_ms\": 10224.833, \"total_train_time_s\": 13.693089962005615}", "{\"n\": 5242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3896.06, \"learn_time_ms\": 10065.302, \"total_train_time_s\": 12.818069219589233}", "{\"n\": 5243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3904.23, \"learn_time_ms\": 10082.562, \"total_train_time_s\": 14.268019437789917}", "{\"n\": 5244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3904.23, \"learn_time_ms\": 10091.75, \"total_train_time_s\": 13.59879446029663}", "{\"n\": 5245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3899.3, \"learn_time_ms\": 10097.053, \"total_train_time_s\": 14.030261516571045}", "{\"n\": 5246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3899.49, \"learn_time_ms\": 10214.688, \"total_train_time_s\": 14.83673644065857}", "{\"n\": 5247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3899.49, \"learn_time_ms\": 10187.277, \"total_train_time_s\": 13.964509963989258}", "{\"n\": 5248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3911.4, \"learn_time_ms\": 10116.787, \"total_train_time_s\": 13.990912675857544}", "{\"n\": 5249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3914.34, \"learn_time_ms\": 10104.299, \"total_train_time_s\": 14.240720272064209}", "{\"n\": 5250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3904.99, \"learn_time_ms\": 10087.378, \"total_train_time_s\": 13.40923261642456}", "{\"n\": 5251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3914.05, \"learn_time_ms\": 10178.48, \"total_train_time_s\": 14.599771738052368}", "{\"n\": 5252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3914.05, \"learn_time_ms\": 10278.285, \"total_train_time_s\": 13.873746156692505}", "{\"n\": 5253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3905.5, \"learn_time_ms\": 10243.472, \"total_train_time_s\": 13.90906548500061}", "{\"n\": 5254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3909.0, \"learn_time_ms\": 10248.458, \"total_train_time_s\": 13.6015145778656}", "{\"n\": 5255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3912.29, \"learn_time_ms\": 10178.255, \"total_train_time_s\": 13.386061191558838}", "{\"n\": 5256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3912.29, \"learn_time_ms\": 10095.32, \"total_train_time_s\": 13.788411617279053}", "{\"n\": 5257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3902.28, \"learn_time_ms\": 10100.257, \"total_train_time_s\": 14.026642560958862}", "{\"n\": 5258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3901.64, \"learn_time_ms\": 10119.389, \"total_train_time_s\": 14.043322801589966}", "{\"n\": 5259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3914.53, \"learn_time_ms\": 10074.15, \"total_train_time_s\": 13.877589464187622}", "{\"n\": 5260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3898.44, \"learn_time_ms\": 10245.062, \"total_train_time_s\": 15.354483842849731}", "{\"n\": 5261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3902.52, \"learn_time_ms\": 10199.002, \"total_train_time_s\": 14.082543849945068}", "{\"n\": 5262, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3890.1, \"learn_time_ms\": 10277.886, \"total_train_time_s\": 14.381890535354614}", "{\"n\": 5263, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3897.1, \"learn_time_ms\": 10349.231, \"total_train_time_s\": 14.53265380859375}", "{\"n\": 5264, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.85, \"learn_time_ms\": 10405.643, \"total_train_time_s\": 14.137341976165771}", "{\"n\": 5265, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.85, \"learn_time_ms\": 10475.695, \"total_train_time_s\": 14.286171913146973}", "{\"n\": 5266, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.85, \"learn_time_ms\": 10504.996, \"total_train_time_s\": 14.25349760055542}", "{\"n\": 5267, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.09, \"learn_time_ms\": 10537.195, \"total_train_time_s\": 14.221250295639038}", "{\"n\": 5268, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.09, \"learn_time_ms\": 10637.631, \"total_train_time_s\": 15.104788064956665}", "{\"n\": 5269, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.09, \"learn_time_ms\": 10786.657, \"total_train_time_s\": 15.268401145935059}", "{\"n\": 5270, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.86, \"learn_time_ms\": 10676.046, \"total_train_time_s\": 14.02934718132019}", "{\"n\": 5271, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3885.54, \"learn_time_ms\": 10638.288, \"total_train_time_s\": 13.766561508178711}", "{\"n\": 5272, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3868.31, \"learn_time_ms\": 10669.297, \"total_train_time_s\": 14.96341609954834}", "{\"n\": 5273, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3869.24, \"learn_time_ms\": 10613.278, \"total_train_time_s\": 14.164577722549438}", "{\"n\": 5274, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3869.45, \"learn_time_ms\": 10645.713, \"total_train_time_s\": 14.492025136947632}", "{\"n\": 5275, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3872.99, \"learn_time_ms\": 10594.479, \"total_train_time_s\": 13.53654432296753}", "{\"n\": 5276, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3881.23, \"learn_time_ms\": 10575.329, \"total_train_time_s\": 14.000231742858887}", "{\"n\": 5277, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3881.23, \"learn_time_ms\": 10553.776, \"total_train_time_s\": 14.177314758300781}", "{\"n\": 5278, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3861.79, \"learn_time_ms\": 10497.996, \"total_train_time_s\": 14.58915400505066}", "{\"n\": 5279, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.11, \"learn_time_ms\": 10342.313, \"total_train_time_s\": 13.97924280166626}", "{\"n\": 5280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.11, \"learn_time_ms\": 10383.319, \"total_train_time_s\": 14.398267269134521}", "{\"n\": 5281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.11, \"learn_time_ms\": 10352.777, \"total_train_time_s\": 13.364693641662598}", "{\"n\": 5282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3889.91, \"learn_time_ms\": 10226.549, \"total_train_time_s\": 13.399523735046387}", "{\"n\": 5283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3889.91, \"learn_time_ms\": 10171.89, \"total_train_time_s\": 13.660563230514526}", "{\"n\": 5284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3889.91, \"learn_time_ms\": 10088.164, \"total_train_time_s\": 13.853121995925903}", "{\"n\": 5285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3880.92, \"learn_time_ms\": 10176.912, \"total_train_time_s\": 14.523777484893799}", "{\"n\": 5286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.19, \"learn_time_ms\": 10129.911, \"total_train_time_s\": 13.388715267181396}", "{\"n\": 5287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3883.19, \"learn_time_ms\": 10275.814, \"total_train_time_s\": 15.768347263336182}", "{\"n\": 5288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3873.79, \"learn_time_ms\": 10154.539, \"total_train_time_s\": 13.51410174369812}", "{\"n\": 5289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3867.12, \"learn_time_ms\": 10204.059, \"total_train_time_s\": 14.600857019424438}", "{\"n\": 5290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3867.12, \"learn_time_ms\": 10289.475, \"total_train_time_s\": 15.59088921546936}", "{\"n\": 5291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3869.62, \"learn_time_ms\": 10314.43, \"total_train_time_s\": 13.688063383102417}", "{\"n\": 5292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3872.71, \"learn_time_ms\": 10377.952, \"total_train_time_s\": 14.10951018333435}", "{\"n\": 5293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3848.05, \"learn_time_ms\": 10413.792, \"total_train_time_s\": 13.630005359649658}", "{\"n\": 5294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3848.05, \"learn_time_ms\": 10424.938, \"total_train_time_s\": 13.682942867279053}", "{\"n\": 5295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3848.05, \"learn_time_ms\": 10435.119, \"total_train_time_s\": 14.816314935684204}", "{\"n\": 5296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3833.64, \"learn_time_ms\": 10481.586, \"total_train_time_s\": 13.827998399734497}", "{\"n\": 5297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3818.14, \"learn_time_ms\": 10309.22, \"total_train_time_s\": 13.729819536209106}", "{\"n\": 5298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3818.14, \"learn_time_ms\": 10456.581, \"total_train_time_s\": 14.858842134475708}", "{\"n\": 5299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3810.86, \"learn_time_ms\": 10473.266, \"total_train_time_s\": 14.359687328338623}", "{\"n\": 5300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.72, \"learn_time_ms\": 10426.897, \"total_train_time_s\": 14.805866479873657}", "{\"n\": 5301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3812.56, \"learn_time_ms\": 10459.254, \"total_train_time_s\": 13.969704389572144}", "{\"n\": 5302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3802.41, \"learn_time_ms\": 10380.443, \"total_train_time_s\": 13.164764404296875}", "{\"n\": 5303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3805.07, \"learn_time_ms\": 10436.276, \"total_train_time_s\": 14.147081136703491}", "{\"n\": 5304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3800.18, \"learn_time_ms\": 10411.476, \"total_train_time_s\": 13.60142183303833}", "{\"n\": 5305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3788.81, \"learn_time_ms\": 10346.815, \"total_train_time_s\": 13.927494525909424}", "{\"n\": 5306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3773.41, \"learn_time_ms\": 10376.009, \"total_train_time_s\": 14.146926403045654}", "{\"n\": 5307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3773.41, \"learn_time_ms\": 10480.088, \"total_train_time_s\": 14.741032600402832}", "{\"n\": 5308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3766.02, \"learn_time_ms\": 10475.219, \"total_train_time_s\": 14.750799179077148}", "{\"n\": 5309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3766.02, \"learn_time_ms\": 10468.249, \"total_train_time_s\": 14.516466617584229}", "{\"n\": 5310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3766.02, \"learn_time_ms\": 10363.929, \"total_train_time_s\": 13.839085102081299}", "{\"n\": 5311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3775.17, \"learn_time_ms\": 10367.476, \"total_train_time_s\": 14.186523675918579}", "{\"n\": 5312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3768.54, \"learn_time_ms\": 10489.68, \"total_train_time_s\": 14.859128952026367}", "{\"n\": 5313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3768.54, \"learn_time_ms\": 10375.869, \"total_train_time_s\": 13.415430307388306}", "{\"n\": 5314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3767.66, \"learn_time_ms\": 10471.984, \"total_train_time_s\": 14.491747617721558}", "{\"n\": 5315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3760.27, \"learn_time_ms\": 10433.57, \"total_train_time_s\": 13.587749719619751}", "{\"n\": 5316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3754.63, \"learn_time_ms\": 10380.134, \"total_train_time_s\": 13.53743839263916}", "{\"n\": 5317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3754.63, \"learn_time_ms\": 10376.316, \"total_train_time_s\": 14.670043706893921}", "{\"n\": 5318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3754.78, \"learn_time_ms\": 10339.998, \"total_train_time_s\": 14.266912937164307}", "{\"n\": 5319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3744.49, \"learn_time_ms\": 10212.949, \"total_train_time_s\": 13.234639406204224}", "{\"n\": 5320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3744.49, \"learn_time_ms\": 10418.766, \"total_train_time_s\": 15.907451152801514}", "{\"n\": 5321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3744.49, \"learn_time_ms\": 10556.758, \"total_train_time_s\": 15.637253046035767}", "{\"n\": 5322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.0, \"learn_time_ms\": 10578.185, \"total_train_time_s\": 14.647215127944946}", "{\"n\": 5323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3736.96, \"learn_time_ms\": 10651.144, \"total_train_time_s\": 13.922746419906616}", "{\"n\": 5324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3736.96, \"learn_time_ms\": 10581.657, \"total_train_time_s\": 14.253202199935913}", "{\"n\": 5325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3736.96, \"learn_time_ms\": 10628.26, \"total_train_time_s\": 14.027950525283813}", "{\"n\": 5326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3751.19, \"learn_time_ms\": 10719.096, \"total_train_time_s\": 14.611599206924438}", "{\"n\": 5327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3752.95, \"learn_time_ms\": 10695.437, \"total_train_time_s\": 14.477549076080322}", "{\"n\": 5328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3779.03, \"learn_time_ms\": 10746.959, \"total_train_time_s\": 14.80172061920166}", "{\"n\": 5329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3779.03, \"learn_time_ms\": 10792.238, \"total_train_time_s\": 13.408641338348389}", "{\"n\": 5330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3770.94, \"learn_time_ms\": 10640.778, \"total_train_time_s\": 14.11249041557312}", "{\"n\": 5331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3764.96, \"learn_time_ms\": 10541.405, \"total_train_time_s\": 14.597863912582397}", "{\"n\": 5332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.5, \"learn_time_ms\": 10573.659, \"total_train_time_s\": 15.162726163864136}", "{\"n\": 5333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.5, \"learn_time_ms\": 10523.772, \"total_train_time_s\": 13.62007188796997}", "{\"n\": 5334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.5, \"learn_time_ms\": 10536.56, \"total_train_time_s\": 14.107205629348755}", "{\"n\": 5335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.24, \"learn_time_ms\": 10611.637, \"total_train_time_s\": 14.821088075637817}", "{\"n\": 5336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3790.5, \"learn_time_ms\": 10657.517, \"total_train_time_s\": 15.094366312026978}", "{\"n\": 5337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3790.5, \"learn_time_ms\": 10520.252, \"total_train_time_s\": 13.250513315200806}", "{\"n\": 5338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3789.9, \"learn_time_ms\": 10367.95, \"total_train_time_s\": 13.735341787338257}", "{\"n\": 5339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3808.35, \"learn_time_ms\": 10423.325, \"total_train_time_s\": 14.248077154159546}", "{\"n\": 5340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3808.35, \"learn_time_ms\": 10437.779, \"total_train_time_s\": 14.668560028076172}", "{\"n\": 5341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3809.67, \"learn_time_ms\": 10345.92, \"total_train_time_s\": 13.690454483032227}", "{\"n\": 5342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.78, \"learn_time_ms\": 10273.607, \"total_train_time_s\": 14.506470918655396}", "{\"n\": 5343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3802.03, \"learn_time_ms\": 10315.749, \"total_train_time_s\": 14.137084245681763}", "{\"n\": 5344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3802.03, \"learn_time_ms\": 10349.197, \"total_train_time_s\": 14.483349561691284}", "{\"n\": 5345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3785.01, \"learn_time_ms\": 10241.082, \"total_train_time_s\": 13.72332215309143}", "{\"n\": 5346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3785.01, \"learn_time_ms\": 10129.974, \"total_train_time_s\": 14.052089929580688}", "{\"n\": 5347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3793.78, \"learn_time_ms\": 10218.975, \"total_train_time_s\": 14.222195386886597}", "{\"n\": 5348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3790.04, \"learn_time_ms\": 10362.807, \"total_train_time_s\": 14.749310970306396}", "{\"n\": 5349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3793.56, \"learn_time_ms\": 10342.642, \"total_train_time_s\": 13.806513547897339}", "{\"n\": 5350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3792.45, \"learn_time_ms\": 10337.569, \"total_train_time_s\": 14.553712368011475}", "{\"n\": 5351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3809.43, \"learn_time_ms\": 10282.471, \"total_train_time_s\": 12.88762903213501}", "{\"n\": 5352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3809.43, \"learn_time_ms\": 10260.65, \"total_train_time_s\": 14.139453172683716}", "{\"n\": 5353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3790.14, \"learn_time_ms\": 10364.018, \"total_train_time_s\": 14.846037149429321}", "{\"n\": 5354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3798.8, \"learn_time_ms\": 10443.602, \"total_train_time_s\": 15.33788776397705}", "{\"n\": 5355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3808.31, \"learn_time_ms\": 10326.767, \"total_train_time_s\": 12.737134456634521}", "{\"n\": 5356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3808.31, \"learn_time_ms\": 10261.37, \"total_train_time_s\": 13.675299882888794}", "{\"n\": 5357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3820.55, \"learn_time_ms\": 10257.167, \"total_train_time_s\": 13.993201971054077}", "{\"n\": 5358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3806.95, \"learn_time_ms\": 10143.884, \"total_train_time_s\": 13.610406875610352}", "{\"n\": 5359, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3809.72, \"learn_time_ms\": 10119.175, \"total_train_time_s\": 13.572934627532959}", "{\"n\": 5360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3809.72, \"learn_time_ms\": 10105.704, \"total_train_time_s\": 14.064254999160767}", "{\"n\": 5361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3798.53, \"learn_time_ms\": 10253.692, \"total_train_time_s\": 14.484515190124512}", "{\"n\": 5362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3795.24, \"learn_time_ms\": 10214.589, \"total_train_time_s\": 13.731852531433105}", "{\"n\": 5363, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3795.59, \"learn_time_ms\": 10125.443, \"total_train_time_s\": 13.964601278305054}", "{\"n\": 5364, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3786.03, \"learn_time_ms\": 10151.604, \"total_train_time_s\": 15.226264953613281}", "{\"n\": 5365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3786.03, \"learn_time_ms\": 10394.296, \"total_train_time_s\": 15.305840492248535}", "{\"n\": 5366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3789.04, \"learn_time_ms\": 10498.229, \"total_train_time_s\": 14.400891780853271}", "{\"n\": 5367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3795.79, \"learn_time_ms\": 10457.257, \"total_train_time_s\": 13.766496658325195}", "{\"n\": 5368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3788.77, \"learn_time_ms\": 10437.591, \"total_train_time_s\": 13.501310586929321}", "{\"n\": 5369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3773.68, \"learn_time_ms\": 10478.188, \"total_train_time_s\": 14.08043384552002}", "{\"n\": 5370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3776.44, \"learn_time_ms\": 10417.229, \"total_train_time_s\": 13.736616373062134}", "{\"n\": 5371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3782.02, \"learn_time_ms\": 10401.576, \"total_train_time_s\": 14.306310892105103}", "{\"n\": 5372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3782.02, \"learn_time_ms\": 10436.177, \"total_train_time_s\": 14.220194816589355}", "{\"n\": 5373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3777.71, \"learn_time_ms\": 10455.007, \"total_train_time_s\": 14.188088417053223}", "{\"n\": 5374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3771.59, \"learn_time_ms\": 10310.269, \"total_train_time_s\": 13.889219045639038}", "{\"n\": 5375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3770.54, \"learn_time_ms\": 10249.928, \"total_train_time_s\": 14.698030471801758}", "{\"n\": 5376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3760.55, \"learn_time_ms\": 10320.391, \"total_train_time_s\": 14.915591716766357}", "{\"n\": 5377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3773.11, \"learn_time_ms\": 10377.298, \"total_train_time_s\": 14.136354207992554}", "{\"n\": 5378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3778.73, \"learn_time_ms\": 10386.763, \"total_train_time_s\": 13.473280906677246}", "{\"n\": 5379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3764.08, \"learn_time_ms\": 10343.66, \"total_train_time_s\": 13.595054864883423}", "{\"n\": 5380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3761.02, \"learn_time_ms\": 10475.21, \"total_train_time_s\": 14.856058835983276}", "{\"n\": 5381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3764.56, \"learn_time_ms\": 10489.524, \"total_train_time_s\": 14.487331867218018}", "{\"n\": 5382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3764.56, \"learn_time_ms\": 10470.141, \"total_train_time_s\": 13.898255586624146}", "{\"n\": 5383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3759.46, \"learn_time_ms\": 10404.578, \"total_train_time_s\": 13.78455400466919}", "{\"n\": 5384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3759.98, \"learn_time_ms\": 10450.938, \"total_train_time_s\": 14.358893156051636}", "{\"n\": 5385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3757.12, \"learn_time_ms\": 10417.525, \"total_train_time_s\": 14.01204800605774}", "{\"n\": 5386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3750.86, \"learn_time_ms\": 10348.917, \"total_train_time_s\": 14.166974067687988}", "{\"n\": 5387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3750.86, \"learn_time_ms\": 10392.113, \"total_train_time_s\": 14.676378726959229}", "{\"n\": 5388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3748.08, \"learn_time_ms\": 10406.538, \"total_train_time_s\": 13.857157945632935}", "{\"n\": 5389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3768.2, \"learn_time_ms\": 10511.408, \"total_train_time_s\": 14.631378889083862}", "{\"n\": 5390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3764.02, \"learn_time_ms\": 10392.223, \"total_train_time_s\": 13.760954856872559}", "{\"n\": 5391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3764.02, \"learn_time_ms\": 10200.811, \"total_train_time_s\": 12.773967504501343}", "{\"n\": 5392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3757.18, \"learn_time_ms\": 9885.707, \"total_train_time_s\": 10.846361637115479}", "{\"n\": 5393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3757.6, \"learn_time_ms\": 9982.906, \"total_train_time_s\": 14.557382345199585}", "{\"n\": 5394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3757.6, \"learn_time_ms\": 10035.285, \"total_train_time_s\": 14.988280057907104}", "{\"n\": 5395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3745.76, \"learn_time_ms\": 9987.095, \"total_train_time_s\": 13.504098892211914}", "{\"n\": 5396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3755.9, \"learn_time_ms\": 9940.528, \"total_train_time_s\": 13.759223937988281}", "{\"n\": 5397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3746.64, \"learn_time_ms\": 9904.944, \"total_train_time_s\": 14.189751863479614}", "{\"n\": 5398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3744.0, \"learn_time_ms\": 10012.315, \"total_train_time_s\": 14.828748226165771}", "{\"n\": 5399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3750.82, \"learn_time_ms\": 10079.933, \"total_train_time_s\": 15.363981008529663}", "{\"n\": 5400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3750.82, \"learn_time_ms\": 10217.381, \"total_train_time_s\": 15.028142213821411}", "{\"n\": 5401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3743.77, \"learn_time_ms\": 10410.436, \"total_train_time_s\": 14.371218204498291}", "{\"n\": 5402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3743.77, \"learn_time_ms\": 10760.435, \"total_train_time_s\": 14.293888330459595}", "{\"n\": 5403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3733.83, \"learn_time_ms\": 10734.067, \"total_train_time_s\": 14.138915061950684}", "{\"n\": 5404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3739.88, \"learn_time_ms\": 10570.241, \"total_train_time_s\": 13.137216091156006}", "{\"n\": 5405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3741.15, \"learn_time_ms\": 10576.859, \"total_train_time_s\": 13.729156255722046}", "{\"n\": 5406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3742.94, \"learn_time_ms\": 10642.539, \"total_train_time_s\": 14.620282888412476}", "{\"n\": 5407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3750.94, \"learn_time_ms\": 10684.286, \"total_train_time_s\": 14.570091009140015}", "{\"n\": 5408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3748.75, \"learn_time_ms\": 10582.577, \"total_train_time_s\": 13.803566932678223}", "{\"n\": 5409, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3741.72, \"learn_time_ms\": 10389.19, \"total_train_time_s\": 13.48054552078247}", "{\"n\": 5410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3735.03, \"learn_time_ms\": 10329.59, \"total_train_time_s\": 14.386541366577148}", "{\"n\": 5411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3735.03, \"learn_time_ms\": 10287.435, \"total_train_time_s\": 14.025609016418457}", "{\"n\": 5412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3724.85, \"learn_time_ms\": 10265.658, \"total_train_time_s\": 14.061686038970947}", "{\"n\": 5413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3716.11, \"learn_time_ms\": 10318.25, \"total_train_time_s\": 14.640568494796753}", "{\"n\": 5414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3716.11, \"learn_time_ms\": 10310.09, \"total_train_time_s\": 13.027525901794434}", "{\"n\": 5415, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3706.87, \"learn_time_ms\": 10419.818, \"total_train_time_s\": 14.935961961746216}", "{\"n\": 5416, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3695.76, \"learn_time_ms\": 10350.81, \"total_train_time_s\": 13.775519609451294}", "{\"n\": 5417, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3695.76, \"learn_time_ms\": 10264.104, \"total_train_time_s\": 13.913158655166626}", "{\"n\": 5418, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3684.05, \"learn_time_ms\": 10332.28, \"total_train_time_s\": 14.502110481262207}", "{\"n\": 5419, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3666.0, \"learn_time_ms\": 10409.984, \"total_train_time_s\": 14.257509231567383}", "{\"n\": 5420, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3669.9, \"learn_time_ms\": 10487.484, \"total_train_time_s\": 15.132145166397095}", "{\"n\": 5421, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3669.9, \"learn_time_ms\": 10521.28, \"total_train_time_s\": 14.747355699539185}", "{\"n\": 5422, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3669.9, \"learn_time_ms\": 10644.597, \"total_train_time_s\": 15.158745527267456}", "{\"n\": 5423, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3648.56, \"learn_time_ms\": 10566.482, \"total_train_time_s\": 13.821701049804688}", "{\"n\": 5424, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.8, \"learn_time_ms\": 10687.746, \"total_train_time_s\": 14.380675077438354}", "{\"n\": 5425, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.8, \"learn_time_ms\": 10524.305, \"total_train_time_s\": 13.414876937866211}", "{\"n\": 5426, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.8, \"learn_time_ms\": 10533.904, \"total_train_time_s\": 14.081483125686646}", "{\"n\": 5427, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3643.01, \"learn_time_ms\": 10554.319, \"total_train_time_s\": 14.132181882858276}", "{\"n\": 5428, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3626.49, \"learn_time_ms\": 10480.614, \"total_train_time_s\": 13.642729997634888}", "{\"n\": 5429, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3626.49, \"learn_time_ms\": 10516.937, \"total_train_time_s\": 14.671651363372803}", "{\"n\": 5430, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3618.3, \"learn_time_ms\": 10566.68, \"total_train_time_s\": 15.793251037597656}", "{\"n\": 5431, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 10487.566, \"total_train_time_s\": 13.66662311553955}", "{\"n\": 5432, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3625.53, \"learn_time_ms\": 10393.326, \"total_train_time_s\": 14.456173658370972}", "{\"n\": 5433, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.64, \"learn_time_ms\": 10427.989, \"total_train_time_s\": 14.177849769592285}", "{\"n\": 5434, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.64, \"learn_time_ms\": 10337.088, \"total_train_time_s\": 13.387918710708618}", "{\"n\": 5435, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3622.45, \"learn_time_ms\": 10376.215, \"total_train_time_s\": 13.64404559135437}", "{\"n\": 5436, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3622.45, \"learn_time_ms\": 10423.216, \"total_train_time_s\": 14.389880418777466}", "{\"n\": 5437, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3611.97, \"learn_time_ms\": 10420.696, \"total_train_time_s\": 13.89725136756897}", "{\"n\": 5438, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3607.59, \"learn_time_ms\": 10446.344, \"total_train_time_s\": 13.869828224182129}", "{\"n\": 5439, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3607.59, \"learn_time_ms\": 10451.881, \"total_train_time_s\": 14.752502202987671}", "{\"n\": 5440, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3607.59, \"learn_time_ms\": 10412.858, \"total_train_time_s\": 15.531893968582153}", "{\"n\": 5441, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3599.57, \"learn_time_ms\": 10375.388, \"total_train_time_s\": 13.329970121383667}", "{\"n\": 5442, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3607.72, \"learn_time_ms\": 10444.196, \"total_train_time_s\": 15.004607915878296}", "{\"n\": 5443, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3594.71, \"learn_time_ms\": 10440.6, \"total_train_time_s\": 14.133562326431274}", "{\"n\": 5444, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3594.71, \"learn_time_ms\": 10550.076, \"total_train_time_s\": 14.394936800003052}", "{\"n\": 5445, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3587.9, \"learn_time_ms\": 10583.448, \"total_train_time_s\": 13.75160837173462}", "{\"n\": 5446, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3587.9, \"learn_time_ms\": 10649.513, \"total_train_time_s\": 14.89614224433899}", "{\"n\": 5447, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3599.14, \"learn_time_ms\": 10669.721, \"total_train_time_s\": 14.250728368759155}", "{\"n\": 5448, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10782.686, \"total_train_time_s\": 14.961079359054565}", "{\"n\": 5449, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3595.78, \"learn_time_ms\": 10746.372, \"total_train_time_s\": 14.355062007904053}", "{\"n\": 5450, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3597.99, \"learn_time_ms\": 10590.587, \"total_train_time_s\": 13.756173849105835}", "{\"n\": 5451, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3597.99, \"learn_time_ms\": 10714.992, \"total_train_time_s\": 14.895862817764282}", "{\"n\": 5452, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3592.82, \"learn_time_ms\": 10611.593, \"total_train_time_s\": 13.93359661102295}", "{\"n\": 5453, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3589.05, \"learn_time_ms\": 10590.349, \"total_train_time_s\": 14.087322235107422}", "{\"n\": 5454, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3604.86, \"learn_time_ms\": 10549.074, \"total_train_time_s\": 14.377989053726196}", "{\"n\": 5455, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3611.16, \"learn_time_ms\": 10692.403, \"total_train_time_s\": 15.285812854766846}", "{\"n\": 5456, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3611.16, \"learn_time_ms\": 10638.76, \"total_train_time_s\": 14.38182783126831}", "{\"n\": 5457, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3616.1, \"learn_time_ms\": 10607.427, \"total_train_time_s\": 13.827874898910522}", "{\"n\": 5458, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.25, \"learn_time_ms\": 10469.23, \"total_train_time_s\": 13.586239337921143}", "{\"n\": 5459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.74, \"learn_time_ms\": 10548.686, \"total_train_time_s\": 14.934196710586548}", "{\"n\": 5460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.74, \"learn_time_ms\": 10502.433, \"total_train_time_s\": 13.504899263381958}", "{\"n\": 5461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 10570.295, \"total_train_time_s\": 15.280280590057373}", "{\"n\": 5462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 10583.728, \"total_train_time_s\": 14.20430064201355}", "{\"n\": 5463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3656.33, \"learn_time_ms\": 10571.971, \"total_train_time_s\": 14.001282453536987}", "{\"n\": 5464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3659.17, \"learn_time_ms\": 10557.834, \"total_train_time_s\": 14.040505647659302}", "{\"n\": 5465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.96, \"learn_time_ms\": 10367.18, \"total_train_time_s\": 13.48334002494812}", "{\"n\": 5466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3645.06, \"learn_time_ms\": 10288.295, \"total_train_time_s\": 13.649136781692505}", "{\"n\": 5467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3650.92, \"learn_time_ms\": 10312.91, \"total_train_time_s\": 13.985612392425537}", "{\"n\": 5468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3646.56, \"learn_time_ms\": 10273.359, \"total_train_time_s\": 13.303245544433594}", "{\"n\": 5469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3632.29, \"learn_time_ms\": 10183.383, \"total_train_time_s\": 14.081896781921387}", "{\"n\": 5470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3632.29, \"learn_time_ms\": 10333.993, \"total_train_time_s\": 15.09135365486145}", "{\"n\": 5471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3652.37, \"learn_time_ms\": 10208.246, \"total_train_time_s\": 14.206677675247192}", "{\"n\": 5472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3654.01, \"learn_time_ms\": 10243.77, \"total_train_time_s\": 14.672107934951782}", "{\"n\": 5473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3666.98, \"learn_time_ms\": 10392.686, \"total_train_time_s\": 15.562280654907227}", "{\"n\": 5474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3671.69, \"learn_time_ms\": 10465.472, \"total_train_time_s\": 14.717168092727661}", "{\"n\": 5475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3677.96, \"learn_time_ms\": 10608.663, \"total_train_time_s\": 15.003694295883179}", "{\"n\": 5476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3688.05, \"learn_time_ms\": 10655.646, \"total_train_time_s\": 14.335781574249268}", "{\"n\": 5477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3693.37, \"learn_time_ms\": 10699.251, \"total_train_time_s\": 14.897518634796143}", "{\"n\": 5478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3689.63, \"learn_time_ms\": 10723.936, \"total_train_time_s\": 13.841560125350952}", "{\"n\": 5479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3690.37, \"learn_time_ms\": 10653.869, \"total_train_time_s\": 13.616403579711914}", "{\"n\": 5480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3670.85, \"learn_time_ms\": 10675.139, \"total_train_time_s\": 15.358960151672363}", "{\"n\": 5481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3670.61, \"learn_time_ms\": 10740.957, \"total_train_time_s\": 14.554305076599121}", "{\"n\": 5482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3670.61, \"learn_time_ms\": 10732.748, \"total_train_time_s\": 14.598944425582886}", "{\"n\": 5483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3670.81, \"learn_time_ms\": 10718.94, \"total_train_time_s\": 15.39463996887207}", "{\"n\": 5484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3670.48, \"learn_time_ms\": 10722.655, \"total_train_time_s\": 14.752725601196289}", "{\"n\": 5485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 10692.983, \"total_train_time_s\": 14.73801064491272}", "{\"n\": 5486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 10745.712, \"total_train_time_s\": 14.58948302268982}", "{\"n\": 5487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3655.15, \"learn_time_ms\": 10683.906, \"total_train_time_s\": 14.108303308486938}", "{\"n\": 5488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3655.82, \"learn_time_ms\": 10712.423, \"total_train_time_s\": 13.999954223632812}", "{\"n\": 5489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3662.99, \"learn_time_ms\": 10666.072, \"total_train_time_s\": 13.08843445777893}", "{\"n\": 5490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3662.99, \"learn_time_ms\": 10569.381, \"total_train_time_s\": 14.21236515045166}", "{\"n\": 5491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3675.23, \"learn_time_ms\": 10569.395, \"total_train_time_s\": 14.493034839630127}", "{\"n\": 5492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3693.79, \"learn_time_ms\": 10512.57, \"total_train_time_s\": 13.972985744476318}", "{\"n\": 5493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3693.79, \"learn_time_ms\": 10465.786, \"total_train_time_s\": 14.748144626617432}", "{\"n\": 5494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3703.5, \"learn_time_ms\": 10379.513, \"total_train_time_s\": 13.889287948608398}", "{\"n\": 5495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3703.5, \"learn_time_ms\": 10251.019, \"total_train_time_s\": 13.172447919845581}", "{\"n\": 5496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3696.69, \"learn_time_ms\": 10178.11, \"total_train_time_s\": 13.987493991851807}", "{\"n\": 5497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3685.98, \"learn_time_ms\": 10092.119, \"total_train_time_s\": 13.069464445114136}", "{\"n\": 5498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3673.21, \"learn_time_ms\": 10062.888, \"total_train_time_s\": 13.596285104751587}", "{\"n\": 5499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3666.29, \"learn_time_ms\": 10131.728, \"total_train_time_s\": 13.562446355819702}", "{\"n\": 5500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3670.35, \"learn_time_ms\": 10057.537, \"total_train_time_s\": 13.346286296844482}", "{\"n\": 5501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.52, \"learn_time_ms\": 10021.428, \"total_train_time_s\": 14.238805294036865}", "{\"n\": 5502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3704.33, \"learn_time_ms\": 9916.21, \"total_train_time_s\": 12.758575916290283}", "{\"n\": 5503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3708.92, \"learn_time_ms\": 9859.229, \"total_train_time_s\": 14.27886962890625}", "{\"n\": 5504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3708.92, \"learn_time_ms\": 9820.07, \"total_train_time_s\": 13.3414945602417}", "{\"n\": 5505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3708.92, \"learn_time_ms\": 9872.123, \"total_train_time_s\": 13.954763412475586}", "{\"n\": 5506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 9902.572, \"total_train_time_s\": 14.176479816436768}", "{\"n\": 5507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 10080.174, \"total_train_time_s\": 14.917133569717407}", "{\"n\": 5508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3731.82, \"learn_time_ms\": 10149.175, \"total_train_time_s\": 14.25817060470581}", "{\"n\": 5509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.52, \"learn_time_ms\": 10233.77, \"total_train_time_s\": 14.493776082992554}", "{\"n\": 5510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.52, \"learn_time_ms\": 10354.422, \"total_train_time_s\": 14.567532062530518}", "{\"n\": 5511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.52, \"learn_time_ms\": 10452.147, \"total_train_time_s\": 15.488006114959717}", "{\"n\": 5512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3770.04, \"learn_time_ms\": 10650.751, \"total_train_time_s\": 14.907923698425293}", "{\"n\": 5513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3770.55, \"learn_time_ms\": 10696.573, \"total_train_time_s\": 14.706578731536865}", "{\"n\": 5514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3768.66, \"learn_time_ms\": 10700.744, \"total_train_time_s\": 13.410859107971191}", "{\"n\": 5515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3768.66, \"learn_time_ms\": 10686.187, \"total_train_time_s\": 13.750545263290405}", "{\"n\": 5516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3764.49, \"learn_time_ms\": 10685.471, \"total_train_time_s\": 14.322508811950684}", "{\"n\": 5517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3778.0, \"learn_time_ms\": 10563.347, \"total_train_time_s\": 13.907520532608032}", "{\"n\": 5518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3778.0, \"learn_time_ms\": 10522.916, \"total_train_time_s\": 13.835871934890747}", "{\"n\": 5519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3779.81, \"learn_time_ms\": 10530.343, \"total_train_time_s\": 14.522192001342773}", "{\"n\": 5520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.63, \"learn_time_ms\": 10629.341, \"total_train_time_s\": 15.435227155685425}", "{\"n\": 5521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3783.75, \"learn_time_ms\": 10486.252, \"total_train_time_s\": 13.892037630081177}", "{\"n\": 5522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.82, \"learn_time_ms\": 10464.709, \"total_train_time_s\": 14.61616826057434}", "{\"n\": 5523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.82, \"learn_time_ms\": 10329.09, \"total_train_time_s\": 13.181679010391235}", "{\"n\": 5524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3789.39, \"learn_time_ms\": 10501.0, \"total_train_time_s\": 15.507397174835205}", "{\"n\": 5525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3775.7, \"learn_time_ms\": 10510.508, \"total_train_time_s\": 13.868303775787354}", "{\"n\": 5526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3753.71, \"learn_time_ms\": 10388.707, \"total_train_time_s\": 12.975327968597412}", "{\"n\": 5527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3753.71, \"learn_time_ms\": 10460.505, \"total_train_time_s\": 14.679332494735718}", "{\"n\": 5528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.27, \"learn_time_ms\": 10517.134, \"total_train_time_s\": 14.53739857673645}", "{\"n\": 5529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3785.21, \"learn_time_ms\": 10417.232, \"total_train_time_s\": 13.69465947151184}", "{\"n\": 5530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3785.21, \"learn_time_ms\": 10215.637, \"total_train_time_s\": 13.83303427696228}", "{\"n\": 5531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3796.4, \"learn_time_ms\": 10178.267, \"total_train_time_s\": 13.272378206253052}", "{\"n\": 5532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.07, \"learn_time_ms\": 10122.553, \"total_train_time_s\": 14.12059736251831}", "{\"n\": 5533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3813.45, \"learn_time_ms\": 10170.817, \"total_train_time_s\": 14.133369207382202}", "{\"n\": 5534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3815.68, \"learn_time_ms\": 10041.968, \"total_train_time_s\": 14.03021502494812}", "{\"n\": 5535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3811.48, \"learn_time_ms\": 10087.799, \"total_train_time_s\": 14.141367197036743}", "{\"n\": 5536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.66, \"learn_time_ms\": 10249.385, \"total_train_time_s\": 14.516790628433228}", "{\"n\": 5537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3807.75, \"learn_time_ms\": 10222.818, \"total_train_time_s\": 14.089265823364258}", "{\"n\": 5538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3805.96, \"learn_time_ms\": 10151.997, \"total_train_time_s\": 13.93448519706726}", "{\"n\": 5539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3796.21, \"learn_time_ms\": 10133.131, \"total_train_time_s\": 13.365541696548462}", "{\"n\": 5540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3800.84, \"learn_time_ms\": 10323.185, \"total_train_time_s\": 15.40339469909668}", "{\"n\": 5541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3774.34, \"learn_time_ms\": 10388.857, \"total_train_time_s\": 14.129050493240356}", "{\"n\": 5542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3773.78, \"learn_time_ms\": 10432.34, \"total_train_time_s\": 14.57624363899231}", "{\"n\": 5543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3773.78, \"learn_time_ms\": 10452.663, \"total_train_time_s\": 14.113750219345093}", "{\"n\": 5544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3779.06, \"learn_time_ms\": 10511.104, \"total_train_time_s\": 14.46592116355896}", "{\"n\": 5545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3767.7, \"learn_time_ms\": 10596.987, \"total_train_time_s\": 15.06900405883789}", "{\"n\": 5546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3767.7, \"learn_time_ms\": 10570.544, \"total_train_time_s\": 14.436197519302368}", "{\"n\": 5547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3751.37, \"learn_time_ms\": 10603.595, \"total_train_time_s\": 14.416520118713379}", "{\"n\": 5548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.07, \"learn_time_ms\": 10652.564, \"total_train_time_s\": 14.124857902526855}", "{\"n\": 5549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.07, \"learn_time_ms\": 10612.836, \"total_train_time_s\": 13.023880958557129}", "{\"n\": 5550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.07, \"learn_time_ms\": 10407.014, \"total_train_time_s\": 13.413969993591309}", "{\"n\": 5551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3716.02, \"learn_time_ms\": 10438.245, \"total_train_time_s\": 14.24286937713623}", "{\"n\": 5552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3709.69, \"learn_time_ms\": 10468.99, \"total_train_time_s\": 15.048535108566284}", "{\"n\": 5553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3709.69, \"learn_time_ms\": 10402.725, \"total_train_time_s\": 13.415050745010376}", "{\"n\": 5554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3686.13, \"learn_time_ms\": 10340.52, \"total_train_time_s\": 13.800109624862671}", "{\"n\": 5555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3687.76, \"learn_time_ms\": 10302.744, \"total_train_time_s\": 14.571208715438843}", "{\"n\": 5556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3687.76, \"learn_time_ms\": 10266.421, \"total_train_time_s\": 14.137020349502563}", "{\"n\": 5557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3685.09, \"learn_time_ms\": 10242.336, \"total_train_time_s\": 14.145289897918701}", "{\"n\": 5558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3673.27, \"learn_time_ms\": 10335.564, \"total_train_time_s\": 15.28032398223877}", "{\"n\": 5559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3668.73, \"learn_time_ms\": 10392.08, \"total_train_time_s\": 13.610755920410156}", "{\"n\": 5560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3668.73, \"learn_time_ms\": 10501.882, \"total_train_time_s\": 14.738552570343018}", "{\"n\": 5561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.29, \"learn_time_ms\": 10467.121, \"total_train_time_s\": 14.032540321350098}", "{\"n\": 5562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.05, \"learn_time_ms\": 10419.99, \"total_train_time_s\": 14.208420515060425}", "{\"n\": 5563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.05, \"learn_time_ms\": 10459.749, \"total_train_time_s\": 13.789926052093506}", "{\"n\": 5564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.47, \"learn_time_ms\": 10467.601, \"total_train_time_s\": 14.06889295578003}", "{\"n\": 5565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.47, \"learn_time_ms\": 10305.74, \"total_train_time_s\": 13.14099669456482}", "{\"n\": 5566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3650.98, \"learn_time_ms\": 10318.984, \"total_train_time_s\": 14.185945272445679}", "{\"n\": 5567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3641.93, \"learn_time_ms\": 10311.554, \"total_train_time_s\": 14.236817359924316}", "{\"n\": 5568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3641.93, \"learn_time_ms\": 10089.414, \"total_train_time_s\": 12.91210412979126}", "{\"n\": 5569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3668.72, \"learn_time_ms\": 10114.487, \"total_train_time_s\": 13.779571056365967}", "{\"n\": 5570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3668.72, \"learn_time_ms\": 10164.69, \"total_train_time_s\": 15.147582530975342}", "{\"n\": 5571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3667.59, \"learn_time_ms\": 10206.55, \"total_train_time_s\": 14.506402254104614}", "{\"n\": 5572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3665.54, \"learn_time_ms\": 10193.825, \"total_train_time_s\": 14.33091115951538}", "{\"n\": 5573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3662.17, \"learn_time_ms\": 10263.294, \"total_train_time_s\": 14.407823324203491}", "{\"n\": 5574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3662.17, \"learn_time_ms\": 10268.952, \"total_train_time_s\": 14.091985702514648}", "{\"n\": 5575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.75, \"learn_time_ms\": 10462.296, \"total_train_time_s\": 14.87772250175476}", "{\"n\": 5576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 10393.321, \"total_train_time_s\": 13.473942756652832}", "{\"n\": 5577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 10436.71, \"total_train_time_s\": 14.70402455329895}", "{\"n\": 5578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.24, \"learn_time_ms\": 10532.196, \"total_train_time_s\": 14.085609197616577}", "{\"n\": 5579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3679.38, \"learn_time_ms\": 10570.323, \"total_train_time_s\": 14.27809190750122}", "{\"n\": 5580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3666.77, \"learn_time_ms\": 10420.411, \"total_train_time_s\": 13.669138193130493}", "{\"n\": 5581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3666.77, \"learn_time_ms\": 10406.383, \"total_train_time_s\": 14.213788032531738}", "{\"n\": 5582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3666.77, \"learn_time_ms\": 10320.436, \"total_train_time_s\": 13.453824281692505}", "{\"n\": 5583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3666.77, \"learn_time_ms\": 10241.281, \"total_train_time_s\": 13.496495485305786}", "{\"n\": 5584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3654.14, \"learn_time_ms\": 10292.354, \"total_train_time_s\": 14.41897463798523}", "{\"n\": 5585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3657.16, \"learn_time_ms\": 10126.037, \"total_train_time_s\": 13.504447937011719}", "{\"n\": 5586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3657.16, \"learn_time_ms\": 10218.301, \"total_train_time_s\": 14.574817657470703}", "{\"n\": 5587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3664.8, \"learn_time_ms\": 10192.112, \"total_train_time_s\": 14.429203271865845}", "{\"n\": 5588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3682.23, \"learn_time_ms\": 10238.056, \"total_train_time_s\": 14.527940511703491}", "{\"n\": 5589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3694.35, \"learn_time_ms\": 10191.834, \"total_train_time_s\": 13.735952377319336}", "{\"n\": 5590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3694.35, \"learn_time_ms\": 10394.593, \"total_train_time_s\": 15.68544602394104}", "{\"n\": 5591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3690.98, \"learn_time_ms\": 10259.067, \"total_train_time_s\": 13.153451442718506}", "{\"n\": 5592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3672.43, \"learn_time_ms\": 10329.443, \"total_train_time_s\": 14.070740222930908}", "{\"n\": 5593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3672.43, \"learn_time_ms\": 10372.281, \"total_train_time_s\": 14.357363939285278}", "{\"n\": 5594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3672.43, \"learn_time_ms\": 10384.823, \"total_train_time_s\": 14.63331937789917}", "{\"n\": 5595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3667.76, \"learn_time_ms\": 10490.475, \"total_train_time_s\": 14.34299635887146}", "{\"n\": 5596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.03, \"learn_time_ms\": 10544.707, \"total_train_time_s\": 14.878757953643799}", "{\"n\": 5597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.03, \"learn_time_ms\": 10521.362, \"total_train_time_s\": 14.247077941894531}", "{\"n\": 5598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.03, \"learn_time_ms\": 10535.151, \"total_train_time_s\": 14.469454050064087}", "{\"n\": 5599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3665.67, \"learn_time_ms\": 10552.853, \"total_train_time_s\": 13.797932147979736}", "{\"n\": 5600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.19, \"learn_time_ms\": 10486.052, \"total_train_time_s\": 14.810956001281738}", "{\"n\": 5601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.19, \"learn_time_ms\": 10614.434, \"total_train_time_s\": 14.147186279296875}", "{\"n\": 5602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3647.42, \"learn_time_ms\": 10602.335, \"total_train_time_s\": 13.831990957260132}", "{\"n\": 5603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3645.52, \"learn_time_ms\": 10625.11, \"total_train_time_s\": 14.257922649383545}", "{\"n\": 5604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3652.75, \"learn_time_ms\": 10574.774, \"total_train_time_s\": 14.141597270965576}", "{\"n\": 5605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3652.75, \"learn_time_ms\": 10591.954, \"total_train_time_s\": 14.443650484085083}", "{\"n\": 5606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3656.14, \"learn_time_ms\": 10575.572, \"total_train_time_s\": 14.751081466674805}", "{\"n\": 5607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3656.14, \"learn_time_ms\": 10487.91, \"total_train_time_s\": 13.248037576675415}", "{\"n\": 5608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3635.66, \"learn_time_ms\": 10574.912, \"total_train_time_s\": 15.380026817321777}", "{\"n\": 5609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3635.66, \"learn_time_ms\": 10578.132, \"total_train_time_s\": 13.823582649230957}", "{\"n\": 5610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3634.28, \"learn_time_ms\": 10490.957, \"total_train_time_s\": 14.013345003128052}", "{\"n\": 5611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3637.32, \"learn_time_ms\": 10435.246, \"total_train_time_s\": 13.824534177780151}", "{\"n\": 5612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3637.64, \"learn_time_ms\": 10375.124, \"total_train_time_s\": 13.134494304656982}", "{\"n\": 5613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3626.71, \"learn_time_ms\": 10368.469, \"total_train_time_s\": 14.198452234268188}", "{\"n\": 5614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.91, \"learn_time_ms\": 10365.284, \"total_train_time_s\": 14.037732601165771}", "{\"n\": 5615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.38, \"learn_time_ms\": 10401.77, \"total_train_time_s\": 14.952157258987427}", "{\"n\": 5616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.38, \"learn_time_ms\": 10235.121, \"total_train_time_s\": 13.225968360900879}", "{\"n\": 5617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.45, \"learn_time_ms\": 10376.373, \"total_train_time_s\": 14.542387008666992}", "{\"n\": 5618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.14, \"learn_time_ms\": 10217.268, \"total_train_time_s\": 13.685917139053345}", "{\"n\": 5619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.14, \"learn_time_ms\": 10227.003, \"total_train_time_s\": 14.125338315963745}", "{\"n\": 5620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3597.28, \"learn_time_ms\": 10179.849, \"total_train_time_s\": 13.728439569473267}", "{\"n\": 5621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.7, \"learn_time_ms\": 10153.13, \"total_train_time_s\": 13.588335752487183}", "{\"n\": 5622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.81, \"learn_time_ms\": 10276.155, \"total_train_time_s\": 14.641561269760132}", "{\"n\": 5623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.18, \"learn_time_ms\": 10242.312, \"total_train_time_s\": 14.056416034698486}", "{\"n\": 5624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.18, \"learn_time_ms\": 10253.744, \"total_train_time_s\": 14.470332860946655}", "{\"n\": 5625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.17, \"learn_time_ms\": 10099.595, \"total_train_time_s\": 13.330894708633423}", "{\"n\": 5626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10227.852, \"total_train_time_s\": 14.3631112575531}", "{\"n\": 5627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10181.895, \"total_train_time_s\": 14.413653373718262}", "{\"n\": 5628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10218.211, \"total_train_time_s\": 14.43783712387085}", "{\"n\": 5629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3633.35, \"learn_time_ms\": 10172.525, \"total_train_time_s\": 13.500636577606201}", "{\"n\": 5630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.64, \"learn_time_ms\": 10239.869, \"total_train_time_s\": 14.097563743591309}", "{\"n\": 5631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.64, \"learn_time_ms\": 10215.524, \"total_train_time_s\": 13.079212427139282}", "{\"n\": 5632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.28, \"learn_time_ms\": 10183.585, \"total_train_time_s\": 14.170688152313232}", "{\"n\": 5633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.91, \"learn_time_ms\": 10104.604, \"total_train_time_s\": 13.094672441482544}", "{\"n\": 5634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.41, \"learn_time_ms\": 10100.962, \"total_train_time_s\": 14.258544683456421}", "{\"n\": 5635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.41, \"learn_time_ms\": 10245.787, \"total_train_time_s\": 14.760637760162354}", "{\"n\": 5636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3664.13, \"learn_time_ms\": 10085.339, \"total_train_time_s\": 12.848006010055542}", "{\"n\": 5637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3664.13, \"learn_time_ms\": 10061.473, \"total_train_time_s\": 14.200818300247192}", "{\"n\": 5638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.63, \"learn_time_ms\": 10093.561, \"total_train_time_s\": 14.653286457061768}", "{\"n\": 5639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3656.3, \"learn_time_ms\": 10152.718, \"total_train_time_s\": 14.332459449768066}", "{\"n\": 5640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.82, \"learn_time_ms\": 10129.057, \"total_train_time_s\": 14.103831768035889}", "{\"n\": 5641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 10256.97, \"total_train_time_s\": 14.528463363647461}", "{\"n\": 5642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 10208.401, \"total_train_time_s\": 13.90793514251709}", "{\"n\": 5643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3667.37, \"learn_time_ms\": 10260.407, \"total_train_time_s\": 13.75265645980835}", "{\"n\": 5644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.05, \"learn_time_ms\": 10230.703, \"total_train_time_s\": 13.785969734191895}", "{\"n\": 5645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.05, \"learn_time_ms\": 10176.168, \"total_train_time_s\": 14.469077110290527}", "{\"n\": 5646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.05, \"learn_time_ms\": 10320.996, \"total_train_time_s\": 14.386675834655762}", "{\"n\": 5647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.16, \"learn_time_ms\": 10403.961, \"total_train_time_s\": 14.94668173789978}", "{\"n\": 5648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 10364.178, \"total_train_time_s\": 14.12552261352539}", "{\"n\": 5649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 10323.769, \"total_train_time_s\": 13.871601343154907}", "{\"n\": 5650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3666.81, \"learn_time_ms\": 10326.54, \"total_train_time_s\": 13.831430912017822}", "{\"n\": 5651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3665.47, \"learn_time_ms\": 10306.795, \"total_train_time_s\": 14.465669870376587}", "{\"n\": 5652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3688.34, \"learn_time_ms\": 10355.431, \"total_train_time_s\": 14.085763931274414}", "{\"n\": 5653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3678.17, \"learn_time_ms\": 10517.383, \"total_train_time_s\": 15.41452145576477}", "{\"n\": 5654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3675.17, \"learn_time_ms\": 10562.78, \"total_train_time_s\": 14.330359935760498}", "{\"n\": 5655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.76, \"learn_time_ms\": 10505.375, \"total_train_time_s\": 13.613035678863525}", "{\"n\": 5656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.76, \"learn_time_ms\": 10530.278, \"total_train_time_s\": 14.700491905212402}", "{\"n\": 5657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 10383.583, \"total_train_time_s\": 13.497293472290039}", "{\"n\": 5658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3682.35, \"learn_time_ms\": 10387.705, \"total_train_time_s\": 14.08168911933899}", "{\"n\": 5659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3682.35, \"learn_time_ms\": 10396.834, \"total_train_time_s\": 13.845580577850342}", "{\"n\": 5660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3670.44, \"learn_time_ms\": 10407.101, \"total_train_time_s\": 13.984242916107178}", "{\"n\": 5661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.83, \"learn_time_ms\": 10425.907, \"total_train_time_s\": 14.47471570968628}", "{\"n\": 5662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.83, \"learn_time_ms\": 10416.502, \"total_train_time_s\": 13.932547807693481}", "{\"n\": 5663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.83, \"learn_time_ms\": 10288.32, \"total_train_time_s\": 14.353549003601074}", "{\"n\": 5664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.76, \"learn_time_ms\": 10322.977, \"total_train_time_s\": 14.754013538360596}", "{\"n\": 5665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.09, \"learn_time_ms\": 10267.588, \"total_train_time_s\": 13.180218696594238}", "{\"n\": 5666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.82, \"learn_time_ms\": 10280.578, \"total_train_time_s\": 14.73229432106018}", "{\"n\": 5667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.82, \"learn_time_ms\": 10303.37, \"total_train_time_s\": 13.3833909034729}", "{\"n\": 5668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3645.85, \"learn_time_ms\": 10276.998, \"total_train_time_s\": 13.92334532737732}", "{\"n\": 5669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.34, \"learn_time_ms\": 10290.806, \"total_train_time_s\": 14.187087535858154}", "{\"n\": 5670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.38, \"learn_time_ms\": 10299.211, \"total_train_time_s\": 14.181891202926636}", "{\"n\": 5671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.38, \"learn_time_ms\": 10259.894, \"total_train_time_s\": 14.003005266189575}", "{\"n\": 5672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.88, \"learn_time_ms\": 10428.862, \"total_train_time_s\": 15.787304639816284}", "{\"n\": 5673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.12, \"learn_time_ms\": 10413.865, \"total_train_time_s\": 13.873548984527588}", "{\"n\": 5674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.12, \"learn_time_ms\": 10277.359, \"total_train_time_s\": 13.586535692214966}", "{\"n\": 5675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3618.81, \"learn_time_ms\": 10468.994, \"total_train_time_s\": 15.116965770721436}", "{\"n\": 5676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.23, \"learn_time_ms\": 10496.158, \"total_train_time_s\": 15.083639144897461}", "{\"n\": 5677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.76, \"learn_time_ms\": 10495.695, \"total_train_time_s\": 13.357669115066528}", "{\"n\": 5678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.76, \"learn_time_ms\": 10495.379, \"total_train_time_s\": 13.873045921325684}", "{\"n\": 5679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.76, \"learn_time_ms\": 10400.49, \"total_train_time_s\": 12.920639276504517}", "{\"n\": 5680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.46, \"learn_time_ms\": 10454.916, \"total_train_time_s\": 14.631158351898193}", "{\"n\": 5681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.62, \"learn_time_ms\": 10461.91, \"total_train_time_s\": 14.117802381515503}", "{\"n\": 5682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.62, \"learn_time_ms\": 10391.351, \"total_train_time_s\": 14.969472646713257}", "{\"n\": 5683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.36, \"learn_time_ms\": 10410.472, \"total_train_time_s\": 13.997444868087769}", "{\"n\": 5684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.97, \"learn_time_ms\": 10419.182, \"total_train_time_s\": 13.465815782546997}", "{\"n\": 5685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3617.15, \"learn_time_ms\": 10351.873, \"total_train_time_s\": 14.55555248260498}", "{\"n\": 5686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.36, \"learn_time_ms\": 10276.039, \"total_train_time_s\": 14.159686803817749}", "{\"n\": 5687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.36, \"learn_time_ms\": 10293.001, \"total_train_time_s\": 13.532590866088867}", "{\"n\": 5688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.81, \"learn_time_ms\": 10363.58, \"total_train_time_s\": 14.504197835922241}", "{\"n\": 5689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.76, \"learn_time_ms\": 10486.262, \"total_train_time_s\": 14.363098621368408}", "{\"n\": 5690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.41, \"learn_time_ms\": 10408.27, \"total_train_time_s\": 14.166805744171143}", "{\"n\": 5691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3592.83, \"learn_time_ms\": 10299.702, \"total_train_time_s\": 13.09729290008545}", "{\"n\": 5692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 10195.641, \"total_train_time_s\": 14.06678557395935}", "{\"n\": 5693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 10213.332, \"total_train_time_s\": 14.263216733932495}", "{\"n\": 5694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 10303.31, \"total_train_time_s\": 14.266524076461792}", "{\"n\": 5695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3597.48, \"learn_time_ms\": 10284.787, \"total_train_time_s\": 14.188168287277222}", "{\"n\": 5696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.46, \"learn_time_ms\": 10256.148, \"total_train_time_s\": 13.810235261917114}", "{\"n\": 5697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.46, \"learn_time_ms\": 10324.149, \"total_train_time_s\": 14.359282493591309}", "{\"n\": 5698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.0, \"learn_time_ms\": 10178.827, \"total_train_time_s\": 13.054182529449463}", "{\"n\": 5699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3584.88, \"learn_time_ms\": 10268.491, \"total_train_time_s\": 15.190280199050903}", "{\"n\": 5700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3584.88, \"learn_time_ms\": 10268.173, \"total_train_time_s\": 13.879729747772217}", "{\"n\": 5701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3575.38, \"learn_time_ms\": 10369.598, \"total_train_time_s\": 13.926550149917603}", "{\"n\": 5702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3573.43, \"learn_time_ms\": 10370.598, \"total_train_time_s\": 13.917621850967407}", "{\"n\": 5703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3574.19, \"learn_time_ms\": 10324.698, \"total_train_time_s\": 13.6309232711792}", "{\"n\": 5704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3578.1, \"learn_time_ms\": 10159.263, \"total_train_time_s\": 12.585811138153076}", "{\"n\": 5705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.8, \"learn_time_ms\": 10158.195, \"total_train_time_s\": 14.39782452583313}", "{\"n\": 5706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3591.64, \"learn_time_ms\": 10174.626, \"total_train_time_s\": 14.049314022064209}", "{\"n\": 5707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3587.47, \"learn_time_ms\": 10264.696, \"total_train_time_s\": 15.396514892578125}", "{\"n\": 5708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3579.55, \"learn_time_ms\": 10436.172, \"total_train_time_s\": 14.982223749160767}", "{\"n\": 5709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3579.55, \"learn_time_ms\": 10382.976, \"total_train_time_s\": 14.680300235748291}", "{\"n\": 5710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3572.86, \"learn_time_ms\": 10528.176, \"total_train_time_s\": 15.35464072227478}", "{\"n\": 5711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.6, \"learn_time_ms\": 10476.193, \"total_train_time_s\": 13.864156007766724}", "{\"n\": 5712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.08, \"learn_time_ms\": 10381.014, \"total_train_time_s\": 13.189912557601929}", "{\"n\": 5713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3570.46, \"learn_time_ms\": 10335.301, \"total_train_time_s\": 13.253500699996948}", "{\"n\": 5714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3566.62, \"learn_time_ms\": 10450.54, \"total_train_time_s\": 13.945258140563965}", "{\"n\": 5715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3575.03, \"learn_time_ms\": 10412.748, \"total_train_time_s\": 13.691244125366211}", "{\"n\": 5716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3575.03, \"learn_time_ms\": 10437.011, \"total_train_time_s\": 14.577454805374146}", "{\"n\": 5717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3574.66, \"learn_time_ms\": 10284.484, \"total_train_time_s\": 13.749300956726074}", "{\"n\": 5718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.52, \"learn_time_ms\": 10199.951, \"total_train_time_s\": 14.060662031173706}", "{\"n\": 5719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.52, \"learn_time_ms\": 10176.735, \"total_train_time_s\": 14.628392219543457}", "{\"n\": 5720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.52, \"learn_time_ms\": 10050.369, \"total_train_time_s\": 14.014279842376709}", "{\"n\": 5721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.57, \"learn_time_ms\": 10177.523, \"total_train_time_s\": 14.621562957763672}", "{\"n\": 5722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.36, \"learn_time_ms\": 10246.24, \"total_train_time_s\": 13.79692816734314}", "{\"n\": 5723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3551.24, \"learn_time_ms\": 10275.512, \"total_train_time_s\": 13.598463296890259}", "{\"n\": 5724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.39, \"learn_time_ms\": 10325.439, \"total_train_time_s\": 14.411048650741577}", "{\"n\": 5725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.85, \"learn_time_ms\": 10313.176, \"total_train_time_s\": 13.730899333953857}", "{\"n\": 5726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.85, \"learn_time_ms\": 10316.405, \"total_train_time_s\": 14.481436729431152}", "{\"n\": 5727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3540.02, \"learn_time_ms\": 10451.81, \"total_train_time_s\": 14.922643184661865}", "{\"n\": 5728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.34, \"learn_time_ms\": 10514.731, \"total_train_time_s\": 14.730218887329102}", "{\"n\": 5729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3532.73, \"learn_time_ms\": 10466.753, \"total_train_time_s\": 14.036201000213623}", "{\"n\": 5730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3532.73, \"learn_time_ms\": 10470.637, \"total_train_time_s\": 14.14161229133606}", "{\"n\": 5731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3538.83, \"learn_time_ms\": 10482.289, \"total_train_time_s\": 14.820211410522461}", "{\"n\": 5732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3538.83, \"learn_time_ms\": 10644.744, \"total_train_time_s\": 15.462306499481201}", "{\"n\": 5733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3546.92, \"learn_time_ms\": 10683.672, \"total_train_time_s\": 13.962672233581543}", "{\"n\": 5734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.77, \"learn_time_ms\": 10596.966, \"total_train_time_s\": 13.567962646484375}", "{\"n\": 5735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3550.17, \"learn_time_ms\": 10678.692, \"total_train_time_s\": 14.434895753860474}", "{\"n\": 5736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3550.17, \"learn_time_ms\": 10627.848, \"total_train_time_s\": 13.943148136138916}", "{\"n\": 5737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3559.12, \"learn_time_ms\": 10603.776, \"total_train_time_s\": 14.713611602783203}", "{\"n\": 5738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 10641.37, \"total_train_time_s\": 14.850764513015747}", "{\"n\": 5739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 10650.703, \"total_train_time_s\": 14.183385133743286}", "{\"n\": 5740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 10625.622, \"total_train_time_s\": 14.153614044189453}", "{\"n\": 5741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3557.18, \"learn_time_ms\": 10347.944, \"total_train_time_s\": 12.096172094345093}", "{\"n\": 5742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3568.79, \"learn_time_ms\": 10232.949, \"total_train_time_s\": 14.338993787765503}", "{\"n\": 5743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3568.79, \"learn_time_ms\": 10163.32, \"total_train_time_s\": 13.296544313430786}", "{\"n\": 5744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3537.82, \"learn_time_ms\": 10084.656, \"total_train_time_s\": 12.54030466079712}", "{\"n\": 5745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3537.82, \"learn_time_ms\": 10107.209, \"total_train_time_s\": 14.744241714477539}", "{\"n\": 5746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3543.77, \"learn_time_ms\": 10224.058, \"total_train_time_s\": 15.090336084365845}", "{\"n\": 5747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3540.58, \"learn_time_ms\": 10219.148, \"total_train_time_s\": 14.810423374176025}", "{\"n\": 5748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3540.9, \"learn_time_ms\": 10102.43, \"total_train_time_s\": 13.839697360992432}", "{\"n\": 5749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3540.09, \"learn_time_ms\": 10109.827, \"total_train_time_s\": 13.971005916595459}", "{\"n\": 5750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3540.09, \"learn_time_ms\": 10109.384, \"total_train_time_s\": 13.9050772190094}", "{\"n\": 5751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3547.19, \"learn_time_ms\": 10286.498, \"total_train_time_s\": 14.138566493988037}", "{\"n\": 5752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3560.69, \"learn_time_ms\": 10366.206, \"total_train_time_s\": 15.086813926696777}", "{\"n\": 5753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3569.28, \"learn_time_ms\": 10512.613, \"total_train_time_s\": 14.73846983909607}", "{\"n\": 5754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.6, \"learn_time_ms\": 10742.377, \"total_train_time_s\": 15.023396968841553}", "{\"n\": 5755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.6, \"learn_time_ms\": 10694.792, \"total_train_time_s\": 14.248703479766846}", "{\"n\": 5756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3589.97, \"learn_time_ms\": 10503.648, \"total_train_time_s\": 12.899165630340576}", "{\"n\": 5757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.55, \"learn_time_ms\": 10429.569, \"total_train_time_s\": 13.944504976272583}", "{\"n\": 5758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.04, \"learn_time_ms\": 10431.631, \"total_train_time_s\": 13.722757816314697}", "{\"n\": 5759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3587.78, \"learn_time_ms\": 10424.073, \"total_train_time_s\": 14.271796464920044}", "{\"n\": 5760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.58, \"learn_time_ms\": 10448.785, \"total_train_time_s\": 14.093177556991577}", "{\"n\": 5761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3608.32, \"learn_time_ms\": 10516.729, \"total_train_time_s\": 14.417415618896484}", "{\"n\": 5762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3595.36, \"learn_time_ms\": 10490.993, \"total_train_time_s\": 14.889081001281738}", "{\"n\": 5763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3589.11, \"learn_time_ms\": 10390.602, \"total_train_time_s\": 13.843712329864502}", "{\"n\": 5764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3579.48, \"learn_time_ms\": 10307.686, \"total_train_time_s\": 14.352393865585327}", "{\"n\": 5765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3561.0, \"learn_time_ms\": 10247.416, \"total_train_time_s\": 13.53905987739563}", "{\"n\": 5766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3563.75, \"learn_time_ms\": 10285.792, \"total_train_time_s\": 13.397433042526245}", "{\"n\": 5767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3563.75, \"learn_time_ms\": 10227.796, \"total_train_time_s\": 13.304826259613037}", "{\"n\": 5768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3556.43, \"learn_time_ms\": 10200.067, \"total_train_time_s\": 13.44743299484253}", "{\"n\": 5769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.33, \"learn_time_ms\": 10195.744, \"total_train_time_s\": 13.898642778396606}", "{\"n\": 5770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3531.17, \"learn_time_ms\": 10211.213, \"total_train_time_s\": 14.345463752746582}", "{\"n\": 5771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3524.99, \"learn_time_ms\": 10098.922, \"total_train_time_s\": 13.561976671218872}", "{\"n\": 5772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3517.68, \"learn_time_ms\": 9967.533, \"total_train_time_s\": 13.485255479812622}", "{\"n\": 5773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3516.02, \"learn_time_ms\": 10004.904, \"total_train_time_s\": 14.322702169418335}", "{\"n\": 5774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3519.06, \"learn_time_ms\": 9876.114, \"total_train_time_s\": 12.920392751693726}", "{\"n\": 5775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3521.25, \"learn_time_ms\": 10013.376, \"total_train_time_s\": 15.077757358551025}", "{\"n\": 5776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3513.68, \"learn_time_ms\": 10118.381, \"total_train_time_s\": 14.345922946929932}", "{\"n\": 5777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3518.13, \"learn_time_ms\": 10197.371, \"total_train_time_s\": 14.340544700622559}", "{\"n\": 5778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3534.8, \"learn_time_ms\": 10289.802, \"total_train_time_s\": 14.318955183029175}", "{\"n\": 5779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3539.54, \"learn_time_ms\": 10301.215, \"total_train_time_s\": 14.157352924346924}", "{\"n\": 5780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3525.37, \"learn_time_ms\": 10400.673, \"total_train_time_s\": 15.363766193389893}", "{\"n\": 5781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3525.37, \"learn_time_ms\": 10456.008, \"total_train_time_s\": 14.136455059051514}", "{\"n\": 5782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3538.39, \"learn_time_ms\": 10535.254, \"total_train_time_s\": 14.08020544052124}", "{\"n\": 5783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3524.92, \"learn_time_ms\": 10578.285, \"total_train_time_s\": 14.791936874389648}", "{\"n\": 5784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3524.92, \"learn_time_ms\": 10781.159, \"total_train_time_s\": 15.012585401535034}", "{\"n\": 5785, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3514.29, \"learn_time_ms\": 10647.641, \"total_train_time_s\": 13.81801176071167}", "{\"n\": 5786, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3519.49, \"learn_time_ms\": 10598.931, \"total_train_time_s\": 14.092637777328491}", "{\"n\": 5787, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3519.49, \"learn_time_ms\": 10632.6, \"total_train_time_s\": 14.427865743637085}", "{\"n\": 5788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3532.9, \"learn_time_ms\": 10661.877, \"total_train_time_s\": 14.847736358642578}", "{\"n\": 5789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3532.9, \"learn_time_ms\": 10601.544, \"total_train_time_s\": 13.7306649684906}", "{\"n\": 5790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3545.42, \"learn_time_ms\": 10434.134, \"total_train_time_s\": 13.683326721191406}", "{\"n\": 5791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3545.42, \"learn_time_ms\": 10321.766, \"total_train_time_s\": 12.796406269073486}", "{\"n\": 5792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3558.77, \"learn_time_ms\": 10345.089, \"total_train_time_s\": 14.652257204055786}", "{\"n\": 5793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3562.26, \"learn_time_ms\": 10235.861, \"total_train_time_s\": 13.419959306716919}", "{\"n\": 5794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.26, \"learn_time_ms\": 10224.562, \"total_train_time_s\": 14.988157987594604}", "{\"n\": 5795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.47, \"learn_time_ms\": 10228.239, \"total_train_time_s\": 13.597701072692871}", "{\"n\": 5796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3569.29, \"learn_time_ms\": 10284.052, \"total_train_time_s\": 14.444586753845215}", "{\"n\": 5797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3561.8, \"learn_time_ms\": 10270.961, \"total_train_time_s\": 14.710212707519531}", "{\"n\": 5798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3553.57, \"learn_time_ms\": 10183.222, \"total_train_time_s\": 14.082749605178833}", "{\"n\": 5799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3549.73, \"learn_time_ms\": 10312.025, \"total_train_time_s\": 14.647584438323975}", "{\"n\": 5800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3548.06, \"learn_time_ms\": 10349.915, \"total_train_time_s\": 14.029752016067505}", "{\"n\": 5801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3553.01, \"learn_time_ms\": 10484.348, \"total_train_time_s\": 14.366339445114136}", "{\"n\": 5802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3553.22, \"learn_time_ms\": 10406.037, \"total_train_time_s\": 13.613126277923584}", "{\"n\": 5803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3547.87, \"learn_time_ms\": 10454.667, \"total_train_time_s\": 13.996110200881958}", "{\"n\": 5804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3547.87, \"learn_time_ms\": 10369.808, \"total_train_time_s\": 14.169835805892944}", "{\"n\": 5805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3534.97, \"learn_time_ms\": 10342.573, \"total_train_time_s\": 13.444170713424683}", "{\"n\": 5806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3540.61, \"learn_time_ms\": 10289.18, \"total_train_time_s\": 13.962677240371704}", "{\"n\": 5807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3540.61, \"learn_time_ms\": 10348.39, \"total_train_time_s\": 15.271027088165283}", "{\"n\": 5808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3540.61, \"learn_time_ms\": 10328.092, \"total_train_time_s\": 13.75454306602478}", "{\"n\": 5809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3513.78, \"learn_time_ms\": 10201.227, \"total_train_time_s\": 13.715328931808472}", "{\"n\": 5810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3526.9, \"learn_time_ms\": 10277.923, \"total_train_time_s\": 14.847523212432861}", "{\"n\": 5811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3526.9, \"learn_time_ms\": 10361.238, \"total_train_time_s\": 14.922610998153687}", "{\"n\": 5812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3526.9, \"learn_time_ms\": 10404.582, \"total_train_time_s\": 14.127456188201904}", "{\"n\": 5813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3535.19, \"learn_time_ms\": 10419.359, \"total_train_time_s\": 14.082442998886108}", "{\"n\": 5814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3560.28, \"learn_time_ms\": 10375.807, \"total_train_time_s\": 13.396164655685425}", "{\"n\": 5815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3560.28, \"learn_time_ms\": 10507.567, \"total_train_time_s\": 14.869866609573364}", "{\"n\": 5816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3560.28, \"learn_time_ms\": 10535.234, \"total_train_time_s\": 14.394636154174805}", "{\"n\": 5817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3588.07, \"learn_time_ms\": 10390.221, \"total_train_time_s\": 13.614311456680298}", "{\"n\": 5818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3586.7, \"learn_time_ms\": 10441.938, \"total_train_time_s\": 14.160900354385376}", "{\"n\": 5819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3586.8, \"learn_time_ms\": 10498.166, \"total_train_time_s\": 14.204100370407104}", "{\"n\": 5820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3584.39, \"learn_time_ms\": 10388.863, \"total_train_time_s\": 13.836619853973389}", "{\"n\": 5821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3591.98, \"learn_time_ms\": 10353.695, \"total_train_time_s\": 14.607349157333374}", "{\"n\": 5822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3598.13, \"learn_time_ms\": 10301.191, \"total_train_time_s\": 13.691609144210815}", "{\"n\": 5823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3605.78, \"learn_time_ms\": 10331.616, \"total_train_time_s\": 14.43476152420044}", "{\"n\": 5824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3605.04, \"learn_time_ms\": 10420.836, \"total_train_time_s\": 14.25713586807251}", "{\"n\": 5825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3605.04, \"learn_time_ms\": 10451.68, \"total_train_time_s\": 15.180270910263062}", "{\"n\": 5826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3613.06, \"learn_time_ms\": 10473.477, \"total_train_time_s\": 14.531089067459106}", "{\"n\": 5827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.69, \"learn_time_ms\": 10609.314, \"total_train_time_s\": 14.851098775863647}", "{\"n\": 5828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.76, \"learn_time_ms\": 10624.639, \"total_train_time_s\": 14.3866548538208}", "{\"n\": 5829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3631.22, \"learn_time_ms\": 10700.162, \"total_train_time_s\": 15.099313020706177}", "{\"n\": 5830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.88, \"learn_time_ms\": 10726.144, \"total_train_time_s\": 14.106622219085693}", "{\"n\": 5831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.88, \"learn_time_ms\": 10830.393, \"total_train_time_s\": 15.783483982086182}", "{\"n\": 5832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.09, \"learn_time_ms\": 10867.911, \"total_train_time_s\": 13.899331092834473}", "{\"n\": 5833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10838.569, \"total_train_time_s\": 13.987132549285889}", "{\"n\": 5834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10905.814, \"total_train_time_s\": 15.234781742095947}", "{\"n\": 5835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10872.332, \"total_train_time_s\": 15.043878316879272}", "{\"n\": 5836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3646.45, \"learn_time_ms\": 10936.85, \"total_train_time_s\": 15.077130556106567}", "{\"n\": 5837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3646.45, \"learn_time_ms\": 10797.15, \"total_train_time_s\": 13.599063396453857}", "{\"n\": 5838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.73, \"learn_time_ms\": 10766.78, \"total_train_time_s\": 14.201216220855713}", "{\"n\": 5839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3638.4, \"learn_time_ms\": 10742.453, \"total_train_time_s\": 14.734304189682007}", "{\"n\": 5840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.99, \"learn_time_ms\": 10805.29, \"total_train_time_s\": 14.535577297210693}", "{\"n\": 5841, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3626.9, \"learn_time_ms\": 10612.673, \"total_train_time_s\": 13.921353340148926}", "{\"n\": 5842, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.75, \"learn_time_ms\": 10584.533, \"total_train_time_s\": 13.730256795883179}", "{\"n\": 5843, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3607.25, \"learn_time_ms\": 10654.369, \"total_train_time_s\": 14.967040538787842}", "{\"n\": 5844, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3609.39, \"learn_time_ms\": 10553.018, \"total_train_time_s\": 13.949541091918945}", "{\"n\": 5845, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3598.61, \"learn_time_ms\": 10532.572, \"total_train_time_s\": 14.41013240814209}", "{\"n\": 5846, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3583.51, \"learn_time_ms\": 10382.435, \"total_train_time_s\": 13.77246356010437}", "{\"n\": 5847, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3589.7, \"learn_time_ms\": 10461.774, \"total_train_time_s\": 14.309157371520996}", "{\"n\": 5848, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3591.68, \"learn_time_ms\": 10462.034, \"total_train_time_s\": 13.910785675048828}", "{\"n\": 5849, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3593.39, \"learn_time_ms\": 10440.887, \"total_train_time_s\": 14.201530456542969}", "{\"n\": 5850, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3593.83, \"learn_time_ms\": 10511.092, \"total_train_time_s\": 15.340648889541626}", "{\"n\": 5851, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3605.71, \"learn_time_ms\": 10599.995, \"total_train_time_s\": 14.74219036102295}", "{\"n\": 5852, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3605.71, \"learn_time_ms\": 10568.931, \"total_train_time_s\": 13.530337810516357}", "{\"n\": 5853, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3623.36, \"learn_time_ms\": 10476.12, \"total_train_time_s\": 13.930658102035522}", "{\"n\": 5854, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3623.36, \"learn_time_ms\": 10474.359, \"total_train_time_s\": 13.972554922103882}", "{\"n\": 5855, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3636.91, \"learn_time_ms\": 10409.864, \"total_train_time_s\": 13.740869998931885}", "{\"n\": 5856, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3638.8, \"learn_time_ms\": 10482.939, \"total_train_time_s\": 14.52968692779541}", "{\"n\": 5857, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3658.06, \"learn_time_ms\": 10463.062, \"total_train_time_s\": 14.407492876052856}", "{\"n\": 5858, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3660.8, \"learn_time_ms\": 10496.318, \"total_train_time_s\": 14.233349323272705}", "{\"n\": 5859, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3665.35, \"learn_time_ms\": 10457.823, \"total_train_time_s\": 13.930451393127441}", "{\"n\": 5860, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3671.56, \"learn_time_ms\": 10496.959, \"total_train_time_s\": 15.830548286437988}", "{\"n\": 5861, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3680.39, \"learn_time_ms\": 10418.846, \"total_train_time_s\": 13.796070098876953}", "{\"n\": 5862, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3679.46, \"learn_time_ms\": 10519.592, \"total_train_time_s\": 14.539101839065552}", "{\"n\": 5863, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3680.92, \"learn_time_ms\": 10557.925, \"total_train_time_s\": 14.35080599784851}", "{\"n\": 5864, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3679.0, \"learn_time_ms\": 10500.215, \"total_train_time_s\": 13.25326943397522}", "{\"n\": 5865, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3673.75, \"learn_time_ms\": 10562.727, \"total_train_time_s\": 14.536153078079224}", "{\"n\": 5866, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3675.84, \"learn_time_ms\": 10445.406, \"total_train_time_s\": 13.124722480773926}", "{\"n\": 5867, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3678.4, \"learn_time_ms\": 10490.212, \"total_train_time_s\": 14.422417879104614}", "{\"n\": 5868, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3678.4, \"learn_time_ms\": 10454.669, \"total_train_time_s\": 14.059302806854248}", "{\"n\": 5869, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3685.95, \"learn_time_ms\": 10460.778, \"total_train_time_s\": 13.942098140716553}", "{\"n\": 5870, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3681.4, \"learn_time_ms\": 10363.856, \"total_train_time_s\": 15.003732204437256}", "{\"n\": 5871, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3675.65, \"learn_time_ms\": 10394.066, \"total_train_time_s\": 14.161033153533936}", "{\"n\": 5872, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.64, \"learn_time_ms\": 10339.149, \"total_train_time_s\": 13.697195768356323}", "{\"n\": 5873, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.64, \"learn_time_ms\": 10348.127, \"total_train_time_s\": 14.1632821559906}", "{\"n\": 5874, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3693.14, \"learn_time_ms\": 10388.319, \"total_train_time_s\": 13.716013193130493}", "{\"n\": 5875, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3693.41, \"learn_time_ms\": 10387.77, \"total_train_time_s\": 14.519208908081055}", "{\"n\": 5876, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 10500.384, \"total_train_time_s\": 14.52862811088562}", "{\"n\": 5877, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 10487.751, \"total_train_time_s\": 14.689844131469727}", "{\"n\": 5878, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 10445.82, \"total_train_time_s\": 13.698086500167847}", "{\"n\": 5879, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.54, \"learn_time_ms\": 10465.938, \"total_train_time_s\": 14.181649208068848}", "{\"n\": 5880, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.54, \"learn_time_ms\": 10443.767, \"total_train_time_s\": 14.798851251602173}", "{\"n\": 5881, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.54, \"learn_time_ms\": 10421.349, \"total_train_time_s\": 14.233469486236572}", "{\"n\": 5882, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.81, \"learn_time_ms\": 10514.307, \"total_train_time_s\": 15.045958518981934}", "{\"n\": 5883, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.16, \"learn_time_ms\": 10487.989, \"total_train_time_s\": 13.996319055557251}", "{\"n\": 5884, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.56, \"learn_time_ms\": 10581.83, \"total_train_time_s\": 14.74671220779419}", "{\"n\": 5885, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3720.66, \"learn_time_ms\": 10609.553, \"total_train_time_s\": 14.782147884368896}", "{\"n\": 5886, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.27, \"learn_time_ms\": 10488.94, \"total_train_time_s\": 13.040777206420898}", "{\"n\": 5887, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3722.76, \"learn_time_ms\": 10422.529, \"total_train_time_s\": 13.793117761611938}", "{\"n\": 5888, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.5, \"learn_time_ms\": 10432.962, \"total_train_time_s\": 13.640517234802246}", "{\"n\": 5889, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.81, \"learn_time_ms\": 10361.982, \"total_train_time_s\": 13.608475685119629}", "{\"n\": 5890, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.81, \"learn_time_ms\": 10321.117, \"total_train_time_s\": 14.197832107543945}", "{\"n\": 5891, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.76, \"learn_time_ms\": 10304.332, \"total_train_time_s\": 13.747462272644043}", "{\"n\": 5892, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.76, \"learn_time_ms\": 10195.994, \"total_train_time_s\": 13.773451566696167}", "{\"n\": 5893, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.78, \"learn_time_ms\": 10125.677, \"total_train_time_s\": 13.241047859191895}", "{\"n\": 5894, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.93, \"learn_time_ms\": 10132.052, \"total_train_time_s\": 14.973429203033447}", "{\"n\": 5895, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.93, \"learn_time_ms\": 9999.495, \"total_train_time_s\": 13.301047325134277}", "{\"n\": 5896, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.93, \"learn_time_ms\": 10068.133, \"total_train_time_s\": 14.074397087097168}", "{\"n\": 5897, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.27, \"learn_time_ms\": 10028.256, \"total_train_time_s\": 13.385709762573242}", "{\"n\": 5898, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.27, \"learn_time_ms\": 10037.754, \"total_train_time_s\": 14.208853960037231}", "{\"n\": 5899, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.8, \"learn_time_ms\": 10161.221, \"total_train_time_s\": 14.762641429901123}", "{\"n\": 5900, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.46, \"learn_time_ms\": 10105.358, \"total_train_time_s\": 13.704167127609253}", "{\"n\": 5901, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.46, \"learn_time_ms\": 10190.632, \"total_train_time_s\": 14.655224800109863}", "{\"n\": 5902, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.46, \"learn_time_ms\": 10268.289, \"total_train_time_s\": 14.5599524974823}", "{\"n\": 5903, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.63, \"learn_time_ms\": 10350.43, \"total_train_time_s\": 14.289126873016357}", "{\"n\": 5904, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.63, \"learn_time_ms\": 10351.074, \"total_train_time_s\": 14.676068782806396}", "{\"n\": 5905, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.24, \"learn_time_ms\": 10330.504, \"total_train_time_s\": 13.179331064224243}", "{\"n\": 5906, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.24, \"learn_time_ms\": 10367.874, \"total_train_time_s\": 14.173891544342041}", "{\"n\": 5907, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.53, \"learn_time_ms\": 10440.599, \"total_train_time_s\": 14.24183440208435}", "{\"n\": 5908, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.53, \"learn_time_ms\": 10564.022, \"total_train_time_s\": 15.162195682525635}", "{\"n\": 5909, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.15, \"learn_time_ms\": 10435.777, \"total_train_time_s\": 13.560622692108154}", "{\"n\": 5910, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.15, \"learn_time_ms\": 10539.972, \"total_train_time_s\": 14.592484474182129}", "{\"n\": 5911, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.74, \"learn_time_ms\": 10622.737, \"total_train_time_s\": 15.545719623565674}", "{\"n\": 5912, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.65, \"learn_time_ms\": 10510.393, \"total_train_time_s\": 13.36925983428955}", "{\"n\": 5913, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.65, \"learn_time_ms\": 10481.829, \"total_train_time_s\": 14.019173860549927}", "{\"n\": 5914, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3729.26, \"learn_time_ms\": 10317.326, \"total_train_time_s\": 13.07386827468872}", "{\"n\": 5915, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3724.33, \"learn_time_ms\": 10381.035, \"total_train_time_s\": 13.813846349716187}", "{\"n\": 5916, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3724.33, \"learn_time_ms\": 10365.309, \"total_train_time_s\": 14.083454608917236}", "{\"n\": 5917, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.26, \"learn_time_ms\": 10389.669, \"total_train_time_s\": 14.68529987335205}", "{\"n\": 5918, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.74, \"learn_time_ms\": 10237.012, \"total_train_time_s\": 13.568855285644531}", "{\"n\": 5919, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.81, \"learn_time_ms\": 10425.06, \"total_train_time_s\": 15.340078353881836}", "{\"n\": 5920, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.13, \"learn_time_ms\": 10312.359, \"total_train_time_s\": 13.516022205352783}", "{\"n\": 5921, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.13, \"learn_time_ms\": 10199.133, \"total_train_time_s\": 14.453003168106079}", "{\"n\": 5922, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.25, \"learn_time_ms\": 10232.154, \"total_train_time_s\": 14.021365880966187}", "{\"n\": 5923, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.94, \"learn_time_ms\": 10312.532, \"total_train_time_s\": 14.688008785247803}", "{\"n\": 5924, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.1, \"learn_time_ms\": 10427.208, \"total_train_time_s\": 14.196860074996948}", "{\"n\": 5925, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.2, \"learn_time_ms\": 10424.635, \"total_train_time_s\": 13.775774240493774}", "{\"n\": 5926, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.53, \"learn_time_ms\": 10267.763, \"total_train_time_s\": 12.791608333587646}", "{\"n\": 5927, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.46, \"learn_time_ms\": 10292.786, \"total_train_time_s\": 14.46245551109314}", "{\"n\": 5928, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.4, \"learn_time_ms\": 10353.863, \"total_train_time_s\": 14.050626277923584}", "{\"n\": 5929, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.4, \"learn_time_ms\": 10280.281, \"total_train_time_s\": 14.768387794494629}", "{\"n\": 5930, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.85, \"learn_time_ms\": 10308.85, \"total_train_time_s\": 13.630300998687744}", "{\"n\": 5931, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.45, \"learn_time_ms\": 10147.775, \"total_train_time_s\": 12.852339506149292}", "{\"n\": 5932, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.45, \"learn_time_ms\": 10262.99, \"total_train_time_s\": 14.881892204284668}", "{\"n\": 5933, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.45, \"learn_time_ms\": 10248.739, \"total_train_time_s\": 14.73647952079773}", "{\"n\": 5934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.56, \"learn_time_ms\": 10203.45, \"total_train_time_s\": 13.872941970825195}", "{\"n\": 5935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.91, \"learn_time_ms\": 10235.484, \"total_train_time_s\": 14.10175371170044}", "{\"n\": 5936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.91, \"learn_time_ms\": 10284.792, \"total_train_time_s\": 13.134728193283081}", "{\"n\": 5937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3729.67, \"learn_time_ms\": 10179.138, \"total_train_time_s\": 13.779614686965942}", "{\"n\": 5938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.08, \"learn_time_ms\": 10229.784, \"total_train_time_s\": 14.579569339752197}", "{\"n\": 5939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.08, \"learn_time_ms\": 10111.341, \"total_train_time_s\": 13.747257947921753}", "{\"n\": 5940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.08, \"learn_time_ms\": 10215.086, \"total_train_time_s\": 14.920709133148193}", "{\"n\": 5941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.02, \"learn_time_ms\": 10366.051, \"total_train_time_s\": 14.171257734298706}", "{\"n\": 5942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10281.152, \"total_train_time_s\": 13.916185855865479}", "{\"n\": 5943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10326.224, \"total_train_time_s\": 15.026046514511108}", "{\"n\": 5944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10359.823, \"total_train_time_s\": 14.370864391326904}", "{\"n\": 5945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.11, \"learn_time_ms\": 10389.522, \"total_train_time_s\": 14.473126888275146}", "{\"n\": 5946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.66, \"learn_time_ms\": 10509.606, \"total_train_time_s\": 14.009845972061157}", "{\"n\": 5947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.76, \"learn_time_ms\": 10635.564, \"total_train_time_s\": 14.977404832839966}", "{\"n\": 5948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.88, \"learn_time_ms\": 10665.844, \"total_train_time_s\": 14.97066593170166}", "{\"n\": 5949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.88, \"learn_time_ms\": 10676.887, \"total_train_time_s\": 13.723729848861694}", "{\"n\": 5950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.81, \"learn_time_ms\": 10677.564, \"total_train_time_s\": 14.680491209030151}", "{\"n\": 5951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.63, \"learn_time_ms\": 10585.269, \"total_train_time_s\": 13.222121477127075}", "{\"n\": 5952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.84, \"learn_time_ms\": 10540.838, \"total_train_time_s\": 13.487837314605713}", "{\"n\": 5953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.84, \"learn_time_ms\": 10429.094, \"total_train_time_s\": 14.079978704452515}", "{\"n\": 5954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.45, \"learn_time_ms\": 10396.457, \"total_train_time_s\": 13.905324220657349}", "{\"n\": 5955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.45, \"learn_time_ms\": 10343.893, \"total_train_time_s\": 13.828208446502686}", "{\"n\": 5956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.73, \"learn_time_ms\": 10398.2, \"total_train_time_s\": 14.55237102508545}", "{\"n\": 5957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.05, \"learn_time_ms\": 10266.549, \"total_train_time_s\": 13.465807676315308}", "{\"n\": 5958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.06, \"learn_time_ms\": 10273.523, \"total_train_time_s\": 15.01313853263855}", "{\"n\": 5959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.11, \"learn_time_ms\": 10387.736, \"total_train_time_s\": 14.602742671966553}", "{\"n\": 5960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.78, \"learn_time_ms\": 10328.287, \"total_train_time_s\": 14.031879425048828}", "{\"n\": 5961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.16, \"learn_time_ms\": 10364.813, \"total_train_time_s\": 13.67232084274292}", "{\"n\": 5962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.16, \"learn_time_ms\": 10520.344, \"total_train_time_s\": 14.933491468429565}", "{\"n\": 5963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3635.97, \"learn_time_ms\": 10486.391, \"total_train_time_s\": 13.905845642089844}", "{\"n\": 5964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.52, \"learn_time_ms\": 10494.98, \"total_train_time_s\": 14.15064001083374}", "{\"n\": 5965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.34, \"learn_time_ms\": 10504.241, \"total_train_time_s\": 14.184262752532959}", "{\"n\": 5966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.05, \"learn_time_ms\": 10445.46, \"total_train_time_s\": 14.33471965789795}", "{\"n\": 5967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.05, \"learn_time_ms\": 10514.871, \"total_train_time_s\": 14.4175546169281}", "{\"n\": 5968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.66, \"learn_time_ms\": 10369.468, \"total_train_time_s\": 13.585192680358887}", "{\"n\": 5969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.59, \"learn_time_ms\": 10347.08, \"total_train_time_s\": 14.30554723739624}", "{\"n\": 5970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 10404.763, \"total_train_time_s\": 14.6494722366333}", "{\"n\": 5971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3591.75, \"learn_time_ms\": 10373.751, \"total_train_time_s\": 13.340751647949219}", "{\"n\": 5972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3591.75, \"learn_time_ms\": 10225.837, \"total_train_time_s\": 13.692724704742432}", "{\"n\": 5973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3588.83, \"learn_time_ms\": 10338.958, \"total_train_time_s\": 14.545410394668579}", "{\"n\": 5974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3584.95, \"learn_time_ms\": 10335.962, \"total_train_time_s\": 14.363117456436157}", "{\"n\": 5975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3596.39, \"learn_time_ms\": 10322.576, \"total_train_time_s\": 13.866195440292358}", "{\"n\": 5976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3596.6, \"learn_time_ms\": 10398.998, \"total_train_time_s\": 15.195476531982422}", "{\"n\": 5977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3600.41, \"learn_time_ms\": 10441.164, \"total_train_time_s\": 14.62260103225708}", "{\"n\": 5978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3600.41, \"learn_time_ms\": 10540.052, \"total_train_time_s\": 14.651248931884766}", "{\"n\": 5979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.31, \"learn_time_ms\": 10576.961, \"total_train_time_s\": 14.760479927062988}", "{\"n\": 5980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.85, \"learn_time_ms\": 10464.297, \"total_train_time_s\": 13.62557578086853}", "{\"n\": 5981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.64, \"learn_time_ms\": 10496.47, \"total_train_time_s\": 13.718567371368408}", "{\"n\": 5982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.64, \"learn_time_ms\": 10619.921, \"total_train_time_s\": 14.994447231292725}", "{\"n\": 5983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.01, \"learn_time_ms\": 10597.477, \"total_train_time_s\": 14.372204542160034}", "{\"n\": 5984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.8, \"learn_time_ms\": 10659.996, \"total_train_time_s\": 14.617427110671997}", "{\"n\": 5985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.67, \"learn_time_ms\": 10689.571, \"total_train_time_s\": 14.090152025222778}", "{\"n\": 5986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3633.93, \"learn_time_ms\": 10598.504, \"total_train_time_s\": 13.960704565048218}", "{\"n\": 5987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.54, \"learn_time_ms\": 10635.974, \"total_train_time_s\": 15.072525978088379}", "{\"n\": 5988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.54, \"learn_time_ms\": 10507.684, \"total_train_time_s\": 13.413347244262695}", "{\"n\": 5989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.98, \"learn_time_ms\": 10432.951, \"total_train_time_s\": 14.172043323516846}", "{\"n\": 5990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.56, \"learn_time_ms\": 10533.163, \"total_train_time_s\": 14.68152379989624}", "{\"n\": 5991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.8, \"learn_time_ms\": 10649.955, \"total_train_time_s\": 14.994169235229492}", "{\"n\": 5992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.8, \"learn_time_ms\": 10710.639, \"total_train_time_s\": 15.479826211929321}", "{\"n\": 5993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3639.38, \"learn_time_ms\": 10697.289, \"total_train_time_s\": 14.65914273262024}", "{\"n\": 5994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3637.31, \"learn_time_ms\": 10644.847, \"total_train_time_s\": 14.129523515701294}", "{\"n\": 5995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.17, \"learn_time_ms\": 10601.838, \"total_train_time_s\": 13.946235656738281}", "{\"n\": 5996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.82, \"learn_time_ms\": 10670.826, \"total_train_time_s\": 14.62043046951294}", "{\"n\": 5997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.27, \"learn_time_ms\": 10603.766, \"total_train_time_s\": 14.20326542854309}", "{\"n\": 5998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.27, \"learn_time_ms\": 10574.765, \"total_train_time_s\": 13.016514301300049}", "{\"n\": 5999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3659.01, \"learn_time_ms\": 10668.45, \"total_train_time_s\": 15.004256248474121}", "{\"n\": 6000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.14, \"learn_time_ms\": 10697.282, \"total_train_time_s\": 14.817066431045532}", "{\"n\": 6001, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.76, \"learn_time_ms\": 10664.971, \"total_train_time_s\": 14.459542512893677}", "{\"n\": 6002, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.22, \"learn_time_ms\": 10513.832, \"total_train_time_s\": 14.277771949768066}", "{\"n\": 6003, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.2, \"learn_time_ms\": 10458.684, \"total_train_time_s\": 13.697529554367065}", "{\"n\": 6004, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3635.28, \"learn_time_ms\": 10391.208, \"total_train_time_s\": 13.375583410263062}", "{\"n\": 6005, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.73, \"learn_time_ms\": 10379.923, \"total_train_time_s\": 13.717626810073853}", "{\"n\": 6006, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.6, \"learn_time_ms\": 10402.426, \"total_train_time_s\": 15.063586473464966}", "{\"n\": 6007, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.6, \"learn_time_ms\": 10303.547, \"total_train_time_s\": 13.360517024993896}", "{\"n\": 6008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.08, \"learn_time_ms\": 10434.446, \"total_train_time_s\": 14.439902305603027}", "{\"n\": 6009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.08, \"learn_time_ms\": 10343.74, \"total_train_time_s\": 14.050288915634155}", "{\"n\": 6010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.34, \"learn_time_ms\": 10388.162, \"total_train_time_s\": 15.252902269363403}", "{\"n\": 6011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.66, \"learn_time_ms\": 10310.681, \"total_train_time_s\": 13.887617349624634}", "{\"n\": 6012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.55, \"learn_time_ms\": 10375.83, \"total_train_time_s\": 14.72724199295044}", "{\"n\": 6013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3672.44, \"learn_time_ms\": 10340.054, \"total_train_time_s\": 13.638181686401367}", "{\"n\": 6014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3672.98, \"learn_time_ms\": 10475.589, \"total_train_time_s\": 14.908241271972656}", "{\"n\": 6015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.11, \"learn_time_ms\": 10579.352, \"total_train_time_s\": 14.597841739654541}", "{\"n\": 6016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.11, \"learn_time_ms\": 10519.03, \"total_train_time_s\": 14.276269912719727}", "{\"n\": 6017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.78, \"learn_time_ms\": 10609.472, \"total_train_time_s\": 14.300634622573853}", "{\"n\": 6018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.78, \"learn_time_ms\": 10501.664, \"total_train_time_s\": 13.032921314239502}", "{\"n\": 6019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.08, \"learn_time_ms\": 10529.215, \"total_train_time_s\": 14.330715417861938}", "{\"n\": 6020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.08, \"learn_time_ms\": 10341.17, \"total_train_time_s\": 13.335038185119629}", "{\"n\": 6021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3633.59, \"learn_time_ms\": 10387.493, \"total_train_time_s\": 14.473260641098022}", "{\"n\": 6022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.16, \"learn_time_ms\": 10309.002, \"total_train_time_s\": 13.858253479003906}", "{\"n\": 6023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.16, \"learn_time_ms\": 10375.118, \"total_train_time_s\": 14.277230024337769}", "{\"n\": 6024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3617.81, \"learn_time_ms\": 10410.173, \"total_train_time_s\": 15.106763124465942}", "{\"n\": 6025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3624.89, \"learn_time_ms\": 10415.615, \"total_train_time_s\": 14.580248594284058}", "{\"n\": 6026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.2, \"learn_time_ms\": 10454.746, \"total_train_time_s\": 14.87820553779602}", "{\"n\": 6027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.94, \"learn_time_ms\": 10501.366, \"total_train_time_s\": 14.921618461608887}", "{\"n\": 6028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.76, \"learn_time_ms\": 10606.485, \"total_train_time_s\": 14.07512640953064}", "{\"n\": 6029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.76, \"learn_time_ms\": 10619.68, \"total_train_time_s\": 14.365840196609497}", "{\"n\": 6030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.6, \"learn_time_ms\": 10718.149, \"total_train_time_s\": 14.487207651138306}", "{\"n\": 6031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.81, \"learn_time_ms\": 10799.774, \"total_train_time_s\": 15.087656259536743}", "{\"n\": 6032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.81, \"learn_time_ms\": 10740.027, \"total_train_time_s\": 13.481689929962158}", "{\"n\": 6033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.81, \"learn_time_ms\": 10783.895, \"total_train_time_s\": 14.714207649230957}", "{\"n\": 6034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3627.02, \"learn_time_ms\": 10703.903, \"total_train_time_s\": 14.681546688079834}", "{\"n\": 6035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.22, \"learn_time_ms\": 10621.048, \"total_train_time_s\": 13.827096939086914}", "{\"n\": 6036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.04, \"learn_time_ms\": 10614.097, \"total_train_time_s\": 14.710320234298706}", "{\"n\": 6037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3600.81, \"learn_time_ms\": 10564.041, \"total_train_time_s\": 14.417195796966553}", "{\"n\": 6038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.51, \"learn_time_ms\": 10562.206, \"total_train_time_s\": 14.299161672592163}", "{\"n\": 6039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.05, \"learn_time_ms\": 10544.674, \"total_train_time_s\": 14.379587650299072}", "{\"n\": 6040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.32, \"learn_time_ms\": 10507.144, \"total_train_time_s\": 14.110464811325073}", "{\"n\": 6041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.77, \"learn_time_ms\": 10446.647, \"total_train_time_s\": 14.427368879318237}", "{\"n\": 6042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.17, \"learn_time_ms\": 10567.075, \"total_train_time_s\": 14.314820766448975}", "{\"n\": 6043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.17, \"learn_time_ms\": 10465.201, \"total_train_time_s\": 13.657819747924805}", "{\"n\": 6044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.26, \"learn_time_ms\": 10369.017, \"total_train_time_s\": 13.186781644821167}", "{\"n\": 6045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.99, \"learn_time_ms\": 10500.873, \"total_train_time_s\": 15.09264850616455}", "{\"n\": 6046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.99, \"learn_time_ms\": 10604.86, \"total_train_time_s\": 15.488297462463379}", "{\"n\": 6047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 10552.88, \"total_train_time_s\": 13.870671272277832}", "{\"n\": 6048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.96, \"learn_time_ms\": 10402.325, \"total_train_time_s\": 12.583500385284424}", "{\"n\": 6049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.96, \"learn_time_ms\": 10290.13, \"total_train_time_s\": 13.503422021865845}", "{\"n\": 6050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10288.702, \"total_train_time_s\": 14.308501482009888}", "{\"n\": 6051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.62, \"learn_time_ms\": 10211.968, \"total_train_time_s\": 13.906302690505981}", "{\"n\": 6052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.62, \"learn_time_ms\": 10190.211, \"total_train_time_s\": 14.57757306098938}", "{\"n\": 6053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.62, \"learn_time_ms\": 10220.797, \"total_train_time_s\": 13.80325698852539}", "{\"n\": 6054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.62, \"learn_time_ms\": 10352.802, \"total_train_time_s\": 14.504173517227173}", "{\"n\": 6055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.55, \"learn_time_ms\": 10320.395, \"total_train_time_s\": 14.765063047409058}", "{\"n\": 6056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.55, \"learn_time_ms\": 10150.772, \"total_train_time_s\": 13.7883141040802}", "{\"n\": 6057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3668.13, \"learn_time_ms\": 10199.977, \"total_train_time_s\": 14.237394571304321}", "{\"n\": 6058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.39, \"learn_time_ms\": 10315.005, \"total_train_time_s\": 13.89529299736023}", "{\"n\": 6059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.39, \"learn_time_ms\": 10325.715, \"total_train_time_s\": 13.400424003601074}", "{\"n\": 6060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.39, \"learn_time_ms\": 10251.608, \"total_train_time_s\": 13.433925867080688}", "{\"n\": 6061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.78, \"learn_time_ms\": 10282.758, \"total_train_time_s\": 13.969351291656494}", "{\"n\": 6062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.28, \"learn_time_ms\": 10217.154, \"total_train_time_s\": 13.521699905395508}", "{\"n\": 6063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.28, \"learn_time_ms\": 10340.804, \"total_train_time_s\": 15.320307731628418}", "{\"n\": 6064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3633.9, \"learn_time_ms\": 10322.517, \"total_train_time_s\": 14.620405197143555}", "{\"n\": 6065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.97, \"learn_time_ms\": 10251.53, \"total_train_time_s\": 14.057117938995361}", "{\"n\": 6066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.05, \"learn_time_ms\": 10265.302, \"total_train_time_s\": 14.107930898666382}", "{\"n\": 6067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3620.92, \"learn_time_ms\": 10243.439, \"total_train_time_s\": 14.007901191711426}", "{\"n\": 6068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10286.047, \"total_train_time_s\": 14.357666730880737}", "{\"n\": 6069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10361.121, \"total_train_time_s\": 14.345200300216675}", "{\"n\": 6070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.04, \"learn_time_ms\": 10424.867, \"total_train_time_s\": 13.970985889434814}", "{\"n\": 6071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.61, \"learn_time_ms\": 10513.741, \"total_train_time_s\": 14.876599550247192}", "{\"n\": 6072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.43, \"learn_time_ms\": 10730.444, \"total_train_time_s\": 15.866771221160889}", "{\"n\": 6073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.44, \"learn_time_ms\": 10616.969, \"total_train_time_s\": 13.780129432678223}", "{\"n\": 6074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.44, \"learn_time_ms\": 10636.204, \"total_train_time_s\": 14.524409770965576}", "{\"n\": 6075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.58, \"learn_time_ms\": 10605.977, \"total_train_time_s\": 14.087217569351196}", "{\"n\": 6076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.03, \"learn_time_ms\": 10706.095, \"total_train_time_s\": 15.386333227157593}", "{\"n\": 6077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.0, \"learn_time_ms\": 10786.978, \"total_train_time_s\": 14.830998420715332}", "{\"n\": 6078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.0, \"learn_time_ms\": 10813.027, \"total_train_time_s\": 14.538758516311646}", "{\"n\": 6079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.01, \"learn_time_ms\": 10752.012, \"total_train_time_s\": 13.427638292312622}", "{\"n\": 6080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3590.97, \"learn_time_ms\": 10708.804, \"total_train_time_s\": 13.705447673797607}", "{\"n\": 6081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.09, \"learn_time_ms\": 10674.4, \"total_train_time_s\": 14.528904676437378}", "{\"n\": 6082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.09, \"learn_time_ms\": 10554.449, \"total_train_time_s\": 14.828980445861816}", "{\"n\": 6083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 10599.595, \"total_train_time_s\": 14.1957848072052}", "{\"n\": 6084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.27, \"learn_time_ms\": 10502.122, \"total_train_time_s\": 13.762001991271973}", "{\"n\": 6085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.27, \"learn_time_ms\": 10513.986, \"total_train_time_s\": 14.370851278305054}", "{\"n\": 6086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3590.74, \"learn_time_ms\": 10404.415, \"total_train_time_s\": 13.94454288482666}", "{\"n\": 6087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3587.53, \"learn_time_ms\": 10390.233, \"total_train_time_s\": 14.592605590820312}", "{\"n\": 6088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.16, \"learn_time_ms\": 10373.402, \"total_train_time_s\": 14.390628099441528}", "{\"n\": 6089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3579.32, \"learn_time_ms\": 10424.831, \"total_train_time_s\": 14.235776901245117}", "{\"n\": 6090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.55, \"learn_time_ms\": 10469.019, \"total_train_time_s\": 13.946256399154663}", "{\"n\": 6091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.55, \"learn_time_ms\": 10471.948, \"total_train_time_s\": 14.9955415725708}", "{\"n\": 6092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.77, \"learn_time_ms\": 10469.788, \"total_train_time_s\": 14.39560079574585}", "{\"n\": 6093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.77, \"learn_time_ms\": 10527.736, \"total_train_time_s\": 15.152286767959595}", "{\"n\": 6094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.77, \"learn_time_ms\": 10545.566, \"total_train_time_s\": 13.711761713027954}", "{\"n\": 6095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3550.87, \"learn_time_ms\": 10475.431, \"total_train_time_s\": 13.510987520217896}", "{\"n\": 6096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.75, \"learn_time_ms\": 10513.711, \"total_train_time_s\": 14.321204662322998}", "{\"n\": 6097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.27, \"learn_time_ms\": 10517.187, \"total_train_time_s\": 14.66594123840332}", "{\"n\": 6098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.27, \"learn_time_ms\": 10449.147, \"total_train_time_s\": 13.731959342956543}", "{\"n\": 6099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.86, \"learn_time_ms\": 10392.43, \"total_train_time_s\": 13.431814193725586}", "{\"n\": 6100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.86, \"learn_time_ms\": 10365.199, \"total_train_time_s\": 14.106764316558838}", "{\"n\": 6101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3542.39, \"learn_time_ms\": 10247.58, \"total_train_time_s\": 13.447151184082031}", "{\"n\": 6102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.34, \"learn_time_ms\": 10263.781, \"total_train_time_s\": 14.542356729507446}", "{\"n\": 6103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.71, \"learn_time_ms\": 10121.548, \"total_train_time_s\": 13.466598749160767}", "{\"n\": 6104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.71, \"learn_time_ms\": 10164.318, \"total_train_time_s\": 14.548185348510742}", "{\"n\": 6105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.82, \"learn_time_ms\": 10394.76, \"total_train_time_s\": 15.663948059082031}", "{\"n\": 6106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.85, \"learn_time_ms\": 10371.048, \"total_train_time_s\": 14.065172910690308}", "{\"n\": 6107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.85, \"learn_time_ms\": 10280.371, \"total_train_time_s\": 13.966867923736572}", "{\"n\": 6108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.85, \"learn_time_ms\": 10283.962, \"total_train_time_s\": 13.968347311019897}", "{\"n\": 6109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.25, \"learn_time_ms\": 10333.968, \"total_train_time_s\": 13.939390659332275}", "{\"n\": 6110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.45, \"learn_time_ms\": 10402.18, \"total_train_time_s\": 14.294915914535522}", "{\"n\": 6111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.45, \"learn_time_ms\": 10433.502, \"total_train_time_s\": 13.988252639770508}", "{\"n\": 6112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.54, \"learn_time_ms\": 10404.579, \"total_train_time_s\": 14.579716205596924}", "{\"n\": 6113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3573.69, \"learn_time_ms\": 10512.422, \"total_train_time_s\": 14.411956071853638}", "{\"n\": 6114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.65, \"learn_time_ms\": 10468.807, \"total_train_time_s\": 13.947911739349365}", "{\"n\": 6115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.75, \"learn_time_ms\": 10225.831, \"total_train_time_s\": 13.57332158088684}", "{\"n\": 6116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.75, \"learn_time_ms\": 10260.864, \"total_train_time_s\": 14.3992440700531}", "{\"n\": 6117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.03, \"learn_time_ms\": 10346.337, \"total_train_time_s\": 14.48395562171936}", "{\"n\": 6118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.51, \"learn_time_ms\": 10373.439, \"total_train_time_s\": 13.97598910331726}", "{\"n\": 6119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.26, \"learn_time_ms\": 10425.55, \"total_train_time_s\": 14.563254356384277}", "{\"n\": 6120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.26, \"learn_time_ms\": 10406.115, \"total_train_time_s\": 14.261804103851318}", "{\"n\": 6121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3583.58, \"learn_time_ms\": 10441.406, \"total_train_time_s\": 14.026044607162476}", "{\"n\": 6122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.23, \"learn_time_ms\": 10489.218, \"total_train_time_s\": 14.837233781814575}", "{\"n\": 6123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.23, \"learn_time_ms\": 10391.443, \"total_train_time_s\": 13.667264699935913}", "{\"n\": 6124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.23, \"learn_time_ms\": 10482.822, \"total_train_time_s\": 14.862139463424683}", "{\"n\": 6125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.05, \"learn_time_ms\": 10604.2, \"total_train_time_s\": 14.323904037475586}", "{\"n\": 6126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 10515.312, \"total_train_time_s\": 13.640660524368286}", "{\"n\": 6127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 10326.368, \"total_train_time_s\": 12.941170454025269}", "{\"n\": 6128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 10344.745, \"total_train_time_s\": 14.279901266098022}", "{\"n\": 6129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3598.4, \"learn_time_ms\": 10279.526, \"total_train_time_s\": 13.84895372390747}", "{\"n\": 6130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.39, \"learn_time_ms\": 10302.285, \"total_train_time_s\": 14.269486904144287}", "{\"n\": 6131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.39, \"learn_time_ms\": 10389.378, \"total_train_time_s\": 15.159318685531616}", "{\"n\": 6132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.92, \"learn_time_ms\": 10326.511, \"total_train_time_s\": 14.157315492630005}", "{\"n\": 6133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.25, \"learn_time_ms\": 10304.075, \"total_train_time_s\": 13.34451675415039}", "{\"n\": 6134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.26, \"learn_time_ms\": 10285.669, \"total_train_time_s\": 14.577246904373169}", "{\"n\": 6135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.26, \"learn_time_ms\": 10201.806, \"total_train_time_s\": 13.60137414932251}", "{\"n\": 6136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.55, \"learn_time_ms\": 10250.125, \"total_train_time_s\": 13.988688945770264}", "{\"n\": 6137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.15, \"learn_time_ms\": 10459.346, \"total_train_time_s\": 14.780409097671509}", "{\"n\": 6138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.15, \"learn_time_ms\": 10554.096, \"total_train_time_s\": 15.19659948348999}", "{\"n\": 6139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.15, \"learn_time_ms\": 10496.1, \"total_train_time_s\": 13.48536205291748}", "{\"n\": 6140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.92, \"learn_time_ms\": 10448.6, \"total_train_time_s\": 14.027069568634033}", "{\"n\": 6141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.33, \"learn_time_ms\": 10234.362, \"total_train_time_s\": 12.924128770828247}", "{\"n\": 6142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.33, \"learn_time_ms\": 10139.057, \"total_train_time_s\": 13.271661758422852}", "{\"n\": 6143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.68, \"learn_time_ms\": 10204.065, \"total_train_time_s\": 13.942484617233276}", "{\"n\": 6144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.52, \"learn_time_ms\": 10273.826, \"total_train_time_s\": 15.15319275856018}", "{\"n\": 6145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.52, \"learn_time_ms\": 10358.588, \"total_train_time_s\": 14.277939319610596}", "{\"n\": 6146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.12, \"learn_time_ms\": 10448.643, \"total_train_time_s\": 15.116229057312012}", "{\"n\": 6147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.14, \"learn_time_ms\": 10448.44, \"total_train_time_s\": 15.05881118774414}", "{\"n\": 6148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.13, \"learn_time_ms\": 10338.006, \"total_train_time_s\": 13.948029518127441}", "{\"n\": 6149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.13, \"learn_time_ms\": 10417.437, \"total_train_time_s\": 13.942744731903076}", "{\"n\": 6150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.13, \"learn_time_ms\": 10420.372, \"total_train_time_s\": 14.107185363769531}", "{\"n\": 6151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.7, \"learn_time_ms\": 10457.435, \"total_train_time_s\": 13.154369354248047}", "{\"n\": 6152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.63, \"learn_time_ms\": 10444.498, \"total_train_time_s\": 13.059424638748169}", "{\"n\": 6153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.63, \"learn_time_ms\": 10451.147, \"total_train_time_s\": 14.162190198898315}", "{\"n\": 6154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 10364.439, \"total_train_time_s\": 14.29987359046936}", "{\"n\": 6155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.44, \"learn_time_ms\": 10373.429, \"total_train_time_s\": 14.501610279083252}", "{\"n\": 6156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.67, \"learn_time_ms\": 10281.384, \"total_train_time_s\": 14.159565925598145}", "{\"n\": 6157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.34, \"learn_time_ms\": 10156.353, \"total_train_time_s\": 13.517215728759766}", "{\"n\": 6158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.78, \"learn_time_ms\": 10243.684, \"total_train_time_s\": 14.777631282806396}", "{\"n\": 6159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.91, \"learn_time_ms\": 10260.181, \"total_train_time_s\": 14.086567640304565}", "{\"n\": 6160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.24, \"learn_time_ms\": 10229.213, \"total_train_time_s\": 13.717081308364868}", "{\"n\": 6161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.45, \"learn_time_ms\": 10384.059, \"total_train_time_s\": 14.628950119018555}", "{\"n\": 6162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.87, \"learn_time_ms\": 10472.737, \"total_train_time_s\": 13.898841142654419}", "{\"n\": 6163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.29, \"learn_time_ms\": 10528.077, \"total_train_time_s\": 14.802292585372925}", "{\"n\": 6164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.07, \"learn_time_ms\": 10496.303, \"total_train_time_s\": 14.210516452789307}", "{\"n\": 6165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.68, \"learn_time_ms\": 10420.973, \"total_train_time_s\": 13.725269794464111}", "{\"n\": 6166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 10499.892, \"total_train_time_s\": 14.975441694259644}", "{\"n\": 6167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.75, \"learn_time_ms\": 10690.758, \"total_train_time_s\": 15.398142337799072}", "{\"n\": 6168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.68, \"learn_time_ms\": 10720.029, \"total_train_time_s\": 15.232789754867554}", "{\"n\": 6169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.68, \"learn_time_ms\": 10756.308, \"total_train_time_s\": 14.382486581802368}", "{\"n\": 6170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.68, \"learn_time_ms\": 10789.273, \"total_train_time_s\": 14.015880584716797}", "{\"n\": 6171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.75, \"learn_time_ms\": 10746.095, \"total_train_time_s\": 14.238807201385498}", "{\"n\": 6172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.61, \"learn_time_ms\": 10750.629, \"total_train_time_s\": 14.083883047103882}", "{\"n\": 6173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.61, \"learn_time_ms\": 10800.158, \"total_train_time_s\": 15.06199026107788}", "{\"n\": 6174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.5, \"learn_time_ms\": 10811.533, \"total_train_time_s\": 14.403903007507324}", "{\"n\": 6175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.2, \"learn_time_ms\": 10904.081, \"total_train_time_s\": 14.565754175186157}", "{\"n\": 6176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.31, \"learn_time_ms\": 10801.348, \"total_train_time_s\": 13.811774015426636}", "{\"n\": 6177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.31, \"learn_time_ms\": 10550.259, \"total_train_time_s\": 13.184359788894653}", "{\"n\": 6178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.82, \"learn_time_ms\": 10394.426, \"total_train_time_s\": 13.506331205368042}", "{\"n\": 6179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.39, \"learn_time_ms\": 10310.851, \"total_train_time_s\": 13.735893487930298}", "{\"n\": 6180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.3, \"learn_time_ms\": 10302.826, \"total_train_time_s\": 13.847936391830444}", "{\"n\": 6181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.3, \"learn_time_ms\": 10294.304, \"total_train_time_s\": 14.441268682479858}", "{\"n\": 6182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.99, \"learn_time_ms\": 10240.604, \"total_train_time_s\": 13.397915124893188}", "{\"n\": 6183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.14, \"learn_time_ms\": 10126.634, \"total_train_time_s\": 14.068093299865723}", "{\"n\": 6184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.82, \"learn_time_ms\": 10232.453, \"total_train_time_s\": 15.250042200088501}", "{\"n\": 6185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.82, \"learn_time_ms\": 10154.678, \"total_train_time_s\": 13.872738599777222}", "{\"n\": 6186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.67, \"learn_time_ms\": 10139.326, \"total_train_time_s\": 13.64103102684021}", "{\"n\": 6187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.05, \"learn_time_ms\": 10258.834, \"total_train_time_s\": 14.082552194595337}", "{\"n\": 6188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.29, \"learn_time_ms\": 10304.501, \"total_train_time_s\": 14.128681182861328}", "{\"n\": 6189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.29, \"learn_time_ms\": 10263.823, \"total_train_time_s\": 13.248104572296143}", "{\"n\": 6190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.47, \"learn_time_ms\": 10339.382, \"total_train_time_s\": 14.710081815719604}", "{\"n\": 6191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.99, \"learn_time_ms\": 10329.295, \"total_train_time_s\": 14.135570049285889}", "{\"n\": 6192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.99, \"learn_time_ms\": 10329.95, \"total_train_time_s\": 13.418959617614746}", "{\"n\": 6193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.99, \"learn_time_ms\": 10380.542, \"total_train_time_s\": 14.386450052261353}", "{\"n\": 6194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.55, \"learn_time_ms\": 10230.12, \"total_train_time_s\": 13.876683950424194}", "{\"n\": 6195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.91, \"learn_time_ms\": 10242.813, \"total_train_time_s\": 14.070522785186768}", "{\"n\": 6196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.91, \"learn_time_ms\": 10260.576, \"total_train_time_s\": 13.666746377944946}", "{\"n\": 6197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.91, \"learn_time_ms\": 10311.976, \"total_train_time_s\": 14.59264063835144}", "{\"n\": 6198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.08, \"learn_time_ms\": 10322.223, \"total_train_time_s\": 14.1706862449646}", "{\"n\": 6199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.66, \"learn_time_ms\": 10445.409, \"total_train_time_s\": 14.530678749084473}", "{\"n\": 6200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.66, \"learn_time_ms\": 10459.652, \"total_train_time_s\": 15.200719118118286}", "{\"n\": 6201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.84, \"learn_time_ms\": 10559.188, \"total_train_time_s\": 15.164379835128784}", "{\"n\": 6202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3736.45, \"learn_time_ms\": 10610.159, \"total_train_time_s\": 13.999743938446045}", "{\"n\": 6203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.12, \"learn_time_ms\": 10563.167, \"total_train_time_s\": 14.126743793487549}", "{\"n\": 6204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.12, \"learn_time_ms\": 10646.239, \"total_train_time_s\": 14.655117988586426}", "{\"n\": 6205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.6, \"learn_time_ms\": 10624.549, \"total_train_time_s\": 13.789141178131104}", "{\"n\": 6206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.66, \"learn_time_ms\": 10704.537, \"total_train_time_s\": 14.674829483032227}", "{\"n\": 6207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.66, \"learn_time_ms\": 10681.427, \"total_train_time_s\": 14.507442951202393}", "{\"n\": 6208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.66, \"learn_time_ms\": 10667.948, \"total_train_time_s\": 13.976576566696167}", "{\"n\": 6209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.56, \"learn_time_ms\": 10574.008, \"total_train_time_s\": 13.60079574584961}", "{\"n\": 6210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.22, \"learn_time_ms\": 10449.39, \"total_train_time_s\": 13.597537755966187}", "{\"n\": 6211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.22, \"learn_time_ms\": 10457.452, \"total_train_time_s\": 15.217205286026001}", "{\"n\": 6212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.22, \"learn_time_ms\": 10469.247, \"total_train_time_s\": 14.034714937210083}", "{\"n\": 6213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3766.64, \"learn_time_ms\": 10435.534, \"total_train_time_s\": 13.841050624847412}", "{\"n\": 6214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.8, \"learn_time_ms\": 10434.431, \"total_train_time_s\": 14.827208757400513}", "{\"n\": 6215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.8, \"learn_time_ms\": 10417.415, \"total_train_time_s\": 13.804626226425171}", "{\"n\": 6216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3747.1, \"learn_time_ms\": 10282.058, \"total_train_time_s\": 13.289159536361694}", "{\"n\": 6217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.96, \"learn_time_ms\": 10223.345, \"total_train_time_s\": 13.912776947021484}", "{\"n\": 6218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.96, \"learn_time_ms\": 10177.007, \"total_train_time_s\": 13.67390751838684}", "{\"n\": 6219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.28, \"learn_time_ms\": 10346.47, \"total_train_time_s\": 15.330487966537476}", "{\"n\": 6220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.8, \"learn_time_ms\": 10380.493, \"total_train_time_s\": 13.844256401062012}", "{\"n\": 6221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.8, \"learn_time_ms\": 10266.545, \"total_train_time_s\": 13.953520774841309}", "{\"n\": 6222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.63, \"learn_time_ms\": 10191.458, \"total_train_time_s\": 13.518413066864014}", "{\"n\": 6223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3741.04, \"learn_time_ms\": 10267.977, \"total_train_time_s\": 14.522013664245605}", "{\"n\": 6224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3738.56, \"learn_time_ms\": 10212.914, \"total_train_time_s\": 14.033427953720093}", "{\"n\": 6225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3738.56, \"learn_time_ms\": 10265.062, \"total_train_time_s\": 14.376257181167603}", "{\"n\": 6226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.03, \"learn_time_ms\": 10389.904, \"total_train_time_s\": 14.668962717056274}", "{\"n\": 6227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3728.93, \"learn_time_ms\": 10455.599, \"total_train_time_s\": 14.73076319694519}", "{\"n\": 6228, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3731.83, \"learn_time_ms\": 10558.946, \"total_train_time_s\": 14.68638563156128}", "{\"n\": 6229, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3741.61, \"learn_time_ms\": 10522.143, \"total_train_time_s\": 15.001058578491211}", "{\"n\": 6230, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.91, \"learn_time_ms\": 10521.042, \"total_train_time_s\": 13.724704027175903}", "{\"n\": 6231, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.45, \"learn_time_ms\": 10576.367, \"total_train_time_s\": 14.5968496799469}", "{\"n\": 6232, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.65, \"learn_time_ms\": 10699.727, \"total_train_time_s\": 14.922351121902466}", "{\"n\": 6233, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.91, \"learn_time_ms\": 10736.557, \"total_train_time_s\": 14.830749034881592}", "{\"n\": 6234, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.69, \"learn_time_ms\": 10661.234, \"total_train_time_s\": 13.108576536178589}", "{\"n\": 6235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.83, \"learn_time_ms\": 10686.368, \"total_train_time_s\": 14.728183507919312}", "{\"n\": 6236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3758.79, \"learn_time_ms\": 10639.793, \"total_train_time_s\": 14.364880561828613}", "{\"n\": 6237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.72, \"learn_time_ms\": 10610.353, \"total_train_time_s\": 14.190325498580933}", "{\"n\": 6238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.72, \"learn_time_ms\": 10513.549, \"total_train_time_s\": 14.055632829666138}", "{\"n\": 6239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.86, \"learn_time_ms\": 10433.532, \"total_train_time_s\": 14.256192207336426}", "{\"n\": 6240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.58, \"learn_time_ms\": 10439.318, \"total_train_time_s\": 13.940739870071411}", "{\"n\": 6241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.58, \"learn_time_ms\": 10428.444, \"total_train_time_s\": 14.804977178573608}", "{\"n\": 6242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.59, \"learn_time_ms\": 10361.784, \"total_train_time_s\": 13.897570848464966}", "{\"n\": 6243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.49, \"learn_time_ms\": 10205.839, \"total_train_time_s\": 13.330937385559082}", "{\"n\": 6244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.49, \"learn_time_ms\": 10337.457, \"total_train_time_s\": 14.652262687683105}", "{\"n\": 6245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.49, \"learn_time_ms\": 10295.539, \"total_train_time_s\": 14.097418546676636}", "{\"n\": 6246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.88, \"learn_time_ms\": 10355.492, \"total_train_time_s\": 14.597634077072144}", "{\"n\": 6247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.02, \"learn_time_ms\": 10362.251, \"total_train_time_s\": 14.298588991165161}", "{\"n\": 6248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.02, \"learn_time_ms\": 10364.698, \"total_train_time_s\": 13.807794332504272}", "{\"n\": 6249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.02, \"learn_time_ms\": 10411.349, \"total_train_time_s\": 14.420750141143799}", "{\"n\": 6250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.92, \"learn_time_ms\": 10432.984, \"total_train_time_s\": 14.112314224243164}", "{\"n\": 6251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.92, \"learn_time_ms\": 10471.615, \"total_train_time_s\": 14.96782636642456}", "{\"n\": 6252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.92, \"learn_time_ms\": 10468.843, \"total_train_time_s\": 14.046579837799072}", "{\"n\": 6253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.38, \"learn_time_ms\": 10514.323, \"total_train_time_s\": 13.823365926742554}", "{\"n\": 6254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.79, \"learn_time_ms\": 10470.506, \"total_train_time_s\": 14.141754865646362}", "{\"n\": 6255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.79, \"learn_time_ms\": 10365.529, \"total_train_time_s\": 13.18564224243164}", "{\"n\": 6256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.31, \"learn_time_ms\": 10271.593, \"total_train_time_s\": 13.94918966293335}", "{\"n\": 6257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3745.21, \"learn_time_ms\": 10307.689, \"total_train_time_s\": 14.477524995803833}", "{\"n\": 6258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3746.0, \"learn_time_ms\": 10356.416, \"total_train_time_s\": 14.197329044342041}", "{\"n\": 6259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.8, \"learn_time_ms\": 10322.332, \"total_train_time_s\": 14.268953084945679}", "{\"n\": 6260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3732.82, \"learn_time_ms\": 10447.49, \"total_train_time_s\": 15.43566107749939}", "{\"n\": 6261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.52, \"learn_time_ms\": 10381.443, \"total_train_time_s\": 14.357312679290771}", "{\"n\": 6262, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.84, \"learn_time_ms\": 10451.241, \"total_train_time_s\": 14.680586814880371}", "{\"n\": 6263, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.35, \"learn_time_ms\": 10507.061, \"total_train_time_s\": 14.215866327285767}", "{\"n\": 6264, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.56, \"learn_time_ms\": 10513.764, \"total_train_time_s\": 14.119543075561523}", "{\"n\": 6265, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.56, \"learn_time_ms\": 10645.857, \"total_train_time_s\": 14.380738735198975}", "{\"n\": 6266, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3743.67, \"learn_time_ms\": 10670.969, \"total_train_time_s\": 13.890331268310547}", "{\"n\": 6267, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3734.49, \"learn_time_ms\": 10633.666, \"total_train_time_s\": 14.234678745269775}", "{\"n\": 6268, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.62, \"learn_time_ms\": 10557.778, \"total_train_time_s\": 13.420577049255371}", "{\"n\": 6269, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.62, \"learn_time_ms\": 10677.775, \"total_train_time_s\": 15.554842948913574}", "{\"n\": 6270, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.09, \"learn_time_ms\": 10631.651, \"total_train_time_s\": 14.913368940353394}", "{\"n\": 6271, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3708.55, \"learn_time_ms\": 10574.053, \"total_train_time_s\": 13.617587089538574}", "{\"n\": 6272, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.58, \"learn_time_ms\": 10431.465, \"total_train_time_s\": 13.315739631652832}", "{\"n\": 6273, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3696.0, \"learn_time_ms\": 10409.149, \"total_train_time_s\": 14.076983213424683}", "{\"n\": 6274, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3684.27, \"learn_time_ms\": 10349.813, \"total_train_time_s\": 13.690998554229736}", "{\"n\": 6275, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3673.33, \"learn_time_ms\": 10395.609, \"total_train_time_s\": 14.65928053855896}", "{\"n\": 6276, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3676.7, \"learn_time_ms\": 10402.838, \"total_train_time_s\": 13.910149335861206}", "{\"n\": 6277, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3664.25, \"learn_time_ms\": 10281.584, \"total_train_time_s\": 13.139502763748169}", "{\"n\": 6278, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3654.25, \"learn_time_ms\": 10412.184, \"total_train_time_s\": 14.785533428192139}", "{\"n\": 6279, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.37, \"learn_time_ms\": 10316.526, \"total_train_time_s\": 14.521639585494995}", "{\"n\": 6280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.37, \"learn_time_ms\": 10191.235, \"total_train_time_s\": 13.703116178512573}", "{\"n\": 6281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3649.96, \"learn_time_ms\": 10255.199, \"total_train_time_s\": 14.434050559997559}", "{\"n\": 6282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3649.96, \"learn_time_ms\": 10353.132, \"total_train_time_s\": 14.467374563217163}", "{\"n\": 6283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.61, \"learn_time_ms\": 10297.22, \"total_train_time_s\": 13.451361179351807}", "{\"n\": 6284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.88, \"learn_time_ms\": 10420.289, \"total_train_time_s\": 15.006077527999878}", "{\"n\": 6285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.45, \"learn_time_ms\": 10324.09, \"total_train_time_s\": 13.688931703567505}", "{\"n\": 6286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.6, \"learn_time_ms\": 10306.119, \"total_train_time_s\": 13.9998140335083}", "{\"n\": 6287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.82, \"learn_time_ms\": 10353.628, \"total_train_time_s\": 13.669367551803589}", "{\"n\": 6288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.82, \"learn_time_ms\": 10282.582, \"total_train_time_s\": 14.240225076675415}", "{\"n\": 6289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.04, \"learn_time_ms\": 10288.582, \"total_train_time_s\": 14.714739799499512}", "{\"n\": 6290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.04, \"learn_time_ms\": 10300.83, \"total_train_time_s\": 13.8753182888031}", "{\"n\": 6291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.04, \"learn_time_ms\": 10435.629, \"total_train_time_s\": 15.710341453552246}", "{\"n\": 6292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.69, \"learn_time_ms\": 10447.735, \"total_train_time_s\": 14.373475551605225}", "{\"n\": 6293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.62, \"learn_time_ms\": 10530.831, \"total_train_time_s\": 14.253431558609009}", "{\"n\": 6294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.71, \"learn_time_ms\": 10444.454, \"total_train_time_s\": 13.97581148147583}", "{\"n\": 6295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.76, \"learn_time_ms\": 10480.162, \"total_train_time_s\": 14.136095762252808}", "{\"n\": 6296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3590.15, \"learn_time_ms\": 10482.452, \"total_train_time_s\": 13.814736366271973}", "{\"n\": 6297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10566.385, \"total_train_time_s\": 14.608145236968994}", "{\"n\": 6298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10549.358, \"total_train_time_s\": 13.771244525909424}", "{\"n\": 6299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.14, \"learn_time_ms\": 10530.701, \"total_train_time_s\": 14.472565650939941}", "{\"n\": 6300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.53, \"learn_time_ms\": 10597.621, \"total_train_time_s\": 14.496521711349487}", "{\"n\": 6301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.52, \"learn_time_ms\": 10377.894, \"total_train_time_s\": 13.603933095932007}", "{\"n\": 6302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.52, \"learn_time_ms\": 10260.256, \"total_train_time_s\": 13.558761596679688}", "{\"n\": 6303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.46, \"learn_time_ms\": 10311.741, \"total_train_time_s\": 14.757415294647217}", "{\"n\": 6304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.46, \"learn_time_ms\": 10306.349, \"total_train_time_s\": 13.839563131332397}", "{\"n\": 6305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.11, \"learn_time_ms\": 10373.019, \"total_train_time_s\": 14.733111381530762}", "{\"n\": 6306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 10370.194, \"total_train_time_s\": 14.216447830200195}", "{\"n\": 6307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 10404.783, \"total_train_time_s\": 14.867430448532104}", "{\"n\": 6308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 10524.872, \"total_train_time_s\": 15.192037343978882}", "{\"n\": 6309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.83, \"learn_time_ms\": 10486.302, \"total_train_time_s\": 13.83322262763977}", "{\"n\": 6310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.83, \"learn_time_ms\": 10474.148, \"total_train_time_s\": 14.435868978500366}", "{\"n\": 6311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.7, \"learn_time_ms\": 10537.788, \"total_train_time_s\": 14.079451322555542}", "{\"n\": 6312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.23, \"learn_time_ms\": 10677.367, \"total_train_time_s\": 14.561956644058228}", "{\"n\": 6313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.96, \"learn_time_ms\": 10542.851, \"total_train_time_s\": 13.762975215911865}", "{\"n\": 6314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.96, \"learn_time_ms\": 10557.731, \"total_train_time_s\": 14.168626308441162}", "{\"n\": 6315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.07, \"learn_time_ms\": 10566.339, \"total_train_time_s\": 15.230047225952148}", "{\"n\": 6316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.3, \"learn_time_ms\": 10699.853, \"total_train_time_s\": 15.224769592285156}", "{\"n\": 6317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.46, \"learn_time_ms\": 10599.938, \"total_train_time_s\": 13.86908507347107}", "{\"n\": 6318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.31, \"learn_time_ms\": 10593.177, \"total_train_time_s\": 14.960101842880249}", "{\"n\": 6319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10632.379, \"total_train_time_s\": 14.234914779663086}", "{\"n\": 6320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10788.409, \"total_train_time_s\": 15.923256158828735}", "{\"n\": 6321, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.08, \"learn_time_ms\": 10724.959, \"total_train_time_s\": 13.488352298736572}", "{\"n\": 6322, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.08, \"learn_time_ms\": 10729.154, \"total_train_time_s\": 14.872406959533691}", "{\"n\": 6323, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.95, \"learn_time_ms\": 10857.167, \"total_train_time_s\": 14.813298463821411}", "{\"n\": 6324, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.95, \"learn_time_ms\": 10923.469, \"total_train_time_s\": 14.837284326553345}", "{\"n\": 6325, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3540.34, \"learn_time_ms\": 10810.339, \"total_train_time_s\": 13.846262693405151}", "{\"n\": 6326, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.78, \"learn_time_ms\": 10640.611, \"total_train_time_s\": 13.459736108779907}", "{\"n\": 6327, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.1, \"learn_time_ms\": 10726.156, \"total_train_time_s\": 14.580158472061157}", "{\"n\": 6328, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.42, \"learn_time_ms\": 10581.198, \"total_train_time_s\": 13.516612529754639}", "{\"n\": 6329, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.42, \"learn_time_ms\": 10616.096, \"total_train_time_s\": 14.803135871887207}", "{\"n\": 6330, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.38, \"learn_time_ms\": 10390.019, \"total_train_time_s\": 13.607094287872314}", "{\"n\": 6331, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.52, \"learn_time_ms\": 10564.734, \"total_train_time_s\": 15.435986042022705}", "{\"n\": 6332, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.09, \"learn_time_ms\": 10575.604, \"total_train_time_s\": 14.561919212341309}", "{\"n\": 6333, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.75, \"learn_time_ms\": 10505.673, \"total_train_time_s\": 14.09855341911316}", "{\"n\": 6334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3551.01, \"learn_time_ms\": 10355.436, \"total_train_time_s\": 13.134346723556519}", "{\"n\": 6335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.19, \"learn_time_ms\": 10397.282, \"total_train_time_s\": 14.21613621711731}", "{\"n\": 6336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.19, \"learn_time_ms\": 10518.182, \"total_train_time_s\": 14.673507452011108}", "{\"n\": 6337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.31, \"learn_time_ms\": 10483.774, \"total_train_time_s\": 14.343021392822266}", "{\"n\": 6338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.66, \"learn_time_ms\": 10434.84, \"total_train_time_s\": 13.249305009841919}", "{\"n\": 6339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.89, \"learn_time_ms\": 10227.694, \"total_train_time_s\": 12.719948530197144}", "{\"n\": 6340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.61, \"learn_time_ms\": 10350.317, \"total_train_time_s\": 15.241853713989258}", "{\"n\": 6341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.61, \"learn_time_ms\": 10255.912, \"total_train_time_s\": 14.250510454177856}", "{\"n\": 6342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.15, \"learn_time_ms\": 10254.226, \"total_train_time_s\": 14.732353448867798}", "{\"n\": 6343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.57, \"learn_time_ms\": 10253.747, \"total_train_time_s\": 14.107652425765991}", "{\"n\": 6344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.57, \"learn_time_ms\": 10328.475, \"total_train_time_s\": 13.96645450592041}", "{\"n\": 6345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.63, \"learn_time_ms\": 10382.466, \"total_train_time_s\": 14.665968179702759}", "{\"n\": 6346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.4, \"learn_time_ms\": 10394.874, \"total_train_time_s\": 15.056633234024048}", "{\"n\": 6347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.42, \"learn_time_ms\": 10362.932, \"total_train_time_s\": 14.080842971801758}", "{\"n\": 6348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.54, \"learn_time_ms\": 10488.32, \"total_train_time_s\": 14.562687873840332}", "{\"n\": 6349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.6, \"learn_time_ms\": 10738.304, \"total_train_time_s\": 15.014253616333008}", "{\"n\": 6350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.27, \"learn_time_ms\": 10726.675, \"total_train_time_s\": 14.817903280258179}", "{\"n\": 6351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.27, \"learn_time_ms\": 10643.841, \"total_train_time_s\": 13.694397211074829}", "{\"n\": 6352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.31, \"learn_time_ms\": 10603.028, \"total_train_time_s\": 14.389255285263062}", "{\"n\": 6353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.31, \"learn_time_ms\": 10587.949, \"total_train_time_s\": 14.09300947189331}", "{\"n\": 6354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.45, \"learn_time_ms\": 10617.825, \"total_train_time_s\": 14.264511585235596}", "{\"n\": 6355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.34, \"learn_time_ms\": 10524.714, \"total_train_time_s\": 13.9481520652771}", "{\"n\": 6356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.09, \"learn_time_ms\": 10348.704, \"total_train_time_s\": 12.910237312316895}", "{\"n\": 6357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.09, \"learn_time_ms\": 10328.918, \"total_train_time_s\": 13.609232664108276}", "{\"n\": 6358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.39, \"learn_time_ms\": 10367.787, \"total_train_time_s\": 14.862200736999512}", "{\"n\": 6359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.93, \"learn_time_ms\": 10268.886, \"total_train_time_s\": 14.06471300125122}", "{\"n\": 6360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.74, \"learn_time_ms\": 10205.991, \"total_train_time_s\": 13.9996919631958}", "{\"n\": 6361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.68, \"learn_time_ms\": 10195.18, \"total_train_time_s\": 13.522774457931519}", "{\"n\": 6362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.32, \"learn_time_ms\": 10141.474, \"total_train_time_s\": 13.937559843063354}", "{\"n\": 6363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.89, \"learn_time_ms\": 10184.198, \"total_train_time_s\": 14.515793323516846}", "{\"n\": 6364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.0, \"learn_time_ms\": 10155.837, \"total_train_time_s\": 14.047836065292358}", "{\"n\": 6365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.09, \"learn_time_ms\": 10126.129, \"total_train_time_s\": 13.400068998336792}", "{\"n\": 6366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.94, \"learn_time_ms\": 10190.249, \"total_train_time_s\": 13.856285572052002}", "{\"n\": 6367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.56, \"learn_time_ms\": 10197.583, \"total_train_time_s\": 13.637412548065186}", "{\"n\": 6368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.78, \"learn_time_ms\": 10058.118, \"total_train_time_s\": 13.351245403289795}", "{\"n\": 6369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.78, \"learn_time_ms\": 10169.563, \"total_train_time_s\": 15.225382566452026}", "{\"n\": 6370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.99, \"learn_time_ms\": 10114.371, \"total_train_time_s\": 13.457940101623535}", "{\"n\": 6371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.99, \"learn_time_ms\": 10165.008, \"total_train_time_s\": 13.839897871017456}", "{\"n\": 6372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10215.358, \"total_train_time_s\": 14.260652303695679}", "{\"n\": 6373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.73, \"learn_time_ms\": 10143.068, \"total_train_time_s\": 13.648310899734497}", "{\"n\": 6374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.73, \"learn_time_ms\": 10134.773, \"total_train_time_s\": 13.815560340881348}", "{\"n\": 6375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.73, \"learn_time_ms\": 10270.449, \"total_train_time_s\": 14.870180606842041}", "{\"n\": 6376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.88, \"learn_time_ms\": 10355.337, \"total_train_time_s\": 14.694683313369751}", "{\"n\": 6377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.48, \"learn_time_ms\": 10356.888, \"total_train_time_s\": 13.869950771331787}", "{\"n\": 6378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.48, \"learn_time_ms\": 10449.683, \"total_train_time_s\": 14.393750190734863}", "{\"n\": 6379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.6, \"learn_time_ms\": 10334.081, \"total_train_time_s\": 14.034741640090942}", "{\"n\": 6380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.89, \"learn_time_ms\": 10423.621, \"total_train_time_s\": 14.465570211410522}", "{\"n\": 6381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.96, \"learn_time_ms\": 10526.965, \"total_train_time_s\": 14.872617959976196}", "{\"n\": 6382, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.77, \"learn_time_ms\": 10516.534, \"total_train_time_s\": 14.01084303855896}", "{\"n\": 6383, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.77, \"learn_time_ms\": 10487.926, \"total_train_time_s\": 13.229328393936157}", "{\"n\": 6384, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.42, \"learn_time_ms\": 10553.038, \"total_train_time_s\": 14.5107421875}", "{\"n\": 6385, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.22, \"learn_time_ms\": 10460.055, \"total_train_time_s\": 13.845322608947754}", "{\"n\": 6386, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.51, \"learn_time_ms\": 10370.059, \"total_train_time_s\": 13.914907693862915}", "{\"n\": 6387, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.11, \"learn_time_ms\": 10509.87, \"total_train_time_s\": 15.209851503372192}", "{\"n\": 6388, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.16, \"learn_time_ms\": 10479.861, \"total_train_time_s\": 13.922382354736328}", "{\"n\": 6389, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.07, \"learn_time_ms\": 10563.146, \"total_train_time_s\": 14.837929725646973}", "{\"n\": 6390, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.63, \"learn_time_ms\": 10661.141, \"total_train_time_s\": 15.61405348777771}", "{\"n\": 6391, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.18, \"learn_time_ms\": 10542.714, \"total_train_time_s\": 13.71791958808899}", "{\"n\": 6392, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.95, \"learn_time_ms\": 10537.985, \"total_train_time_s\": 14.34310507774353}", "{\"n\": 6393, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.87, \"learn_time_ms\": 10666.436, \"total_train_time_s\": 14.682482481002808}", "{\"n\": 6394, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10645.692, \"total_train_time_s\": 14.385127544403076}", "{\"n\": 6395, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10589.2, \"total_train_time_s\": 13.29770016670227}", "{\"n\": 6396, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.8, \"learn_time_ms\": 10669.076, \"total_train_time_s\": 14.529564619064331}", "{\"n\": 6397, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.02, \"learn_time_ms\": 10604.552, \"total_train_time_s\": 14.429411888122559}", "{\"n\": 6398, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.54, \"learn_time_ms\": 10710.401, \"total_train_time_s\": 14.857245683670044}", "{\"n\": 6399, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.69, \"learn_time_ms\": 10580.592, \"total_train_time_s\": 13.498974800109863}", "{\"n\": 6400, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.69, \"learn_time_ms\": 10541.123, \"total_train_time_s\": 15.310128211975098}", "{\"n\": 6401, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.78, \"learn_time_ms\": 10651.058, \"total_train_time_s\": 14.697788000106812}", "{\"n\": 6402, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.78, \"learn_time_ms\": 10655.049, \"total_train_time_s\": 14.186310768127441}", "{\"n\": 6403, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.66, \"learn_time_ms\": 10577.418, \"total_train_time_s\": 13.760942935943604}", "{\"n\": 6404, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.98, \"learn_time_ms\": 10543.659, \"total_train_time_s\": 13.963323831558228}", "{\"n\": 6405, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.35, \"learn_time_ms\": 10635.878, \"total_train_time_s\": 14.144179582595825}", "{\"n\": 6406, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.69, \"learn_time_ms\": 10567.079, \"total_train_time_s\": 13.99287748336792}", "{\"n\": 6407, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.89, \"learn_time_ms\": 10478.43, \"total_train_time_s\": 13.522845268249512}", "{\"n\": 6408, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.0, \"learn_time_ms\": 10295.012, \"total_train_time_s\": 13.176188230514526}", "{\"n\": 6409, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.0, \"learn_time_ms\": 10320.298, \"total_train_time_s\": 14.042896509170532}", "{\"n\": 6410, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.99, \"learn_time_ms\": 10310.541, \"total_train_time_s\": 15.215728521347046}", "{\"n\": 6411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.72, \"learn_time_ms\": 10294.589, \"total_train_time_s\": 14.538231611251831}", "{\"n\": 6412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.72, \"learn_time_ms\": 10335.627, \"total_train_time_s\": 14.42005443572998}", "{\"n\": 6413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.72, \"learn_time_ms\": 10348.923, \"total_train_time_s\": 13.966891288757324}", "{\"n\": 6414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.52, \"learn_time_ms\": 10332.741, \"total_train_time_s\": 13.774595260620117}", "{\"n\": 6415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.08, \"learn_time_ms\": 10380.876, \"total_train_time_s\": 14.843863248825073}", "{\"n\": 6416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.08, \"learn_time_ms\": 10469.411, \"total_train_time_s\": 14.720786571502686}", "{\"n\": 6417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.32, \"learn_time_ms\": 10452.779, \"total_train_time_s\": 13.565794229507446}", "{\"n\": 6418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.11, \"learn_time_ms\": 10545.021, \"total_train_time_s\": 14.003337144851685}", "{\"n\": 6419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.11, \"learn_time_ms\": 10463.564, \"total_train_time_s\": 13.051262140274048}", "{\"n\": 6420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.05, \"learn_time_ms\": 10304.708, \"total_train_time_s\": 13.474349737167358}", "{\"n\": 6421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.2, \"learn_time_ms\": 10302.571, \"total_train_time_s\": 14.768120288848877}", "{\"n\": 6422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.09, \"learn_time_ms\": 10164.13, \"total_train_time_s\": 12.992338418960571}", "{\"n\": 6423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.09, \"learn_time_ms\": 10166.962, \"total_train_time_s\": 14.156249761581421}", "{\"n\": 6424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.91, \"learn_time_ms\": 10116.074, \"total_train_time_s\": 13.219787120819092}", "{\"n\": 6425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.9, \"learn_time_ms\": 9984.391, \"total_train_time_s\": 13.659762620925903}", "{\"n\": 6426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.9, \"learn_time_ms\": 10020.964, \"total_train_time_s\": 15.021058320999146}", "{\"n\": 6427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.44, \"learn_time_ms\": 10127.101, \"total_train_time_s\": 14.728473663330078}", "{\"n\": 6428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.29, \"learn_time_ms\": 10140.785, \"total_train_time_s\": 14.4210364818573}", "{\"n\": 6429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.97, \"learn_time_ms\": 10299.76, \"total_train_time_s\": 14.586992979049683}", "{\"n\": 6430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.47, \"learn_time_ms\": 10447.788, \"total_train_time_s\": 14.808934211730957}", "{\"n\": 6431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.96, \"learn_time_ms\": 10423.278, \"total_train_time_s\": 14.566776752471924}", "{\"n\": 6432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.15, \"learn_time_ms\": 10593.29, \"total_train_time_s\": 15.237869024276733}", "{\"n\": 6433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.71, \"learn_time_ms\": 10640.449, \"total_train_time_s\": 14.565013647079468}", "{\"n\": 6434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.87, \"learn_time_ms\": 10692.211, \"total_train_time_s\": 13.783018112182617}", "{\"n\": 6435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.87, \"learn_time_ms\": 10709.888, \"total_train_time_s\": 13.563618898391724}", "{\"n\": 6436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.45, \"learn_time_ms\": 10627.552, \"total_train_time_s\": 14.086641788482666}", "{\"n\": 6437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.57, \"learn_time_ms\": 10601.146, \"total_train_time_s\": 14.605663776397705}", "{\"n\": 6438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.58, \"learn_time_ms\": 10576.969, \"total_train_time_s\": 13.896221160888672}", "{\"n\": 6439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.09, \"learn_time_ms\": 10505.934, \"total_train_time_s\": 13.892303466796875}", "{\"n\": 6440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.09, \"learn_time_ms\": 10366.949, \"total_train_time_s\": 13.323706865310669}", "{\"n\": 6441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.4, \"learn_time_ms\": 10415.212, \"total_train_time_s\": 14.910406112670898}", "{\"n\": 6442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.4, \"learn_time_ms\": 10310.327, \"total_train_time_s\": 13.874990940093994}", "{\"n\": 6443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10273.717, \"total_train_time_s\": 14.233249425888062}", "{\"n\": 6444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10203.855, \"total_train_time_s\": 13.161051988601685}", "{\"n\": 6445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 10233.15, \"total_train_time_s\": 13.707441329956055}", "{\"n\": 6446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.32, \"learn_time_ms\": 10170.64, \"total_train_time_s\": 13.575578451156616}", "{\"n\": 6447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.32, \"learn_time_ms\": 10217.47, \"total_train_time_s\": 14.633111953735352}", "{\"n\": 6448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.08, \"learn_time_ms\": 10211.914, \"total_train_time_s\": 13.805123090744019}", "{\"n\": 6449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.29, \"learn_time_ms\": 10123.522, \"total_train_time_s\": 12.959974765777588}", "{\"n\": 6450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.53, \"learn_time_ms\": 10134.753, \"total_train_time_s\": 13.913504838943481}", "{\"n\": 6451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.43, \"learn_time_ms\": 10089.015, \"total_train_time_s\": 14.324884414672852}", "{\"n\": 6452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.96, \"learn_time_ms\": 10138.735, \"total_train_time_s\": 14.199453353881836}", "{\"n\": 6453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.62, \"learn_time_ms\": 10042.024, \"total_train_time_s\": 13.27329707145691}", "{\"n\": 6454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.69, \"learn_time_ms\": 10141.966, \"total_train_time_s\": 14.22613787651062}", "{\"n\": 6455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.64, \"learn_time_ms\": 10084.438, \"total_train_time_s\": 13.173989057540894}", "{\"n\": 6456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.45, \"learn_time_ms\": 10178.526, \"total_train_time_s\": 14.440117120742798}", "{\"n\": 6457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.38, \"learn_time_ms\": 10002.828, \"total_train_time_s\": 13.115744352340698}", "{\"n\": 6458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.63, \"learn_time_ms\": 10058.727, \"total_train_time_s\": 14.320281028747559}", "{\"n\": 6459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.63, \"learn_time_ms\": 10169.57, \"total_train_time_s\": 14.185364007949829}", "{\"n\": 6460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.88, \"learn_time_ms\": 10191.7, \"total_train_time_s\": 13.865599393844604}", "{\"n\": 6461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.62, \"learn_time_ms\": 10188.937, \"total_train_time_s\": 14.256251573562622}", "{\"n\": 6462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.65, \"learn_time_ms\": 10147.945, \"total_train_time_s\": 13.754067659378052}", "{\"n\": 6463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.65, \"learn_time_ms\": 10299.504, \"total_train_time_s\": 14.85033369064331}", "{\"n\": 6464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.82, \"learn_time_ms\": 10317.417, \"total_train_time_s\": 14.523516654968262}", "{\"n\": 6465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3586.85, \"learn_time_ms\": 10492.604, \"total_train_time_s\": 14.992035388946533}", "{\"n\": 6466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.58, \"learn_time_ms\": 10423.65, \"total_train_time_s\": 13.726670503616333}", "{\"n\": 6467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.58, \"learn_time_ms\": 10464.016, \"total_train_time_s\": 13.369649171829224}", "{\"n\": 6468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.73, \"learn_time_ms\": 10407.767, \"total_train_time_s\": 13.799437761306763}", "{\"n\": 6469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.36, \"learn_time_ms\": 10529.332, \"total_train_time_s\": 15.778325319290161}", "{\"n\": 6470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.51, \"learn_time_ms\": 10703.708, \"total_train_time_s\": 15.64993691444397}", "{\"n\": 6471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.51, \"learn_time_ms\": 10632.24, \"total_train_time_s\": 13.82265019416809}", "{\"n\": 6472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.93, \"learn_time_ms\": 10586.859, \"total_train_time_s\": 13.539860486984253}", "{\"n\": 6473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10619.451, \"total_train_time_s\": 15.189853191375732}", "{\"n\": 6474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10612.396, \"total_train_time_s\": 14.519274711608887}", "{\"n\": 6475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.96, \"learn_time_ms\": 10483.187, \"total_train_time_s\": 13.767001867294312}", "{\"n\": 6476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.09, \"learn_time_ms\": 10487.206, \"total_train_time_s\": 14.125010967254639}", "{\"n\": 6477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.09, \"learn_time_ms\": 10587.821, \"total_train_time_s\": 14.324947834014893}", "{\"n\": 6478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.09, \"learn_time_ms\": 10601.832, \"total_train_time_s\": 14.267996549606323}", "{\"n\": 6479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.53, \"learn_time_ms\": 10605.084, \"total_train_time_s\": 15.303401231765747}", "{\"n\": 6480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 10418.669, \"total_train_time_s\": 13.809748888015747}", "{\"n\": 6481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 10416.163, \"total_train_time_s\": 13.687777757644653}", "{\"n\": 6482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 10513.133, \"total_train_time_s\": 14.25736403465271}", "{\"n\": 6483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.16, \"learn_time_ms\": 10424.35, \"total_train_time_s\": 14.031944513320923}", "{\"n\": 6484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.6, \"learn_time_ms\": 10482.491, \"total_train_time_s\": 14.836498975753784}", "{\"n\": 6485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.6, \"learn_time_ms\": 10546.671, \"total_train_time_s\": 14.40237283706665}", "{\"n\": 6486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.19, \"learn_time_ms\": 10525.222, \"total_train_time_s\": 13.707728624343872}", "{\"n\": 6487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.7, \"learn_time_ms\": 10441.385, \"total_train_time_s\": 13.530900001525879}", "{\"n\": 6488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.11, \"learn_time_ms\": 10416.369, \"total_train_time_s\": 14.097992897033691}", "{\"n\": 6489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.89, \"learn_time_ms\": 10276.363, \"total_train_time_s\": 14.05054759979248}", "{\"n\": 6490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.18, \"learn_time_ms\": 10282.311, \"total_train_time_s\": 13.826171398162842}", "{\"n\": 6491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.15, \"learn_time_ms\": 10364.395, \"total_train_time_s\": 14.279041528701782}", "{\"n\": 6492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.56, \"learn_time_ms\": 10271.387, \"total_train_time_s\": 13.378458976745605}", "{\"n\": 6493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.56, \"learn_time_ms\": 10172.809, \"total_train_time_s\": 13.46699857711792}", "{\"n\": 6494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.2, \"learn_time_ms\": 10117.933, \"total_train_time_s\": 14.294445753097534}", "{\"n\": 6495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.28, \"learn_time_ms\": 10115.967, \"total_train_time_s\": 14.290136814117432}", "{\"n\": 6496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.65, \"learn_time_ms\": 10227.2, \"total_train_time_s\": 14.770795583724976}", "{\"n\": 6497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.02, \"learn_time_ms\": 10202.895, \"total_train_time_s\": 13.379390954971313}", "{\"n\": 6498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.78, \"learn_time_ms\": 10217.527, \"total_train_time_s\": 13.9463951587677}", "{\"n\": 6499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.24, \"learn_time_ms\": 10256.241, \"total_train_time_s\": 14.366119623184204}", "{\"n\": 6500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.24, \"learn_time_ms\": 10368.921, \"total_train_time_s\": 15.018499612808228}", "{\"n\": 6501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10265.246, \"total_train_time_s\": 13.254874229431152}", "{\"n\": 6502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.92, \"learn_time_ms\": 10285.377, \"total_train_time_s\": 13.65619945526123}", "{\"n\": 6503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.92, \"learn_time_ms\": 10339.994, \"total_train_time_s\": 13.713338375091553}", "{\"n\": 6504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.64, \"learn_time_ms\": 10305.765, \"total_train_time_s\": 14.115410566329956}", "{\"n\": 6505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.48, \"learn_time_ms\": 10322.234, \"total_train_time_s\": 14.694350719451904}", "{\"n\": 6506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.36, \"learn_time_ms\": 10232.259, \"total_train_time_s\": 13.925679683685303}", "{\"n\": 6507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.03, \"learn_time_ms\": 10306.83, \"total_train_time_s\": 14.05430293083191}", "{\"n\": 6508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.46, \"learn_time_ms\": 10282.633, \"total_train_time_s\": 13.896366357803345}", "{\"n\": 6509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.44, \"learn_time_ms\": 10412.259, \"total_train_time_s\": 15.616058588027954}", "{\"n\": 6510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.57, \"learn_time_ms\": 10344.164, \"total_train_time_s\": 14.399638891220093}", "{\"n\": 6511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.17, \"learn_time_ms\": 10412.567, \"total_train_time_s\": 14.065426349639893}", "{\"n\": 6512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.28, \"learn_time_ms\": 10493.29, \"total_train_time_s\": 14.585018634796143}", "{\"n\": 6513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.79, \"learn_time_ms\": 10479.547, \"total_train_time_s\": 13.496978044509888}", "{\"n\": 6514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.15, \"learn_time_ms\": 10474.864, \"total_train_time_s\": 13.963171005249023}", "{\"n\": 6515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.77, \"learn_time_ms\": 10470.629, \"total_train_time_s\": 14.66871690750122}", "{\"n\": 6516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.77, \"learn_time_ms\": 10542.26, \"total_train_time_s\": 14.698591232299805}", "{\"n\": 6517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.43, \"learn_time_ms\": 10556.448, \"total_train_time_s\": 14.36710500717163}", "{\"n\": 6518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.91, \"learn_time_ms\": 10577.861, \"total_train_time_s\": 13.900578022003174}", "{\"n\": 6519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.06, \"learn_time_ms\": 10506.258, \"total_train_time_s\": 14.935258626937866}", "{\"n\": 6520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.06, \"learn_time_ms\": 10572.871, \"total_train_time_s\": 15.00418996810913}", "{\"n\": 6521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.2, \"learn_time_ms\": 10625.236, \"total_train_time_s\": 14.547900199890137}", "{\"n\": 6522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.05, \"learn_time_ms\": 10627.058, \"total_train_time_s\": 14.43267035484314}", "{\"n\": 6523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 10691.618, \"total_train_time_s\": 14.156686782836914}", "{\"n\": 6524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 10749.657, \"total_train_time_s\": 14.649006843566895}", "{\"n\": 6525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.88, \"learn_time_ms\": 10736.033, \"total_train_time_s\": 14.283117294311523}", "{\"n\": 6526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.88, \"learn_time_ms\": 10722.323, \"total_train_time_s\": 14.376728534698486}", "{\"n\": 6527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.77, \"learn_time_ms\": 10638.884, \"total_train_time_s\": 13.369697332382202}", "{\"n\": 6528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.98, \"learn_time_ms\": 10525.843, \"total_train_time_s\": 13.010346412658691}", "{\"n\": 6529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.99, \"learn_time_ms\": 10408.68, \"total_train_time_s\": 13.812458753585815}", "{\"n\": 6530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.99, \"learn_time_ms\": 10358.677, \"total_train_time_s\": 14.632699728012085}", "{\"n\": 6531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.68, \"learn_time_ms\": 10236.498, \"total_train_time_s\": 13.587222337722778}", "{\"n\": 6532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.74, \"learn_time_ms\": 10226.893, \"total_train_time_s\": 14.305467367172241}", "{\"n\": 6533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 10271.16, \"total_train_time_s\": 14.541546106338501}", "{\"n\": 6534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10247.775, \"total_train_time_s\": 14.30958366394043}", "{\"n\": 6535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10243.056, \"total_train_time_s\": 14.580609321594238}", "{\"n\": 6536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.99, \"learn_time_ms\": 10191.288, \"total_train_time_s\": 14.06311297416687}", "{\"n\": 6537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.47, \"learn_time_ms\": 10158.258, \"total_train_time_s\": 12.965044260025024}", "{\"n\": 6538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.26, \"learn_time_ms\": 10284.616, \"total_train_time_s\": 14.166847944259644}", "{\"n\": 6539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.5, \"learn_time_ms\": 10223.719, \"total_train_time_s\": 13.182059526443481}", "{\"n\": 6540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.5, \"learn_time_ms\": 10187.566, \"total_train_time_s\": 14.113339900970459}", "{\"n\": 6541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.11, \"learn_time_ms\": 10174.596, \"total_train_time_s\": 13.157912731170654}", "{\"n\": 6542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.06, \"learn_time_ms\": 10273.122, \"total_train_time_s\": 15.626724243164062}", "{\"n\": 6543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.06, \"learn_time_ms\": 10262.087, \"total_train_time_s\": 14.564361810684204}", "{\"n\": 6544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.64, \"learn_time_ms\": 10153.714, \"total_train_time_s\": 13.23292088508606}", "{\"n\": 6545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.14, \"learn_time_ms\": 10101.847, \"total_train_time_s\": 13.71915340423584}", "{\"n\": 6546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.14, \"learn_time_ms\": 10173.07, \"total_train_time_s\": 14.79514193534851}", "{\"n\": 6547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.4, \"learn_time_ms\": 10245.817, \"total_train_time_s\": 14.025192499160767}", "{\"n\": 6548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.4, \"learn_time_ms\": 10304.301, \"total_train_time_s\": 14.971110343933105}", "{\"n\": 6549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.09, \"learn_time_ms\": 10401.762, \"total_train_time_s\": 14.050412654876709}", "{\"n\": 6550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.67, \"learn_time_ms\": 10416.938, \"total_train_time_s\": 14.032783508300781}", "{\"n\": 6551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.67, \"learn_time_ms\": 10459.359, \"total_train_time_s\": 13.483893632888794}", "{\"n\": 6552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.15, \"learn_time_ms\": 10315.36, \"total_train_time_s\": 13.86194109916687}", "{\"n\": 6553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.37, \"learn_time_ms\": 10321.567, \"total_train_time_s\": 14.51579999923706}", "{\"n\": 6554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.37, \"learn_time_ms\": 10464.534, \"total_train_time_s\": 14.815276622772217}", "{\"n\": 6555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.26, \"learn_time_ms\": 10586.674, \"total_train_time_s\": 15.032654523849487}", "{\"n\": 6556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.79, \"learn_time_ms\": 10520.792, \"total_train_time_s\": 13.927044868469238}", "{\"n\": 6557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.79, \"learn_time_ms\": 10561.215, \"total_train_time_s\": 14.27706527709961}", "{\"n\": 6558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.25, \"learn_time_ms\": 10509.099, \"total_train_time_s\": 14.047611951828003}", "{\"n\": 6559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.2, \"learn_time_ms\": 10438.736, \"total_train_time_s\": 13.565737962722778}", "{\"n\": 6560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.73, \"learn_time_ms\": 10345.925, \"total_train_time_s\": 13.36465048789978}", "{\"n\": 6561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.73, \"learn_time_ms\": 10338.696, \"total_train_time_s\": 13.815450429916382}", "{\"n\": 6562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 10333.03, \"total_train_time_s\": 13.885448455810547}", "{\"n\": 6563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 10279.312, \"total_train_time_s\": 14.123000860214233}", "{\"n\": 6564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 10249.344, \"total_train_time_s\": 14.318011283874512}", "{\"n\": 6565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 10185.04, \"total_train_time_s\": 14.58378553390503}", "{\"n\": 6566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.01, \"learn_time_ms\": 10226.545, \"total_train_time_s\": 14.347539901733398}", "{\"n\": 6567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.34, \"learn_time_ms\": 10193.359, \"total_train_time_s\": 13.972766399383545}", "{\"n\": 6568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.34, \"learn_time_ms\": 10309.006, \"total_train_time_s\": 15.086726427078247}", "{\"n\": 6569, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.34, \"learn_time_ms\": 10415.716, \"total_train_time_s\": 14.625738620758057}", "{\"n\": 6570, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.59, \"learn_time_ms\": 10500.341, \"total_train_time_s\": 13.986371517181396}", "{\"n\": 6571, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.38, \"learn_time_ms\": 10575.151, \"total_train_time_s\": 14.445230484008789}", "{\"n\": 6572, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.38, \"learn_time_ms\": 10646.813, \"total_train_time_s\": 14.855533599853516}", "{\"n\": 6573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.41, \"learn_time_ms\": 10639.093, \"total_train_time_s\": 13.9346182346344}", "{\"n\": 6574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.04, \"learn_time_ms\": 10747.769, \"total_train_time_s\": 15.237909317016602}", "{\"n\": 6575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.28, \"learn_time_ms\": 10812.564, \"total_train_time_s\": 14.908170223236084}", "{\"n\": 6576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.92, \"learn_time_ms\": 10839.86, \"total_train_time_s\": 14.864099264144897}", "{\"n\": 6577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.01, \"learn_time_ms\": 10917.51, \"total_train_time_s\": 14.761701822280884}", "{\"n\": 6578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.01, \"learn_time_ms\": 10788.766, \"total_train_time_s\": 14.354313850402832}", "{\"n\": 6579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10773.08, \"total_train_time_s\": 14.332213640213013}", "{\"n\": 6580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.61, \"learn_time_ms\": 10815.127, \"total_train_time_s\": 14.600188970565796}", "{\"n\": 6581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.61, \"learn_time_ms\": 10879.042, \"total_train_time_s\": 15.136353969573975}", "{\"n\": 6582, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.51, \"learn_time_ms\": 10759.949, \"total_train_time_s\": 13.311256408691406}", "{\"n\": 6583, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.14, \"learn_time_ms\": 10723.747, \"total_train_time_s\": 13.45794129371643}", "{\"n\": 6584, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.08, \"learn_time_ms\": 10544.576, \"total_train_time_s\": 13.481656312942505}", "{\"n\": 6585, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.25, \"learn_time_ms\": 10438.792, \"total_train_time_s\": 14.028886556625366}", "{\"n\": 6586, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.23, \"learn_time_ms\": 10419.341, \"total_train_time_s\": 14.37969970703125}", "{\"n\": 6587, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.68, \"learn_time_ms\": 10458.916, \"total_train_time_s\": 14.941738843917847}", "{\"n\": 6588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.35, \"learn_time_ms\": 10455.539, \"total_train_time_s\": 14.20457935333252}", "{\"n\": 6589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.35, \"learn_time_ms\": 10520.923, \"total_train_time_s\": 15.004208326339722}", "{\"n\": 6590, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.63, \"learn_time_ms\": 10489.519, \"total_train_time_s\": 14.25332498550415}", "{\"n\": 6591, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.92, \"learn_time_ms\": 10473.574, \"total_train_time_s\": 14.663491010665894}", "{\"n\": 6592, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.92, \"learn_time_ms\": 10560.747, \"total_train_time_s\": 14.54064154624939}", "{\"n\": 6593, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.64, \"learn_time_ms\": 10606.315, \"total_train_time_s\": 14.304545402526855}", "{\"n\": 6594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.75, \"learn_time_ms\": 10678.176, \"total_train_time_s\": 14.262197971343994}", "{\"n\": 6595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 10723.952, \"total_train_time_s\": 14.655120611190796}", "{\"n\": 6596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 10659.264, \"total_train_time_s\": 14.321130514144897}", "{\"n\": 6597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 10592.297, \"total_train_time_s\": 14.269217252731323}", "{\"n\": 6598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.01, \"learn_time_ms\": 10628.669, \"total_train_time_s\": 14.350741863250732}", "{\"n\": 6599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.97, \"learn_time_ms\": 10501.054, \"total_train_time_s\": 13.601250410079956}", "{\"n\": 6600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.97, \"learn_time_ms\": 10510.261, \"total_train_time_s\": 14.098824262619019}", "{\"n\": 6601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.52, \"learn_time_ms\": 10469.058, \"total_train_time_s\": 14.385226488113403}", "{\"n\": 6602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.77, \"learn_time_ms\": 10448.853, \"total_train_time_s\": 14.251527786254883}", "{\"n\": 6603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.77, \"learn_time_ms\": 10452.659, \"total_train_time_s\": 14.024179697036743}", "{\"n\": 6604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.58, \"learn_time_ms\": 10385.31, \"total_train_time_s\": 13.595756530761719}", "{\"n\": 6605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 10434.801, \"total_train_time_s\": 14.871300220489502}", "{\"n\": 6606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 10458.76, \"total_train_time_s\": 14.33669376373291}", "{\"n\": 6607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 10392.664, \"total_train_time_s\": 13.695623874664307}", "{\"n\": 6608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.34, \"learn_time_ms\": 10375.566, \"total_train_time_s\": 14.34496784210205}", "{\"n\": 6609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10334.238, \"total_train_time_s\": 13.303606986999512}", "{\"n\": 6610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10417.531, \"total_train_time_s\": 15.418359994888306}", "{\"n\": 6611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10394.806, \"total_train_time_s\": 14.223950624465942}", "{\"n\": 6612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.67, \"learn_time_ms\": 10484.239, \"total_train_time_s\": 14.969914674758911}", "{\"n\": 6613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.92, \"learn_time_ms\": 10486.834, \"total_train_time_s\": 14.003687620162964}", "{\"n\": 6614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.92, \"learn_time_ms\": 10446.021, \"total_train_time_s\": 13.45012378692627}", "{\"n\": 6615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.53, \"learn_time_ms\": 10299.357, \"total_train_time_s\": 13.565608024597168}", "{\"n\": 6616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.3, \"learn_time_ms\": 10351.371, \"total_train_time_s\": 14.456421375274658}", "{\"n\": 6617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.13, \"learn_time_ms\": 10361.016, \"total_train_time_s\": 13.863927602767944}", "{\"n\": 6618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.13, \"learn_time_ms\": 10344.634, \"total_train_time_s\": 14.256285429000854}", "{\"n\": 6619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.46, \"learn_time_ms\": 10490.685, \"total_train_time_s\": 15.099655389785767}", "{\"n\": 6620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.28, \"learn_time_ms\": 10386.153, \"total_train_time_s\": 14.077421426773071}", "{\"n\": 6621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.28, \"learn_time_ms\": 10408.847, \"total_train_time_s\": 14.29792857170105}", "{\"n\": 6622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3635.91, \"learn_time_ms\": 10360.974, \"total_train_time_s\": 14.419677734375}", "{\"n\": 6623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.91, \"learn_time_ms\": 10426.899, \"total_train_time_s\": 14.922916650772095}", "{\"n\": 6624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.14, \"learn_time_ms\": 10526.938, \"total_train_time_s\": 14.20235824584961}", "{\"n\": 6625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.14, \"learn_time_ms\": 10666.53, \"total_train_time_s\": 14.980888605117798}", "{\"n\": 6626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.81, \"learn_time_ms\": 10661.298, \"total_train_time_s\": 14.444693565368652}", "{\"n\": 6627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.13, \"learn_time_ms\": 10642.499, \"total_train_time_s\": 13.486446380615234}", "{\"n\": 6628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.47, \"learn_time_ms\": 10799.389, \"total_train_time_s\": 15.832333087921143}", "{\"n\": 6629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.47, \"learn_time_ms\": 10794.306, \"total_train_time_s\": 14.848758220672607}", "{\"n\": 6630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.5, \"learn_time_ms\": 10721.16, \"total_train_time_s\": 13.370590448379517}", "{\"n\": 6631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.6, \"learn_time_ms\": 10707.852, \"total_train_time_s\": 14.288874626159668}", "{\"n\": 6632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.6, \"learn_time_ms\": 10659.001, \"total_train_time_s\": 13.951056957244873}", "{\"n\": 6633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.63, \"learn_time_ms\": 10460.984, \"total_train_time_s\": 12.94520092010498}", "{\"n\": 6634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.47, \"learn_time_ms\": 10445.516, \"total_train_time_s\": 14.164711713790894}", "{\"n\": 6635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.47, \"learn_time_ms\": 10322.13, \"total_train_time_s\": 13.701329946517944}", "{\"n\": 6636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.39, \"learn_time_ms\": 10196.559, \"total_train_time_s\": 13.233243942260742}", "{\"n\": 6637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.39, \"learn_time_ms\": 10272.749, \"total_train_time_s\": 14.617234230041504}", "{\"n\": 6638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.81, \"learn_time_ms\": 10170.545, \"total_train_time_s\": 14.6793954372406}", "{\"n\": 6639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.81, \"learn_time_ms\": 10170.684, \"total_train_time_s\": 14.901089668273926}", "{\"n\": 6640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10384.732, \"total_train_time_s\": 15.497348308563232}", "{\"n\": 6641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10325.191, \"total_train_time_s\": 13.928430080413818}", "{\"n\": 6642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.77, \"learn_time_ms\": 10386.39, \"total_train_time_s\": 14.508716821670532}", "{\"n\": 6643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.79, \"learn_time_ms\": 10384.994, \"total_train_time_s\": 12.859600067138672}", "{\"n\": 6644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.76, \"learn_time_ms\": 10346.468, \"total_train_time_s\": 13.768867015838623}", "{\"n\": 6645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.7, \"learn_time_ms\": 10460.674, \"total_train_time_s\": 14.602696895599365}", "{\"n\": 6646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.7, \"learn_time_ms\": 10572.658, \"total_train_time_s\": 14.291278839111328}", "{\"n\": 6647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.03, \"learn_time_ms\": 10556.651, \"total_train_time_s\": 14.473249197006226}", "{\"n\": 6648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 10446.759, \"total_train_time_s\": 13.313760995864868}", "{\"n\": 6649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 10385.678, \"total_train_time_s\": 14.31423568725586}", "{\"n\": 6650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 10313.334, \"total_train_time_s\": 14.672577381134033}", "{\"n\": 6651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.71, \"learn_time_ms\": 10269.23, \"total_train_time_s\": 13.407449722290039}", "{\"n\": 6652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.59, \"learn_time_ms\": 10099.189, \"total_train_time_s\": 12.870174884796143}", "{\"n\": 6653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.59, \"learn_time_ms\": 10233.503, \"total_train_time_s\": 14.06849718093872}", "{\"n\": 6654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.0, \"learn_time_ms\": 10271.94, \"total_train_time_s\": 14.267077445983887}", "{\"n\": 6655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.7, \"learn_time_ms\": 10264.113, \"total_train_time_s\": 14.559423446655273}", "{\"n\": 6656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.28, \"learn_time_ms\": 10198.363, \"total_train_time_s\": 13.793232917785645}", "{\"n\": 6657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.28, \"learn_time_ms\": 10136.56, \"total_train_time_s\": 13.834507942199707}", "{\"n\": 6658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.04, \"learn_time_ms\": 10175.136, \"total_train_time_s\": 14.008556604385376}", "{\"n\": 6659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.65, \"learn_time_ms\": 10130.868, \"total_train_time_s\": 13.868597507476807}", "{\"n\": 6660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.0, \"learn_time_ms\": 10064.86, \"total_train_time_s\": 13.902918815612793}", "{\"n\": 6661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.0, \"learn_time_ms\": 10183.329, \"total_train_time_s\": 14.702836751937866}", "{\"n\": 6662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.18, \"learn_time_ms\": 10315.852, \"total_train_time_s\": 14.180972814559937}", "{\"n\": 6663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.18, \"learn_time_ms\": 10236.604, \"total_train_time_s\": 13.466412544250488}", "{\"n\": 6664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.03, \"learn_time_ms\": 10284.507, \"total_train_time_s\": 14.518377780914307}", "{\"n\": 6665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.75, \"learn_time_ms\": 10161.254, \"total_train_time_s\": 13.655283689498901}", "{\"n\": 6666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.35, \"learn_time_ms\": 10189.042, \"total_train_time_s\": 13.897839069366455}", "{\"n\": 6667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.48, \"learn_time_ms\": 10267.987, \"total_train_time_s\": 14.370563507080078}", "{\"n\": 6668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.48, \"learn_time_ms\": 10338.557, \"total_train_time_s\": 14.572062492370605}", "{\"n\": 6669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.07, \"learn_time_ms\": 10385.003, \"total_train_time_s\": 14.275548458099365}", "{\"n\": 6670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.78, \"learn_time_ms\": 10321.358, \"total_train_time_s\": 13.351161479949951}", "{\"n\": 6671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.06, \"learn_time_ms\": 10369.531, \"total_train_time_s\": 14.882048606872559}", "{\"n\": 6672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.06, \"learn_time_ms\": 10353.87, \"total_train_time_s\": 14.101791143417358}", "{\"n\": 6673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.76, \"learn_time_ms\": 10436.414, \"total_train_time_s\": 14.134691715240479}", "{\"n\": 6674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.15, \"learn_time_ms\": 10373.163, \"total_train_time_s\": 14.070255517959595}", "{\"n\": 6675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.15, \"learn_time_ms\": 10525.231, \"total_train_time_s\": 15.169153928756714}", "{\"n\": 6676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.15, \"learn_time_ms\": 10479.354, \"total_train_time_s\": 13.687570571899414}", "{\"n\": 6677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.87, \"learn_time_ms\": 10413.779, \"total_train_time_s\": 13.636275291442871}", "{\"n\": 6678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3743.53, \"learn_time_ms\": 10304.006, \"total_train_time_s\": 13.54751467704773}", "{\"n\": 6679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3743.53, \"learn_time_ms\": 10323.752, \"total_train_time_s\": 14.65204668045044}", "{\"n\": 6680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.79, \"learn_time_ms\": 10374.887, \"total_train_time_s\": 14.140349626541138}", "{\"n\": 6681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 10247.903, \"total_train_time_s\": 13.49020767211914}", "{\"n\": 6682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 10257.522, \"total_train_time_s\": 14.138959169387817}", "{\"n\": 6683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 10217.527, \"total_train_time_s\": 14.130090236663818}", "{\"n\": 6684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.7, \"learn_time_ms\": 10257.174, \"total_train_time_s\": 14.401390790939331}", "{\"n\": 6685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.91, \"learn_time_ms\": 10249.162, \"total_train_time_s\": 14.957859516143799}", "{\"n\": 6686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.91, \"learn_time_ms\": 10366.198, \"total_train_time_s\": 14.897613286972046}", "{\"n\": 6687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.91, \"learn_time_ms\": 10409.744, \"total_train_time_s\": 14.38770580291748}", "{\"n\": 6688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.67, \"learn_time_ms\": 10504.15, \"total_train_time_s\": 14.201752662658691}", "{\"n\": 6689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.19, \"learn_time_ms\": 10532.127, \"total_train_time_s\": 14.591708660125732}", "{\"n\": 6690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3752.55, \"learn_time_ms\": 10606.157, \"total_train_time_s\": 14.759288311004639}", "{\"n\": 6691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3748.67, \"learn_time_ms\": 10575.416, \"total_train_time_s\": 13.660310983657837}", "{\"n\": 6692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.89, \"learn_time_ms\": 10557.4, \"total_train_time_s\": 13.91574239730835}", "{\"n\": 6693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.76, \"learn_time_ms\": 10601.482, \"total_train_time_s\": 14.282449722290039}", "{\"n\": 6694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.76, \"learn_time_ms\": 10467.603, \"total_train_time_s\": 13.109044313430786}", "{\"n\": 6695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3751.41, \"learn_time_ms\": 10490.594, \"total_train_time_s\": 15.099325895309448}", "{\"n\": 6696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3748.95, \"learn_time_ms\": 10423.21, \"total_train_time_s\": 14.248272180557251}", "{\"n\": 6697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.23, \"learn_time_ms\": 10412.123, \"total_train_time_s\": 14.053072690963745}", "{\"n\": 6698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.23, \"learn_time_ms\": 10477.131, \"total_train_time_s\": 15.225568771362305}", "{\"n\": 6699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.76, \"learn_time_ms\": 10386.016, \"total_train_time_s\": 13.609260082244873}", "{\"n\": 6700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.86, \"learn_time_ms\": 10309.127, \"total_train_time_s\": 13.849145889282227}", "{\"n\": 6701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.86, \"learn_time_ms\": 10413.231, \"total_train_time_s\": 14.641807079315186}", "{\"n\": 6702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.78, \"learn_time_ms\": 10371.195, \"total_train_time_s\": 13.869254112243652}", "{\"n\": 6703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3748.68, \"learn_time_ms\": 10435.042, \"total_train_time_s\": 14.80839228630066}", "{\"n\": 6704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3748.68, \"learn_time_ms\": 10596.921, \"total_train_time_s\": 14.843057632446289}", "{\"n\": 6705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3762.32, \"learn_time_ms\": 10495.771, \"total_train_time_s\": 13.951362371444702}", "{\"n\": 6706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3762.48, \"learn_time_ms\": 10371.309, \"total_train_time_s\": 12.691625356674194}", "{\"n\": 6707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3746.3, \"learn_time_ms\": 10310.761, \"total_train_time_s\": 13.395618677139282}", "{\"n\": 6708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.32, \"learn_time_ms\": 10191.899, \"total_train_time_s\": 13.740664005279541}", "{\"n\": 6709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.32, \"learn_time_ms\": 10309.503, \"total_train_time_s\": 14.858427286148071}", "{\"n\": 6710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.09, \"learn_time_ms\": 10379.417, \"total_train_time_s\": 14.536771535873413}", "{\"n\": 6711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3728.31, \"learn_time_ms\": 10538.15, \"total_train_time_s\": 16.028064250946045}", "{\"n\": 6712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.7, \"learn_time_ms\": 10602.506, \"total_train_time_s\": 14.327908515930176}", "{\"n\": 6713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.67, \"learn_time_ms\": 10445.009, \"total_train_time_s\": 13.249502897262573}", "{\"n\": 6714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.54, \"learn_time_ms\": 10474.298, \"total_train_time_s\": 14.84351921081543}", "{\"n\": 6715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.02, \"learn_time_ms\": 10396.466, \"total_train_time_s\": 13.5611572265625}", "{\"n\": 6716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.98, \"learn_time_ms\": 10527.856, \"total_train_time_s\": 14.026009321212769}", "{\"n\": 6717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.86, \"learn_time_ms\": 10582.004, \"total_train_time_s\": 14.0486319065094}", "{\"n\": 6718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.86, \"learn_time_ms\": 10593.981, \"total_train_time_s\": 14.298763990402222}", "{\"n\": 6719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3733.94, \"learn_time_ms\": 10634.437, \"total_train_time_s\": 15.60872507095337}", "{\"n\": 6720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.83, \"learn_time_ms\": 10604.673, \"total_train_time_s\": 14.160325050354004}", "{\"n\": 6721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.75, \"learn_time_ms\": 10511.418, \"total_train_time_s\": 14.860950469970703}", "{\"n\": 6722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.75, \"learn_time_ms\": 10433.201, \"total_train_time_s\": 13.497559785842896}", "{\"n\": 6723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.37, \"learn_time_ms\": 10499.604, \"total_train_time_s\": 13.932923555374146}", "{\"n\": 6724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.37, \"learn_time_ms\": 10573.937, \"total_train_time_s\": 15.720181703567505}", "{\"n\": 6725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.32, \"learn_time_ms\": 10725.643, \"total_train_time_s\": 14.947311401367188}", "{\"n\": 6726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.32, \"learn_time_ms\": 10756.346, \"total_train_time_s\": 14.619723320007324}", "{\"n\": 6727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3745.95, \"learn_time_ms\": 10760.925, \"total_train_time_s\": 13.884279251098633}", "{\"n\": 6728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.03, \"learn_time_ms\": 10783.558, \"total_train_time_s\": 14.189016342163086}", "{\"n\": 6729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.71, \"learn_time_ms\": 10642.977, \"total_train_time_s\": 14.184247493743896}", "{\"n\": 6730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.71, \"learn_time_ms\": 10673.384, \"total_train_time_s\": 14.53247618675232}", "{\"n\": 6731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.31, \"learn_time_ms\": 10535.795, \"total_train_time_s\": 13.677979707717896}", "{\"n\": 6732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3747.14, \"learn_time_ms\": 10609.288, \"total_train_time_s\": 14.145545959472656}", "{\"n\": 6733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3758.82, \"learn_time_ms\": 10627.592, \"total_train_time_s\": 14.142898321151733}", "{\"n\": 6734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3758.82, \"learn_time_ms\": 10547.055, \"total_train_time_s\": 15.129306077957153}", "{\"n\": 6735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.1, \"learn_time_ms\": 10548.107, \"total_train_time_s\": 14.814806699752808}", "{\"n\": 6736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.78, \"learn_time_ms\": 10594.177, \"total_train_time_s\": 14.900138854980469}", "{\"n\": 6737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.78, \"learn_time_ms\": 10545.456, \"total_train_time_s\": 13.764463901519775}", "{\"n\": 6738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.46, \"learn_time_ms\": 10549.547, \"total_train_time_s\": 14.442675113677979}", "{\"n\": 6739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.17, \"learn_time_ms\": 10507.56, \"total_train_time_s\": 13.446752071380615}", "{\"n\": 6740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.19, \"learn_time_ms\": 10453.581, \"total_train_time_s\": 14.264713764190674}", "{\"n\": 6741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.03, \"learn_time_ms\": 10592.284, \"total_train_time_s\": 15.135645151138306}", "{\"n\": 6742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.01, \"learn_time_ms\": 10572.13, \"total_train_time_s\": 13.834383010864258}", "{\"n\": 6743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.83, \"learn_time_ms\": 10534.462, \"total_train_time_s\": 13.631903648376465}", "{\"n\": 6744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3762.39, \"learn_time_ms\": 10407.839, \"total_train_time_s\": 13.830347537994385}", "{\"n\": 6745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.14, \"learn_time_ms\": 10324.724, \"total_train_time_s\": 14.166024923324585}", "{\"n\": 6746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.42, \"learn_time_ms\": 10194.853, \"total_train_time_s\": 13.666027307510376}", "{\"n\": 6747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.12, \"learn_time_ms\": 10199.361, \"total_train_time_s\": 13.480926036834717}", "{\"n\": 6748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.12, \"learn_time_ms\": 10267.596, \"total_train_time_s\": 14.90234899520874}", "{\"n\": 6749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.07, \"learn_time_ms\": 10346.497, \"total_train_time_s\": 14.292175054550171}", "{\"n\": 6750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3741.57, \"learn_time_ms\": 10301.507, \"total_train_time_s\": 13.508710145950317}", "{\"n\": 6751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3731.27, \"learn_time_ms\": 10237.779, \"total_train_time_s\": 14.443061828613281}", "{\"n\": 6752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.55, \"learn_time_ms\": 10176.755, \"total_train_time_s\": 13.518183469772339}", "{\"n\": 6753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.26, \"learn_time_ms\": 10297.593, \"total_train_time_s\": 15.006717681884766}", "{\"n\": 6754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3732.12, \"learn_time_ms\": 10241.4, \"total_train_time_s\": 12.937979936599731}", "{\"n\": 6755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.64, \"learn_time_ms\": 10323.905, \"total_train_time_s\": 14.81990122795105}", "{\"n\": 6756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3718.06, \"learn_time_ms\": 10397.31, \"total_train_time_s\": 14.197959423065186}", "{\"n\": 6757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3718.06, \"learn_time_ms\": 10498.887, \"total_train_time_s\": 15.019490718841553}", "{\"n\": 6758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 10423.399, \"total_train_time_s\": 14.151156425476074}", "{\"n\": 6759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.29, \"learn_time_ms\": 10414.806, \"total_train_time_s\": 14.60726809501648}", "{\"n\": 6760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3724.45, \"learn_time_ms\": 10401.706, \"total_train_time_s\": 13.443910837173462}", "{\"n\": 6761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3723.0, \"learn_time_ms\": 10331.133, \"total_train_time_s\": 13.79270339012146}", "{\"n\": 6762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3723.0, \"learn_time_ms\": 10485.867, \"total_train_time_s\": 14.962417840957642}", "{\"n\": 6763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.23, \"learn_time_ms\": 10394.842, \"total_train_time_s\": 14.097813367843628}", "{\"n\": 6764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.03, \"learn_time_ms\": 10457.297, \"total_train_time_s\": 13.492528676986694}", "{\"n\": 6765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.03, \"learn_time_ms\": 10416.992, \"total_train_time_s\": 14.345171213150024}", "{\"n\": 6766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3717.89, \"learn_time_ms\": 10406.225, \"total_train_time_s\": 14.169943571090698}", "{\"n\": 6767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3720.19, \"learn_time_ms\": 10403.573, \"total_train_time_s\": 14.53326678276062}", "{\"n\": 6768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.93, \"learn_time_ms\": 10446.042, \"total_train_time_s\": 14.730358362197876}", "{\"n\": 6769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3714.19, \"learn_time_ms\": 10513.057, \"total_train_time_s\": 15.145378351211548}", "{\"n\": 6770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3714.19, \"learn_time_ms\": 10520.785, \"total_train_time_s\": 13.69036054611206}", "{\"n\": 6771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3714.71, \"learn_time_ms\": 10578.882, \"total_train_time_s\": 14.165211200714111}", "{\"n\": 6772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3720.19, \"learn_time_ms\": 10541.174, \"total_train_time_s\": 14.442981481552124}", "{\"n\": 6773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.42, \"learn_time_ms\": 10641.849, \"total_train_time_s\": 15.061395168304443}", "{\"n\": 6774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.52, \"learn_time_ms\": 10590.441, \"total_train_time_s\": 13.025164365768433}", "{\"n\": 6775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.06, \"learn_time_ms\": 10530.204, \"total_train_time_s\": 13.777879476547241}", "{\"n\": 6776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.06, \"learn_time_ms\": 10575.771, \"total_train_time_s\": 14.827261209487915}", "{\"n\": 6777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.35, \"learn_time_ms\": 10532.144, \"total_train_time_s\": 14.29195761680603}", "{\"n\": 6778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.37, \"learn_time_ms\": 10504.775, \"total_train_time_s\": 14.341490268707275}", "{\"n\": 6779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.37, \"learn_time_ms\": 10444.087, \"total_train_time_s\": 14.584655284881592}", "{\"n\": 6780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.3, \"learn_time_ms\": 10507.31, \"total_train_time_s\": 14.368812799453735}", "{\"n\": 6781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.04, \"learn_time_ms\": 10438.767, \"total_train_time_s\": 13.793507099151611}", "{\"n\": 6782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.49, \"learn_time_ms\": 10512.779, \"total_train_time_s\": 15.479138135910034}", "{\"n\": 6783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.49, \"learn_time_ms\": 10464.303, \"total_train_time_s\": 14.62925386428833}", "{\"n\": 6784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.44, \"learn_time_ms\": 10530.182, \"total_train_time_s\": 13.707725763320923}", "{\"n\": 6785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.43, \"learn_time_ms\": 10642.408, \"total_train_time_s\": 15.197667837142944}", "{\"n\": 6786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.12, \"learn_time_ms\": 10628.446, \"total_train_time_s\": 14.692163944244385}", "{\"n\": 6787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.12, \"learn_time_ms\": 10649.245, \"total_train_time_s\": 14.434083700180054}", "{\"n\": 6788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.1, \"learn_time_ms\": 10586.501, \"total_train_time_s\": 13.89843487739563}", "{\"n\": 6789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.21, \"learn_time_ms\": 10629.307, \"total_train_time_s\": 14.735633373260498}", "{\"n\": 6790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.58, \"learn_time_ms\": 10537.935, \"total_train_time_s\": 13.175093412399292}", "{\"n\": 6791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.58, \"learn_time_ms\": 10550.307, \"total_train_time_s\": 13.887395858764648}", "{\"n\": 6792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.12, \"learn_time_ms\": 10432.43, \"total_train_time_s\": 14.16543960571289}", "{\"n\": 6793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10444.608, \"total_train_time_s\": 14.806219339370728}", "{\"n\": 6794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10454.659, \"total_train_time_s\": 14.191740989685059}", "{\"n\": 6795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10409.525, \"total_train_time_s\": 14.492568254470825}", "{\"n\": 6796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10403.391, \"total_train_time_s\": 14.396940231323242}", "{\"n\": 6797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.11, \"learn_time_ms\": 10431.116, \"total_train_time_s\": 14.585074663162231}", "{\"n\": 6798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.73, \"learn_time_ms\": 10414.834, \"total_train_time_s\": 13.43111538887024}", "{\"n\": 6799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.73, \"learn_time_ms\": 10277.601, \"total_train_time_s\": 13.172187328338623}", "{\"n\": 6800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.22, \"learn_time_ms\": 10315.218, \"total_train_time_s\": 13.56948184967041}", "{\"n\": 6801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.62, \"learn_time_ms\": 10461.102, \"total_train_time_s\": 15.226932287216187}", "{\"n\": 6802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.81, \"learn_time_ms\": 10438.008, \"total_train_time_s\": 13.91696548461914}", "{\"n\": 6803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.81, \"learn_time_ms\": 10472.541, \"total_train_time_s\": 14.964937210083008}", "{\"n\": 6804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.74, \"learn_time_ms\": 10513.61, \"total_train_time_s\": 14.460839986801147}", "{\"n\": 6805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.03, \"learn_time_ms\": 10646.431, \"total_train_time_s\": 16.129900693893433}", "{\"n\": 6806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.8, \"learn_time_ms\": 10650.183, \"total_train_time_s\": 14.634445428848267}", "{\"n\": 6807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.8, \"learn_time_ms\": 10647.352, \"total_train_time_s\": 14.46027684211731}", "{\"n\": 6808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.41, \"learn_time_ms\": 10816.035, \"total_train_time_s\": 15.230337381362915}", "{\"n\": 6809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.94, \"learn_time_ms\": 10984.263, \"total_train_time_s\": 15.044292688369751}", "{\"n\": 6810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.94, \"learn_time_ms\": 10974.211, \"total_train_time_s\": 13.758447647094727}", "{\"n\": 6811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.62, \"learn_time_ms\": 10895.149, \"total_train_time_s\": 14.618210077285767}", "{\"n\": 6812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.69, \"learn_time_ms\": 10942.07, \"total_train_time_s\": 14.415724992752075}", "{\"n\": 6813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.69, \"learn_time_ms\": 10854.298, \"total_train_time_s\": 14.151715755462646}", "{\"n\": 6814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.69, \"learn_time_ms\": 10846.613, \"total_train_time_s\": 14.252551794052124}", "{\"n\": 6815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.21, \"learn_time_ms\": 10677.31, \"total_train_time_s\": 14.136528491973877}", "{\"n\": 6816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.52, \"learn_time_ms\": 10659.606, \"total_train_time_s\": 14.42203974723816}", "{\"n\": 6817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.52, \"learn_time_ms\": 10685.467, \"total_train_time_s\": 14.752717971801758}", "{\"n\": 6818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.03, \"learn_time_ms\": 10638.131, \"total_train_time_s\": 14.678154945373535}", "{\"n\": 6819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.33, \"learn_time_ms\": 10531.26, \"total_train_time_s\": 14.01558804512024}", "{\"n\": 6820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.33, \"learn_time_ms\": 10611.115, \"total_train_time_s\": 14.210531949996948}", "{\"n\": 6821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.46, \"learn_time_ms\": 10572.263, \"total_train_time_s\": 13.94822096824646}", "{\"n\": 6822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.05, \"learn_time_ms\": 10539.668, \"total_train_time_s\": 14.037843704223633}", "{\"n\": 6823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.02, \"learn_time_ms\": 10579.301, \"total_train_time_s\": 14.478317737579346}", "{\"n\": 6824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.02, \"learn_time_ms\": 10640.908, \"total_train_time_s\": 14.761536598205566}", "{\"n\": 6825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.03, \"learn_time_ms\": 10694.198, \"total_train_time_s\": 14.785960912704468}", "{\"n\": 6826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.62, \"learn_time_ms\": 10559.849, \"total_train_time_s\": 13.383300542831421}", "{\"n\": 6827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.53, \"learn_time_ms\": 10470.968, \"total_train_time_s\": 13.933164119720459}", "{\"n\": 6828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.32, \"learn_time_ms\": 10490.86, \"total_train_time_s\": 14.933480739593506}", "{\"n\": 6829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.67, \"learn_time_ms\": 10518.893, \"total_train_time_s\": 14.146475315093994}", "{\"n\": 6830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.17, \"learn_time_ms\": 10446.808, \"total_train_time_s\": 13.590444564819336}", "{\"n\": 6831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.16, \"learn_time_ms\": 10388.032, \"total_train_time_s\": 13.355655908584595}", "{\"n\": 6832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.16, \"learn_time_ms\": 10418.741, \"total_train_time_s\": 14.283889055252075}", "{\"n\": 6833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.58, \"learn_time_ms\": 10360.901, \"total_train_time_s\": 14.109991788864136}", "{\"n\": 6834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.21, \"learn_time_ms\": 10258.868, \"total_train_time_s\": 13.942943572998047}", "{\"n\": 6835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.75, \"learn_time_ms\": 10260.5, \"total_train_time_s\": 14.788347005844116}", "{\"n\": 6836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.75, \"learn_time_ms\": 10416.807, \"total_train_time_s\": 14.826248168945312}", "{\"n\": 6837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.37, \"learn_time_ms\": 10385.065, \"total_train_time_s\": 13.496036529541016}", "{\"n\": 6838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.37, \"learn_time_ms\": 10227.362, \"total_train_time_s\": 13.361483097076416}", "{\"n\": 6839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.27, \"learn_time_ms\": 10210.325, \"total_train_time_s\": 14.170254945755005}", "{\"n\": 6840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.22, \"learn_time_ms\": 10260.228, \"total_train_time_s\": 14.253321647644043}", "{\"n\": 6841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.81, \"learn_time_ms\": 10368.305, \"total_train_time_s\": 14.547769784927368}", "{\"n\": 6842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.81, \"learn_time_ms\": 10415.381, \"total_train_time_s\": 14.800262928009033}", "{\"n\": 6843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.81, \"learn_time_ms\": 10353.727, \"total_train_time_s\": 13.1955246925354}", "{\"n\": 6844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.5, \"learn_time_ms\": 10381.84, \"total_train_time_s\": 14.013428688049316}", "{\"n\": 6845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.93, \"learn_time_ms\": 10235.338, \"total_train_time_s\": 13.134029626846313}", "{\"n\": 6846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.93, \"learn_time_ms\": 10209.84, \"total_train_time_s\": 14.457933187484741}", "{\"n\": 6847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.19, \"learn_time_ms\": 10351.085, \"total_train_time_s\": 15.256261587142944}", "{\"n\": 6848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.91, \"learn_time_ms\": 10349.653, \"total_train_time_s\": 13.249679327011108}", "{\"n\": 6849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.14, \"learn_time_ms\": 10311.079, \"total_train_time_s\": 13.540545463562012}", "{\"n\": 6850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.73, \"learn_time_ms\": 10352.097, \"total_train_time_s\": 14.495224475860596}", "{\"n\": 6851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.73, \"learn_time_ms\": 10374.04, \"total_train_time_s\": 15.059731006622314}", "{\"n\": 6852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.05, \"learn_time_ms\": 10326.127, \"total_train_time_s\": 14.394087076187134}", "{\"n\": 6853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.18, \"learn_time_ms\": 10390.158, \"total_train_time_s\": 14.242833137512207}", "{\"n\": 6854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.18, \"learn_time_ms\": 10357.948, \"total_train_time_s\": 13.66374135017395}", "{\"n\": 6855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.05, \"learn_time_ms\": 10417.654, \"total_train_time_s\": 13.805590629577637}", "{\"n\": 6856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.01, \"learn_time_ms\": 10455.325, \"total_train_time_s\": 14.79654312133789}", "{\"n\": 6857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.9, \"learn_time_ms\": 10309.79, \"total_train_time_s\": 13.656387329101562}", "{\"n\": 6858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.44, \"learn_time_ms\": 10473.218, \"total_train_time_s\": 14.928527593612671}", "{\"n\": 6859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 10508.549, \"total_train_time_s\": 14.012859582901001}", "{\"n\": 6860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.76, \"learn_time_ms\": 10455.637, \"total_train_time_s\": 13.881895542144775}", "{\"n\": 6861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.69, \"learn_time_ms\": 10486.751, \"total_train_time_s\": 15.093961000442505}", "{\"n\": 6862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.69, \"learn_time_ms\": 10427.861, \"total_train_time_s\": 13.817777395248413}", "{\"n\": 6863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.13, \"learn_time_ms\": 10512.817, \"total_train_time_s\": 15.210904598236084}", "{\"n\": 6864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.81, \"learn_time_ms\": 10535.82, \"total_train_time_s\": 14.256530523300171}", "{\"n\": 6865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.09, \"learn_time_ms\": 10521.965, \"total_train_time_s\": 13.616269588470459}", "{\"n\": 6866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.18, \"learn_time_ms\": 10562.296, \"total_train_time_s\": 15.061289548873901}", "{\"n\": 6867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.18, \"learn_time_ms\": 10614.805, \"total_train_time_s\": 14.035467147827148}", "{\"n\": 6868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.39, \"learn_time_ms\": 10569.284, \"total_train_time_s\": 14.631840705871582}", "{\"n\": 6869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.07, \"learn_time_ms\": 10652.468, \"total_train_time_s\": 14.752706050872803}", "{\"n\": 6870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.74, \"learn_time_ms\": 10655.283, \"total_train_time_s\": 13.935511350631714}", "{\"n\": 6871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.74, \"learn_time_ms\": 10562.579, \"total_train_time_s\": 14.075769901275635}", "{\"n\": 6872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.74, \"learn_time_ms\": 10576.567, \"total_train_time_s\": 14.057748556137085}", "{\"n\": 6873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.64, \"learn_time_ms\": 10516.711, \"total_train_time_s\": 14.287110805511475}", "{\"n\": 6874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.02, \"learn_time_ms\": 10566.808, \"total_train_time_s\": 14.470596551895142}", "{\"n\": 6875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.02, \"learn_time_ms\": 10725.523, \"total_train_time_s\": 15.184643507003784}", "{\"n\": 6876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.78, \"learn_time_ms\": 10632.26, \"total_train_time_s\": 14.361754894256592}", "{\"n\": 6877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.26, \"learn_time_ms\": 10759.204, \"total_train_time_s\": 15.597076177597046}", "{\"n\": 6878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.91, \"learn_time_ms\": 10684.539, \"total_train_time_s\": 13.749471664428711}", "{\"n\": 6879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.9, \"learn_time_ms\": 10491.397, \"total_train_time_s\": 12.87402606010437}", "{\"n\": 6880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.9, \"learn_time_ms\": 10544.247, \"total_train_time_s\": 14.424654722213745}", "{\"n\": 6881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.23, \"learn_time_ms\": 10566.082, \"total_train_time_s\": 14.241672039031982}", "{\"n\": 6882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.23, \"learn_time_ms\": 10588.643, \"total_train_time_s\": 14.262321472167969}", "{\"n\": 6883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.53, \"learn_time_ms\": 10611.021, \"total_train_time_s\": 14.358224391937256}", "{\"n\": 6884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.51, \"learn_time_ms\": 10539.328, \"total_train_time_s\": 13.887452840805054}", "{\"n\": 6885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.77, \"learn_time_ms\": 10473.228, \"total_train_time_s\": 14.748436689376831}", "{\"n\": 6886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.56, \"learn_time_ms\": 10486.765, \"total_train_time_s\": 14.486926078796387}", "{\"n\": 6887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.43, \"learn_time_ms\": 10338.858, \"total_train_time_s\": 14.257334470748901}", "{\"n\": 6888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.43, \"learn_time_ms\": 10441.507, \"total_train_time_s\": 15.127742767333984}", "{\"n\": 6889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.43, \"learn_time_ms\": 10682.87, \"total_train_time_s\": 15.543306589126587}", "{\"n\": 6890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.17, \"learn_time_ms\": 10564.925, \"total_train_time_s\": 13.315941095352173}", "{\"n\": 6891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.91, \"learn_time_ms\": 10607.591, \"total_train_time_s\": 14.653199195861816}", "{\"n\": 6892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.91, \"learn_time_ms\": 10589.326, \"total_train_time_s\": 14.17482304573059}", "{\"n\": 6893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.68, \"learn_time_ms\": 10619.624, \"total_train_time_s\": 14.724493741989136}", "{\"n\": 6894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.49, \"learn_time_ms\": 10642.01, \"total_train_time_s\": 14.00097131729126}", "{\"n\": 6895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.94, \"learn_time_ms\": 10625.678, \"total_train_time_s\": 14.51905083656311}", "{\"n\": 6896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.94, \"learn_time_ms\": 10621.474, \"total_train_time_s\": 14.197347640991211}", "{\"n\": 6897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.9, \"learn_time_ms\": 10701.4, \"total_train_time_s\": 14.57488751411438}", "{\"n\": 6898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.25, \"learn_time_ms\": 10646.247, \"total_train_time_s\": 14.059096097946167}", "{\"n\": 6899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.25, \"learn_time_ms\": 10427.224, \"total_train_time_s\": 13.3312246799469}", "{\"n\": 6900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.11, \"learn_time_ms\": 10554.258, \"total_train_time_s\": 14.701629638671875}", "{\"n\": 6901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.26, \"learn_time_ms\": 10534.157, \"total_train_time_s\": 14.478288650512695}", "{\"n\": 6902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.26, \"learn_time_ms\": 10542.351, \"total_train_time_s\": 14.057059288024902}", "{\"n\": 6903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.26, \"learn_time_ms\": 10539.721, \"total_train_time_s\": 14.832628965377808}", "{\"n\": 6904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.74, \"learn_time_ms\": 10601.435, \"total_train_time_s\": 14.804410696029663}", "{\"n\": 6905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.28, \"learn_time_ms\": 10597.868, \"total_train_time_s\": 14.39084267616272}", "{\"n\": 6906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.28, \"learn_time_ms\": 10549.507, \"total_train_time_s\": 13.870882511138916}", "{\"n\": 6907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.28, \"learn_time_ms\": 10572.058, \"total_train_time_s\": 14.797626972198486}", "{\"n\": 6908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.11, \"learn_time_ms\": 10619.548, \"total_train_time_s\": 14.681201457977295}", "{\"n\": 6909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.11, \"learn_time_ms\": 10757.075, \"total_train_time_s\": 14.426061630249023}", "{\"n\": 6910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.11, \"learn_time_ms\": 10721.182, \"total_train_time_s\": 14.312503099441528}", "{\"n\": 6911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.23, \"learn_time_ms\": 10602.437, \"total_train_time_s\": 13.354817152023315}", "{\"n\": 6912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.2, \"learn_time_ms\": 10615.077, \"total_train_time_s\": 14.261393547058105}", "{\"n\": 6913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.2, \"learn_time_ms\": 10594.092, \"total_train_time_s\": 14.578969955444336}", "{\"n\": 6914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.6, \"learn_time_ms\": 10574.252, \"total_train_time_s\": 14.401928901672363}", "{\"n\": 6915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.6, \"learn_time_ms\": 10474.097, \"total_train_time_s\": 13.47131633758545}", "{\"n\": 6916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.65, \"learn_time_ms\": 10529.906, \"total_train_time_s\": 14.265211343765259}", "{\"n\": 6917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.5, \"learn_time_ms\": 10461.778, \"total_train_time_s\": 14.168293952941895}", "{\"n\": 6918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.13, \"learn_time_ms\": 10376.569, \"total_train_time_s\": 13.76766300201416}", "{\"n\": 6919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.15, \"learn_time_ms\": 10351.627, \"total_train_time_s\": 14.182682991027832}", "{\"n\": 6920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.15, \"learn_time_ms\": 10323.151, \"total_train_time_s\": 13.980547904968262}", "{\"n\": 6921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.38, \"learn_time_ms\": 10369.701, \"total_train_time_s\": 13.711473941802979}", "{\"n\": 6922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10431.627, \"total_train_time_s\": 14.685303688049316}", "{\"n\": 6923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10410.298, \"total_train_time_s\": 14.380650043487549}", "{\"n\": 6924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 10275.992, \"total_train_time_s\": 13.082866430282593}", "{\"n\": 6925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.98, \"learn_time_ms\": 10275.828, \"total_train_time_s\": 13.323254585266113}", "{\"n\": 6926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.77, \"learn_time_ms\": 10226.206, \"total_train_time_s\": 13.928071975708008}", "{\"n\": 6927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.77, \"learn_time_ms\": 10153.618, \"total_train_time_s\": 13.495368719100952}", "{\"n\": 6928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.49, \"learn_time_ms\": 10197.668, \"total_train_time_s\": 14.224114418029785}", "{\"n\": 6929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.36, \"learn_time_ms\": 10152.188, \"total_train_time_s\": 13.773689270019531}", "{\"n\": 6930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.45, \"learn_time_ms\": 10163.338, \"total_train_time_s\": 14.058883666992188}", "{\"n\": 6931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.45, \"learn_time_ms\": 10165.274, \"total_train_time_s\": 13.798491716384888}", "{\"n\": 6932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.05, \"learn_time_ms\": 10066.471, \"total_train_time_s\": 13.627927780151367}", "{\"n\": 6933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.79, \"learn_time_ms\": 10048.678, \"total_train_time_s\": 14.026188135147095}", "{\"n\": 6934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.82, \"learn_time_ms\": 10182.089, \"total_train_time_s\": 14.488186836242676}", "{\"n\": 6935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.71, \"learn_time_ms\": 10290.692, \"total_train_time_s\": 14.527624368667603}", "{\"n\": 6936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.69, \"learn_time_ms\": 10282.717, \"total_train_time_s\": 13.897612571716309}", "{\"n\": 6937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.82, \"learn_time_ms\": 10314.435, \"total_train_time_s\": 13.832671880722046}", "{\"n\": 6938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.29, \"learn_time_ms\": 10242.282, \"total_train_time_s\": 13.68393588066101}", "{\"n\": 6939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.68, \"learn_time_ms\": 10228.922, \"total_train_time_s\": 13.824293375015259}", "{\"n\": 6940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.22, \"learn_time_ms\": 10177.059, \"total_train_time_s\": 13.496040344238281}", "{\"n\": 6941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.23, \"learn_time_ms\": 10135.372, \"total_train_time_s\": 13.440671443939209}", "{\"n\": 6942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.23, \"learn_time_ms\": 10222.175, \"total_train_time_s\": 14.820794820785522}", "{\"n\": 6943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.97, \"learn_time_ms\": 10230.002, \"total_train_time_s\": 14.38920521736145}", "{\"n\": 6944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10175.569, \"total_train_time_s\": 13.83839726448059}", "{\"n\": 6945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10078.349, \"total_train_time_s\": 13.612276315689087}", "{\"n\": 6946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10118.518, \"total_train_time_s\": 14.133801221847534}", "{\"n\": 6947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10231.576, \"total_train_time_s\": 14.89998459815979}", "{\"n\": 6948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.42, \"learn_time_ms\": 10177.326, \"total_train_time_s\": 12.990883827209473}", "{\"n\": 6949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.42, \"learn_time_ms\": 10307.872, \"total_train_time_s\": 14.881777286529541}", "{\"n\": 6950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.93, \"learn_time_ms\": 10375.433, \"total_train_time_s\": 14.275858640670776}", "{\"n\": 6951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.9, \"learn_time_ms\": 10458.052, \"total_train_time_s\": 14.403233051300049}", "{\"n\": 6952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.59, \"learn_time_ms\": 10447.556, \"total_train_time_s\": 14.372332334518433}", "{\"n\": 6953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.77, \"learn_time_ms\": 10312.129, \"total_train_time_s\": 12.968773126602173}", "{\"n\": 6954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.77, \"learn_time_ms\": 10354.511, \"total_train_time_s\": 14.400076389312744}", "{\"n\": 6955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.93, \"learn_time_ms\": 10337.735, \"total_train_time_s\": 13.214410305023193}", "{\"n\": 6956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.68, \"learn_time_ms\": 10380.516, \"total_train_time_s\": 14.591951131820679}", "{\"n\": 6957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.68, \"learn_time_ms\": 10273.131, \"total_train_time_s\": 14.225800037384033}", "{\"n\": 6958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.59, \"learn_time_ms\": 10457.123, \"total_train_time_s\": 15.010059356689453}", "{\"n\": 6959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.24, \"learn_time_ms\": 10302.924, \"total_train_time_s\": 13.645666599273682}", "{\"n\": 6960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.24, \"learn_time_ms\": 10273.467, \"total_train_time_s\": 13.889750719070435}", "{\"n\": 6961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.02, \"learn_time_ms\": 10243.909, \"total_train_time_s\": 14.131597995758057}", "{\"n\": 6962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.13, \"learn_time_ms\": 10197.722, \"total_train_time_s\": 14.021430492401123}", "{\"n\": 6963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.22, \"learn_time_ms\": 10270.487, \"total_train_time_s\": 13.867924928665161}", "{\"n\": 6964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.88, \"learn_time_ms\": 10243.153, \"total_train_time_s\": 13.937699794769287}", "{\"n\": 6965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.76, \"learn_time_ms\": 10389.365, \"total_train_time_s\": 14.86842966079712}", "{\"n\": 6966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.02, \"learn_time_ms\": 10424.743, \"total_train_time_s\": 15.151285171508789}", "{\"n\": 6967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.77, \"learn_time_ms\": 10414.819, \"total_train_time_s\": 13.757481575012207}", "{\"n\": 6968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.01, \"learn_time_ms\": 10327.122, \"total_train_time_s\": 13.95883584022522}", "{\"n\": 6969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.01, \"learn_time_ms\": 10473.432, \"total_train_time_s\": 14.995240926742554}", "{\"n\": 6970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.88, \"learn_time_ms\": 10429.383, \"total_train_time_s\": 13.683505773544312}", "{\"n\": 6971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.06, \"learn_time_ms\": 10476.52, \"total_train_time_s\": 14.39163613319397}", "{\"n\": 6972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.06, \"learn_time_ms\": 10441.462, \"total_train_time_s\": 13.800611972808838}", "{\"n\": 6973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.03, \"learn_time_ms\": 10400.098, \"total_train_time_s\": 13.084929943084717}", "{\"n\": 6974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.5, \"learn_time_ms\": 10461.643, \"total_train_time_s\": 14.778175830841064}", "{\"n\": 6975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10401.391, \"total_train_time_s\": 14.20578670501709}", "{\"n\": 6976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10396.426, \"total_train_time_s\": 14.942152738571167}", "{\"n\": 6977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.0, \"learn_time_ms\": 10460.209, \"total_train_time_s\": 14.322269916534424}", "{\"n\": 6978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.94, \"learn_time_ms\": 10427.74, \"total_train_time_s\": 13.832991600036621}", "{\"n\": 6979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.43, \"learn_time_ms\": 10281.983, \"total_train_time_s\": 13.426490783691406}", "{\"n\": 6980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.43, \"learn_time_ms\": 10380.22, \"total_train_time_s\": 14.777571678161621}", "{\"n\": 6981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.48, \"learn_time_ms\": 10363.972, \"total_train_time_s\": 14.211491823196411}", "{\"n\": 6982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.48, \"learn_time_ms\": 10391.769, \"total_train_time_s\": 14.030017375946045}", "{\"n\": 6983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.21, \"learn_time_ms\": 10589.842, \"total_train_time_s\": 15.27427864074707}", "{\"n\": 6984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.77, \"learn_time_ms\": 10575.926, \"total_train_time_s\": 14.704709768295288}", "{\"n\": 6985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.93, \"learn_time_ms\": 10618.672, \"total_train_time_s\": 14.55360722541809}", "{\"n\": 6986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.03, \"learn_time_ms\": 10592.4, \"total_train_time_s\": 14.739349603652954}", "{\"n\": 6987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.03, \"learn_time_ms\": 10561.848, \"total_train_time_s\": 14.308258533477783}", "{\"n\": 6988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.18, \"learn_time_ms\": 10625.202, \"total_train_time_s\": 14.251495361328125}", "{\"n\": 6989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.34, \"learn_time_ms\": 10652.569, \"total_train_time_s\": 13.654524564743042}", "{\"n\": 6990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.34, \"learn_time_ms\": 10571.866, \"total_train_time_s\": 13.599347114562988}", "{\"n\": 6991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.68, \"learn_time_ms\": 10614.527, \"total_train_time_s\": 14.60293173789978}", "{\"n\": 6992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.46, \"learn_time_ms\": 10612.752, \"total_train_time_s\": 14.187453985214233}", "{\"n\": 6993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.46, \"learn_time_ms\": 10562.68, \"total_train_time_s\": 14.797466039657593}", "{\"n\": 6994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.25, \"learn_time_ms\": 10444.343, \"total_train_time_s\": 13.180593252182007}", "{\"n\": 6995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.78, \"learn_time_ms\": 10245.771, \"total_train_time_s\": 12.533806562423706}", "{\"n\": 6996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.78, \"learn_time_ms\": 10204.107, \"total_train_time_s\": 14.217236042022705}", "{\"n\": 6997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.71, \"learn_time_ms\": 10186.531, \"total_train_time_s\": 13.914095163345337}", "{\"n\": 6998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.16, \"learn_time_ms\": 10152.331, \"total_train_time_s\": 14.181276798248291}", "{\"n\": 6999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.63, \"learn_time_ms\": 10199.069, \"total_train_time_s\": 14.101645231246948}", "{\"n\": 7000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.81, \"learn_time_ms\": 10240.05, \"total_train_time_s\": 14.059185266494751}", "{\"n\": 7001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.81, \"learn_time_ms\": 10219.882, \"total_train_time_s\": 14.341400384902954}", "{\"n\": 7002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.1, \"learn_time_ms\": 10263.106, \"total_train_time_s\": 14.306733846664429}", "{\"n\": 7003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.93, \"learn_time_ms\": 10221.594, \"total_train_time_s\": 14.23166012763977}", "{\"n\": 7004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.93, \"learn_time_ms\": 10360.159, \"total_train_time_s\": 14.980832576751709}", "{\"n\": 7005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.25, \"learn_time_ms\": 10492.809, \"total_train_time_s\": 14.280466318130493}", "{\"n\": 7006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.81, \"learn_time_ms\": 10555.338, \"total_train_time_s\": 14.814990997314453}", "{\"n\": 7007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.81, \"learn_time_ms\": 10529.649, \"total_train_time_s\": 14.067022562026978}", "{\"n\": 7008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.81, \"learn_time_ms\": 10666.127, \"total_train_time_s\": 15.207152605056763}", "{\"n\": 7009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.41, \"learn_time_ms\": 10602.896, \"total_train_time_s\": 13.499475479125977}", "{\"n\": 7010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.97, \"learn_time_ms\": 10747.08, \"total_train_time_s\": 15.75033450126648}", "{\"n\": 7011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.17, \"learn_time_ms\": 10685.524, \"total_train_time_s\": 13.83841323852539}", "{\"n\": 7012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.82, \"learn_time_ms\": 10680.203, \"total_train_time_s\": 14.535131692886353}", "{\"n\": 7013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.21, \"learn_time_ms\": 10599.908, \"total_train_time_s\": 13.387023210525513}", "{\"n\": 7014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.06, \"learn_time_ms\": 10576.046, \"total_train_time_s\": 14.577588558197021}", "{\"n\": 7015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.06, \"learn_time_ms\": 10578.588, \"total_train_time_s\": 14.198477983474731}", "{\"n\": 7016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.81, \"learn_time_ms\": 10502.233, \"total_train_time_s\": 14.010035753250122}", "{\"n\": 7017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.36, \"learn_time_ms\": 10535.164, \"total_train_time_s\": 14.04051423072815}", "{\"n\": 7018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.72, \"learn_time_ms\": 10484.796, \"total_train_time_s\": 14.885730504989624}", "{\"n\": 7019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.72, \"learn_time_ms\": 10612.286, \"total_train_time_s\": 15.06472635269165}", "{\"n\": 7020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.94, \"learn_time_ms\": 10476.268, \"total_train_time_s\": 14.097470045089722}", "{\"n\": 7021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.12, \"learn_time_ms\": 10522.038, \"total_train_time_s\": 14.554869413375854}", "{\"n\": 7022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.12, \"learn_time_ms\": 10482.252, \"total_train_time_s\": 14.28873586654663}", "{\"n\": 7023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.73, \"learn_time_ms\": 10456.736, \"total_train_time_s\": 13.168473720550537}", "{\"n\": 7024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.28, \"learn_time_ms\": 10442.32, \"total_train_time_s\": 14.240462064743042}", "{\"n\": 7025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.09, \"learn_time_ms\": 10453.217, \"total_train_time_s\": 14.237613677978516}", "{\"n\": 7026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.75, \"learn_time_ms\": 10465.218, \"total_train_time_s\": 14.148943424224854}", "{\"n\": 7027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.55, \"learn_time_ms\": 10347.148, \"total_train_time_s\": 12.85662293434143}", "{\"n\": 7028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.06, \"learn_time_ms\": 10297.438, \"total_train_time_s\": 14.516379833221436}", "{\"n\": 7029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.19, \"learn_time_ms\": 10287.487, \"total_train_time_s\": 14.683989524841309}", "{\"n\": 7030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.13, \"learn_time_ms\": 10314.429, \"total_train_time_s\": 14.437984943389893}", "{\"n\": 7031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.89, \"learn_time_ms\": 10251.452, \"total_train_time_s\": 13.565331220626831}", "{\"n\": 7032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.53, \"learn_time_ms\": 10326.486, \"total_train_time_s\": 14.59548044204712}", "{\"n\": 7033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.64, \"learn_time_ms\": 10438.82, \"total_train_time_s\": 14.308635950088501}", "{\"n\": 7034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.56, \"learn_time_ms\": 10465.896, \"total_train_time_s\": 14.697206497192383}", "{\"n\": 7035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.56, \"learn_time_ms\": 10474.679, \"total_train_time_s\": 14.179904460906982}", "{\"n\": 7036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 10510.125, \"total_train_time_s\": 14.386455297470093}", "{\"n\": 7037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.25, \"learn_time_ms\": 10731.246, \"total_train_time_s\": 14.96760606765747}", "{\"n\": 7038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.25, \"learn_time_ms\": 10753.657, \"total_train_time_s\": 14.475895643234253}", "{\"n\": 7039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.2, \"learn_time_ms\": 10707.166, \"total_train_time_s\": 14.310377597808838}", "{\"n\": 7040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.9, \"learn_time_ms\": 10760.498, \"total_train_time_s\": 14.88562536239624}", "{\"n\": 7041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.51, \"learn_time_ms\": 10737.039, \"total_train_time_s\": 13.450262784957886}", "{\"n\": 7042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.51, \"learn_time_ms\": 10780.56, \"total_train_time_s\": 15.402233600616455}", "{\"n\": 7043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.52, \"learn_time_ms\": 10731.325, \"total_train_time_s\": 13.967244386672974}", "{\"n\": 7044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.34, \"learn_time_ms\": 10659.637, \"total_train_time_s\": 13.982635498046875}", "{\"n\": 7045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.34, \"learn_time_ms\": 10676.944, \"total_train_time_s\": 14.492425918579102}", "{\"n\": 7046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.55, \"learn_time_ms\": 10557.715, \"total_train_time_s\": 13.312146425247192}", "{\"n\": 7047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.55, \"learn_time_ms\": 10450.877, \"total_train_time_s\": 13.919601440429688}", "{\"n\": 7048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3655.39, \"learn_time_ms\": 10456.262, \"total_train_time_s\": 14.632600545883179}", "{\"n\": 7049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.42, \"learn_time_ms\": 10520.134, \"total_train_time_s\": 14.982681274414062}", "{\"n\": 7050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.42, \"learn_time_ms\": 10402.532, \"total_train_time_s\": 13.826628684997559}", "{\"n\": 7051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.42, \"learn_time_ms\": 10425.71, \"total_train_time_s\": 13.590919017791748}", "{\"n\": 7052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3663.08, \"learn_time_ms\": 10368.334, \"total_train_time_s\": 14.466861248016357}", "{\"n\": 7053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.82, \"learn_time_ms\": 10430.269, \"total_train_time_s\": 14.347968101501465}", "{\"n\": 7054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.82, \"learn_time_ms\": 10454.694, \"total_train_time_s\": 14.476679801940918}", "{\"n\": 7055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3648.56, \"learn_time_ms\": 10479.357, \"total_train_time_s\": 15.052506446838379}", "{\"n\": 7056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.79, \"learn_time_ms\": 10486.231, \"total_train_time_s\": 13.375147819519043}", "{\"n\": 7057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.53, \"learn_time_ms\": 10472.307, \"total_train_time_s\": 14.246712684631348}", "{\"n\": 7058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.53, \"learn_time_ms\": 10398.666, \"total_train_time_s\": 13.764206409454346}", "{\"n\": 7059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.9, \"learn_time_ms\": 10383.056, \"total_train_time_s\": 14.653290748596191}", "{\"n\": 7060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.9, \"learn_time_ms\": 10458.284, \"total_train_time_s\": 14.88269305229187}", "{\"n\": 7061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.54, \"learn_time_ms\": 10502.535, \"total_train_time_s\": 14.016361474990845}", "{\"n\": 7062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.4, \"learn_time_ms\": 10402.875, \"total_train_time_s\": 13.68829607963562}", "{\"n\": 7063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.99, \"learn_time_ms\": 10312.101, \"total_train_time_s\": 13.527312755584717}", "{\"n\": 7064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.08, \"learn_time_ms\": 10254.76, \"total_train_time_s\": 13.72640585899353}", "{\"n\": 7065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.08, \"learn_time_ms\": 10115.278, \"total_train_time_s\": 13.332539081573486}", "{\"n\": 7066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3654.38, \"learn_time_ms\": 10187.695, \"total_train_time_s\": 14.046990871429443}", "{\"n\": 7067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.07, \"learn_time_ms\": 10207.128, \"total_train_time_s\": 14.0827476978302}", "{\"n\": 7068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.07, \"learn_time_ms\": 10256.798, \"total_train_time_s\": 14.221774101257324}", "{\"n\": 7069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.39, \"learn_time_ms\": 10218.533, \"total_train_time_s\": 14.53976559638977}", "{\"n\": 7070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3648.95, \"learn_time_ms\": 10260.924, \"total_train_time_s\": 15.243029594421387}", "{\"n\": 7071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.48, \"learn_time_ms\": 10219.81, \"total_train_time_s\": 13.968851804733276}", "{\"n\": 7072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.59, \"learn_time_ms\": 10280.827, \"total_train_time_s\": 14.159611701965332}", "{\"n\": 7073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.59, \"learn_time_ms\": 10257.59, \"total_train_time_s\": 13.489958047866821}", "{\"n\": 7074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.71, \"learn_time_ms\": 10276.318, \"total_train_time_s\": 13.798182964324951}", "{\"n\": 7075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.71, \"learn_time_ms\": 10386.606, \"total_train_time_s\": 14.456866264343262}", "{\"n\": 7076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 10336.516, \"total_train_time_s\": 13.584511756896973}", "{\"n\": 7077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 10283.897, \"total_train_time_s\": 13.629966735839844}", "{\"n\": 7078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.96, \"learn_time_ms\": 10251.629, \"total_train_time_s\": 13.991521120071411}", "{\"n\": 7079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.36, \"learn_time_ms\": 10293.895, \"total_train_time_s\": 14.866259336471558}", "{\"n\": 7080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.41, \"learn_time_ms\": 10239.618, \"total_train_time_s\": 14.35464096069336}", "{\"n\": 7081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.13, \"learn_time_ms\": 10239.776, \"total_train_time_s\": 13.742227792739868}", "{\"n\": 7082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.13, \"learn_time_ms\": 10342.439, \"total_train_time_s\": 15.193356037139893}", "{\"n\": 7083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.13, \"learn_time_ms\": 10443.16, \"total_train_time_s\": 14.19523572921753}", "{\"n\": 7084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.91, \"learn_time_ms\": 10493.501, \"total_train_time_s\": 14.176188945770264}", "{\"n\": 7085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.37, \"learn_time_ms\": 10632.688, \"total_train_time_s\": 15.816388607025146}", "{\"n\": 7086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3609.2, \"learn_time_ms\": 10778.638, \"total_train_time_s\": 15.085110664367676}", "{\"n\": 7087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3609.2, \"learn_time_ms\": 10759.88, \"total_train_time_s\": 13.399346590042114}", "{\"n\": 7088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.68, \"learn_time_ms\": 10752.94, \"total_train_time_s\": 13.88291883468628}", "{\"n\": 7089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.19, \"learn_time_ms\": 10627.172, \"total_train_time_s\": 13.639356136322021}", "{\"n\": 7090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.19, \"learn_time_ms\": 10539.627, \"total_train_time_s\": 13.777153968811035}", "{\"n\": 7091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.71, \"learn_time_ms\": 10470.973, \"total_train_time_s\": 12.878558874130249}", "{\"n\": 7092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.48, \"learn_time_ms\": 10402.568, \"total_train_time_s\": 14.696424007415771}", "{\"n\": 7093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10439.386, \"total_train_time_s\": 14.580872774124146}", "{\"n\": 7094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10500.313, \"total_train_time_s\": 14.940933465957642}", "{\"n\": 7095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.83, \"learn_time_ms\": 10214.034, \"total_train_time_s\": 12.705014944076538}", "{\"n\": 7096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.95, \"learn_time_ms\": 10101.955, \"total_train_time_s\": 13.830482244491577}", "{\"n\": 7097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.01, \"learn_time_ms\": 10198.214, \"total_train_time_s\": 14.257251739501953}", "{\"n\": 7098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.01, \"learn_time_ms\": 10314.317, \"total_train_time_s\": 15.276175022125244}", "{\"n\": 7099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.41, \"learn_time_ms\": 10329.775, \"total_train_time_s\": 13.57260513305664}", "{\"n\": 7100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.94, \"learn_time_ms\": 10428.3, \"total_train_time_s\": 14.492144346237183}", "{\"n\": 7101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.94, \"learn_time_ms\": 10521.275, \"total_train_time_s\": 13.75762939453125}", "{\"n\": 7102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.96, \"learn_time_ms\": 10502.814, \"total_train_time_s\": 14.515744924545288}", "{\"n\": 7103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.48, \"learn_time_ms\": 10391.582, \"total_train_time_s\": 13.516646385192871}", "{\"n\": 7104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.67, \"learn_time_ms\": 10236.113, \"total_train_time_s\": 13.167116403579712}", "{\"n\": 7105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.87, \"learn_time_ms\": 10327.11, \"total_train_time_s\": 13.766432523727417}", "{\"n\": 7106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.87, \"learn_time_ms\": 10338.092, \"total_train_time_s\": 14.1143319606781}", "{\"n\": 7107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.14, \"learn_time_ms\": 10251.541, \"total_train_time_s\": 13.5402512550354}", "{\"n\": 7108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.14, \"learn_time_ms\": 10088.12, \"total_train_time_s\": 13.45150351524353}", "{\"n\": 7109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.0, \"learn_time_ms\": 10142.728, \"total_train_time_s\": 14.395267963409424}", "{\"n\": 7110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.37, \"learn_time_ms\": 10054.097, \"total_train_time_s\": 14.043620109558105}", "{\"n\": 7111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.12, \"learn_time_ms\": 10096.72, \"total_train_time_s\": 14.519621133804321}", "{\"n\": 7112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.9, \"learn_time_ms\": 10067.401, \"total_train_time_s\": 13.974457502365112}", "{\"n\": 7113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.9, \"learn_time_ms\": 10180.043, \"total_train_time_s\": 14.866678953170776}", "{\"n\": 7114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.87, \"learn_time_ms\": 10204.973, \"total_train_time_s\": 13.490437269210815}", "{\"n\": 7115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.93, \"learn_time_ms\": 10266.756, \"total_train_time_s\": 14.507298707962036}", "{\"n\": 7116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.72, \"learn_time_ms\": 10256.814, \"total_train_time_s\": 13.839102029800415}", "{\"n\": 7117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.72, \"learn_time_ms\": 10419.703, \"total_train_time_s\": 15.205931186676025}", "{\"n\": 7118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.11, \"learn_time_ms\": 10576.643, \"total_train_time_s\": 15.186325550079346}", "{\"n\": 7119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.5, \"learn_time_ms\": 10487.31, \"total_train_time_s\": 13.454274654388428}", "{\"n\": 7120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.5, \"learn_time_ms\": 10456.029, \"total_train_time_s\": 13.565485000610352}", "{\"n\": 7121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.53, \"learn_time_ms\": 10383.079, \"total_train_time_s\": 13.52619194984436}", "{\"n\": 7122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.89, \"learn_time_ms\": 10485.472, \"total_train_time_s\": 15.416146278381348}", "{\"n\": 7123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.1, \"learn_time_ms\": 10446.005, \"total_train_time_s\": 14.176931619644165}", "{\"n\": 7124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.23, \"learn_time_ms\": 10504.763, \"total_train_time_s\": 14.023369073867798}", "{\"n\": 7125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.76, \"learn_time_ms\": 10527.55, \"total_train_time_s\": 14.635794162750244}", "{\"n\": 7126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.14, \"learn_time_ms\": 10618.563, \"total_train_time_s\": 14.887652158737183}", "{\"n\": 7127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.02, \"learn_time_ms\": 10489.598, \"total_train_time_s\": 13.665157318115234}", "{\"n\": 7128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.77, \"learn_time_ms\": 10396.781, \"total_train_time_s\": 14.006162643432617}", "{\"n\": 7129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10533.268, \"total_train_time_s\": 14.773318529129028}", "{\"n\": 7130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10642.583, \"total_train_time_s\": 14.595013618469238}", "{\"n\": 7131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.48, \"learn_time_ms\": 10688.231, \"total_train_time_s\": 14.000091791152954}", "{\"n\": 7132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.76, \"learn_time_ms\": 10552.615, \"total_train_time_s\": 13.941920757293701}", "{\"n\": 7133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.75, \"learn_time_ms\": 10630.684, \"total_train_time_s\": 14.910333633422852}", "{\"n\": 7134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.48, \"learn_time_ms\": 10600.034, \"total_train_time_s\": 13.784043550491333}", "{\"n\": 7135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.48, \"learn_time_ms\": 10543.67, \"total_train_time_s\": 14.186217784881592}", "{\"n\": 7136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.84, \"learn_time_ms\": 10505.855, \"total_train_time_s\": 14.455107927322388}", "{\"n\": 7137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.84, \"learn_time_ms\": 10582.581, \"total_train_time_s\": 14.982173681259155}", "{\"n\": 7138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.26, \"learn_time_ms\": 10494.683, \"total_train_time_s\": 13.296836614608765}", "{\"n\": 7139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.1, \"learn_time_ms\": 10439.385, \"total_train_time_s\": 14.400162935256958}", "{\"n\": 7140, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.1, \"learn_time_ms\": 10363.329, \"total_train_time_s\": 13.677472114562988}", "{\"n\": 7141, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.1, \"learn_time_ms\": 10314.312, \"total_train_time_s\": 13.680412530899048}", "{\"n\": 7142, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.18, \"learn_time_ms\": 10231.311, \"total_train_time_s\": 12.72509241104126}", "{\"n\": 7143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.31, \"learn_time_ms\": 10057.03, \"total_train_time_s\": 13.605034828186035}", "{\"n\": 7144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.31, \"learn_time_ms\": 10086.913, \"total_train_time_s\": 14.023338079452515}", "{\"n\": 7145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3635.37, \"learn_time_ms\": 10106.455, \"total_train_time_s\": 14.391252756118774}", "{\"n\": 7146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.39, \"learn_time_ms\": 9970.882, \"total_train_time_s\": 13.148788690567017}", "{\"n\": 7147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.64, \"learn_time_ms\": 9935.523, \"total_train_time_s\": 14.19816279411316}", "{\"n\": 7148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.64, \"learn_time_ms\": 9909.191, \"total_train_time_s\": 12.966572284698486}", "{\"n\": 7149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.38, \"learn_time_ms\": 9890.355, \"total_train_time_s\": 14.179570436477661}", "{\"n\": 7150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.82, \"learn_time_ms\": 9995.681, \"total_train_time_s\": 14.739132642745972}", "{\"n\": 7151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 10074.107, \"total_train_time_s\": 14.422280550003052}", "{\"n\": 7152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 10288.156, \"total_train_time_s\": 14.976959466934204}", "{\"n\": 7153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.63, \"learn_time_ms\": 10286.3, \"total_train_time_s\": 13.236008882522583}", "{\"n\": 7154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.4, \"learn_time_ms\": 10355.695, \"total_train_time_s\": 15.018447160720825}", "{\"n\": 7155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.4, \"learn_time_ms\": 10443.327, \"total_train_time_s\": 15.07030463218689}", "{\"n\": 7156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.53, \"learn_time_ms\": 10601.88, \"total_train_time_s\": 14.6111159324646}", "{\"n\": 7157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.87, \"learn_time_ms\": 10557.903, \"total_train_time_s\": 13.599783658981323}", "{\"n\": 7158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.62, \"learn_time_ms\": 10811.523, \"total_train_time_s\": 15.583595514297485}", "{\"n\": 7159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.45, \"learn_time_ms\": 10838.54, \"total_train_time_s\": 14.472607851028442}", "{\"n\": 7160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.29, \"learn_time_ms\": 10804.934, \"total_train_time_s\": 14.557288646697998}", "{\"n\": 7161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.29, \"learn_time_ms\": 10937.48, \"total_train_time_s\": 15.852092504501343}", "{\"n\": 7162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.41, \"learn_time_ms\": 10883.851, \"total_train_time_s\": 14.52204942703247}", "{\"n\": 7163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.39, \"learn_time_ms\": 10993.136, \"total_train_time_s\": 14.455845355987549}", "{\"n\": 7164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.41, \"learn_time_ms\": 10959.456, \"total_train_time_s\": 14.623811483383179}", "{\"n\": 7165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.41, \"learn_time_ms\": 10926.659, \"total_train_time_s\": 15.063884258270264}", "{\"n\": 7166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.41, \"learn_time_ms\": 10869.868, \"total_train_time_s\": 14.315430879592896}", "{\"n\": 7167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.69, \"learn_time_ms\": 10894.111, \"total_train_time_s\": 14.069352388381958}", "{\"n\": 7168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10706.001, \"total_train_time_s\": 13.487741947174072}", "{\"n\": 7169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10608.797, \"total_train_time_s\": 13.471841096878052}", "{\"n\": 7170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.71, \"learn_time_ms\": 10478.577, \"total_train_time_s\": 13.133777141571045}", "{\"n\": 7171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.4, \"learn_time_ms\": 10329.491, \"total_train_time_s\": 14.177300691604614}", "{\"n\": 7172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.4, \"learn_time_ms\": 10294.901, \"total_train_time_s\": 14.452443361282349}", "{\"n\": 7173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.29, \"learn_time_ms\": 10243.944, \"total_train_time_s\": 13.756938457489014}", "{\"n\": 7174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 10259.322, \"total_train_time_s\": 14.699849843978882}", "{\"n\": 7175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.97, \"learn_time_ms\": 10238.859, \"total_train_time_s\": 14.685642957687378}", "{\"n\": 7176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3614.55, \"learn_time_ms\": 10276.879, \"total_train_time_s\": 14.516802787780762}", "{\"n\": 7177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3614.55, \"learn_time_ms\": 10187.232, \"total_train_time_s\": 13.289018154144287}", "{\"n\": 7178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3616.22, \"learn_time_ms\": 10293.015, \"total_train_time_s\": 14.860551834106445}", "{\"n\": 7179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3614.96, \"learn_time_ms\": 10288.102, \"total_train_time_s\": 13.126930713653564}", "{\"n\": 7180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3606.56, \"learn_time_ms\": 10383.162, \"total_train_time_s\": 14.19132661819458}", "{\"n\": 7181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3606.56, \"learn_time_ms\": 10295.261, \"total_train_time_s\": 13.172688722610474}", "{\"n\": 7182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3599.48, \"learn_time_ms\": 10315.452, \"total_train_time_s\": 14.213111400604248}", "{\"n\": 7183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3599.48, \"learn_time_ms\": 10384.918, \"total_train_time_s\": 14.657325506210327}", "{\"n\": 7184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.65, \"learn_time_ms\": 10308.297, \"total_train_time_s\": 13.976155996322632}", "{\"n\": 7185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3590.5, \"learn_time_ms\": 10221.369, \"total_train_time_s\": 13.896615505218506}", "{\"n\": 7186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 10149.309, \"total_train_time_s\": 13.85276746749878}", "{\"n\": 7187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 10248.105, \"total_train_time_s\": 14.154790163040161}", "{\"n\": 7188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3595.22, \"learn_time_ms\": 10159.395, \"total_train_time_s\": 13.947401762008667}", "{\"n\": 7189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3597.51, \"learn_time_ms\": 10286.313, \"total_train_time_s\": 14.457990169525146}", "{\"n\": 7190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3597.51, \"learn_time_ms\": 10285.192, \"total_train_time_s\": 14.42398190498352}", "{\"n\": 7191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3597.51, \"learn_time_ms\": 10324.665, \"total_train_time_s\": 13.918332815170288}", "{\"n\": 7192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3585.02, \"learn_time_ms\": 10299.019, \"total_train_time_s\": 14.061493873596191}", "{\"n\": 7193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.0, \"learn_time_ms\": 10198.804, \"total_train_time_s\": 14.001121997833252}", "{\"n\": 7194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.0, \"learn_time_ms\": 10237.498, \"total_train_time_s\": 14.240735054016113}", "{\"n\": 7195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.98, \"learn_time_ms\": 10410.972, \"total_train_time_s\": 15.399338960647583}", "{\"n\": 7196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.98, \"learn_time_ms\": 10453.652, \"total_train_time_s\": 14.495505571365356}", "{\"n\": 7197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.98, \"learn_time_ms\": 10530.338, \"total_train_time_s\": 14.843206644058228}", "{\"n\": 7198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3576.04, \"learn_time_ms\": 10540.608, \"total_train_time_s\": 13.834678411483765}", "{\"n\": 7199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3561.46, \"learn_time_ms\": 10438.822, \"total_train_time_s\": 13.501355648040771}", "{\"n\": 7200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3561.46, \"learn_time_ms\": 10426.223, \"total_train_time_s\": 13.860201835632324}", "{\"n\": 7201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3561.46, \"learn_time_ms\": 10427.433, \"total_train_time_s\": 13.589972019195557}", "{\"n\": 7202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3566.07, \"learn_time_ms\": 10389.575, \"total_train_time_s\": 13.917681694030762}", "{\"n\": 7203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3559.25, \"learn_time_ms\": 10426.934, \"total_train_time_s\": 14.081185579299927}", "{\"n\": 7204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3559.25, \"learn_time_ms\": 10376.657, \"total_train_time_s\": 13.912115812301636}", "{\"n\": 7205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3558.36, \"learn_time_ms\": 10284.141, \"total_train_time_s\": 14.549384832382202}", "{\"n\": 7206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3558.36, \"learn_time_ms\": 10325.958, \"total_train_time_s\": 14.70515489578247}", "{\"n\": 7207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3557.24, \"learn_time_ms\": 10223.228, \"total_train_time_s\": 14.130757808685303}", "{\"n\": 7208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3551.51, \"learn_time_ms\": 10269.897, \"total_train_time_s\": 14.517759084701538}", "{\"n\": 7209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3551.51, \"learn_time_ms\": 10344.777, \"total_train_time_s\": 14.140971183776855}", "{\"n\": 7210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3545.01, \"learn_time_ms\": 10375.393, \"total_train_time_s\": 14.36258316040039}", "{\"n\": 7211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3545.6, \"learn_time_ms\": 10351.801, \"total_train_time_s\": 13.772515296936035}", "{\"n\": 7212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.99, \"learn_time_ms\": 10364.378, \"total_train_time_s\": 13.661004781723022}", "{\"n\": 7213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.71, \"learn_time_ms\": 10334.013, \"total_train_time_s\": 13.585526704788208}", "{\"n\": 7214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3563.78, \"learn_time_ms\": 10393.615, \"total_train_time_s\": 14.457994937896729}", "{\"n\": 7215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3563.78, \"learn_time_ms\": 10313.842, \"total_train_time_s\": 13.864825963973999}", "{\"n\": 7216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3560.73, \"learn_time_ms\": 10246.1, \"total_train_time_s\": 14.049554109573364}", "{\"n\": 7217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3564.31, \"learn_time_ms\": 10362.906, \"total_train_time_s\": 14.932425260543823}", "{\"n\": 7218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3568.61, \"learn_time_ms\": 10334.882, \"total_train_time_s\": 13.98719596862793}", "{\"n\": 7219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3570.58, \"learn_time_ms\": 10163.596, \"total_train_time_s\": 12.3187735080719}", "{\"n\": 7220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3565.97, \"learn_time_ms\": 10184.023, \"total_train_time_s\": 14.409379005432129}", "{\"n\": 7221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3568.47, \"learn_time_ms\": 10302.523, \"total_train_time_s\": 14.63124704360962}", "{\"n\": 7222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3569.29, \"learn_time_ms\": 10290.933, \"total_train_time_s\": 13.63382887840271}", "{\"n\": 7223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3564.19, \"learn_time_ms\": 10316.901, \"total_train_time_s\": 13.752468824386597}", "{\"n\": 7224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.93, \"learn_time_ms\": 10291.677, \"total_train_time_s\": 14.188925981521606}", "{\"n\": 7225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3567.34, \"learn_time_ms\": 10387.969, \"total_train_time_s\": 14.762915134429932}", "{\"n\": 7226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3567.34, \"learn_time_ms\": 10414.301, \"total_train_time_s\": 14.18335747718811}", "{\"n\": 7227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3582.13, \"learn_time_ms\": 10357.808, \"total_train_time_s\": 14.49392580986023}", "{\"n\": 7228, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3568.53, \"learn_time_ms\": 10393.378, \"total_train_time_s\": 14.81529188156128}", "{\"n\": 7229, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3568.53, \"learn_time_ms\": 10566.487, \"total_train_time_s\": 14.383938312530518}", "{\"n\": 7230, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.57, \"learn_time_ms\": 10493.208, \"total_train_time_s\": 13.709494829177856}", "{\"n\": 7231, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3570.69, \"learn_time_ms\": 10402.347, \"total_train_time_s\": 13.797587394714355}", "{\"n\": 7232, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.63, \"learn_time_ms\": 10508.458, \"total_train_time_s\": 14.700690746307373}", "{\"n\": 7233, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.63, \"learn_time_ms\": 10537.627, \"total_train_time_s\": 14.33951187133789}", "{\"n\": 7234, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3584.68, \"learn_time_ms\": 10537.538, \"total_train_time_s\": 14.203370332717896}", "{\"n\": 7235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3587.55, \"learn_time_ms\": 10617.774, \"total_train_time_s\": 15.452609062194824}", "{\"n\": 7236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3581.67, \"learn_time_ms\": 10663.074, \"total_train_time_s\": 14.64455509185791}", "{\"n\": 7237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3581.67, \"learn_time_ms\": 10588.697, \"total_train_time_s\": 13.769527435302734}", "{\"n\": 7238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.11, \"learn_time_ms\": 10569.772, \"total_train_time_s\": 14.09093427658081}", "{\"n\": 7239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3580.42, \"learn_time_ms\": 10562.16, \"total_train_time_s\": 14.270429134368896}", "{\"n\": 7240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3580.42, \"learn_time_ms\": 10619.851, \"total_train_time_s\": 14.7249436378479}", "{\"n\": 7241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3580.42, \"learn_time_ms\": 10716.046, \"total_train_time_s\": 14.641103744506836}", "{\"n\": 7242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3587.99, \"learn_time_ms\": 10662.63, \"total_train_time_s\": 14.334462642669678}", "{\"n\": 7243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 10654.254, \"total_train_time_s\": 14.109469652175903}", "{\"n\": 7244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 10551.004, \"total_train_time_s\": 13.097121715545654}", "{\"n\": 7245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3595.97, \"learn_time_ms\": 10373.056, \"total_train_time_s\": 13.577995538711548}", "{\"n\": 7246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.92, \"learn_time_ms\": 10295.005, \"total_train_time_s\": 13.881645679473877}", "{\"n\": 7247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.92, \"learn_time_ms\": 10348.183, \"total_train_time_s\": 14.285518884658813}", "{\"n\": 7248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3602.28, \"learn_time_ms\": 10420.092, \"total_train_time_s\": 14.913298845291138}"]