["{\"n\": 101, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9614.125, \"total_train_time_s\": 13.33422327041626}", "{\"n\": 102, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10494.088, \"total_train_time_s\": 14.905922412872314}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1110.75, \"learn_time_ms\": 10217.063, \"total_train_time_s\": 13.366818904876709}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1170.125, \"learn_time_ms\": 9968.781, \"total_train_time_s\": 13.07467246055603}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.583333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1164.0, \"learn_time_ms\": 10378.053, \"total_train_time_s\": 15.65909218788147}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1153.625, \"learn_time_ms\": 10430.903, \"total_train_time_s\": 14.271212339401245}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1161.55, \"learn_time_ms\": 10418.169, \"total_train_time_s\": 14.056128978729248}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47826086956522, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1150.8695652173913, \"learn_time_ms\": 10284.935, \"total_train_time_s\": 13.127874851226807}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1148.8, \"learn_time_ms\": 10276.162, \"total_train_time_s\": 13.747327327728271}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.392857142857142, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1146.9642857142858, \"learn_time_ms\": 10439.922, \"total_train_time_s\": 15.462424516677856}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1146.9375, \"learn_time_ms\": 10553.092, \"total_train_time_s\": 14.338992595672607}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.305555555555557, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1144.2777777777778, \"learn_time_ms\": 10436.43, \"total_train_time_s\": 13.75337266921997}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.325, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1142.65, \"learn_time_ms\": 10530.839, \"total_train_time_s\": 14.156122207641602}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.295454545454547, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1142.3863636363637, \"learn_time_ms\": 10622.545, \"total_train_time_s\": 13.794536590576172}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.270833333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.7083333333333, \"learn_time_ms\": 10405.559, \"total_train_time_s\": 13.411885738372803}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.4423076923076, \"learn_time_ms\": 10363.318, \"total_train_time_s\": 13.83849835395813}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.254545454545454, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.9454545454546, \"learn_time_ms\": 10524.971, \"total_train_time_s\": 15.826766014099121}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25862068965517, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.5862068965516, \"learn_time_ms\": 10716.405, \"total_train_time_s\": 15.016493558883667}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24590163934426, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.688524590164, \"learn_time_ms\": 10666.927, \"total_train_time_s\": 13.263536214828491}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.246153846153845, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.4307692307693, \"learn_time_ms\": 10445.275, \"total_train_time_s\": 13.30116057395935}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.246376811594203, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.7246376811595, \"learn_time_ms\": 10474.59, \"total_train_time_s\": 14.699002742767334}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23611111111111, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.9583333333333, \"learn_time_ms\": 10431.509, \"total_train_time_s\": 13.490079402923584}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.236842105263158, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.9605263157894, \"learn_time_ms\": 10394.87, \"total_train_time_s\": 13.787702322006226}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1141.9875, \"learn_time_ms\": 10358.307, \"total_train_time_s\": 13.322246789932251}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.238095238095237, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1141.3690476190477, \"learn_time_ms\": 10314.162, \"total_train_time_s\": 13.201148509979248}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24137931034483, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.344827586207, \"learn_time_ms\": 10437.581, \"total_train_time_s\": 15.158541202545166}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.235955056179776, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.8539325842696, \"learn_time_ms\": 10190.977, \"total_train_time_s\": 13.11772894859314}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.225806451612904, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.2043010752689, \"learn_time_ms\": 10157.21, \"total_train_time_s\": 14.502500057220459}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.216494845360824, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.1958762886597, \"learn_time_ms\": 10256.338, \"total_train_time_s\": 14.452296257019043}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1140.87, \"learn_time_ms\": 10275.174, \"total_train_time_s\": 13.498414754867554}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.59, \"learn_time_ms\": 10259.565, \"total_train_time_s\": 14.48306679725647}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1138.25, \"learn_time_ms\": 10334.431, \"total_train_time_s\": 14.394416570663452}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1139.12, \"learn_time_ms\": 10266.275, \"total_train_time_s\": 13.382622480392456}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1139.2, \"learn_time_ms\": 10295.262, \"total_train_time_s\": 13.713029623031616}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1136.3, \"learn_time_ms\": 10534.993, \"total_train_time_s\": 15.373960018157959}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1138.77, \"learn_time_ms\": 10335.944, \"total_train_time_s\": 13.089616537094116}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1139.19, \"learn_time_ms\": 10460.143, \"total_train_time_s\": 14.400262832641602}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1140.81, \"learn_time_ms\": 10521.758, \"total_train_time_s\": 15.346089839935303}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1143.61, \"learn_time_ms\": 10451.017, \"total_train_time_s\": 13.55635666847229}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1144.56, \"learn_time_ms\": 10425.777, \"total_train_time_s\": 13.203742742538452}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1144.79, \"learn_time_ms\": 10384.717, \"total_train_time_s\": 14.028759479522705}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.07, \"learn_time_ms\": 10335.663, \"total_train_time_s\": 13.906953573226929}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.73, \"learn_time_ms\": 10359.582, \"total_train_time_s\": 13.562910556793213}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1160.15, \"learn_time_ms\": 10314.745, \"total_train_time_s\": 13.248433113098145}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1160.27, \"learn_time_ms\": 10241.389, \"total_train_time_s\": 14.81030821800232}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1161.63, \"learn_time_ms\": 10472.684, \"total_train_time_s\": 15.401147365570068}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1162.73, \"learn_time_ms\": 10573.78, \"total_train_time_s\": 15.309124946594238}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1163.47, \"learn_time_ms\": 10369.026, \"total_train_time_s\": 13.100111484527588}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1164.81, \"learn_time_ms\": 10438.916, \"total_train_time_s\": 14.276268482208252}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1167.15, \"learn_time_ms\": 10493.006, \"total_train_time_s\": 13.745856761932373}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1167.61, \"learn_time_ms\": 10471.342, \"total_train_time_s\": 13.91481328010559}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1167.43, \"learn_time_ms\": 10545.796, \"total_train_time_s\": 14.392725229263306}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1165.96, \"learn_time_ms\": 10586.471, \"total_train_time_s\": 13.822360754013062}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1169.05, \"learn_time_ms\": 10661.53, \"total_train_time_s\": 14.070611953735352}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1173.91, \"learn_time_ms\": 10523.023, \"total_train_time_s\": 13.492126703262329}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1174.34, \"learn_time_ms\": 10329.955, \"total_train_time_s\": 13.553366422653198}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1174.88, \"learn_time_ms\": 10109.617, \"total_train_time_s\": 13.112936973571777}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1178.16, \"learn_time_ms\": 10181.626, \"total_train_time_s\": 13.85547924041748}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1181.09, \"learn_time_ms\": 10020.042, \"total_train_time_s\": 12.769970178604126}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1184.85, \"learn_time_ms\": 10102.152, \"total_train_time_s\": 14.614293813705444}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1186.93, \"learn_time_ms\": 10047.605, \"total_train_time_s\": 13.275948286056519}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1187.11, \"learn_time_ms\": 9943.958, \"total_train_time_s\": 13.288789510726929}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1186.74, \"learn_time_ms\": 9916.269, \"total_train_time_s\": 13.481472969055176}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1187.69, \"learn_time_ms\": 9796.548, \"total_train_time_s\": 12.762360572814941}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1193.29, \"learn_time_ms\": 9901.12, \"total_train_time_s\": 14.302384853363037}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1201.64, \"learn_time_ms\": 9963.329, \"total_train_time_s\": 14.217793703079224}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1203.67, \"learn_time_ms\": 10209.732, \"total_train_time_s\": 15.594711065292358}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.54, \"learn_time_ms\": 10198.279, \"total_train_time_s\": 13.692163228988647}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.81, \"learn_time_ms\": 10303.454, \"total_train_time_s\": 13.70740532875061}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1211.22, \"learn_time_ms\": 10236.073, \"total_train_time_s\": 14.175656795501709}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.01, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1217.55, \"learn_time_ms\": 10350.261, \"total_train_time_s\": 14.429270267486572}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.99, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1226.38, \"learn_time_ms\": 10346.828, \"total_train_time_s\": 13.383304119110107}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1233.33, \"learn_time_ms\": 10338.996, \"total_train_time_s\": 13.741394758224487}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1231.38, \"learn_time_ms\": 10393.586, \"total_train_time_s\": 13.285725355148315}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1239.0, \"learn_time_ms\": 10443.383, \"total_train_time_s\": 14.937535524368286}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1241.68, \"learn_time_ms\": 10308.392, \"total_train_time_s\": 12.87944483757019}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1240.83, \"learn_time_ms\": 10060.215, \"total_train_time_s\": 13.146212100982666}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1243.27, \"learn_time_ms\": 10098.93, \"total_train_time_s\": 14.19403624534607}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1243.55, \"learn_time_ms\": 10169.96, \"total_train_time_s\": 14.430742740631104}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1247.16, \"learn_time_ms\": 10205.801, \"total_train_time_s\": 14.313548803329468}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1250.58, \"learn_time_ms\": 10118.792, \"total_train_time_s\": 13.637105941772461}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1254.24, \"learn_time_ms\": 10200.439, \"total_train_time_s\": 14.311705112457275}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1257.68, \"learn_time_ms\": 10238.336, \"total_train_time_s\": 13.96140170097351}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1264.81, \"learn_time_ms\": 10177.361, \"total_train_time_s\": 12.765425682067871}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1266.39, \"learn_time_ms\": 10113.682, \"total_train_time_s\": 14.153702020645142}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.24, \"learn_time_ms\": 10358.695, \"total_train_time_s\": 15.344959497451782}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1259.4, \"learn_time_ms\": 10309.676, \"total_train_time_s\": 12.612580060958862}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1259.9, \"learn_time_ms\": 10327.65, \"total_train_time_s\": 14.404625415802002}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1258.31, \"learn_time_ms\": 10354.84, \"total_train_time_s\": 14.752643585205078}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1259.63, \"learn_time_ms\": 10376.534, \"total_train_time_s\": 14.503421783447266}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1262.53, \"learn_time_ms\": 10273.163, \"total_train_time_s\": 12.564828157424927}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1266.34, \"learn_time_ms\": 10354.024, \"total_train_time_s\": 14.892545223236084}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1266.66, \"learn_time_ms\": 10333.559, \"total_train_time_s\": 13.84433388710022}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1275.14, \"learn_time_ms\": 10424.647, \"total_train_time_s\": 13.701040983200073}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.67, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1280.41, \"learn_time_ms\": 10269.631, \"total_train_time_s\": 12.738106727600098}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1274.5, \"learn_time_ms\": 10155.169, \"total_train_time_s\": 14.131491661071777}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1265.25, \"learn_time_ms\": 10305.799, \"total_train_time_s\": 14.136239290237427}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1268.11, \"learn_time_ms\": 10313.41, \"total_train_time_s\": 14.317338228225708}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1269.71, \"learn_time_ms\": 10194.601, \"total_train_time_s\": 13.522022008895874}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1266.01, \"learn_time_ms\": 10104.814, \"total_train_time_s\": 13.745763778686523}"]["{\"n\": 201, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9478.547, \"total_train_time_s\": 13.20383620262146}", "{\"n\": 202, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9601.451, \"total_train_time_s\": 13.256191968917847}", "{\"n\": 203, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1267.0, \"learn_time_ms\": 9694.676, \"total_train_time_s\": 13.505725860595703}", "{\"n\": 204, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1274.625, \"learn_time_ms\": 9848.814, \"total_train_time_s\": 13.901952981948853}", "{\"n\": 205, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1256.0, \"learn_time_ms\": 9878.558, \"total_train_time_s\": 13.68318247795105}", "{\"n\": 206, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.53846153846154, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1259.6153846153845, \"learn_time_ms\": 9898.172, \"total_train_time_s\": 13.573922395706177}", "{\"n\": 207, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.5625, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1272.375, \"learn_time_ms\": 9846.34, \"total_train_time_s\": 13.062481164932251}", "{\"n\": 208, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1263.6, \"learn_time_ms\": 9838.982, \"total_train_time_s\": 13.472287893295288}", "{\"n\": 209, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.681818181818183, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1253.0454545454545, \"learn_time_ms\": 9888.808, \"total_train_time_s\": 13.846161365509033}", "{\"n\": 210, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1250.36, \"learn_time_ms\": 9955.459, \"total_train_time_s\": 14.37628698348999}", "{\"n\": 211, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.642857142857142, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1274.1785714285713, \"learn_time_ms\": 10034.942, \"total_train_time_s\": 13.849184036254883}", "{\"n\": 212, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.612903225806452, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1271.1935483870968, \"learn_time_ms\": 10179.75, \"total_train_time_s\": 14.75954294204712}", "{\"n\": 213, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.514285714285716, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1274.8285714285714, \"learn_time_ms\": 10204.216, \"total_train_time_s\": 13.781875610351562}", "{\"n\": 214, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.342105263157894, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1300.6842105263158, \"learn_time_ms\": 10260.99, \"total_train_time_s\": 14.76826548576355}", "{\"n\": 215, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1302.75, \"learn_time_ms\": 10174.718, \"total_train_time_s\": 12.772489309310913}", "{\"n\": 216, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.232558139534884, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1316.8139534883721, \"learn_time_ms\": 10202.451, \"total_train_time_s\": 13.845318078994751}", "{\"n\": 217, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.217391304347824, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1314.5217391304348, \"learn_time_ms\": 10202.405, \"total_train_time_s\": 13.115907669067383}", "{\"n\": 218, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.1875, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1325.8125, \"learn_time_ms\": 10299.001, \"total_train_time_s\": 14.317664861679077}", "{\"n\": 219, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.11764705882353, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1337.7450980392157, \"learn_time_ms\": 10303.193, \"total_train_time_s\": 14.05549669265747}", "{\"n\": 220, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.11111111111111, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1341.0555555555557, \"learn_time_ms\": 10299.028, \"total_train_time_s\": 14.114075422286987}", "{\"n\": 221, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.087719298245613, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1346.5263157894738, \"learn_time_ms\": 10324.673, \"total_train_time_s\": 14.12399959564209}", "{\"n\": 222, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.050847457627118, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1350.084745762712, \"learn_time_ms\": 10190.163, \"total_train_time_s\": 13.432984352111816}", "{\"n\": 223, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.015873015873016, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1351.3968253968253, \"learn_time_ms\": 10105.328, \"total_train_time_s\": 12.874219179153442}", "{\"n\": 224, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1354.3181818181818, \"learn_time_ms\": 10131.076, \"total_train_time_s\": 14.790499925613403}", "{\"n\": 225, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -18.955882352941178, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1359.5, \"learn_time_ms\": 10245.745, \"total_train_time_s\": 13.83690595626831}", "{\"n\": 226, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -18.943661971830984, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1360.225352112676, \"learn_time_ms\": 10224.733, \"total_train_time_s\": 13.651429891586304}", "{\"n\": 227, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -18.93243243243243, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1366.662162162162, \"learn_time_ms\": 10283.977, \"total_train_time_s\": 13.668776512145996}", "{\"n\": 228, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -18.933333333333334, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1367.1866666666667, \"learn_time_ms\": 10260.763, \"total_train_time_s\": 14.105060577392578}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.924050632911392, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1374.367088607595, \"learn_time_ms\": 10334.818, \"total_train_time_s\": 14.683125734329224}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9390243902439, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1377.3536585365853, \"learn_time_ms\": 10411.02, \"total_train_time_s\": 14.888282060623169}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.927710843373493, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1380.55421686747, \"learn_time_ms\": 10277.752, \"total_train_time_s\": 12.812060356140137}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.850574712643677, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1391.6091954022988, \"learn_time_ms\": 10212.031, \"total_train_time_s\": 12.83722472190857}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.831460674157302, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1392.8314606741574, \"learn_time_ms\": 10263.956, \"total_train_time_s\": 13.370567560195923}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83695652173913, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1391.2717391304348, \"learn_time_ms\": 10242.303, \"total_train_time_s\": 14.5399911403656}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.778947368421054, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1403.4421052631578, \"learn_time_ms\": 10306.723, \"total_train_time_s\": 14.594979286193848}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.760416666666668, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1406.5520833333333, \"learn_time_ms\": 10259.049, \"total_train_time_s\": 13.334618330001831}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.727272727272727, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1412.6969696969697, \"learn_time_ms\": 10306.906, \"total_train_time_s\": 14.231549739837646}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1422.4, \"learn_time_ms\": 10217.483, \"total_train_time_s\": 13.265779972076416}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1429.36, \"learn_time_ms\": 10155.186, \"total_train_time_s\": 14.104562759399414}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1444.18, \"learn_time_ms\": 9944.88, \"total_train_time_s\": 12.83612847328186}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1452.5, \"learn_time_ms\": 10079.347, \"total_train_time_s\": 14.447197675704956}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1458.15, \"learn_time_ms\": 10177.488, \"total_train_time_s\": 13.945342302322388}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1469.46, \"learn_time_ms\": 10151.751, \"total_train_time_s\": 13.117965698242188}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.4, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1476.86, \"learn_time_ms\": 10146.432, \"total_train_time_s\": 14.585734844207764}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1487.86, \"learn_time_ms\": 10038.894, \"total_train_time_s\": 13.557724475860596}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1493.52, \"learn_time_ms\": 10051.944, \"total_train_time_s\": 13.536622762680054}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1503.76, \"learn_time_ms\": 10005.718, \"total_train_time_s\": 13.700486421585083}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1510.56, \"learn_time_ms\": 10036.669, \"total_train_time_s\": 13.680363416671753}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1511.84, \"learn_time_ms\": 10065.758, \"total_train_time_s\": 14.310201644897461}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1530.35, \"learn_time_ms\": 10227.571, \"total_train_time_s\": 14.365789651870728}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1531.92, \"learn_time_ms\": 10183.306, \"total_train_time_s\": 13.723100662231445}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1543.4, \"learn_time_ms\": 10171.559, \"total_train_time_s\": 13.586205244064331}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1548.46, \"learn_time_ms\": 10204.37, \"total_train_time_s\": 13.626167297363281}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1550.07, \"learn_time_ms\": 10176.532, \"total_train_time_s\": 14.46599555015564}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1557.89, \"learn_time_ms\": 10370.224, \"total_train_time_s\": 15.432170152664185}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1567.3, \"learn_time_ms\": 10341.348, \"total_train_time_s\": 12.992483377456665}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1570.73, \"learn_time_ms\": 10414.248, \"total_train_time_s\": 14.412888526916504}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1572.43, \"learn_time_ms\": 10433.186, \"total_train_time_s\": 13.901897192001343}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1574.4, \"learn_time_ms\": 10413.038, \"total_train_time_s\": 14.335869312286377}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1585.01, \"learn_time_ms\": 10276.516, \"total_train_time_s\": 12.974675416946411}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1589.59, \"learn_time_ms\": 10247.841, \"total_train_time_s\": 13.551567316055298}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1595.72, \"learn_time_ms\": 10199.396, \"total_train_time_s\": 13.141975402832031}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1602.69, \"learn_time_ms\": 10208.363, \"total_train_time_s\": 13.518932104110718}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1615.52, \"learn_time_ms\": 10156.808, \"total_train_time_s\": 13.631876468658447}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1625.2, \"learn_time_ms\": 10052.101, \"total_train_time_s\": 14.28546142578125}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1625.76, \"learn_time_ms\": 10049.84, \"total_train_time_s\": 13.082642793655396}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1638.87, \"learn_time_ms\": 9963.905, \"total_train_time_s\": 13.66157054901123}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1644.12, \"learn_time_ms\": 9943.587, \"total_train_time_s\": 13.51893925666809}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1651.58, \"learn_time_ms\": 9887.394, \"total_train_time_s\": 13.531965732574463}", "{\"n\": 270, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1662.71, \"learn_time_ms\": 9897.415, \"total_train_time_s\": 13.287418127059937}", "{\"n\": 271, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1665.57, \"learn_time_ms\": 9930.925, \"total_train_time_s\": 13.769710063934326}", "{\"n\": 272, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1669.59, \"learn_time_ms\": 9985.844, \"total_train_time_s\": 13.942803144454956}", "{\"n\": 273, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1669.27, \"learn_time_ms\": 10114.952, \"total_train_time_s\": 14.84812593460083}", "{\"n\": 274, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1674.52, \"learn_time_ms\": 10167.91, \"total_train_time_s\": 14.431943893432617}", "{\"n\": 275, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1685.77, \"learn_time_ms\": 10023.95, \"total_train_time_s\": 12.886783599853516}", "{\"n\": 276, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1693.45, \"learn_time_ms\": 10034.933, \"total_train_time_s\": 13.12582015991211}", "{\"n\": 277, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1707.05, \"learn_time_ms\": 10125.884, \"total_train_time_s\": 14.540201663970947}", "{\"n\": 278, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1710.52, \"learn_time_ms\": 10173.202, \"total_train_time_s\": 13.979262113571167}", "{\"n\": 279, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1719.94, \"learn_time_ms\": 10150.887, \"total_train_time_s\": 13.540886878967285}", "{\"n\": 280, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1727.01, \"learn_time_ms\": 10134.059, \"total_train_time_s\": 12.960969686508179}", "{\"n\": 281, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1729.6, \"learn_time_ms\": 10229.163, \"total_train_time_s\": 14.73769235610962}", "{\"n\": 282, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1731.3, \"learn_time_ms\": 10106.475, \"total_train_time_s\": 12.529870510101318}", "{\"n\": 283, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1733.46, \"learn_time_ms\": 10023.838, \"total_train_time_s\": 14.055482149124146}", "{\"n\": 284, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1747.76, \"learn_time_ms\": 10001.415, \"total_train_time_s\": 13.98515272140503}", "{\"n\": 285, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1754.33, \"learn_time_ms\": 10041.392, \"total_train_time_s\": 13.267058849334717}", "{\"n\": 286, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1760.55, \"learn_time_ms\": 10076.156, \"total_train_time_s\": 13.60996699333191}", "{\"n\": 287, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1763.31, \"learn_time_ms\": 10012.376, \"total_train_time_s\": 13.861145734786987}", "{\"n\": 288, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1776.41, \"learn_time_ms\": 9950.513, \"total_train_time_s\": 13.514474868774414}", "{\"n\": 289, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1785.19, \"learn_time_ms\": 9994.14, \"total_train_time_s\": 13.88794231414795}", "{\"n\": 290, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1795.79, \"learn_time_ms\": 10075.521, \"total_train_time_s\": 13.855501174926758}", "{\"n\": 291, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1802.31, \"learn_time_ms\": 9859.464, \"total_train_time_s\": 12.637329339981079}", "{\"n\": 292, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1804.98, \"learn_time_ms\": 9907.98, \"total_train_time_s\": 13.018162965774536}", "{\"n\": 293, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1813.65, \"learn_time_ms\": 9871.533, \"total_train_time_s\": 13.628018140792847}", "{\"n\": 294, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1826.18, \"learn_time_ms\": 9834.132, \"total_train_time_s\": 13.665276288986206}", "{\"n\": 295, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1832.88, \"learn_time_ms\": 9837.109, \"total_train_time_s\": 13.305830240249634}", "{\"n\": 296, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1842.27, \"learn_time_ms\": 9800.583, \"total_train_time_s\": 13.07968807220459}", "{\"n\": 297, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1849.46, \"learn_time_ms\": 9906.393, \"total_train_time_s\": 14.985750436782837}", "{\"n\": 298, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1857.19, \"learn_time_ms\": 9903.377, \"total_train_time_s\": 13.338752508163452}", "{\"n\": 299, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1863.38, \"learn_time_ms\": 9868.483, \"total_train_time_s\": 13.48432445526123}", "{\"n\": 300, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1868.77, \"learn_time_ms\": 9862.453, \"total_train_time_s\": 13.709152936935425}", "{\"n\": 301, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1881.63, \"learn_time_ms\": 9851.337, \"total_train_time_s\": 12.521777629852295}", "{\"n\": 302, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1886.44, \"learn_time_ms\": 9982.588, \"total_train_time_s\": 14.512817144393921}", "{\"n\": 303, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1891.13, \"learn_time_ms\": 9998.222, \"total_train_time_s\": 13.790424346923828}", "{\"n\": 304, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1897.35, \"learn_time_ms\": 9951.264, \"total_train_time_s\": 13.113415479660034}", "{\"n\": 305, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1912.63, \"learn_time_ms\": 9975.941, \"total_train_time_s\": 13.638880252838135}", "{\"n\": 306, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1917.32, \"learn_time_ms\": 10049.579, \"total_train_time_s\": 13.823677778244019}", "{\"n\": 307, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1917.43, \"learn_time_ms\": 9911.833, \"total_train_time_s\": 13.633332014083862}", "{\"n\": 308, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1925.95, \"learn_time_ms\": 9982.164, \"total_train_time_s\": 14.058942317962646}", "{\"n\": 309, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1937.27, \"learn_time_ms\": 9964.829, \"total_train_time_s\": 13.21909475326538}", "{\"n\": 310, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1951.22, \"learn_time_ms\": 9859.252, \"total_train_time_s\": 12.828908443450928}", "{\"n\": 311, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1955.05, \"learn_time_ms\": 9907.017, \"total_train_time_s\": 13.078591585159302}", "{\"n\": 312, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1965.58, \"learn_time_ms\": 9739.6, \"total_train_time_s\": 12.576947212219238}", "{\"n\": 313, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1966.86, \"learn_time_ms\": 9641.138, \"total_train_time_s\": 13.099272727966309}", "{\"n\": 314, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1976.09, \"learn_time_ms\": 9729.528, \"total_train_time_s\": 14.098593473434448}", "{\"n\": 315, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1975.09, \"learn_time_ms\": 9742.607, \"total_train_time_s\": 13.712594509124756}", "{\"n\": 316, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1991.99, \"learn_time_ms\": 9652.182, \"total_train_time_s\": 13.006774663925171}", "{\"n\": 317, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1994.35, \"learn_time_ms\": 9662.879, \"total_train_time_s\": 13.64572548866272}", "{\"n\": 318, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2003.89, \"learn_time_ms\": 9737.447, \"total_train_time_s\": 14.847469568252563}", "{\"n\": 319, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2007.65, \"learn_time_ms\": 9781.016, \"total_train_time_s\": 13.717251062393188}", "{\"n\": 320, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2012.45, \"learn_time_ms\": 9895.507, \"total_train_time_s\": 13.806748151779175}", "{\"n\": 321, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2012.23, \"learn_time_ms\": 9878.253, \"total_train_time_s\": 12.869821310043335}", "{\"n\": 322, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2018.7, \"learn_time_ms\": 9966.774, \"total_train_time_s\": 13.493836402893066}", "{\"n\": 323, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2030.86, \"learn_time_ms\": 10032.167, \"total_train_time_s\": 13.620667457580566}", "{\"n\": 324, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2029.99, \"learn_time_ms\": 10025.016, \"total_train_time_s\": 14.003096103668213}", "{\"n\": 325, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2032.27, \"learn_time_ms\": 10034.004, \"total_train_time_s\": 13.903080463409424}", "{\"n\": 326, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2031.26, \"learn_time_ms\": 10174.153, \"total_train_time_s\": 14.408828020095825}", "{\"n\": 327, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2034.79, \"learn_time_ms\": 10221.819, \"total_train_time_s\": 14.125078678131104}", "{\"n\": 328, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2032.9, \"learn_time_ms\": 10227.108, \"total_train_time_s\": 14.917834997177124}", "{\"n\": 329, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2036.46, \"learn_time_ms\": 10199.724, \"total_train_time_s\": 13.424618244171143}", "{\"n\": 330, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2038.44, \"learn_time_ms\": 10186.439, \"total_train_time_s\": 13.791311502456665}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2035.38, \"learn_time_ms\": 10309.142, \"total_train_time_s\": 14.060623168945312}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2043.34, \"learn_time_ms\": 10276.45, \"total_train_time_s\": 13.214736461639404}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2048.49, \"learn_time_ms\": 10207.152, \"total_train_time_s\": 12.726403951644897}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2044.91, \"learn_time_ms\": 10135.076, \"total_train_time_s\": 13.456249475479126}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2049.37, \"learn_time_ms\": 10144.595, \"total_train_time_s\": 13.878867387771606}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.79, \"learn_time_ms\": 10051.072, \"total_train_time_s\": 13.392791032791138}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2053.32, \"learn_time_ms\": 10054.716, \"total_train_time_s\": 14.248838186264038}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.2, \"learn_time_ms\": 9874.493, \"total_train_time_s\": 13.016396760940552}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2045.64, \"learn_time_ms\": 9967.31, \"total_train_time_s\": 14.341939687728882}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2039.89, \"learn_time_ms\": 9917.522, \"total_train_time_s\": 13.162097215652466}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2040.01, \"learn_time_ms\": 9838.496, \"total_train_time_s\": 13.473793268203735}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2040.51, \"learn_time_ms\": 9810.521, \"total_train_time_s\": 13.174505233764648}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2047.37, \"learn_time_ms\": 9925.325, \"total_train_time_s\": 13.981799602508545}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2045.77, \"learn_time_ms\": 9881.649, \"total_train_time_s\": 12.985399007797241}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2050.23, \"learn_time_ms\": 9884.347, \"total_train_time_s\": 13.910863161087036}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2047.77, \"learn_time_ms\": 9908.571, \"total_train_time_s\": 13.587225198745728}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2050.12, \"learn_time_ms\": 9864.983, \"total_train_time_s\": 13.841432332992554}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2048.55, \"learn_time_ms\": 9825.135, \"total_train_time_s\": 12.655056953430176}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2047.71, \"learn_time_ms\": 9733.144, \"total_train_time_s\": 13.462507009506226}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2042.92, \"learn_time_ms\": 9735.345, \"total_train_time_s\": 13.245743751525879}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2041.51, \"learn_time_ms\": 9738.86, \"total_train_time_s\": 13.230704307556152}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2034.6, \"learn_time_ms\": 9808.024, \"total_train_time_s\": 13.547434329986572}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2036.53, \"learn_time_ms\": 9836.334, \"total_train_time_s\": 14.209067583084106}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2042.85, \"learn_time_ms\": 9902.594, \"total_train_time_s\": 13.459785223007202}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.73, \"learn_time_ms\": 9850.736, \"total_train_time_s\": 13.440865755081177}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.0, \"learn_time_ms\": 9874.581, \"total_train_time_s\": 13.845205307006836}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2050.16, \"learn_time_ms\": 9936.278, \"total_train_time_s\": 14.462178707122803}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2054.9, \"learn_time_ms\": 10019.668, \"total_train_time_s\": 13.506476163864136}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2057.23, \"learn_time_ms\": 9989.642, \"total_train_time_s\": 13.143288850784302}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2050.82, \"learn_time_ms\": 10063.203, \"total_train_time_s\": 14.005102396011353}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2053.72, \"learn_time_ms\": 10131.543, \"total_train_time_s\": 13.851736783981323}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.2, \"learn_time_ms\": 10179.892, \"total_train_time_s\": 14.069441556930542}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2046.34, \"learn_time_ms\": 10226.469, \"total_train_time_s\": 14.669090270996094}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2049.24, \"learn_time_ms\": 10235.524, \"total_train_time_s\": 13.71374773979187}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2047.98, \"learn_time_ms\": 10242.187, \"total_train_time_s\": 13.584723711013794}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2054.27, \"learn_time_ms\": 10224.65, \"total_train_time_s\": 13.82472848892212}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2051.28, \"learn_time_ms\": 10140.066, \"total_train_time_s\": 13.488554239273071}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2053.82, \"learn_time_ms\": 10200.166, \"total_train_time_s\": 14.121430158615112}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2057.52, \"learn_time_ms\": 10287.035, \"total_train_time_s\": 14.032865047454834}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2059.25, \"learn_time_ms\": 10218.228, \"total_train_time_s\": 13.649335384368896}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2061.4, \"learn_time_ms\": 10112.81, \"total_train_time_s\": 12.855196714401245}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2060.12, \"learn_time_ms\": 10052.504, \"total_train_time_s\": 13.8088538646698}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2060.16, \"learn_time_ms\": 9922.521, \"total_train_time_s\": 13.491245746612549}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2059.23, \"learn_time_ms\": 9885.839, \"total_train_time_s\": 13.25696063041687}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2066.0, \"learn_time_ms\": 9971.49, \"total_train_time_s\": 14.398582935333252}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2063.41, \"learn_time_ms\": 9862.877, \"total_train_time_s\": 12.598437547683716}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2067.94, \"learn_time_ms\": 9830.729, \"total_train_time_s\": 13.269386529922485}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2066.53, \"learn_time_ms\": 9788.349, \"total_train_time_s\": 13.640933752059937}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2075.63, \"learn_time_ms\": 9682.174, \"total_train_time_s\": 12.959257125854492}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2074.81, \"learn_time_ms\": 9851.696, \"total_train_time_s\": 15.181817770004272}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2077.53, \"learn_time_ms\": 9933.871, \"total_train_time_s\": 13.65404200553894}", "{\"n\": 382, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2076.49, \"learn_time_ms\": 9926.78, \"total_train_time_s\": 13.358896017074585}", "{\"n\": 383, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2069.63, \"learn_time_ms\": 9949.686, \"total_train_time_s\": 13.605334997177124}", "{\"n\": 384, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2072.55, \"learn_time_ms\": 10009.0, \"total_train_time_s\": 13.90563678741455}", "{\"n\": 385, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2069.4, \"learn_time_ms\": 9912.951, \"total_train_time_s\": 13.407670259475708}", "{\"n\": 386, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2063.23, \"learn_time_ms\": 10064.162, \"total_train_time_s\": 14.096870183944702}", "{\"n\": 387, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2068.69, \"learn_time_ms\": 10114.522, \"total_train_time_s\": 13.869705200195312}", "{\"n\": 388, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2069.95, \"learn_time_ms\": 10034.651, \"total_train_time_s\": 12.819251298904419}", "{\"n\": 389, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2081.3, \"learn_time_ms\": 10179.956, \"total_train_time_s\": 14.43183422088623}", "{\"n\": 390, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2082.67, \"learn_time_ms\": 10053.508, \"total_train_time_s\": 13.833902835845947}", "{\"n\": 391, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2084.9, \"learn_time_ms\": 10104.178, \"total_train_time_s\": 14.190948247909546}", "{\"n\": 392, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2083.6, \"learn_time_ms\": 10076.045, \"total_train_time_s\": 13.083189010620117}", "{\"n\": 393, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2088.33, \"learn_time_ms\": 10069.489, \"total_train_time_s\": 13.538745164871216}", "{\"n\": 394, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2090.11, \"learn_time_ms\": 10092.179, \"total_train_time_s\": 13.994334697723389}", "{\"n\": 395, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2091.72, \"learn_time_ms\": 10009.066, \"total_train_time_s\": 12.495483160018921}", "{\"n\": 396, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2095.09, \"learn_time_ms\": 10004.61, \"total_train_time_s\": 14.058623552322388}", "{\"n\": 397, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2094.08, \"learn_time_ms\": 9963.904, \"total_train_time_s\": 13.328611612319946}", "{\"n\": 398, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2089.81, \"learn_time_ms\": 10035.33, \"total_train_time_s\": 13.639259576797485}", "{\"n\": 399, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.52, \"learn_time_ms\": 10011.461, \"total_train_time_s\": 14.200002908706665}", "{\"n\": 400, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2098.46, \"learn_time_ms\": 10016.694, \"total_train_time_s\": 13.72631025314331}", "{\"n\": 401, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2096.62, \"learn_time_ms\": 9983.533, \"total_train_time_s\": 13.810863733291626}", "{\"n\": 402, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2100.0, \"learn_time_ms\": 10026.64, \"total_train_time_s\": 13.491498231887817}", "{\"n\": 403, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2104.68, \"learn_time_ms\": 9982.974, \"total_train_time_s\": 13.251712799072266}", "{\"n\": 404, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.07, \"learn_time_ms\": 9913.094, \"total_train_time_s\": 13.305670738220215}", "{\"n\": 405, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.3, \"learn_time_ms\": 9949.324, \"total_train_time_s\": 12.860106468200684}", "{\"n\": 406, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.64, \"learn_time_ms\": 9947.561, \"total_train_time_s\": 14.02486515045166}", "{\"n\": 407, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2108.59, \"learn_time_ms\": 9921.014, \"total_train_time_s\": 13.026796579360962}", "{\"n\": 408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2104.72, \"learn_time_ms\": 9909.542, \"total_train_time_s\": 13.643160343170166}", "{\"n\": 409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.36, \"learn_time_ms\": 9887.733, \"total_train_time_s\": 14.081610918045044}", "{\"n\": 410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.49, \"learn_time_ms\": 9874.017, \"total_train_time_s\": 13.643528699874878}", "{\"n\": 411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.61, \"learn_time_ms\": 9823.471, \"total_train_time_s\": 13.320370197296143}", "{\"n\": 412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.61, \"learn_time_ms\": 9899.249, \"total_train_time_s\": 14.476813554763794}", "{\"n\": 413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.67, \"learn_time_ms\": 10011.965, \"total_train_time_s\": 14.19544243812561}", "{\"n\": 414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2108.16, \"learn_time_ms\": 10063.257, \"total_train_time_s\": 13.898367881774902}", "{\"n\": 415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2111.21, \"learn_time_ms\": 10122.948, \"total_train_time_s\": 13.610601902008057}", "{\"n\": 416, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2122.57, \"learn_time_ms\": 9988.438, \"total_train_time_s\": 12.762368202209473}", "{\"n\": 417, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2122.57, \"learn_time_ms\": 9971.839, \"total_train_time_s\": 12.892570495605469}", "{\"n\": 418, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2135.28, \"learn_time_ms\": 10062.634, \"total_train_time_s\": 14.565675020217896}", "{\"n\": 419, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2132.71, \"learn_time_ms\": 10053.095, \"total_train_time_s\": 14.03945279121399}", "{\"n\": 420, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2135.18, \"learn_time_ms\": 10064.765, \"total_train_time_s\": 13.680389881134033}", "{\"n\": 421, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2140.69, \"learn_time_ms\": 10048.292, \"total_train_time_s\": 13.10175609588623}", "{\"n\": 422, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2139.96, \"learn_time_ms\": 9981.444, \"total_train_time_s\": 13.608381986618042}", "{\"n\": 423, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2144.44, \"learn_time_ms\": 9973.096, \"total_train_time_s\": 14.203223466873169}", "{\"n\": 424, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2142.91, \"learn_time_ms\": 9873.892, \"total_train_time_s\": 12.823761940002441}", "{\"n\": 425, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2148.53, \"learn_time_ms\": 9874.621, \"total_train_time_s\": 13.791922330856323}", "{\"n\": 426, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2152.22, \"learn_time_ms\": 9876.626, \"total_train_time_s\": 12.762474060058594}", "{\"n\": 427, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2162.68, \"learn_time_ms\": 9925.126, \"total_train_time_s\": 13.341234922409058}", "{\"n\": 428, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2167.89, \"learn_time_ms\": 9806.994, \"total_train_time_s\": 13.372455596923828}", "{\"n\": 429, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2167.23, \"learn_time_ms\": 9781.537, \"total_train_time_s\": 13.572266578674316}", "{\"n\": 430, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2167.12, \"learn_time_ms\": 9808.537, \"total_train_time_s\": 14.161518812179565}", "{\"n\": 431, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2172.49, \"learn_time_ms\": 9751.468, \"total_train_time_s\": 12.557661533355713}", "{\"n\": 432, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2177.26, \"learn_time_ms\": 9751.578, \"total_train_time_s\": 13.757343292236328}", "{\"n\": 433, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2185.36, \"learn_time_ms\": 9641.943, \"total_train_time_s\": 13.019663572311401}", "{\"n\": 434, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2187.41, \"learn_time_ms\": 9779.828, \"total_train_time_s\": 14.30957293510437}", "{\"n\": 435, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2187.65, \"learn_time_ms\": 9835.725, \"total_train_time_s\": 14.178234577178955}", "{\"n\": 436, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2179.13, \"learn_time_ms\": 9926.916, \"total_train_time_s\": 13.605683326721191}", "{\"n\": 437, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2198.35, \"learn_time_ms\": 10005.894, \"total_train_time_s\": 14.111544370651245}", "{\"n\": 438, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2203.42, \"learn_time_ms\": 9986.469, \"total_train_time_s\": 12.972529649734497}", "{\"n\": 439, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2208.99, \"learn_time_ms\": 10053.418, \"total_train_time_s\": 14.315472841262817}", "{\"n\": 440, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2209.57, \"learn_time_ms\": 10066.994, \"total_train_time_s\": 14.104260206222534}", "{\"n\": 441, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2205.43, \"learn_time_ms\": 10142.704, \"total_train_time_s\": 13.347437620162964}", "{\"n\": 442, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2204.31, \"learn_time_ms\": 10162.142, \"total_train_time_s\": 13.77668809890747}", "{\"n\": 443, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2204.31, \"learn_time_ms\": 10139.995, \"total_train_time_s\": 13.12280559539795}", "{\"n\": 444, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2209.79, \"learn_time_ms\": 10070.606, \"total_train_time_s\": 13.518098831176758}", "{\"n\": 445, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2208.63, \"learn_time_ms\": 10018.062, \"total_train_time_s\": 13.510039329528809}", "{\"n\": 446, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2215.18, \"learn_time_ms\": 10015.942, \"total_train_time_s\": 13.639105319976807}", "{\"n\": 447, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2226.37, \"learn_time_ms\": 9944.796, \"total_train_time_s\": 13.393813133239746}", "{\"n\": 448, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2227.26, \"learn_time_ms\": 9924.693, \"total_train_time_s\": 12.840709686279297}", "{\"n\": 449, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2223.77, \"learn_time_ms\": 9906.005, \"total_train_time_s\": 14.148258447647095}", "{\"n\": 450, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2223.77, \"learn_time_ms\": 9885.498, \"total_train_time_s\": 14.027150869369507}", "{\"n\": 451, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2223.99, \"learn_time_ms\": 9856.521, \"total_train_time_s\": 13.121739864349365}", "{\"n\": 452, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2223.99, \"learn_time_ms\": 9796.639, \"total_train_time_s\": 13.259442329406738}", "{\"n\": 453, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2236.13, \"learn_time_ms\": 9890.432, \"total_train_time_s\": 13.80125117301941}", "{\"n\": 454, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2233.18, \"learn_time_ms\": 9857.235, \"total_train_time_s\": 13.162223100662231}", "{\"n\": 455, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2234.34, \"learn_time_ms\": 9898.889, \"total_train_time_s\": 14.051552295684814}", "{\"n\": 456, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2238.04, \"learn_time_ms\": 9876.905, \"total_train_time_s\": 13.39582633972168}", "{\"n\": 457, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2241.39, \"learn_time_ms\": 9947.591, \"total_train_time_s\": 14.115639448165894}", "{\"n\": 458, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2244.32, \"learn_time_ms\": 9960.765, \"total_train_time_s\": 12.969011068344116}", "{\"n\": 459, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2244.32, \"learn_time_ms\": 9942.694, \"total_train_time_s\": 13.920212507247925}", "{\"n\": 460, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2243.88, \"learn_time_ms\": 9896.721, \"total_train_time_s\": 13.437994003295898}", "{\"n\": 461, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2243.88, \"learn_time_ms\": 9942.512, \"total_train_time_s\": 13.479972124099731}", "{\"n\": 462, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2254.47, \"learn_time_ms\": 9966.117, \"total_train_time_s\": 13.627878189086914}", "{\"n\": 463, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2254.27, \"learn_time_ms\": 9954.472, \"total_train_time_s\": 13.781487703323364}", "{\"n\": 464, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2250.43, \"learn_time_ms\": 10074.808, \"total_train_time_s\": 14.47746205329895}", "{\"n\": 465, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2259.35, \"learn_time_ms\": 10015.038, \"total_train_time_s\": 13.358522415161133}", "{\"n\": 466, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2253.7, \"learn_time_ms\": 9996.355, \"total_train_time_s\": 13.351173639297485}", "{\"n\": 467, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2265.85, \"learn_time_ms\": 9983.024, \"total_train_time_s\": 14.093220710754395}", "{\"n\": 468, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2266.16, \"learn_time_ms\": 10071.913, \"total_train_time_s\": 13.87518310546875}", "{\"n\": 469, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2263.59, \"learn_time_ms\": 9984.676, \"total_train_time_s\": 13.280729055404663}", "{\"n\": 470, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2266.77, \"learn_time_ms\": 9989.169, \"total_train_time_s\": 13.501692056655884}", "{\"n\": 471, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.45, \"learn_time_ms\": 10000.144, \"total_train_time_s\": 13.59542441368103}", "{\"n\": 472, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2276.84, \"learn_time_ms\": 10036.094, \"total_train_time_s\": 14.155452728271484}", "{\"n\": 473, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.61, \"learn_time_ms\": 10057.568, \"total_train_time_s\": 14.100199937820435}", "{\"n\": 474, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2268.37, \"learn_time_ms\": 9993.94, \"total_train_time_s\": 13.683501958847046}", "{\"n\": 475, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.94, \"learn_time_ms\": 10109.457, \"total_train_time_s\": 14.495519399642944}", "{\"n\": 476, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.11, \"learn_time_ms\": 10144.561, \"total_train_time_s\": 13.573524713516235}", "{\"n\": 477, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.48, \"learn_time_ms\": 10114.051, \"total_train_time_s\": 13.727081298828125}", "{\"n\": 478, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2266.03, \"learn_time_ms\": 10077.715, \"total_train_time_s\": 13.443673610687256}", "{\"n\": 479, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.11, \"learn_time_ms\": 10063.62, \"total_train_time_s\": 12.967203140258789}", "{\"n\": 480, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2268.94, \"learn_time_ms\": 10075.554, \"total_train_time_s\": 13.665205955505371}", "{\"n\": 481, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.09, \"learn_time_ms\": 10023.158, \"total_train_time_s\": 13.093569278717041}", "{\"n\": 482, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.09, \"learn_time_ms\": 10007.514, \"total_train_time_s\": 14.069304704666138}", "{\"n\": 483, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.5, \"learn_time_ms\": 10065.205, \"total_train_time_s\": 14.511392831802368}", "{\"n\": 484, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2267.85, \"learn_time_ms\": 10078.041, \"total_train_time_s\": 13.909594297409058}", "{\"n\": 485, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.53, \"learn_time_ms\": 9982.623, \"total_train_time_s\": 13.705716609954834}", "{\"n\": 486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2273.74, \"learn_time_ms\": 9893.883, \"total_train_time_s\": 12.671214580535889}", "{\"n\": 487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2273.74, \"learn_time_ms\": 9848.199, \"total_train_time_s\": 13.463624000549316}", "{\"n\": 488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.29, \"learn_time_ms\": 9920.697, \"total_train_time_s\": 14.14631724357605}", "{\"n\": 489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.29, \"learn_time_ms\": 9945.627, \"total_train_time_s\": 13.091579914093018}", "{\"n\": 490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2267.36, \"learn_time_ms\": 9966.704, \"total_train_time_s\": 13.92002272605896}", "{\"n\": 491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.14, \"learn_time_ms\": 9967.479, \"total_train_time_s\": 13.184027433395386}", "{\"n\": 492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2285.28, \"learn_time_ms\": 10027.45, \"total_train_time_s\": 14.205356359481812}", "{\"n\": 493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2288.12, \"learn_time_ms\": 9902.642, \"total_train_time_s\": 13.203556537628174}", "{\"n\": 494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2282.74, \"learn_time_ms\": 9790.949, \"total_train_time_s\": 13.022053718566895}", "{\"n\": 495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2287.26, \"learn_time_ms\": 9802.78, \"total_train_time_s\": 13.660419702529907}", "{\"n\": 496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2291.47, \"learn_time_ms\": 9885.964, \"total_train_time_s\": 13.530108451843262}", "{\"n\": 497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2291.59, \"learn_time_ms\": 9857.936, \"total_train_time_s\": 12.947262048721313}", "{\"n\": 498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2295.69, \"learn_time_ms\": 9747.288, \"total_train_time_s\": 13.172549962997437}", "{\"n\": 499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2303.28, \"learn_time_ms\": 9827.039, \"total_train_time_s\": 13.903045177459717}", "{\"n\": 500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.36, \"learn_time_ms\": 9773.364, \"total_train_time_s\": 13.261731386184692}", "{\"n\": 501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.36, \"learn_time_ms\": 9877.874, \"total_train_time_s\": 14.581713914871216}", "{\"n\": 502, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2318.43, \"learn_time_ms\": 9813.113, \"total_train_time_s\": 13.755675792694092}", "{\"n\": 503, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2320.15, \"learn_time_ms\": 9812.491, \"total_train_time_s\": 13.522321224212646}", "{\"n\": 504, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2322.74, \"learn_time_ms\": 9871.732, \"total_train_time_s\": 13.338367223739624}", "{\"n\": 505, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2324.55, \"learn_time_ms\": 9918.132, \"total_train_time_s\": 14.293122291564941}", "{\"n\": 506, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2317.24, \"learn_time_ms\": 9942.582, \"total_train_time_s\": 13.852365493774414}", "{\"n\": 507, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2325.7, \"learn_time_ms\": 9920.864, \"total_train_time_s\": 12.74053144454956}", "{\"n\": 508, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2325.7, \"learn_time_ms\": 10015.452, \"total_train_time_s\": 14.30988621711731}", "{\"n\": 509, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2327.63, \"learn_time_ms\": 9954.834, \"total_train_time_s\": 13.387963771820068}", "{\"n\": 510, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2327.63, \"learn_time_ms\": 9979.484, \"total_train_time_s\": 13.509900331497192}", "{\"n\": 511, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2330.42, \"learn_time_ms\": 9846.285, \"total_train_time_s\": 12.818718433380127}", "{\"n\": 512, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2333.94, \"learn_time_ms\": 9816.609, \"total_train_time_s\": 13.560227155685425}", "{\"n\": 513, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2333.94, \"learn_time_ms\": 9854.563, \"total_train_time_s\": 13.666569709777832}", "{\"n\": 514, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2341.88, \"learn_time_ms\": 9948.764, \"total_train_time_s\": 14.475439071655273}", "{\"n\": 515, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2341.88, \"learn_time_ms\": 9852.293, \"total_train_time_s\": 13.1640043258667}", "{\"n\": 516, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2357.01, \"learn_time_ms\": 9835.235, \"total_train_time_s\": 13.583319187164307}", "{\"n\": 517, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2362.15, \"learn_time_ms\": 9908.809, \"total_train_time_s\": 13.534089088439941}", "{\"n\": 518, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2362.15, \"learn_time_ms\": 9865.169, \"total_train_time_s\": 13.90550947189331}", "{\"n\": 519, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2365.53, \"learn_time_ms\": 9819.437, \"total_train_time_s\": 12.842793464660645}", "{\"n\": 520, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2365.53, \"learn_time_ms\": 9804.971, \"total_train_time_s\": 13.715019464492798}", "{\"n\": 521, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.22, \"learn_time_ms\": 9923.479, \"total_train_time_s\": 14.140503168106079}", "{\"n\": 522, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.22, \"learn_time_ms\": 9927.45, \"total_train_time_s\": 13.508010864257812}", "{\"n\": 523, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.28, \"learn_time_ms\": 9978.832, \"total_train_time_s\": 14.13313889503479}", "{\"n\": 524, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2361.55, \"learn_time_ms\": 9873.09, \"total_train_time_s\": 13.237125635147095}", "{\"n\": 525, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2367.71, \"learn_time_ms\": 9980.95, \"total_train_time_s\": 14.308736801147461}", "{\"n\": 526, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2374.14, \"learn_time_ms\": 10011.079, \"total_train_time_s\": 13.876849174499512}", "{\"n\": 527, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2374.14, \"learn_time_ms\": 10064.383, \"total_train_time_s\": 14.196808576583862}", "{\"n\": 528, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2373.79, \"learn_time_ms\": 10041.294, \"total_train_time_s\": 13.448431491851807}", "{\"n\": 529, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2377.48, \"learn_time_ms\": 10157.66, \"total_train_time_s\": 14.045040369033813}", "{\"n\": 530, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2373.67, \"learn_time_ms\": 10232.888, \"total_train_time_s\": 14.239870548248291}", "{\"n\": 531, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2372.78, \"learn_time_ms\": 10139.077, \"total_train_time_s\": 13.04579758644104}", "{\"n\": 532, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2374.91, \"learn_time_ms\": 10248.941, \"total_train_time_s\": 14.43131971359253}", "{\"n\": 533, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2374.7, \"learn_time_ms\": 10207.162, \"total_train_time_s\": 13.641237020492554}", "{\"n\": 534, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2362.81, \"learn_time_ms\": 10183.308, \"total_train_time_s\": 13.007301092147827}", "{\"n\": 535, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2358.38, \"learn_time_ms\": 10169.721, \"total_train_time_s\": 14.201155662536621}", "{\"n\": 536, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2370.65, \"learn_time_ms\": 10114.88, \"total_train_time_s\": 13.421594142913818}", "{\"n\": 537, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2371.34, \"learn_time_ms\": 10031.507, \"total_train_time_s\": 13.12339186668396}", "{\"n\": 538, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2378.05, \"learn_time_ms\": 10020.029, \"total_train_time_s\": 13.464709043502808}", "{\"n\": 539, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2381.18, \"learn_time_ms\": 9942.591, \"total_train_time_s\": 13.363231658935547}", "{\"n\": 540, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2375.15, \"learn_time_ms\": 9789.602, \"total_train_time_s\": 12.711149215698242}", "{\"n\": 541, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2370.49, \"learn_time_ms\": 9793.153, \"total_train_time_s\": 13.08190369606018}", "{\"n\": 542, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2370.49, \"learn_time_ms\": 9753.281, \"total_train_time_s\": 14.143108129501343}", "{\"n\": 543, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.74, \"learn_time_ms\": 9741.653, \"total_train_time_s\": 13.554521560668945}", "{\"n\": 544, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.74, \"learn_time_ms\": 9910.438, \"total_train_time_s\": 14.674773216247559}", "{\"n\": 545, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2390.93, \"learn_time_ms\": 9879.404, \"total_train_time_s\": 13.75157356262207}", "{\"n\": 546, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.06, \"learn_time_ms\": 9852.718, \"total_train_time_s\": 13.080244779586792}", "{\"n\": 547, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.06, \"learn_time_ms\": 9868.863, \"total_train_time_s\": 13.3100106716156}", "{\"n\": 548, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.54, \"learn_time_ms\": 9859.296, \"total_train_time_s\": 13.147488117218018}", "{\"n\": 549, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.15, \"learn_time_ms\": 9865.213, \"total_train_time_s\": 13.259681940078735}", "{\"n\": 550, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.86, \"learn_time_ms\": 9900.917, \"total_train_time_s\": 13.035691261291504}", "{\"n\": 551, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.11, \"learn_time_ms\": 9987.829, \"total_train_time_s\": 14.083884954452515}", "{\"n\": 552, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.11, \"learn_time_ms\": 9984.293, \"total_train_time_s\": 13.99801516532898}", "{\"n\": 553, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2401.45, \"learn_time_ms\": 9985.185, \"total_train_time_s\": 13.51768445968628}", "{\"n\": 554, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.45, \"learn_time_ms\": 9869.206, \"total_train_time_s\": 13.538382768630981}", "{\"n\": 555, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.1, \"learn_time_ms\": 9800.467, \"total_train_time_s\": 13.28715205192566}", "{\"n\": 556, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.84, \"learn_time_ms\": 9757.645, \"total_train_time_s\": 12.664264917373657}", "{\"n\": 557, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2428.81, \"learn_time_ms\": 9762.619, \"total_train_time_s\": 13.42498517036438}", "{\"n\": 558, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.23, \"learn_time_ms\": 9824.164, \"total_train_time_s\": 13.730163812637329}", "{\"n\": 559, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.23, \"learn_time_ms\": 9832.117, \"total_train_time_s\": 13.544909000396729}", "{\"n\": 560, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2435.05, \"learn_time_ms\": 9941.03, \"total_train_time_s\": 14.087765216827393}", "{\"n\": 561, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2435.05, \"learn_time_ms\": 9947.152, \"total_train_time_s\": 14.025947332382202}", "{\"n\": 562, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2438.9, \"learn_time_ms\": 9799.66, \"total_train_time_s\": 12.919157028198242}", "{\"n\": 563, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2446.42, \"learn_time_ms\": 9825.493, \"total_train_time_s\": 13.8735511302948}", "{\"n\": 564, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2442.64, \"learn_time_ms\": 9819.818, \"total_train_time_s\": 13.668961524963379}", "{\"n\": 565, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2452.69, \"learn_time_ms\": 9798.625, \"total_train_time_s\": 12.921608448028564}", "{\"n\": 566, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2452.69, \"learn_time_ms\": 9898.158, \"total_train_time_s\": 13.602378606796265}", "{\"n\": 567, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2459.26, \"learn_time_ms\": 9778.448, \"total_train_time_s\": 12.335763692855835}", "{\"n\": 568, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2458.68, \"learn_time_ms\": 9714.512, \"total_train_time_s\": 13.128971099853516}", "{\"n\": 569, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2465.2, \"learn_time_ms\": 9830.828, \"total_train_time_s\": 14.733169317245483}", "{\"n\": 570, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2465.2, \"learn_time_ms\": 9794.568, \"total_train_time_s\": 13.729727506637573}", "{\"n\": 571, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2469.97, \"learn_time_ms\": 9798.691, \"total_train_time_s\": 14.185017108917236}", "{\"n\": 572, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2459.84, \"learn_time_ms\": 9979.474, \"total_train_time_s\": 14.317564249038696}", "{\"n\": 573, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2464.91, \"learn_time_ms\": 9915.693, \"total_train_time_s\": 13.153985023498535}", "{\"n\": 574, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2472.25, \"learn_time_ms\": 9877.65, \"total_train_time_s\": 13.10350751876831}", "{\"n\": 575, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2482.92, \"learn_time_ms\": 9946.876, \"total_train_time_s\": 13.710837125778198}", "{\"n\": 576, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2481.4, \"learn_time_ms\": 9915.169, \"total_train_time_s\": 13.325177431106567}", "{\"n\": 577, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2463.52, \"learn_time_ms\": 10006.458, \"total_train_time_s\": 13.089646577835083}", "{\"n\": 578, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2463.52, \"learn_time_ms\": 10019.559, \"total_train_time_s\": 13.22550892829895}", "{\"n\": 579, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2472.05, \"learn_time_ms\": 9830.462, \"total_train_time_s\": 12.628206968307495}", "{\"n\": 580, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2472.05, \"learn_time_ms\": 9803.038, \"total_train_time_s\": 13.403756856918335}", "{\"n\": 581, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.56, \"learn_time_ms\": 9709.672, \"total_train_time_s\": 13.130144357681274}", "{\"n\": 582, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.56, \"learn_time_ms\": 9699.391, \"total_train_time_s\": 14.180845975875854}", "{\"n\": 583, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.88, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2476.8, \"learn_time_ms\": 9780.219, \"total_train_time_s\": 14.10787034034729}", "{\"n\": 584, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2502.34, \"learn_time_ms\": 9791.362, \"total_train_time_s\": 13.233535528182983}", "{\"n\": 585, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2502.34, \"learn_time_ms\": 9710.797, \"total_train_time_s\": 13.040397882461548}", "{\"n\": 586, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2513.61, \"learn_time_ms\": 9806.338, \"total_train_time_s\": 14.286302089691162}", "{\"n\": 587, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2525.12, \"learn_time_ms\": 9875.651, \"total_train_time_s\": 13.744384288787842}", "{\"n\": 588, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2522.36, \"learn_time_ms\": 9809.51, \"total_train_time_s\": 12.66499400138855}", "{\"n\": 589, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2519.01, \"learn_time_ms\": 9886.68, \"total_train_time_s\": 13.452540636062622}", "{\"n\": 590, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2519.01, \"learn_time_ms\": 9965.707, \"total_train_time_s\": 14.264837265014648}", "{\"n\": 591, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2519.01, \"learn_time_ms\": 9964.846, \"total_train_time_s\": 13.101096391677856}", "{\"n\": 592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2530.51, \"learn_time_ms\": 9861.869, \"total_train_time_s\": 13.463350772857666}", "{\"n\": 593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2527.67, \"learn_time_ms\": 9804.619, \"total_train_time_s\": 13.383602857589722}", "{\"n\": 594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2564.0, \"learn_time_ms\": 9836.443, \"total_train_time_s\": 13.494788646697998}", "{\"n\": 595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2564.0, \"learn_time_ms\": 9882.648, \"total_train_time_s\": 13.216444969177246}", "{\"n\": 596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2576.8, \"learn_time_ms\": 9826.0, \"total_train_time_s\": 13.79406452178955}", "{\"n\": 597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2575.58, \"learn_time_ms\": 9771.973, \"total_train_time_s\": 13.295649290084839}", "{\"n\": 598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2572.0, \"learn_time_ms\": 9873.107, \"total_train_time_s\": 13.895682334899902}", "{\"n\": 599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2582.39, \"learn_time_ms\": 9839.184, \"total_train_time_s\": 13.203040838241577}", "{\"n\": 600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2600.03, \"learn_time_ms\": 9765.994, \"total_train_time_s\": 13.45762014389038}", "{\"n\": 601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2591.49, \"learn_time_ms\": 9731.303, \"total_train_time_s\": 12.782243728637695}", "{\"n\": 602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2594.05, \"learn_time_ms\": 9901.204, \"total_train_time_s\": 14.888100624084473}", "{\"n\": 603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2594.05, \"learn_time_ms\": 9873.607, \"total_train_time_s\": 13.155620098114014}", "{\"n\": 604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2600.26, \"learn_time_ms\": 9863.993, \"total_train_time_s\": 13.512372732162476}", "{\"n\": 605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2609.24, \"learn_time_ms\": 9996.108, \"total_train_time_s\": 14.562685012817383}", "{\"n\": 606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2612.91, \"learn_time_ms\": 9989.597, \"total_train_time_s\": 13.615516662597656}", "{\"n\": 607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2606.33, \"learn_time_ms\": 9995.591, \"total_train_time_s\": 13.313023805618286}", "{\"n\": 608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2606.33, \"learn_time_ms\": 10064.573, \"total_train_time_s\": 14.72833800315857}", "{\"n\": 609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2601.27, \"learn_time_ms\": 10078.54, \"total_train_time_s\": 13.216885328292847}", "{\"n\": 610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2603.17, \"learn_time_ms\": 10170.47, \"total_train_time_s\": 14.773729801177979}", "{\"n\": 611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2608.66, \"learn_time_ms\": 10252.694, \"total_train_time_s\": 13.62253189086914}", "{\"n\": 612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2613.75, \"learn_time_ms\": 10146.097, \"total_train_time_s\": 13.802868366241455}", "{\"n\": 613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2614.94, \"learn_time_ms\": 10135.163, \"total_train_time_s\": 12.986053228378296}", "{\"n\": 614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2617.69, \"learn_time_ms\": 10220.711, \"total_train_time_s\": 14.262251377105713}", "{\"n\": 615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2626.92, \"learn_time_ms\": 10163.035, \"total_train_time_s\": 14.116025447845459}", "{\"n\": 616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2625.09, \"learn_time_ms\": 10171.567, \"total_train_time_s\": 13.76994776725769}", "{\"n\": 617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2625.38, \"learn_time_ms\": 10173.805, \"total_train_time_s\": 13.325607538223267}", "{\"n\": 618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2626.06, \"learn_time_ms\": 10107.221, \"total_train_time_s\": 13.995688915252686}", "{\"n\": 619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2627.12, \"learn_time_ms\": 10153.209, \"total_train_time_s\": 13.848560571670532}", "{\"n\": 620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2626.14, \"learn_time_ms\": 10121.672, \"total_train_time_s\": 14.061501741409302}", "{\"n\": 621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2624.24, \"learn_time_ms\": 10079.317, \"total_train_time_s\": 13.162201404571533}", "{\"n\": 622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2616.61, \"learn_time_ms\": 10015.904, \"total_train_time_s\": 13.292734622955322}", "{\"n\": 623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2614.7, \"learn_time_ms\": 10138.693, \"total_train_time_s\": 14.263750553131104}", "{\"n\": 624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2628.38, \"learn_time_ms\": 9969.764, \"total_train_time_s\": 12.536494255065918}", "{\"n\": 625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2634.71, \"learn_time_ms\": 9890.099, \"total_train_time_s\": 13.240872383117676}", "{\"n\": 626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2633.33, \"learn_time_ms\": 9872.439, \"total_train_time_s\": 13.515860080718994}", "{\"n\": 627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2628.7, \"learn_time_ms\": 9827.008, \"total_train_time_s\": 12.986315250396729}", "{\"n\": 628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2625.77, \"learn_time_ms\": 9728.424, \"total_train_time_s\": 12.930541038513184}", "{\"n\": 629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2618.99, \"learn_time_ms\": 9650.748, \"total_train_time_s\": 13.067526578903198}", "{\"n\": 630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2627.77, \"learn_time_ms\": 9501.507, \"total_train_time_s\": 12.601857423782349}", "{\"n\": 631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2627.77, \"learn_time_ms\": 9629.895, \"total_train_time_s\": 14.575566291809082}", "{\"n\": 632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2635.49, \"learn_time_ms\": 9723.902, \"total_train_time_s\": 14.454453706741333}", "{\"n\": 633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2639.31, \"learn_time_ms\": 9650.503, \"total_train_time_s\": 13.588258266448975}", "{\"n\": 634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2635.75, \"learn_time_ms\": 9654.616, \"total_train_time_s\": 12.594195127487183}", "{\"n\": 635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2649.52, \"learn_time_ms\": 9695.679, \"total_train_time_s\": 13.831478834152222}", "{\"n\": 636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2642.15, \"learn_time_ms\": 9725.293, \"total_train_time_s\": 13.856359004974365}", "{\"n\": 637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2638.5, \"learn_time_ms\": 9789.266, \"total_train_time_s\": 13.621244192123413}", "{\"n\": 638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2650.45, \"learn_time_ms\": 9831.076, \"total_train_time_s\": 13.046833753585815}", "{\"n\": 639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2659.53, \"learn_time_ms\": 9934.399, \"total_train_time_s\": 13.9381742477417}", "{\"n\": 640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2662.93, \"learn_time_ms\": 10074.497, \"total_train_time_s\": 13.931880474090576}", "{\"n\": 641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2659.25, \"learn_time_ms\": 9976.239, \"total_train_time_s\": 13.519135236740112}", "{\"n\": 642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2659.86, \"learn_time_ms\": 9873.276, \"total_train_time_s\": 13.077691555023193}", "{\"n\": 643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2668.78, \"learn_time_ms\": 9881.993, \"total_train_time_s\": 13.719539642333984}", "{\"n\": 644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2673.27, \"learn_time_ms\": 9896.482, \"total_train_time_s\": 12.715863466262817}", "{\"n\": 645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2665.4, \"learn_time_ms\": 9937.613, \"total_train_time_s\": 13.985160112380981}", "{\"n\": 646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2648.35, \"learn_time_ms\": 9941.242, \"total_train_time_s\": 13.857172012329102}", "{\"n\": 647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2654.06, \"learn_time_ms\": 9978.592, \"total_train_time_s\": 13.915234804153442}", "{\"n\": 648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2656.11, \"learn_time_ms\": 9976.336, \"total_train_time_s\": 12.988508224487305}", "{\"n\": 649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2665.18, \"learn_time_ms\": 9930.4, \"total_train_time_s\": 13.600087642669678}", "{\"n\": 650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2646.17, \"learn_time_ms\": 9875.493, \"total_train_time_s\": 13.590652465820312}", "{\"n\": 651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2645.67, \"learn_time_ms\": 9802.836, \"total_train_time_s\": 12.849984407424927}", "{\"n\": 652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2642.94, \"learn_time_ms\": 9879.007, \"total_train_time_s\": 13.860342979431152}", "{\"n\": 653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2648.39, \"learn_time_ms\": 9906.397, \"total_train_time_s\": 14.000137090682983}", "{\"n\": 654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2649.16, \"learn_time_ms\": 9944.47, \"total_train_time_s\": 13.17978811264038}", "{\"n\": 655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2664.86, \"learn_time_ms\": 9896.227, \"total_train_time_s\": 13.539533138275146}", "{\"n\": 656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2666.15, \"learn_time_ms\": 9817.094, \"total_train_time_s\": 13.221531391143799}", "{\"n\": 657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2669.69, \"learn_time_ms\": 9674.364, \"total_train_time_s\": 12.571274995803833}", "{\"n\": 658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2676.27, \"learn_time_ms\": 9683.07, \"total_train_time_s\": 13.127187728881836}", "{\"n\": 659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2668.64, \"learn_time_ms\": 9710.96, \"total_train_time_s\": 13.758848667144775}", "{\"n\": 660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2658.28, \"learn_time_ms\": 9622.058, \"total_train_time_s\": 12.7355318069458}", "{\"n\": 661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2657.15, \"learn_time_ms\": 9693.062, \"total_train_time_s\": 13.53128170967102}", "{\"n\": 662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2639.65, \"learn_time_ms\": 9605.074, \"total_train_time_s\": 13.062162399291992}", "{\"n\": 663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2646.03, \"learn_time_ms\": 9538.773, \"total_train_time_s\": 13.229261875152588}", "{\"n\": 664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2648.36, \"learn_time_ms\": 9641.585, \"total_train_time_s\": 14.420876264572144}", "{\"n\": 665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2648.36, \"learn_time_ms\": 9609.167, \"total_train_time_s\": 13.407378435134888}", "{\"n\": 666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2648.37, \"learn_time_ms\": 9574.945, \"total_train_time_s\": 12.932995080947876}", "{\"n\": 667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2648.98, \"learn_time_ms\": 9705.741, \"total_train_time_s\": 13.755636215209961}", "{\"n\": 668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2659.85, \"learn_time_ms\": 9761.798, \"total_train_time_s\": 13.869332313537598}", "{\"n\": 669, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2660.45, \"learn_time_ms\": 9836.69, \"total_train_time_s\": 14.481336116790771}", "{\"n\": 670, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2683.14, \"learn_time_ms\": 9962.216, \"total_train_time_s\": 13.788792133331299}", "{\"n\": 671, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2679.59, \"learn_time_ms\": 9962.501, \"total_train_time_s\": 13.66476321220398}", "{\"n\": 672, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2679.59, \"learn_time_ms\": 9959.21, \"total_train_time_s\": 12.986913919448853}", "{\"n\": 673, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.24, \"learn_time_ms\": 9928.987, \"total_train_time_s\": 12.925387620925903}", "{\"n\": 674, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.87, \"learn_time_ms\": 9940.908, \"total_train_time_s\": 14.26632046699524}", "{\"n\": 675, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2692.36, \"learn_time_ms\": 9992.446, \"total_train_time_s\": 14.036749601364136}", "{\"n\": 676, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2701.27, \"learn_time_ms\": 10041.321, \"total_train_time_s\": 13.267155170440674}", "{\"n\": 677, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2697.26, \"learn_time_ms\": 10079.993, \"total_train_time_s\": 14.41021728515625}", "{\"n\": 678, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2701.55, \"learn_time_ms\": 9954.885, \"total_train_time_s\": 12.583232164382935}", "{\"n\": 679, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2705.45, \"learn_time_ms\": 9853.925, \"total_train_time_s\": 13.490549087524414}", "{\"n\": 680, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2705.45, \"learn_time_ms\": 9774.921, \"total_train_time_s\": 13.109955549240112}", "{\"n\": 681, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2706.93, \"learn_time_ms\": 9783.058, \"total_train_time_s\": 13.631986379623413}", "{\"n\": 682, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2702.83, \"learn_time_ms\": 9803.73, \"total_train_time_s\": 13.137649297714233}", "{\"n\": 683, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2702.83, \"learn_time_ms\": 9928.767, \"total_train_time_s\": 14.509751796722412}", "{\"n\": 684, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2702.69, \"learn_time_ms\": 9859.836, \"total_train_time_s\": 13.585799217224121}", "{\"n\": 685, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2707.57, \"learn_time_ms\": 9814.03, \"total_train_time_s\": 13.315660238265991}", "{\"n\": 686, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2709.38, \"learn_time_ms\": 9826.853, \"total_train_time_s\": 13.401989459991455}", "{\"n\": 687, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2722.76, \"learn_time_ms\": 9705.939, \"total_train_time_s\": 13.198314905166626}", "{\"n\": 688, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2722.76, \"learn_time_ms\": 9789.996, \"total_train_time_s\": 13.356924295425415}", "{\"n\": 689, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2722.28, \"learn_time_ms\": 9818.788, \"total_train_time_s\": 13.812216997146606}", "{\"n\": 690, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2721.78, \"learn_time_ms\": 9986.717, \"total_train_time_s\": 14.662382364273071}", "{\"n\": 691, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2727.44, \"learn_time_ms\": 9922.984, \"total_train_time_s\": 12.875235795974731}", "{\"n\": 692, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2726.55, \"learn_time_ms\": 9987.2, \"total_train_time_s\": 13.81829309463501}", "{\"n\": 693, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2716.97, \"learn_time_ms\": 9843.217, \"total_train_time_s\": 12.772128582000732}", "{\"n\": 694, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2716.97, \"learn_time_ms\": 9786.928, \"total_train_time_s\": 13.02908968925476}", "{\"n\": 695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2723.96, \"learn_time_ms\": 9795.798, \"total_train_time_s\": 13.380740880966187}", "{\"n\": 696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2719.78, \"learn_time_ms\": 9742.003, \"total_train_time_s\": 13.009641885757446}", "{\"n\": 697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2719.78, \"learn_time_ms\": 9849.372, \"total_train_time_s\": 14.016655921936035}", "{\"n\": 698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2718.11, \"learn_time_ms\": 9990.285, \"total_train_time_s\": 14.773934364318848}", "{\"n\": 699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2723.44, \"learn_time_ms\": 9921.911, \"total_train_time_s\": 13.465952157974243}", "{\"n\": 700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2723.44, \"learn_time_ms\": 9851.387, \"total_train_time_s\": 13.963889360427856}", "{\"n\": 701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2729.16, \"learn_time_ms\": 10039.384, \"total_train_time_s\": 14.753469705581665}", "{\"n\": 702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2740.76, \"learn_time_ms\": 9969.47, \"total_train_time_s\": 13.364214897155762}", "{\"n\": 703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2739.12, \"learn_time_ms\": 10077.381, \"total_train_time_s\": 13.906174182891846}", "{\"n\": 704, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2745.49, \"learn_time_ms\": 10105.022, \"total_train_time_s\": 13.292096853256226}", "{\"n\": 705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2741.59, \"learn_time_ms\": 10150.407, \"total_train_time_s\": 14.124755144119263}", "{\"n\": 706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2742.77, \"learn_time_ms\": 10235.749, \"total_train_time_s\": 13.845619678497314}", "{\"n\": 707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2746.15, \"learn_time_ms\": 10110.121, \"total_train_time_s\": 12.948050260543823}", "{\"n\": 708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2729.53, \"learn_time_ms\": 9948.303, \"total_train_time_s\": 13.339025735855103}", "{\"n\": 709, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2729.53, \"learn_time_ms\": 10030.766, \"total_train_time_s\": 14.043842554092407}", "{\"n\": 710, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2719.26, \"learn_time_ms\": 9989.129, \"total_train_time_s\": 13.602853775024414}", "{\"n\": 711, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2724.75, \"learn_time_ms\": 9830.945, \"total_train_time_s\": 13.216516971588135}", "{\"n\": 712, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2727.32, \"learn_time_ms\": 9849.125, \"total_train_time_s\": 13.386130332946777}", "{\"n\": 713, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2728.59, \"learn_time_ms\": 9809.184, \"total_train_time_s\": 13.570353507995605}", "{\"n\": 714, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.71, \"learn_time_ms\": 9801.921, \"total_train_time_s\": 13.272555589675903}", "{\"n\": 715, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.71, \"learn_time_ms\": 9739.888, \"total_train_time_s\": 13.242029190063477}", "{\"n\": 716, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.54, \"learn_time_ms\": 9724.298, \"total_train_time_s\": 13.515345096588135}", "{\"n\": 717, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.54, \"learn_time_ms\": 9830.187, \"total_train_time_s\": 14.026450157165527}", "{\"n\": 718, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.07, \"learn_time_ms\": 9859.003, \"total_train_time_s\": 13.299759864807129}", "{\"n\": 719, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2760.17, \"learn_time_ms\": 9778.41, \"total_train_time_s\": 13.142752647399902}", "{\"n\": 720, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2760.17, \"learn_time_ms\": 9805.601, \"total_train_time_s\": 14.056715250015259}", "{\"n\": 721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2763.94, \"learn_time_ms\": 9887.927, \"total_train_time_s\": 14.00418210029602}", "{\"n\": 722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2764.36, \"learn_time_ms\": 10011.615, \"total_train_time_s\": 14.627063751220703}", "{\"n\": 723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2764.36, \"learn_time_ms\": 10055.222, \"total_train_time_s\": 13.992368459701538}", "{\"n\": 724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2756.13, \"learn_time_ms\": 10134.012, \"total_train_time_s\": 14.079457998275757}", "{\"n\": 725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2757.86, \"learn_time_ms\": 10279.692, \"total_train_time_s\": 14.758110761642456}", "{\"n\": 726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2757.86, \"learn_time_ms\": 10250.622, \"total_train_time_s\": 13.276590824127197}", "{\"n\": 727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.19, \"learn_time_ms\": 10324.621, \"total_train_time_s\": 14.68963098526001}", "{\"n\": 728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2757.77, \"learn_time_ms\": 10321.169, \"total_train_time_s\": 13.531681537628174}", "{\"n\": 729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2760.03, \"learn_time_ms\": 10397.479, \"total_train_time_s\": 13.84255599975586}", "{\"n\": 730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2776.08, \"learn_time_ms\": 10355.701, \"total_train_time_s\": 13.386361598968506}", "{\"n\": 731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2780.71, \"learn_time_ms\": 10275.217, \"total_train_time_s\": 13.193280935287476}", "{\"n\": 732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2775.67, \"learn_time_ms\": 10198.957, \"total_train_time_s\": 13.992820739746094}", "{\"n\": 733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2770.14, \"learn_time_ms\": 10254.184, \"total_train_time_s\": 14.374272346496582}", "{\"n\": 734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2765.47, \"learn_time_ms\": 10316.691, \"total_train_time_s\": 14.725754737854004}", "{\"n\": 735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2761.14, \"learn_time_ms\": 10283.655, \"total_train_time_s\": 14.445056200027466}", "{\"n\": 736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.25, \"learn_time_ms\": 10308.152, \"total_train_time_s\": 13.535403728485107}", "{\"n\": 737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2738.55, \"learn_time_ms\": 10192.5, \"total_train_time_s\": 13.4028160572052}", "{\"n\": 738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2726.05, \"learn_time_ms\": 10176.732, \"total_train_time_s\": 13.268981456756592}", "{\"n\": 739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2719.08, \"learn_time_ms\": 10119.87, \"total_train_time_s\": 13.35713815689087}", "{\"n\": 740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2731.31, \"learn_time_ms\": 10222.988, \"total_train_time_s\": 14.461002826690674}", "{\"n\": 741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2748.84, \"learn_time_ms\": 10436.23, \"total_train_time_s\": 15.51693344116211}", "{\"n\": 742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.77, \"learn_time_ms\": 10359.828, \"total_train_time_s\": 13.095263481140137}", "{\"n\": 743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2752.31, \"learn_time_ms\": 10229.434, \"total_train_time_s\": 13.128111600875854}", "{\"n\": 744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.37, \"learn_time_ms\": 10070.125, \"total_train_time_s\": 13.198383569717407}", "{\"n\": 745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2754.99, \"learn_time_ms\": 10028.474, \"total_train_time_s\": 13.92007040977478}", "{\"n\": 746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2754.99, \"learn_time_ms\": 9931.768, \"total_train_time_s\": 12.705870389938354}", "{\"n\": 747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.16, \"learn_time_ms\": 10063.559, \"total_train_time_s\": 14.738770723342896}", "{\"n\": 748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2753.88, \"learn_time_ms\": 10051.265, \"total_train_time_s\": 13.18445897102356}", "{\"n\": 749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2753.88, \"learn_time_ms\": 10026.72, \"total_train_time_s\": 13.048811674118042}", "{\"n\": 750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.5, \"learn_time_ms\": 9916.78, \"total_train_time_s\": 13.314088106155396}", "{\"n\": 751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2756.19, \"learn_time_ms\": 9796.007, \"total_train_time_s\": 14.159120321273804}", "{\"n\": 752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2756.19, \"learn_time_ms\": 9816.463, \"total_train_time_s\": 13.342498540878296}", "{\"n\": 753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2756.62, \"learn_time_ms\": 9797.985, \"total_train_time_s\": 12.911770105361938}", "{\"n\": 754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.6, \"learn_time_ms\": 9867.48, \"total_train_time_s\": 13.730435132980347}", "{\"n\": 755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2752.79, \"learn_time_ms\": 9828.377, \"total_train_time_s\": 13.490973949432373}", "{\"n\": 756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2756.84, \"learn_time_ms\": 9912.539, \"total_train_time_s\": 13.437187433242798}", "{\"n\": 757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2770.87, \"learn_time_ms\": 9809.835, \"total_train_time_s\": 13.75370478630066}", "{\"n\": 758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2770.87, \"learn_time_ms\": 9808.666, \"total_train_time_s\": 12.99383544921875}", "{\"n\": 759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2774.94, \"learn_time_ms\": 9788.023, \"total_train_time_s\": 12.856422424316406}", "{\"n\": 760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2774.94, \"learn_time_ms\": 9826.668, \"total_train_time_s\": 13.731981754302979}", "{\"n\": 761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2774.94, \"learn_time_ms\": 9727.4, \"total_train_time_s\": 13.174570798873901}", "{\"n\": 762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2779.45, \"learn_time_ms\": 9724.759, \"total_train_time_s\": 13.17776346206665}", "{\"n\": 763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2785.27, \"learn_time_ms\": 9800.044, \"total_train_time_s\": 13.683791399002075}", "{\"n\": 764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2784.37, \"learn_time_ms\": 9765.968, \"total_train_time_s\": 13.396955728530884}", "{\"n\": 765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.41, \"learn_time_ms\": 9746.554, \"total_train_time_s\": 13.559660196304321}", "{\"n\": 766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2807.6, \"learn_time_ms\": 9723.786, \"total_train_time_s\": 13.109874963760376}", "{\"n\": 767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2803.61, \"learn_time_ms\": 9711.462, \"total_train_time_s\": 13.693537950515747}", "{\"n\": 768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2804.27, \"learn_time_ms\": 9733.238, \"total_train_time_s\": 13.225472211837769}", "{\"n\": 769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2804.27, \"learn_time_ms\": 9797.341, \"total_train_time_s\": 13.497199058532715}", "{\"n\": 770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2801.09, \"learn_time_ms\": 9754.235, \"total_train_time_s\": 13.733983516693115}", "{\"n\": 771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.68, \"learn_time_ms\": 9712.291, \"total_train_time_s\": 12.740079879760742}", "{\"n\": 772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2795.2, \"learn_time_ms\": 9723.608, \"total_train_time_s\": 13.279662609100342}", "{\"n\": 773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2798.49, \"learn_time_ms\": 9715.857, \"total_train_time_s\": 13.972215175628662}", "{\"n\": 774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2810.66, \"learn_time_ms\": 9786.613, \"total_train_time_s\": 14.253659963607788}", "{\"n\": 775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2810.66, \"learn_time_ms\": 9932.081, \"total_train_time_s\": 14.748364448547363}", "{\"n\": 776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2807.11, \"learn_time_ms\": 9975.463, \"total_train_time_s\": 13.778074026107788}", "{\"n\": 777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2806.1, \"learn_time_ms\": 9944.328, \"total_train_time_s\": 13.443359851837158}", "{\"n\": 778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2806.1, \"learn_time_ms\": 10068.851, \"total_train_time_s\": 14.426753044128418}", "{\"n\": 779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2816.73, \"learn_time_ms\": 10096.75, \"total_train_time_s\": 13.833978176116943}", "{\"n\": 780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2816.73, \"learn_time_ms\": 10160.673, \"total_train_time_s\": 14.327364921569824}", "{\"n\": 781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2813.83, \"learn_time_ms\": 10272.163, \"total_train_time_s\": 13.920372486114502}", "{\"n\": 782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2812.02, \"learn_time_ms\": 10217.816, \"total_train_time_s\": 12.832869529724121}", "{\"n\": 783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2812.02, \"learn_time_ms\": 10190.052, \"total_train_time_s\": 13.255959033966064}", "{\"n\": 784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2818.87, \"learn_time_ms\": 10173.706, \"total_train_time_s\": 14.0956289768219}", "{\"n\": 785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2825.15, \"learn_time_ms\": 10004.713, \"total_train_time_s\": 13.038368940353394}", "{\"n\": 786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2816.14, \"learn_time_ms\": 10056.034, \"total_train_time_s\": 14.046094179153442}", "{\"n\": 787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2811.49, \"learn_time_ms\": 10088.117, \"total_train_time_s\": 13.546883583068848}", "{\"n\": 788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2802.17, \"learn_time_ms\": 9959.096, \"total_train_time_s\": 13.247102975845337}", "{\"n\": 789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.94, \"learn_time_ms\": 9871.242, \"total_train_time_s\": 12.853742837905884}", "{\"n\": 790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2786.42, \"learn_time_ms\": 9852.913, \"total_train_time_s\": 13.796910762786865}", "{\"n\": 791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2785.99, \"learn_time_ms\": 9840.02, \"total_train_time_s\": 13.75797414779663}", "{\"n\": 792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2789.38, \"learn_time_ms\": 9888.911, \"total_train_time_s\": 13.24928879737854}", "{\"n\": 793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.43, \"learn_time_ms\": 9956.546, \"total_train_time_s\": 14.295706033706665}", "{\"n\": 794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2787.87, \"learn_time_ms\": 9929.846, \"total_train_time_s\": 13.66563868522644}", "{\"n\": 795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2805.57, \"learn_time_ms\": 10060.172, \"total_train_time_s\": 14.42352557182312}", "{\"n\": 796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2810.16, \"learn_time_ms\": 9936.839, \"total_train_time_s\": 12.980521202087402}", "{\"n\": 797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2809.99, \"learn_time_ms\": 9937.696, \"total_train_time_s\": 13.862462282180786}", "{\"n\": 798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2805.92, \"learn_time_ms\": 10021.732, \"total_train_time_s\": 14.212970972061157}", "{\"n\": 799, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2805.92, \"learn_time_ms\": 10095.079, \"total_train_time_s\": 13.716213941574097}", "{\"n\": 800, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2788.27, \"learn_time_ms\": 10114.239, \"total_train_time_s\": 14.044888019561768}", "{\"n\": 801, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2789.2, \"learn_time_ms\": 10030.324, \"total_train_time_s\": 12.982178449630737}", "{\"n\": 802, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2797.51, \"learn_time_ms\": 10052.025, \"total_train_time_s\": 13.448666095733643}", "{\"n\": 803, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2808.28, \"learn_time_ms\": 9910.114, \"total_train_time_s\": 12.600795030593872}", "{\"n\": 804, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2820.19, \"learn_time_ms\": 9983.907, \"total_train_time_s\": 14.594683408737183}", "{\"n\": 805, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2815.03, \"learn_time_ms\": 9892.676, \"total_train_time_s\": 13.53116488456726}", "{\"n\": 806, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2835.8, \"learn_time_ms\": 9944.664, \"total_train_time_s\": 13.332989931106567}", "{\"n\": 807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2839.68, \"learn_time_ms\": 10007.666, \"total_train_time_s\": 14.256165027618408}", "{\"n\": 808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2847.71, \"learn_time_ms\": 10041.785, \"total_train_time_s\": 14.580398797988892}", "{\"n\": 809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2856.01, \"learn_time_ms\": 10080.796, \"total_train_time_s\": 14.024773597717285}", "{\"n\": 810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2859.62, \"learn_time_ms\": 10156.457, \"total_train_time_s\": 14.797633409500122}", "{\"n\": 811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2854.13, \"learn_time_ms\": 10112.241, \"total_train_time_s\": 12.464271068572998}", "{\"n\": 812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2841.76, \"learn_time_ms\": 10166.155, \"total_train_time_s\": 14.016659021377563}", "{\"n\": 813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2847.75, \"learn_time_ms\": 10287.29, \"total_train_time_s\": 13.943553686141968}", "{\"n\": 814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2847.75, \"learn_time_ms\": 10215.488, \"total_train_time_s\": 13.757184982299805}", "{\"n\": 815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.18, \"learn_time_ms\": 10194.832, \"total_train_time_s\": 13.471476554870605}", "{\"n\": 816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.18, \"learn_time_ms\": 10358.42, \"total_train_time_s\": 14.992828130722046}", "{\"n\": 817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.18, \"learn_time_ms\": 10311.855, \"total_train_time_s\": 13.937713623046875}", "{\"n\": 818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.55, \"learn_time_ms\": 10133.518, \"total_train_time_s\": 12.598668336868286}", "{\"n\": 819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.55, \"learn_time_ms\": 10129.699, \"total_train_time_s\": 13.991030216217041}", "{\"n\": 820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2848.55, \"learn_time_ms\": 10057.26, \"total_train_time_s\": 14.147204637527466}", "{\"n\": 821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2860.14, \"learn_time_ms\": 10161.637, \"total_train_time_s\": 13.460269451141357}", "{\"n\": 822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2860.14, \"learn_time_ms\": 10092.248, \"total_train_time_s\": 13.630011320114136}", "{\"n\": 823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2865.62, \"learn_time_ms\": 10138.248, \"total_train_time_s\": 14.218417644500732}", "{\"n\": 824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2868.62, \"learn_time_ms\": 10178.882, \"total_train_time_s\": 14.177186727523804}", "{\"n\": 825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2868.62, \"learn_time_ms\": 10192.221, \"total_train_time_s\": 13.372061491012573}", "{\"n\": 826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2866.46, \"learn_time_ms\": 9965.307, \"total_train_time_s\": 12.719095706939697}", "{\"n\": 827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2861.38, \"learn_time_ms\": 9926.313, \"total_train_time_s\": 13.463408946990967}", "{\"n\": 828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2861.38, \"learn_time_ms\": 10032.012, \"total_train_time_s\": 13.622381687164307}", "{\"n\": 829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2855.6, \"learn_time_ms\": 10007.756, \"total_train_time_s\": 13.825103282928467}", "{\"n\": 830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.29, \"learn_time_ms\": 9898.143, \"total_train_time_s\": 12.902008295059204}", "{\"n\": 831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.29, \"learn_time_ms\": 9960.217, \"total_train_time_s\": 14.079360008239746}", "{\"n\": 832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2856.24, \"learn_time_ms\": 9953.065, \"total_train_time_s\": 13.458451747894287}", "{\"n\": 833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2856.24, \"learn_time_ms\": 9905.033, \"total_train_time_s\": 13.758796453475952}", "{\"n\": 834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2856.24, \"learn_time_ms\": 9774.426, \"total_train_time_s\": 12.813111305236816}", "{\"n\": 835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2852.81, \"learn_time_ms\": 9774.771, \"total_train_time_s\": 13.580010890960693}", "{\"n\": 836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2851.13, \"learn_time_ms\": 9761.409, \"total_train_time_s\": 12.60907769203186}", "{\"n\": 837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2845.03, \"learn_time_ms\": 9769.063, \"total_train_time_s\": 13.677746534347534}", "{\"n\": 838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.18, \"learn_time_ms\": 9753.99, \"total_train_time_s\": 13.853457927703857}", "{\"n\": 839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2852.66, \"learn_time_ms\": 9826.926, \"total_train_time_s\": 14.68591833114624}", "{\"n\": 840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2852.66, \"learn_time_ms\": 9961.908, \"total_train_time_s\": 14.247973442077637}", "{\"n\": 841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.33, \"learn_time_ms\": 9969.894, \"total_train_time_s\": 14.160757303237915}", "{\"n\": 842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2862.22, \"learn_time_ms\": 10026.504, \"total_train_time_s\": 13.797980070114136}", "{\"n\": 843, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2847.91, \"learn_time_ms\": 10077.365, \"total_train_time_s\": 14.352384328842163}", "{\"n\": 844, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2848.75, \"learn_time_ms\": 10114.23, \"total_train_time_s\": 13.380890130996704}", "{\"n\": 845, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2847.17, \"learn_time_ms\": 10181.41, \"total_train_time_s\": 14.042357683181763}", "{\"n\": 846, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2843.72, \"learn_time_ms\": 10274.754, \"total_train_time_s\": 13.548235416412354}", "{\"n\": 847, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2843.38, \"learn_time_ms\": 10395.711, \"total_train_time_s\": 14.763020992279053}", "{\"n\": 848, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2855.44, \"learn_time_ms\": 10499.467, \"total_train_time_s\": 14.672494649887085}", "{\"n\": 849, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2853.83, \"learn_time_ms\": 10423.179, \"total_train_time_s\": 13.952364206314087}", "{\"n\": 850, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2865.65, \"learn_time_ms\": 10403.832, \"total_train_time_s\": 14.02708888053894}", "{\"n\": 851, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2873.75, \"learn_time_ms\": 10293.806, \"total_train_time_s\": 13.082204818725586}", "{\"n\": 852, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2884.73, \"learn_time_ms\": 10241.893, \"total_train_time_s\": 13.236495971679688}", "{\"n\": 853, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2881.6, \"learn_time_ms\": 10186.536, \"total_train_time_s\": 13.664975643157959}", "{\"n\": 854, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2881.6, \"learn_time_ms\": 10178.419, \"total_train_time_s\": 13.270390748977661}", "{\"n\": 855, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2884.6, \"learn_time_ms\": 10113.613, \"total_train_time_s\": 13.455585956573486}", "{\"n\": 856, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2875.14, \"learn_time_ms\": 10117.515, \"total_train_time_s\": 13.56032657623291}", "{\"n\": 857, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2872.2, \"learn_time_ms\": 10035.483, \"total_train_time_s\": 14.071358919143677}", "{\"n\": 858, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2881.08, \"learn_time_ms\": 9873.331, \"total_train_time_s\": 13.150752305984497}", "{\"n\": 859, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2881.08, \"learn_time_ms\": 10006.217, \"total_train_time_s\": 15.030874252319336}", "{\"n\": 860, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.27, \"learn_time_ms\": 9920.465, \"total_train_time_s\": 13.247163772583008}", "{\"n\": 861, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2900.38, \"learn_time_ms\": 9971.75, \"total_train_time_s\": 13.710458040237427}", "{\"n\": 862, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2907.78, \"learn_time_ms\": 9957.345, \"total_train_time_s\": 13.116133689880371}", "{\"n\": 863, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2902.79, \"learn_time_ms\": 10029.945, \"total_train_time_s\": 14.404265642166138}", "{\"n\": 864, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2902.79, \"learn_time_ms\": 10159.39, \"total_train_time_s\": 14.687851190567017}", "{\"n\": 865, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.46, \"learn_time_ms\": 10208.375, \"total_train_time_s\": 14.274022579193115}", "{\"n\": 866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2873.36, \"learn_time_ms\": 10238.689, \"total_train_time_s\": 14.008034229278564}", "{\"n\": 867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2874.43, \"learn_time_ms\": 10198.47, \"total_train_time_s\": 13.872761011123657}", "{\"n\": 868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2864.89, \"learn_time_ms\": 10215.888, \"total_train_time_s\": 13.078275680541992}", "{\"n\": 869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2864.89, \"learn_time_ms\": 10020.696, \"total_train_time_s\": 13.068320035934448}", "{\"n\": 870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2870.84, \"learn_time_ms\": 10097.77, \"total_train_time_s\": 14.058924198150635}", "{\"n\": 871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2868.05, \"learn_time_ms\": 9977.35, \"total_train_time_s\": 12.558685541152954}", "{\"n\": 872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2870.39, \"learn_time_ms\": 9987.534, \"total_train_time_s\": 13.234293222427368}", "{\"n\": 873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2880.61, \"learn_time_ms\": 9841.144, \"total_train_time_s\": 13.103938579559326}", "{\"n\": 874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2890.82, \"learn_time_ms\": 9751.622, \"total_train_time_s\": 13.543495655059814}", "{\"n\": 875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.7, \"learn_time_ms\": 9687.49, \"total_train_time_s\": 13.219886064529419}", "{\"n\": 876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2886.88, \"learn_time_ms\": 9700.58, \"total_train_time_s\": 14.028930902481079}", "{\"n\": 877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2888.61, \"learn_time_ms\": 9748.639, \"total_train_time_s\": 14.009607315063477}", "{\"n\": 878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2888.61, \"learn_time_ms\": 9725.664, \"total_train_time_s\": 12.894361734390259}", "{\"n\": 879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2892.54, \"learn_time_ms\": 9797.604, \"total_train_time_s\": 13.816431283950806}", "{\"n\": 880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2888.94, \"learn_time_ms\": 9739.785, \"total_train_time_s\": 13.512129783630371}", "{\"n\": 881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2888.94, \"learn_time_ms\": 9833.793, \"total_train_time_s\": 13.42251467704773}", "{\"n\": 882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2900.27, \"learn_time_ms\": 9952.313, \"total_train_time_s\": 14.41564416885376}", "{\"n\": 883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.23, \"learn_time_ms\": 9915.133, \"total_train_time_s\": 12.609728336334229}", "{\"n\": 884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2900.8, \"learn_time_ms\": 10020.357, \"total_train_time_s\": 14.735052347183228}", "{\"n\": 885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2897.21, \"learn_time_ms\": 10000.292, \"total_train_time_s\": 13.110225915908813}", "{\"n\": 886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2903.05, \"learn_time_ms\": 9939.76, \"total_train_time_s\": 13.46756362915039}", "{\"n\": 887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2896.66, \"learn_time_ms\": 9907.727, \"total_train_time_s\": 13.735111951828003}", "{\"n\": 888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2886.88, \"learn_time_ms\": 9937.436, \"total_train_time_s\": 13.140466451644897}", "{\"n\": 889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2883.93, \"learn_time_ms\": 9872.56, \"total_train_time_s\": 13.267778158187866}", "{\"n\": 890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2902.21, \"learn_time_ms\": 9875.437, \"total_train_time_s\": 13.381929874420166}", "{\"n\": 891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2904.14, \"learn_time_ms\": 9950.406, \"total_train_time_s\": 14.087965488433838}", "{\"n\": 892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2899.0, \"learn_time_ms\": 9807.974, \"total_train_time_s\": 13.077858209609985}", "{\"n\": 893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2906.46, \"learn_time_ms\": 9953.229, \"total_train_time_s\": 14.25288200378418}", "{\"n\": 894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2902.65, \"learn_time_ms\": 9879.524, \"total_train_time_s\": 13.956753969192505}", "{\"n\": 895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.92, \"learn_time_ms\": 9948.961, \"total_train_time_s\": 13.82980227470398}", "{\"n\": 896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2890.44, \"learn_time_ms\": 9929.564, \"total_train_time_s\": 13.285725831985474}", "{\"n\": 897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2890.44, \"learn_time_ms\": 9904.271, \"total_train_time_s\": 13.30498194694519}", "{\"n\": 898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2900.78, \"learn_time_ms\": 9961.387, \"total_train_time_s\": 13.726982831954956}", "{\"n\": 899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2889.69, \"learn_time_ms\": 10090.263, \"total_train_time_s\": 14.46351432800293}", "{\"n\": 900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2891.02, \"learn_time_ms\": 10103.499, \"total_train_time_s\": 13.75972318649292}", "{\"n\": 901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2885.03, \"learn_time_ms\": 10075.549, \"total_train_time_s\": 13.786624431610107}", "{\"n\": 902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2885.95, \"learn_time_ms\": 10156.299, \"total_train_time_s\": 13.850841999053955}", "{\"n\": 903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2876.74, \"learn_time_ms\": 9976.675, \"total_train_time_s\": 12.242434740066528}", "{\"n\": 904, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2880.39, \"learn_time_ms\": 9979.052, \"total_train_time_s\": 13.859660863876343}", "{\"n\": 905, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2883.27, \"learn_time_ms\": 9918.087, \"total_train_time_s\": 13.19990611076355}", "{\"n\": 906, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2883.92, \"learn_time_ms\": 9915.952, \"total_train_time_s\": 13.227153301239014}", "{\"n\": 907, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2888.91, \"learn_time_ms\": 9905.26, \"total_train_time_s\": 13.229565620422363}", "{\"n\": 908, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2888.08, \"learn_time_ms\": 9844.914, \"total_train_time_s\": 13.470137119293213}", "{\"n\": 909, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2883.29, \"learn_time_ms\": 9917.925, \"total_train_time_s\": 15.186772346496582}", "{\"n\": 910, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2880.21, \"learn_time_ms\": 9847.834, \"total_train_time_s\": 12.935274839401245}", "{\"n\": 911, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2885.35, \"learn_time_ms\": 9854.262, \"total_train_time_s\": 13.872684717178345}", "{\"n\": 912, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.0, \"learn_time_ms\": 9875.607, \"total_train_time_s\": 14.18015193939209}", "{\"n\": 913, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2890.27, \"learn_time_ms\": 10030.5, \"total_train_time_s\": 13.945004940032959}", "{\"n\": 914, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2891.3, \"learn_time_ms\": 9973.389, \"total_train_time_s\": 13.356074810028076}", "{\"n\": 915, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2898.2, \"learn_time_ms\": 10035.314, \"total_train_time_s\": 13.778194189071655}", "{\"n\": 916, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.03, \"learn_time_ms\": 10000.961, \"total_train_time_s\": 12.858528137207031}", "{\"n\": 917, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.03, \"learn_time_ms\": 10002.687, \"total_train_time_s\": 13.287693500518799}", "{\"n\": 918, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2873.81, \"learn_time_ms\": 10006.68, \"total_train_time_s\": 13.202850580215454}", "{\"n\": 919, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2873.81, \"learn_time_ms\": 9745.575, \"total_train_time_s\": 12.617314100265503}", "{\"n\": 920, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2873.81, \"learn_time_ms\": 9786.888, \"total_train_time_s\": 13.391534805297852}", "{\"n\": 921, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2861.13, \"learn_time_ms\": 9756.101, \"total_train_time_s\": 13.51314640045166}", "{\"n\": 922, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2861.13, \"learn_time_ms\": 9773.6, \"total_train_time_s\": 14.190809726715088}", "{\"n\": 923, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2855.69, \"learn_time_ms\": 9777.008, \"total_train_time_s\": 13.907329082489014}", "{\"n\": 924, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2854.61, \"learn_time_ms\": 9840.562, \"total_train_time_s\": 13.883841753005981}", "{\"n\": 925, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2854.61, \"learn_time_ms\": 9808.801, \"total_train_time_s\": 13.860044717788696}", "{\"n\": 926, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2844.41, \"learn_time_ms\": 9888.878, \"total_train_time_s\": 13.632865905761719}", "{\"n\": 927, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2850.42, \"learn_time_ms\": 9874.532, \"total_train_time_s\": 13.219653606414795}", "{\"n\": 928, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2850.42, \"learn_time_ms\": 9905.542, \"total_train_time_s\": 13.445019245147705}", "{\"n\": 929, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2866.01, \"learn_time_ms\": 10099.885, \"total_train_time_s\": 14.53825855255127}", "{\"n\": 930, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2870.25, \"learn_time_ms\": 10130.022, \"total_train_time_s\": 13.495148658752441}", "{\"n\": 931, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2870.25, \"learn_time_ms\": 10113.415, \"total_train_time_s\": 13.335376262664795}", "{\"n\": 932, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2869.23, \"learn_time_ms\": 10073.282, \"total_train_time_s\": 13.883909463882446}", "{\"n\": 933, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2866.98, \"learn_time_ms\": 9962.396, \"total_train_time_s\": 12.820598125457764}", "{\"n\": 934, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2869.37, \"learn_time_ms\": 9933.165, \"total_train_time_s\": 13.766348838806152}", "{\"n\": 935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2859.52, \"learn_time_ms\": 10031.076, \"total_train_time_s\": 14.431676387786865}", "{\"n\": 936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2859.52, \"learn_time_ms\": 9987.555, \"total_train_time_s\": 13.237318277359009}", "{\"n\": 937, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2858.92, \"learn_time_ms\": 10031.114, \"total_train_time_s\": 13.62453293800354}", "{\"n\": 938, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2879.95, \"learn_time_ms\": 10017.227, \"total_train_time_s\": 13.470650434494019}", "{\"n\": 939, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2879.95, \"learn_time_ms\": 9830.827, \"total_train_time_s\": 12.764250040054321}", "{\"n\": 940, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2867.72, \"learn_time_ms\": 9521.287, \"total_train_time_s\": 10.604342460632324}", "{\"n\": 941, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2873.8, \"learn_time_ms\": 9423.664, \"total_train_time_s\": 12.670634984970093}", "{\"n\": 942, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2875.79, \"learn_time_ms\": 9438.078, \"total_train_time_s\": 13.899301052093506}", "{\"n\": 943, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2862.37, \"learn_time_ms\": 9581.401, \"total_train_time_s\": 14.241438627243042}", "{\"n\": 944, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2850.09, \"learn_time_ms\": 9519.412, \"total_train_time_s\": 13.237584829330444}", "{\"n\": 945, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2842.48, \"learn_time_ms\": 9422.65, \"total_train_time_s\": 13.493562698364258}", "{\"n\": 946, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2836.48, \"learn_time_ms\": 9408.242, \"total_train_time_s\": 13.024390935897827}", "{\"n\": 947, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2807.09, \"learn_time_ms\": 9302.446, \"total_train_time_s\": 12.60155463218689}", "{\"n\": 948, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2807.09, \"learn_time_ms\": 9264.6, \"total_train_time_s\": 12.937295913696289}", "{\"n\": 949, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2803.88, \"learn_time_ms\": 9253.326, \"total_train_time_s\": 12.521687507629395}", "{\"n\": 950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.84, \"learn_time_ms\": 9516.238, \"total_train_time_s\": 13.225600242614746}", "{\"n\": 951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.84, \"learn_time_ms\": 9689.098, \"total_train_time_s\": 14.340789318084717}", "{\"n\": 952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2781.55, \"learn_time_ms\": 9676.659, \"total_train_time_s\": 13.81498670578003}", "{\"n\": 953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2777.43, \"learn_time_ms\": 9606.461, \"total_train_time_s\": 13.598146677017212}", "{\"n\": 954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2777.43, \"learn_time_ms\": 9663.284, \"total_train_time_s\": 13.64257001876831}", "{\"n\": 955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2777.5, \"learn_time_ms\": 9777.479, \"total_train_time_s\": 14.882946968078613}", "{\"n\": 956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2788.43, \"learn_time_ms\": 9790.847, \"total_train_time_s\": 13.17620325088501}", "{\"n\": 957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2793.54, \"learn_time_ms\": 9861.465, \"total_train_time_s\": 13.616760015487671}", "{\"n\": 958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2797.38, \"learn_time_ms\": 9916.324, \"total_train_time_s\": 13.493923902511597}", "{\"n\": 959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.07, \"learn_time_ms\": 9961.54, \"total_train_time_s\": 12.986732244491577}", "{\"n\": 960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2796.5, \"learn_time_ms\": 9935.057, \"total_train_time_s\": 12.821882963180542}", "{\"n\": 961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2800.32, \"learn_time_ms\": 9921.626, \"total_train_time_s\": 14.004788637161255}", "{\"n\": 962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2807.37, \"learn_time_ms\": 9884.378, \"total_train_time_s\": 13.415781259536743}", "{\"n\": 963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2793.83, \"learn_time_ms\": 9864.392, \"total_train_time_s\": 13.245951652526855}", "{\"n\": 964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2795.65, \"learn_time_ms\": 9800.857, \"total_train_time_s\": 13.230026960372925}", "{\"n\": 965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2795.65, \"learn_time_ms\": 9760.466, \"total_train_time_s\": 14.181679010391235}", "{\"n\": 966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2805.03, \"learn_time_ms\": 9777.507, \"total_train_time_s\": 13.359872817993164}", "{\"n\": 967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2797.99, \"learn_time_ms\": 9806.826, \"total_train_time_s\": 13.684037685394287}", "{\"n\": 968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2790.88, \"learn_time_ms\": 9819.295, \"total_train_time_s\": 13.736921787261963}", "{\"n\": 969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2802.9, \"learn_time_ms\": 9855.064, \"total_train_time_s\": 13.356098175048828}", "{\"n\": 970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2806.56, \"learn_time_ms\": 9913.925, \"total_train_time_s\": 13.655828714370728}", "{\"n\": 971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2806.56, \"learn_time_ms\": 9839.588, \"total_train_time_s\": 13.397842645645142}", "{\"n\": 972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2800.4, \"learn_time_ms\": 9764.8, \"total_train_time_s\": 12.787600755691528}", "{\"n\": 973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2795.38, \"learn_time_ms\": 9880.934, \"total_train_time_s\": 14.39046049118042}", "{\"n\": 974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2792.51, \"learn_time_ms\": 9913.318, \"total_train_time_s\": 13.209058284759521}", "{\"n\": 975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2778.54, \"learn_time_ms\": 9847.988, \"total_train_time_s\": 13.804493427276611}", "{\"n\": 976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2783.63, \"learn_time_ms\": 9855.87, \"total_train_time_s\": 13.53893494606018}", "{\"n\": 977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2787.35, \"learn_time_ms\": 9852.941, \"total_train_time_s\": 13.468927145004272}", "{\"n\": 978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.6, \"learn_time_ms\": 9812.433, \"total_train_time_s\": 13.24107575416565}", "{\"n\": 979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2793.79, \"learn_time_ms\": 9724.046, \"total_train_time_s\": 12.640599489212036}", "{\"n\": 980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.48, \"learn_time_ms\": 9730.174, \"total_train_time_s\": 13.541051387786865}", "{\"n\": 981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2788.55, \"learn_time_ms\": 9774.061, \"total_train_time_s\": 13.70949935913086}", "{\"n\": 982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2789.9, \"learn_time_ms\": 9814.104, \"total_train_time_s\": 13.14750075340271}", "{\"n\": 983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2791.56, \"learn_time_ms\": 9659.739, \"total_train_time_s\": 12.937911748886108}", "{\"n\": 984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2790.45, \"learn_time_ms\": 9560.599, \"total_train_time_s\": 12.216039896011353}", "{\"n\": 985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2788.77, \"learn_time_ms\": 9496.971, \"total_train_time_s\": 12.927799224853516}", "{\"n\": 986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2775.73, \"learn_time_ms\": 9570.386, \"total_train_time_s\": 14.179312705993652}", "{\"n\": 987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2778.48, \"learn_time_ms\": 9530.017, \"total_train_time_s\": 13.068788290023804}", "{\"n\": 988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2792.58, \"learn_time_ms\": 9555.336, \"total_train_time_s\": 13.69258975982666}", "{\"n\": 989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2789.31, \"learn_time_ms\": 9584.995, \"total_train_time_s\": 12.752322673797607}", "{\"n\": 990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2806.13, \"learn_time_ms\": 9506.349, \"total_train_time_s\": 12.724184036254883}", "{\"n\": 991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2814.22, \"learn_time_ms\": 9506.857, \"total_train_time_s\": 13.76574420928955}", "{\"n\": 992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2828.89, \"learn_time_ms\": 9573.326, \"total_train_time_s\": 13.733151912689209}", "{\"n\": 993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2840.18, \"learn_time_ms\": 9610.246, \"total_train_time_s\": 13.278839588165283}", "{\"n\": 994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2839.63, \"learn_time_ms\": 9677.967, \"total_train_time_s\": 13.35961365699768}", "{\"n\": 995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2844.35, \"learn_time_ms\": 9797.442, \"total_train_time_s\": 14.415352821350098}", "{\"n\": 996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2856.99, \"learn_time_ms\": 9751.626, \"total_train_time_s\": 13.728610515594482}", "{\"n\": 997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2852.58, \"learn_time_ms\": 9794.978, \"total_train_time_s\": 13.836298704147339}", "{\"n\": 998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2857.77, \"learn_time_ms\": 9816.02, \"total_train_time_s\": 13.636772155761719}", "{\"n\": 999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2870.47, \"learn_time_ms\": 10012.781, \"total_train_time_s\": 14.792508840560913}", "{\"n\": 1000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2870.47, \"learn_time_ms\": 10101.348, \"total_train_time_s\": 13.564310312271118}", "{\"n\": 1001, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2859.07, \"learn_time_ms\": 10104.676, \"total_train_time_s\": 13.870616912841797}", "{\"n\": 1002, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2853.71, \"learn_time_ms\": 10006.291, \"total_train_time_s\": 12.993285655975342}", "{\"n\": 1003, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2853.71, \"learn_time_ms\": 10016.106, \"total_train_time_s\": 13.720242738723755}", "{\"n\": 1004, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2861.13, \"learn_time_ms\": 10105.796, \"total_train_time_s\": 13.822717189788818}", "{\"n\": 1005, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2874.1, \"learn_time_ms\": 10065.968, \"total_train_time_s\": 13.736645460128784}", "{\"n\": 1006, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2875.52, \"learn_time_ms\": 10072.95, \"total_train_time_s\": 13.900575876235962}", "{\"n\": 1007, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2886.89, \"learn_time_ms\": 10122.65, \"total_train_time_s\": 14.056279182434082}", "{\"n\": 1008, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2884.41, \"learn_time_ms\": 10107.217, \"total_train_time_s\": 13.506529092788696}", "{\"n\": 1009, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2892.43, \"learn_time_ms\": 9983.197, \"total_train_time_s\": 13.53188180923462}", "{\"n\": 1010, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2885.01, \"learn_time_ms\": 9979.379, \"total_train_time_s\": 13.541133165359497}", "{\"n\": 1011, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2884.09, \"learn_time_ms\": 9943.327, \"total_train_time_s\": 13.538554430007935}", "{\"n\": 1012, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.74, \"learn_time_ms\": 10088.327, \"total_train_time_s\": 14.356963634490967}", "{\"n\": 1013, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.77, \"learn_time_ms\": 10105.497, \"total_train_time_s\": 13.66659426689148}", "{\"n\": 1014, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.77, \"learn_time_ms\": 10153.226, \"total_train_time_s\": 14.330816984176636}", "{\"n\": 1015, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.65, \"learn_time_ms\": 10111.351, \"total_train_time_s\": 13.402068376541138}", "{\"n\": 1016, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.3, \"learn_time_ms\": 9968.807, \"total_train_time_s\": 12.405704975128174}", "{\"n\": 1017, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.3, \"learn_time_ms\": 9956.113, \"total_train_time_s\": 13.910045385360718}", "{\"n\": 1018, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2921.05, \"learn_time_ms\": 9986.429, \"total_train_time_s\": 13.931084394454956}", "{\"n\": 1019, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2924.91, \"learn_time_ms\": 10016.454, \"total_train_time_s\": 13.956026077270508}", "{\"n\": 1020, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2930.49, \"learn_time_ms\": 9968.496, \"total_train_time_s\": 13.016381978988647}", "{\"n\": 1021, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2940.0, \"learn_time_ms\": 9926.076, \"total_train_time_s\": 12.922528982162476}", "{\"n\": 1022, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2956.87, \"learn_time_ms\": 9831.634, \"total_train_time_s\": 13.476272583007812}", "{\"n\": 1023, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2954.97, \"learn_time_ms\": 9884.184, \"total_train_time_s\": 14.121689796447754}", "{\"n\": 1024, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2955.18, \"learn_time_ms\": 9740.457, \"total_train_time_s\": 12.832221031188965}", "{\"n\": 1025, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2966.59, \"learn_time_ms\": 9746.278, \"total_train_time_s\": 13.509690523147583}", "{\"n\": 1026, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2973.68, \"learn_time_ms\": 9869.728, \"total_train_time_s\": 13.602691650390625}", "{\"n\": 1027, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2974.46, \"learn_time_ms\": 9808.523, \"total_train_time_s\": 13.319550514221191}", "{\"n\": 1028, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2977.56, \"learn_time_ms\": 9756.81, \"total_train_time_s\": 13.351744890213013}", "{\"n\": 1029, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.79, \"learn_time_ms\": 9757.907, \"total_train_time_s\": 14.007627725601196}", "{\"n\": 1030, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2978.46, \"learn_time_ms\": 9770.664, \"total_train_time_s\": 13.321075677871704}", "{\"n\": 1031, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2978.76, \"learn_time_ms\": 9905.787, \"total_train_time_s\": 14.326478958129883}", "{\"n\": 1032, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.76, \"learn_time_ms\": 10010.728, \"total_train_time_s\": 14.412671566009521}", "{\"n\": 1033, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2990.11, \"learn_time_ms\": 9978.1, \"total_train_time_s\": 13.71623182296753}", "{\"n\": 1034, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2973.05, \"learn_time_ms\": 10149.919, \"total_train_time_s\": 14.652459144592285}", "{\"n\": 1035, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.78, \"learn_time_ms\": 10122.748, \"total_train_time_s\": 13.10362982749939}", "{\"n\": 1036, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2982.98, \"learn_time_ms\": 10145.741, \"total_train_time_s\": 13.874387264251709}", "{\"n\": 1037, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2984.73, \"learn_time_ms\": 10106.885, \"total_train_time_s\": 12.833546876907349}", "{\"n\": 1038, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2991.57, \"learn_time_ms\": 10155.711, \"total_train_time_s\": 13.798551082611084}", "{\"n\": 1039, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2993.78, \"learn_time_ms\": 10205.709, \"total_train_time_s\": 14.38725757598877}", "{\"n\": 1040, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2989.65, \"learn_time_ms\": 10207.425, \"total_train_time_s\": 13.284389972686768}", "{\"n\": 1041, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2989.65, \"learn_time_ms\": 10139.578, \"total_train_time_s\": 13.69350552558899}", "{\"n\": 1042, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2999.99, \"learn_time_ms\": 10061.947, \"total_train_time_s\": 13.586383581161499}", "{\"n\": 1043, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2999.19, \"learn_time_ms\": 10081.832, \"total_train_time_s\": 13.925495624542236}", "{\"n\": 1044, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2999.19, \"learn_time_ms\": 9984.757, \"total_train_time_s\": 13.60495114326477}", "{\"n\": 1045, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2991.06, \"learn_time_ms\": 10111.747, \"total_train_time_s\": 14.362582921981812}", "{\"n\": 1046, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3003.2, \"learn_time_ms\": 10092.312, \"total_train_time_s\": 13.858567714691162}", "{\"n\": 1047, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3011.5, \"learn_time_ms\": 10091.857, \"total_train_time_s\": 12.871864318847656}", "{\"n\": 1048, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3020.71, \"learn_time_ms\": 10086.775, \"total_train_time_s\": 13.735349893569946}", "{\"n\": 1049, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3026.06, \"learn_time_ms\": 9985.876, \"total_train_time_s\": 13.418399333953857}", "{\"n\": 1050, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3036.54, \"learn_time_ms\": 10028.368, \"total_train_time_s\": 13.744155406951904}", "{\"n\": 1051, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3036.31, \"learn_time_ms\": 10106.369, \"total_train_time_s\": 14.433894395828247}", "{\"n\": 1052, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3036.31, \"learn_time_ms\": 10203.363, \"total_train_time_s\": 14.577453136444092}", "{\"n\": 1053, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3029.08, \"learn_time_ms\": 10184.246, \"total_train_time_s\": 13.885714530944824}", "{\"n\": 1054, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3023.39, \"learn_time_ms\": 10254.824, \"total_train_time_s\": 14.314293146133423}", "{\"n\": 1055, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3019.95, \"learn_time_ms\": 10175.598, \"total_train_time_s\": 13.536608457565308}", "{\"n\": 1056, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3019.56, \"learn_time_ms\": 10081.109, \"total_train_time_s\": 12.901641130447388}", "{\"n\": 1057, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3014.03, \"learn_time_ms\": 10012.796, \"total_train_time_s\": 12.360592126846313}", "{\"n\": 1058, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3023.29, \"learn_time_ms\": 10023.469, \"total_train_time_s\": 13.84118366241455}", "{\"n\": 1059, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3037.52, \"learn_time_ms\": 10150.838, \"total_train_time_s\": 14.754517793655396}", "{\"n\": 1060, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3048.76, \"learn_time_ms\": 10224.708, \"total_train_time_s\": 14.513773679733276}", "{\"n\": 1061, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3054.7, \"learn_time_ms\": 10094.786, \"total_train_time_s\": 13.423717021942139}", "{\"n\": 1062, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3053.43, \"learn_time_ms\": 9927.957, \"total_train_time_s\": 12.939684867858887}", "{\"n\": 1063, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3041.17, \"learn_time_ms\": 9940.279, \"total_train_time_s\": 13.906413793563843}", "{\"n\": 1064, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3039.75, \"learn_time_ms\": 9797.87, \"total_train_time_s\": 13.122976064682007}", "{\"n\": 1065, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3029.23, \"learn_time_ms\": 9838.53, \"total_train_time_s\": 13.968707084655762}", "{\"n\": 1066, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3033.63, \"learn_time_ms\": 9895.91, \"total_train_time_s\": 13.245132684707642}", "{\"n\": 1067, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3025.67, \"learn_time_ms\": 10002.525, \"total_train_time_s\": 13.4558424949646}", "{\"n\": 1068, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3009.74, \"learn_time_ms\": 9955.197, \"total_train_time_s\": 13.5532808303833}", "{\"n\": 1069, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3009.74, \"learn_time_ms\": 9963.763, \"total_train_time_s\": 15.008767366409302}", "{\"n\": 1070, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3015.21, \"learn_time_ms\": 9904.351, \"total_train_time_s\": 13.761364221572876}", "{\"n\": 1071, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3025.22, \"learn_time_ms\": 9932.443, \"total_train_time_s\": 13.396711111068726}", "{\"n\": 1072, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3025.22, \"learn_time_ms\": 10031.366, \"total_train_time_s\": 13.816299200057983}", "{\"n\": 1073, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3024.26, \"learn_time_ms\": 10041.652, \"total_train_time_s\": 14.108262777328491}", "{\"n\": 1074, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3016.91, \"learn_time_ms\": 10116.163, \"total_train_time_s\": 13.655508995056152}", "{\"n\": 1075, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3016.91, \"learn_time_ms\": 10087.441, \"total_train_time_s\": 13.65491533279419}", "{\"n\": 1076, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3017.96, \"learn_time_ms\": 10166.107, \"total_train_time_s\": 14.023754596710205}", "{\"n\": 1077, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3010.94, \"learn_time_ms\": 10201.298, \"total_train_time_s\": 13.58616328239441}", "{\"n\": 1078, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3008.05, \"learn_time_ms\": 10143.2, \"total_train_time_s\": 12.78933596611023}", "{\"n\": 1079, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3005.52, \"learn_time_ms\": 10044.921, \"total_train_time_s\": 14.035865306854248}", "{\"n\": 1080, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3005.52, \"learn_time_ms\": 10016.946, \"total_train_time_s\": 13.4944167137146}", "{\"n\": 1081, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3010.41, \"learn_time_ms\": 10067.991, \"total_train_time_s\": 13.920299530029297}", "{\"n\": 1082, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3010.41, \"learn_time_ms\": 10063.735, \"total_train_time_s\": 13.932055234909058}", "{\"n\": 1083, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3014.57, \"learn_time_ms\": 10082.565, \"total_train_time_s\": 14.133877754211426}", "{\"n\": 1084, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3020.1, \"learn_time_ms\": 9898.77, \"total_train_time_s\": 11.890514135360718}", "{\"n\": 1085, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3019.63, \"learn_time_ms\": 9919.805, \"total_train_time_s\": 13.95940113067627}", "{\"n\": 1086, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3022.66, \"learn_time_ms\": 9904.318, \"total_train_time_s\": 13.88746976852417}", "{\"n\": 1087, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3013.35, \"learn_time_ms\": 9862.163, \"total_train_time_s\": 13.165348291397095}", "{\"n\": 1088, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3027.31, \"learn_time_ms\": 9865.611, \"total_train_time_s\": 12.927786827087402}", "{\"n\": 1089, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3032.17, \"learn_time_ms\": 9777.823, \"total_train_time_s\": 12.788298845291138}", "{\"n\": 1090, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3039.15, \"learn_time_ms\": 9699.343, \"total_train_time_s\": 12.87955379486084}", "{\"n\": 1091, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3039.15, \"learn_time_ms\": 9663.227, \"total_train_time_s\": 13.560546875}", "{\"n\": 1092, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3041.11, \"learn_time_ms\": 9598.418, \"total_train_time_s\": 13.17164421081543}", "{\"n\": 1093, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3041.11, \"learn_time_ms\": 9521.271, \"total_train_time_s\": 13.379381656646729}", "{\"n\": 1094, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3033.57, \"learn_time_ms\": 9617.208, \"total_train_time_s\": 12.700114965438843}", "{\"n\": 1095, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3035.71, \"learn_time_ms\": 9506.285, \"total_train_time_s\": 12.95949649810791}", "{\"n\": 1096, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3036.47, \"learn_time_ms\": 9543.465, \"total_train_time_s\": 14.275472640991211}", "{\"n\": 1097, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3033.08, \"learn_time_ms\": 9524.61, \"total_train_time_s\": 13.346352100372314}", "{\"n\": 1098, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3042.96, \"learn_time_ms\": 9522.028, \"total_train_time_s\": 12.823326110839844}", "{\"n\": 1099, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3034.1, \"learn_time_ms\": 9703.261, \"total_train_time_s\": 14.580963611602783}", "{\"n\": 1100, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3022.46, \"learn_time_ms\": 9788.247, \"total_train_time_s\": 13.791512250900269}", "{\"n\": 1101, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3017.5, \"learn_time_ms\": 9736.654, \"total_train_time_s\": 13.093900442123413}", "{\"n\": 1102, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3016.36, \"learn_time_ms\": 9700.794, \"total_train_time_s\": 12.805236339569092}", "{\"n\": 1103, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3026.08, \"learn_time_ms\": 9863.763, \"total_train_time_s\": 14.985004663467407}", "{\"n\": 1104, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3018.67, \"learn_time_ms\": 9901.038, \"total_train_time_s\": 13.587669610977173}", "{\"n\": 1105, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3013.19, \"learn_time_ms\": 10008.684, \"total_train_time_s\": 13.847535848617554}", "{\"n\": 1106, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3013.19, \"learn_time_ms\": 9931.672, \"total_train_time_s\": 13.547505378723145}", "{\"n\": 1107, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3023.2, \"learn_time_ms\": 9913.431, \"total_train_time_s\": 12.86330771446228}", "{\"n\": 1108, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.18, \"learn_time_ms\": 9965.541, \"total_train_time_s\": 13.54229211807251}", "{\"n\": 1109, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.18, \"learn_time_ms\": 9877.939, \"total_train_time_s\": 13.835020303726196}", "{\"n\": 1110, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3019.44, \"learn_time_ms\": 9984.574, \"total_train_time_s\": 14.61949896812439}", "{\"n\": 1111, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.11, \"learn_time_ms\": 10094.715, \"total_train_time_s\": 14.097403287887573}", "{\"n\": 1112, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.11, \"learn_time_ms\": 10111.512, \"total_train_time_s\": 13.055854320526123}", "{\"n\": 1113, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3031.54, \"learn_time_ms\": 9973.0, \"total_train_time_s\": 13.672797203063965}", "{\"n\": 1114, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3037.74, \"learn_time_ms\": 10012.732, \"total_train_time_s\": 13.748554229736328}", "{\"n\": 1115, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3037.74, \"learn_time_ms\": 9936.407, \"total_train_time_s\": 13.063339233398438}", "{\"n\": 1116, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.71, \"learn_time_ms\": 9906.745, \"total_train_time_s\": 13.337322473526001}", "{\"n\": 1117, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3036.67, \"learn_time_ms\": 10074.101, \"total_train_time_s\": 14.430015563964844}", "{\"n\": 1118, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.4, \"learn_time_ms\": 10175.048, \"total_train_time_s\": 14.376894474029541}", "{\"n\": 1119, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.75, \"learn_time_ms\": 10135.138, \"total_train_time_s\": 13.497586250305176}", "{\"n\": 1120, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.22, \"learn_time_ms\": 10064.041, \"total_train_time_s\": 13.879253387451172}", "{\"n\": 1121, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.44, \"learn_time_ms\": 9932.011, \"total_train_time_s\": 12.868659257888794}", "{\"n\": 1122, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.44, \"learn_time_ms\": 10083.081, \"total_train_time_s\": 14.54172158241272}", "{\"n\": 1123, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.64, \"learn_time_ms\": 10096.787, \"total_train_time_s\": 13.73687195777893}", "{\"n\": 1124, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.57, \"learn_time_ms\": 10096.221, \"total_train_time_s\": 13.53075885772705}", "{\"n\": 1125, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.57, \"learn_time_ms\": 10202.504, \"total_train_time_s\": 14.145201444625854}", "{\"n\": 1126, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.97, \"learn_time_ms\": 10299.609, \"total_train_time_s\": 14.599318981170654}", "{\"n\": 1127, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.14, \"learn_time_ms\": 10280.022, \"total_train_time_s\": 14.269683837890625}", "{\"n\": 1128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.14, \"learn_time_ms\": 10333.261, \"total_train_time_s\": 14.831463098526001}", "{\"n\": 1129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.02, \"learn_time_ms\": 10336.736, \"total_train_time_s\": 13.499019622802734}", "{\"n\": 1130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.27, \"learn_time_ms\": 10248.538, \"total_train_time_s\": 13.000888586044312}", "{\"n\": 1131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.27, \"learn_time_ms\": 10241.479, \"total_train_time_s\": 13.033159732818604}", "{\"n\": 1132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3058.24, \"learn_time_ms\": 10183.342, \"total_train_time_s\": 13.973093509674072}", "{\"n\": 1133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.46, \"learn_time_ms\": 10149.889, \"total_train_time_s\": 13.405463457107544}", "{\"n\": 1134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.46, \"learn_time_ms\": 10172.76, \"total_train_time_s\": 13.904610633850098}", "{\"n\": 1135, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.03, \"learn_time_ms\": 10105.517, \"total_train_time_s\": 13.510467290878296}", "{\"n\": 1136, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.27, \"learn_time_ms\": 10064.611, \"total_train_time_s\": 13.776328802108765}", "{\"n\": 1137, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.27, \"learn_time_ms\": 9986.02, \"total_train_time_s\": 13.834025382995605}", "{\"n\": 1138, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.29, \"learn_time_ms\": 9747.042, \"total_train_time_s\": 12.632000207901001}", "{\"n\": 1139, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.6, \"learn_time_ms\": 9715.509, \"total_train_time_s\": 13.356214761734009}", "{\"n\": 1140, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.82, \"learn_time_ms\": 9705.661, \"total_train_time_s\": 13.161521911621094}", "{\"n\": 1141, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3058.45, \"learn_time_ms\": 9826.408, \"total_train_time_s\": 13.996816873550415}", "{\"n\": 1142, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.03, \"learn_time_ms\": 9819.767, \"total_train_time_s\": 13.81594181060791}", "{\"n\": 1143, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.03, \"learn_time_ms\": 9791.494, \"total_train_time_s\": 13.190420389175415}", "{\"n\": 1144, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3064.08, \"learn_time_ms\": 9854.312, \"total_train_time_s\": 14.382968187332153}", "{\"n\": 1145, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3068.44, \"learn_time_ms\": 9908.821, \"total_train_time_s\": 14.04369306564331}", "{\"n\": 1146, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3068.86, \"learn_time_ms\": 9957.727, \"total_train_time_s\": 14.491698026657104}", "{\"n\": 1147, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3061.25, \"learn_time_ms\": 10017.026, \"total_train_time_s\": 14.323323965072632}", "{\"n\": 1148, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3060.59, \"learn_time_ms\": 10136.604, \"total_train_time_s\": 13.871886968612671}", "{\"n\": 1149, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3053.92, \"learn_time_ms\": 10241.294, \"total_train_time_s\": 14.054691076278687}", "{\"n\": 1150, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3053.92, \"learn_time_ms\": 10353.128, \"total_train_time_s\": 14.234732627868652}", "{\"n\": 1151, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3066.52, \"learn_time_ms\": 10466.61, \"total_train_time_s\": 15.050771713256836}", "{\"n\": 1152, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3066.52, \"learn_time_ms\": 10401.342, \"total_train_time_s\": 13.310851812362671}", "{\"n\": 1153, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3066.52, \"learn_time_ms\": 10472.914, \"total_train_time_s\": 14.069186925888062}", "{\"n\": 1154, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3068.47, \"learn_time_ms\": 10419.519, \"total_train_time_s\": 13.798040628433228}", "{\"n\": 1155, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3062.25, \"learn_time_ms\": 10392.294, \"total_train_time_s\": 13.756388902664185}", "{\"n\": 1156, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3064.86, \"learn_time_ms\": 10371.585, \"total_train_time_s\": 14.118682146072388}", "{\"n\": 1157, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.19, \"learn_time_ms\": 10334.768, \"total_train_time_s\": 13.792542457580566}", "{\"n\": 1158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3039.17, \"learn_time_ms\": 10221.159, \"total_train_time_s\": 12.54563307762146}", "{\"n\": 1159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.61, \"learn_time_ms\": 10206.614, \"total_train_time_s\": 13.921064376831055}", "{\"n\": 1160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3047.45, \"learn_time_ms\": 10224.096, \"total_train_time_s\": 14.279242277145386}", "{\"n\": 1161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3047.45, \"learn_time_ms\": 10112.748, \"total_train_time_s\": 14.130885601043701}", "{\"n\": 1162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.65, \"learn_time_ms\": 10209.239, \"total_train_time_s\": 14.134255647659302}", "{\"n\": 1163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.06, \"learn_time_ms\": 10182.682, \"total_train_time_s\": 13.649286270141602}", "{\"n\": 1164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3024.1, \"learn_time_ms\": 10191.516, \"total_train_time_s\": 13.928651094436646}", "{\"n\": 1165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.27, \"learn_time_ms\": 10093.894, \"total_train_time_s\": 12.783036231994629}", "{\"n\": 1166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3026.2, \"learn_time_ms\": 10143.747, \"total_train_time_s\": 14.89052438735962}", "{\"n\": 1167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.72, \"learn_time_ms\": 10109.157, \"total_train_time_s\": 13.336295127868652}", "{\"n\": 1168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.72, \"learn_time_ms\": 10156.641, \"total_train_time_s\": 13.001698970794678}", "{\"n\": 1169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.61, \"learn_time_ms\": 10168.655, \"total_train_time_s\": 14.157651901245117}", "{\"n\": 1170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.98, \"learn_time_ms\": 10131.33, \"total_train_time_s\": 14.020978450775146}", "{\"n\": 1171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.44, \"learn_time_ms\": 10047.302, \"total_train_time_s\": 13.121184825897217}", "{\"n\": 1172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3031.6, \"learn_time_ms\": 10033.981, \"total_train_time_s\": 14.326236963272095}", "{\"n\": 1173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.4, \"learn_time_ms\": 10056.456, \"total_train_time_s\": 13.784212350845337}", "{\"n\": 1174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.2, \"learn_time_ms\": 10029.139, \"total_train_time_s\": 13.719963550567627}", "{\"n\": 1175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3061.88, \"learn_time_ms\": 10002.076, \"total_train_time_s\": 12.632071733474731}", "{\"n\": 1176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3064.34, \"learn_time_ms\": 9953.701, \"total_train_time_s\": 14.101122856140137}", "{\"n\": 1177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3066.83, \"learn_time_ms\": 9987.286, \"total_train_time_s\": 13.664822101593018}", "{\"n\": 1178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3056.48, \"learn_time_ms\": 9961.157, \"total_train_time_s\": 12.761276721954346}", "{\"n\": 1179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3056.48, \"learn_time_ms\": 9972.626, \"total_train_time_s\": 14.245357275009155}", "{\"n\": 1180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3056.48, \"learn_time_ms\": 9970.334, \"total_train_time_s\": 13.821681499481201}", "{\"n\": 1181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3060.17, \"learn_time_ms\": 10129.639, \"total_train_time_s\": 14.804157495498657}", "{\"n\": 1182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3060.17, \"learn_time_ms\": 10110.811, \"total_train_time_s\": 13.824132919311523}", "{\"n\": 1183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3061.21, \"learn_time_ms\": 10082.161, \"total_train_time_s\": 13.646406888961792}", "{\"n\": 1184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3061.21, \"learn_time_ms\": 10073.939, \"total_train_time_s\": 13.770894765853882}", "{\"n\": 1185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3043.39, \"learn_time_ms\": 10170.827, \"total_train_time_s\": 13.493615627288818}", "{\"n\": 1186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3043.39, \"learn_time_ms\": 10045.151, \"total_train_time_s\": 12.896194696426392}", "{\"n\": 1187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3035.55, \"learn_time_ms\": 10029.909, \"total_train_time_s\": 13.592566728591919}", "{\"n\": 1188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.56, \"learn_time_ms\": 10079.115, \"total_train_time_s\": 13.359933614730835}", "{\"n\": 1189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.75, \"learn_time_ms\": 10035.624, \"total_train_time_s\": 13.923881530761719}", "{\"n\": 1190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.75, \"learn_time_ms\": 9943.569, \"total_train_time_s\": 13.028724431991577}", "{\"n\": 1191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.08, \"learn_time_ms\": 9878.722, \"total_train_time_s\": 14.085017919540405}", "{\"n\": 1192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.09, \"learn_time_ms\": 9822.091, \"total_train_time_s\": 13.580289840698242}", "{\"n\": 1193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.09, \"learn_time_ms\": 9835.768, \"total_train_time_s\": 13.748143672943115}", "{\"n\": 1194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3027.74, \"learn_time_ms\": 9825.258, \"total_train_time_s\": 13.534116268157959}", "{\"n\": 1195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.73, \"learn_time_ms\": 9900.536, \"total_train_time_s\": 14.222593307495117}", "{\"n\": 1196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.9, \"learn_time_ms\": 9945.226, \"total_train_time_s\": 13.237244129180908}", "{\"n\": 1197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.12, \"learn_time_ms\": 10010.082, \"total_train_time_s\": 14.270391941070557}", "{\"n\": 1198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3039.58, \"learn_time_ms\": 10057.119, \"total_train_time_s\": 13.710790872573853}", "{\"n\": 1199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3053.58, \"learn_time_ms\": 9925.084, \"total_train_time_s\": 12.416685581207275}", "{\"n\": 1200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3059.4, \"learn_time_ms\": 9984.474, \"total_train_time_s\": 13.696442365646362}"]