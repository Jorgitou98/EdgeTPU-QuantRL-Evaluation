["{\"n\": 7249, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11075.31, \"total_train_time_s\": 14.786371231079102}", "{\"n\": 7250, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10623.628, \"total_train_time_s\": 13.699827909469604}", "{\"n\": 7251, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10739.157, \"total_train_time_s\": 14.484182834625244}", "{\"n\": 7252, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11058.283, \"total_train_time_s\": 15.59007740020752}", "{\"n\": 7253, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11041.813, \"total_train_time_s\": 14.889317274093628}", "{\"n\": 7254, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11085.649, \"total_train_time_s\": 15.21885061264038}", "{\"n\": 7255, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3637.6666666666665, \"learn_time_ms\": 11086.946, \"total_train_time_s\": 14.96446681022644}", "{\"n\": 7256, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3637.6666666666665, \"learn_time_ms\": 11020.769, \"total_train_time_s\": 14.375472068786621}", "{\"n\": 7257, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3619.75, \"learn_time_ms\": 10998.108, \"total_train_time_s\": 14.665371179580688}", "{\"n\": 7258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3439.4, \"learn_time_ms\": 10976.795, \"total_train_time_s\": 14.485737085342407}", "{\"n\": 7259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3310.5714285714284, \"learn_time_ms\": 10886.901, \"total_train_time_s\": 13.807923316955566}", "{\"n\": 7260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3493.25, \"learn_time_ms\": 10900.68, \"total_train_time_s\": 13.953920364379883}", "{\"n\": 7261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3493.25, \"learn_time_ms\": 10915.279, \"total_train_time_s\": 14.68931794166565}", "{\"n\": 7262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.090909090909091, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.909090909091, \"learn_time_ms\": 10769.108, \"total_train_time_s\": 14.156927824020386}", "{\"n\": 7263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.090909090909091, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.909090909091, \"learn_time_ms\": 10666.429, \"total_train_time_s\": 13.763651371002197}", "{\"n\": 7264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6666666666666665, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3496.5833333333335, \"learn_time_ms\": 10590.121, \"total_train_time_s\": 14.449944496154785}", "{\"n\": 7265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6666666666666665, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3496.5833333333335, \"learn_time_ms\": 10503.579, \"total_train_time_s\": 14.028154134750366}", "{\"n\": 7266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3492.6666666666665, \"learn_time_ms\": 10618.401, \"total_train_time_s\": 15.317418813705444}", "{\"n\": 7267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3492.6666666666665, \"learn_time_ms\": 10611.059, \"total_train_time_s\": 14.638972520828247}", "{\"n\": 7268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.5, \"learn_time_ms\": 10630.641, \"total_train_time_s\": 14.680951833724976}", "{\"n\": 7269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7777777777777777, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3561.5, \"learn_time_ms\": 10729.548, \"total_train_time_s\": 15.084357023239136}", "{\"n\": 7270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.631578947368421, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.0526315789475, \"learn_time_ms\": 10786.798, \"total_train_time_s\": 14.75437045097351}", "{\"n\": 7271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.631578947368421, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.0526315789475, \"learn_time_ms\": 10675.327, \"total_train_time_s\": 14.098974466323853}", "{\"n\": 7272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.7, \"learn_time_ms\": 10864.105, \"total_train_time_s\": 16.186437129974365}", "{\"n\": 7273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.380952380952381, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.190476190476, \"learn_time_ms\": 10954.154, \"total_train_time_s\": 14.68351697921753}", "{\"n\": 7274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9565217391304348, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.6521739130435, \"learn_time_ms\": 10948.526, \"total_train_time_s\": 14.223830699920654}", "{\"n\": 7275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1666666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.875, \"learn_time_ms\": 11138.514, \"total_train_time_s\": 16.071407556533813}", "{\"n\": 7276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1666666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.875, \"learn_time_ms\": 10966.789, \"total_train_time_s\": 13.582531213760376}", "{\"n\": 7277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9259259259259259, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.4074074074074, \"learn_time_ms\": 10915.607, \"total_train_time_s\": 13.88190245628357}", "{\"n\": 7278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9259259259259259, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.4074074074074, \"learn_time_ms\": 10903.488, \"total_train_time_s\": 14.59687614440918}", "{\"n\": 7279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.964285714286, \"learn_time_ms\": 10956.316, \"total_train_time_s\": 15.462499856948853}", "{\"n\": 7280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.4333333333334, \"learn_time_ms\": 10915.894, \"total_train_time_s\": 14.132683992385864}", "{\"n\": 7281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.4333333333334, \"learn_time_ms\": 11050.916, \"total_train_time_s\": 15.218307733535767}", "{\"n\": 7282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.9354838709677419, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.7419354838707, \"learn_time_ms\": 10788.369, \"total_train_time_s\": 13.665025234222412}", "{\"n\": 7283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.09375, \"learn_time_ms\": 10666.276, \"total_train_time_s\": 13.301517963409424}", "{\"n\": 7284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.6176470588234, \"learn_time_ms\": 10627.469, \"total_train_time_s\": 13.954864263534546}", "{\"n\": 7285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.6176470588234, \"learn_time_ms\": 10520.935, \"total_train_time_s\": 15.134698152542114}", "{\"n\": 7286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6111111111111112, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.8055555555557, \"learn_time_ms\": 10505.544, \"total_train_time_s\": 13.45716643333435}", "{\"n\": 7287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6111111111111112, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.8055555555557, \"learn_time_ms\": 10507.082, \"total_train_time_s\": 13.84044337272644}", "{\"n\": 7288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5897435897435896, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.358974358974, \"learn_time_ms\": 10563.079, \"total_train_time_s\": 15.281448602676392}", "{\"n\": 7289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.275, \"learn_time_ms\": 10439.829, \"total_train_time_s\": 14.059271574020386}", "{\"n\": 7290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.275, \"learn_time_ms\": 10571.796, \"total_train_time_s\": 15.60018253326416}", "{\"n\": 7291, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.073170731707317, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.9756097560976, \"learn_time_ms\": 10484.699, \"total_train_time_s\": 14.35400104522705}", "{\"n\": 7292, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.0232558139534884, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.0232558139537, \"learn_time_ms\": 10577.655, \"total_train_time_s\": 14.622575521469116}", "{\"n\": 7293, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.9318181818181819, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.590909090909, \"learn_time_ms\": 10682.326, \"total_train_time_s\": 14.334646224975586}", "{\"n\": 7294, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.9318181818181819, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.590909090909, \"learn_time_ms\": 10787.237, \"total_train_time_s\": 14.788235902786255}", "{\"n\": 7295, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6521739130434783, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.782608695652, \"learn_time_ms\": 10794.775, \"total_train_time_s\": 14.83741307258606}", "{\"n\": 7296, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4893617021276595, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.9574468085107, \"learn_time_ms\": 10762.19, \"total_train_time_s\": 13.149386644363403}", "{\"n\": 7297, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4166666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.5625, \"learn_time_ms\": 10796.389, \"total_train_time_s\": 14.485151529312134}", "{\"n\": 7298, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2653061224489797, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.816326530612, \"learn_time_ms\": 10672.283, \"total_train_time_s\": 14.058212041854858}", "{\"n\": 7299, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2653061224489797, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.816326530612, \"learn_time_ms\": 10753.876, \"total_train_time_s\": 15.085493803024292}", "{\"n\": 7300, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2352941176470589, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.843137254902, \"learn_time_ms\": 10661.845, \"total_train_time_s\": 14.731754541397095}", "{\"n\": 7301, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.1538461538461537, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.8076923076924, \"learn_time_ms\": 10696.545, \"total_train_time_s\": 14.573731660842896}", "{\"n\": 7302, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.320754716981132, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.811320754717, \"learn_time_ms\": 10676.085, \"total_train_time_s\": 14.236361265182495}", "{\"n\": 7303, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3703703703703705, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.925925925926, \"learn_time_ms\": 10623.359, \"total_train_time_s\": 13.697617292404175}", "{\"n\": 7304, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.290909090909091, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.1272727272726, \"learn_time_ms\": 10547.287, \"total_train_time_s\": 14.150965452194214}", "{\"n\": 7305, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2456140350877194, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.8596491228072, \"learn_time_ms\": 10417.486, \"total_train_time_s\": 13.844140529632568}", "{\"n\": 7306, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3620689655172413, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3666.0172413793102, \"learn_time_ms\": 10522.067, \"total_train_time_s\": 14.40372371673584}", "{\"n\": 7307, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.271186440677966, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.4745762711864, \"learn_time_ms\": 10560.864, \"total_train_time_s\": 14.856294870376587}", "{\"n\": 7308, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4166666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.2833333333333, \"learn_time_ms\": 10640.505, \"total_train_time_s\": 14.726635456085205}", "{\"n\": 7309, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4098360655737705, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.901639344262, \"learn_time_ms\": 10502.009, \"total_train_time_s\": 13.70149850845337}", "{\"n\": 7310, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5161290322580645, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.1129032258063, \"learn_time_ms\": 10442.237, \"total_train_time_s\": 14.121015310287476}", "{\"n\": 7311, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4126984126984128, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.3174603174602, \"learn_time_ms\": 10455.62, \"total_train_time_s\": 14.843406200408936}", "{\"n\": 7312, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.578125, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.875, \"learn_time_ms\": 10520.275, \"total_train_time_s\": 14.823397636413574}", "{\"n\": 7313, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.606060606060606, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.3939393939395, \"learn_time_ms\": 10559.085, \"total_train_time_s\": 14.231133460998535}", "{\"n\": 7314, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.606060606060606, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.3939393939395, \"learn_time_ms\": 10564.41, \"total_train_time_s\": 14.160080194473267}", "{\"n\": 7315, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5588235294117647, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.1323529411766, \"learn_time_ms\": 10711.584, \"total_train_time_s\": 15.139591932296753}", "{\"n\": 7316, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5588235294117647, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.1323529411766, \"learn_time_ms\": 10812.882, \"total_train_time_s\": 15.267907619476318}", "{\"n\": 7317, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6142857142857143, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.442857142857, \"learn_time_ms\": 10790.209, \"total_train_time_s\": 14.523049592971802}", "{\"n\": 7318, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6901408450704225, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.605633802817, \"learn_time_ms\": 10838.709, \"total_train_time_s\": 15.348851919174194}", "{\"n\": 7319, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5833333333333333, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.7916666666665, \"learn_time_ms\": 10799.398, \"total_train_time_s\": 13.130754232406616}", "{\"n\": 7320, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6027397260273972, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.6301369863013, \"learn_time_ms\": 10731.05, \"total_train_time_s\": 13.212158918380737}", "{\"n\": 7321, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5405405405405406, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.9189189189187, \"learn_time_ms\": 10631.032, \"total_train_time_s\": 13.763470888137817}", "{\"n\": 7322, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3866666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.88, \"learn_time_ms\": 10592.025, \"total_train_time_s\": 14.51429533958435}", "{\"n\": 7323, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.355263157894737, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.815789473684, \"learn_time_ms\": 10730.26, \"total_train_time_s\": 15.510885000228882}", "{\"n\": 7324, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3205128205128205, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.7820512820513, \"learn_time_ms\": 10782.961, \"total_train_time_s\": 14.694478511810303}", "{\"n\": 7325, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2784810126582278, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.481012658228, \"learn_time_ms\": 10862.864, \"total_train_time_s\": 15.770236015319824}", "{\"n\": 7326, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.2784810126582278, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.481012658228, \"learn_time_ms\": 10754.014, \"total_train_time_s\": 14.292679071426392}", "{\"n\": 7327, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4146341463414633, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.743902439024, \"learn_time_ms\": 10781.002, \"total_train_time_s\": 14.792485475540161}", "{\"n\": 7328, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4096385542168675, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.9277108433735, \"learn_time_ms\": 10697.163, \"total_train_time_s\": 14.589691400527954}", "{\"n\": 7329, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4096385542168675, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.9277108433735, \"learn_time_ms\": 10778.599, \"total_train_time_s\": 14.1269052028656}", "{\"n\": 7330, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4642857142857142, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.845238095238, \"learn_time_ms\": 10955.663, \"total_train_time_s\": 15.068649053573608}", "{\"n\": 7331, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6744186046511629, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.2558139534885, \"learn_time_ms\": 11082.6, \"total_train_time_s\": 15.213484764099121}", "{\"n\": 7332, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.7586206896551724, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.425287356322, \"learn_time_ms\": 11032.206, \"total_train_time_s\": 13.96030306816101}", "{\"n\": 7333, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.7586206896551724, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.425287356322, \"learn_time_ms\": 11032.124, \"total_train_time_s\": 15.74506163597107}", "{\"n\": 7334, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6931818181818181, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.090909090909, \"learn_time_ms\": 11071.617, \"total_train_time_s\": 15.11981725692749}", "{\"n\": 7335, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6923076923076923, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.3296703296705, \"learn_time_ms\": 10910.201, \"total_train_time_s\": 14.320043087005615}", "{\"n\": 7336, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6923076923076923, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.3296703296705, \"learn_time_ms\": 10905.014, \"total_train_time_s\": 14.116469383239746}", "{\"n\": 7337, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6923076923076923, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.3296703296705, \"learn_time_ms\": 10873.81, \"total_train_time_s\": 14.41335415840149}", "{\"n\": 7338, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.6666666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.064516129032, \"learn_time_ms\": 11015.15, \"total_train_time_s\": 15.890639543533325}", "{\"n\": 7339, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5157894736842106, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.5157894736844, \"learn_time_ms\": 11037.834, \"total_train_time_s\": 14.301550388336182}", "{\"n\": 7340, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5157894736842106, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.5157894736844, \"learn_time_ms\": 10974.218, \"total_train_time_s\": 14.435707807540894}", "{\"n\": 7341, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5157894736842106, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.5157894736844, \"learn_time_ms\": 10843.497, \"total_train_time_s\": 13.524309873580933}", "{\"n\": 7342, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3775510204081634, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.122448979592, \"learn_time_ms\": 10927.036, \"total_train_time_s\": 14.75271487236023}", "{\"n\": 7343, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3434343434343434, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.6161616161617, \"learn_time_ms\": 10690.36, \"total_train_time_s\": 13.115781307220459}", "{\"n\": 7344, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.3434343434343434, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.6161616161617, \"learn_time_ms\": 10607.42, \"total_train_time_s\": 14.163265228271484}", "{\"n\": 7345, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.92, \"learn_time_ms\": 10609.004, \"total_train_time_s\": 14.260010480880737}", "{\"n\": 7346, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.1, \"learn_time_ms\": 10554.544, \"total_train_time_s\": 13.703155279159546}", "{\"n\": 7347, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.61, \"learn_time_ms\": 10510.701, \"total_train_time_s\": 13.974397897720337}", "{\"n\": 7348, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.61, \"learn_time_ms\": 10327.236, \"total_train_time_s\": 14.099558591842651}", "{\"n\": 7349, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.56, \"learn_time_ms\": 10174.375, \"total_train_time_s\": 12.664115905761719}", "{\"n\": 7350, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.64, \"learn_time_ms\": 10126.283, \"total_train_time_s\": 13.859825849533081}", "{\"n\": 7351, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.01, \"learn_time_ms\": 10215.208, \"total_train_time_s\": 14.459679365158081}", "{\"n\": 7352, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.7, \"learn_time_ms\": 10082.426, \"total_train_time_s\": 13.625718832015991}", "{\"n\": 7353, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.03, \"learn_time_ms\": 10297.918, \"total_train_time_s\": 15.46972918510437}", "{\"n\": 7354, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.03, \"learn_time_ms\": 10256.834, \"total_train_time_s\": 13.909141063690186}", "{\"n\": 7355, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.46, \"learn_time_ms\": 10300.605, \"total_train_time_s\": 14.79260516166687}", "{\"n\": 7356, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3680.68, \"learn_time_ms\": 10453.479, \"total_train_time_s\": 15.12172269821167}", "{\"n\": 7357, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3680.68, \"learn_time_ms\": 10476.473, \"total_train_time_s\": 14.18910002708435}", "{\"n\": 7358, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.69, \"learn_time_ms\": 10540.499, \"total_train_time_s\": 14.492975950241089}", "{\"n\": 7359, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.29, \"learn_time_ms\": 10697.109, \"total_train_time_s\": 14.608896493911743}", "{\"n\": 7360, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.29, \"learn_time_ms\": 10646.572, \"total_train_time_s\": 13.590116500854492}", "{\"n\": 7361, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.29, \"learn_time_ms\": 10725.99, \"total_train_time_s\": 15.4588463306427}", "{\"n\": 7362, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.69, \"learn_time_ms\": 10793.626, \"total_train_time_s\": 14.14609169960022}", "{\"n\": 7363, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.69, \"learn_time_ms\": 10750.209, \"total_train_time_s\": 15.022258043289185}", "{\"n\": 7364, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.69, \"learn_time_ms\": 10804.815, \"total_train_time_s\": 14.43408727645874}", "{\"n\": 7365, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3672.24, \"learn_time_ms\": 10712.934, \"total_train_time_s\": 13.801741123199463}", "{\"n\": 7366, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3676.22, \"learn_time_ms\": 10598.253, \"total_train_time_s\": 13.964586019515991}", "{\"n\": 7367, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.46, \"learn_time_ms\": 10628.088, \"total_train_time_s\": 14.639870405197144}", "{\"n\": 7368, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.46, \"learn_time_ms\": 10651.85, \"total_train_time_s\": 14.830683469772339}", "{\"n\": 7369, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.35, \"learn_time_ms\": 10617.496, \"total_train_time_s\": 14.129345655441284}", "{\"n\": 7370, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.42, \"learn_time_ms\": 10822.021, \"total_train_time_s\": 15.56091022491455}", "{\"n\": 7371, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.42, \"learn_time_ms\": 10700.411, \"total_train_time_s\": 13.99377703666687}", "{\"n\": 7372, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.67, \"learn_time_ms\": 10741.01, \"total_train_time_s\": 14.964624881744385}", "{\"n\": 7373, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3666.57, \"learn_time_ms\": 10691.093, \"total_train_time_s\": 14.342100620269775}", "{\"n\": 7374, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.59, \"learn_time_ms\": 10685.856, \"total_train_time_s\": 14.526927947998047}", "{\"n\": 7375, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.59, \"learn_time_ms\": 10853.936, \"total_train_time_s\": 15.34161114692688}", "{\"n\": 7376, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.68, \"learn_time_ms\": 10925.463, \"total_train_time_s\": 14.606111288070679}", "{\"n\": 7377, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.67, \"learn_time_ms\": 10924.131, \"total_train_time_s\": 14.473004579544067}", "{\"n\": 7378, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.67, \"learn_time_ms\": 10821.744, \"total_train_time_s\": 13.87308669090271}", "{\"n\": 7379, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.67, \"learn_time_ms\": 10914.346, \"total_train_time_s\": 14.989920377731323}", "{\"n\": 7380, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3640.73, \"learn_time_ms\": 10945.5, \"total_train_time_s\": 15.804704189300537}", "{\"n\": 7381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3657.01, \"learn_time_ms\": 10833.308, \"total_train_time_s\": 13.0427565574646}", "{\"n\": 7382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3657.01, \"learn_time_ms\": 10788.945, \"total_train_time_s\": 14.148562908172607}", "{\"n\": 7383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3666.55, \"learn_time_ms\": 10793.617, \"total_train_time_s\": 14.454567432403564}", "{\"n\": 7384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.55, \"learn_time_ms\": 10723.77, \"total_train_time_s\": 13.656089067459106}", "{\"n\": 7385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3655.88, \"learn_time_ms\": 10576.995, \"total_train_time_s\": 14.379339933395386}", "{\"n\": 7386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3655.88, \"learn_time_ms\": 10536.744, \"total_train_time_s\": 14.20840859413147}", "{\"n\": 7387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.22, \"learn_time_ms\": 10570.72, \"total_train_time_s\": 14.963409185409546}", "{\"n\": 7388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.16, \"learn_time_ms\": 10566.048, \"total_train_time_s\": 13.604809761047363}", "{\"n\": 7389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.37, \"learn_time_ms\": 10502.271, \"total_train_time_s\": 14.240265130996704}", "{\"n\": 7390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.37, \"learn_time_ms\": 10420.151, \"total_train_time_s\": 15.188447713851929}", "{\"n\": 7391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.42, \"learn_time_ms\": 10525.061, \"total_train_time_s\": 13.892365455627441}", "{\"n\": 7392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.48, \"learn_time_ms\": 10627.51, \"total_train_time_s\": 15.12455153465271}", "{\"n\": 7393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.74, \"learn_time_ms\": 10678.957, \"total_train_time_s\": 15.037219285964966}", "{\"n\": 7394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.47, \"learn_time_ms\": 10732.488, \"total_train_time_s\": 14.08412790298462}", "{\"n\": 7395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 10744.407, \"total_train_time_s\": 14.364954710006714}", "{\"n\": 7396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 10775.666, \"total_train_time_s\": 14.702504396438599}", "{\"n\": 7397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.38, \"learn_time_ms\": 10803.592, \"total_train_time_s\": 15.441722631454468}", "{\"n\": 7398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.38, \"learn_time_ms\": 10978.623, \"total_train_time_s\": 15.587969064712524}", "{\"n\": 7399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.14, \"learn_time_ms\": 10966.17, \"total_train_time_s\": 14.340668439865112}", "{\"n\": 7400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.8, \"learn_time_ms\": 10883.643, \"total_train_time_s\": 14.047269105911255}", "{\"n\": 7401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.8, \"learn_time_ms\": 11054.722, \"total_train_time_s\": 15.993250846862793}", "{\"n\": 7402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.91, \"learn_time_ms\": 11041.238, \"total_train_time_s\": 15.23356819152832}", "{\"n\": 7403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.91, \"learn_time_ms\": 10950.606, \"total_train_time_s\": 14.241530179977417}", "{\"n\": 7404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.86, \"learn_time_ms\": 11037.788, \"total_train_time_s\": 15.343716621398926}", "{\"n\": 7405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.86, \"learn_time_ms\": 10968.119, \"total_train_time_s\": 13.237314224243164}", "{\"n\": 7406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.31, \"learn_time_ms\": 10934.149, \"total_train_time_s\": 14.289661407470703}", "{\"n\": 7407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.66, \"learn_time_ms\": 10851.997, \"total_train_time_s\": 14.420828104019165}", "{\"n\": 7408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.55, \"learn_time_ms\": 10645.228, \"total_train_time_s\": 13.403874635696411}", "{\"n\": 7409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.58, \"learn_time_ms\": 10754.174, \"total_train_time_s\": 15.15827989578247}", "{\"n\": 7410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.35, \"learn_time_ms\": 10813.283, \"total_train_time_s\": 14.644545078277588}", "{\"n\": 7411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.74, \"learn_time_ms\": 10703.236, \"total_train_time_s\": 14.513400077819824}", "{\"n\": 7412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.81, \"learn_time_ms\": 10556.238, \"total_train_time_s\": 13.554078817367554}", "{\"n\": 7413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.81, \"learn_time_ms\": 10570.782, \"total_train_time_s\": 14.394400119781494}", "{\"n\": 7414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.73, \"learn_time_ms\": 10494.305, \"total_train_time_s\": 14.349161148071289}", "{\"n\": 7415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.73, \"learn_time_ms\": 10672.081, \"total_train_time_s\": 15.534558773040771}", "{\"n\": 7416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.66, \"learn_time_ms\": 10745.516, \"total_train_time_s\": 15.327056407928467}", "{\"n\": 7417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.89, \"learn_time_ms\": 10809.639, \"total_train_time_s\": 15.114748477935791}", "{\"n\": 7418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.25, \"learn_time_ms\": 11015.707, \"total_train_time_s\": 15.604502439498901}", "{\"n\": 7419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.98, \"learn_time_ms\": 10855.682, \"total_train_time_s\": 13.87099838256836}", "{\"n\": 7420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.97, \"learn_time_ms\": 10867.137, \"total_train_time_s\": 14.895668029785156}", "{\"n\": 7421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.96, \"learn_time_ms\": 10985.983, \"total_train_time_s\": 15.986199855804443}", "{\"n\": 7422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.96, \"learn_time_ms\": 11045.657, \"total_train_time_s\": 14.19377613067627}", "{\"n\": 7423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.73, \"learn_time_ms\": 11141.49, \"total_train_time_s\": 15.362442970275879}", "{\"n\": 7424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.47, \"learn_time_ms\": 11206.72, \"total_train_time_s\": 14.868772983551025}", "{\"n\": 7425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.66, \"learn_time_ms\": 11098.211, \"total_train_time_s\": 14.179329633712769}", "{\"n\": 7426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.31, \"learn_time_ms\": 11075.328, \"total_train_time_s\": 14.766688108444214}", "{\"n\": 7427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.31, \"learn_time_ms\": 11017.397, \"total_train_time_s\": 14.342592239379883}", "{\"n\": 7428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.65, \"learn_time_ms\": 10911.817, \"total_train_time_s\": 14.637628078460693}", "{\"n\": 7429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.54, \"learn_time_ms\": 11007.367, \"total_train_time_s\": 14.745401382446289}", "{\"n\": 7430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.04, \"learn_time_ms\": 10908.809, \"total_train_time_s\": 14.065148830413818}", "{\"n\": 7431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.73, \"learn_time_ms\": 10673.264, \"total_train_time_s\": 13.613191366195679}", "{\"n\": 7432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.1, \"learn_time_ms\": 10617.326, \"total_train_time_s\": 13.674493074417114}", "{\"n\": 7433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.68, \"learn_time_ms\": 10599.395, \"total_train_time_s\": 15.199230909347534}", "{\"n\": 7434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.68, \"learn_time_ms\": 10525.217, \"total_train_time_s\": 14.650957822799683}", "{\"n\": 7435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.91, \"learn_time_ms\": 10567.454, \"total_train_time_s\": 14.477919101715088}", "{\"n\": 7436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.91, \"learn_time_ms\": 10482.025, \"total_train_time_s\": 13.853896617889404}", "{\"n\": 7437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.84, \"learn_time_ms\": 10474.667, \"total_train_time_s\": 14.442567110061646}", "{\"n\": 7438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.84, \"learn_time_ms\": 10563.364, \"total_train_time_s\": 15.316505908966064}", "{\"n\": 7439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.44, \"learn_time_ms\": 10575.243, \"total_train_time_s\": 14.817384243011475}", "{\"n\": 7440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3541.58, \"learn_time_ms\": 10735.698, \"total_train_time_s\": 15.463762283325195}", "{\"n\": 7441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3541.17, \"learn_time_ms\": 10755.469, \"total_train_time_s\": 13.580007076263428}", "{\"n\": 7442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3541.17, \"learn_time_ms\": 10810.625, \"total_train_time_s\": 14.288143157958984}", "{\"n\": 7443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.42, \"learn_time_ms\": 10735.656, \"total_train_time_s\": 14.319059610366821}", "{\"n\": 7444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.83, \"learn_time_ms\": 10683.785, \"total_train_time_s\": 13.727227210998535}", "{\"n\": 7445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.83, \"learn_time_ms\": 10634.41, \"total_train_time_s\": 14.192525386810303}", "{\"n\": 7446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.83, \"learn_time_ms\": 10664.661, \"total_train_time_s\": 14.269165992736816}", "{\"n\": 7447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.83, \"learn_time_ms\": 10638.548, \"total_train_time_s\": 14.358026027679443}", "{\"n\": 7448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.5, \"learn_time_ms\": 10519.98, \"total_train_time_s\": 13.998535633087158}", "{\"n\": 7449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.5, \"learn_time_ms\": 10447.34, \"total_train_time_s\": 14.231891870498657}", "{\"n\": 7450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.5, \"learn_time_ms\": 10238.483, \"total_train_time_s\": 13.254504919052124}", "{\"n\": 7451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.7, \"learn_time_ms\": 10246.652, \"total_train_time_s\": 13.934518575668335}", "{\"n\": 7452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.07, \"learn_time_ms\": 10252.042, \"total_train_time_s\": 14.098931074142456}", "{\"n\": 7453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.07, \"learn_time_ms\": 10238.293, \"total_train_time_s\": 14.135746240615845}", "{\"n\": 7454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.89, \"learn_time_ms\": 10402.542, \"total_train_time_s\": 15.480901718139648}", "{\"n\": 7455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.19, \"learn_time_ms\": 10505.247, \"total_train_time_s\": 14.961776733398438}", "{\"n\": 7456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.4, \"learn_time_ms\": 10457.625, \"total_train_time_s\": 13.709963321685791}", "{\"n\": 7457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.4, \"learn_time_ms\": 10511.674, \"total_train_time_s\": 14.465051889419556}", "{\"n\": 7458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.39, \"learn_time_ms\": 10565.067, \"total_train_time_s\": 14.611440420150757}", "{\"n\": 7459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.39, \"learn_time_ms\": 10571.206, \"total_train_time_s\": 14.474204301834106}", "{\"n\": 7460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.86, \"learn_time_ms\": 10635.1, \"total_train_time_s\": 14.05146074295044}", "{\"n\": 7461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.86, \"learn_time_ms\": 10715.105, \"total_train_time_s\": 14.44058609008789}", "{\"n\": 7462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.99, \"learn_time_ms\": 10756.291, \"total_train_time_s\": 14.65611743927002}", "{\"n\": 7463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.76, \"learn_time_ms\": 10895.332, \"total_train_time_s\": 15.597823858261108}", "{\"n\": 7464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.86, \"learn_time_ms\": 10856.407, \"total_train_time_s\": 15.089030265808105}", "{\"n\": 7465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.86, \"learn_time_ms\": 10804.287, \"total_train_time_s\": 14.630365133285522}", "{\"n\": 7466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.53, \"learn_time_ms\": 10899.835, \"total_train_time_s\": 14.709262132644653}", "{\"n\": 7467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.35, \"learn_time_ms\": 10985.334, \"total_train_time_s\": 15.33045482635498}", "{\"n\": 7468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.26, \"learn_time_ms\": 10864.62, \"total_train_time_s\": 13.62242078781128}", "{\"n\": 7469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.26, \"learn_time_ms\": 10943.335, \"total_train_time_s\": 15.067224025726318}", "{\"n\": 7470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.31, \"learn_time_ms\": 11084.994, \"total_train_time_s\": 15.57214069366455}", "{\"n\": 7471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.31, \"learn_time_ms\": 11135.418, \"total_train_time_s\": 15.21981406211853}", "{\"n\": 7472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.63, \"learn_time_ms\": 11089.795, \"total_train_time_s\": 14.254331588745117}", "{\"n\": 7473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.45, \"learn_time_ms\": 10874.514, \"total_train_time_s\": 13.777013540267944}", "{\"n\": 7474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.88, \"learn_time_ms\": 10793.87, \"total_train_time_s\": 13.973857879638672}", "{\"n\": 7475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.88, \"learn_time_ms\": 10778.076, \"total_train_time_s\": 14.35810899734497}", "{\"n\": 7476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.49, \"learn_time_ms\": 10804.49, \"total_train_time_s\": 14.876408338546753}", "{\"n\": 7477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.16, \"learn_time_ms\": 10741.249, \"total_train_time_s\": 14.738443851470947}", "{\"n\": 7478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.16, \"learn_time_ms\": 10901.63, \"total_train_time_s\": 15.158529996871948}", "{\"n\": 7479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.43, \"learn_time_ms\": 10764.847, \"total_train_time_s\": 13.628710746765137}", "{\"n\": 7480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.68, \"learn_time_ms\": 10640.078, \"total_train_time_s\": 14.33966326713562}", "{\"n\": 7481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.34, \"learn_time_ms\": 10568.301, \"total_train_time_s\": 14.4580819606781}", "{\"n\": 7482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.34, \"learn_time_ms\": 10579.044, \"total_train_time_s\": 14.469701528549194}", "{\"n\": 7483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.34, \"learn_time_ms\": 10648.294, \"total_train_time_s\": 14.188606262207031}", "{\"n\": 7484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.97, \"learn_time_ms\": 10618.007, \"total_train_time_s\": 13.881067752838135}", "{\"n\": 7485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.02, \"learn_time_ms\": 10619.012, \"total_train_time_s\": 14.351737260818481}", "{\"n\": 7486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.02, \"learn_time_ms\": 10541.526, \"total_train_time_s\": 14.253795623779297}", "{\"n\": 7487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.02, \"learn_time_ms\": 10508.806, \"total_train_time_s\": 14.782278299331665}", "{\"n\": 7488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.85, \"learn_time_ms\": 10465.788, \"total_train_time_s\": 14.65264081954956}", "{\"n\": 7489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.9, \"learn_time_ms\": 10555.11, \"total_train_time_s\": 14.238036394119263}", "{\"n\": 7490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.9, \"learn_time_ms\": 10568.645, \"total_train_time_s\": 14.623862743377686}", "{\"n\": 7491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.9, \"learn_time_ms\": 10537.234, \"total_train_time_s\": 14.289890050888062}", "{\"n\": 7492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.15, \"learn_time_ms\": 10586.377, \"total_train_time_s\": 14.912841320037842}", "{\"n\": 7493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.15, \"learn_time_ms\": 10510.759, \"total_train_time_s\": 13.209311485290527}", "{\"n\": 7494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.15, \"learn_time_ms\": 10416.216, \"total_train_time_s\": 12.880982875823975}", "{\"n\": 7495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.79, \"learn_time_ms\": 10496.387, \"total_train_time_s\": 15.109223365783691}", "{\"n\": 7496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.48, \"learn_time_ms\": 10483.274, \"total_train_time_s\": 14.020796537399292}", "{\"n\": 7497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.48, \"learn_time_ms\": 10574.278, \"total_train_time_s\": 15.574888706207275}", "{\"n\": 7498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.8, \"learn_time_ms\": 10512.308, \"total_train_time_s\": 14.3397696018219}", "{\"n\": 7499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3659.71, \"learn_time_ms\": 10413.702, \"total_train_time_s\": 13.351303577423096}", "{\"n\": 7500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10451.915, \"total_train_time_s\": 14.581901788711548}", "{\"n\": 7501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10573.487, \"total_train_time_s\": 15.287104368209839}", "{\"n\": 7502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.72, \"learn_time_ms\": 10477.096, \"total_train_time_s\": 13.831400632858276}", "{\"n\": 7503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.18, \"learn_time_ms\": 10584.876, \"total_train_time_s\": 14.45097303390503}", "{\"n\": 7504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.46, \"learn_time_ms\": 10739.584, \"total_train_time_s\": 14.623411655426025}", "{\"n\": 7505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.1, \"learn_time_ms\": 10692.716, \"total_train_time_s\": 14.787795066833496}", "{\"n\": 7506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.1, \"learn_time_ms\": 10785.454, \"total_train_time_s\": 14.888752222061157}", "{\"n\": 7507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.21, \"learn_time_ms\": 10732.584, \"total_train_time_s\": 15.056514501571655}", "{\"n\": 7508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.44, \"learn_time_ms\": 10852.389, \"total_train_time_s\": 15.327681303024292}", "{\"n\": 7509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.44, \"learn_time_ms\": 10955.136, \"total_train_time_s\": 14.534806251525879}", "{\"n\": 7510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.44, \"learn_time_ms\": 11017.638, \"total_train_time_s\": 15.476866006851196}", "{\"n\": 7511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.24, \"learn_time_ms\": 10837.897, \"total_train_time_s\": 13.508625507354736}", "{\"n\": 7512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.38, \"learn_time_ms\": 11027.314, \"total_train_time_s\": 15.586061239242554}", "{\"n\": 7513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.38, \"learn_time_ms\": 10950.142, \"total_train_time_s\": 13.731906414031982}", "{\"n\": 7514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3648.29, \"learn_time_ms\": 10973.322, \"total_train_time_s\": 14.694349527359009}", "{\"n\": 7515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3647.46, \"learn_time_ms\": 11059.99, \"total_train_time_s\": 15.640153646469116}", "{\"n\": 7516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3647.46, \"learn_time_ms\": 11093.427, \"total_train_time_s\": 15.45608401298523}", "{\"n\": 7517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.7, \"learn_time_ms\": 11144.683, \"total_train_time_s\": 15.399803400039673}", "{\"n\": 7518, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.83, \"learn_time_ms\": 11252.02, \"total_train_time_s\": 16.43290901184082}", "{\"n\": 7519, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.2, \"learn_time_ms\": 11245.088, \"total_train_time_s\": 14.525978326797485}", "{\"n\": 7520, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.97, \"learn_time_ms\": 11260.435, \"total_train_time_s\": 15.450272798538208}", "{\"n\": 7521, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.51, \"learn_time_ms\": 11393.928, \"total_train_time_s\": 14.743003606796265}", "{\"n\": 7522, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.46, \"learn_time_ms\": 11248.724, \"total_train_time_s\": 14.250888347625732}", "{\"n\": 7523, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3665.8, \"learn_time_ms\": 11344.957, \"total_train_time_s\": 14.70133638381958}", "{\"n\": 7524, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3665.8, \"learn_time_ms\": 11180.36, \"total_train_time_s\": 12.889396905899048}", "{\"n\": 7525, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.23, \"learn_time_ms\": 10955.853, \"total_train_time_s\": 13.721727848052979}", "{\"n\": 7526, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.81, \"learn_time_ms\": 10983.842, \"total_train_time_s\": 15.64217472076416}", "{\"n\": 7527, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.51, \"learn_time_ms\": 10950.642, \"total_train_time_s\": 15.243391990661621}", "{\"n\": 7528, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.64, \"learn_time_ms\": 10816.653, \"total_train_time_s\": 14.807449102401733}", "{\"n\": 7529, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.81, \"learn_time_ms\": 11022.112, \"total_train_time_s\": 16.572110414505005}", "{\"n\": 7530, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3655.46, \"learn_time_ms\": 10822.288, \"total_train_time_s\": 13.528898239135742}", "{\"n\": 7531, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.31, \"learn_time_ms\": 10769.933, \"total_train_time_s\": 14.421326875686646}", "{\"n\": 7532, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.77, \"learn_time_ms\": 10703.217, \"total_train_time_s\": 13.442881345748901}", "{\"n\": 7533, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.77, \"learn_time_ms\": 10753.38, \"total_train_time_s\": 15.261647462844849}", "{\"n\": 7534, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10887.813, \"total_train_time_s\": 14.403498888015747}", "{\"n\": 7535, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.25, \"learn_time_ms\": 11061.265, \"total_train_time_s\": 14.975547552108765}", "{\"n\": 7536, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 11016.812, \"total_train_time_s\": 15.054919242858887}", "{\"n\": 7537, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 10942.3, \"total_train_time_s\": 14.570815563201904}", "{\"n\": 7538, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.75, \"learn_time_ms\": 10911.304, \"total_train_time_s\": 14.652182340621948}", "{\"n\": 7539, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.38, \"learn_time_ms\": 10732.498, \"total_train_time_s\": 14.505465745925903}", "{\"n\": 7540, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.39, \"learn_time_ms\": 10789.031, \"total_train_time_s\": 14.04758095741272}", "{\"n\": 7541, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.39, \"learn_time_ms\": 10978.563, \"total_train_time_s\": 16.233380556106567}", "{\"n\": 7542, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.35, \"learn_time_ms\": 11131.614, \"total_train_time_s\": 14.991969585418701}", "{\"n\": 7543, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.58, \"learn_time_ms\": 11102.528, \"total_train_time_s\": 14.929445266723633}", "{\"n\": 7544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.54, \"learn_time_ms\": 11081.618, \"total_train_time_s\": 13.96877670288086}", "{\"n\": 7545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.49, \"learn_time_ms\": 10977.084, \"total_train_time_s\": 13.912769079208374}", "{\"n\": 7546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.78, \"learn_time_ms\": 10857.285, \"total_train_time_s\": 13.952451944351196}", "{\"n\": 7547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.85, \"learn_time_ms\": 10725.655, \"total_train_time_s\": 12.933390617370605}", "{\"n\": 7548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.85, \"learn_time_ms\": 10793.866, \"total_train_time_s\": 15.14082956314087}", "{\"n\": 7549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.69, \"learn_time_ms\": 10748.614, \"total_train_time_s\": 13.979130268096924}", "{\"n\": 7550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.28, \"learn_time_ms\": 10850.015, \"total_train_time_s\": 15.061538219451904}", "{\"n\": 7551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10574.638, \"total_train_time_s\": 13.360420942306519}", "{\"n\": 7552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10402.988, \"total_train_time_s\": 13.436721086502075}", "{\"n\": 7553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.32, \"learn_time_ms\": 10404.512, \"total_train_time_s\": 14.94133448600769}", "{\"n\": 7554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.32, \"learn_time_ms\": 10460.875, \"total_train_time_s\": 14.770658016204834}", "{\"n\": 7555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.84, \"learn_time_ms\": 10394.436, \"total_train_time_s\": 13.402708292007446}", "{\"n\": 7556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.84, \"learn_time_ms\": 10462.307, \"total_train_time_s\": 14.83441710472107}", "{\"n\": 7557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.93, \"learn_time_ms\": 10541.255, \"total_train_time_s\": 13.846622467041016}", "{\"n\": 7558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.68, \"learn_time_ms\": 10386.623, \"total_train_time_s\": 13.73745083808899}", "{\"n\": 7559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.68, \"learn_time_ms\": 10486.406, \"total_train_time_s\": 15.210785388946533}", "{\"n\": 7560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.75, \"learn_time_ms\": 10357.767, \"total_train_time_s\": 13.88764476776123}", "{\"n\": 7561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.95, \"learn_time_ms\": 10400.498, \"total_train_time_s\": 13.929487466812134}", "{\"n\": 7562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.95, \"learn_time_ms\": 10370.958, \"total_train_time_s\": 13.169605493545532}", "{\"n\": 7563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3587.03, \"learn_time_ms\": 10268.655, \"total_train_time_s\": 14.023293733596802}", "{\"n\": 7564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.65, \"learn_time_ms\": 10232.094, \"total_train_time_s\": 14.289399147033691}", "{\"n\": 7565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.73, \"learn_time_ms\": 10172.035, \"total_train_time_s\": 12.628186225891113}", "{\"n\": 7566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.73, \"learn_time_ms\": 10208.895, \"total_train_time_s\": 15.363493919372559}", "{\"n\": 7567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.22, \"learn_time_ms\": 10365.0, \"total_train_time_s\": 15.141529560089111}", "{\"n\": 7568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.06, \"learn_time_ms\": 10456.764, \"total_train_time_s\": 14.760988473892212}", "{\"n\": 7569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.06, \"learn_time_ms\": 10424.9, \"total_train_time_s\": 15.065897703170776}", "{\"n\": 7570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.59, \"learn_time_ms\": 10429.186, \"total_train_time_s\": 13.777875423431396}", "{\"n\": 7571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.59, \"learn_time_ms\": 10461.478, \"total_train_time_s\": 14.36125659942627}", "{\"n\": 7572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3587.09, \"learn_time_ms\": 10592.296, \"total_train_time_s\": 14.546631813049316}", "{\"n\": 7573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.57, \"learn_time_ms\": 10609.369, \"total_train_time_s\": 13.945663928985596}", "{\"n\": 7574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.28, \"learn_time_ms\": 10691.414, \"total_train_time_s\": 15.447675943374634}", "{\"n\": 7575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.06, \"learn_time_ms\": 10902.561, \"total_train_time_s\": 15.18232250213623}", "{\"n\": 7576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.97, \"learn_time_ms\": 10797.684, \"total_train_time_s\": 13.970166444778442}", "{\"n\": 7577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.8, \"learn_time_ms\": 10958.663, \"total_train_time_s\": 16.88043999671936}", "{\"n\": 7578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3573.07, \"learn_time_ms\": 10954.012, \"total_train_time_s\": 14.738411664962769}", "{\"n\": 7579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.14, \"learn_time_ms\": 11024.282, \"total_train_time_s\": 15.431174993515015}", "{\"n\": 7580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3572.49, \"learn_time_ms\": 11190.262, \"total_train_time_s\": 15.753157377243042}", "{\"n\": 7581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3575.36, \"learn_time_ms\": 11250.452, \"total_train_time_s\": 14.665648698806763}", "{\"n\": 7582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3577.76, \"learn_time_ms\": 11310.06, \"total_train_time_s\": 14.884926080703735}", "{\"n\": 7583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3577.76, \"learn_time_ms\": 11268.45, \"total_train_time_s\": 13.470625162124634}", "{\"n\": 7584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3575.39, \"learn_time_ms\": 11158.456, \"total_train_time_s\": 14.22662901878357}", "{\"n\": 7585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3575.39, \"learn_time_ms\": 11036.293, \"total_train_time_s\": 13.92917251586914}", "{\"n\": 7586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3574.74, \"learn_time_ms\": 11063.238, \"total_train_time_s\": 14.215300798416138}", "{\"n\": 7587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3578.17, \"learn_time_ms\": 10778.97, \"total_train_time_s\": 14.24987006187439}", "{\"n\": 7588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.75, \"learn_time_ms\": 10795.992, \"total_train_time_s\": 14.899877548217773}", "{\"n\": 7589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.75, \"learn_time_ms\": 10686.574, \"total_train_time_s\": 14.313036680221558}", "{\"n\": 7590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.82, \"learn_time_ms\": 10621.679, \"total_train_time_s\": 14.951005458831787}", "{\"n\": 7591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.76, \"learn_time_ms\": 10681.418, \"total_train_time_s\": 15.378723382949829}", "{\"n\": 7592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.33, \"learn_time_ms\": 10645.517, \"total_train_time_s\": 14.748235940933228}", "{\"n\": 7593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.33, \"learn_time_ms\": 10642.367, \"total_train_time_s\": 13.845702648162842}", "{\"n\": 7594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.94, \"learn_time_ms\": 10835.489, \"total_train_time_s\": 16.250734567642212}", "{\"n\": 7595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 11033.467, \"total_train_time_s\": 15.891249895095825}", "{\"n\": 7596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3613.05, \"learn_time_ms\": 10995.14, \"total_train_time_s\": 13.845253705978394}", "{\"n\": 7597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3613.05, \"learn_time_ms\": 11096.869, \"total_train_time_s\": 15.253753423690796}", "{\"n\": 7598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.89, \"learn_time_ms\": 11184.043, \"total_train_time_s\": 15.628178834915161}", "{\"n\": 7599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.89, \"learn_time_ms\": 11235.903, \"total_train_time_s\": 15.01108980178833}", "{\"n\": 7600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 11219.689, \"total_train_time_s\": 14.554024696350098}", "{\"n\": 7601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 11196.299, \"total_train_time_s\": 14.984854459762573}", "{\"n\": 7602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.2, \"learn_time_ms\": 11165.5, \"total_train_time_s\": 14.521480083465576}", "{\"n\": 7603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.53, \"learn_time_ms\": 11291.052, \"total_train_time_s\": 15.105408191680908}", "{\"n\": 7604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.53, \"learn_time_ms\": 11182.106, \"total_train_time_s\": 14.898602485656738}", "{\"n\": 7605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.53, \"learn_time_ms\": 11095.701, \"total_train_time_s\": 14.759759664535522}", "{\"n\": 7606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.01, \"learn_time_ms\": 11226.143, \"total_train_time_s\": 15.102174997329712}", "{\"n\": 7607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.88, \"learn_time_ms\": 11144.724, \"total_train_time_s\": 14.352340936660767}", "{\"n\": 7608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.88, \"learn_time_ms\": 11202.286, \"total_train_time_s\": 16.39875078201294}", "{\"n\": 7609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.84, \"learn_time_ms\": 11107.077, \"total_train_time_s\": 13.905215978622437}", "{\"n\": 7610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.44, \"learn_time_ms\": 11072.878, \"total_train_time_s\": 14.201683759689331}", "{\"n\": 7611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.44, \"learn_time_ms\": 10998.287, \"total_train_time_s\": 14.241546869277954}", "{\"n\": 7612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.65, \"learn_time_ms\": 11169.836, \"total_train_time_s\": 15.956531524658203}", "{\"n\": 7613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.49, \"learn_time_ms\": 11158.421, \"total_train_time_s\": 14.639759063720703}", "{\"n\": 7614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.27, \"learn_time_ms\": 11134.443, \"total_train_time_s\": 14.531976699829102}", "{\"n\": 7615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.39, \"learn_time_ms\": 10986.866, \"total_train_time_s\": 13.131371974945068}", "{\"n\": 7616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.28, \"learn_time_ms\": 10954.332, \"total_train_time_s\": 14.874475717544556}", "{\"n\": 7617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.1, \"learn_time_ms\": 10973.783, \"total_train_time_s\": 14.682478189468384}", "{\"n\": 7618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.14, \"learn_time_ms\": 10766.687, \"total_train_time_s\": 14.312725305557251}", "{\"n\": 7619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.07, \"learn_time_ms\": 10805.246, \"total_train_time_s\": 14.492347002029419}", "{\"n\": 7620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.51, \"learn_time_ms\": 10751.52, \"total_train_time_s\": 13.73955774307251}", "{\"n\": 7621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.51, \"learn_time_ms\": 10736.598, \"total_train_time_s\": 14.101137399673462}", "{\"n\": 7622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.82, \"learn_time_ms\": 10609.655, \"total_train_time_s\": 14.90622067451477}", "{\"n\": 7623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.72, \"learn_time_ms\": 10662.743, \"total_train_time_s\": 15.317731142044067}", "{\"n\": 7624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.72, \"learn_time_ms\": 10560.749, \"total_train_time_s\": 13.591195821762085}", "{\"n\": 7625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.72, \"learn_time_ms\": 10656.403, \"total_train_time_s\": 14.188106060028076}", "{\"n\": 7626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.13, \"learn_time_ms\": 10602.729, \"total_train_time_s\": 14.377364873886108}", "{\"n\": 7627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.05, \"learn_time_ms\": 10595.843, \"total_train_time_s\": 14.274984359741211}", "{\"n\": 7628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.05, \"learn_time_ms\": 10686.24, \"total_train_time_s\": 15.17140793800354}", "{\"n\": 7629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.05, \"learn_time_ms\": 10620.993, \"total_train_time_s\": 13.972367763519287}", "{\"n\": 7630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.89, \"learn_time_ms\": 10597.863, \"total_train_time_s\": 13.703579425811768}", "{\"n\": 7631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.89, \"learn_time_ms\": 10716.247, \"total_train_time_s\": 15.38942837715149}", "{\"n\": 7632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.89, \"learn_time_ms\": 10680.715, \"total_train_time_s\": 14.462539911270142}", "{\"n\": 7633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.89, \"learn_time_ms\": 10616.257, \"total_train_time_s\": 14.911116123199463}", "{\"n\": 7634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.27, \"learn_time_ms\": 10646.085, \"total_train_time_s\": 14.18305516242981}", "{\"n\": 7635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.27, \"learn_time_ms\": 10831.605, \"total_train_time_s\": 16.22393822669983}", "{\"n\": 7636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 10826.293, \"total_train_time_s\": 14.594596862792969}", "{\"n\": 7637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.13, \"learn_time_ms\": 10782.642, \"total_train_time_s\": 14.083722829818726}", "{\"n\": 7638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.68, \"learn_time_ms\": 10653.312, \"total_train_time_s\": 13.971076011657715}", "{\"n\": 7639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.68, \"learn_time_ms\": 10757.918, \"total_train_time_s\": 14.61522912979126}", "{\"n\": 7640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.36, \"learn_time_ms\": 10878.742, \"total_train_time_s\": 14.809162378311157}", "{\"n\": 7641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 10942.708, \"total_train_time_s\": 16.151453733444214}", "{\"n\": 7642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.63, \"learn_time_ms\": 10876.767, \"total_train_time_s\": 13.735743761062622}", "{\"n\": 7643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.83, \"learn_time_ms\": 10901.695, \"total_train_time_s\": 14.965898513793945}", "{\"n\": 7644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.23, \"learn_time_ms\": 10923.385, \"total_train_time_s\": 14.223934412002563}", "{\"n\": 7645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.23, \"learn_time_ms\": 10813.849, \"total_train_time_s\": 14.979094505310059}", "{\"n\": 7646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.19, \"learn_time_ms\": 10913.923, \"total_train_time_s\": 15.303359985351562}", "{\"n\": 7647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.01, \"learn_time_ms\": 10896.232, \"total_train_time_s\": 13.845533609390259}", "{\"n\": 7648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.37, \"learn_time_ms\": 10911.502, \"total_train_time_s\": 13.840122699737549}", "{\"n\": 7649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.5, \"learn_time_ms\": 11027.737, \"total_train_time_s\": 16.085089921951294}", "{\"n\": 7650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.88, \"learn_time_ms\": 10999.93, \"total_train_time_s\": 14.383310317993164}", "{\"n\": 7651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.65, \"learn_time_ms\": 10748.413, \"total_train_time_s\": 13.475404977798462}", "{\"n\": 7652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.65, \"learn_time_ms\": 10761.05, \"total_train_time_s\": 13.812077760696411}", "{\"n\": 7653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.02, \"learn_time_ms\": 10831.095, \"total_train_time_s\": 15.680908918380737}", "{\"n\": 7654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10742.968, \"total_train_time_s\": 13.140425682067871}", "{\"n\": 7655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10662.795, \"total_train_time_s\": 14.318479776382446}", "{\"n\": 7656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 10740.757, \"total_train_time_s\": 16.077065229415894}", "{\"n\": 7657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.86, \"learn_time_ms\": 10692.613, \"total_train_time_s\": 13.20595097541809}", "{\"n\": 7658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.08, \"learn_time_ms\": 10690.871, \"total_train_time_s\": 14.04554271697998}", "{\"n\": 7659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.08, \"learn_time_ms\": 10515.006, \"total_train_time_s\": 14.18586277961731}", "{\"n\": 7660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.89, \"learn_time_ms\": 10558.845, \"total_train_time_s\": 15.356992721557617}", "{\"n\": 7661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.55, \"learn_time_ms\": 10707.556, \"total_train_time_s\": 14.863189935684204}", "{\"n\": 7662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.99, \"learn_time_ms\": 10684.996, \"total_train_time_s\": 13.764203786849976}", "{\"n\": 7663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.99, \"learn_time_ms\": 10604.507, \"total_train_time_s\": 14.867351531982422}", "{\"n\": 7664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.21, \"learn_time_ms\": 10686.672, \"total_train_time_s\": 14.258885383605957}", "{\"n\": 7665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.29, \"learn_time_ms\": 10680.973, \"total_train_time_s\": 14.342779159545898}", "{\"n\": 7666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.29, \"learn_time_ms\": 10518.453, \"total_train_time_s\": 14.49018669128418}", "{\"n\": 7667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.73, \"learn_time_ms\": 10658.045, \"total_train_time_s\": 14.96138858795166}", "{\"n\": 7668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.73, \"learn_time_ms\": 10728.222, \"total_train_time_s\": 14.970096349716187}", "{\"n\": 7669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 10873.421, \"total_train_time_s\": 15.546100854873657}", "{\"n\": 7670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 10880.353, \"total_train_time_s\": 14.994836807250977}", "{\"n\": 7671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.71, \"learn_time_ms\": 10750.254, \"total_train_time_s\": 13.835805892944336}", "{\"n\": 7672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.7, \"learn_time_ms\": 10841.907, \"total_train_time_s\": 14.59708571434021}", "{\"n\": 7673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.7, \"learn_time_ms\": 10797.833, \"total_train_time_s\": 14.359513282775879}", "{\"n\": 7674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.51, \"learn_time_ms\": 10852.724, \"total_train_time_s\": 14.95078420639038}", "{\"n\": 7675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.01, \"learn_time_ms\": 10920.542, \"total_train_time_s\": 14.980094909667969}", "{\"n\": 7676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.01, \"learn_time_ms\": 10949.267, \"total_train_time_s\": 14.71916651725769}", "{\"n\": 7677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.01, \"learn_time_ms\": 10890.169, \"total_train_time_s\": 14.074084997177124}", "{\"n\": 7678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.53, \"learn_time_ms\": 10839.769, \"total_train_time_s\": 13.979555130004883}", "{\"n\": 7679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.31, \"learn_time_ms\": 10718.243, \"total_train_time_s\": 14.367409706115723}", "{\"n\": 7680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.31, \"learn_time_ms\": 10621.936, \"total_train_time_s\": 14.355345010757446}", "{\"n\": 7681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.31, \"learn_time_ms\": 10597.718, \"total_train_time_s\": 13.694825410842896}", "{\"n\": 7682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.97, \"learn_time_ms\": 10576.657, \"total_train_time_s\": 14.374918937683105}", "{\"n\": 7683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.97, \"learn_time_ms\": 10529.949, \"total_train_time_s\": 13.976992845535278}", "{\"n\": 7684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.97, \"learn_time_ms\": 10476.125, \"total_train_time_s\": 13.963563919067383}", "{\"n\": 7685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.79, \"learn_time_ms\": 10374.66, \"total_train_time_s\": 13.904281377792358}", "{\"n\": 7686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.07, \"learn_time_ms\": 10343.109, \"total_train_time_s\": 14.25742483139038}", "{\"n\": 7687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.07, \"learn_time_ms\": 10380.277, \"total_train_time_s\": 14.540194749832153}", "{\"n\": 7688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.07, \"learn_time_ms\": 10408.338, \"total_train_time_s\": 14.512317657470703}", "{\"n\": 7689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.02, \"learn_time_ms\": 10335.03, \"total_train_time_s\": 13.533088445663452}", "{\"n\": 7690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.02, \"learn_time_ms\": 10374.53, \"total_train_time_s\": 14.616497278213501}", "{\"n\": 7691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.02, \"learn_time_ms\": 10466.96, \"total_train_time_s\": 14.486676692962646}", "{\"n\": 7692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.47, \"learn_time_ms\": 10512.746, \"total_train_time_s\": 14.909473657608032}", "{\"n\": 7693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.59, \"learn_time_ms\": 10558.416, \"total_train_time_s\": 14.187912225723267}", "{\"n\": 7694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.16, \"learn_time_ms\": 10523.044, \"total_train_time_s\": 13.835201025009155}", "{\"n\": 7695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.16, \"learn_time_ms\": 10483.853, \"total_train_time_s\": 13.691361665725708}", "{\"n\": 7696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.67, \"learn_time_ms\": 10512.54, \"total_train_time_s\": 14.540745258331299}", "{\"n\": 7697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.21, \"learn_time_ms\": 10520.193, \"total_train_time_s\": 14.51933479309082}", "{\"n\": 7698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.21, \"learn_time_ms\": 10371.093, \"total_train_time_s\": 12.749561548233032}", "{\"n\": 7699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.02, \"learn_time_ms\": 10362.188, \"total_train_time_s\": 13.811830043792725}", "{\"n\": 7700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.75, \"learn_time_ms\": 10416.501, \"total_train_time_s\": 14.895360946655273}", "{\"n\": 7701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.75, \"learn_time_ms\": 10299.964, \"total_train_time_s\": 13.201918363571167}", "{\"n\": 7702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.09, \"learn_time_ms\": 10290.242, \"total_train_time_s\": 14.72016716003418}", "{\"n\": 7703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.61, \"learn_time_ms\": 10255.331, \"total_train_time_s\": 14.099995851516724}", "{\"n\": 7704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.46, \"learn_time_ms\": 10232.595, \"total_train_time_s\": 13.592726707458496}", "{\"n\": 7705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.19, \"learn_time_ms\": 10305.842, \"total_train_time_s\": 14.256902933120728}", "{\"n\": 7706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.19, \"learn_time_ms\": 10206.811, \"total_train_time_s\": 13.628872156143188}", "{\"n\": 7707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.03, \"learn_time_ms\": 10190.98, \"total_train_time_s\": 14.470118284225464}", "{\"n\": 7708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 10449.527, \"total_train_time_s\": 15.726351261138916}", "{\"n\": 7709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 10448.16, \"total_train_time_s\": 13.67044448852539}", "{\"n\": 7710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 10361.169, \"total_train_time_s\": 14.353713035583496}", "{\"n\": 7711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.04, \"learn_time_ms\": 10539.667, \"total_train_time_s\": 14.891477346420288}", "{\"n\": 7712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.83, \"learn_time_ms\": 10472.23, \"total_train_time_s\": 14.221938848495483}", "{\"n\": 7713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.83, \"learn_time_ms\": 10576.284, \"total_train_time_s\": 15.340205669403076}", "{\"n\": 7714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.05, \"learn_time_ms\": 10742.333, \"total_train_time_s\": 15.134131669998169}", "{\"n\": 7715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.66, \"learn_time_ms\": 10889.301, \"total_train_time_s\": 15.596152782440186}", "{\"n\": 7716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.31, \"learn_time_ms\": 10965.054, \"total_train_time_s\": 14.331875801086426}", "{\"n\": 7717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.31, \"learn_time_ms\": 10884.643, \"total_train_time_s\": 13.655001401901245}", "{\"n\": 7718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.31, \"learn_time_ms\": 10785.815, \"total_train_time_s\": 14.356934309005737}", "{\"n\": 7719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.02, \"learn_time_ms\": 10874.845, \"total_train_time_s\": 14.404995441436768}", "{\"n\": 7720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.7, \"learn_time_ms\": 10960.319, \"total_train_time_s\": 15.234179258346558}", "{\"n\": 7721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.7, \"learn_time_ms\": 10953.429, \"total_train_time_s\": 15.078313827514648}", "{\"n\": 7722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.98, \"learn_time_ms\": 11045.168, \"total_train_time_s\": 15.093396425247192}", "{\"n\": 7723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.69, \"learn_time_ms\": 10930.179, \"total_train_time_s\": 13.714932918548584}", "{\"n\": 7724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.13, \"learn_time_ms\": 10876.691, \"total_train_time_s\": 14.639251947402954}", "{\"n\": 7725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.13, \"learn_time_ms\": 10806.492, \"total_train_time_s\": 15.02094292640686}", "{\"n\": 7726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.34, \"learn_time_ms\": 10898.601, \"total_train_time_s\": 15.666560173034668}", "{\"n\": 7727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.18, \"learn_time_ms\": 11066.625, \"total_train_time_s\": 15.658297538757324}", "{\"n\": 7728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.88, \"learn_time_ms\": 11006.043, \"total_train_time_s\": 13.75055742263794}", "{\"n\": 7729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.88, \"learn_time_ms\": 11004.188, \"total_train_time_s\": 14.599943399429321}", "{\"n\": 7730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.69, \"learn_time_ms\": 10935.943, \"total_train_time_s\": 14.386154890060425}", "{\"n\": 7731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.33, \"learn_time_ms\": 10909.393, \"total_train_time_s\": 14.837621927261353}", "{\"n\": 7732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.33, \"learn_time_ms\": 10825.112, \"total_train_time_s\": 14.193722486495972}", "{\"n\": 7733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.61, \"learn_time_ms\": 10825.712, \"total_train_time_s\": 13.864554405212402}", "{\"n\": 7734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.73, \"learn_time_ms\": 10808.528, \"total_train_time_s\": 14.5054292678833}", "{\"n\": 7735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.91, \"learn_time_ms\": 10797.006, \"total_train_time_s\": 14.897218227386475}", "{\"n\": 7736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.91, \"learn_time_ms\": 10770.911, \"total_train_time_s\": 14.955383062362671}", "{\"n\": 7737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.1, \"learn_time_ms\": 10674.207, \"total_train_time_s\": 14.182874202728271}", "{\"n\": 7738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.38, \"learn_time_ms\": 10694.951, \"total_train_time_s\": 14.111499547958374}", "{\"n\": 7739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.38, \"learn_time_ms\": 10679.851, \"total_train_time_s\": 14.160126209259033}", "{\"n\": 7740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.17, \"learn_time_ms\": 10631.3, \"total_train_time_s\": 14.068136930465698}", "{\"n\": 7741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.51, \"learn_time_ms\": 10704.797, \"total_train_time_s\": 15.730733156204224}", "{\"n\": 7742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10765.101, \"total_train_time_s\": 14.835402727127075}", "{\"n\": 7743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10796.572, \"total_train_time_s\": 14.168324947357178}", "{\"n\": 7744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10662.289, \"total_train_time_s\": 13.109278440475464}", "{\"n\": 7745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.4, \"learn_time_ms\": 10737.469, \"total_train_time_s\": 15.488524198532104}", "{\"n\": 7746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.3, \"learn_time_ms\": 10701.591, \"total_train_time_s\": 14.58651876449585}", "{\"n\": 7747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.3, \"learn_time_ms\": 10633.116, \"total_train_time_s\": 13.612060785293579}", "{\"n\": 7748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.3, \"learn_time_ms\": 10623.633, \"total_train_time_s\": 14.318154335021973}", "{\"n\": 7749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.56, \"learn_time_ms\": 10749.763, \"total_train_time_s\": 15.533557415008545}", "{\"n\": 7750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10910.588, \"total_train_time_s\": 15.461276054382324}", "{\"n\": 7751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10860.727, \"total_train_time_s\": 15.215333223342896}", "{\"n\": 7752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10840.242, \"total_train_time_s\": 14.47104525566101}", "{\"n\": 7753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.61, \"learn_time_ms\": 10881.986, \"total_train_time_s\": 14.576210498809814}", "{\"n\": 7754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.61, \"learn_time_ms\": 11044.136, \"total_train_time_s\": 15.181031465530396}", "{\"n\": 7755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.05, \"learn_time_ms\": 10793.978, \"total_train_time_s\": 13.124449729919434}", "{\"n\": 7756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.05, \"learn_time_ms\": 10726.242, \"total_train_time_s\": 14.148132801055908}", "{\"n\": 7757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.0, \"learn_time_ms\": 10833.93, \"total_train_time_s\": 14.630714654922485}", "{\"n\": 7758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.74, \"learn_time_ms\": 10934.888, \"total_train_time_s\": 15.01392912864685}", "{\"n\": 7759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.74, \"learn_time_ms\": 10780.008, \"total_train_time_s\": 14.14279842376709}", "{\"n\": 7760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.61, \"learn_time_ms\": 10658.303, \"total_train_time_s\": 14.2678804397583}", "{\"n\": 7761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.46, \"learn_time_ms\": 10496.58, \"total_train_time_s\": 13.137221097946167}", "{\"n\": 7762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.46, \"learn_time_ms\": 10408.29, \"total_train_time_s\": 13.78780460357666}", "{\"n\": 7763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.54, \"learn_time_ms\": 10342.927, \"total_train_time_s\": 14.036344766616821}", "{\"n\": 7764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.54, \"learn_time_ms\": 10302.453, \"total_train_time_s\": 14.466368198394775}", "{\"n\": 7765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.92, \"learn_time_ms\": 10448.322, \"total_train_time_s\": 14.669668912887573}", "{\"n\": 7766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.92, \"learn_time_ms\": 10435.64, \"total_train_time_s\": 14.11328649520874}", "{\"n\": 7767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.73, \"learn_time_ms\": 10430.495, \"total_train_time_s\": 14.816876888275146}", "{\"n\": 7768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.57, \"learn_time_ms\": 10406.917, \"total_train_time_s\": 15.039997339248657}", "{\"n\": 7769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.0, \"learn_time_ms\": 10537.217, \"total_train_time_s\": 15.228753566741943}", "{\"n\": 7770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.0, \"learn_time_ms\": 10566.599, \"total_train_time_s\": 14.441879272460938}", "{\"n\": 7771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.13, \"learn_time_ms\": 10711.342, \"total_train_time_s\": 14.779254913330078}", "{\"n\": 7772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.04, \"learn_time_ms\": 10745.36, \"total_train_time_s\": 14.185349225997925}", "{\"n\": 7773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3727.17, \"learn_time_ms\": 10892.162, \"total_train_time_s\": 15.394200086593628}", "{\"n\": 7774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.41, \"learn_time_ms\": 10865.752, \"total_train_time_s\": 14.29379153251648}", "{\"n\": 7775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.41, \"learn_time_ms\": 11008.851, \"total_train_time_s\": 15.914542198181152}", "{\"n\": 7776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.93, \"learn_time_ms\": 11133.572, \"total_train_time_s\": 15.156865358352661}", "{\"n\": 7777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.93, \"learn_time_ms\": 10972.727, \"total_train_time_s\": 12.91780138015747}", "{\"n\": 7778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.5, \"learn_time_ms\": 11109.846, \"total_train_time_s\": 16.166995525360107}", "{\"n\": 7779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.13, \"learn_time_ms\": 11173.732, \"total_train_time_s\": 15.926942586898804}", "{\"n\": 7780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.13, \"learn_time_ms\": 11104.95, \"total_train_time_s\": 14.13013243675232}", "{\"n\": 7781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.68, \"learn_time_ms\": 11058.068, \"total_train_time_s\": 14.234723567962646}", "{\"n\": 7782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.26, \"learn_time_ms\": 11117.417, \"total_train_time_s\": 14.473411321640015}", "{\"n\": 7783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.26, \"learn_time_ms\": 10993.506, \"total_train_time_s\": 14.098964929580688}", "{\"n\": 7784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.26, \"learn_time_ms\": 11100.91, \"total_train_time_s\": 15.53430461883545}", "{\"n\": 7785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.99, \"learn_time_ms\": 10883.608, \"total_train_time_s\": 13.614585876464844}", "{\"n\": 7786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 10893.416, \"total_train_time_s\": 15.157402992248535}", "{\"n\": 7787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 11008.99, \"total_train_time_s\": 14.26501202583313}", "{\"n\": 7788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 10726.154, \"total_train_time_s\": 13.661160469055176}", "{\"n\": 7789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.42, \"learn_time_ms\": 10533.129, \"total_train_time_s\": 14.20646858215332}", "{\"n\": 7790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.21, \"learn_time_ms\": 10566.693, \"total_train_time_s\": 14.145333290100098}", "{\"n\": 7791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.21, \"learn_time_ms\": 10610.094, \"total_train_time_s\": 15.009285688400269}", "{\"n\": 7792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.21, \"learn_time_ms\": 10618.489, \"total_train_time_s\": 14.681990146636963}", "{\"n\": 7793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.47, \"learn_time_ms\": 10631.897, \"total_train_time_s\": 14.201409101486206}", "{\"n\": 7794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.38, \"learn_time_ms\": 10530.096, \"total_train_time_s\": 13.99395227432251}", "{\"n\": 7795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.38, \"learn_time_ms\": 10668.295, \"total_train_time_s\": 14.995310306549072}", "{\"n\": 7796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.38, \"learn_time_ms\": 10609.495, \"total_train_time_s\": 14.521958827972412}", "{\"n\": 7797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.8, \"learn_time_ms\": 10611.998, \"total_train_time_s\": 14.247041463851929}", "{\"n\": 7798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.8, \"learn_time_ms\": 10803.208, \"total_train_time_s\": 15.382456064224243}", "{\"n\": 7799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.8, \"learn_time_ms\": 10816.494, \"total_train_time_s\": 14.122617244720459}", "{\"n\": 7800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.8, \"learn_time_ms\": 10878.468, \"total_train_time_s\": 14.684489727020264}", "{\"n\": 7801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3733.24, \"learn_time_ms\": 10769.549, \"total_train_time_s\": 13.739336490631104}", "{\"n\": 7802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3733.24, \"learn_time_ms\": 10815.756, \"total_train_time_s\": 15.18056058883667}", "{\"n\": 7803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3733.24, \"learn_time_ms\": 10432.47, \"total_train_time_s\": 10.486255645751953}", "{\"n\": 7804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3736.93, \"learn_time_ms\": 10266.953, \"total_train_time_s\": 12.696022748947144}", "{\"n\": 7805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3739.16, \"learn_time_ms\": 10059.429, \"total_train_time_s\": 18.65646004676819}", "{\"n\": 7806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3739.16, \"learn_time_ms\": 9641.942, \"total_train_time_s\": 10.758125066757202}", "{\"n\": 7807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3739.16, \"learn_time_ms\": 9279.103, \"total_train_time_s\": 10.850802183151245}", "{\"n\": 7808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3733.18, \"learn_time_ms\": 8820.931, \"total_train_time_s\": 10.972498655319214}", "{\"n\": 7809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.82, \"learn_time_ms\": 8868.637, \"total_train_time_s\": 14.92807412147522}", "{\"n\": 7810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3744.28, \"learn_time_ms\": 8771.96, \"total_train_time_s\": 13.874467134475708}", "{\"n\": 7811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3744.28, \"learn_time_ms\": 8903.378, \"total_train_time_s\": 15.120084285736084}", "{\"n\": 7812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3744.28, \"learn_time_ms\": 8949.262, \"total_train_time_s\": 15.603748798370361}", "{\"n\": 7813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3740.93, \"learn_time_ms\": 9377.084, \"total_train_time_s\": 14.649782419204712}", "{\"n\": 7814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3740.93, \"learn_time_ms\": 9585.172, \"total_train_time_s\": 14.52244234085083}", "{\"n\": 7815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3740.93, \"learn_time_ms\": 9802.718, \"total_train_time_s\": 15.30286693572998}", "{\"n\": 7816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.96, \"learn_time_ms\": 10170.153, \"total_train_time_s\": 14.177817344665527}", "{\"n\": 7817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.47, \"learn_time_ms\": 10501.083, \"total_train_time_s\": 13.919563293457031}", "{\"n\": 7818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.47, \"learn_time_ms\": 10937.3, \"total_train_time_s\": 15.220897674560547}", "{\"n\": 7819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.26, \"learn_time_ms\": 10917.408, \"total_train_time_s\": 14.320061683654785}", "{\"n\": 7820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.27, \"learn_time_ms\": 10920.938, \"total_train_time_s\": 13.740583181381226}", "{\"n\": 7821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.27, \"learn_time_ms\": 10802.205, \"total_train_time_s\": 14.150038480758667}", "{\"n\": 7822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.96, \"learn_time_ms\": 10763.638, \"total_train_time_s\": 15.486637592315674}", "{\"n\": 7823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.12, \"learn_time_ms\": 10822.321, \"total_train_time_s\": 15.187361717224121}", "{\"n\": 7824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.87, \"learn_time_ms\": 10814.746, \"total_train_time_s\": 14.518102407455444}", "{\"n\": 7825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.87, \"learn_time_ms\": 10733.625, \"total_train_time_s\": 14.624399185180664}", "{\"n\": 7826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.12, \"learn_time_ms\": 10741.609, \"total_train_time_s\": 14.308891296386719}", "{\"n\": 7827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.56, \"learn_time_ms\": 10852.832, \"total_train_time_s\": 14.959245443344116}", "{\"n\": 7828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.85, \"learn_time_ms\": 10717.1, \"total_train_time_s\": 13.530011892318726}", "{\"n\": 7829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.4, \"learn_time_ms\": 10550.395, \"total_train_time_s\": 12.966327905654907}", "{\"n\": 7830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.3, \"learn_time_ms\": 10658.09, \"total_train_time_s\": 15.019212007522583}", "{\"n\": 7831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.79, \"learn_time_ms\": 10735.043, \"total_train_time_s\": 14.60848355293274}", "{\"n\": 7832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.79, \"learn_time_ms\": 10573.724, \"total_train_time_s\": 13.937881469726562}", "{\"n\": 7833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.4, \"learn_time_ms\": 10465.932, \"total_train_time_s\": 14.334161758422852}", "{\"n\": 7834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.22, \"learn_time_ms\": 10585.451, \"total_train_time_s\": 15.862163066864014}", "{\"n\": 7835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.05, \"learn_time_ms\": 10568.36, \"total_train_time_s\": 14.556793212890625}", "{\"n\": 7836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.05, \"learn_time_ms\": 10543.764, \"total_train_time_s\": 14.159026622772217}", "{\"n\": 7837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.62, \"learn_time_ms\": 10566.167, \"total_train_time_s\": 15.2065908908844}", "{\"n\": 7838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.33, \"learn_time_ms\": 10683.859, \"total_train_time_s\": 14.757940769195557}", "{\"n\": 7839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.15, \"learn_time_ms\": 10908.579, \"total_train_time_s\": 15.312523365020752}", "{\"n\": 7840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.04, \"learn_time_ms\": 10843.784, \"total_train_time_s\": 14.556610822677612}", "{\"n\": 7841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.56, \"learn_time_ms\": 10842.087, \"total_train_time_s\": 14.447704792022705}", "{\"n\": 7842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.67, \"learn_time_ms\": 10964.192, \"total_train_time_s\": 14.770079374313354}", "{\"n\": 7843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.67, \"learn_time_ms\": 10992.318, \"total_train_time_s\": 14.568419456481934}", "{\"n\": 7844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.29, \"learn_time_ms\": 10865.644, \"total_train_time_s\": 14.323427677154541}", "{\"n\": 7845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.96, \"learn_time_ms\": 10755.977, \"total_train_time_s\": 13.091306209564209}", "{\"n\": 7846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.74, \"learn_time_ms\": 10878.707, \"total_train_time_s\": 15.184877395629883}", "{\"n\": 7847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.91, \"learn_time_ms\": 10843.972, \"total_train_time_s\": 15.021717071533203}", "{\"n\": 7848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.02, \"learn_time_ms\": 10928.87, \"total_train_time_s\": 15.724721670150757}", "{\"n\": 7849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.02, \"learn_time_ms\": 10945.53, \"total_train_time_s\": 15.65059518814087}", "{\"n\": 7850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.74, \"learn_time_ms\": 10947.963, \"total_train_time_s\": 14.242342472076416}", "{\"n\": 7851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.42, \"learn_time_ms\": 10954.309, \"total_train_time_s\": 14.83567762374878}", "{\"n\": 7852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.42, \"learn_time_ms\": 10934.099, \"total_train_time_s\": 14.512585639953613}", "{\"n\": 7853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.7, \"learn_time_ms\": 10994.803, \"total_train_time_s\": 14.990529298782349}", "{\"n\": 7854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.15, \"learn_time_ms\": 11024.216, \"total_train_time_s\": 14.594143152236938}", "{\"n\": 7855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.96, \"learn_time_ms\": 11274.634, \"total_train_time_s\": 15.686866044998169}", "{\"n\": 7856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.96, \"learn_time_ms\": 11224.502, \"total_train_time_s\": 14.854037046432495}", "{\"n\": 7857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.59, \"learn_time_ms\": 11178.224, \"total_train_time_s\": 14.45702576637268}", "{\"n\": 7858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.59, \"learn_time_ms\": 11072.76, \"total_train_time_s\": 14.516772747039795}", "{\"n\": 7859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.86, \"learn_time_ms\": 11111.504, \"total_train_time_s\": 15.52977967262268}", "{\"n\": 7860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.9, \"learn_time_ms\": 11167.229, \"total_train_time_s\": 14.723879337310791}", "{\"n\": 7861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.9, \"learn_time_ms\": 11170.42, \"total_train_time_s\": 14.489636659622192}", "{\"n\": 7862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.41, \"learn_time_ms\": 11243.844, \"total_train_time_s\": 15.516053438186646}", "{\"n\": 7863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.67, \"learn_time_ms\": 11181.399, \"total_train_time_s\": 14.448645114898682}", "{\"n\": 7864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.03, \"learn_time_ms\": 11086.657, \"total_train_time_s\": 13.973517179489136}", "{\"n\": 7865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.03, \"learn_time_ms\": 10938.635, \"total_train_time_s\": 14.024710178375244}", "{\"n\": 7866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.53, \"learn_time_ms\": 10865.306, \"total_train_time_s\": 13.952307939529419}", "{\"n\": 7867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.7, \"learn_time_ms\": 10853.928, \"total_train_time_s\": 14.645408868789673}", "{\"n\": 7868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.87, \"learn_time_ms\": 10831.268, \"total_train_time_s\": 14.576682329177856}", "{\"n\": 7869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.56, \"learn_time_ms\": 10689.005, \"total_train_time_s\": 14.004579305648804}", "{\"n\": 7870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.86, \"learn_time_ms\": 10581.083, \"total_train_time_s\": 13.947517156600952}", "{\"n\": 7871, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.95, \"learn_time_ms\": 10548.486, \"total_train_time_s\": 14.342743635177612}", "{\"n\": 7872, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.49, \"learn_time_ms\": 10337.12, \"total_train_time_s\": 13.224261045455933}", "{\"n\": 7873, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.49, \"learn_time_ms\": 10368.819, \"total_train_time_s\": 15.107743978500366}", "{\"n\": 7874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.5, \"learn_time_ms\": 10406.673, \"total_train_time_s\": 14.141906023025513}", "{\"n\": 7875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.24, \"learn_time_ms\": 10514.302, \"total_train_time_s\": 15.282608985900879}", "{\"n\": 7876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.57, \"learn_time_ms\": 10595.639, \"total_train_time_s\": 14.978424072265625}", "{\"n\": 7877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.57, \"learn_time_ms\": 10704.543, \"total_train_time_s\": 15.409795761108398}", "{\"n\": 7878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.18, \"learn_time_ms\": 10766.36, \"total_train_time_s\": 15.05690860748291}", "{\"n\": 7879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.89, \"learn_time_ms\": 10833.466, \"total_train_time_s\": 14.898466110229492}", "{\"n\": 7880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.21, \"learn_time_ms\": 11008.417, \"total_train_time_s\": 15.508399248123169}", "{\"n\": 7881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.8, \"learn_time_ms\": 10992.237, \"total_train_time_s\": 14.2587149143219}", "{\"n\": 7882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.14, \"learn_time_ms\": 11002.035, \"total_train_time_s\": 13.682866334915161}", "{\"n\": 7883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.36, \"learn_time_ms\": 10924.632, \"total_train_time_s\": 14.058032274246216}", "{\"n\": 7884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.36, \"learn_time_ms\": 11072.624, \"total_train_time_s\": 15.506130695343018}", "{\"n\": 7885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.02, \"learn_time_ms\": 11074.318, \"total_train_time_s\": 15.343936681747437}", "{\"n\": 7886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 11027.104, \"total_train_time_s\": 14.461150884628296}", "{\"n\": 7887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10904.798, \"total_train_time_s\": 14.232682466506958}", "{\"n\": 7888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.62, \"learn_time_ms\": 10794.913, \"total_train_time_s\": 14.06892442703247}", "{\"n\": 7889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.68, \"learn_time_ms\": 10735.464, \"total_train_time_s\": 14.204905271530151}", "{\"n\": 7890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.58, \"learn_time_ms\": 10608.584, \"total_train_time_s\": 14.314499378204346}", "{\"n\": 7891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.57, \"learn_time_ms\": 10646.035, \"total_train_time_s\": 14.48951506614685}", "{\"n\": 7892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.0, \"learn_time_ms\": 10807.514, \"total_train_time_s\": 14.882808208465576}", "{\"n\": 7893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.6, \"learn_time_ms\": 10761.882, \"total_train_time_s\": 13.845634937286377}", "{\"n\": 7894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.44, \"learn_time_ms\": 10688.805, \"total_train_time_s\": 14.730892419815063}", "{\"n\": 7895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.34, \"learn_time_ms\": 10565.105, \"total_train_time_s\": 14.103093147277832}", "{\"n\": 7896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.88, \"learn_time_ms\": 10595.709, \"total_train_time_s\": 14.656544208526611}", "{\"n\": 7897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.04, \"learn_time_ms\": 10712.809, \"total_train_time_s\": 15.23127007484436}", "{\"n\": 7898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.93, \"learn_time_ms\": 10768.953, \"total_train_time_s\": 14.603770732879639}", "{\"n\": 7899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.93, \"learn_time_ms\": 10809.298, \"total_train_time_s\": 15.028524398803711}", "{\"n\": 7900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.01, \"learn_time_ms\": 10770.949, \"total_train_time_s\": 14.051313638687134}", "{\"n\": 7901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.93, \"learn_time_ms\": 10700.79, \"total_train_time_s\": 13.815297842025757}", "{\"n\": 7902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.55, \"learn_time_ms\": 10723.719, \"total_train_time_s\": 15.306849718093872}", "{\"n\": 7903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.55, \"learn_time_ms\": 10829.29, \"total_train_time_s\": 14.824307918548584}", "{\"n\": 7904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.17, \"learn_time_ms\": 10738.205, \"total_train_time_s\": 13.8570876121521}", "{\"n\": 7905, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.69, \"learn_time_ms\": 10814.355, \"total_train_time_s\": 14.989484786987305}", "{\"n\": 7906, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.57, \"learn_time_ms\": 10805.549, \"total_train_time_s\": 14.511619567871094}", "{\"n\": 7907, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.57, \"learn_time_ms\": 10614.447, \"total_train_time_s\": 13.34557318687439}", "{\"n\": 7908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.99, \"learn_time_ms\": 10563.442, \"total_train_time_s\": 13.994804859161377}", "{\"n\": 7909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.71, \"learn_time_ms\": 10561.054, \"total_train_time_s\": 14.451712608337402}", "{\"n\": 7910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.71, \"learn_time_ms\": 10690.625, \"total_train_time_s\": 15.196643114089966}", "{\"n\": 7911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.23, \"learn_time_ms\": 10829.064, \"total_train_time_s\": 15.215064764022827}", "{\"n\": 7912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.69, \"learn_time_ms\": 10692.645, \"total_train_time_s\": 13.950587511062622}", "{\"n\": 7913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.87, \"learn_time_ms\": 10690.053, \"total_train_time_s\": 14.537450075149536}", "{\"n\": 7914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.87, \"learn_time_ms\": 10748.011, \"total_train_time_s\": 14.428810358047485}", "{\"n\": 7915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.97, \"learn_time_ms\": 10770.409, \"total_train_time_s\": 15.26026201248169}", "{\"n\": 7916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.67, \"learn_time_ms\": 10773.45, \"total_train_time_s\": 14.643738508224487}", "{\"n\": 7917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.38, \"learn_time_ms\": 10929.263, \"total_train_time_s\": 15.17290997505188}", "{\"n\": 7918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.38, \"learn_time_ms\": 10907.303, \"total_train_time_s\": 14.081665515899658}", "{\"n\": 7919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.64, \"learn_time_ms\": 10890.44, \"total_train_time_s\": 14.308889865875244}", "{\"n\": 7920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.64, \"learn_time_ms\": 10793.896, \"total_train_time_s\": 14.370860815048218}", "{\"n\": 7921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.59, \"learn_time_ms\": 10743.478, \"total_train_time_s\": 14.625253438949585}", "{\"n\": 7922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.63, \"learn_time_ms\": 10756.873, \"total_train_time_s\": 14.087981462478638}", "{\"n\": 7923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.07, \"learn_time_ms\": 10812.989, \"total_train_time_s\": 15.089779615402222}", "{\"n\": 7924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.07, \"learn_time_ms\": 10800.382, \"total_train_time_s\": 14.644391536712646}", "{\"n\": 7925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.03, \"learn_time_ms\": 10657.67, \"total_train_time_s\": 13.51101279258728}", "{\"n\": 7926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.65, \"learn_time_ms\": 10710.476, \"total_train_time_s\": 15.277500629425049}", "{\"n\": 7927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.63, \"learn_time_ms\": 10629.17, \"total_train_time_s\": 14.127154111862183}", "{\"n\": 7928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.83, \"learn_time_ms\": 10580.095, \"total_train_time_s\": 13.292016983032227}", "{\"n\": 7929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.83, \"learn_time_ms\": 10603.693, \"total_train_time_s\": 14.599174976348877}", "{\"n\": 7930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.06, \"learn_time_ms\": 10756.41, \"total_train_time_s\": 15.710001945495605}", "{\"n\": 7931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.77, \"learn_time_ms\": 10737.769, \"total_train_time_s\": 14.493911027908325}", "{\"n\": 7932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.74, \"learn_time_ms\": 10710.928, \"total_train_time_s\": 13.739553213119507}", "{\"n\": 7933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.74, \"learn_time_ms\": 10664.715, \"total_train_time_s\": 15.03127646446228}", "{\"n\": 7934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.03, \"learn_time_ms\": 10554.709, \"total_train_time_s\": 13.397485733032227}", "{\"n\": 7935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.1, \"learn_time_ms\": 10662.718, \"total_train_time_s\": 14.635755062103271}", "{\"n\": 7936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.1, \"learn_time_ms\": 10577.766, \"total_train_time_s\": 14.21267056465149}", "{\"n\": 7937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.29, \"learn_time_ms\": 10638.88, \"total_train_time_s\": 15.044862270355225}", "{\"n\": 7938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.15, \"learn_time_ms\": 10755.476, \"total_train_time_s\": 14.526187658309937}", "{\"n\": 7939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.15, \"learn_time_ms\": 10844.698, \"total_train_time_s\": 15.600002765655518}", "{\"n\": 7940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.99, \"learn_time_ms\": 10821.874, \"total_train_time_s\": 15.862289428710938}", "{\"n\": 7941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.95, \"learn_time_ms\": 10836.507, \"total_train_time_s\": 14.865379095077515}", "{\"n\": 7942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.95, \"learn_time_ms\": 10802.284, \"total_train_time_s\": 13.517499208450317}", "{\"n\": 7943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.95, \"learn_time_ms\": 10787.038, \"total_train_time_s\": 14.491528034210205}", "{\"n\": 7944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.79, \"learn_time_ms\": 10867.851, \"total_train_time_s\": 14.407525539398193}", "{\"n\": 7945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.92, \"learn_time_ms\": 10856.597, \"total_train_time_s\": 14.666532278060913}", "{\"n\": 7946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.92, \"learn_time_ms\": 10836.806, \"total_train_time_s\": 14.247291564941406}", "{\"n\": 7947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.82, \"learn_time_ms\": 10835.159, \"total_train_time_s\": 14.752745389938354}", "{\"n\": 7948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.99, \"learn_time_ms\": 10860.421, \"total_train_time_s\": 14.893725633621216}", "{\"n\": 7949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.99, \"learn_time_ms\": 10726.232, \"total_train_time_s\": 14.238921165466309}", "{\"n\": 7950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.99, \"learn_time_ms\": 10649.45, \"total_train_time_s\": 14.588902711868286}", "{\"n\": 7951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.49, \"learn_time_ms\": 10687.181, \"total_train_time_s\": 15.16445016860962}", "{\"n\": 7952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.33, \"learn_time_ms\": 10777.522, \"total_train_time_s\": 14.246829986572266}", "{\"n\": 7953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.33, \"learn_time_ms\": 10812.486, \"total_train_time_s\": 15.06453275680542}", "{\"n\": 7954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.79, \"learn_time_ms\": 10873.087, \"total_train_time_s\": 14.919997453689575}", "{\"n\": 7955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.3, \"learn_time_ms\": 10772.278, \"total_train_time_s\": 13.733096837997437}", "{\"n\": 7956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.6, \"learn_time_ms\": 10812.292, \"total_train_time_s\": 14.377689838409424}", "{\"n\": 7957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.49, \"learn_time_ms\": 10698.083, \"total_train_time_s\": 13.950801849365234}", "{\"n\": 7958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.21, \"learn_time_ms\": 10690.103, \"total_train_time_s\": 14.834951400756836}", "{\"n\": 7959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10700.334, \"total_train_time_s\": 14.510525703430176}", "{\"n\": 7960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10668.306, \"total_train_time_s\": 14.622434854507446}", "{\"n\": 7961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10476.015, \"total_train_time_s\": 12.93635106086731}", "{\"n\": 7962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.05, \"learn_time_ms\": 10519.75, \"total_train_time_s\": 14.644952058792114}", "{\"n\": 7963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.87, \"learn_time_ms\": 10521.035, \"total_train_time_s\": 15.120125770568848}", "{\"n\": 7964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.87, \"learn_time_ms\": 10444.253, \"total_train_time_s\": 14.144871950149536}", "{\"n\": 7965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.66, \"learn_time_ms\": 10460.991, \"total_train_time_s\": 13.951916217803955}", "{\"n\": 7966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.24, \"learn_time_ms\": 10429.957, \"total_train_time_s\": 14.138193130493164}", "{\"n\": 7967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.08, \"learn_time_ms\": 10481.537, \"total_train_time_s\": 14.352644681930542}", "{\"n\": 7968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.22, \"learn_time_ms\": 10583.194, \"total_train_time_s\": 15.603733777999878}", "{\"n\": 7969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.42, \"learn_time_ms\": 10559.091, \"total_train_time_s\": 14.054125308990479}", "{\"n\": 7970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.24, \"learn_time_ms\": 10600.381, \"total_train_time_s\": 14.889789581298828}", "{\"n\": 7971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.47, \"learn_time_ms\": 10773.245, \"total_train_time_s\": 15.086984872817993}", "{\"n\": 7972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.47, \"learn_time_ms\": 10807.609, \"total_train_time_s\": 15.06785535812378}", "{\"n\": 7973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.06, \"learn_time_ms\": 10809.529, \"total_train_time_s\": 14.861263036727905}", "{\"n\": 7974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.06, \"learn_time_ms\": 10916.536, \"total_train_time_s\": 15.2240629196167}", "{\"n\": 7975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.13, \"learn_time_ms\": 10943.002, \"total_train_time_s\": 14.05707335472107}", "{\"n\": 7976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.93, \"learn_time_ms\": 11019.76, \"total_train_time_s\": 14.940416812896729}", "{\"n\": 7977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.93, \"learn_time_ms\": 10965.154, \"total_train_time_s\": 13.707720756530762}", "{\"n\": 7978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.09, \"learn_time_ms\": 10803.164, \"total_train_time_s\": 14.095906019210815}", "{\"n\": 7979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.35, \"learn_time_ms\": 10797.609, \"total_train_time_s\": 13.94755482673645}", "{\"n\": 7980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.32, \"learn_time_ms\": 10738.585, \"total_train_time_s\": 14.318264961242676}", "{\"n\": 7981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.22, \"learn_time_ms\": 10696.283, \"total_train_time_s\": 14.340059518814087}", "{\"n\": 7982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.62, \"learn_time_ms\": 10702.846, \"total_train_time_s\": 15.286955118179321}", "{\"n\": 7983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.33, \"learn_time_ms\": 10707.654, \"total_train_time_s\": 14.897356986999512}", "{\"n\": 7984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.33, \"learn_time_ms\": 10559.217, \"total_train_time_s\": 13.452548265457153}", "{\"n\": 7985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.79, \"learn_time_ms\": 10559.998, \"total_train_time_s\": 13.922636270523071}", "{\"n\": 7986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.92, \"learn_time_ms\": 10489.693, \"total_train_time_s\": 14.251158952713013}", "{\"n\": 7987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.25, \"learn_time_ms\": 10662.373, \"total_train_time_s\": 15.284440279006958}", "{\"n\": 7988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.25, \"learn_time_ms\": 10622.156, \"total_train_time_s\": 13.591584920883179}", "{\"n\": 7989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.79, \"learn_time_ms\": 10641.512, \"total_train_time_s\": 14.152236700057983}", "{\"n\": 7990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.42, \"learn_time_ms\": 10686.305, \"total_train_time_s\": 14.733139038085938}", "{\"n\": 7991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.85, \"learn_time_ms\": 10699.231, \"total_train_time_s\": 14.382583379745483}", "{\"n\": 7992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.85, \"learn_time_ms\": 10520.973, \"total_train_time_s\": 13.185174942016602}", "{\"n\": 7993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.34, \"learn_time_ms\": 10396.128, \"total_train_time_s\": 13.636814832687378}", "{\"n\": 7994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.85, \"learn_time_ms\": 10464.212, \"total_train_time_s\": 14.513413429260254}", "{\"n\": 7995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.43, \"learn_time_ms\": 10589.001, \"total_train_time_s\": 15.19471287727356}", "{\"n\": 7996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.43, \"learn_time_ms\": 10493.154, \"total_train_time_s\": 13.401012420654297}", "{\"n\": 7997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.1, \"learn_time_ms\": 10419.39, \"total_train_time_s\": 14.718999862670898}", "{\"n\": 7998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.31, \"learn_time_ms\": 10451.932, \"total_train_time_s\": 13.961926460266113}", "{\"n\": 7999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.31, \"learn_time_ms\": 10533.914, \"total_train_time_s\": 15.407033920288086}", "{\"n\": 8000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.94, \"learn_time_ms\": 10437.929, \"total_train_time_s\": 13.727243185043335}", "{\"n\": 8001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.78, \"learn_time_ms\": 10490.059, \"total_train_time_s\": 15.153717517852783}", "{\"n\": 8002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.78, \"learn_time_ms\": 10717.665, \"total_train_time_s\": 15.783168315887451}", "{\"n\": 8003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.85, \"learn_time_ms\": 10761.073, \"total_train_time_s\": 14.086425065994263}", "{\"n\": 8004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.82, \"learn_time_ms\": 10806.865, \"total_train_time_s\": 14.709680795669556}", "{\"n\": 8005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.66, \"learn_time_ms\": 10682.593, \"total_train_time_s\": 14.227981328964233}", "{\"n\": 8006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.53, \"learn_time_ms\": 10861.729, \"total_train_time_s\": 14.86897087097168}", "{\"n\": 8007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.53, \"learn_time_ms\": 10931.259, \"total_train_time_s\": 15.25255012512207}", "{\"n\": 8008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.93, \"learn_time_ms\": 10930.377, \"total_train_time_s\": 13.970341205596924}", "{\"n\": 8009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3550.93, \"learn_time_ms\": 10917.182, \"total_train_time_s\": 14.765566349029541}", "{\"n\": 8010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.15, \"learn_time_ms\": 11015.552, \"total_train_time_s\": 14.652888059616089}", "{\"n\": 8011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.15, \"learn_time_ms\": 10958.761, \"total_train_time_s\": 14.406706094741821}", "{\"n\": 8012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.01, \"learn_time_ms\": 10928.23, \"total_train_time_s\": 15.23442268371582}", "{\"n\": 8013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.01, \"learn_time_ms\": 10899.751, \"total_train_time_s\": 13.74725341796875}", "{\"n\": 8014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.23, \"learn_time_ms\": 10880.274, \"total_train_time_s\": 14.398430109024048}", "{\"n\": 8015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.36, \"learn_time_ms\": 10909.974, \"total_train_time_s\": 14.313372373580933}", "{\"n\": 8016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.36, \"learn_time_ms\": 10894.072, \"total_train_time_s\": 14.756510972976685}", "{\"n\": 8017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.24, \"learn_time_ms\": 10793.311, \"total_train_time_s\": 14.201244831085205}", "{\"n\": 8018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.61, \"learn_time_ms\": 10755.638, \"total_train_time_s\": 13.64617371559143}", "{\"n\": 8019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.61, \"learn_time_ms\": 10687.744, \"total_train_time_s\": 14.096768856048584}", "{\"n\": 8020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.61, \"learn_time_ms\": 10813.027, \"total_train_time_s\": 16.12701678276062}", "{\"n\": 8021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3540.02, \"learn_time_ms\": 10861.299, \"total_train_time_s\": 15.185183763504028}", "{\"n\": 8022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.82, \"learn_time_ms\": 10826.575, \"total_train_time_s\": 14.989959478378296}", "{\"n\": 8023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.82, \"learn_time_ms\": 10833.346, \"total_train_time_s\": 13.98443055152893}", "{\"n\": 8024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.82, \"learn_time_ms\": 10822.492, \"total_train_time_s\": 14.240890502929688}", "{\"n\": 8025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.88, \"learn_time_ms\": 10861.875, \"total_train_time_s\": 14.58163070678711}", "{\"n\": 8026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3534.75, \"learn_time_ms\": 10841.958, \"total_train_time_s\": 14.580136775970459}", "{\"n\": 8027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3534.75, \"learn_time_ms\": 10776.533, \"total_train_time_s\": 13.678386211395264}", "{\"n\": 8028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.74, \"learn_time_ms\": 10789.188, \"total_train_time_s\": 13.577914237976074}", "{\"n\": 8029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3539.39, \"learn_time_ms\": 10772.983, \"total_train_time_s\": 14.095819234848022}", "{\"n\": 8030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.65, \"learn_time_ms\": 10467.815, \"total_train_time_s\": 12.920695781707764}", "{\"n\": 8031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.65, \"learn_time_ms\": 10338.57, \"total_train_time_s\": 13.93079400062561}", "{\"n\": 8032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.65, \"learn_time_ms\": 10368.057, \"total_train_time_s\": 15.368881464004517}", "{\"n\": 8033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3549.48, \"learn_time_ms\": 10471.646, \"total_train_time_s\": 14.871826171875}", "{\"n\": 8034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3549.48, \"learn_time_ms\": 10444.579, \"total_train_time_s\": 14.385036945343018}", "{\"n\": 8035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3549.48, \"learn_time_ms\": 10410.245, \"total_train_time_s\": 14.510663270950317}", "{\"n\": 8036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.96, \"learn_time_ms\": 10457.364, \"total_train_time_s\": 15.261606931686401}", "{\"n\": 8037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.96, \"learn_time_ms\": 10555.013, \"total_train_time_s\": 14.748502731323242}", "{\"n\": 8038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.96, \"learn_time_ms\": 10639.188, \"total_train_time_s\": 14.337990045547485}", "{\"n\": 8039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.35, \"learn_time_ms\": 10598.32, \"total_train_time_s\": 13.6279137134552}", "{\"n\": 8040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 10799.383, \"total_train_time_s\": 14.829346179962158}", "{\"n\": 8041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 10776.742, \"total_train_time_s\": 13.374684572219849}", "{\"n\": 8042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.34, \"learn_time_ms\": 10731.118, \"total_train_time_s\": 14.67847490310669}", "{\"n\": 8043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.32, \"learn_time_ms\": 10675.446, \"total_train_time_s\": 14.541230201721191}", "{\"n\": 8044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.32, \"learn_time_ms\": 10756.828, \"total_train_time_s\": 14.804921865463257}", "{\"n\": 8045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.32, \"learn_time_ms\": 10661.933, \"total_train_time_s\": 13.338851690292358}", "{\"n\": 8046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.15, \"learn_time_ms\": 10520.33, \"total_train_time_s\": 13.766572713851929}", "{\"n\": 8047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.02, \"learn_time_ms\": 10441.347, \"total_train_time_s\": 13.931490659713745}", "{\"n\": 8048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.02, \"learn_time_ms\": 10451.461, \"total_train_time_s\": 14.521697521209717}", "{\"n\": 8049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.02, \"learn_time_ms\": 10408.732, \"total_train_time_s\": 13.452061176300049}", "{\"n\": 8050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.9, \"learn_time_ms\": 10317.328, \"total_train_time_s\": 14.17497706413269}", "{\"n\": 8051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.53, \"learn_time_ms\": 10422.354, \"total_train_time_s\": 14.419822692871094}", "{\"n\": 8052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.53, \"learn_time_ms\": 10435.542, \"total_train_time_s\": 15.176273822784424}", "{\"n\": 8053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.04, \"learn_time_ms\": 10445.596, \"total_train_time_s\": 14.416212320327759}", "{\"n\": 8054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.26, \"learn_time_ms\": 10495.868, \"total_train_time_s\": 15.34004259109497}", "{\"n\": 8055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.98, \"learn_time_ms\": 10557.882, \"total_train_time_s\": 13.951752185821533}", "{\"n\": 8056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.68, \"learn_time_ms\": 10652.143, \"total_train_time_s\": 14.815601348876953}", "{\"n\": 8057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3533.81, \"learn_time_ms\": 10790.22, \"total_train_time_s\": 15.575942993164062}", "{\"n\": 8058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 10797.481, \"total_train_time_s\": 14.684275388717651}", "{\"n\": 8059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.4, \"learn_time_ms\": 10882.909, \"total_train_time_s\": 14.437929391860962}", "{\"n\": 8060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.4, \"learn_time_ms\": 10895.271, \"total_train_time_s\": 14.060663938522339}", "{\"n\": 8061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.19, \"learn_time_ms\": 10733.95, \"total_train_time_s\": 12.987229347229004}", "{\"n\": 8062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.09, \"learn_time_ms\": 10773.638, \"total_train_time_s\": 15.27957797050476}", "{\"n\": 8063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.98, \"learn_time_ms\": 10678.605, \"total_train_time_s\": 13.4530668258667}", "{\"n\": 8064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.38, \"learn_time_ms\": 10609.734, \"total_train_time_s\": 14.69609546661377}", "{\"n\": 8065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.49, \"learn_time_ms\": 10524.84, \"total_train_time_s\": 13.22588586807251}", "{\"n\": 8066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.79, \"learn_time_ms\": 10610.029, \"total_train_time_s\": 15.454197645187378}", "{\"n\": 8067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.15, \"learn_time_ms\": 10484.325, \"total_train_time_s\": 13.890995502471924}", "{\"n\": 8068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.15, \"learn_time_ms\": 10409.777, \"total_train_time_s\": 14.060007572174072}", "{\"n\": 8069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.42, \"learn_time_ms\": 10280.925, \"total_train_time_s\": 12.715142011642456}", "{\"n\": 8070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.92, \"learn_time_ms\": 10347.168, \"total_train_time_s\": 14.668118238449097}", "{\"n\": 8071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.95, \"learn_time_ms\": 10490.774, \"total_train_time_s\": 14.300329446792603}", "{\"n\": 8072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.89, \"learn_time_ms\": 10349.955, \"total_train_time_s\": 14.17780351638794}", "{\"n\": 8073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 10450.167, \"total_train_time_s\": 14.459871292114258}", "{\"n\": 8074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 10400.996, \"total_train_time_s\": 14.25631070137024}", "{\"n\": 8075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.83, \"learn_time_ms\": 10455.111, \"total_train_time_s\": 13.546174049377441}", "{\"n\": 8076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.59, \"learn_time_ms\": 10205.131, \"total_train_time_s\": 13.272811651229858}", "{\"n\": 8077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.68, \"learn_time_ms\": 10288.355, \"total_train_time_s\": 14.729218482971191}", "{\"n\": 8078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.68, \"learn_time_ms\": 10301.777, \"total_train_time_s\": 14.05704927444458}", "{\"n\": 8079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.91, \"learn_time_ms\": 10454.754, \"total_train_time_s\": 14.407679796218872}", "{\"n\": 8080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.91, \"learn_time_ms\": 10397.985, \"total_train_time_s\": 14.363056659698486}", "{\"n\": 8081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.1, \"learn_time_ms\": 10502.211, \"total_train_time_s\": 15.325328350067139}", "{\"n\": 8082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.1, \"learn_time_ms\": 10633.997, \"total_train_time_s\": 15.290570974349976}", "{\"n\": 8083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.71, \"learn_time_ms\": 10561.037, \"total_train_time_s\": 14.04419755935669}", "{\"n\": 8084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.86, \"learn_time_ms\": 10540.051, \"total_train_time_s\": 14.138027429580688}", "{\"n\": 8085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.78, \"learn_time_ms\": 10264.762, \"total_train_time_s\": 10.991079092025757}", "{\"n\": 8086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.78, \"learn_time_ms\": 10299.712, \"total_train_time_s\": 13.396687030792236}", "{\"n\": 8087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.94, \"learn_time_ms\": 10172.619, \"total_train_time_s\": 13.50597071647644}", "{\"n\": 8088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.96, \"learn_time_ms\": 10229.053, \"total_train_time_s\": 14.930504560470581}", "{\"n\": 8089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.29, \"learn_time_ms\": 10152.852, \"total_train_time_s\": 13.62499213218689}", "{\"n\": 8090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.54, \"learn_time_ms\": 10196.73, \"total_train_time_s\": 14.882020473480225}", "{\"n\": 8091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.55, \"learn_time_ms\": 10098.789, \"total_train_time_s\": 14.32710886001587}", "{\"n\": 8092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.55, \"learn_time_ms\": 10050.327, \"total_train_time_s\": 14.668471336364746}", "{\"n\": 8093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.6, \"learn_time_ms\": 10063.51, \"total_train_time_s\": 14.379732608795166}", "{\"n\": 8094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.79, \"learn_time_ms\": 10087.154, \"total_train_time_s\": 14.69912576675415}", "{\"n\": 8095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.33, \"learn_time_ms\": 10540.572, \"total_train_time_s\": 15.949060440063477}", "{\"n\": 8096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.33, \"learn_time_ms\": 10613.827, \"total_train_time_s\": 14.084745407104492}", "{\"n\": 8097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.77, \"learn_time_ms\": 10711.552, \"total_train_time_s\": 14.564646005630493}", "{\"n\": 8098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.39, \"learn_time_ms\": 10728.061, \"total_train_time_s\": 15.027153253555298}", "{\"n\": 8099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.97, \"learn_time_ms\": 10837.164, \"total_train_time_s\": 14.633321285247803}", "{\"n\": 8100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.01, \"learn_time_ms\": 10747.843, \"total_train_time_s\": 13.78783893585205}", "{\"n\": 8101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.01, \"learn_time_ms\": 10806.597, \"total_train_time_s\": 15.047161102294922}", "{\"n\": 8102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.32, \"learn_time_ms\": 10702.909, \"total_train_time_s\": 13.663206338882446}", "{\"n\": 8103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.67, \"learn_time_ms\": 10610.57, \"total_train_time_s\": 13.021261930465698}", "{\"n\": 8104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.67, \"learn_time_ms\": 10654.439, \"total_train_time_s\": 14.859379768371582}", "{\"n\": 8105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.69, \"learn_time_ms\": 10465.174, \"total_train_time_s\": 13.559537172317505}", "{\"n\": 8106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.72, \"learn_time_ms\": 10434.099, \"total_train_time_s\": 13.657443761825562}", "{\"n\": 8107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.31, \"learn_time_ms\": 10336.042, \"total_train_time_s\": 13.703819751739502}", "{\"n\": 8108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.31, \"learn_time_ms\": 10461.601, \"total_train_time_s\": 16.11080265045166}", "{\"n\": 8109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.57, \"learn_time_ms\": 10359.134, \"total_train_time_s\": 13.72922134399414}", "{\"n\": 8110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.57, \"learn_time_ms\": 10527.598, \"total_train_time_s\": 15.46753740310669}", "{\"n\": 8111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.36, \"learn_time_ms\": 10491.001, \"total_train_time_s\": 14.558040857315063}", "{\"n\": 8112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.03, \"learn_time_ms\": 10553.434, \"total_train_time_s\": 14.229658126831055}", "{\"n\": 8113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.49, \"learn_time_ms\": 10702.037, \"total_train_time_s\": 14.562268733978271}", "{\"n\": 8114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.49, \"learn_time_ms\": 10589.249, \"total_train_time_s\": 13.556450128555298}", "{\"n\": 8115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.68, \"learn_time_ms\": 10624.118, \"total_train_time_s\": 13.873332977294922}", "{\"n\": 8116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3746.98, \"learn_time_ms\": 10683.66, \"total_train_time_s\": 14.463988304138184}", "{\"n\": 8117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3744.57, \"learn_time_ms\": 10719.913, \"total_train_time_s\": 13.922013998031616}", "{\"n\": 8118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3744.57, \"learn_time_ms\": 10483.605, \"total_train_time_s\": 13.857565879821777}", "{\"n\": 8119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.91, \"learn_time_ms\": 10497.122, \"total_train_time_s\": 13.730000734329224}", "{\"n\": 8120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.66, \"learn_time_ms\": 10371.002, \"total_train_time_s\": 14.229834794998169}", "{\"n\": 8121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.0, \"learn_time_ms\": 10311.664, \"total_train_time_s\": 13.899705410003662}", "{\"n\": 8122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3745.6, \"learn_time_ms\": 10327.531, \"total_train_time_s\": 14.494548797607422}", "{\"n\": 8123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3746.55, \"learn_time_ms\": 10317.505, \"total_train_time_s\": 14.42697286605835}", "{\"n\": 8124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3746.55, \"learn_time_ms\": 10389.512, \"total_train_time_s\": 14.299628734588623}", "{\"n\": 8125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.04, \"learn_time_ms\": 10470.096, \"total_train_time_s\": 14.771049737930298}", "{\"n\": 8126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3745.22, \"learn_time_ms\": 10525.929, \"total_train_time_s\": 14.932512044906616}", "{\"n\": 8127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.48, \"learn_time_ms\": 10661.444, \"total_train_time_s\": 15.316571712493896}", "{\"n\": 8128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.48, \"learn_time_ms\": 10744.182, \"total_train_time_s\": 14.591878175735474}", "{\"n\": 8129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3751.91, \"learn_time_ms\": 10788.647, \"total_train_time_s\": 14.349113464355469}", "{\"n\": 8130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3755.25, \"learn_time_ms\": 10865.295, \"total_train_time_s\": 14.971758127212524}", "{\"n\": 8131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3755.25, \"learn_time_ms\": 10916.292, \"total_train_time_s\": 14.776492595672607}", "{\"n\": 8132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3755.25, \"learn_time_ms\": 10865.704, \"total_train_time_s\": 13.866449117660522}", "{\"n\": 8133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3768.26, \"learn_time_ms\": 10846.806, \"total_train_time_s\": 14.418184280395508}", "{\"n\": 8134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3771.51, \"learn_time_ms\": 10820.108, \"total_train_time_s\": 13.953068733215332}", "{\"n\": 8135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3771.51, \"learn_time_ms\": 10679.236, \"total_train_time_s\": 13.190829515457153}", "{\"n\": 8136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3771.51, \"learn_time_ms\": 10667.87, \"total_train_time_s\": 14.701443433761597}", "{\"n\": 8137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3775.18, \"learn_time_ms\": 10553.787, \"total_train_time_s\": 14.089999198913574}", "{\"n\": 8138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3786.47, \"learn_time_ms\": 10576.633, \"total_train_time_s\": 14.873634099960327}", "{\"n\": 8139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3792.97, \"learn_time_ms\": 10507.448, \"total_train_time_s\": 13.470665216445923}", "{\"n\": 8140, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3800.84, \"learn_time_ms\": 10500.108, \"total_train_time_s\": 14.887151956558228}", "{\"n\": 8141, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3797.02, \"learn_time_ms\": 10507.038, \"total_train_time_s\": 14.534508228302002}", "{\"n\": 8142, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3805.99, \"learn_time_ms\": 10632.785, \"total_train_time_s\": 15.134584188461304}", "{\"n\": 8143, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3795.21, \"learn_time_ms\": 10529.166, \"total_train_time_s\": 13.169407606124878}", "{\"n\": 8144, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3801.59, \"learn_time_ms\": 10507.19, \"total_train_time_s\": 13.950927734375}", "{\"n\": 8145, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3801.59, \"learn_time_ms\": 10751.064, \"total_train_time_s\": 15.966838598251343}", "{\"n\": 8146, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3798.39, \"learn_time_ms\": 10858.094, \"total_train_time_s\": 15.877473831176758}", "{\"n\": 8147, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3794.4, \"learn_time_ms\": 10909.023, \"total_train_time_s\": 14.77573299407959}", "{\"n\": 8148, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3791.73, \"learn_time_ms\": 10964.55, \"total_train_time_s\": 15.302426099777222}", "{\"n\": 8149, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3797.91, \"learn_time_ms\": 11080.532, \"total_train_time_s\": 14.811949014663696}", "{\"n\": 8150, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3796.86, \"learn_time_ms\": 11008.706, \"total_train_time_s\": 14.455049991607666}", "{\"n\": 8151, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3802.5, \"learn_time_ms\": 10965.543, \"total_train_time_s\": 14.295322179794312}", "{\"n\": 8152, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3802.5, \"learn_time_ms\": 10898.031, \"total_train_time_s\": 14.475029468536377}", "{\"n\": 8153, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3799.66, \"learn_time_ms\": 10995.359, \"total_train_time_s\": 14.047849655151367}", "{\"n\": 8154, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3801.72, \"learn_time_ms\": 11021.698, \"total_train_time_s\": 14.248141050338745}", "{\"n\": 8155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3805.08, \"learn_time_ms\": 11025.025, \"total_train_time_s\": 15.852712631225586}", "{\"n\": 8156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3805.08, \"learn_time_ms\": 10939.196, \"total_train_time_s\": 15.052550315856934}", "{\"n\": 8157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3808.04, \"learn_time_ms\": 10882.452, \"total_train_time_s\": 13.939064025878906}", "{\"n\": 8158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3808.04, \"learn_time_ms\": 10670.236, \"total_train_time_s\": 13.055112600326538}", "{\"n\": 8159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3825.72, \"learn_time_ms\": 10691.302, \"total_train_time_s\": 15.145016431808472}", "{\"n\": 8160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3826.13, \"learn_time_ms\": 10734.04, \"total_train_time_s\": 14.603135824203491}", "{\"n\": 8161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3826.13, \"learn_time_ms\": 10793.442, \"total_train_time_s\": 14.764764785766602}", "{\"n\": 8162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3814.89, \"learn_time_ms\": 10735.897, \"total_train_time_s\": 13.880922317504883}", "{\"n\": 8163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3816.34, \"learn_time_ms\": 10809.865, \"total_train_time_s\": 15.210215091705322}", "{\"n\": 8164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3816.34, \"learn_time_ms\": 10825.612, \"total_train_time_s\": 14.16231632232666}", "{\"n\": 8165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3816.34, \"learn_time_ms\": 10683.811, \"total_train_time_s\": 14.344635725021362}", "{\"n\": 8166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3804.03, \"learn_time_ms\": 10635.035, \"total_train_time_s\": 14.748449325561523}", "{\"n\": 8167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3784.1, \"learn_time_ms\": 10679.91, \"total_train_time_s\": 14.401190757751465}", "{\"n\": 8168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3784.1, \"learn_time_ms\": 10717.072, \"total_train_time_s\": 13.829890727996826}", "{\"n\": 8169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3779.81, \"learn_time_ms\": 10676.158, \"total_train_time_s\": 14.430156946182251}", "{\"n\": 8170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3786.01, \"learn_time_ms\": 10628.205, \"total_train_time_s\": 14.272742509841919}", "{\"n\": 8171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3784.55, \"learn_time_ms\": 10710.63, \"total_train_time_s\": 15.512275218963623}", "{\"n\": 8172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3765.81, \"learn_time_ms\": 10794.668, \"total_train_time_s\": 14.90446662902832}", "{\"n\": 8173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3765.81, \"learn_time_ms\": 10760.414, \"total_train_time_s\": 14.505811929702759}", "{\"n\": 8174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.3, \"learn_time_ms\": 10721.219, \"total_train_time_s\": 14.027213096618652}", "{\"n\": 8175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.3, \"learn_time_ms\": 10632.624, \"total_train_time_s\": 13.620819330215454}", "{\"n\": 8176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3750.84, \"learn_time_ms\": 10575.83, \"total_train_time_s\": 14.130218982696533}", "{\"n\": 8177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.49, \"learn_time_ms\": 10429.224, \"total_train_time_s\": 13.051260709762573}", "{\"n\": 8178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.49, \"learn_time_ms\": 10608.516, \"total_train_time_s\": 15.392887830734253}", "{\"n\": 8179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.43, \"learn_time_ms\": 10676.62, \"total_train_time_s\": 15.149783611297607}", "{\"n\": 8180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.74, \"learn_time_ms\": 10734.453, \"total_train_time_s\": 14.637239456176758}", "{\"n\": 8181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.88, \"learn_time_ms\": 10558.381, \"total_train_time_s\": 13.739624261856079}", "{\"n\": 8182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.88, \"learn_time_ms\": 10452.476, \"total_train_time_s\": 14.032885551452637}", "{\"n\": 8183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.53, \"learn_time_ms\": 10508.232, \"total_train_time_s\": 15.035948514938354}", "{\"n\": 8184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.53, \"learn_time_ms\": 10524.804, \"total_train_time_s\": 14.214484453201294}", "{\"n\": 8185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.51, \"learn_time_ms\": 10607.499, \"total_train_time_s\": 14.370386600494385}", "{\"n\": 8186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.51, \"learn_time_ms\": 10789.274, \"total_train_time_s\": 16.160372257232666}", "{\"n\": 8187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.19, \"learn_time_ms\": 10911.741, \"total_train_time_s\": 14.242811441421509}", "{\"n\": 8188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.99, \"learn_time_ms\": 10764.306, \"total_train_time_s\": 14.18845796585083}", "{\"n\": 8189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.94, \"learn_time_ms\": 10648.219, \"total_train_time_s\": 14.061456203460693}", "{\"n\": 8190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.57, \"learn_time_ms\": 10550.545, \"total_train_time_s\": 13.761608600616455}", "{\"n\": 8191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.8, \"learn_time_ms\": 10653.801, \"total_train_time_s\": 15.01173448562622}", "{\"n\": 8192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.8, \"learn_time_ms\": 10764.251, \"total_train_time_s\": 15.246777534484863}", "{\"n\": 8193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.33, \"learn_time_ms\": 10727.893, \"total_train_time_s\": 14.680224657058716}", "{\"n\": 8194, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.64, \"learn_time_ms\": 10684.45, \"total_train_time_s\": 13.470413446426392}", "{\"n\": 8195, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.69, \"learn_time_ms\": 10650.959, \"total_train_time_s\": 14.022481441497803}", "{\"n\": 8196, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.08, \"learn_time_ms\": 10417.525, \"total_train_time_s\": 13.3475182056427}", "{\"n\": 8197, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.66, \"learn_time_ms\": 10473.045, \"total_train_time_s\": 14.93166732788086}", "{\"n\": 8198, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.66, \"learn_time_ms\": 10404.357, \"total_train_time_s\": 13.234901666641235}", "{\"n\": 8199, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.5, \"learn_time_ms\": 10460.234, \"total_train_time_s\": 14.52974820137024}", "{\"n\": 8200, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.97, \"learn_time_ms\": 10549.324, \"total_train_time_s\": 14.51762342453003}", "{\"n\": 8201, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.03, \"learn_time_ms\": 10620.781, \"total_train_time_s\": 15.531994819641113}", "{\"n\": 8202, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.44, \"learn_time_ms\": 10637.311, \"total_train_time_s\": 14.883579730987549}", "{\"n\": 8203, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.62, \"learn_time_ms\": 10623.622, \"total_train_time_s\": 14.661820888519287}", "{\"n\": 8204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.21, \"learn_time_ms\": 10610.418, \"total_train_time_s\": 13.464102268218994}", "{\"n\": 8205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.21, \"learn_time_ms\": 10492.792, \"total_train_time_s\": 12.67830228805542}", "{\"n\": 8206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.65, \"learn_time_ms\": 10527.459, \"total_train_time_s\": 13.7971670627594}", "{\"n\": 8207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.65, \"learn_time_ms\": 10422.584, \"total_train_time_s\": 14.049283742904663}", "{\"n\": 8208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.07, \"learn_time_ms\": 10440.643, \"total_train_time_s\": 13.611631870269775}", "{\"n\": 8209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.07, \"learn_time_ms\": 10416.657, \"total_train_time_s\": 14.701239347457886}", "{\"n\": 8210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.27, \"learn_time_ms\": 10413.496, \"total_train_time_s\": 14.550121545791626}", "{\"n\": 8211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.27, \"learn_time_ms\": 10348.9, \"total_train_time_s\": 14.89000153541565}", "{\"n\": 8212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.02, \"learn_time_ms\": 10205.415, \"total_train_time_s\": 13.508620500564575}", "{\"n\": 8213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.04, \"learn_time_ms\": 10212.808, \"total_train_time_s\": 14.78590440750122}", "{\"n\": 8214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.62, \"learn_time_ms\": 10361.043, \"total_train_time_s\": 15.012681722640991}", "{\"n\": 8215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.21, \"learn_time_ms\": 10582.192, \"total_train_time_s\": 15.252700328826904}", "{\"n\": 8216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.4, \"learn_time_ms\": 10522.667, \"total_train_time_s\": 13.241701126098633}", "{\"n\": 8217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.8, \"learn_time_ms\": 10558.675, \"total_train_time_s\": 13.956676244735718}", "{\"n\": 8218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.8, \"learn_time_ms\": 10638.357, \"total_train_time_s\": 14.351394414901733}", "{\"n\": 8219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.12, \"learn_time_ms\": 10653.465, \"total_train_time_s\": 14.591734647750854}", "{\"n\": 8220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.45, \"learn_time_ms\": 10573.655, \"total_train_time_s\": 13.976025819778442}", "{\"n\": 8221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 10454.248, \"total_train_time_s\": 13.709826231002808}", "{\"n\": 8222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 10611.205, \"total_train_time_s\": 15.211005210876465}", "{\"n\": 8223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.82, \"learn_time_ms\": 10645.447, \"total_train_time_s\": 14.971635580062866}", "{\"n\": 8224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.82, \"learn_time_ms\": 10525.954, \"total_train_time_s\": 13.737581968307495}", "{\"n\": 8225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.0, \"learn_time_ms\": 10382.627, \"total_train_time_s\": 13.862124919891357}", "{\"n\": 8226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.0, \"learn_time_ms\": 10524.976, \"total_train_time_s\": 14.705466032028198}", "{\"n\": 8227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.07, \"learn_time_ms\": 10562.428, \"total_train_time_s\": 14.42365312576294}", "{\"n\": 8228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.07, \"learn_time_ms\": 10672.889, \"total_train_time_s\": 15.292571067810059}", "{\"n\": 8229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.15, \"learn_time_ms\": 10739.814, \"total_train_time_s\": 15.16189432144165}", "{\"n\": 8230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.45, \"learn_time_ms\": 10739.21, \"total_train_time_s\": 13.884568452835083}", "{\"n\": 8231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.03, \"learn_time_ms\": 10772.497, \"total_train_time_s\": 13.916524171829224}", "{\"n\": 8232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.03, \"learn_time_ms\": 10628.96, \"total_train_time_s\": 13.926261901855469}", "{\"n\": 8233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.98, \"learn_time_ms\": 10661.608, \"total_train_time_s\": 15.27847933769226}", "{\"n\": 8234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.24, \"learn_time_ms\": 10708.956, \"total_train_time_s\": 14.20564317703247}", "{\"n\": 8235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.24, \"learn_time_ms\": 10657.674, \"total_train_time_s\": 13.568369150161743}", "{\"n\": 8236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.52, \"learn_time_ms\": 10621.189, \"total_train_time_s\": 14.660572528839111}", "{\"n\": 8237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.0, \"learn_time_ms\": 10692.987, \"total_train_time_s\": 15.268489837646484}", "{\"n\": 8238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.23, \"learn_time_ms\": 10677.113, \"total_train_time_s\": 15.210452795028687}", "{\"n\": 8239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.23, \"learn_time_ms\": 10532.168, \"total_train_time_s\": 13.594807147979736}", "{\"n\": 8240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.42, \"learn_time_ms\": 10635.459, \"total_train_time_s\": 14.86516523361206}", "{\"n\": 8241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.66, \"learn_time_ms\": 10680.788, \"total_train_time_s\": 14.632962942123413}", "{\"n\": 8242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.66, \"learn_time_ms\": 10908.591, \"total_train_time_s\": 16.27336621284485}", "{\"n\": 8243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.66, \"learn_time_ms\": 10796.797, \"total_train_time_s\": 14.541423082351685}", "{\"n\": 8244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.59, \"learn_time_ms\": 10879.111, \"total_train_time_s\": 15.059995889663696}", "{\"n\": 8245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.66, \"learn_time_ms\": 11019.185, \"total_train_time_s\": 14.385324239730835}", "{\"n\": 8246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.66, \"learn_time_ms\": 11077.733, \"total_train_time_s\": 14.798878908157349}", "{\"n\": 8247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.66, \"learn_time_ms\": 10984.557, \"total_train_time_s\": 14.25354814529419}", "{\"n\": 8248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.71, \"learn_time_ms\": 10971.058, \"total_train_time_s\": 15.182778120040894}", "{\"n\": 8249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.09, \"learn_time_ms\": 10995.226, \"total_train_time_s\": 14.2163405418396}", "{\"n\": 8250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.54, \"learn_time_ms\": 11052.888, \"total_train_time_s\": 15.22920823097229}", "{\"n\": 8251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.54, \"learn_time_ms\": 10891.131, \"total_train_time_s\": 12.723286867141724}", "{\"n\": 8252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.73, \"learn_time_ms\": 10724.647, \"total_train_time_s\": 14.30541729927063}", "{\"n\": 8253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.73, \"learn_time_ms\": 10743.408, \"total_train_time_s\": 14.51813793182373}", "{\"n\": 8254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.84, \"learn_time_ms\": 10660.003, \"total_train_time_s\": 14.147066593170166}", "{\"n\": 8255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.21, \"learn_time_ms\": 10562.764, \"total_train_time_s\": 13.401891946792603}", "{\"n\": 8256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.48, \"learn_time_ms\": 10567.784, \"total_train_time_s\": 15.203025341033936}", "{\"n\": 8257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.65, \"learn_time_ms\": 10547.214, \"total_train_time_s\": 14.197872877120972}", "{\"n\": 8258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.65, \"learn_time_ms\": 10616.036, \"total_train_time_s\": 15.76475477218628}", "{\"n\": 8259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.76, \"learn_time_ms\": 10623.877, \"total_train_time_s\": 14.07866358757019}", "{\"n\": 8260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.97, \"learn_time_ms\": 10453.316, \"total_train_time_s\": 13.703380584716797}", "{\"n\": 8261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.81, \"learn_time_ms\": 10644.343, \"total_train_time_s\": 14.710819959640503}", "{\"n\": 8262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.81, \"learn_time_ms\": 10736.148, \"total_train_time_s\": 15.521858930587769}", "{\"n\": 8263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.97, \"learn_time_ms\": 10761.266, \"total_train_time_s\": 14.720240592956543}", "{\"n\": 8264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.39, \"learn_time_ms\": 10784.819, \"total_train_time_s\": 14.713627815246582}", "{\"n\": 8265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.01, \"learn_time_ms\": 10858.885, \"total_train_time_s\": 14.498459577560425}", "{\"n\": 8266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.47, \"learn_time_ms\": 10789.264, \"total_train_time_s\": 14.395302772521973}", "{\"n\": 8267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.02, \"learn_time_ms\": 10853.47, \"total_train_time_s\": 14.636149883270264}", "{\"n\": 8268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.84, \"learn_time_ms\": 10859.041, \"total_train_time_s\": 15.916359901428223}", "{\"n\": 8269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.39, \"learn_time_ms\": 10984.431, \"total_train_time_s\": 15.132278680801392}", "{\"n\": 8270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.96, \"learn_time_ms\": 11105.93, \"total_train_time_s\": 15.020514726638794}", "{\"n\": 8271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.11, \"learn_time_ms\": 11000.435, \"total_train_time_s\": 13.812732934951782}", "{\"n\": 8272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.11, \"learn_time_ms\": 10906.158, \"total_train_time_s\": 14.496080875396729}", "{\"n\": 8273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.71, \"learn_time_ms\": 10960.433, \"total_train_time_s\": 15.296988725662231}", "{\"n\": 8274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.18, \"learn_time_ms\": 11015.685, \"total_train_time_s\": 14.92572283744812}", "{\"n\": 8275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.23, \"learn_time_ms\": 10913.944, \"total_train_time_s\": 13.255208730697632}", "{\"n\": 8276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.44, \"learn_time_ms\": 10906.938, \"total_train_time_s\": 14.201590299606323}", "{\"n\": 8277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.91, \"learn_time_ms\": 10944.359, \"total_train_time_s\": 15.265685319900513}", "{\"n\": 8278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.54, \"learn_time_ms\": 10784.688, \"total_train_time_s\": 14.213373184204102}", "{\"n\": 8279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.54, \"learn_time_ms\": 10665.17, \"total_train_time_s\": 13.90138053894043}", "{\"n\": 8280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.91, \"learn_time_ms\": 10598.334, \"total_train_time_s\": 14.41994857788086}", "{\"n\": 8281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.27, \"learn_time_ms\": 10730.447, \"total_train_time_s\": 15.096558809280396}", "{\"n\": 8282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.27, \"learn_time_ms\": 10790.03, \"total_train_time_s\": 15.040292978286743}", "{\"n\": 8283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.75, \"learn_time_ms\": 10607.767, \"total_train_time_s\": 13.370487928390503}", "{\"n\": 8284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.98, \"learn_time_ms\": 10567.665, \"total_train_time_s\": 14.757972240447998}", "{\"n\": 8285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.25, \"learn_time_ms\": 10781.618, \"total_train_time_s\": 15.372179746627808}", "{\"n\": 8286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.84, \"learn_time_ms\": 10849.404, \"total_train_time_s\": 14.978777170181274}", "{\"n\": 8287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10887.89, \"total_train_time_s\": 15.404205322265625}", "{\"n\": 8288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 10877.257, \"total_train_time_s\": 14.006214618682861}", "{\"n\": 8289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 10935.827, \"total_train_time_s\": 14.929501056671143}", "{\"n\": 8290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 11040.961, \"total_train_time_s\": 15.380012512207031}", "{\"n\": 8291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.46, \"learn_time_ms\": 10883.701, \"total_train_time_s\": 13.38840103149414}", "{\"n\": 8292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.52, \"learn_time_ms\": 10797.127, \"total_train_time_s\": 14.229481220245361}", "{\"n\": 8293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.78, \"learn_time_ms\": 10878.641, \"total_train_time_s\": 14.10984206199646}", "{\"n\": 8294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.78, \"learn_time_ms\": 10967.865, \"total_train_time_s\": 15.655926704406738}", "{\"n\": 8295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.8, \"learn_time_ms\": 10897.611, \"total_train_time_s\": 14.70264720916748}", "{\"n\": 8296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.8, \"learn_time_ms\": 10767.59, \"total_train_time_s\": 13.748564720153809}", "{\"n\": 8297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 10756.932, \"total_train_time_s\": 15.236949920654297}", "{\"n\": 8298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.81, \"learn_time_ms\": 10728.248, \"total_train_time_s\": 13.77225661277771}", "{\"n\": 8299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.02, \"learn_time_ms\": 10674.502, \"total_train_time_s\": 14.070410251617432}", "{\"n\": 8300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.02, \"learn_time_ms\": 10568.507, \"total_train_time_s\": 14.058118104934692}", "{\"n\": 8301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.72, \"learn_time_ms\": 10624.387, \"total_train_time_s\": 13.919842958450317}", "{\"n\": 8302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.3, \"learn_time_ms\": 10574.651, \"total_train_time_s\": 13.557065963745117}", "{\"n\": 8303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.3, \"learn_time_ms\": 10554.715, \"total_train_time_s\": 13.922132968902588}", "{\"n\": 8304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.23, \"learn_time_ms\": 10366.75, \"total_train_time_s\": 13.480407953262329}", "{\"n\": 8305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10444.352, \"total_train_time_s\": 15.3367178440094}", "{\"n\": 8306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.77, \"learn_time_ms\": 10536.045, \"total_train_time_s\": 14.345699548721313}", "{\"n\": 8307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.02, \"learn_time_ms\": 10298.923, \"total_train_time_s\": 13.051178216934204}", "{\"n\": 8308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.02, \"learn_time_ms\": 10403.639, \"total_train_time_s\": 14.753676891326904}", "{\"n\": 8309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.9, \"learn_time_ms\": 10441.109, \"total_train_time_s\": 14.501548051834106}", "{\"n\": 8310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.66, \"learn_time_ms\": 10465.799, \"total_train_time_s\": 14.48269510269165}", "{\"n\": 8311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.66, \"learn_time_ms\": 10440.317, \"total_train_time_s\": 13.75028920173645}", "{\"n\": 8312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.65, \"learn_time_ms\": 10523.606, \"total_train_time_s\": 14.275777578353882}", "{\"n\": 8313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.45, \"learn_time_ms\": 10584.91, \"total_train_time_s\": 14.583386898040771}", "{\"n\": 8314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.58, \"learn_time_ms\": 10726.174, \"total_train_time_s\": 15.129794359207153}", "{\"n\": 8315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.58, \"learn_time_ms\": 10687.125, \"total_train_time_s\": 15.33485460281372}", "{\"n\": 8316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.4, \"learn_time_ms\": 10752.265, \"total_train_time_s\": 15.137992143630981}", "{\"n\": 8317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.96, \"learn_time_ms\": 10758.51, \"total_train_time_s\": 13.081604242324829}", "{\"n\": 8318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.51, \"learn_time_ms\": 10697.017, \"total_train_time_s\": 14.329965114593506}", "{\"n\": 8319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.75, \"learn_time_ms\": 10719.019, \"total_train_time_s\": 14.875558614730835}", "{\"n\": 8320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.36, \"learn_time_ms\": 10741.843, \"total_train_time_s\": 15.009404420852661}", "{\"n\": 8321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.11, \"learn_time_ms\": 10714.473, \"total_train_time_s\": 13.591408729553223}", "{\"n\": 8322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.52, \"learn_time_ms\": 10690.771, \"total_train_time_s\": 14.03282117843628}", "{\"n\": 8323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.4, \"learn_time_ms\": 10662.011, \"total_train_time_s\": 14.22522759437561}", "{\"n\": 8324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.38, \"learn_time_ms\": 10575.346, \"total_train_time_s\": 14.432762145996094}", "{\"n\": 8325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.9, \"learn_time_ms\": 10519.734, \"total_train_time_s\": 14.552757501602173}", "{\"n\": 8326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.69, \"learn_time_ms\": 10416.499, \"total_train_time_s\": 14.287609100341797}", "{\"n\": 8327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.4, \"learn_time_ms\": 10613.809, \"total_train_time_s\": 15.041853189468384}", "{\"n\": 8328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.66, \"learn_time_ms\": 10616.603, \"total_train_time_s\": 14.244895219802856}", "{\"n\": 8329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.02, \"learn_time_ms\": 10485.504, \"total_train_time_s\": 13.75536561012268}", "{\"n\": 8330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.18, \"learn_time_ms\": 10514.722, \"total_train_time_s\": 14.885586261749268}", "{\"n\": 8331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.18, \"learn_time_ms\": 10571.446, \"total_train_time_s\": 14.032735824584961}", "{\"n\": 8332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.17, \"learn_time_ms\": 10525.779, \"total_train_time_s\": 13.713959693908691}", "{\"n\": 8333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.0, \"learn_time_ms\": 10397.326, \"total_train_time_s\": 13.284621477127075}", "{\"n\": 8334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.0, \"learn_time_ms\": 10435.984, \"total_train_time_s\": 14.564157009124756}", "{\"n\": 8335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.81, \"learn_time_ms\": 10603.011, \"total_train_time_s\": 16.20657706260681}", "{\"n\": 8336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.85, \"learn_time_ms\": 10649.871, \"total_train_time_s\": 14.68108320236206}", "{\"n\": 8337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.9, \"learn_time_ms\": 10666.224, \"total_train_time_s\": 15.178784370422363}", "{\"n\": 8338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.98, \"learn_time_ms\": 10601.812, \"total_train_time_s\": 13.823630094528198}", "{\"n\": 8339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.62, \"learn_time_ms\": 10743.84, \"total_train_time_s\": 15.014330863952637}", "{\"n\": 8340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.79, \"learn_time_ms\": 10776.446, \"total_train_time_s\": 15.392386198043823}", "{\"n\": 8341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.79, \"learn_time_ms\": 10664.754, \"total_train_time_s\": 12.868497133255005}", "{\"n\": 8342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.5, \"learn_time_ms\": 10784.663, \"total_train_time_s\": 15.160080432891846}", "{\"n\": 8343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.07, \"learn_time_ms\": 10808.248, \"total_train_time_s\": 13.499079465866089}", "{\"n\": 8344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.45, \"learn_time_ms\": 10785.997, \"total_train_time_s\": 14.607443571090698}", "{\"n\": 8345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.45, \"learn_time_ms\": 10593.185, \"total_train_time_s\": 14.134164094924927}", "{\"n\": 8346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.43, \"learn_time_ms\": 10636.958, \"total_train_time_s\": 15.057133197784424}", "{\"n\": 8347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.43, \"learn_time_ms\": 10465.915, \"total_train_time_s\": 13.759737253189087}", "{\"n\": 8348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.02, \"learn_time_ms\": 10539.479, \"total_train_time_s\": 14.521624326705933}", "{\"n\": 8349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.45, \"learn_time_ms\": 10672.828, \"total_train_time_s\": 16.290528774261475}", "{\"n\": 8350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.78, \"learn_time_ms\": 10583.319, \"total_train_time_s\": 14.331427335739136}", "{\"n\": 8351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.78, \"learn_time_ms\": 10765.483, \"total_train_time_s\": 14.774844646453857}", "{\"n\": 8352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.89, \"learn_time_ms\": 10670.947, \"total_train_time_s\": 14.055509090423584}", "{\"n\": 8353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.72, \"learn_time_ms\": 10839.818, \"total_train_time_s\": 15.289870262145996}", "{\"n\": 8354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.42, \"learn_time_ms\": 10898.103, \"total_train_time_s\": 15.18716287612915}", "{\"n\": 8355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.42, \"learn_time_ms\": 10887.61, \"total_train_time_s\": 14.332982540130615}", "{\"n\": 8356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.86, \"learn_time_ms\": 10851.122, \"total_train_time_s\": 14.645203113555908}", "{\"n\": 8357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.09, \"learn_time_ms\": 10935.507, \"total_train_time_s\": 14.446125030517578}", "{\"n\": 8358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.09, \"learn_time_ms\": 10977.143, \"total_train_time_s\": 14.637960195541382}", "{\"n\": 8359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.09, \"learn_time_ms\": 10810.954, \"total_train_time_s\": 14.66213083267212}", "{\"n\": 8360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.31, \"learn_time_ms\": 10701.81, \"total_train_time_s\": 13.431802749633789}", "{\"n\": 8361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.29, \"learn_time_ms\": 10569.007, \"total_train_time_s\": 13.536355972290039}", "{\"n\": 8362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.29, \"learn_time_ms\": 10586.711, \"total_train_time_s\": 14.132130146026611}", "{\"n\": 8363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.59, \"learn_time_ms\": 10448.63, \"total_train_time_s\": 13.720454216003418}", "{\"n\": 8364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.77, \"learn_time_ms\": 10429.253, \"total_train_time_s\": 14.580366373062134}", "{\"n\": 8365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.19, \"learn_time_ms\": 10305.405, \"total_train_time_s\": 12.937079906463623}", "{\"n\": 8366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.54, \"learn_time_ms\": 10363.947, \"total_train_time_s\": 15.07738733291626}", "{\"n\": 8367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.14, \"learn_time_ms\": 10384.829, \"total_train_time_s\": 14.505722999572754}", "{\"n\": 8368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.02, \"learn_time_ms\": 10414.442, \"total_train_time_s\": 14.865621566772461}", "{\"n\": 8369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.02, \"learn_time_ms\": 10436.422, \"total_train_time_s\": 14.981573820114136}", "{\"n\": 8370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.66, \"learn_time_ms\": 10518.12, \"total_train_time_s\": 14.158443927764893}", "{\"n\": 8371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.69, \"learn_time_ms\": 10779.546, \"total_train_time_s\": 16.193670749664307}", "{\"n\": 8372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.1, \"learn_time_ms\": 10771.385, \"total_train_time_s\": 13.943849563598633}", "{\"n\": 8373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 10834.43, \"total_train_time_s\": 14.277631521224976}", "{\"n\": 8374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 10788.767, \"total_train_time_s\": 14.481098175048828}", "{\"n\": 8375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.77, \"learn_time_ms\": 10898.927, \"total_train_time_s\": 13.917547464370728}", "{\"n\": 8376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.94, \"learn_time_ms\": 10898.235, \"total_train_time_s\": 15.171753406524658}", "{\"n\": 8377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.03, \"learn_time_ms\": 10896.143, \"total_train_time_s\": 14.615028381347656}", "{\"n\": 8378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.03, \"learn_time_ms\": 10814.841, \"total_train_time_s\": 14.228139638900757}", "{\"n\": 8379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 10786.779, \"total_train_time_s\": 14.263364553451538}", "{\"n\": 8380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.99, \"learn_time_ms\": 10712.101, \"total_train_time_s\": 13.327819585800171}", "{\"n\": 8381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.55, \"learn_time_ms\": 10537.721, \"total_train_time_s\": 14.196711778640747}", "{\"n\": 8382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.13, \"learn_time_ms\": 10559.063, \"total_train_time_s\": 14.23237681388855}", "{\"n\": 8383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.13, \"learn_time_ms\": 10562.947, \"total_train_time_s\": 14.41758394241333}", "{\"n\": 8384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.36, \"learn_time_ms\": 10523.229, \"total_train_time_s\": 13.711261749267578}", "{\"n\": 8385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.29, \"learn_time_ms\": 10582.916, \"total_train_time_s\": 14.653633832931519}", "{\"n\": 8386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.29, \"learn_time_ms\": 10518.773, \"total_train_time_s\": 14.628828763961792}", "{\"n\": 8387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.22, \"learn_time_ms\": 10510.016, \"total_train_time_s\": 14.538151741027832}", "{\"n\": 8388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.43, \"learn_time_ms\": 10434.22, \"total_train_time_s\": 13.516097784042358}", "{\"n\": 8389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.59, \"learn_time_ms\": 10481.024, \"total_train_time_s\": 14.92201852798462}", "{\"n\": 8390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.14, \"learn_time_ms\": 10595.951, \"total_train_time_s\": 14.410988807678223}", "{\"n\": 8391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.82, \"learn_time_ms\": 10624.646, \"total_train_time_s\": 14.503141641616821}", "{\"n\": 8392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3586.82, \"learn_time_ms\": 10728.136, \"total_train_time_s\": 15.33835768699646}", "{\"n\": 8393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3587.5, \"learn_time_ms\": 10774.013, \"total_train_time_s\": 14.61443567276001}", "{\"n\": 8394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.84, \"learn_time_ms\": 10833.489, \"total_train_time_s\": 14.496883869171143}", "{\"n\": 8395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.31, \"learn_time_ms\": 10788.16, \"total_train_time_s\": 14.208407163619995}", "{\"n\": 8396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.31, \"learn_time_ms\": 10899.349, \"total_train_time_s\": 15.79570198059082}", "{\"n\": 8397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.36, \"learn_time_ms\": 10852.942, \"total_train_time_s\": 13.80139708518982}", "{\"n\": 8398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.74, \"learn_time_ms\": 10980.579, \"total_train_time_s\": 14.92683458328247}", "{\"n\": 8399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.69, \"learn_time_ms\": 10953.091, \"total_train_time_s\": 14.475942373275757}", "{\"n\": 8400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.69, \"learn_time_ms\": 10864.416, \"total_train_time_s\": 13.636425018310547}", "{\"n\": 8401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.31, \"learn_time_ms\": 10892.063, \"total_train_time_s\": 14.910160779953003}", "{\"n\": 8402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.93, \"learn_time_ms\": 10720.136, \"total_train_time_s\": 13.628846168518066}", "{\"n\": 8403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.0, \"learn_time_ms\": 10610.727, \"total_train_time_s\": 13.572076797485352}", "{\"n\": 8404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.0, \"learn_time_ms\": 10585.815, \"total_train_time_s\": 14.076101779937744}", "{\"n\": 8405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.34, \"learn_time_ms\": 10622.513, \"total_train_time_s\": 14.594889879226685}", "{\"n\": 8406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.89, \"learn_time_ms\": 10452.533, \"total_train_time_s\": 14.015815496444702}", "{\"n\": 8407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.89, \"learn_time_ms\": 10521.792, \"total_train_time_s\": 14.471085786819458}", "{\"n\": 8408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.99, \"learn_time_ms\": 10436.985, \"total_train_time_s\": 13.726691007614136}", "{\"n\": 8409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.43, \"learn_time_ms\": 10439.156, \"total_train_time_s\": 14.682812452316284}", "{\"n\": 8410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.66, \"learn_time_ms\": 10507.532, \"total_train_time_s\": 14.36149001121521}", "{\"n\": 8411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.66, \"learn_time_ms\": 10484.773, \"total_train_time_s\": 14.554781198501587}", "{\"n\": 8412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.08, \"learn_time_ms\": 10532.736, \"total_train_time_s\": 14.029882907867432}", "{\"n\": 8413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.54, \"learn_time_ms\": 10597.416, \"total_train_time_s\": 14.178797483444214}", "{\"n\": 8414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.54, \"learn_time_ms\": 10628.533, \"total_train_time_s\": 14.55293893814087}", "{\"n\": 8415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.54, \"learn_time_ms\": 10611.512, \"total_train_time_s\": 14.451832056045532}", "{\"n\": 8416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.94, \"learn_time_ms\": 10667.913, \"total_train_time_s\": 14.627995252609253}", "{\"n\": 8417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.99, \"learn_time_ms\": 10565.778, \"total_train_time_s\": 13.590392589569092}", "{\"n\": 8418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.99, \"learn_time_ms\": 10545.179, \"total_train_time_s\": 13.545812129974365}", "{\"n\": 8419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3599.92, \"learn_time_ms\": 10475.065, \"total_train_time_s\": 13.891236782073975}", "{\"n\": 8420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.96, \"learn_time_ms\": 10437.958, \"total_train_time_s\": 14.111115455627441}", "{\"n\": 8421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.76, \"learn_time_ms\": 10470.963, \"total_train_time_s\": 14.956559419631958}", "{\"n\": 8422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.76, \"learn_time_ms\": 10456.499, \"total_train_time_s\": 13.945900917053223}", "{\"n\": 8423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.01, \"learn_time_ms\": 10485.294, \"total_train_time_s\": 14.452204465866089}", "{\"n\": 8424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.19, \"learn_time_ms\": 10478.116, \"total_train_time_s\": 14.677937030792236}", "{\"n\": 8425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.5, \"learn_time_ms\": 10664.158, \"total_train_time_s\": 16.356027126312256}", "{\"n\": 8426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.5, \"learn_time_ms\": 10706.614, \"total_train_time_s\": 15.135674476623535}", "{\"n\": 8427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.65, \"learn_time_ms\": 10805.929, \"total_train_time_s\": 14.65571117401123}", "{\"n\": 8428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.64, \"learn_time_ms\": 10809.61, \"total_train_time_s\": 13.689546346664429}", "{\"n\": 8429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.81, \"learn_time_ms\": 10808.251, \"total_train_time_s\": 14.141427993774414}", "{\"n\": 8430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.19, \"learn_time_ms\": 10765.491, \"total_train_time_s\": 13.64681601524353}", "{\"n\": 8431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.21, \"learn_time_ms\": 10739.65, \"total_train_time_s\": 14.676829099655151}", "{\"n\": 8432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.8, \"learn_time_ms\": 10934.842, \"total_train_time_s\": 15.761760473251343}", "{\"n\": 8433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.17, \"learn_time_ms\": 10931.812, \"total_train_time_s\": 14.72347092628479}", "{\"n\": 8434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.52, \"learn_time_ms\": 10939.179, \"total_train_time_s\": 14.61476469039917}", "{\"n\": 8435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.6, \"learn_time_ms\": 10779.746, \"total_train_time_s\": 14.688586950302124}", "{\"n\": 8436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.6, \"learn_time_ms\": 10657.502, \"total_train_time_s\": 13.960465669631958}", "{\"n\": 8437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.7, \"learn_time_ms\": 10806.777, \"total_train_time_s\": 16.021209478378296}", "{\"n\": 8438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.7, \"learn_time_ms\": 10718.322, \"total_train_time_s\": 12.828511476516724}", "{\"n\": 8439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.36, \"learn_time_ms\": 10645.966, \"total_train_time_s\": 13.10519003868103}", "{\"n\": 8440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.36, \"learn_time_ms\": 10752.964, \"total_train_time_s\": 14.762104034423828}", "{\"n\": 8441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.52, \"learn_time_ms\": 10697.954, \"total_train_time_s\": 14.184895515441895}", "{\"n\": 8442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.04, \"learn_time_ms\": 10426.351, \"total_train_time_s\": 13.365679264068604}", "{\"n\": 8443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.74, \"learn_time_ms\": 10467.283, \"total_train_time_s\": 14.994170188903809}", "{\"n\": 8444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.74, \"learn_time_ms\": 10471.486, \"total_train_time_s\": 14.771924018859863}", "{\"n\": 8445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.91, \"learn_time_ms\": 10584.556, \"total_train_time_s\": 15.689634561538696}", "{\"n\": 8446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.36, \"learn_time_ms\": 10645.653, \"total_train_time_s\": 14.401010274887085}", "{\"n\": 8447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.64, \"learn_time_ms\": 10379.582, \"total_train_time_s\": 13.33503007888794}", "{\"n\": 8448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.64, \"learn_time_ms\": 10548.365, \"total_train_time_s\": 14.434577226638794}", "{\"n\": 8449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.24, \"learn_time_ms\": 10712.542, \"total_train_time_s\": 14.698820114135742}", "{\"n\": 8450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.24, \"learn_time_ms\": 10684.119, \"total_train_time_s\": 14.213485956192017}", "{\"n\": 8451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.24, \"learn_time_ms\": 10712.234, \"total_train_time_s\": 14.766550779342651}", "{\"n\": 8452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3656.46, \"learn_time_ms\": 10990.691, \"total_train_time_s\": 16.069583892822266}", "{\"n\": 8453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.14, \"learn_time_ms\": 10879.198, \"total_train_time_s\": 13.845490455627441}", "{\"n\": 8454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.14, \"learn_time_ms\": 10834.334, \"total_train_time_s\": 14.173951387405396}", "{\"n\": 8455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.14, \"learn_time_ms\": 10734.463, \"total_train_time_s\": 14.862933158874512}", "{\"n\": 8456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.32, \"learn_time_ms\": 10693.843, \"total_train_time_s\": 14.401183843612671}", "{\"n\": 8457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.86, \"learn_time_ms\": 10762.435, \"total_train_time_s\": 14.039885759353638}", "{\"n\": 8458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.86, \"learn_time_ms\": 10782.031, \"total_train_time_s\": 14.915261030197144}", "{\"n\": 8459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10716.597, \"total_train_time_s\": 14.301955699920654}", "{\"n\": 8460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.26, \"learn_time_ms\": 10647.74, \"total_train_time_s\": 13.534626483917236}", "{\"n\": 8461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.57, \"learn_time_ms\": 10582.611, \"total_train_time_s\": 13.92865800857544}", "{\"n\": 8462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.57, \"learn_time_ms\": 10448.15, \"total_train_time_s\": 14.55851674079895}", "{\"n\": 8463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.03, \"learn_time_ms\": 10467.473, \"total_train_time_s\": 14.118900299072266}", "{\"n\": 8464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.69, \"learn_time_ms\": 10554.557, \"total_train_time_s\": 14.854403495788574}", "{\"n\": 8465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.69, \"learn_time_ms\": 10510.885, \"total_train_time_s\": 14.31279993057251}", "{\"n\": 8466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.69, \"learn_time_ms\": 10660.377, \"total_train_time_s\": 15.747264862060547}", "{\"n\": 8467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.95, \"learn_time_ms\": 10684.715, \"total_train_time_s\": 14.39462423324585}", "{\"n\": 8468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 10665.681, \"total_train_time_s\": 14.487807273864746}", "{\"n\": 8469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 10607.05, \"total_train_time_s\": 13.792752981185913}", "{\"n\": 8470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 10697.041, \"total_train_time_s\": 14.706954956054688}", "{\"n\": 8471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.25, \"learn_time_ms\": 10775.519, \"total_train_time_s\": 14.61953592300415}", "{\"n\": 8472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.25, \"learn_time_ms\": 10816.494, \"total_train_time_s\": 15.026950359344482}", "{\"n\": 8473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.25, \"learn_time_ms\": 10806.753, \"total_train_time_s\": 13.99277663230896}", "{\"n\": 8474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.25, \"learn_time_ms\": 10809.531, \"total_train_time_s\": 15.340426445007324}", "{\"n\": 8475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.72, \"learn_time_ms\": 10831.52, \"total_train_time_s\": 14.386768817901611}", "{\"n\": 8476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.51, \"learn_time_ms\": 10745.847, \"total_train_time_s\": 14.430415868759155}", "{\"n\": 8477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.51, \"learn_time_ms\": 10833.787, \"total_train_time_s\": 15.303012371063232}", "{\"n\": 8478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.35, \"learn_time_ms\": 10848.279, \"total_train_time_s\": 14.49657416343689}", "{\"n\": 8479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.87, \"learn_time_ms\": 10860.28, \"total_train_time_s\": 13.774309635162354}", "{\"n\": 8480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.87, \"learn_time_ms\": 10824.656, \"total_train_time_s\": 14.581903457641602}", "{\"n\": 8481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.67, \"learn_time_ms\": 10783.047, \"total_train_time_s\": 14.071513652801514}", "{\"n\": 8482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 10679.147, \"total_train_time_s\": 14.103874683380127}", "{\"n\": 8483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.84, \"learn_time_ms\": 10724.211, \"total_train_time_s\": 14.322606801986694}", "{\"n\": 8484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.97, \"learn_time_ms\": 10668.642, \"total_train_time_s\": 14.573407649993896}", "{\"n\": 8485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.97, \"learn_time_ms\": 10729.272, \"total_train_time_s\": 15.338728666305542}", "{\"n\": 8486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.61, \"learn_time_ms\": 10615.519, \"total_train_time_s\": 13.660562992095947}", "{\"n\": 8487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.53, \"learn_time_ms\": 10471.6, \"total_train_time_s\": 13.72334599494934}", "{\"n\": 8488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.18, \"learn_time_ms\": 10287.987, \"total_train_time_s\": 12.751124858856201}", "{\"n\": 8489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.14, \"learn_time_ms\": 10418.174, \"total_train_time_s\": 15.307838916778564}", "{\"n\": 8490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.14, \"learn_time_ms\": 10475.863, \"total_train_time_s\": 14.92924165725708}", "{\"n\": 8491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.74, \"learn_time_ms\": 10607.075, \"total_train_time_s\": 15.494915008544922}", "{\"n\": 8492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.27, \"learn_time_ms\": 10714.651, \"total_train_time_s\": 15.159200191497803}", "{\"n\": 8493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.36, \"learn_time_ms\": 10911.335, \"total_train_time_s\": 16.274595022201538}", "{\"n\": 8494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.18, \"learn_time_ms\": 10905.619, \"total_train_time_s\": 14.44834280014038}", "{\"n\": 8495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.53, \"learn_time_ms\": 10861.57, \"total_train_time_s\": 14.712842464447021}", "{\"n\": 8496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3679.32, \"learn_time_ms\": 10993.426, \"total_train_time_s\": 15.022778749465942}", "{\"n\": 8497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3679.32, \"learn_time_ms\": 10980.926, \"total_train_time_s\": 13.844112157821655}", "{\"n\": 8498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.99, \"learn_time_ms\": 11167.381, \"total_train_time_s\": 14.509358406066895}", "{\"n\": 8499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.59, \"learn_time_ms\": 11070.739, \"total_train_time_s\": 14.210586786270142}", "{\"n\": 8500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3672.74, \"learn_time_ms\": 10918.187, \"total_train_time_s\": 13.199272155761719}", "{\"n\": 8501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3672.74, \"learn_time_ms\": 10852.613, \"total_train_time_s\": 14.762468338012695}", "{\"n\": 8502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.03, \"learn_time_ms\": 10779.58, \"total_train_time_s\": 14.365894317626953}", "{\"n\": 8503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3687.5, \"learn_time_ms\": 10650.97, \"total_train_time_s\": 15.200387001037598}", "{\"n\": 8504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.83, \"learn_time_ms\": 10611.452, \"total_train_time_s\": 13.986151456832886}", "{\"n\": 8505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.22, \"learn_time_ms\": 10487.972, \"total_train_time_s\": 13.470505952835083}", "{\"n\": 8506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3690.72, \"learn_time_ms\": 10386.961, \"total_train_time_s\": 13.806861162185669}", "{\"n\": 8507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.04, \"learn_time_ms\": 10403.882, \"total_train_time_s\": 13.852450847625732}", "{\"n\": 8508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3687.63, \"learn_time_ms\": 10338.374, \"total_train_time_s\": 14.126782178878784}", "{\"n\": 8509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.21, \"learn_time_ms\": 10355.604, \"total_train_time_s\": 14.075623512268066}", "{\"n\": 8510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3693.64, \"learn_time_ms\": 10510.584, \"total_train_time_s\": 14.802344799041748}", "{\"n\": 8511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3694.3, \"learn_time_ms\": 10447.148, \"total_train_time_s\": 14.289425611495972}", "{\"n\": 8512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3694.3, \"learn_time_ms\": 10463.231, \"total_train_time_s\": 14.681070804595947}", "{\"n\": 8513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.07, \"learn_time_ms\": 10496.892, \"total_train_time_s\": 15.369237184524536}", "{\"n\": 8514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3684.98, \"learn_time_ms\": 10473.629, \"total_train_time_s\": 13.75761365890503}", "{\"n\": 8515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3691.53, \"learn_time_ms\": 10656.314, \"total_train_time_s\": 15.23799729347229}", "{\"n\": 8516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.21, \"learn_time_ms\": 10800.317, \"total_train_time_s\": 15.073655843734741}", "{\"n\": 8517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.21, \"learn_time_ms\": 10855.551, \"total_train_time_s\": 14.555914640426636}", "{\"n\": 8518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.44, \"learn_time_ms\": 10924.852, \"total_train_time_s\": 14.587947845458984}", "{\"n\": 8519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.77, \"learn_time_ms\": 11003.06, \"total_train_time_s\": 14.999671459197998}", "{\"n\": 8520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.49, \"learn_time_ms\": 10857.017, \"total_train_time_s\": 13.295757293701172}", "{\"n\": 8521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.32, \"learn_time_ms\": 10926.26, \"total_train_time_s\": 14.874617099761963}", "{\"n\": 8522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.94, \"learn_time_ms\": 10883.466, \"total_train_time_s\": 14.337615251541138}", "{\"n\": 8523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.64, \"learn_time_ms\": 10803.706, \"total_train_time_s\": 14.818528890609741}", "{\"n\": 8524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.64, \"learn_time_ms\": 10801.404, \"total_train_time_s\": 13.9082510471344}", "{\"n\": 8525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3695.55, \"learn_time_ms\": 10792.009, \"total_train_time_s\": 15.518594741821289}", "{\"n\": 8526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.56, \"learn_time_ms\": 10659.068, \"total_train_time_s\": 14.042427778244019}", "{\"n\": 8527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3690.43, \"learn_time_ms\": 10744.34, \"total_train_time_s\": 15.37000298500061}", "{\"n\": 8528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3690.43, \"learn_time_ms\": 10669.893, \"total_train_time_s\": 13.945677280426025}", "{\"n\": 8529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.31, \"learn_time_ms\": 10468.956, \"total_train_time_s\": 13.005727291107178}", "{\"n\": 8530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.26, \"learn_time_ms\": 10613.382, \"total_train_time_s\": 14.788502216339111}", "{\"n\": 8531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.07, \"learn_time_ms\": 10478.256, \"total_train_time_s\": 13.641246318817139}", "{\"n\": 8532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.76, \"learn_time_ms\": 10605.024, \"total_train_time_s\": 15.328684329986572}", "{\"n\": 8533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.76, \"learn_time_ms\": 10706.322, \"total_train_time_s\": 15.629162073135376}", "{\"n\": 8534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.49, \"learn_time_ms\": 10715.457, \"total_train_time_s\": 13.729889154434204}", "{\"n\": 8535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.43, \"learn_time_ms\": 10675.538, \"total_train_time_s\": 14.754778146743774}", "{\"n\": 8536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.74, \"learn_time_ms\": 10829.308, \"total_train_time_s\": 15.783160209655762}", "{\"n\": 8537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3674.35, \"learn_time_ms\": 10786.653, \"total_train_time_s\": 14.897950410842896}", "{\"n\": 8538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3679.18, \"learn_time_ms\": 10858.746, \"total_train_time_s\": 14.726808071136475}", "{\"n\": 8539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3686.47, \"learn_time_ms\": 11049.968, \"total_train_time_s\": 14.917251825332642}", "{\"n\": 8540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3686.47, \"learn_time_ms\": 11013.101, \"total_train_time_s\": 14.51857328414917}", "{\"n\": 8541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3678.61, \"learn_time_ms\": 11004.562, \"total_train_time_s\": 13.465075016021729}", "{\"n\": 8542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3678.61, \"learn_time_ms\": 10968.039, \"total_train_time_s\": 14.77458667755127}", "{\"n\": 8543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.61, \"learn_time_ms\": 10829.762, \"total_train_time_s\": 14.141621351242065}", "{\"n\": 8544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.61, \"learn_time_ms\": 10980.889, \"total_train_time_s\": 15.491111993789673}", "{\"n\": 8545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.05, \"learn_time_ms\": 10959.932, \"total_train_time_s\": 14.484078645706177}", "{\"n\": 8546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.65, \"learn_time_ms\": 10807.169, \"total_train_time_s\": 13.876814603805542}", "{\"n\": 8547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.65, \"learn_time_ms\": 10783.264, \"total_train_time_s\": 14.835452556610107}", "{\"n\": 8548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.92, \"learn_time_ms\": 10897.709, \"total_train_time_s\": 15.979391098022461}", "{\"n\": 8549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3690.02, \"learn_time_ms\": 10929.021, \"total_train_time_s\": 15.091426849365234}", "{\"n\": 8550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.16, \"learn_time_ms\": 11033.094, \"total_train_time_s\": 15.391532182693481}", "{\"n\": 8551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.16, \"learn_time_ms\": 11096.537, \"total_train_time_s\": 14.10351276397705}", "{\"n\": 8552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3694.57, \"learn_time_ms\": 10941.588, \"total_train_time_s\": 13.439491748809814}", "{\"n\": 8553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.74, \"learn_time_ms\": 11014.043, \"total_train_time_s\": 14.857509136199951}", "{\"n\": 8554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.74, \"learn_time_ms\": 10858.361, \"total_train_time_s\": 14.026397228240967}", "{\"n\": 8555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.44, \"learn_time_ms\": 10895.547, \"total_train_time_s\": 14.84728479385376}", "{\"n\": 8556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3705.42, \"learn_time_ms\": 10996.796, \"total_train_time_s\": 14.74907898902893}", "{\"n\": 8557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3705.42, \"learn_time_ms\": 10989.219, \"total_train_time_s\": 14.680545568466187}", "{\"n\": 8558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.5, \"learn_time_ms\": 10870.099, \"total_train_time_s\": 14.72614860534668}", "{\"n\": 8559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.5, \"learn_time_ms\": 10808.737, \"total_train_time_s\": 14.757097005844116}", "{\"n\": 8560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.02, \"learn_time_ms\": 10741.73, \"total_train_time_s\": 14.726653814315796}", "{\"n\": 8561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3692.86, \"learn_time_ms\": 10767.839, \"total_train_time_s\": 14.246510028839111}", "{\"n\": 8562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.0, \"learn_time_ms\": 10800.024, \"total_train_time_s\": 13.611063003540039}", "{\"n\": 8563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3688.14, \"learn_time_ms\": 10821.805, \"total_train_time_s\": 15.434305429458618}", "{\"n\": 8564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3697.82, \"learn_time_ms\": 10927.655, \"total_train_time_s\": 14.738680839538574}", "{\"n\": 8565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3691.45, \"learn_time_ms\": 10795.284, \"total_train_time_s\": 13.640692949295044}", "{\"n\": 8566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3691.45, \"learn_time_ms\": 10669.489, \"total_train_time_s\": 13.526577472686768}", "{\"n\": 8567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3686.46, \"learn_time_ms\": 10650.263, \"total_train_time_s\": 14.238003253936768}", "{\"n\": 8568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3685.28, \"learn_time_ms\": 10553.405, \"total_train_time_s\": 13.637629508972168}", "{\"n\": 8569, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3676.3, \"learn_time_ms\": 10550.144, \"total_train_time_s\": 14.813226461410522}", "{\"n\": 8570, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3666.3, \"learn_time_ms\": 10535.552, \"total_train_time_s\": 14.827053546905518}", "{\"n\": 8571, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.94, \"learn_time_ms\": 10451.594, \"total_train_time_s\": 13.455564022064209}", "{\"n\": 8572, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.74, \"learn_time_ms\": 10571.102, \"total_train_time_s\": 14.744245529174805}", "{\"n\": 8573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3663.52, \"learn_time_ms\": 10453.722, \"total_train_time_s\": 14.016008138656616}", "{\"n\": 8574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3663.52, \"learn_time_ms\": 10417.186, \"total_train_time_s\": 14.672150611877441}", "{\"n\": 8575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3658.2, \"learn_time_ms\": 10529.142, \"total_train_time_s\": 14.815617799758911}", "{\"n\": 8576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.85, \"learn_time_ms\": 10624.091, \"total_train_time_s\": 14.776493787765503}", "{\"n\": 8577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3659.13, \"learn_time_ms\": 10599.247, \"total_train_time_s\": 14.104371070861816}", "{\"n\": 8578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3660.52, \"learn_time_ms\": 10718.634, \"total_train_time_s\": 14.904111385345459}", "{\"n\": 8579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 10769.284, \"total_train_time_s\": 15.065398693084717}", "{\"n\": 8580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.61, \"learn_time_ms\": 10666.629, \"total_train_time_s\": 13.459740400314331}", "{\"n\": 8581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3633.38, \"learn_time_ms\": 10765.225, \"total_train_time_s\": 14.5653235912323}", "{\"n\": 8582, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.31, \"learn_time_ms\": 10633.094, \"total_train_time_s\": 13.674841403961182}", "{\"n\": 8583, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.14, \"learn_time_ms\": 10617.917, \"total_train_time_s\": 13.771799325942993}", "{\"n\": 8584, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.64, \"learn_time_ms\": 10663.149, \"total_train_time_s\": 14.878772974014282}", "{\"n\": 8585, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.28, \"learn_time_ms\": 10590.824, \"total_train_time_s\": 14.220329523086548}", "{\"n\": 8586, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.77, \"learn_time_ms\": 10562.371, \"total_train_time_s\": 14.221426725387573}", "{\"n\": 8587, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.57, \"learn_time_ms\": 10538.007, \"total_train_time_s\": 13.922250270843506}", "{\"n\": 8588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.57, \"learn_time_ms\": 10456.596, \"total_train_time_s\": 13.903716802597046}", "{\"n\": 8589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.65, \"learn_time_ms\": 10397.205, \"total_train_time_s\": 14.544704914093018}", "{\"n\": 8590, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.46, \"learn_time_ms\": 10562.368, \"total_train_time_s\": 15.151078939437866}", "{\"n\": 8591, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3622.29, \"learn_time_ms\": 10716.329, \"total_train_time_s\": 16.1951961517334}", "{\"n\": 8592, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.91, \"learn_time_ms\": 10866.188, \"total_train_time_s\": 14.968987226486206}", "{\"n\": 8593, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3624.91, \"learn_time_ms\": 10945.817, \"total_train_time_s\": 14.89452838897705}", "{\"n\": 8594, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.84, \"learn_time_ms\": 10963.767, \"total_train_time_s\": 15.269070863723755}", "{\"n\": 8595, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.7, \"learn_time_ms\": 10946.027, \"total_train_time_s\": 13.934501647949219}", "{\"n\": 8596, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.24, \"learn_time_ms\": 10927.344, \"total_train_time_s\": 14.32838225364685}", "{\"n\": 8597, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.24, \"learn_time_ms\": 11012.056, \"total_train_time_s\": 14.579381227493286}", "{\"n\": 8598, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.96, \"learn_time_ms\": 11030.935, \"total_train_time_s\": 14.100085020065308}", "{\"n\": 8599, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.59, \"learn_time_ms\": 10973.623, \"total_train_time_s\": 13.948460102081299}", "{\"n\": 8600, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10786.766, \"total_train_time_s\": 13.502243280410767}", "{\"n\": 8601, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.87, \"learn_time_ms\": 10701.299, \"total_train_time_s\": 15.297605037689209}", "{\"n\": 8602, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.74, \"learn_time_ms\": 10508.891, \"total_train_time_s\": 13.064639329910278}", "{\"n\": 8603, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.74, \"learn_time_ms\": 10565.456, \"total_train_time_s\": 15.34102177619934}", "{\"n\": 8604, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3617.91, \"learn_time_ms\": 10579.43, \"total_train_time_s\": 15.289880275726318}", "{\"n\": 8605, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3607.3, \"learn_time_ms\": 10551.578, \"total_train_time_s\": 13.62416124343872}", "{\"n\": 8606, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.8, \"learn_time_ms\": 10524.283, \"total_train_time_s\": 13.719935894012451}", "{\"n\": 8607, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.46, \"learn_time_ms\": 10519.515, \"total_train_time_s\": 14.502434492111206}", "{\"n\": 8608, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.31, \"learn_time_ms\": 10518.395, \"total_train_time_s\": 14.288656949996948}", "{\"n\": 8609, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.31, \"learn_time_ms\": 10731.194, \"total_train_time_s\": 16.19562554359436}", "{\"n\": 8610, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.42, \"learn_time_ms\": 10832.574, \"total_train_time_s\": 14.355552673339844}", "{\"n\": 8611, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3590.46, \"learn_time_ms\": 10654.296, \"total_train_time_s\": 13.689875364303589}", "{\"n\": 8612, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.21, \"learn_time_ms\": 10811.808, \"total_train_time_s\": 14.890039682388306}", "{\"n\": 8613, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.87, \"learn_time_ms\": 10838.466, \"total_train_time_s\": 15.413583517074585}", "{\"n\": 8614, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.91, \"learn_time_ms\": 10765.635, \"total_train_time_s\": 14.468978643417358}", "{\"n\": 8615, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.37, \"learn_time_ms\": 11034.298, \"total_train_time_s\": 16.26710033416748}", "{\"n\": 8616, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.78, \"learn_time_ms\": 11124.697, \"total_train_time_s\": 14.946886539459229}", "{\"n\": 8617, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3586.02, \"learn_time_ms\": 11174.142, \"total_train_time_s\": 15.021889686584473}", "{\"n\": 8618, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3588.69, \"learn_time_ms\": 11215.421, \"total_train_time_s\": 14.556874752044678}", "{\"n\": 8619, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.6, \"learn_time_ms\": 11182.166, \"total_train_time_s\": 15.756219148635864}", "{\"n\": 8620, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.6, \"learn_time_ms\": 11260.391, \"total_train_time_s\": 15.371328353881836}", "{\"n\": 8621, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.48, \"learn_time_ms\": 11281.305, \"total_train_time_s\": 13.82005500793457}", "{\"n\": 8622, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.1, \"learn_time_ms\": 11346.232, \"total_train_time_s\": 15.532800674438477}", "{\"n\": 8623, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.2, \"learn_time_ms\": 11317.65, \"total_train_time_s\": 15.393192529678345}", "{\"n\": 8624, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.41, \"learn_time_ms\": 11330.678, \"total_train_time_s\": 14.645771741867065}", "{\"n\": 8625, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 11247.838, \"total_train_time_s\": 15.740957736968994}", "{\"n\": 8626, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 11213.329, \"total_train_time_s\": 14.24945878982544}", "{\"n\": 8627, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.89, \"learn_time_ms\": 11053.405, \"total_train_time_s\": 13.430433988571167}", "{\"n\": 8628, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.89, \"learn_time_ms\": 10946.889, \"total_train_time_s\": 13.613213777542114}", "{\"n\": 8629, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10855.309, \"total_train_time_s\": 15.020406007766724}", "{\"n\": 8630, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10732.57, \"total_train_time_s\": 14.19278597831726}", "{\"n\": 8631, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.76, \"learn_time_ms\": 10779.828, \"total_train_time_s\": 14.077632427215576}", "{\"n\": 8632, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.99, \"learn_time_ms\": 10639.981, \"total_train_time_s\": 14.011208772659302}", "{\"n\": 8633, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.57, \"learn_time_ms\": 10608.88, \"total_train_time_s\": 15.152453660964966}", "{\"n\": 8634, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.83, \"learn_time_ms\": 10615.925, \"total_train_time_s\": 14.677205801010132}", "{\"n\": 8635, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10566.875, \"total_train_time_s\": 14.993640184402466}", "{\"n\": 8636, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10504.208, \"total_train_time_s\": 13.661872863769531}", "{\"n\": 8637, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.18, \"learn_time_ms\": 10590.282, \"total_train_time_s\": 14.582960844039917}", "{\"n\": 8638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.13, \"learn_time_ms\": 10788.897, \"total_train_time_s\": 15.753104209899902}", "{\"n\": 8639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.32, \"learn_time_ms\": 10876.491, \"total_train_time_s\": 15.86156964302063}", "{\"n\": 8640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.32, \"learn_time_ms\": 10890.884, \"total_train_time_s\": 14.089321613311768}", "{\"n\": 8641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.19, \"learn_time_ms\": 10926.625, \"total_train_time_s\": 14.327537298202515}", "{\"n\": 8642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.6, \"learn_time_ms\": 11078.963, \"total_train_time_s\": 15.441446304321289}", "{\"n\": 8643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.6, \"learn_time_ms\": 10988.109, \"total_train_time_s\": 14.255642175674438}", "{\"n\": 8644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.55, \"learn_time_ms\": 11109.895, \"total_train_time_s\": 16.00350332260132}", "{\"n\": 8645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.18, \"learn_time_ms\": 11152.798, \"total_train_time_s\": 15.460200786590576}", "{\"n\": 8646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.54, \"learn_time_ms\": 11276.072, \"total_train_time_s\": 14.87401270866394}", "{\"n\": 8647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.25, \"learn_time_ms\": 11309.244, \"total_train_time_s\": 14.861854076385498}", "{\"n\": 8648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.97, \"learn_time_ms\": 11188.264, \"total_train_time_s\": 14.245957374572754}", "{\"n\": 8649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 11108.397, \"total_train_time_s\": 14.707708597183228}", "{\"n\": 8650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 11192.888, \"total_train_time_s\": 15.016616821289062}", "{\"n\": 8651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.85, \"learn_time_ms\": 11259.334, \"total_train_time_s\": 15.031646251678467}", "{\"n\": 8652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.23, \"learn_time_ms\": 11061.477, \"total_train_time_s\": 13.747528314590454}", "{\"n\": 8653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.78, \"learn_time_ms\": 11130.216, \"total_train_time_s\": 14.742884397506714}", "{\"n\": 8654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.78, \"learn_time_ms\": 11040.63, \"total_train_time_s\": 14.909432172775269}", "{\"n\": 8655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.25, \"learn_time_ms\": 10865.406, \"total_train_time_s\": 13.549139499664307}", "{\"n\": 8656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.48, \"learn_time_ms\": 10808.756, \"total_train_time_s\": 14.590161085128784}", "{\"n\": 8657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3578.89, \"learn_time_ms\": 10779.989, \"total_train_time_s\": 14.332753419876099}", "{\"n\": 8658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.92, \"learn_time_ms\": 10921.239, \"total_train_time_s\": 15.861049890518188}", "{\"n\": 8659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 10859.803, \"total_train_time_s\": 14.404430150985718}", "{\"n\": 8660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 10871.571, \"total_train_time_s\": 15.026161670684814}", "{\"n\": 8661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.09, \"learn_time_ms\": 10778.475, \"total_train_time_s\": 14.308154106140137}", "{\"n\": 8662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3580.24, \"learn_time_ms\": 10897.487, \"total_train_time_s\": 14.976229667663574}", "{\"n\": 8663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.81, \"learn_time_ms\": 10900.244, \"total_train_time_s\": 14.927078008651733}", "{\"n\": 8664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.81, \"learn_time_ms\": 10732.085, \"total_train_time_s\": 13.57472848892212}", "{\"n\": 8665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.04, \"learn_time_ms\": 10800.707, \"total_train_time_s\": 14.560251951217651}", "{\"n\": 8666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.9, \"learn_time_ms\": 10806.353, \"total_train_time_s\": 14.406560182571411}", "{\"n\": 8667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.9, \"learn_time_ms\": 10782.717, \"total_train_time_s\": 14.286262273788452}", "{\"n\": 8668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.9, \"learn_time_ms\": 10620.019, \"total_train_time_s\": 14.092062711715698}", "{\"n\": 8669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.88, \"learn_time_ms\": 10588.689, \"total_train_time_s\": 14.09276556968689}", "{\"n\": 8670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.22, \"learn_time_ms\": 10544.845, \"total_train_time_s\": 14.737703800201416}", "{\"n\": 8671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.22, \"learn_time_ms\": 10560.313, \"total_train_time_s\": 14.446825742721558}", "{\"n\": 8672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10621.887, \"total_train_time_s\": 15.245376825332642}", "{\"n\": 8673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.39, \"learn_time_ms\": 10623.339, \"total_train_time_s\": 14.670554399490356}", "{\"n\": 8674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.39, \"learn_time_ms\": 10707.92, \"total_train_time_s\": 14.203478336334229}", "{\"n\": 8675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.22, \"learn_time_ms\": 10746.6, \"total_train_time_s\": 14.880411863327026}", "{\"n\": 8676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.99, \"learn_time_ms\": 10707.986, \"total_train_time_s\": 14.468894958496094}", "{\"n\": 8677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.22, \"learn_time_ms\": 10668.69, \"total_train_time_s\": 13.912420749664307}", "{\"n\": 8678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.22, \"learn_time_ms\": 10663.028, \"total_train_time_s\": 14.223469495773315}", "{\"n\": 8679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.02, \"learn_time_ms\": 10657.63, \"total_train_time_s\": 14.154510736465454}", "{\"n\": 8680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.61, \"learn_time_ms\": 10480.252, \"total_train_time_s\": 13.150893211364746}", "{\"n\": 8681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.61, \"learn_time_ms\": 10475.819, \"total_train_time_s\": 14.382539749145508}", "{\"n\": 8682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.61, \"learn_time_ms\": 10332.9, \"total_train_time_s\": 13.993254899978638}", "{\"n\": 8683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.82, \"learn_time_ms\": 10503.855, \"total_train_time_s\": 16.311883211135864}", "{\"n\": 8684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.2, \"learn_time_ms\": 10567.811, \"total_train_time_s\": 15.041667222976685}", "{\"n\": 8685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.45, \"learn_time_ms\": 10539.605, \"total_train_time_s\": 14.746892213821411}", "{\"n\": 8686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.45, \"learn_time_ms\": 10464.526, \"total_train_time_s\": 13.419927835464478}", "{\"n\": 8687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 10595.893, \"total_train_time_s\": 15.048179626464844}", "{\"n\": 8688, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.26, \"learn_time_ms\": 10631.736, \"total_train_time_s\": 14.290285587310791}", "{\"n\": 8689, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3549.26, \"learn_time_ms\": 10674.262, \"total_train_time_s\": 14.141702890396118}", "{\"n\": 8690, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.1, \"learn_time_ms\": 10810.955, \"total_train_time_s\": 14.090661525726318}", "{\"n\": 8691, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.19, \"learn_time_ms\": 10868.191, \"total_train_time_s\": 15.028816938400269}", "{\"n\": 8692, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.19, \"learn_time_ms\": 10942.288, \"total_train_time_s\": 14.730027198791504}", "{\"n\": 8693, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.45, \"learn_time_ms\": 10678.38, \"total_train_time_s\": 13.696805953979492}", "{\"n\": 8694, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.09, \"learn_time_ms\": 10507.172, \"total_train_time_s\": 13.173588514328003}", "{\"n\": 8695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.99, \"learn_time_ms\": 10443.775, \"total_train_time_s\": 14.111758708953857}", "{\"n\": 8696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.99, \"learn_time_ms\": 10494.679, \"total_train_time_s\": 14.117550134658813}", "{\"n\": 8697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.13, \"learn_time_ms\": 10440.181, \"total_train_time_s\": 14.689662456512451}", "{\"n\": 8698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.01, \"learn_time_ms\": 10437.667, \"total_train_time_s\": 14.414719820022583}", "{\"n\": 8699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.36, \"learn_time_ms\": 10501.754, \"total_train_time_s\": 14.9544198513031}", "{\"n\": 8700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.36, \"learn_time_ms\": 10490.372, \"total_train_time_s\": 14.220501184463501}", "{\"n\": 8701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3523.79, \"learn_time_ms\": 10532.8, \"total_train_time_s\": 15.472471237182617}", "{\"n\": 8702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3530.29, \"learn_time_ms\": 10618.032, \"total_train_time_s\": 15.389800310134888}", "{\"n\": 8703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3530.29, \"learn_time_ms\": 10778.148, \"total_train_time_s\": 15.472099304199219}", "{\"n\": 8704, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.66, \"learn_time_ms\": 10814.099, \"total_train_time_s\": 13.61343240737915}", "{\"n\": 8705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.01, \"learn_time_ms\": 10873.591, \"total_train_time_s\": 14.602723121643066}", "{\"n\": 8706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.52, \"learn_time_ms\": 10969.28, \"total_train_time_s\": 14.675098419189453}", "{\"n\": 8707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.33, \"learn_time_ms\": 10969.171, \"total_train_time_s\": 14.675287246704102}", "{\"n\": 8708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.02, \"learn_time_ms\": 10890.01, \"total_train_time_s\": 13.585038185119629}", "{\"n\": 8709, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.02, \"learn_time_ms\": 10795.681, \"total_train_time_s\": 14.00498080253601}", "{\"n\": 8710, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3528.27, \"learn_time_ms\": 10762.388, \"total_train_time_s\": 13.806409120559692}", "{\"n\": 8711, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.23, \"learn_time_ms\": 10547.74, \"total_train_time_s\": 13.108073711395264}", "{\"n\": 8712, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.86, \"learn_time_ms\": 10344.58, \"total_train_time_s\": 13.370879173278809}", "{\"n\": 8713, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.86, \"learn_time_ms\": 10281.181, \"total_train_time_s\": 14.691546201705933}", "{\"n\": 8714, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3511.19, \"learn_time_ms\": 10301.853, \"total_train_time_s\": 13.788449048995972}", "{\"n\": 8715, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3517.1, \"learn_time_ms\": 10373.055, \"total_train_time_s\": 15.12747859954834}", "{\"n\": 8716, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3508.22, \"learn_time_ms\": 10514.528, \"total_train_time_s\": 16.175546646118164}", "{\"n\": 8717, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3512.17, \"learn_time_ms\": 10567.352, \"total_train_time_s\": 14.956147909164429}", "{\"n\": 8718, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.46, \"learn_time_ms\": 10586.293, \"total_train_time_s\": 13.941033840179443}", "{\"n\": 8719, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.89, \"learn_time_ms\": 10498.082, \"total_train_time_s\": 13.097452640533447}", "{\"n\": 8720, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.89, \"learn_time_ms\": 10608.754, \"total_train_time_s\": 14.804848670959473}", "{\"n\": 8721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.51, \"learn_time_ms\": 10752.928, \"total_train_time_s\": 14.844436168670654}", "{\"n\": 8722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.51, \"learn_time_ms\": 10801.958, \"total_train_time_s\": 13.941258430480957}", "{\"n\": 8723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3529.86, \"learn_time_ms\": 10743.504, \"total_train_time_s\": 14.394684791564941}", "{\"n\": 8724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.77, \"learn_time_ms\": 10846.354, \"total_train_time_s\": 14.682146549224854}", "{\"n\": 8725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.84, \"learn_time_ms\": 10725.279, \"total_train_time_s\": 13.833361148834229}", "{\"n\": 8726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.26, \"learn_time_ms\": 10556.67, \"total_train_time_s\": 14.607417345046997}", "{\"n\": 8727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.77, \"learn_time_ms\": 10446.811, \"total_train_time_s\": 13.99132776260376}", "{\"n\": 8728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.55, \"learn_time_ms\": 10466.456, \"total_train_time_s\": 13.91679859161377}", "{\"n\": 8729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3520.32, \"learn_time_ms\": 10559.513, \"total_train_time_s\": 13.973937034606934}", "{\"n\": 8730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.04, \"learn_time_ms\": 10490.095, \"total_train_time_s\": 14.38294506072998}", "{\"n\": 8731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.09, \"learn_time_ms\": 10409.445, \"total_train_time_s\": 13.803701639175415}", "{\"n\": 8732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3509.77, \"learn_time_ms\": 10411.324, \"total_train_time_s\": 13.997198820114136}", "{\"n\": 8733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3511.28, \"learn_time_ms\": 10445.141, \"total_train_time_s\": 14.780367136001587}", "{\"n\": 8734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3511.28, \"learn_time_ms\": 10421.213, \"total_train_time_s\": 14.590030193328857}", "{\"n\": 8735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3508.18, \"learn_time_ms\": 10584.912, \"total_train_time_s\": 15.67941951751709}", "{\"n\": 8736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3507.22, \"learn_time_ms\": 10634.0, \"total_train_time_s\": 15.308634519577026}", "{\"n\": 8737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3504.33, \"learn_time_ms\": 10747.108, \"total_train_time_s\": 15.084363222122192}", "{\"n\": 8738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3505.06, \"learn_time_ms\": 10921.98, \"total_train_time_s\": 16.034409999847412}", "{\"n\": 8739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3507.91, \"learn_time_ms\": 10968.744, \"total_train_time_s\": 14.708996295928955}", "{\"n\": 8740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.68, \"learn_time_ms\": 11127.784, \"total_train_time_s\": 15.687808275222778}", "{\"n\": 8741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3517.87, \"learn_time_ms\": 11075.516, \"total_train_time_s\": 13.445271015167236}", "{\"n\": 8742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3508.08, \"learn_time_ms\": 11161.895, \"total_train_time_s\": 14.86431074142456}", "{\"n\": 8743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.9, \"learn_time_ms\": 11114.605, \"total_train_time_s\": 14.054426431655884}", "{\"n\": 8744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.9, \"learn_time_ms\": 10993.168, \"total_train_time_s\": 13.216443061828613}", "{\"n\": 8745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.54, \"learn_time_ms\": 10960.961, \"total_train_time_s\": 15.093925714492798}", "{\"n\": 8746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.62, \"learn_time_ms\": 10998.111, \"total_train_time_s\": 15.316125869750977}", "{\"n\": 8747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.16, \"learn_time_ms\": 11021.267, \"total_train_time_s\": 15.344936609268188}", "{\"n\": 8748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3511.51, \"learn_time_ms\": 10948.776, \"total_train_time_s\": 15.11932635307312}", "{\"n\": 8749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.69, \"learn_time_ms\": 10965.558, \"total_train_time_s\": 14.682467460632324}", "{\"n\": 8750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.45, \"learn_time_ms\": 10906.793, \"total_train_time_s\": 15.05927300453186}", "{\"n\": 8751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.45, \"learn_time_ms\": 10896.492, \"total_train_time_s\": 13.576953887939453}", "{\"n\": 8752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3535.37, \"learn_time_ms\": 10821.633, \"total_train_time_s\": 14.226625204086304}", "{\"n\": 8753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.39, \"learn_time_ms\": 10843.824, \"total_train_time_s\": 14.358217239379883}", "{\"n\": 8754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 11040.894, \"total_train_time_s\": 15.383192777633667}", "{\"n\": 8755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.79, \"learn_time_ms\": 10900.146, \"total_train_time_s\": 13.9636971950531}", "{\"n\": 8756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.51, \"learn_time_ms\": 10801.205, \"total_train_time_s\": 14.383351802825928}", "{\"n\": 8757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.09, \"learn_time_ms\": 10660.162, \"total_train_time_s\": 13.925187826156616}", "{\"n\": 8758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.91, \"learn_time_ms\": 10595.856, \"total_train_time_s\": 14.647303104400635}", "{\"n\": 8759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.13, \"learn_time_ms\": 10571.877, \"total_train_time_s\": 14.410054922103882}", "{\"n\": 8760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.13, \"learn_time_ms\": 10608.232, \"total_train_time_s\": 15.841557264328003}", "{\"n\": 8761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3539.65, \"learn_time_ms\": 10831.66, \"total_train_time_s\": 15.2405526638031}", "{\"n\": 8762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3530.17, \"learn_time_ms\": 10821.062, \"total_train_time_s\": 13.837677240371704}", "{\"n\": 8763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3530.17, \"learn_time_ms\": 10885.382, \"total_train_time_s\": 15.042667388916016}", "{\"n\": 8764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3530.17, \"learn_time_ms\": 10820.844, \"total_train_time_s\": 14.736390352249146}", "{\"n\": 8765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3541.43, \"learn_time_ms\": 10867.345, \"total_train_time_s\": 14.170795679092407}", "{\"n\": 8766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3541.43, \"learn_time_ms\": 10879.491, \"total_train_time_s\": 14.59719443321228}", "{\"n\": 8767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3541.43, \"learn_time_ms\": 10827.733, \"total_train_time_s\": 13.438267707824707}", "{\"n\": 8768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3531.44, \"learn_time_ms\": 10766.227, \"total_train_time_s\": 13.925511121749878}", "{\"n\": 8769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3536.69, \"learn_time_ms\": 10898.494, \"total_train_time_s\": 15.681446313858032}", "{\"n\": 8770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.28, \"learn_time_ms\": 10788.5, \"total_train_time_s\": 14.59105658531189}", "{\"n\": 8771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.28, \"learn_time_ms\": 10847.89, \"total_train_time_s\": 15.867143392562866}", "{\"n\": 8772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3507.81, \"learn_time_ms\": 10996.313, \"total_train_time_s\": 15.337624311447144}", "{\"n\": 8773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3507.81, \"learn_time_ms\": 10906.858, \"total_train_time_s\": 14.31725263595581}", "{\"n\": 8774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3505.27, \"learn_time_ms\": 10888.657, \"total_train_time_s\": 14.534224033355713}", "{\"n\": 8775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3508.94, \"learn_time_ms\": 10968.945, \"total_train_time_s\": 15.237839698791504}", "{\"n\": 8776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3522.47, \"learn_time_ms\": 10978.959, \"total_train_time_s\": 14.529516220092773}", "{\"n\": 8777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3522.66, \"learn_time_ms\": 11207.432, \"total_train_time_s\": 15.874256134033203}", "{\"n\": 8778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3520.89, \"learn_time_ms\": 11291.445, \"total_train_time_s\": 14.60671591758728}", "{\"n\": 8779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3531.92, \"learn_time_ms\": 11113.632, \"total_train_time_s\": 14.111104249954224}", "{\"n\": 8780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.0, \"learn_time_ms\": 11109.321, \"total_train_time_s\": 14.474072456359863}", "{\"n\": 8781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3516.28, \"learn_time_ms\": 10932.425, \"total_train_time_s\": 14.191269636154175}", "{\"n\": 8782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.29, \"learn_time_ms\": 10777.006, \"total_train_time_s\": 14.012387037277222}", "{\"n\": 8783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3519.2, \"learn_time_ms\": 10707.91, \"total_train_time_s\": 13.517602920532227}", "{\"n\": 8784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.49, \"learn_time_ms\": 10734.012, \"total_train_time_s\": 14.895267486572266}", "{\"n\": 8785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3526.34, \"learn_time_ms\": 10515.326, \"total_train_time_s\": 12.9934241771698}", "{\"n\": 8786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3526.34, \"learn_time_ms\": 10497.498, \"total_train_time_s\": 14.764002323150635}", "{\"n\": 8787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3526.58, \"learn_time_ms\": 10237.762, \"total_train_time_s\": 12.995659112930298}", "{\"n\": 8788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3517.75, \"learn_time_ms\": 10166.653, \"total_train_time_s\": 13.761917352676392}", "{\"n\": 8789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3508.5, \"learn_time_ms\": 10097.083, \"total_train_time_s\": 13.150283336639404}", "{\"n\": 8790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3508.5, \"learn_time_ms\": 10200.936, \"total_train_time_s\": 15.432427883148193}", "{\"n\": 8791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3514.68, \"learn_time_ms\": 10184.119, \"total_train_time_s\": 14.064183950424194}", "{\"n\": 8792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3520.37, \"learn_time_ms\": 10241.503, \"total_train_time_s\": 14.363665103912354}", "{\"n\": 8793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.41, \"learn_time_ms\": 10419.217, \"total_train_time_s\": 15.017061233520508}", "{\"n\": 8794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.41, \"learn_time_ms\": 10493.482, \"total_train_time_s\": 15.772023439407349}", "{\"n\": 8795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3514.72, \"learn_time_ms\": 10636.403, \"total_train_time_s\": 14.250740766525269}", "{\"n\": 8796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.28, \"learn_time_ms\": 10569.705, \"total_train_time_s\": 13.992417097091675}", "{\"n\": 8797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3508.18, \"learn_time_ms\": 10653.647, \"total_train_time_s\": 14.118697166442871}", "{\"n\": 8798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3507.53, \"learn_time_ms\": 10762.715, \"total_train_time_s\": 15.117526054382324}", "{\"n\": 8799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.38, \"learn_time_ms\": 10867.137, \"total_train_time_s\": 14.27139949798584}", "{\"n\": 8800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.38, \"learn_time_ms\": 10663.541, \"total_train_time_s\": 13.344793558120728}", "{\"n\": 8801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.19, \"learn_time_ms\": 10771.918, \"total_train_time_s\": 15.166649103164673}", "{\"n\": 8802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.56, \"learn_time_ms\": 10788.138, \"total_train_time_s\": 15.034940958023071}", "{\"n\": 8803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3502.06, \"learn_time_ms\": 10727.192, \"total_train_time_s\": 14.679312229156494}", "{\"n\": 8804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.34, \"learn_time_ms\": 10567.242, \"total_train_time_s\": 13.975422859191895}", "{\"n\": 8805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.44, \"learn_time_ms\": 10602.281, \"total_train_time_s\": 14.83880615234375}", "{\"n\": 8806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.69, \"learn_time_ms\": 10761.394, \"total_train_time_s\": 15.697284698486328}", "{\"n\": 8807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.66, \"learn_time_ms\": 10882.857, \"total_train_time_s\": 15.268921613693237}", "{\"n\": 8808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.26, \"learn_time_ms\": 10859.49, \"total_train_time_s\": 14.72406554222107}", "{\"n\": 8809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.26, \"learn_time_ms\": 11015.154, \"total_train_time_s\": 16.257571697235107}", "{\"n\": 8810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3492.79, \"learn_time_ms\": 11248.649, \"total_train_time_s\": 15.666146039962769}", "{\"n\": 8811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.33, \"learn_time_ms\": 11085.985, \"total_train_time_s\": 13.618501663208008}", "{\"n\": 8812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.33, \"learn_time_ms\": 11123.133, \"total_train_time_s\": 14.917723894119263}", "{\"n\": 8813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3495.43, \"learn_time_ms\": 11138.097, \"total_train_time_s\": 14.889759063720703}", "{\"n\": 8814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.46, \"learn_time_ms\": 11244.664, \"total_train_time_s\": 15.05717921257019}", "{\"n\": 8815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.46, \"learn_time_ms\": 11251.227, \"total_train_time_s\": 14.974482536315918}", "{\"n\": 8816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.32, \"learn_time_ms\": 11215.828, \"total_train_time_s\": 14.965585708618164}", "{\"n\": 8817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.25, \"learn_time_ms\": 11280.24, \"total_train_time_s\": 15.801045656204224}", "{\"n\": 8818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.91, \"learn_time_ms\": 11160.768, \"total_train_time_s\": 13.50217890739441}", "{\"n\": 8819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.91, \"learn_time_ms\": 11094.271, \"total_train_time_s\": 15.514237880706787}", "{\"n\": 8820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3495.69, \"learn_time_ms\": 10959.023, \"total_train_time_s\": 14.40583324432373}", "{\"n\": 8821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3497.08, \"learn_time_ms\": 11080.892, \"total_train_time_s\": 14.838874816894531}", "{\"n\": 8822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.84, \"learn_time_ms\": 11029.182, \"total_train_time_s\": 14.475754022598267}", "{\"n\": 8823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3488.7, \"learn_time_ms\": 11006.989, \"total_train_time_s\": 14.342163801193237}", "{\"n\": 8824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3491.27, \"learn_time_ms\": 10932.064, \"total_train_time_s\": 14.160154581069946}", "{\"n\": 8825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3487.46, \"learn_time_ms\": 10994.551, \"total_train_time_s\": 15.32512378692627}", "{\"n\": 8826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3487.46, \"learn_time_ms\": 10966.926, \"total_train_time_s\": 14.940167427062988}", "{\"n\": 8827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.65, \"learn_time_ms\": 10728.219, \"total_train_time_s\": 13.392760276794434}", "{\"n\": 8828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.47, \"learn_time_ms\": 10856.586, \"total_train_time_s\": 14.810606718063354}", "{\"n\": 8829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3497.84, \"learn_time_ms\": 10692.025, \"total_train_time_s\": 13.606040716171265}", "{\"n\": 8830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3495.15, \"learn_time_ms\": 10630.58, \"total_train_time_s\": 13.80431056022644}", "{\"n\": 8831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3483.63, \"learn_time_ms\": 10708.876, \"total_train_time_s\": 15.490556478500366}", "{\"n\": 8832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3483.63, \"learn_time_ms\": 10784.082, \"total_train_time_s\": 15.140166521072388}", "{\"n\": 8833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3483.73, \"learn_time_ms\": 10812.405, \"total_train_time_s\": 14.645294666290283}", "{\"n\": 8834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.37, \"learn_time_ms\": 10966.992, \"total_train_time_s\": 15.74824857711792}", "{\"n\": 8835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3490.72, \"learn_time_ms\": 10948.136, \"total_train_time_s\": 15.07400107383728}", "{\"n\": 8836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.97, \"learn_time_ms\": 10964.001, \"total_train_time_s\": 14.795798540115356}", "{\"n\": 8837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.97, \"learn_time_ms\": 10956.375, \"total_train_time_s\": 13.489177703857422}", "{\"n\": 8838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.5, \"learn_time_ms\": 10807.509, \"total_train_time_s\": 13.231133699417114}", "{\"n\": 8839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3476.43, \"learn_time_ms\": 10891.535, \"total_train_time_s\": 14.338717937469482}", "{\"n\": 8840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3476.43, \"learn_time_ms\": 11056.057, \"total_train_time_s\": 15.781996488571167}", "{\"n\": 8841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3479.33, \"learn_time_ms\": 11081.88, \"total_train_time_s\": 15.690227031707764}", "{\"n\": 8842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3480.58, \"learn_time_ms\": 10955.13, \"total_train_time_s\": 14.318132638931274}", "{\"n\": 8843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3480.58, \"learn_time_ms\": 10930.298, \"total_train_time_s\": 14.373757362365723}", "{\"n\": 8844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3465.61, \"learn_time_ms\": 10892.11, \"total_train_time_s\": 15.475677728652954}", "{\"n\": 8845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3457.36, \"learn_time_ms\": 10814.778, \"total_train_time_s\": 14.421077251434326}", "{\"n\": 8846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3455.94, \"learn_time_ms\": 10780.73, \"total_train_time_s\": 14.579464673995972}", "{\"n\": 8847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3454.43, \"learn_time_ms\": 10884.881, \"total_train_time_s\": 14.684197664260864}", "{\"n\": 8848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3452.61, \"learn_time_ms\": 11128.934, \"total_train_time_s\": 15.840950727462769}", "{\"n\": 8849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3450.28, \"learn_time_ms\": 11113.876, \"total_train_time_s\": 14.338318347930908}", "{\"n\": 8850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3439.84, \"learn_time_ms\": 10955.644, \"total_train_time_s\": 13.682974338531494}", "{\"n\": 8851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3439.84, \"learn_time_ms\": 10731.8, \"total_train_time_s\": 13.361164093017578}", "{\"n\": 8852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3441.08, \"learn_time_ms\": 10804.687, \"total_train_time_s\": 14.618491411209106}", "{\"n\": 8853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3439.16, \"learn_time_ms\": 10848.187, \"total_train_time_s\": 15.143936157226562}", "{\"n\": 8854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3439.16, \"learn_time_ms\": 10771.496, \"total_train_time_s\": 14.739312887191772}", "{\"n\": 8855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3431.33, \"learn_time_ms\": 10832.13, \"total_train_time_s\": 15.276705741882324}", "{\"n\": 8856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3441.12, \"learn_time_ms\": 11075.125, \"total_train_time_s\": 16.967194080352783}", "{\"n\": 8857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3436.49, \"learn_time_ms\": 11088.627, \"total_train_time_s\": 14.683730125427246}", "{\"n\": 8858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3441.41, \"learn_time_ms\": 10964.525, \"total_train_time_s\": 14.534223318099976}", "{\"n\": 8859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3443.25, \"learn_time_ms\": 10963.337, \"total_train_time_s\": 14.385859727859497}", "{\"n\": 8860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3452.49, \"learn_time_ms\": 10983.818, \"total_train_time_s\": 14.135431289672852}", "{\"n\": 8861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3467.12, \"learn_time_ms\": 10997.073, \"total_train_time_s\": 13.886909008026123}", "{\"n\": 8862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3467.12, \"learn_time_ms\": 10866.064, \"total_train_time_s\": 13.53695034980774}", "{\"n\": 8863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3464.45, \"learn_time_ms\": 10792.573, \"total_train_time_s\": 14.309582948684692}", "{\"n\": 8864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3469.48, \"learn_time_ms\": 10769.749, \"total_train_time_s\": 14.474281072616577}", "{\"n\": 8865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3466.46, \"learn_time_ms\": 10736.272, \"total_train_time_s\": 14.499976873397827}", "{\"n\": 8866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3466.46, \"learn_time_ms\": 10413.867, \"total_train_time_s\": 13.83551573753357}", "{\"n\": 8867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3475.04, \"learn_time_ms\": 10328.091, \"total_train_time_s\": 13.634472608566284}", "{\"n\": 8868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3477.3, \"learn_time_ms\": 10366.397, \"total_train_time_s\": 14.914637565612793}", "{\"n\": 8869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3480.34, \"learn_time_ms\": 10380.879, \"total_train_time_s\": 14.324503421783447}", "{\"n\": 8870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3473.7, \"learn_time_ms\": 10589.537, \"total_train_time_s\": 16.40746808052063}", "{\"n\": 8871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.78, \"learn_time_ms\": 10668.516, \"total_train_time_s\": 14.31835675239563}", "{\"n\": 8872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.93, \"learn_time_ms\": 10868.325, \"total_train_time_s\": 15.356452941894531}", "{\"n\": 8873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.54, \"learn_time_ms\": 10916.914, \"total_train_time_s\": 14.593361377716064}", "{\"n\": 8874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.54, \"learn_time_ms\": 11009.895, \"total_train_time_s\": 15.227603912353516}", "{\"n\": 8875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3473.47, \"learn_time_ms\": 10831.345, \"total_train_time_s\": 12.835020542144775}", "{\"n\": 8876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3479.84, \"learn_time_ms\": 10852.799, \"total_train_time_s\": 13.862765789031982}", "{\"n\": 8877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.18, \"learn_time_ms\": 10892.406, \"total_train_time_s\": 13.975439548492432}", "{\"n\": 8878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.18, \"learn_time_ms\": 10917.063, \"total_train_time_s\": 15.167174577713013}", "{\"n\": 8879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3469.14, \"learn_time_ms\": 11001.893, \"total_train_time_s\": 15.189365863800049}", "{\"n\": 8880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.28, \"learn_time_ms\": 10921.536, \"total_train_time_s\": 15.28832221031189}", "{\"n\": 8881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.28, \"learn_time_ms\": 10916.986, \"total_train_time_s\": 14.610370874404907}", "{\"n\": 8882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3491.84, \"learn_time_ms\": 10841.398, \"total_train_time_s\": 14.594561576843262}", "{\"n\": 8883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3491.84, \"learn_time_ms\": 10785.814, \"total_train_time_s\": 14.401532173156738}", "{\"n\": 8884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3509.65, \"learn_time_ms\": 10671.393, \"total_train_time_s\": 14.012761116027832}", "{\"n\": 8885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3509.65, \"learn_time_ms\": 10821.503, \"total_train_time_s\": 14.702029943466187}", "{\"n\": 8886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3512.72, \"learn_time_ms\": 10823.245, \"total_train_time_s\": 13.895318031311035}", "{\"n\": 8887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.91, \"learn_time_ms\": 10878.218, \"total_train_time_s\": 14.484747171401978}", "{\"n\": 8888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.41, \"learn_time_ms\": 10812.108, \"total_train_time_s\": 14.513073444366455}", "{\"n\": 8889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.96, \"learn_time_ms\": 10775.13, \"total_train_time_s\": 14.880006074905396}", "{\"n\": 8890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.4, \"learn_time_ms\": 10660.447, \"total_train_time_s\": 14.306576251983643}", "{\"n\": 8891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.49, \"learn_time_ms\": 10573.311, \"total_train_time_s\": 13.47575855255127}", "{\"n\": 8892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.49, \"learn_time_ms\": 10503.387, \"total_train_time_s\": 14.006283283233643}", "{\"n\": 8893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.0, \"learn_time_ms\": 10413.064, \"total_train_time_s\": 13.233203411102295}", "{\"n\": 8894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.05, \"learn_time_ms\": 10529.359, \"total_train_time_s\": 15.349965810775757}", "{\"n\": 8895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3515.1, \"learn_time_ms\": 10482.406, \"total_train_time_s\": 13.746495723724365}", "{\"n\": 8896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3515.1, \"learn_time_ms\": 10569.492, \"total_train_time_s\": 15.066805362701416}", "{\"n\": 8897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3521.0, \"learn_time_ms\": 10498.11, \"total_train_time_s\": 13.874829292297363}", "{\"n\": 8898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.99, \"learn_time_ms\": 10532.848, \"total_train_time_s\": 14.901618957519531}", "{\"n\": 8899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.3, \"learn_time_ms\": 10462.485, \"total_train_time_s\": 14.418297529220581}", "{\"n\": 8900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.3, \"learn_time_ms\": 10575.346, \"total_train_time_s\": 15.163147926330566}", "{\"n\": 8901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.3, \"learn_time_ms\": 10710.689, \"total_train_time_s\": 14.78157377243042}", "{\"n\": 8902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3538.16, \"learn_time_ms\": 10816.888, \"total_train_time_s\": 14.957148551940918}", "{\"n\": 8903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.92, \"learn_time_ms\": 10834.889, \"total_train_time_s\": 13.653277158737183}", "{\"n\": 8904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.92, \"learn_time_ms\": 10882.844, \"total_train_time_s\": 15.789406776428223}", "{\"n\": 8905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3531.72, \"learn_time_ms\": 10991.984, \"total_train_time_s\": 14.886812448501587}", "{\"n\": 8906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3529.99, \"learn_time_ms\": 11079.716, \"total_train_time_s\": 15.70883321762085}", "{\"n\": 8907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.77, \"learn_time_ms\": 11237.827, \"total_train_time_s\": 15.63041639328003}", "{\"n\": 8908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.78, \"learn_time_ms\": 11100.155, \"total_train_time_s\": 13.887222051620483}", "{\"n\": 8909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3539.28, \"learn_time_ms\": 11103.023, \"total_train_time_s\": 14.467493534088135}", "{\"n\": 8910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3542.02, \"learn_time_ms\": 11025.0, \"total_train_time_s\": 14.461283922195435}", "{\"n\": 8911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3542.02, \"learn_time_ms\": 10961.118, \"total_train_time_s\": 14.097193479537964}", "{\"n\": 8912, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3553.31, \"learn_time_ms\": 10885.111, \"total_train_time_s\": 14.311781644821167}", "{\"n\": 8913, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.9, \"learn_time_ms\": 10948.267, \"total_train_time_s\": 14.331092834472656}", "{\"n\": 8914, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3562.32, \"learn_time_ms\": 10930.374, \"total_train_time_s\": 15.746274709701538}", "{\"n\": 8915, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.65, \"learn_time_ms\": 10795.797, \"total_train_time_s\": 13.716475248336792}", "{\"n\": 8916, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.65, \"learn_time_ms\": 10704.9, \"total_train_time_s\": 15.070645570755005}", "{\"n\": 8917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3560.96, \"learn_time_ms\": 10687.572, \"total_train_time_s\": 15.338384628295898}", "{\"n\": 8918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.48, \"learn_time_ms\": 10853.324, \"total_train_time_s\": 15.200681686401367}", "{\"n\": 8919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.48, \"learn_time_ms\": 10983.761, \"total_train_time_s\": 15.585430145263672}", "{\"n\": 8920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3560.8, \"learn_time_ms\": 11028.338, \"total_train_time_s\": 15.199310302734375}", "{\"n\": 8921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3562.44, \"learn_time_ms\": 11172.3, \"total_train_time_s\": 15.698980808258057}", "{\"n\": 8922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3562.44, \"learn_time_ms\": 11342.716, \"total_train_time_s\": 15.887542724609375}", "{\"n\": 8923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3562.44, \"learn_time_ms\": 11382.497, \"total_train_time_s\": 14.248044967651367}", "{\"n\": 8924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.54, \"learn_time_ms\": 11206.969, \"total_train_time_s\": 13.786340713500977}", "{\"n\": 8925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.63, \"learn_time_ms\": 11285.151, \"total_train_time_s\": 14.530951023101807}", "{\"n\": 8926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.63, \"learn_time_ms\": 11272.655, \"total_train_time_s\": 14.689306735992432}", "{\"n\": 8927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.2, \"learn_time_ms\": 11173.831, \"total_train_time_s\": 14.268924236297607}", "{\"n\": 8928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3559.39, \"learn_time_ms\": 11146.811, \"total_train_time_s\": 15.235901117324829}", "{\"n\": 8929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3559.39, \"learn_time_ms\": 11135.159, \"total_train_time_s\": 15.540417671203613}", "{\"n\": 8930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3560.03, \"learn_time_ms\": 11086.687, \"total_train_time_s\": 14.53955078125}", "{\"n\": 8931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3560.03, \"learn_time_ms\": 11060.628, \"total_train_time_s\": 15.6347496509552}", "{\"n\": 8932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3564.19, \"learn_time_ms\": 10853.901, \"total_train_time_s\": 13.898972511291504}", "{\"n\": 8933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.05, \"learn_time_ms\": 10926.923, \"total_train_time_s\": 15.204377174377441}", "{\"n\": 8934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.05, \"learn_time_ms\": 11041.049, \"total_train_time_s\": 14.99482774734497}", "{\"n\": 8935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.05, \"learn_time_ms\": 11089.521, \"total_train_time_s\": 15.23280644416809}", "{\"n\": 8936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3582.55, \"learn_time_ms\": 11035.299, \"total_train_time_s\": 14.286886215209961}", "{\"n\": 8937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3582.2, \"learn_time_ms\": 11065.128, \"total_train_time_s\": 14.601552963256836}", "{\"n\": 8938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3582.2, \"learn_time_ms\": 10951.236, \"total_train_time_s\": 13.606787919998169}", "{\"n\": 8939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.04, \"learn_time_ms\": 10686.009, \"total_train_time_s\": 12.807140827178955}", "{\"n\": 8940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.63, \"learn_time_ms\": 10709.844, \"total_train_time_s\": 14.6201913356781}", "{\"n\": 8941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.05, \"learn_time_ms\": 10533.352, \"total_train_time_s\": 13.67099666595459}", "{\"n\": 8942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.05, \"learn_time_ms\": 10653.678, \"total_train_time_s\": 15.019042253494263}", "{\"n\": 8943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3624.72, \"learn_time_ms\": 10582.055, \"total_train_time_s\": 14.458821535110474}", "{\"n\": 8944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.04, \"learn_time_ms\": 10568.848, \"total_train_time_s\": 15.070629119873047}", "{\"n\": 8945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.04, \"learn_time_ms\": 10630.825, \"total_train_time_s\": 15.505510807037354}", "{\"n\": 8946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.84, \"learn_time_ms\": 10688.905, \"total_train_time_s\": 14.904685258865356}", "{\"n\": 8947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.59, \"learn_time_ms\": 10671.855, \"total_train_time_s\": 14.483710527420044}", "{\"n\": 8948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.75, \"learn_time_ms\": 10771.664, \"total_train_time_s\": 14.836935043334961}", "{\"n\": 8949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.75, \"learn_time_ms\": 11108.799, \"total_train_time_s\": 16.18168592453003}", "{\"n\": 8950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.91, \"learn_time_ms\": 10986.599, \"total_train_time_s\": 13.66472601890564}", "{\"n\": 8951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.91, \"learn_time_ms\": 11087.365, \"total_train_time_s\": 14.87297534942627}", "{\"n\": 8952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.25, \"learn_time_ms\": 10946.136, \"total_train_time_s\": 13.752886056900024}", "{\"n\": 8953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.25, \"learn_time_ms\": 10931.858, \"total_train_time_s\": 14.26173996925354}", "{\"n\": 8954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.68, \"learn_time_ms\": 10849.143, \"total_train_time_s\": 14.028145790100098}", "{\"n\": 8955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.68, \"learn_time_ms\": 10799.249, \"total_train_time_s\": 14.8807852268219}", "{\"n\": 8956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.28, \"learn_time_ms\": 10789.644, \"total_train_time_s\": 14.84302806854248}", "{\"n\": 8957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.47, \"learn_time_ms\": 10784.574, \"total_train_time_s\": 14.349071741104126}", "{\"n\": 8958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.67, \"learn_time_ms\": 10843.908, \"total_train_time_s\": 15.235963106155396}", "{\"n\": 8959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.67, \"learn_time_ms\": 10564.67, \"total_train_time_s\": 13.334868907928467}", "{\"n\": 8960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3637.14, \"learn_time_ms\": 10595.175, \"total_train_time_s\": 13.817826271057129}", "{\"n\": 8961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.17, \"learn_time_ms\": 10562.356, \"total_train_time_s\": 14.383563041687012}", "{\"n\": 8962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.26, \"learn_time_ms\": 10597.428, \"total_train_time_s\": 13.865707397460938}", "{\"n\": 8963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.77, \"learn_time_ms\": 10566.658, \"total_train_time_s\": 13.805855751037598}", "{\"n\": 8964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.64, \"learn_time_ms\": 10511.68, \"total_train_time_s\": 13.425622463226318}", "{\"n\": 8965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.27, \"learn_time_ms\": 10401.659, \"total_train_time_s\": 14.005447626113892}", "{\"n\": 8966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.27, \"learn_time_ms\": 10336.795, \"total_train_time_s\": 14.045477151870728}", "{\"n\": 8967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.83, \"learn_time_ms\": 10393.521, \"total_train_time_s\": 15.248364686965942}", "{\"n\": 8968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.92, \"learn_time_ms\": 10222.982, \"total_train_time_s\": 13.546486139297485}", "{\"n\": 8969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.92, \"learn_time_ms\": 10409.87, \"total_train_time_s\": 15.471253395080566}", "{\"n\": 8970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.92, \"learn_time_ms\": 10444.771, \"total_train_time_s\": 14.311984062194824}", "{\"n\": 8971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.08, \"learn_time_ms\": 10491.632, \"total_train_time_s\": 14.886210918426514}", "{\"n\": 8972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.21, \"learn_time_ms\": 10520.152, \"total_train_time_s\": 14.3168044090271}", "{\"n\": 8973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.21, \"learn_time_ms\": 10664.004, \"total_train_time_s\": 15.651488780975342}", "{\"n\": 8974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.21, \"learn_time_ms\": 10858.615, \"total_train_time_s\": 15.639737606048584}", "{\"n\": 8975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.72, \"learn_time_ms\": 11018.096, \"total_train_time_s\": 15.382045030593872}", "{\"n\": 8976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.72, \"learn_time_ms\": 11057.748, \"total_train_time_s\": 14.302046060562134}", "{\"n\": 8977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.72, \"learn_time_ms\": 11002.65, \"total_train_time_s\": 14.515086889266968}", "{\"n\": 8978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.46, \"learn_time_ms\": 10989.506, \"total_train_time_s\": 13.536361455917358}", "{\"n\": 8979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.02, \"learn_time_ms\": 10982.854, \"total_train_time_s\": 15.159843921661377}", "{\"n\": 8980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.02, \"learn_time_ms\": 11172.335, \"total_train_time_s\": 16.076534271240234}", "{\"n\": 8981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.82, \"learn_time_ms\": 11125.886, \"total_train_time_s\": 14.426391363143921}", "{\"n\": 8982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.11, \"learn_time_ms\": 11144.984, \"total_train_time_s\": 14.573075294494629}", "{\"n\": 8983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.6, \"learn_time_ms\": 11013.114, \"total_train_time_s\": 14.084311246871948}", "{\"n\": 8984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.13, \"learn_time_ms\": 10866.18, \"total_train_time_s\": 13.867972612380981}", "{\"n\": 8985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.36, \"learn_time_ms\": 10753.315, \"total_train_time_s\": 14.506582021713257}", "{\"n\": 8986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.5, \"learn_time_ms\": 10773.285, \"total_train_time_s\": 14.60254716873169}", "{\"n\": 8987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3622.5, \"learn_time_ms\": 10700.984, \"total_train_time_s\": 13.650330781936646}", "{\"n\": 8988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.27, \"learn_time_ms\": 10731.057, \"total_train_time_s\": 13.805172443389893}", "{\"n\": 8989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10605.598, \"total_train_time_s\": 14.012155771255493}", "{\"n\": 8990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.7, \"learn_time_ms\": 10443.481, \"total_train_time_s\": 14.291282892227173}", "{\"n\": 8991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.7, \"learn_time_ms\": 10449.994, \"total_train_time_s\": 14.46718168258667}", "{\"n\": 8992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.4, \"learn_time_ms\": 10323.894, \"total_train_time_s\": 13.228392601013184}", "{\"n\": 8993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.78, \"learn_time_ms\": 10210.337, \"total_train_time_s\": 12.991446495056152}", "{\"n\": 8994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.34, \"learn_time_ms\": 10272.027, \"total_train_time_s\": 14.718597173690796}", "{\"n\": 8995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.98, \"learn_time_ms\": 10192.838, \"total_train_time_s\": 13.719913959503174}", "{\"n\": 8996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.16, \"learn_time_ms\": 10307.497, \"total_train_time_s\": 15.635272741317749}", "{\"n\": 8997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.16, \"learn_time_ms\": 10359.013, \"total_train_time_s\": 14.261164426803589}", "{\"n\": 8998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.86, \"learn_time_ms\": 10442.792, \"total_train_time_s\": 14.759151697158813}", "{\"n\": 8999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.54, \"learn_time_ms\": 10474.819, \"total_train_time_s\": 14.072314262390137}", "{\"n\": 9000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.64, \"learn_time_ms\": 10514.107, \"total_train_time_s\": 14.69242000579834}", "{\"n\": 9001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.64, \"learn_time_ms\": 10657.92, \"total_train_time_s\": 16.063349723815918}", "{\"n\": 9002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.34, \"learn_time_ms\": 10734.297, \"total_train_time_s\": 14.105987071990967}", "{\"n\": 9003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.44, \"learn_time_ms\": 10821.336, \"total_train_time_s\": 13.802936315536499}", "{\"n\": 9004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.77, \"learn_time_ms\": 10796.897, \"total_train_time_s\": 14.267125129699707}", "{\"n\": 9005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.77, \"learn_time_ms\": 10905.036, \"total_train_time_s\": 14.62862229347229}", "{\"n\": 9006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.98, \"learn_time_ms\": 10837.825, \"total_train_time_s\": 15.031524658203125}", "{\"n\": 9007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.5, \"learn_time_ms\": 10712.405, \"total_train_time_s\": 13.126397848129272}", "{\"n\": 9008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.09, \"learn_time_ms\": 10786.169, \"total_train_time_s\": 15.422868728637695}", "{\"n\": 9009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.09, \"learn_time_ms\": 10809.861, \"total_train_time_s\": 14.497275114059448}", "{\"n\": 9010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.76, \"learn_time_ms\": 10831.041, \"total_train_time_s\": 14.97641658782959}", "{\"n\": 9011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.15, \"learn_time_ms\": 10821.479, \"total_train_time_s\": 15.820754051208496}", "{\"n\": 9012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.15, \"learn_time_ms\": 10940.148, \"total_train_time_s\": 15.231873035430908}", "{\"n\": 9013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.79, \"learn_time_ms\": 10989.278, \"total_train_time_s\": 14.620510578155518}", "{\"n\": 9014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.72, \"learn_time_ms\": 11101.889, \"total_train_time_s\": 15.653370380401611}", "{\"n\": 9015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.63, \"learn_time_ms\": 11189.671, \"total_train_time_s\": 15.59562087059021}", "{\"n\": 9016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3641.04, \"learn_time_ms\": 11175.114, \"total_train_time_s\": 14.973223447799683}", "{\"n\": 9017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.23, \"learn_time_ms\": 11441.735, \"total_train_time_s\": 15.788325309753418}", "{\"n\": 9018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.99, \"learn_time_ms\": 11320.098, \"total_train_time_s\": 14.273885488510132}", "{\"n\": 9019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.99, \"learn_time_ms\": 11258.979, \"total_train_time_s\": 14.273473739624023}", "{\"n\": 9020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.27, \"learn_time_ms\": 11247.379, \"total_train_time_s\": 14.96078085899353}", "{\"n\": 9021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.03, \"learn_time_ms\": 11069.652, \"total_train_time_s\": 14.361960887908936}", "{\"n\": 9022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.58, \"learn_time_ms\": 11103.421, \"total_train_time_s\": 15.403738021850586}", "{\"n\": 9023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.58, \"learn_time_ms\": 11054.191, \"total_train_time_s\": 13.902002811431885}", "{\"n\": 9024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.27, \"learn_time_ms\": 10875.543, \"total_train_time_s\": 13.517428398132324}", "{\"n\": 9025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.0, \"learn_time_ms\": 10797.819, \"total_train_time_s\": 14.887331247329712}", "{\"n\": 9026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.55, \"learn_time_ms\": 10713.086, \"total_train_time_s\": 14.007121086120605}", "{\"n\": 9027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.55, \"learn_time_ms\": 10703.18, \"total_train_time_s\": 15.534787654876709}", "{\"n\": 9028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.65, \"learn_time_ms\": 10634.184, \"total_train_time_s\": 13.41277003288269}", "{\"n\": 9029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.98, \"learn_time_ms\": 10721.003, \"total_train_time_s\": 14.617963790893555}", "{\"n\": 9030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.45, \"learn_time_ms\": 10698.138, \"total_train_time_s\": 14.571122884750366}", "{\"n\": 9031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.45, \"learn_time_ms\": 10780.172, \"total_train_time_s\": 14.840053081512451}", "{\"n\": 9032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.76, \"learn_time_ms\": 10709.701, \"total_train_time_s\": 14.702133893966675}", "{\"n\": 9033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.76, \"learn_time_ms\": 10831.975, \"total_train_time_s\": 15.212825298309326}", "{\"n\": 9034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.04, \"learn_time_ms\": 10965.103, \"total_train_time_s\": 14.887755393981934}", "{\"n\": 9035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.43, \"learn_time_ms\": 10918.369, \"total_train_time_s\": 14.452428340911865}", "{\"n\": 9036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.43, \"learn_time_ms\": 10897.799, \"total_train_time_s\": 14.147308588027954}", "{\"n\": 9037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.28, \"learn_time_ms\": 10810.49, \"total_train_time_s\": 14.668181419372559}", "{\"n\": 9038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.08, \"learn_time_ms\": 11019.703, \"total_train_time_s\": 15.740614414215088}", "{\"n\": 9039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.61, \"learn_time_ms\": 11016.971, \"total_train_time_s\": 14.853576898574829}", "{\"n\": 9040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.61, \"learn_time_ms\": 11037.047, \"total_train_time_s\": 14.711827993392944}", "{\"n\": 9041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.3, \"learn_time_ms\": 10923.315, \"total_train_time_s\": 13.703635692596436}", "{\"n\": 9042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.74, \"learn_time_ms\": 10806.306, \"total_train_time_s\": 13.777039051055908}", "{\"n\": 9043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.74, \"learn_time_ms\": 10660.773, \"total_train_time_s\": 13.685235738754272}", "{\"n\": 9044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.95, \"learn_time_ms\": 10620.764, \"total_train_time_s\": 14.614539861679077}", "{\"n\": 9045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.98, \"learn_time_ms\": 10601.56, \"total_train_time_s\": 14.37123727798462}", "{\"n\": 9046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.82, \"learn_time_ms\": 10461.324, \"total_train_time_s\": 12.394552946090698}", "{\"n\": 9047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.82, \"learn_time_ms\": 10447.408, \"total_train_time_s\": 14.573158979415894}", "{\"n\": 9048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.89, \"learn_time_ms\": 10388.804, \"total_train_time_s\": 15.000660181045532}", "{\"n\": 9049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.31, \"learn_time_ms\": 10339.744, \"total_train_time_s\": 14.216187477111816}", "{\"n\": 9050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.07, \"learn_time_ms\": 10365.831, \"total_train_time_s\": 14.999375343322754}", "{\"n\": 9051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.07, \"learn_time_ms\": 10485.344, \"total_train_time_s\": 14.700054407119751}", "{\"n\": 9052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.28, \"learn_time_ms\": 10574.578, \"total_train_time_s\": 14.489864349365234}", "{\"n\": 9053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.61, \"learn_time_ms\": 10727.679, \"total_train_time_s\": 15.069551467895508}", "{\"n\": 9054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.76, \"learn_time_ms\": 10723.779, \"total_train_time_s\": 14.692986011505127}", "{\"n\": 9055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.76, \"learn_time_ms\": 10774.263, \"total_train_time_s\": 14.641464233398438}", "{\"n\": 9056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.56, \"learn_time_ms\": 11013.087, \"total_train_time_s\": 15.013375043869019}", "{\"n\": 9057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.56, \"learn_time_ms\": 11022.708, \"total_train_time_s\": 14.807992696762085}", "{\"n\": 9058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.68, \"learn_time_ms\": 10985.974, \"total_train_time_s\": 14.596879243850708}", "{\"n\": 9059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.68, \"learn_time_ms\": 10976.394, \"total_train_time_s\": 14.189948081970215}", "{\"n\": 9060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.6, \"learn_time_ms\": 10928.062, \"total_train_time_s\": 14.6431405544281}", "{\"n\": 9061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.6, \"learn_time_ms\": 10901.318, \"total_train_time_s\": 14.420902729034424}", "{\"n\": 9062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.15, \"learn_time_ms\": 11019.935, \"total_train_time_s\": 15.933869123458862}", "{\"n\": 9063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.09, \"learn_time_ms\": 10912.474, \"total_train_time_s\": 14.038067102432251}", "{\"n\": 9064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.19, \"learn_time_ms\": 10818.869, \"total_train_time_s\": 13.644188165664673}", "{\"n\": 9065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.19, \"learn_time_ms\": 10784.242, \"total_train_time_s\": 14.439370155334473}", "{\"n\": 9066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.15, \"learn_time_ms\": 10890.035, \"total_train_time_s\": 15.790973663330078}", "{\"n\": 9067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.76, \"learn_time_ms\": 10840.569, \"total_train_time_s\": 14.028939008712769}", "{\"n\": 9068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.63, \"learn_time_ms\": 10952.559, \"total_train_time_s\": 15.815636396408081}", "{\"n\": 9069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.24, \"learn_time_ms\": 11084.534, \"total_train_time_s\": 15.264161586761475}", "{\"n\": 9070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.24, \"learn_time_ms\": 11115.388, \"total_train_time_s\": 15.002865552902222}", "{\"n\": 9071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.08, \"learn_time_ms\": 11140.486, \"total_train_time_s\": 14.931912422180176}", "{\"n\": 9072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.56, \"learn_time_ms\": 10994.001, \"total_train_time_s\": 14.377147912979126}", "{\"n\": 9073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.67, \"learn_time_ms\": 11014.962, \"total_train_time_s\": 14.424794435501099}", "{\"n\": 9074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.65, \"learn_time_ms\": 11058.98, \"total_train_time_s\": 14.249226093292236}", "{\"n\": 9075, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.42, \"learn_time_ms\": 11062.016, \"total_train_time_s\": 14.260337352752686}", "{\"n\": 9076, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.4, \"learn_time_ms\": 10900.097, \"total_train_time_s\": 14.394823551177979}", "{\"n\": 9077, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.46, \"learn_time_ms\": 10952.016, \"total_train_time_s\": 14.790133714675903}", "{\"n\": 9078, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.32, \"learn_time_ms\": 10891.222, \"total_train_time_s\": 15.034671306610107}", "{\"n\": 9079, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 10908.739, \"total_train_time_s\": 15.431614637374878}", "{\"n\": 9080, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.62, \"learn_time_ms\": 10930.049, \"total_train_time_s\": 15.37917447090149}", "{\"n\": 9081, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.13, \"learn_time_ms\": 10908.905, \"total_train_time_s\": 14.676053762435913}", "{\"n\": 9082, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.13, \"learn_time_ms\": 10910.307, \"total_train_time_s\": 14.265866994857788}", "{\"n\": 9083, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.8, \"learn_time_ms\": 10818.122, \"total_train_time_s\": 13.325715065002441}", "{\"n\": 9084, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.98, \"learn_time_ms\": 10829.131, \"total_train_time_s\": 14.184733390808105}", "{\"n\": 9085, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.88, \"learn_time_ms\": 10931.676, \"total_train_time_s\": 15.498780488967896}", "{\"n\": 9086, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.88, \"learn_time_ms\": 10977.096, \"total_train_time_s\": 14.812936067581177}", "{\"n\": 9087, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.16, \"learn_time_ms\": 10935.012, \"total_train_time_s\": 14.07407021522522}", "{\"n\": 9088, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.96, \"learn_time_ms\": 10857.441, \"total_train_time_s\": 14.206271648406982}", "{\"n\": 9089, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.96, \"learn_time_ms\": 10740.35, \"total_train_time_s\": 14.492571592330933}", "{\"n\": 9090, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.12, \"learn_time_ms\": 10750.474, \"total_train_time_s\": 15.282338857650757}", "{\"n\": 9091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.12, \"learn_time_ms\": 10806.132, \"total_train_time_s\": 15.386267900466919}", "{\"n\": 9092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.65, \"learn_time_ms\": 10832.52, \"total_train_time_s\": 14.446006298065186}", "{\"n\": 9093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.65, \"learn_time_ms\": 11056.1, \"total_train_time_s\": 16.013115406036377}", "{\"n\": 9094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.44, \"learn_time_ms\": 11114.399, \"total_train_time_s\": 14.844674110412598}", "{\"n\": 9095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.25, \"learn_time_ms\": 11050.162, \"total_train_time_s\": 14.869078397750854}", "{\"n\": 9096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.78, \"learn_time_ms\": 11025.122, \"total_train_time_s\": 14.522716760635376}", "{\"n\": 9097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.78, \"learn_time_ms\": 11087.498, \"total_train_time_s\": 15.216702222824097}", "{\"n\": 9098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.78, \"learn_time_ms\": 11091.263, \"total_train_time_s\": 14.469771385192871}", "{\"n\": 9099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.06, \"learn_time_ms\": 11211.872, \"total_train_time_s\": 15.498657703399658}", "{\"n\": 9100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.7, \"learn_time_ms\": 11123.449, \"total_train_time_s\": 14.437237024307251}", "{\"n\": 9101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.7, \"learn_time_ms\": 10973.992, \"total_train_time_s\": 13.873869895935059}", "{\"n\": 9102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.51, \"learn_time_ms\": 11022.298, \"total_train_time_s\": 15.026153087615967}", "{\"n\": 9103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.78, \"learn_time_ms\": 10870.247, \"total_train_time_s\": 14.038618564605713}", "{\"n\": 9104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.71, \"learn_time_ms\": 10733.502, \"total_train_time_s\": 13.401488304138184}", "{\"n\": 9105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.71, \"learn_time_ms\": 10668.882, \"total_train_time_s\": 14.0078763961792}", "{\"n\": 9106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.45, \"learn_time_ms\": 10658.537, \"total_train_time_s\": 14.409587144851685}", "{\"n\": 9107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.1, \"learn_time_ms\": 10597.019, \"total_train_time_s\": 14.098517179489136}", "{\"n\": 9108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 10617.926, \"total_train_time_s\": 14.75092101097107}", "{\"n\": 9109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 10505.668, \"total_train_time_s\": 14.355295896530151}", "{\"n\": 9110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.21, \"learn_time_ms\": 10488.526, \"total_train_time_s\": 14.156447410583496}", "{\"n\": 9111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.39, \"learn_time_ms\": 10548.344, \"total_train_time_s\": 14.269146919250488}", "{\"n\": 9112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.39, \"learn_time_ms\": 10497.619, \"total_train_time_s\": 14.72854208946228}", "{\"n\": 9113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.4, \"learn_time_ms\": 10538.391, \"total_train_time_s\": 14.668816089630127}", "{\"n\": 9114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.41, \"learn_time_ms\": 10703.713, \"total_train_time_s\": 14.868359804153442}", "{\"n\": 9115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.79, \"learn_time_ms\": 10754.863, \"total_train_time_s\": 14.774003982543945}", "{\"n\": 9116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.79, \"learn_time_ms\": 10610.63, \"total_train_time_s\": 13.31718397140503}", "{\"n\": 9117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.47, \"learn_time_ms\": 10555.553, \"total_train_time_s\": 13.65979552268982}", "{\"n\": 9118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.84, \"learn_time_ms\": 10587.338, \"total_train_time_s\": 14.97688603401184}", "{\"n\": 9119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.84, \"learn_time_ms\": 10452.142, \"total_train_time_s\": 12.996778011322021}", "{\"n\": 9120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.84, \"learn_time_ms\": 10451.218, \"total_train_time_s\": 14.32608938217163}", "{\"n\": 9121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.07, \"learn_time_ms\": 10487.286, \"total_train_time_s\": 14.586896181106567}", "{\"n\": 9122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.03, \"learn_time_ms\": 10468.64, \"total_train_time_s\": 14.284940242767334}", "{\"n\": 9123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.03, \"learn_time_ms\": 10403.851, \"total_train_time_s\": 13.764140367507935}", "{\"n\": 9124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.56, \"learn_time_ms\": 10286.377, \"total_train_time_s\": 13.974100351333618}", "{\"n\": 9125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.09, \"learn_time_ms\": 10265.298, \"total_train_time_s\": 14.406523704528809}", "{\"n\": 9126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.09, \"learn_time_ms\": 10262.951, \"total_train_time_s\": 12.84206509590149}", "{\"n\": 9127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.09, \"learn_time_ms\": 10235.398, \"total_train_time_s\": 13.552065372467041}", "{\"n\": 9128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.2, \"learn_time_ms\": 10126.44, \"total_train_time_s\": 14.00727653503418}", "{\"n\": 9129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.65, \"learn_time_ms\": 10226.76, \"total_train_time_s\": 14.122714757919312}", "{\"n\": 9130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.65, \"learn_time_ms\": 10225.724, \"total_train_time_s\": 14.320996522903442}", "{\"n\": 9131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.82, \"learn_time_ms\": 10294.786, \"total_train_time_s\": 15.546853065490723}", "{\"n\": 9132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.1, \"learn_time_ms\": 10301.659, \"total_train_time_s\": 14.54765248298645}", "{\"n\": 9133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.1, \"learn_time_ms\": 10351.386, \"total_train_time_s\": 14.296995878219604}", "{\"n\": 9134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.1, \"learn_time_ms\": 10479.674, \"total_train_time_s\": 15.498304605484009}", "{\"n\": 9135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.12, \"learn_time_ms\": 10476.499, \"total_train_time_s\": 14.295058965682983}", "{\"n\": 9136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 10609.378, \"total_train_time_s\": 14.344712018966675}", "{\"n\": 9137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 10778.849, \"total_train_time_s\": 15.29839277267456}", "{\"n\": 9138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.37, \"learn_time_ms\": 10813.882, \"total_train_time_s\": 14.055588245391846}", "{\"n\": 9139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 10849.619, \"total_train_time_s\": 14.432332277297974}", "{\"n\": 9140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.27, \"learn_time_ms\": 10953.452, \"total_train_time_s\": 15.21943211555481}", "{\"n\": 9141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.27, \"learn_time_ms\": 10966.188, \"total_train_time_s\": 15.552840948104858}", "{\"n\": 9142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.27, \"learn_time_ms\": 10961.863, \"total_train_time_s\": 14.550496578216553}", "{\"n\": 9143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.39, \"learn_time_ms\": 11051.275, \"total_train_time_s\": 15.066981554031372}", "{\"n\": 9144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.39, \"learn_time_ms\": 11029.413, \"total_train_time_s\": 15.127685546875}", "{\"n\": 9145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.58, \"learn_time_ms\": 11131.616, \"total_train_time_s\": 15.31587290763855}", "{\"n\": 9146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.78, \"learn_time_ms\": 11172.008, \"total_train_time_s\": 14.578570127487183}", "{\"n\": 9147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.04, \"learn_time_ms\": 11071.358, \"total_train_time_s\": 14.072211742401123}", "{\"n\": 9148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.93, \"learn_time_ms\": 10950.235, \"total_train_time_s\": 13.24782657623291}", "{\"n\": 9149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.19, \"learn_time_ms\": 10936.087, \"total_train_time_s\": 14.318482875823975}", "{\"n\": 9150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.16, \"learn_time_ms\": 10799.573, \"total_train_time_s\": 13.885883092880249}", "{\"n\": 9151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.16, \"learn_time_ms\": 10675.538, \"total_train_time_s\": 14.410145044326782}", "{\"n\": 9152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.31, \"learn_time_ms\": 10637.527, \"total_train_time_s\": 14.062516450881958}", "{\"n\": 9153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.31, \"learn_time_ms\": 10615.705, \"total_train_time_s\": 15.098009824752808}", "{\"n\": 9154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.88, \"learn_time_ms\": 10501.627, \"total_train_time_s\": 13.944169282913208}", "{\"n\": 9155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.88, \"learn_time_ms\": 10350.624, \"total_train_time_s\": 13.789702892303467}", "{\"n\": 9156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.94, \"learn_time_ms\": 10335.549, \"total_train_time_s\": 14.804924011230469}", "{\"n\": 9157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.28, \"learn_time_ms\": 10400.416, \"total_train_time_s\": 14.87087607383728}", "{\"n\": 9158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.28, \"learn_time_ms\": 10595.306, \"total_train_time_s\": 15.11743688583374}", "{\"n\": 9159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.28, \"learn_time_ms\": 10725.685, \"total_train_time_s\": 15.510437250137329}", "{\"n\": 9160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.29, \"learn_time_ms\": 10762.541, \"total_train_time_s\": 14.3654203414917}", "{\"n\": 9161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.29, \"learn_time_ms\": 10887.039, \"total_train_time_s\": 15.580776929855347}", "{\"n\": 9162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.12, \"learn_time_ms\": 11033.805, \"total_train_time_s\": 15.553674697875977}", "{\"n\": 9163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.2, \"learn_time_ms\": 10939.935, \"total_train_time_s\": 13.879924058914185}", "{\"n\": 9164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.93, \"learn_time_ms\": 10977.33, \"total_train_time_s\": 14.04587697982788}", "{\"n\": 9165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.48, \"learn_time_ms\": 11079.439, \"total_train_time_s\": 15.009089231491089}", "{\"n\": 9166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.48, \"learn_time_ms\": 10964.547, \"total_train_time_s\": 13.288443326950073}", "{\"n\": 9167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.96, \"learn_time_ms\": 10957.173, \"total_train_time_s\": 14.721611738204956}", "{\"n\": 9168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.96, \"learn_time_ms\": 10864.72, \"total_train_time_s\": 14.264837265014648}", "{\"n\": 9169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.8, \"learn_time_ms\": 10775.984, \"total_train_time_s\": 14.786963701248169}", "{\"n\": 9170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.07, \"learn_time_ms\": 10902.739, \"total_train_time_s\": 15.464801788330078}", "{\"n\": 9171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.9, \"learn_time_ms\": 10790.974, \"total_train_time_s\": 14.260972261428833}", "{\"n\": 9172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.21, \"learn_time_ms\": 10705.475, \"total_train_time_s\": 14.508440971374512}", "{\"n\": 9173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.58, \"learn_time_ms\": 10766.871, \"total_train_time_s\": 14.877923011779785}", "{\"n\": 9174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.58, \"learn_time_ms\": 10728.126, \"total_train_time_s\": 13.751400709152222}", "{\"n\": 9175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.13, \"learn_time_ms\": 10568.938, \"total_train_time_s\": 13.30165982246399}", "{\"n\": 9176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.54, \"learn_time_ms\": 10709.083, \"total_train_time_s\": 14.704488277435303}", "{\"n\": 9177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.54, \"learn_time_ms\": 10652.64, \"total_train_time_s\": 14.117687225341797}", "{\"n\": 9178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.54, \"learn_time_ms\": 10722.381, \"total_train_time_s\": 14.605623245239258}", "{\"n\": 9179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.63, \"learn_time_ms\": 10653.069, \"total_train_time_s\": 14.080475568771362}", "{\"n\": 9180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.34, \"learn_time_ms\": 10440.393, \"total_train_time_s\": 13.43685793876648}", "{\"n\": 9181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.34, \"learn_time_ms\": 10389.739, \"total_train_time_s\": 13.981967687606812}", "{\"n\": 9182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.75, \"learn_time_ms\": 10353.809, \"total_train_time_s\": 14.466885805130005}", "{\"n\": 9183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.13, \"learn_time_ms\": 10268.629, \"total_train_time_s\": 13.731284618377686}", "{\"n\": 9184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.13, \"learn_time_ms\": 10315.615, \"total_train_time_s\": 14.389349937438965}", "{\"n\": 9185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.13, \"learn_time_ms\": 10410.999, \"total_train_time_s\": 14.327409982681274}", "{\"n\": 9186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.12, \"learn_time_ms\": 10392.352, \"total_train_time_s\": 14.807607412338257}", "{\"n\": 9187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.1, \"learn_time_ms\": 10500.116, \"total_train_time_s\": 15.10369610786438}", "{\"n\": 9188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.1, \"learn_time_ms\": 10487.053, \"total_train_time_s\": 14.388498544692993}", "{\"n\": 9189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.1, \"learn_time_ms\": 10508.814, \"total_train_time_s\": 14.181813478469849}", "{\"n\": 9190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.31, \"learn_time_ms\": 10628.537, \"total_train_time_s\": 14.52932620048523}", "{\"n\": 9191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.45, \"learn_time_ms\": 10798.555, \"total_train_time_s\": 15.412807941436768}", "{\"n\": 9192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.45, \"learn_time_ms\": 10864.724, \"total_train_time_s\": 14.728310346603394}", "{\"n\": 9193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.7, \"learn_time_ms\": 11061.218, \"total_train_time_s\": 15.877869606018066}", "{\"n\": 9194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.57, \"learn_time_ms\": 11061.281, \"total_train_time_s\": 14.355167627334595}", "{\"n\": 9195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.57, \"learn_time_ms\": 11158.419, \"total_train_time_s\": 15.181637287139893}", "{\"n\": 9196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.57, \"learn_time_ms\": 11104.931, \"total_train_time_s\": 14.079683542251587}", "{\"n\": 9197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.6, \"learn_time_ms\": 10986.517, \"total_train_time_s\": 14.049213647842407}", "{\"n\": 9198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.52, \"learn_time_ms\": 10948.83, \"total_train_time_s\": 14.08780574798584}", "{\"n\": 9199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.3, \"learn_time_ms\": 11065.172, \"total_train_time_s\": 15.460130453109741}", "{\"n\": 9200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.75, \"learn_time_ms\": 10907.303, \"total_train_time_s\": 13.056405067443848}", "{\"n\": 9201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.53, \"learn_time_ms\": 10884.002, \"total_train_time_s\": 15.338069677352905}", "{\"n\": 9202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.26, \"learn_time_ms\": 10896.738, \"total_train_time_s\": 15.061535120010376}", "{\"n\": 9203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.12, \"learn_time_ms\": 10701.781, \"total_train_time_s\": 13.854616403579712}", "{\"n\": 9204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.08, \"learn_time_ms\": 10724.072, \"total_train_time_s\": 14.296217918395996}", "{\"n\": 9205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10775.016, \"total_train_time_s\": 15.581899642944336}", "{\"n\": 9206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10794.99, \"total_train_time_s\": 14.243873596191406}", "{\"n\": 9207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.99, \"learn_time_ms\": 10864.484, \"total_train_time_s\": 14.685535907745361}", "{\"n\": 9208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.67, \"learn_time_ms\": 10879.403, \"total_train_time_s\": 14.521684885025024}", "{\"n\": 9209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.67, \"learn_time_ms\": 10814.224, \"total_train_time_s\": 15.035635471343994}", "{\"n\": 9210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.47, \"learn_time_ms\": 10871.03, \"total_train_time_s\": 13.69131875038147}", "{\"n\": 9211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.05, \"learn_time_ms\": 10793.072, \"total_train_time_s\": 14.494609832763672}", "{\"n\": 9212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.34, \"learn_time_ms\": 10776.579, \"total_train_time_s\": 14.931306838989258}", "{\"n\": 9213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.34, \"learn_time_ms\": 10830.331, \"total_train_time_s\": 14.311956882476807}", "{\"n\": 9214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.36, \"learn_time_ms\": 10784.514, \"total_train_time_s\": 14.11319613456726}", "{\"n\": 9215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.59, \"learn_time_ms\": 10720.498, \"total_train_time_s\": 14.928676843643188}", "{\"n\": 9216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.59, \"learn_time_ms\": 10736.009, \"total_train_time_s\": 14.300029277801514}", "{\"n\": 9217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.59, \"learn_time_ms\": 10656.593, \"total_train_time_s\": 14.13485836982727}", "{\"n\": 9218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.2, \"learn_time_ms\": 10695.775, \"total_train_time_s\": 14.575589179992676}", "{\"n\": 9219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 10643.346, \"total_train_time_s\": 14.148688077926636}", "{\"n\": 9220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 10641.955, \"total_train_time_s\": 13.494078874588013}", "{\"n\": 9221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.85, \"learn_time_ms\": 10624.701, \"total_train_time_s\": 14.388660907745361}", "{\"n\": 9222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.76, \"learn_time_ms\": 10470.068, \"total_train_time_s\": 13.211358785629272}", "{\"n\": 9223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.76, \"learn_time_ms\": 10478.689, \"total_train_time_s\": 14.705086469650269}", "{\"n\": 9224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.99, \"learn_time_ms\": 10417.023, \"total_train_time_s\": 13.490641355514526}", "{\"n\": 9225, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.58, \"learn_time_ms\": 10386.179, \"total_train_time_s\": 14.706155061721802}", "{\"n\": 9226, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.69, \"learn_time_ms\": 10304.808, \"total_train_time_s\": 13.75691294670105}", "{\"n\": 9227, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.69, \"learn_time_ms\": 10390.674, \"total_train_time_s\": 14.988538980484009}", "{\"n\": 9228, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.95, \"learn_time_ms\": 10244.958, \"total_train_time_s\": 13.137796401977539}", "{\"n\": 9229, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.27, \"learn_time_ms\": 10300.032, \"total_train_time_s\": 14.785683393478394}", "{\"n\": 9230, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.27, \"learn_time_ms\": 10375.927, \"total_train_time_s\": 14.203685998916626}", "{\"n\": 9231, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.27, \"learn_time_ms\": 10407.311, \"total_train_time_s\": 14.752860069274902}", "{\"n\": 9232, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 10489.603, \"total_train_time_s\": 14.24924921989441}", "{\"n\": 9233, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 10458.911, \"total_train_time_s\": 13.952208042144775}", "{\"n\": 9234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 10552.725, \"total_train_time_s\": 14.389218807220459}", "{\"n\": 9235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.29, \"learn_time_ms\": 10531.512, \"total_train_time_s\": 14.401537656784058}", "{\"n\": 9236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.45, \"learn_time_ms\": 10558.326, \"total_train_time_s\": 13.942795038223267}", "{\"n\": 9237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.45, \"learn_time_ms\": 10540.342, \"total_train_time_s\": 14.70257043838501}", "{\"n\": 9238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.45, \"learn_time_ms\": 10672.98, \"total_train_time_s\": 14.84870982170105}", "{\"n\": 9239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.63, \"learn_time_ms\": 10781.244, \"total_train_time_s\": 16.104837656021118}", "{\"n\": 9240, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 10758.259, \"total_train_time_s\": 14.482250690460205}", "{\"n\": 9241, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 10655.34, \"total_train_time_s\": 13.712361812591553}", "{\"n\": 9242, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.2, \"learn_time_ms\": 10848.792, \"total_train_time_s\": 16.170897245407104}", "{\"n\": 9243, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.07, \"learn_time_ms\": 10846.49, \"total_train_time_s\": 14.188043117523193}", "{\"n\": 9244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.07, \"learn_time_ms\": 10836.27, \"total_train_time_s\": 14.413212299346924}", "{\"n\": 9245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.07, \"learn_time_ms\": 10768.915, \"total_train_time_s\": 13.912437438964844}", "{\"n\": 9246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.53, \"learn_time_ms\": 10875.535, \"total_train_time_s\": 15.141621112823486}", "{\"n\": 9247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.53, \"learn_time_ms\": 10870.094, \"total_train_time_s\": 14.365511655807495}", "{\"n\": 9248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.53, \"learn_time_ms\": 10809.305, \"total_train_time_s\": 13.8189218044281}", "{\"n\": 9249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.79, \"learn_time_ms\": 10662.549, \"total_train_time_s\": 14.487545728683472}", "{\"n\": 9250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.38, \"learn_time_ms\": 10759.515, \"total_train_time_s\": 15.160182476043701}", "{\"n\": 9251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.62, \"learn_time_ms\": 10892.228, \"total_train_time_s\": 15.065057039260864}", "{\"n\": 9252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.62, \"learn_time_ms\": 10724.012, \"total_train_time_s\": 14.217906951904297}", "{\"n\": 9253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.28, \"learn_time_ms\": 10760.779, \"total_train_time_s\": 14.365153789520264}", "{\"n\": 9254, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.18, \"learn_time_ms\": 10788.337, \"total_train_time_s\": 14.52411699295044}", "{\"n\": 9255, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.98, \"learn_time_ms\": 10863.425, \"total_train_time_s\": 14.794616937637329}", "{\"n\": 9256, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.98, \"learn_time_ms\": 10784.222, \"total_train_time_s\": 14.192068576812744}", "{\"n\": 9257, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.18, \"learn_time_ms\": 10864.925, \"total_train_time_s\": 15.221329927444458}", "{\"n\": 9258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.14, \"learn_time_ms\": 11007.761, \"total_train_time_s\": 15.423394918441772}", "{\"n\": 9259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.42, \"learn_time_ms\": 10935.228, \"total_train_time_s\": 13.729416608810425}", "{\"n\": 9260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.42, \"learn_time_ms\": 10858.629, \"total_train_time_s\": 14.418654441833496}", "{\"n\": 9261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.89, \"learn_time_ms\": 10741.82, \"total_train_time_s\": 13.837361335754395}", "{\"n\": 9262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.44, \"learn_time_ms\": 10679.331, \"total_train_time_s\": 13.666980504989624}", "{\"n\": 9263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.44, \"learn_time_ms\": 10769.421, \"total_train_time_s\": 15.332156419754028}", "{\"n\": 9264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.88, \"learn_time_ms\": 10840.689, \"total_train_time_s\": 15.45712161064148}", "{\"n\": 9265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.73, \"learn_time_ms\": 10929.412, \"total_train_time_s\": 15.460107564926147}", "{\"n\": 9266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.83, \"learn_time_ms\": 11044.086, \"total_train_time_s\": 15.239492893218994}", "{\"n\": 9267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.83, \"learn_time_ms\": 10948.832, \"total_train_time_s\": 14.60657286643982}", "{\"n\": 9268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.71, \"learn_time_ms\": 10844.256, \"total_train_time_s\": 14.361591339111328}", "{\"n\": 9269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.19, \"learn_time_ms\": 11001.354, \"total_train_time_s\": 15.18831729888916}", "{\"n\": 9270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.39, \"learn_time_ms\": 10899.763, \"total_train_time_s\": 13.34451150894165}", "{\"n\": 9271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.56, \"learn_time_ms\": 10965.235, \"total_train_time_s\": 14.67008662223816}", "{\"n\": 9272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.33, \"learn_time_ms\": 11028.764, \"total_train_time_s\": 14.489615201950073}", "{\"n\": 9273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.86, \"learn_time_ms\": 10876.043, \"total_train_time_s\": 13.84544587135315}", "{\"n\": 9274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.86, \"learn_time_ms\": 10878.847, \"total_train_time_s\": 15.547994375228882}", "{\"n\": 9275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.86, \"learn_time_ms\": 10695.419, \"total_train_time_s\": 13.532201051712036}", "{\"n\": 9276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.23, \"learn_time_ms\": 10623.18, \"total_train_time_s\": 14.591341257095337}", "{\"n\": 9277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.52, \"learn_time_ms\": 10673.129, \"total_train_time_s\": 14.809696912765503}", "{\"n\": 9278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.52, \"learn_time_ms\": 10682.355, \"total_train_time_s\": 14.62803840637207}", "{\"n\": 9279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.52, \"learn_time_ms\": 10616.258, \"total_train_time_s\": 14.75572681427002}", "{\"n\": 9280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.76, \"learn_time_ms\": 10747.71, \"total_train_time_s\": 14.439804553985596}", "{\"n\": 9281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.4, \"learn_time_ms\": 10728.984, \"total_train_time_s\": 14.328629732131958}", "{\"n\": 9282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.4, \"learn_time_ms\": 10718.188, \"total_train_time_s\": 14.405459880828857}", "{\"n\": 9283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.6, \"learn_time_ms\": 10833.829, \"total_train_time_s\": 14.956891298294067}", "{\"n\": 9284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.17, \"learn_time_ms\": 10801.922, \"total_train_time_s\": 14.88343095779419}", "{\"n\": 9285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.31, \"learn_time_ms\": 10938.182, \"total_train_time_s\": 15.088347673416138}", "{\"n\": 9286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.31, \"learn_time_ms\": 10899.197, \"total_train_time_s\": 14.292288541793823}", "{\"n\": 9287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.89, \"learn_time_ms\": 10746.616, \"total_train_time_s\": 13.611681461334229}", "{\"n\": 9288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.89, \"learn_time_ms\": 10799.435, \"total_train_time_s\": 15.081315279006958}", "{\"n\": 9289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 10925.487, \"total_train_time_s\": 15.964214324951172}", "{\"n\": 9290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 11037.694, \"total_train_time_s\": 15.640716314315796}", "{\"n\": 9291, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.65, \"learn_time_ms\": 11066.127, \"total_train_time_s\": 14.500203132629395}", "{\"n\": 9292, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.65, \"learn_time_ms\": 11147.873, \"total_train_time_s\": 15.173561096191406}", "{\"n\": 9293, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.32, \"learn_time_ms\": 11125.676, \"total_train_time_s\": 14.935443878173828}", "{\"n\": 9294, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.39, \"learn_time_ms\": 11014.067, \"total_train_time_s\": 14.016936779022217}", "{\"n\": 9295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.92, \"learn_time_ms\": 10934.438, \"total_train_time_s\": 14.137975692749023}", "{\"n\": 9296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.92, \"learn_time_ms\": 10915.982, \"total_train_time_s\": 13.984519958496094}", "{\"n\": 9297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3669.6, \"learn_time_ms\": 10954.026, \"total_train_time_s\": 14.008142709732056}", "{\"n\": 9298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3673.81, \"learn_time_ms\": 10817.613, \"total_train_time_s\": 13.579277992248535}", "{\"n\": 9299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3673.23, \"learn_time_ms\": 10744.356, \"total_train_time_s\": 15.166512489318848}", "{\"n\": 9300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3675.25, \"learn_time_ms\": 10648.375, \"total_train_time_s\": 14.635498762130737}", "{\"n\": 9301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3676.77, \"learn_time_ms\": 10636.834, \"total_train_time_s\": 14.390431642532349}", "{\"n\": 9302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10555.023, \"total_train_time_s\": 14.461971998214722}", "{\"n\": 9303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10561.522, \"total_train_time_s\": 14.702255249023438}", "{\"n\": 9304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3668.68, \"learn_time_ms\": 10598.917, \"total_train_time_s\": 14.097633361816406}", "{\"n\": 9305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3657.55, \"learn_time_ms\": 10547.542, \"total_train_time_s\": 13.741740942001343}", "{\"n\": 9306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3659.62, \"learn_time_ms\": 10450.562, \"total_train_time_s\": 13.16615080833435}", "{\"n\": 9307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3660.11, \"learn_time_ms\": 10516.864, \"total_train_time_s\": 14.682743549346924}", "{\"n\": 9308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.21, \"learn_time_ms\": 10629.486, \"total_train_time_s\": 14.599660396575928}", "{\"n\": 9309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.27, \"learn_time_ms\": 10637.003, \"total_train_time_s\": 15.181258201599121}", "{\"n\": 9310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.04, \"learn_time_ms\": 10673.435, \"total_train_time_s\": 15.160173892974854}", "{\"n\": 9311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10612.489, \"total_train_time_s\": 13.675719738006592}", "{\"n\": 9312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10550.214, \"total_train_time_s\": 13.725752830505371}", "{\"n\": 9313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.08, \"learn_time_ms\": 10422.847, \"total_train_time_s\": 13.596128702163696}", "{\"n\": 9314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.42, \"learn_time_ms\": 10414.236, \"total_train_time_s\": 14.160221815109253}", "{\"n\": 9315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.9, \"learn_time_ms\": 10532.718, \"total_train_time_s\": 14.918355703353882}", "{\"n\": 9316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.9, \"learn_time_ms\": 10716.25, \"total_train_time_s\": 14.888168334960938}", "{\"n\": 9317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.52, \"learn_time_ms\": 10697.267, \"total_train_time_s\": 14.19636583328247}", "{\"n\": 9318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.12, \"learn_time_ms\": 10630.906, \"total_train_time_s\": 14.05858826637268}", "{\"n\": 9319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.34, \"learn_time_ms\": 10493.261, \"total_train_time_s\": 13.738768815994263}", "{\"n\": 9320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.69, \"learn_time_ms\": 10442.294, \"total_train_time_s\": 14.66231918334961}", "{\"n\": 9321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.17, \"learn_time_ms\": 10602.899, \"total_train_time_s\": 15.7028067111969}", "{\"n\": 9322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.97, \"learn_time_ms\": 10675.854, \"total_train_time_s\": 14.307127952575684}", "{\"n\": 9323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.97, \"learn_time_ms\": 10738.885, \"total_train_time_s\": 14.071609020233154}", "{\"n\": 9324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.47, \"learn_time_ms\": 10808.959, \"total_train_time_s\": 14.928646802902222}", "{\"n\": 9325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.65, \"learn_time_ms\": 10829.904, \"total_train_time_s\": 15.009751796722412}", "{\"n\": 9326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.96, \"learn_time_ms\": 10730.693, \"total_train_time_s\": 14.117763757705688}", "{\"n\": 9327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.96, \"learn_time_ms\": 10730.822, \"total_train_time_s\": 14.134950399398804}", "{\"n\": 9328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.86, \"learn_time_ms\": 10700.241, \"total_train_time_s\": 13.754464387893677}", "{\"n\": 9329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.66, \"learn_time_ms\": 10800.208, \"total_train_time_s\": 14.968010187149048}", "{\"n\": 9330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.66, \"learn_time_ms\": 10769.711, \"total_train_time_s\": 14.279192686080933}", "{\"n\": 9331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.66, \"learn_time_ms\": 10589.415, \"total_train_time_s\": 13.532403707504272}", "{\"n\": 9332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.54, \"learn_time_ms\": 10671.922, \"total_train_time_s\": 15.120724439620972}", "{\"n\": 9333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.47, \"learn_time_ms\": 10813.631, \"total_train_time_s\": 15.532425880432129}", "{\"n\": 9334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.47, \"learn_time_ms\": 10797.583, \"total_train_time_s\": 14.579451560974121}", "{\"n\": 9335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.47, \"learn_time_ms\": 10706.949, \"total_train_time_s\": 14.205899477005005}", "{\"n\": 9336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.05, \"learn_time_ms\": 10775.399, \"total_train_time_s\": 14.640058517456055}", "{\"n\": 9337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.05, \"learn_time_ms\": 10764.464, \"total_train_time_s\": 14.159600496292114}", "{\"n\": 9338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.05, \"learn_time_ms\": 10913.316, \"total_train_time_s\": 15.243170261383057}", "{\"n\": 9339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.92, \"learn_time_ms\": 10937.208, \"total_train_time_s\": 15.17129111289978}", "{\"n\": 9340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.33, \"learn_time_ms\": 11020.561, \"total_train_time_s\": 15.045426368713379}", "{\"n\": 9341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.33, \"learn_time_ms\": 10998.195, \"total_train_time_s\": 13.492430686950684}", "{\"n\": 9342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.33, \"learn_time_ms\": 11026.843, \"total_train_time_s\": 15.39260458946228}", "{\"n\": 9343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.4, \"learn_time_ms\": 10898.555, \"total_train_time_s\": 14.447682619094849}", "{\"n\": 9344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.59, \"learn_time_ms\": 10986.608, \"total_train_time_s\": 15.47317624092102}", "{\"n\": 9345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.59, \"learn_time_ms\": 11046.738, \"total_train_time_s\": 15.16636323928833}", "{\"n\": 9346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.65, \"learn_time_ms\": 11069.37, \"total_train_time_s\": 14.834856510162354}", "{\"n\": 9347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.26, \"learn_time_ms\": 11178.623, \"total_train_time_s\": 15.331281423568726}", "{\"n\": 9348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.26, \"learn_time_ms\": 11075.063, \"total_train_time_s\": 14.488489151000977}", "{\"n\": 9349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.12, \"learn_time_ms\": 10994.895, \"total_train_time_s\": 14.346898555755615}", "{\"n\": 9350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.66, \"learn_time_ms\": 10916.772, \"total_train_time_s\": 14.419247150421143}", "{\"n\": 9351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.03, \"learn_time_ms\": 10961.501, \"total_train_time_s\": 14.013193368911743}", "{\"n\": 9352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.03, \"learn_time_ms\": 10889.012, \"total_train_time_s\": 14.630374908447266}", "{\"n\": 9353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.03, \"learn_time_ms\": 10959.349, \"total_train_time_s\": 15.261495590209961}", "{\"n\": 9354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.45, \"learn_time_ms\": 10851.021, \"total_train_time_s\": 14.273803234100342}", "{\"n\": 9355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.45, \"learn_time_ms\": 10815.527, \"total_train_time_s\": 14.734793186187744}", "{\"n\": 9356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.45, \"learn_time_ms\": 10955.466, \"total_train_time_s\": 16.42342758178711}", "{\"n\": 9357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.81, \"learn_time_ms\": 10921.343, \"total_train_time_s\": 14.71866750717163}", "{\"n\": 9358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.02, \"learn_time_ms\": 10897.259, \"total_train_time_s\": 14.1321120262146}", "{\"n\": 9359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.62, \"learn_time_ms\": 10854.56, \"total_train_time_s\": 14.052745580673218}", "{\"n\": 9360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.62, \"learn_time_ms\": 10814.317, \"total_train_time_s\": 13.96935772895813}", "{\"n\": 9361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.53, \"learn_time_ms\": 10824.55, \"total_train_time_s\": 13.972081422805786}", "{\"n\": 9362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.06, \"learn_time_ms\": 10735.794, \"total_train_time_s\": 13.796845197677612}", "{\"n\": 9363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.06, \"learn_time_ms\": 10680.516, \"total_train_time_s\": 14.821959257125854}", "{\"n\": 9364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.62, \"learn_time_ms\": 10690.936, \"total_train_time_s\": 14.859952211380005}", "{\"n\": 9365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.89, \"learn_time_ms\": 10764.781, \"total_train_time_s\": 15.213500738143921}", "{\"n\": 9366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.49, \"learn_time_ms\": 10528.661, \"total_train_time_s\": 13.694025754928589}", "{\"n\": 9367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.49, \"learn_time_ms\": 10567.206, \"total_train_time_s\": 15.540751934051514}", "{\"n\": 9368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.58, \"learn_time_ms\": 10515.465, \"total_train_time_s\": 13.469000339508057}", "{\"n\": 9369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.62, \"learn_time_ms\": 10481.264, \"total_train_time_s\": 13.406930685043335}", "{\"n\": 9370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.57, \"learn_time_ms\": 10506.796, \"total_train_time_s\": 14.442010641098022}", "{\"n\": 9371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.57, \"learn_time_ms\": 10534.565, \"total_train_time_s\": 14.30417513847351}", "{\"n\": 9372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.04, \"learn_time_ms\": 10564.879, \"total_train_time_s\": 14.359673976898193}", "{\"n\": 9373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.51, \"learn_time_ms\": 10498.516, \"total_train_time_s\": 13.89029860496521}", "{\"n\": 9374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.51, \"learn_time_ms\": 10485.73, \"total_train_time_s\": 14.48738718032837}", "{\"n\": 9375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.09, \"learn_time_ms\": 10401.583, \"total_train_time_s\": 14.39687991142273}", "{\"n\": 9376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.15, \"learn_time_ms\": 10567.311, \"total_train_time_s\": 15.435370206832886}", "{\"n\": 9377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.15, \"learn_time_ms\": 10482.413, \"total_train_time_s\": 14.248043060302734}", "{\"n\": 9378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.55, \"learn_time_ms\": 10614.549, \"total_train_time_s\": 14.920325994491577}", "{\"n\": 9379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.33, \"learn_time_ms\": 10676.393, \"total_train_time_s\": 14.295241355895996}", "{\"n\": 9380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.33, \"learn_time_ms\": 10703.268, \"total_train_time_s\": 14.837280750274658}", "{\"n\": 9381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.51, \"learn_time_ms\": 10708.009, \"total_train_time_s\": 14.280295610427856}", "{\"n\": 9382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.51, \"learn_time_ms\": 10778.953, \"total_train_time_s\": 14.842403411865234}", "{\"n\": 9383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.95, \"learn_time_ms\": 10682.528, \"total_train_time_s\": 12.89593505859375}", "{\"n\": 9384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.95, \"learn_time_ms\": 10589.49, \"total_train_time_s\": 13.537200450897217}", "{\"n\": 9385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.87, \"learn_time_ms\": 10690.143, \"total_train_time_s\": 15.274366855621338}", "{\"n\": 9386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.87, \"learn_time_ms\": 10515.47, \"total_train_time_s\": 13.573665380477905}", "{\"n\": 9387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.23, \"learn_time_ms\": 10497.951, \"total_train_time_s\": 14.147725105285645}", "{\"n\": 9388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.84, \"learn_time_ms\": 10356.137, \"total_train_time_s\": 13.50998854637146}", "{\"n\": 9389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.31, \"learn_time_ms\": 10414.872, \"total_train_time_s\": 14.936514616012573}", "{\"n\": 9390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.31, \"learn_time_ms\": 10400.73, \"total_train_time_s\": 14.425253868103027}", "{\"n\": 9391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.99, \"learn_time_ms\": 10432.393, \"total_train_time_s\": 14.604807615280151}", "{\"n\": 9392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 10468.003, \"total_train_time_s\": 15.117782354354858}", "{\"n\": 9393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.41, \"learn_time_ms\": 10605.312, \"total_train_time_s\": 14.244425535202026}", "{\"n\": 9394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.6, \"learn_time_ms\": 10743.026, \"total_train_time_s\": 14.993496894836426}", "{\"n\": 9395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.66, \"learn_time_ms\": 10576.567, \"total_train_time_s\": 13.777021646499634}", "{\"n\": 9396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.91, \"learn_time_ms\": 10619.704, \"total_train_time_s\": 14.251070976257324}", "{\"n\": 9397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.91, \"learn_time_ms\": 10614.156, \"total_train_time_s\": 14.377072811126709}", "{\"n\": 9398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.11, \"learn_time_ms\": 10768.802, \"total_train_time_s\": 15.119082689285278}", "{\"n\": 9399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.11, \"learn_time_ms\": 10771.237, \"total_train_time_s\": 15.01448655128479}", "{\"n\": 9400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.8, \"learn_time_ms\": 10862.103, \"total_train_time_s\": 15.295910835266113}", "{\"n\": 9401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.72, \"learn_time_ms\": 10805.209, \"total_train_time_s\": 13.976080894470215}", "{\"n\": 9402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.69, \"learn_time_ms\": 10644.185, \"total_train_time_s\": 13.561589002609253}", "{\"n\": 9403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.83, \"learn_time_ms\": 10593.184, \"total_train_time_s\": 13.650949716567993}", "{\"n\": 9404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.47, \"learn_time_ms\": 10625.827, \"total_train_time_s\": 15.429145574569702}", "{\"n\": 9405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.25, \"learn_time_ms\": 10759.822, \"total_train_time_s\": 14.959051609039307}", "{\"n\": 9406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.53, \"learn_time_ms\": 10898.468, \"total_train_time_s\": 15.412415981292725}", "{\"n\": 9407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.53, \"learn_time_ms\": 10859.148, \"total_train_time_s\": 13.836501121520996}", "{\"n\": 9408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.94, \"learn_time_ms\": 10887.705, \"total_train_time_s\": 15.216796636581421}", "{\"n\": 9409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.53, \"learn_time_ms\": 10777.895, \"total_train_time_s\": 13.735060691833496}", "{\"n\": 9410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.09, \"learn_time_ms\": 10625.317, \"total_train_time_s\": 13.777586460113525}", "{\"n\": 9411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.09, \"learn_time_ms\": 10603.093, \"total_train_time_s\": 14.301665544509888}", "{\"n\": 9412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.1, \"learn_time_ms\": 10774.672, \"total_train_time_s\": 15.24769902229309}", "{\"n\": 9413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3709.03, \"learn_time_ms\": 10878.328, \"total_train_time_s\": 14.92374062538147}", "{\"n\": 9414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.31, \"learn_time_ms\": 10817.953, \"total_train_time_s\": 14.506198644638062}", "{\"n\": 9415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.96, \"learn_time_ms\": 10634.1, \"total_train_time_s\": 13.08725118637085}", "{\"n\": 9416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.96, \"learn_time_ms\": 10515.653, \"total_train_time_s\": 14.647088050842285}", "{\"n\": 9417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.53, \"learn_time_ms\": 10613.978, \"total_train_time_s\": 14.655600547790527}", "{\"n\": 9418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.53, \"learn_time_ms\": 10539.931, \"total_train_time_s\": 14.860370635986328}", "{\"n\": 9419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.57, \"learn_time_ms\": 10660.306, \"total_train_time_s\": 14.796552419662476}", "{\"n\": 9420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.68, \"learn_time_ms\": 10757.106, \"total_train_time_s\": 14.96361756324768}", "{\"n\": 9421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.68, \"learn_time_ms\": 10715.652, \"total_train_time_s\": 13.48294973373413}", "{\"n\": 9422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.77, \"learn_time_ms\": 10630.401, \"total_train_time_s\": 14.425679445266724}", "{\"n\": 9423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.93, \"learn_time_ms\": 10590.509, \"total_train_time_s\": 14.393773794174194}", "{\"n\": 9424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.38, \"learn_time_ms\": 10638.942, \"total_train_time_s\": 15.080886840820312}", "{\"n\": 9425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.45, \"learn_time_ms\": 10623.446, \"total_train_time_s\": 13.124378442764282}", "{\"n\": 9426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.22, \"learn_time_ms\": 10657.156, \"total_train_time_s\": 14.84386920928955}", "{\"n\": 9427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.63, \"learn_time_ms\": 10656.254, \"total_train_time_s\": 14.917800903320312}", "{\"n\": 9428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.09, \"learn_time_ms\": 10687.974, \"total_train_time_s\": 14.705457210540771}", "{\"n\": 9429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.09, \"learn_time_ms\": 10562.83, \"total_train_time_s\": 13.434590816497803}", "{\"n\": 9430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.02, \"learn_time_ms\": 10599.296, \"total_train_time_s\": 15.062692642211914}", "{\"n\": 9431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.8, \"learn_time_ms\": 10656.412, \"total_train_time_s\": 14.121917963027954}", "{\"n\": 9432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.23, \"learn_time_ms\": 10807.979, \"total_train_time_s\": 16.107393264770508}", "{\"n\": 9433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.23, \"learn_time_ms\": 11026.758, \"total_train_time_s\": 16.7395236492157}", "{\"n\": 9434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.75, \"learn_time_ms\": 10906.69, \"total_train_time_s\": 13.833529472351074}", "{\"n\": 9435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.75, \"learn_time_ms\": 11165.199, \"total_train_time_s\": 15.775353908538818}", "{\"n\": 9436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.54, \"learn_time_ms\": 11077.233, \"total_train_time_s\": 13.934805393218994}", "{\"n\": 9437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.54, \"learn_time_ms\": 10985.417, \"total_train_time_s\": 13.87473464012146}", "{\"n\": 9438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.78, \"learn_time_ms\": 11012.812, \"total_train_time_s\": 14.994201898574829}", "{\"n\": 9439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.26, \"learn_time_ms\": 11054.9, \"total_train_time_s\": 13.929190397262573}", "{\"n\": 9440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.16, \"learn_time_ms\": 10941.352, \"total_train_time_s\": 13.956979274749756}", "{\"n\": 9441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.55, \"learn_time_ms\": 11011.009, \"total_train_time_s\": 14.696753978729248}", "{\"n\": 9442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.84, \"learn_time_ms\": 10809.932, \"total_train_time_s\": 14.147441625595093}", "{\"n\": 9443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.84, \"learn_time_ms\": 10575.987, \"total_train_time_s\": 14.250929832458496}", "{\"n\": 9444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.57, \"learn_time_ms\": 10659.249, \"total_train_time_s\": 14.841760635375977}", "{\"n\": 9445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.57, \"learn_time_ms\": 10522.799, \"total_train_time_s\": 14.123555898666382}", "{\"n\": 9446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.37, \"learn_time_ms\": 10680.315, \"total_train_time_s\": 15.51004147529602}", "{\"n\": 9447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.37, \"learn_time_ms\": 10726.051, \"total_train_time_s\": 14.363253831863403}", "{\"n\": 9448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.16, \"learn_time_ms\": 10664.591, \"total_train_time_s\": 14.670325994491577}", "{\"n\": 9449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.65, \"learn_time_ms\": 10775.89, \"total_train_time_s\": 15.051299333572388}", "{\"n\": 9450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.29, \"learn_time_ms\": 10700.16, \"total_train_time_s\": 13.1170973777771}", "{\"n\": 9451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.29, \"learn_time_ms\": 10545.152, \"total_train_time_s\": 13.258153200149536}", "{\"n\": 9452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.75, \"learn_time_ms\": 10658.071, \"total_train_time_s\": 15.0129714012146}", "{\"n\": 9453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.72, \"learn_time_ms\": 10797.475, \"total_train_time_s\": 15.679142475128174}", "{\"n\": 9454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.39, \"learn_time_ms\": 10770.991, \"total_train_time_s\": 14.360048770904541}", "{\"n\": 9455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.96, \"learn_time_ms\": 10781.722, \"total_train_time_s\": 14.572539806365967}", "{\"n\": 9456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.96, \"learn_time_ms\": 10679.427, \"total_train_time_s\": 14.750545740127563}", "{\"n\": 9457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.56, \"learn_time_ms\": 10740.619, \"total_train_time_s\": 15.091338157653809}", "{\"n\": 9458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.62, \"learn_time_ms\": 10707.677, \"total_train_time_s\": 14.203606367111206}", "{\"n\": 9459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.62, \"learn_time_ms\": 10637.097, \"total_train_time_s\": 14.64829397201538}", "{\"n\": 9460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3688.06, \"learn_time_ms\": 10700.96, \"total_train_time_s\": 13.780991315841675}", "{\"n\": 9461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3688.06, \"learn_time_ms\": 10835.216, \"total_train_time_s\": 14.627899885177612}", "{\"n\": 9462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.16, \"learn_time_ms\": 10828.179, \"total_train_time_s\": 15.06361699104309}", "{\"n\": 9463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.71, \"learn_time_ms\": 10789.973, \"total_train_time_s\": 15.118510961532593}", "{\"n\": 9464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.15, \"learn_time_ms\": 10821.089, \"total_train_time_s\": 14.637616634368896}", "{\"n\": 9465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.68, \"learn_time_ms\": 10701.085, \"total_train_time_s\": 13.001828670501709}", "{\"n\": 9466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.55, \"learn_time_ms\": 10693.422, \"total_train_time_s\": 14.396129608154297}", "{\"n\": 9467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 10703.457, \"total_train_time_s\": 15.233604669570923}", "{\"n\": 9468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.39, \"learn_time_ms\": 10678.999, \"total_train_time_s\": 13.73134469985962}", "{\"n\": 9469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.81, \"learn_time_ms\": 10795.089, \"total_train_time_s\": 15.637895584106445}", "{\"n\": 9470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.58, \"learn_time_ms\": 10935.952, \"total_train_time_s\": 15.076338768005371}", "{\"n\": 9471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.49, \"learn_time_ms\": 10895.253, \"total_train_time_s\": 14.096857786178589}", "{\"n\": 9472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.63, \"learn_time_ms\": 10804.161, \"total_train_time_s\": 14.306321382522583}", "{\"n\": 9473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 10691.783, \"total_train_time_s\": 14.25959324836731}", "{\"n\": 9474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.38, \"learn_time_ms\": 10542.01, \"total_train_time_s\": 13.491915225982666}", "{\"n\": 9475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.09, \"learn_time_ms\": 10638.319, \"total_train_time_s\": 14.090217351913452}", "{\"n\": 9476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.76, \"learn_time_ms\": 10599.213, \"total_train_time_s\": 13.89219355583191}", "{\"n\": 9477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.04, \"learn_time_ms\": 10464.355, \"total_train_time_s\": 13.849174976348877}", "{\"n\": 9478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.61, \"learn_time_ms\": 10461.274, \"total_train_time_s\": 13.83307957649231}", "{\"n\": 9479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.61, \"learn_time_ms\": 10345.01, \"total_train_time_s\": 14.31890344619751}", "{\"n\": 9480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.68, \"learn_time_ms\": 10354.246, \"total_train_time_s\": 15.273426532745361}", "{\"n\": 9481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.68, \"learn_time_ms\": 10333.98, \"total_train_time_s\": 14.002262830734253}", "{\"n\": 9482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.77, \"learn_time_ms\": 10386.473, \"total_train_time_s\": 14.618759155273438}", "{\"n\": 9483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.38, \"learn_time_ms\": 10396.112, \"total_train_time_s\": 14.417476654052734}", "{\"n\": 9484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.77, \"learn_time_ms\": 10498.556, \"total_train_time_s\": 14.470839023590088}", "{\"n\": 9485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.57, \"learn_time_ms\": 10578.194, \"total_train_time_s\": 15.139397859573364}", "{\"n\": 9486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.57, \"learn_time_ms\": 10638.43, \"total_train_time_s\": 14.512594223022461}", "{\"n\": 9487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.57, \"learn_time_ms\": 10693.768, \"total_train_time_s\": 14.076043128967285}", "{\"n\": 9488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.79, \"learn_time_ms\": 10813.192, \"total_train_time_s\": 14.990752935409546}", "{\"n\": 9489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.79, \"learn_time_ms\": 10740.243, \"total_train_time_s\": 13.556571960449219}", "{\"n\": 9490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.79, \"learn_time_ms\": 10649.831, \"total_train_time_s\": 14.46648383140564}", "{\"n\": 9491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.4, \"learn_time_ms\": 10632.028, \"total_train_time_s\": 13.774944067001343}", "{\"n\": 9492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.19, \"learn_time_ms\": 10639.838, \"total_train_time_s\": 15.054626226425171}", "{\"n\": 9493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.19, \"learn_time_ms\": 10641.808, \"total_train_time_s\": 14.063962697982788}", "{\"n\": 9494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.19, \"learn_time_ms\": 10659.052, \"total_train_time_s\": 14.54222559928894}", "{\"n\": 9495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.33, \"learn_time_ms\": 10674.161, \"total_train_time_s\": 15.219189405441284}", "{\"n\": 9496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.86, \"learn_time_ms\": 10729.122, \"total_train_time_s\": 15.187525272369385}", "{\"n\": 9497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.86, \"learn_time_ms\": 10776.691, \"total_train_time_s\": 14.83748722076416}", "{\"n\": 9498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.86, \"learn_time_ms\": 10675.107, \"total_train_time_s\": 14.2323899269104}", "{\"n\": 9499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.45, \"learn_time_ms\": 10681.879, \"total_train_time_s\": 13.866820573806763}", "{\"n\": 9500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.45, \"learn_time_ms\": 10672.856, \"total_train_time_s\": 14.378092288970947}", "{\"n\": 9501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.45, \"learn_time_ms\": 10535.388, \"total_train_time_s\": 12.600738286972046}", "{\"n\": 9502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.71, \"learn_time_ms\": 10528.267, \"total_train_time_s\": 14.892986536026001}", "{\"n\": 9503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.64, \"learn_time_ms\": 10654.397, \"total_train_time_s\": 15.427205562591553}", "{\"n\": 9504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.58, \"learn_time_ms\": 10698.259, \"total_train_time_s\": 15.014981746673584}", "{\"n\": 9505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.58, \"learn_time_ms\": 10757.375, \"total_train_time_s\": 15.862391233444214}", "{\"n\": 9506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.56, \"learn_time_ms\": 10695.784, \"total_train_time_s\": 14.37276577949524}", "{\"n\": 9507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.7, \"learn_time_ms\": 10622.929, \"total_train_time_s\": 13.809193849563599}", "{\"n\": 9508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.01, \"learn_time_ms\": 10595.901, \"total_train_time_s\": 13.660425186157227}", "{\"n\": 9509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.73, \"learn_time_ms\": 10687.671, \"total_train_time_s\": 14.913046836853027}", "{\"n\": 9510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.87, \"learn_time_ms\": 10770.91, \"total_train_time_s\": 15.236087799072266}", "{\"n\": 9511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.58, \"learn_time_ms\": 11103.428, \"total_train_time_s\": 15.658235788345337}", "{\"n\": 9512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.58, \"learn_time_ms\": 11080.401, \"total_train_time_s\": 14.8132004737854}", "{\"n\": 9513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.84, \"learn_time_ms\": 11023.043, \"total_train_time_s\": 15.146454095840454}", "{\"n\": 9514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 10882.684, \"total_train_time_s\": 13.312687873840332}", "{\"n\": 9515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 10712.506, \"total_train_time_s\": 13.842274188995361}", "{\"n\": 9516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 10609.302, \"total_train_time_s\": 13.443997383117676}", "{\"n\": 9517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.57, \"learn_time_ms\": 10539.241, \"total_train_time_s\": 13.136301755905151}", "{\"n\": 9518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.57, \"learn_time_ms\": 10488.702, \"total_train_time_s\": 13.105769157409668}", "{\"n\": 9519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.17, \"learn_time_ms\": 10466.355, \"total_train_time_s\": 14.452139854431152}", "{\"n\": 9520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.17, \"learn_time_ms\": 10321.237, \"total_train_time_s\": 14.022746562957764}", "{\"n\": 9521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.32, \"learn_time_ms\": 10201.338, \"total_train_time_s\": 14.560280323028564}", "{\"n\": 9522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.69, \"learn_time_ms\": 10242.941, \"total_train_time_s\": 15.112335920333862}", "{\"n\": 9523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.69, \"learn_time_ms\": 10209.475, \"total_train_time_s\": 15.075127601623535}", "{\"n\": 9524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.73, \"learn_time_ms\": 10428.394, \"total_train_time_s\": 15.731081008911133}", "{\"n\": 9525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.97, \"learn_time_ms\": 10379.938, \"total_train_time_s\": 13.80025315284729}", "{\"n\": 9526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.58, \"learn_time_ms\": 10517.609, \"total_train_time_s\": 14.805251359939575}", "{\"n\": 9527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.58, \"learn_time_ms\": 10578.162, \"total_train_time_s\": 14.045469999313354}", "{\"n\": 9528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.83, \"learn_time_ms\": 10646.468, \"total_train_time_s\": 13.986422300338745}", "{\"n\": 9529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.02, \"learn_time_ms\": 10587.942, \"total_train_time_s\": 13.806357860565186}", "{\"n\": 9530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.82, \"learn_time_ms\": 10601.256, \"total_train_time_s\": 13.774996995925903}", "{\"n\": 9531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.29, \"learn_time_ms\": 10500.03, \"total_train_time_s\": 13.390822172164917}", "{\"n\": 9532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.36, \"learn_time_ms\": 10448.192, \"total_train_time_s\": 14.521507263183594}", "{\"n\": 9533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.92, \"learn_time_ms\": 10481.743, \"total_train_time_s\": 15.103503465652466}", "{\"n\": 9534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.13, \"learn_time_ms\": 10347.978, \"total_train_time_s\": 14.434484958648682}", "{\"n\": 9535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.23, \"learn_time_ms\": 10390.166, \"total_train_time_s\": 13.908358573913574}", "{\"n\": 9536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.62, \"learn_time_ms\": 10408.988, \"total_train_time_s\": 15.079731464385986}", "{\"n\": 9537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.17, \"learn_time_ms\": 10497.381, \"total_train_time_s\": 15.022026777267456}", "{\"n\": 9538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.48, \"learn_time_ms\": 10515.1, \"total_train_time_s\": 14.311266899108887}", "{\"n\": 9539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.9, \"learn_time_ms\": 10483.834, \"total_train_time_s\": 13.636138200759888}", "{\"n\": 9540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.5, \"learn_time_ms\": 10522.959, \"total_train_time_s\": 14.340661525726318}", "{\"n\": 9541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.72, \"learn_time_ms\": 10670.717, \"total_train_time_s\": 14.806698322296143}", "{\"n\": 9542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.56, \"learn_time_ms\": 10645.415, \"total_train_time_s\": 13.965030431747437}", "{\"n\": 9543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.56, \"learn_time_ms\": 10627.337, \"total_train_time_s\": 14.940571308135986}", "{\"n\": 9544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.94, \"learn_time_ms\": 10590.097, \"total_train_time_s\": 14.030932188034058}", "{\"n\": 9545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.94, \"learn_time_ms\": 10643.711, \"total_train_time_s\": 14.438677072525024}", "{\"n\": 9546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.08, \"learn_time_ms\": 10634.477, \"total_train_time_s\": 14.828840970993042}", "{\"n\": 9547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 10559.441, \"total_train_time_s\": 14.025190591812134}", "{\"n\": 9548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 10551.187, \"total_train_time_s\": 14.041534900665283}", "{\"n\": 9549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 10542.175, \"total_train_time_s\": 13.541439294815063}", "{\"n\": 9550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.71, \"learn_time_ms\": 10449.534, \"total_train_time_s\": 13.21482229232788}", "{\"n\": 9551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.71, \"learn_time_ms\": 10486.895, \"total_train_time_s\": 15.178024291992188}", "{\"n\": 9552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.71, \"learn_time_ms\": 10574.075, \"total_train_time_s\": 14.857685327529907}", "{\"n\": 9553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10479.016, \"total_train_time_s\": 13.716416835784912}", "{\"n\": 9554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10509.949, \"total_train_time_s\": 14.650599002838135}", "{\"n\": 9555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10607.595, \"total_train_time_s\": 15.367420196533203}", "{\"n\": 9556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 10660.301, \"total_train_time_s\": 15.363501071929932}", "{\"n\": 9557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.46, \"learn_time_ms\": 10753.349, \"total_train_time_s\": 15.11028790473938}", "{\"n\": 9558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.46, \"learn_time_ms\": 10837.508, \"total_train_time_s\": 14.693113327026367}", "{\"n\": 9559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.46, \"learn_time_ms\": 10956.192, \"total_train_time_s\": 14.752668142318726}", "{\"n\": 9560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.46, \"learn_time_ms\": 11001.696, \"total_train_time_s\": 13.912686824798584}", "{\"n\": 9561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.45, \"learn_time_ms\": 10801.068, \"total_train_time_s\": 13.30327558517456}", "{\"n\": 9562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.45, \"learn_time_ms\": 10763.829, \"total_train_time_s\": 14.694207906723022}", "{\"n\": 9563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.45, \"learn_time_ms\": 10999.248, \"total_train_time_s\": 16.52883219718933}", "{\"n\": 9564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.78, \"learn_time_ms\": 11062.121, \"total_train_time_s\": 15.146498441696167}", "{\"n\": 9565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.22, \"learn_time_ms\": 10908.999, \"total_train_time_s\": 14.024424314498901}", "{\"n\": 9566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.22, \"learn_time_ms\": 10817.533, \"total_train_time_s\": 14.35610318183899}", "{\"n\": 9567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.51, \"learn_time_ms\": 10830.879, \"total_train_time_s\": 15.155627012252808}", "{\"n\": 9568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.58, \"learn_time_ms\": 10805.562, \"total_train_time_s\": 14.797202825546265}", "{\"n\": 9569, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.58, \"learn_time_ms\": 10817.614, \"total_train_time_s\": 14.714645385742188}", "{\"n\": 9570, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.58, \"learn_time_ms\": 10830.223, \"total_train_time_s\": 13.76415228843689}", "{\"n\": 9571, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.39, \"learn_time_ms\": 11034.707, \"total_train_time_s\": 15.403989315032959}", "{\"n\": 9572, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.74, \"learn_time_ms\": 10965.983, \"total_train_time_s\": 14.010960817337036}", "{\"n\": 9573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.74, \"learn_time_ms\": 10756.234, \"total_train_time_s\": 14.30827283859253}", "{\"n\": 9574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.74, \"learn_time_ms\": 10625.167, \"total_train_time_s\": 13.660325288772583}", "{\"n\": 9575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.21, \"learn_time_ms\": 10623.31, \"total_train_time_s\": 13.802796363830566}", "{\"n\": 9576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.03, \"learn_time_ms\": 10704.125, \"total_train_time_s\": 15.392695665359497}", "{\"n\": 9577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.03, \"learn_time_ms\": 10679.437, \"total_train_time_s\": 14.734873533248901}", "{\"n\": 9578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.03, \"learn_time_ms\": 10731.821, \"total_train_time_s\": 15.45804214477539}", "{\"n\": 9579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.98, \"learn_time_ms\": 10693.946, \"total_train_time_s\": 14.338647603988647}", "{\"n\": 9580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.91, \"learn_time_ms\": 10750.531, \"total_train_time_s\": 14.459890604019165}", "{\"n\": 9581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.91, \"learn_time_ms\": 10546.581, \"total_train_time_s\": 13.260082244873047}", "{\"n\": 9582, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.26, \"learn_time_ms\": 10519.578, \"total_train_time_s\": 13.611754655838013}", "{\"n\": 9583, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.25, \"learn_time_ms\": 10461.105, \"total_train_time_s\": 13.305030822753906}", "{\"n\": 9584, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 10651.271, \"total_train_time_s\": 15.408132314682007}", "{\"n\": 9585, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.88, \"learn_time_ms\": 10583.631, \"total_train_time_s\": 13.404687404632568}", "{\"n\": 9586, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.14, \"learn_time_ms\": 10458.648, \"total_train_time_s\": 13.949726581573486}", "{\"n\": 9587, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.72, \"learn_time_ms\": 10361.394, \"total_train_time_s\": 13.784540176391602}", "{\"n\": 9588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.72, \"learn_time_ms\": 10330.164, \"total_train_time_s\": 15.099535942077637}", "{\"n\": 9589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.72, \"learn_time_ms\": 10297.43, \"total_train_time_s\": 14.51517653465271}", "{\"n\": 9590, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.16, \"learn_time_ms\": 10451.355, \"total_train_time_s\": 16.092278242111206}", "{\"n\": 9591, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.65, \"learn_time_ms\": 10586.142, \"total_train_time_s\": 14.682355403900146}", "{\"n\": 9592, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.65, \"learn_time_ms\": 10694.672, \"total_train_time_s\": 14.881932973861694}", "{\"n\": 9593, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.65, \"learn_time_ms\": 10915.099, \"total_train_time_s\": 15.593655824661255}", "{\"n\": 9594, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.51, \"learn_time_ms\": 10839.047, \"total_train_time_s\": 14.833299160003662}", "{\"n\": 9595, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.07, \"learn_time_ms\": 10980.114, \"total_train_time_s\": 14.71144723892212}", "{\"n\": 9596, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.07, \"learn_time_ms\": 11001.483, \"total_train_time_s\": 14.470720291137695}", "{\"n\": 9597, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.68, \"learn_time_ms\": 11043.661, \"total_train_time_s\": 14.409211158752441}", "{\"n\": 9598, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.84, \"learn_time_ms\": 11050.193, \"total_train_time_s\": 14.89148497581482}", "{\"n\": 9599, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.88, \"learn_time_ms\": 11105.429, \"total_train_time_s\": 14.513035774230957}", "{\"n\": 9600, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.88, \"learn_time_ms\": 10951.727, \"total_train_time_s\": 14.31942105293274}", "{\"n\": 9601, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.45, \"learn_time_ms\": 10912.304, \"total_train_time_s\": 14.117944717407227}", "{\"n\": 9602, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.6, \"learn_time_ms\": 10832.147, \"total_train_time_s\": 13.879645824432373}", "{\"n\": 9603, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.83, \"learn_time_ms\": 10745.793, \"total_train_time_s\": 14.756377935409546}", "{\"n\": 9604, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.94, \"learn_time_ms\": 10726.795, \"total_train_time_s\": 14.456063747406006}", "{\"n\": 9605, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.48, \"learn_time_ms\": 10714.187, \"total_train_time_s\": 14.438447713851929}", "{\"n\": 9606, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.17, \"learn_time_ms\": 10801.234, \"total_train_time_s\": 15.228093385696411}", "{\"n\": 9607, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.91, \"learn_time_ms\": 10771.329, \"total_train_time_s\": 13.94574785232544}", "{\"n\": 9608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.84, \"learn_time_ms\": 10664.904, \"total_train_time_s\": 14.03338623046875}", "{\"n\": 9609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.73, \"learn_time_ms\": 10762.716, \"total_train_time_s\": 15.504436016082764}", "{\"n\": 9610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.27, \"learn_time_ms\": 10729.747, \"total_train_time_s\": 14.000857591629028}", "{\"n\": 9611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.27, \"learn_time_ms\": 10843.057, \"total_train_time_s\": 15.208585023880005}", "{\"n\": 9612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.46, \"learn_time_ms\": 10900.6, \"total_train_time_s\": 14.77385401725769}", "{\"n\": 9613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.03, \"learn_time_ms\": 10762.417, \"total_train_time_s\": 13.295359134674072}", "{\"n\": 9614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.9, \"learn_time_ms\": 10681.134, \"total_train_time_s\": 13.536340475082397}", "{\"n\": 9615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.9, \"learn_time_ms\": 10660.165, \"total_train_time_s\": 14.109481811523438}", "{\"n\": 9616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.35, \"learn_time_ms\": 10429.951, \"total_train_time_s\": 13.079856157302856}", "{\"n\": 9617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.35, \"learn_time_ms\": 10566.282, \"total_train_time_s\": 15.33374309539795}", "{\"n\": 9618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.58, \"learn_time_ms\": 10642.399, \"total_train_time_s\": 14.466399908065796}", "{\"n\": 9619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.26, \"learn_time_ms\": 10522.857, \"total_train_time_s\": 14.538675546646118}", "{\"n\": 9620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.76, \"learn_time_ms\": 10636.878, \"total_train_time_s\": 15.249309778213501}", "{\"n\": 9621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.76, \"learn_time_ms\": 10641.05, \"total_train_time_s\": 15.438904523849487}", "{\"n\": 9622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.62, \"learn_time_ms\": 10587.017, \"total_train_time_s\": 14.202839851379395}", "{\"n\": 9623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.26, \"learn_time_ms\": 10743.868, \"total_train_time_s\": 15.152394771575928}", "{\"n\": 9624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.81, \"learn_time_ms\": 10786.759, \"total_train_time_s\": 14.2019624710083}", "{\"n\": 9625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.81, \"learn_time_ms\": 10796.111, \"total_train_time_s\": 14.494783639907837}", "{\"n\": 9626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.25, \"learn_time_ms\": 10933.705, \"total_train_time_s\": 14.211474418640137}", "{\"n\": 9627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.54, \"learn_time_ms\": 10811.602, \"total_train_time_s\": 13.979649066925049}", "{\"n\": 9628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.54, \"learn_time_ms\": 10821.137, \"total_train_time_s\": 14.63888692855835}", "{\"n\": 9629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.61, \"learn_time_ms\": 10844.109, \"total_train_time_s\": 14.693163394927979}", "{\"n\": 9630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.23, \"learn_time_ms\": 10735.061, \"total_train_time_s\": 14.072195529937744}", "{\"n\": 9631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.63, \"learn_time_ms\": 10681.458, \"total_train_time_s\": 14.87917709350586}", "{\"n\": 9632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.63, \"learn_time_ms\": 10736.551, \"total_train_time_s\": 14.824806690216064}", "{\"n\": 9633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.64, \"learn_time_ms\": 10783.296, \"total_train_time_s\": 15.317467451095581}", "{\"n\": 9634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10947.724, \"total_train_time_s\": 15.985372304916382}", "{\"n\": 9635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10913.35, \"total_train_time_s\": 13.995348453521729}", "{\"n\": 9636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.23, \"learn_time_ms\": 10889.25, \"total_train_time_s\": 14.006232023239136}", "{\"n\": 9637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 10931.505, \"total_train_time_s\": 14.40818977355957}", "{\"n\": 9638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 10938.699, \"total_train_time_s\": 14.693726778030396}", "{\"n\": 9639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 10970.534, \"total_train_time_s\": 15.12974739074707}", "{\"n\": 9640, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.92, \"learn_time_ms\": 11055.048, \"total_train_time_s\": 15.084148645401001}", "{\"n\": 9641, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.92, \"learn_time_ms\": 10966.527, \"total_train_time_s\": 14.285963535308838}", "{\"n\": 9642, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.92, \"learn_time_ms\": 10948.498, \"total_train_time_s\": 14.3768150806427}", "{\"n\": 9643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.16, \"learn_time_ms\": 10820.157, \"total_train_time_s\": 14.010130167007446}", "{\"n\": 9644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.64, \"learn_time_ms\": 10695.591, \"total_train_time_s\": 14.659667730331421}", "{\"n\": 9645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.64, \"learn_time_ms\": 10735.614, \"total_train_time_s\": 14.343993902206421}", "{\"n\": 9646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.64, \"learn_time_ms\": 10747.089, \"total_train_time_s\": 14.133725881576538}", "{\"n\": 9647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.21, \"learn_time_ms\": 10760.825, \"total_train_time_s\": 14.86316728591919}", "{\"n\": 9648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.41, \"learn_time_ms\": 10714.634, \"total_train_time_s\": 14.16299033164978}", "{\"n\": 9649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.41, \"learn_time_ms\": 10612.698, \"total_train_time_s\": 13.778587579727173}", "{\"n\": 9650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.71, \"learn_time_ms\": 10490.562, \"total_train_time_s\": 13.951360702514648}", "{\"n\": 9651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.13, \"learn_time_ms\": 10459.457, \"total_train_time_s\": 13.618638753890991}", "{\"n\": 9652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.88, \"learn_time_ms\": 10435.213, \"total_train_time_s\": 14.003103017807007}", "{\"n\": 9653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.88, \"learn_time_ms\": 10459.721, \"total_train_time_s\": 14.393118619918823}", "{\"n\": 9654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.98, \"learn_time_ms\": 10362.023, \"total_train_time_s\": 13.474502563476562}", "{\"n\": 9655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.71, \"learn_time_ms\": 10387.86, \"total_train_time_s\": 14.912084102630615}", "{\"n\": 9656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.71, \"learn_time_ms\": 10463.088, \"total_train_time_s\": 15.116806745529175}", "{\"n\": 9657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 10496.896, \"total_train_time_s\": 15.09929609298706}", "{\"n\": 9658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 10554.075, \"total_train_time_s\": 15.193793058395386}", "{\"n\": 9659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.42, \"learn_time_ms\": 10532.828, \"total_train_time_s\": 13.976598978042603}", "{\"n\": 9660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.38, \"learn_time_ms\": 10662.36, \"total_train_time_s\": 15.10100507736206}", "{\"n\": 9661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.03, \"learn_time_ms\": 10757.651, \"total_train_time_s\": 14.63254976272583}", "{\"n\": 9662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 10733.926, \"total_train_time_s\": 14.135162591934204}", "{\"n\": 9663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.35, \"learn_time_ms\": 10677.307, \"total_train_time_s\": 13.766220569610596}", "{\"n\": 9664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.24, \"learn_time_ms\": 10714.452, \"total_train_time_s\": 13.913956642150879}", "{\"n\": 9665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.97, \"learn_time_ms\": 10727.116, \"total_train_time_s\": 14.707491636276245}", "{\"n\": 9666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.23, \"learn_time_ms\": 10759.273, \"total_train_time_s\": 15.139257669448853}", "{\"n\": 9667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.82, \"learn_time_ms\": 10718.722, \"total_train_time_s\": 14.649288892745972}", "{\"n\": 9668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.75, \"learn_time_ms\": 10584.201, \"total_train_time_s\": 13.827728509902954}", "{\"n\": 9669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.75, \"learn_time_ms\": 10618.01, \"total_train_time_s\": 14.060787916183472}", "{\"n\": 9670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.91, \"learn_time_ms\": 10450.056, \"total_train_time_s\": 13.247321128845215}", "{\"n\": 9671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10350.513, \"total_train_time_s\": 13.56487250328064}", "{\"n\": 9672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10395.948, \"total_train_time_s\": 14.19305682182312}", "{\"n\": 9673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10377.067, \"total_train_time_s\": 13.73595404624939}", "{\"n\": 9674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.59, \"learn_time_ms\": 10478.169, \"total_train_time_s\": 14.953088998794556}", "{\"n\": 9675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 10346.74, \"total_train_time_s\": 13.400595664978027}", "{\"n\": 9676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 10284.926, \"total_train_time_s\": 14.55335783958435}", "{\"n\": 9677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.62, \"learn_time_ms\": 10357.623, \"total_train_time_s\": 15.620473384857178}", "{\"n\": 9678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.8, \"learn_time_ms\": 10476.32, \"total_train_time_s\": 14.711964130401611}", "{\"n\": 9679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 10562.727, \"total_train_time_s\": 14.828219890594482}", "{\"n\": 9680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 10769.465, \"total_train_time_s\": 15.294508934020996}", "{\"n\": 9681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.87, \"learn_time_ms\": 10946.95, \"total_train_time_s\": 15.443735361099243}", "{\"n\": 9682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.97, \"learn_time_ms\": 10966.636, \"total_train_time_s\": 14.454704999923706}", "{\"n\": 9683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.97, \"learn_time_ms\": 10997.918, \"total_train_time_s\": 14.072520017623901}", "{\"n\": 9684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3586.0, \"learn_time_ms\": 10864.243, \"total_train_time_s\": 13.757993459701538}", "{\"n\": 9685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.79, \"learn_time_ms\": 10872.17, \"total_train_time_s\": 13.464659929275513}", "{\"n\": 9686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.06, \"learn_time_ms\": 10764.251, \"total_train_time_s\": 13.487760543823242}", "{\"n\": 9687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.08, \"learn_time_ms\": 10699.474, \"total_train_time_s\": 14.830478191375732}", "{\"n\": 9688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.42, \"learn_time_ms\": 10726.972, \"total_train_time_s\": 15.059707641601562}", "{\"n\": 9689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.42, \"learn_time_ms\": 10625.999, \"total_train_time_s\": 14.099398851394653}", "{\"n\": 9690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.31, \"learn_time_ms\": 10407.542, \"total_train_time_s\": 13.482395648956299}", "{\"n\": 9691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.56, \"learn_time_ms\": 10238.766, \"total_train_time_s\": 13.565324068069458}", "{\"n\": 9692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.59, \"learn_time_ms\": 10228.845, \"total_train_time_s\": 14.677401065826416}", "{\"n\": 9693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.99, \"learn_time_ms\": 10317.695, \"total_train_time_s\": 14.7649085521698}", "{\"n\": 9694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3564.99, \"learn_time_ms\": 10353.41, \"total_train_time_s\": 14.054608583450317}", "{\"n\": 9695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.34, \"learn_time_ms\": 10516.311, \"total_train_time_s\": 15.388526916503906}", "{\"n\": 9696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.33, \"learn_time_ms\": 10599.39, \"total_train_time_s\": 14.230095148086548}", "{\"n\": 9697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.6, \"learn_time_ms\": 10563.273, \"total_train_time_s\": 14.339902639389038}", "{\"n\": 9698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.6, \"learn_time_ms\": 10451.637, \"total_train_time_s\": 14.141408920288086}", "{\"n\": 9699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.62, \"learn_time_ms\": 10538.186, \"total_train_time_s\": 14.89732575416565}", "{\"n\": 9700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.62, \"learn_time_ms\": 10618.223, \"total_train_time_s\": 13.97148871421814}", "{\"n\": 9701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.48, \"learn_time_ms\": 10823.868, \"total_train_time_s\": 15.856586694717407}", "{\"n\": 9702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.48, \"learn_time_ms\": 10800.306, \"total_train_time_s\": 14.051583528518677}", "{\"n\": 9703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.72, \"learn_time_ms\": 10826.993, \"total_train_time_s\": 15.079168558120728}", "{\"n\": 9704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.72, \"learn_time_ms\": 10902.404, \"total_train_time_s\": 14.836498260498047}", "{\"n\": 9705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.32, \"learn_time_ms\": 10887.613, \"total_train_time_s\": 15.261828422546387}", "{\"n\": 9706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.08, \"learn_time_ms\": 10903.801, \"total_train_time_s\": 14.719517707824707}", "{\"n\": 9707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.08, \"learn_time_ms\": 10877.858, \"total_train_time_s\": 14.10432744026184}", "{\"n\": 9708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.08, \"learn_time_ms\": 10895.551, \"total_train_time_s\": 14.042486906051636}", "{\"n\": 9709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.45, \"learn_time_ms\": 10931.225, \"total_train_time_s\": 15.022363185882568}", "{\"n\": 9710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.09, \"learn_time_ms\": 11129.335, \"total_train_time_s\": 16.04446005821228}", "{\"n\": 9711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.09, \"learn_time_ms\": 10941.32, \"total_train_time_s\": 13.889678955078125}", "{\"n\": 9712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.09, \"learn_time_ms\": 11023.182, \"total_train_time_s\": 15.260329246520996}", "{\"n\": 9713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.91, \"learn_time_ms\": 11144.649, \"total_train_time_s\": 16.49988341331482}", "{\"n\": 9714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.59, \"learn_time_ms\": 11051.471, \"total_train_time_s\": 13.633316993713379}", "{\"n\": 9715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3559.59, \"learn_time_ms\": 10933.271, \"total_train_time_s\": 14.03363561630249}", "{\"n\": 9716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.58, \"learn_time_ms\": 10984.789, \"total_train_time_s\": 14.875992059707642}", "{\"n\": 9717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.12, \"learn_time_ms\": 10912.498, \"total_train_time_s\": 13.205734491348267}", "{\"n\": 9718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.43, \"learn_time_ms\": 11083.894, \"total_train_time_s\": 15.727719068527222}", "{\"n\": 9719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.39, \"learn_time_ms\": 10972.24, \"total_train_time_s\": 14.187124967575073}", "{\"n\": 9720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.18, \"learn_time_ms\": 10796.628, \"total_train_time_s\": 14.206857919692993}", "{\"n\": 9721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.18, \"learn_time_ms\": 10738.218, \"total_train_time_s\": 13.259523153305054}", "{\"n\": 9722, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.93, \"learn_time_ms\": 10689.57, \"total_train_time_s\": 14.673914432525635}", "{\"n\": 9723, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.83, \"learn_time_ms\": 10494.426, \"total_train_time_s\": 14.515546798706055}", "{\"n\": 9724, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.82, \"learn_time_ms\": 10554.403, \"total_train_time_s\": 14.248759984970093}", "{\"n\": 9725, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.82, \"learn_time_ms\": 10742.324, \"total_train_time_s\": 15.839116096496582}", "{\"n\": 9726, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.58, \"learn_time_ms\": 10746.336, \"total_train_time_s\": 14.945186376571655}", "{\"n\": 9727, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.54, \"learn_time_ms\": 10718.692, \"total_train_time_s\": 13.177583932876587}", "{\"n\": 9728, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.68, \"learn_time_ms\": 10574.087, \"total_train_time_s\": 14.317111730575562}", "{\"n\": 9729, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.87, \"learn_time_ms\": 10562.112, \"total_train_time_s\": 14.0872642993927}", "{\"n\": 9730, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.98, \"learn_time_ms\": 10540.113, \"total_train_time_s\": 14.432796716690063}", "{\"n\": 9731, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.92, \"learn_time_ms\": 10517.206, \"total_train_time_s\": 12.968661069869995}", "{\"n\": 9732, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.92, \"learn_time_ms\": 10480.454, \"total_train_time_s\": 14.183653116226196}", "{\"n\": 9733, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.19, \"learn_time_ms\": 10393.693, \"total_train_time_s\": 13.755490779876709}", "{\"n\": 9734, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.48, \"learn_time_ms\": 10334.632, \"total_train_time_s\": 13.726061582565308}", "{\"n\": 9735, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.48, \"learn_time_ms\": 10191.471, \"total_train_time_s\": 14.191547393798828}", "{\"n\": 9736, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 10075.305, \"total_train_time_s\": 13.983747005462646}", "{\"n\": 9737, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 10250.999, \"total_train_time_s\": 14.927586793899536}", "{\"n\": 9738, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 10142.836, \"total_train_time_s\": 13.360872507095337}", "{\"n\": 9739, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.24, \"learn_time_ms\": 10277.5, \"total_train_time_s\": 15.126301765441895}", "{\"n\": 9740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.08, \"learn_time_ms\": 10271.232, \"total_train_time_s\": 14.032946348190308}", "{\"n\": 9741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.08, \"learn_time_ms\": 10463.39, \"total_train_time_s\": 14.887863159179688}", "{\"n\": 9742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.08, \"learn_time_ms\": 10553.675, \"total_train_time_s\": 15.32700777053833}", "{\"n\": 9743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10620.247, \"total_train_time_s\": 14.204128503799438}", "{\"n\": 9744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10654.347, \"total_train_time_s\": 14.274011850357056}", "{\"n\": 9745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10691.132, \"total_train_time_s\": 14.764305591583252}", "{\"n\": 9746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.17, \"learn_time_ms\": 10731.537, \"total_train_time_s\": 14.451160669326782}", "{\"n\": 9747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.64, \"learn_time_ms\": 10713.957, \"total_train_time_s\": 14.584486246109009}", "{\"n\": 9748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.64, \"learn_time_ms\": 10821.617, \"total_train_time_s\": 14.282043218612671}", "{\"n\": 9749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.64, \"learn_time_ms\": 10642.0, \"total_train_time_s\": 13.525115251541138}", "{\"n\": 9750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.64, \"learn_time_ms\": 10684.435, \"total_train_time_s\": 14.44559121131897}", "{\"n\": 9751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.94, \"learn_time_ms\": 10653.478, \"total_train_time_s\": 14.619261264801025}", "{\"n\": 9752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.94, \"learn_time_ms\": 10656.847, \"total_train_time_s\": 15.327993869781494}", "{\"n\": 9753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.94, \"learn_time_ms\": 10590.606, \"total_train_time_s\": 13.628368139266968}", "{\"n\": 9754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.39, \"learn_time_ms\": 10693.576, \"total_train_time_s\": 15.271904468536377}", "{\"n\": 9755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.88, \"learn_time_ms\": 10614.441, \"total_train_time_s\": 14.003312110900879}", "{\"n\": 9756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.88, \"learn_time_ms\": 10695.626, \"total_train_time_s\": 15.367924451828003}", "{\"n\": 9757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.88, \"learn_time_ms\": 10619.017, \"total_train_time_s\": 13.793339729309082}", "{\"n\": 9758, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.62, \"learn_time_ms\": 10613.471, \"total_train_time_s\": 14.435758829116821}", "{\"n\": 9759, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 10642.604, \"total_train_time_s\": 13.793781757354736}", "{\"n\": 9760, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 10693.512, \"total_train_time_s\": 15.157573699951172}", "{\"n\": 9761, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 10660.835, \"total_train_time_s\": 14.589980363845825}", "{\"n\": 9762, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.44, \"learn_time_ms\": 10424.158, \"total_train_time_s\": 12.734249591827393}", "{\"n\": 9763, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.49, \"learn_time_ms\": 10500.18, \"total_train_time_s\": 14.456868171691895}", "{\"n\": 9764, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.49, \"learn_time_ms\": 10372.298, \"total_train_time_s\": 14.092179536819458}", "{\"n\": 9765, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.49, \"learn_time_ms\": 10485.596, \"total_train_time_s\": 14.980897903442383}", "{\"n\": 9766, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.33, \"learn_time_ms\": 10511.118, \"total_train_time_s\": 15.402700185775757}", "{\"n\": 9767, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.33, \"learn_time_ms\": 10443.507, \"total_train_time_s\": 13.308102369308472}", "{\"n\": 9768, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.33, \"learn_time_ms\": 10475.312, \"total_train_time_s\": 14.638894319534302}", "{\"n\": 9769, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.43, \"learn_time_ms\": 10440.593, \"total_train_time_s\": 13.626430034637451}", "{\"n\": 9770, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.86, \"learn_time_ms\": 10364.559, \"total_train_time_s\": 14.260224342346191}", "{\"n\": 9771, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.29, \"learn_time_ms\": 10389.74, \"total_train_time_s\": 14.47497034072876}", "{\"n\": 9772, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.29, \"learn_time_ms\": 10576.171, \"total_train_time_s\": 14.49130892753601}", "{\"n\": 9773, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.61, \"learn_time_ms\": 10561.905, \"total_train_time_s\": 14.216208219528198}", "{\"n\": 9774, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.53, \"learn_time_ms\": 10620.537, \"total_train_time_s\": 14.511861562728882}", "{\"n\": 9775, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.53, \"learn_time_ms\": 10536.284, \"total_train_time_s\": 14.112149715423584}", "{\"n\": 9776, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.17, \"learn_time_ms\": 10400.79, \"total_train_time_s\": 14.076610803604126}", "{\"n\": 9777, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.01, \"learn_time_ms\": 10515.741, \"total_train_time_s\": 14.351145029067993}", "{\"n\": 9778, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.25, \"learn_time_ms\": 10504.301, \"total_train_time_s\": 14.61233901977539}", "{\"n\": 9779, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.01, \"learn_time_ms\": 10501.405, \"total_train_time_s\": 13.676459074020386}", "{\"n\": 9780, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.01, \"learn_time_ms\": 10542.329, \"total_train_time_s\": 14.85194182395935}", "{\"n\": 9781, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.82, \"learn_time_ms\": 10423.957, \"total_train_time_s\": 13.278130292892456}", "{\"n\": 9782, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.09, \"learn_time_ms\": 10450.214, \"total_train_time_s\": 14.820654153823853}", "{\"n\": 9783, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.09, \"learn_time_ms\": 10400.293, \"total_train_time_s\": 13.823476552963257}", "{\"n\": 9784, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.14, \"learn_time_ms\": 10361.767, \"total_train_time_s\": 14.013640880584717}", "{\"n\": 9785, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.32, \"learn_time_ms\": 10409.567, \"total_train_time_s\": 14.82874846458435}", "{\"n\": 9786, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.84, \"learn_time_ms\": 10443.061, \"total_train_time_s\": 14.41257619857788}", "{\"n\": 9787, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.84, \"learn_time_ms\": 10468.399, \"total_train_time_s\": 14.636846780776978}", "{\"n\": 9788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.25, \"learn_time_ms\": 10462.711, \"total_train_time_s\": 14.347473621368408}", "{\"n\": 9789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.98, \"learn_time_ms\": 10575.132, \"total_train_time_s\": 14.845828533172607}", "{\"n\": 9790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.39, \"learn_time_ms\": 10550.335, \"total_train_time_s\": 14.470494031906128}", "{\"n\": 9791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.84, \"learn_time_ms\": 10551.984, \"total_train_time_s\": 13.39022183418274}", "{\"n\": 9792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.17, \"learn_time_ms\": 10607.962, \"total_train_time_s\": 15.73786187171936}", "{\"n\": 9793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.17, \"learn_time_ms\": 10680.299, \"total_train_time_s\": 14.490400314331055}", "{\"n\": 9794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.14, \"learn_time_ms\": 10735.456, \"total_train_time_s\": 14.580200433731079}", "{\"n\": 9795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.94, \"learn_time_ms\": 10738.47, \"total_train_time_s\": 14.912405967712402}", "{\"n\": 9796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.53, \"learn_time_ms\": 10697.627, \"total_train_time_s\": 13.996683359146118}", "{\"n\": 9797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.62, \"learn_time_ms\": 10721.836, \"total_train_time_s\": 14.89109468460083}", "{\"n\": 9798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.8, \"learn_time_ms\": 10773.0, \"total_train_time_s\": 14.885602235794067}", "{\"n\": 9799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.1, \"learn_time_ms\": 10739.556, \"total_train_time_s\": 14.183353662490845}", "{\"n\": 9800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.94, \"learn_time_ms\": 10796.248, \"total_train_time_s\": 14.810494184494019}", "{\"n\": 9801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.96, \"learn_time_ms\": 10926.714, \"total_train_time_s\": 14.632946252822876}", "{\"n\": 9802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.77, \"learn_time_ms\": 10827.674, \"total_train_time_s\": 14.371127128601074}", "{\"n\": 9803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.89, \"learn_time_ms\": 10826.774, \"total_train_time_s\": 14.257545709609985}", "{\"n\": 9804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.53, \"learn_time_ms\": 10938.052, \"total_train_time_s\": 15.68305516242981}", "{\"n\": 9805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.98, \"learn_time_ms\": 10938.045, \"total_train_time_s\": 14.863451480865479}", "{\"n\": 9806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.98, \"learn_time_ms\": 10948.241, \"total_train_time_s\": 14.372358560562134}", "{\"n\": 9807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.11, \"learn_time_ms\": 10836.754, \"total_train_time_s\": 13.682723760604858}", "{\"n\": 9808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.85, \"learn_time_ms\": 10779.914, \"total_train_time_s\": 14.260111093521118}", "{\"n\": 9809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.22, \"learn_time_ms\": 10859.769, \"total_train_time_s\": 15.224054098129272}", "{\"n\": 9810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.61, \"learn_time_ms\": 10832.424, \"total_train_time_s\": 14.584541320800781}", "{\"n\": 9811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 10822.51, \"total_train_time_s\": 14.696682929992676}", "{\"n\": 9812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.77, \"learn_time_ms\": 10783.077, \"total_train_time_s\": 14.155799865722656}", "{\"n\": 9813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.7, \"learn_time_ms\": 10739.142, \"total_train_time_s\": 13.903316497802734}", "{\"n\": 9814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.61, \"learn_time_ms\": 10465.296, \"total_train_time_s\": 12.956607103347778}", "{\"n\": 9815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.99, \"learn_time_ms\": 10432.639, \"total_train_time_s\": 14.51019811630249}", "{\"n\": 9816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 10560.364, \"total_train_time_s\": 15.212778806686401}", "{\"n\": 9817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 10679.494, \"total_train_time_s\": 15.058337926864624}", "{\"n\": 9818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.23, \"learn_time_ms\": 10643.796, \"total_train_time_s\": 14.064484357833862}", "{\"n\": 9819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.59, \"learn_time_ms\": 10610.334, \"total_train_time_s\": 14.544731378555298}", "{\"n\": 9820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.15, \"learn_time_ms\": 10489.019, \"total_train_time_s\": 13.541905403137207}", "{\"n\": 9821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.0, \"learn_time_ms\": 10500.316, \"total_train_time_s\": 14.842452764511108}", "{\"n\": 9822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.13, \"learn_time_ms\": 10588.379, \"total_train_time_s\": 15.021971702575684}", "{\"n\": 9823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.2, \"learn_time_ms\": 10548.609, \"total_train_time_s\": 13.538572788238525}", "{\"n\": 9824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.2, \"learn_time_ms\": 10587.334, \"total_train_time_s\": 13.430777788162231}", "{\"n\": 9825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.21, \"learn_time_ms\": 10544.483, \"total_train_time_s\": 13.817103862762451}", "{\"n\": 9826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.21, \"learn_time_ms\": 10410.286, \"total_train_time_s\": 13.91126561164856}", "{\"n\": 9827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.3, \"learn_time_ms\": 10365.91, \"total_train_time_s\": 14.342564582824707}", "{\"n\": 9828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.3, \"learn_time_ms\": 10428.395, \"total_train_time_s\": 14.57742953300476}", "{\"n\": 9829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.1, \"learn_time_ms\": 10379.037, \"total_train_time_s\": 14.166819334030151}", "{\"n\": 9830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.1, \"learn_time_ms\": 10423.618, \"total_train_time_s\": 13.737305164337158}", "{\"n\": 9831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.23, \"learn_time_ms\": 10328.355, \"total_train_time_s\": 13.699633598327637}", "{\"n\": 9832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.13, \"learn_time_ms\": 10229.337, \"total_train_time_s\": 14.192978382110596}", "{\"n\": 9833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.13, \"learn_time_ms\": 10356.371, \"total_train_time_s\": 14.839058876037598}", "{\"n\": 9834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.41, \"learn_time_ms\": 10488.368, \"total_train_time_s\": 15.01629114151001}", "{\"n\": 9835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.41, \"learn_time_ms\": 10702.64, \"total_train_time_s\": 15.932491540908813}", "{\"n\": 9836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.76, \"learn_time_ms\": 10778.84, \"total_train_time_s\": 14.720438241958618}", "{\"n\": 9837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.01, \"learn_time_ms\": 10806.936, \"total_train_time_s\": 14.772843837738037}", "{\"n\": 9838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.01, \"learn_time_ms\": 10724.492, \"total_train_time_s\": 14.019187688827515}", "{\"n\": 9839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.12, \"learn_time_ms\": 10813.969, \"total_train_time_s\": 14.883710384368896}", "{\"n\": 9840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.12, \"learn_time_ms\": 10806.654, \"total_train_time_s\": 13.779026508331299}", "{\"n\": 9841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 11021.102, \"total_train_time_s\": 15.906413078308105}", "{\"n\": 9842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 11098.612, \"total_train_time_s\": 14.962612390518188}", "{\"n\": 9843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.34, \"learn_time_ms\": 11223.354, \"total_train_time_s\": 15.944684267044067}", "{\"n\": 9844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.19, \"learn_time_ms\": 11043.457, \"total_train_time_s\": 12.819647312164307}", "{\"n\": 9845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.57, \"learn_time_ms\": 10757.805, \"total_train_time_s\": 13.188997030258179}", "{\"n\": 9846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.57, \"learn_time_ms\": 10897.873, \"total_train_time_s\": 16.265714645385742}", "{\"n\": 9847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.34, \"learn_time_ms\": 10884.379, \"total_train_time_s\": 14.846858978271484}", "{\"n\": 9848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10831.055, \"total_train_time_s\": 13.104528188705444}", "{\"n\": 9849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10807.984, \"total_train_time_s\": 14.753628969192505}", "{\"n\": 9850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10945.154, \"total_train_time_s\": 15.092883586883545}", "{\"n\": 9851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.97, \"learn_time_ms\": 10853.263, \"total_train_time_s\": 14.944230794906616}", "{\"n\": 9852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.97, \"learn_time_ms\": 10743.955, \"total_train_time_s\": 13.714770555496216}", "{\"n\": 9853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.97, \"learn_time_ms\": 10488.633, \"total_train_time_s\": 13.347642660140991}", "{\"n\": 9854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 10715.477, \"total_train_time_s\": 15.092062950134277}", "{\"n\": 9855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.0, \"learn_time_ms\": 10760.809, \"total_train_time_s\": 13.799188137054443}", "{\"n\": 9856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.45, \"learn_time_ms\": 10505.797, \"total_train_time_s\": 13.854307174682617}", "{\"n\": 9857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3609.9, \"learn_time_ms\": 10599.828, \"total_train_time_s\": 15.815135478973389}", "{\"n\": 9858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10712.258, \"total_train_time_s\": 14.63353943824768}", "{\"n\": 9859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.77, \"learn_time_ms\": 10752.581, \"total_train_time_s\": 15.409054517745972}", "{\"n\": 9860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.77, \"learn_time_ms\": 10680.498, \"total_train_time_s\": 14.491651058197021}", "{\"n\": 9861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.29, \"learn_time_ms\": 10235.275, \"total_train_time_s\": 10.6437828540802}", "{\"n\": 9862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3599.22, \"learn_time_ms\": 10084.023, \"total_train_time_s\": 12.328272104263306}", "{\"n\": 9863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.92, \"learn_time_ms\": 10215.775, \"total_train_time_s\": 14.736839532852173}", "{\"n\": 9864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.92, \"learn_time_ms\": 10225.031, \"total_train_time_s\": 15.303264379501343}", "{\"n\": 9865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.52, \"learn_time_ms\": 10304.525, \"total_train_time_s\": 14.505723714828491}", "{\"n\": 9866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3594.53, \"learn_time_ms\": 10396.909, \"total_train_time_s\": 14.44901990890503}", "{\"n\": 9867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10289.021, \"total_train_time_s\": 14.41341257095337}", "{\"n\": 9868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10341.577, \"total_train_time_s\": 14.868618965148926}", "{\"n\": 9869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.37, \"learn_time_ms\": 10374.516, \"total_train_time_s\": 15.661961793899536}", "{\"n\": 9870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.24, \"learn_time_ms\": 10384.695, \"total_train_time_s\": 14.774638652801514}", "{\"n\": 9871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.76, \"learn_time_ms\": 10792.824, \"total_train_time_s\": 14.62232494354248}", "{\"n\": 9872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.18, \"learn_time_ms\": 11000.957, \"total_train_time_s\": 14.233100414276123}", "{\"n\": 9873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.0, \"learn_time_ms\": 10922.628, \"total_train_time_s\": 13.881654262542725}", "{\"n\": 9874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.01, \"learn_time_ms\": 10775.903, \"total_train_time_s\": 14.094775676727295}", "{\"n\": 9875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.01, \"learn_time_ms\": 10860.644, \"total_train_time_s\": 15.359358549118042}", "{\"n\": 9876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.95, \"learn_time_ms\": 10869.832, \"total_train_time_s\": 14.714029788970947}", "{\"n\": 9877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.95, \"learn_time_ms\": 10878.113, \"total_train_time_s\": 14.442156553268433}", "{\"n\": 9878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.17, \"learn_time_ms\": 10679.045, \"total_train_time_s\": 13.079972982406616}", "{\"n\": 9879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.6, \"learn_time_ms\": 10595.316, \"total_train_time_s\": 14.591161966323853}", "{\"n\": 9880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.31, \"learn_time_ms\": 10551.575, \"total_train_time_s\": 14.204294919967651}", "{\"n\": 9881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.21, \"learn_time_ms\": 10510.775, \"total_train_time_s\": 14.237573623657227}", "{\"n\": 9882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.3, \"learn_time_ms\": 10633.667, \"total_train_time_s\": 15.375367403030396}", "{\"n\": 9883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.8, \"learn_time_ms\": 10651.204, \"total_train_time_s\": 14.296995639801025}", "{\"n\": 9884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.53, \"learn_time_ms\": 10651.991, \"total_train_time_s\": 14.20116662979126}", "{\"n\": 9885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.53, \"learn_time_ms\": 10664.182, \"total_train_time_s\": 15.308557033538818}", "{\"n\": 9886, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.45, \"learn_time_ms\": 10661.093, \"total_train_time_s\": 14.651079416275024}", "{\"n\": 9887, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.91, \"learn_time_ms\": 10691.608, \"total_train_time_s\": 14.880935907363892}", "{\"n\": 9888, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.91, \"learn_time_ms\": 10785.687, \"total_train_time_s\": 13.864965677261353}", "{\"n\": 9889, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.91, \"learn_time_ms\": 10754.558, \"total_train_time_s\": 14.632577180862427}", "{\"n\": 9890, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.42, \"learn_time_ms\": 10738.811, \"total_train_time_s\": 13.946873188018799}", "{\"n\": 9891, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.89, \"learn_time_ms\": 10787.285, \"total_train_time_s\": 14.646972179412842}", "{\"n\": 9892, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.89, \"learn_time_ms\": 10711.732, \"total_train_time_s\": 14.656880617141724}", "{\"n\": 9893, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.89, \"learn_time_ms\": 10707.227, \"total_train_time_s\": 14.324495077133179}", "{\"n\": 9894, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3620.98, \"learn_time_ms\": 10733.744, \"total_train_time_s\": 14.211092233657837}", "{\"n\": 9895, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 10654.25, \"total_train_time_s\": 14.691423416137695}", "{\"n\": 9896, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 10512.423, \"total_train_time_s\": 12.992006301879883}", "{\"n\": 9897, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 10502.445, \"total_train_time_s\": 15.031396865844727}", "{\"n\": 9898, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10716.984, \"total_train_time_s\": 15.98649287223816}", "{\"n\": 9899, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10695.474, \"total_train_time_s\": 14.352320909500122}", "{\"n\": 9900, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10730.269, \"total_train_time_s\": 14.48514437675476}", "{\"n\": 9901, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10614.597, \"total_train_time_s\": 13.529350280761719}", "{\"n\": 9902, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.16, \"learn_time_ms\": 10554.188, \"total_train_time_s\": 14.040096282958984}", "{\"n\": 9903, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.16, \"learn_time_ms\": 10689.369, \"total_train_time_s\": 15.906911849975586}", "{\"n\": 9904, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.16, \"learn_time_ms\": 10721.85, \"total_train_time_s\": 14.432758092880249}", "{\"n\": 9905, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.29, \"learn_time_ms\": 10722.546, \"total_train_time_s\": 14.82440733909607}", "{\"n\": 9906, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3648.97, \"learn_time_ms\": 10807.808, \"total_train_time_s\": 13.995573282241821}", "{\"n\": 9907, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3648.97, \"learn_time_ms\": 10756.093, \"total_train_time_s\": 14.16213059425354}", "{\"n\": 9908, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3648.97, \"learn_time_ms\": 10614.566, \"total_train_time_s\": 14.582845449447632}", "{\"n\": 9909, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.24, \"learn_time_ms\": 10707.778, \"total_train_time_s\": 15.231025457382202}", "{\"n\": 9910, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.17, \"learn_time_ms\": 10569.328, \"total_train_time_s\": 12.843090295791626}", "{\"n\": 9911, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.17, \"learn_time_ms\": 10747.25, \"total_train_time_s\": 15.304429769515991}", "{\"n\": 9912, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.36, \"learn_time_ms\": 10766.785, \"total_train_time_s\": 14.242341756820679}", "{\"n\": 9913, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.38, \"learn_time_ms\": 10588.192, \"total_train_time_s\": 13.679369688034058}", "{\"n\": 9914, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.38, \"learn_time_ms\": 10475.918, \"total_train_time_s\": 13.316929340362549}", "{\"n\": 9915, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.38, \"learn_time_ms\": 10442.373, \"total_train_time_s\": 14.462630033493042}", "{\"n\": 9916, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.3, \"learn_time_ms\": 10455.261, \"total_train_time_s\": 14.023197889328003}", "{\"n\": 9917, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.3, \"learn_time_ms\": 10432.89, \"total_train_time_s\": 14.087515592575073}", "{\"n\": 9918, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.3, \"learn_time_ms\": 10413.277, \"total_train_time_s\": 14.547053813934326}", "{\"n\": 9919, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.24, \"learn_time_ms\": 10351.939, \"total_train_time_s\": 14.588852167129517}", "{\"n\": 9920, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.77, \"learn_time_ms\": 10524.523, \"total_train_time_s\": 14.67063045501709}", "{\"n\": 9921, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.77, \"learn_time_ms\": 10515.171, \"total_train_time_s\": 15.295520782470703}", "{\"n\": 9922, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.77, \"learn_time_ms\": 10581.263, \"total_train_time_s\": 15.068628311157227}", "{\"n\": 9923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.92, \"learn_time_ms\": 10764.384, \"total_train_time_s\": 15.454944372177124}", "{\"n\": 9924, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.92, \"learn_time_ms\": 10933.903, \"total_train_time_s\": 14.871473789215088}", "{\"n\": 9925, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.92, \"learn_time_ms\": 10967.852, \"total_train_time_s\": 14.49844765663147}", "{\"n\": 9926, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.92, \"learn_time_ms\": 11015.926, \"total_train_time_s\": 14.473193407058716}", "{\"n\": 9927, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.86, \"learn_time_ms\": 11096.119, \"total_train_time_s\": 14.774344444274902}", "{\"n\": 9928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.86, \"learn_time_ms\": 11218.004, \"total_train_time_s\": 15.678134679794312}", "{\"n\": 9929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.86, \"learn_time_ms\": 11242.25, \"total_train_time_s\": 15.04960823059082}", "{\"n\": 9930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.4, \"learn_time_ms\": 11302.157, \"total_train_time_s\": 15.571201801300049}", "{\"n\": 9931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 11235.475, \"total_train_time_s\": 14.586606502532959}", "{\"n\": 9932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 11190.019, \"total_train_time_s\": 14.569428443908691}", "{\"n\": 9933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 11015.473, \"total_train_time_s\": 13.952813386917114}", "{\"n\": 9934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.18, \"learn_time_ms\": 10954.445, \"total_train_time_s\": 14.40981912612915}", "{\"n\": 9935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.22, \"learn_time_ms\": 10993.216, \"total_train_time_s\": 15.303710460662842}", "{\"n\": 9936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.22, \"learn_time_ms\": 10966.19, \"total_train_time_s\": 14.566031455993652}", "{\"n\": 9937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.01, \"learn_time_ms\": 11126.791, \"total_train_time_s\": 16.826885223388672}", "{\"n\": 9938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.74, \"learn_time_ms\": 11024.408, \"total_train_time_s\": 14.918190240859985}", "{\"n\": 9939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.74, \"learn_time_ms\": 11055.261, \"total_train_time_s\": 15.189983606338501}", "{\"n\": 9940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.8, \"learn_time_ms\": 10976.005, \"total_train_time_s\": 14.364651679992676}", "{\"n\": 9941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.8, \"learn_time_ms\": 10924.053, \"total_train_time_s\": 14.291627407073975}", "{\"n\": 9942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.19, \"learn_time_ms\": 10952.958, \"total_train_time_s\": 14.615662574768066}", "{\"n\": 9943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.19, \"learn_time_ms\": 11036.613, \"total_train_time_s\": 14.564315795898438}", "{\"n\": 9944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.63, \"learn_time_ms\": 11089.624, \"total_train_time_s\": 14.807683229446411}", "{\"n\": 9945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.19, \"learn_time_ms\": 10910.393, \"total_train_time_s\": 13.712193727493286}", "{\"n\": 9946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.83, \"learn_time_ms\": 11047.691, \"total_train_time_s\": 15.939756870269775}", "{\"n\": 9947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.22, \"learn_time_ms\": 10832.994, \"total_train_time_s\": 14.144880056381226}", "{\"n\": 9948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.86, \"learn_time_ms\": 10855.878, \"total_train_time_s\": 14.850510835647583}", "{\"n\": 9949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.65, \"learn_time_ms\": 10799.917, \"total_train_time_s\": 14.634241342544556}", "{\"n\": 9950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.72, \"learn_time_ms\": 10710.903, \"total_train_time_s\": 13.44251537322998}", "{\"n\": 9951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.6, \"learn_time_ms\": 10757.96, \"total_train_time_s\": 14.835484743118286}", "{\"n\": 9952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.73, \"learn_time_ms\": 10705.657, \"total_train_time_s\": 14.069385290145874}", "{\"n\": 9953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.73, \"learn_time_ms\": 10655.16, \"total_train_time_s\": 14.112374782562256}", "{\"n\": 9954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.2, \"learn_time_ms\": 10617.258, \"total_train_time_s\": 14.712282419204712}", "{\"n\": 9955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.2, \"learn_time_ms\": 10808.784, \"total_train_time_s\": 15.506255388259888}", "{\"n\": 9956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.94, \"learn_time_ms\": 10646.452, \"total_train_time_s\": 14.170882940292358}", "{\"n\": 9957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.31, \"learn_time_ms\": 10720.674, \"total_train_time_s\": 15.029130458831787}", "{\"n\": 9958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 10771.689, \"total_train_time_s\": 15.17004132270813}", "{\"n\": 9959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 10873.747, \"total_train_time_s\": 15.518060207366943}", "{\"n\": 9960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.23, \"learn_time_ms\": 10898.976, \"total_train_time_s\": 13.774046421051025}", "{\"n\": 9961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.08, \"learn_time_ms\": 10977.916, \"total_train_time_s\": 15.579880237579346}", "{\"n\": 9962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.8, \"learn_time_ms\": 11068.453, \"total_train_time_s\": 15.180665254592896}", "{\"n\": 9963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.8, \"learn_time_ms\": 11056.038, \"total_train_time_s\": 14.040536165237427}", "{\"n\": 9964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.13, \"learn_time_ms\": 10983.225, \"total_train_time_s\": 13.90752911567688}", "{\"n\": 9965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.78, \"learn_time_ms\": 10910.571, \"total_train_time_s\": 14.677803039550781}", "{\"n\": 9966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.78, \"learn_time_ms\": 10923.881, \"total_train_time_s\": 14.242297410964966}", "{\"n\": 9967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.31, \"learn_time_ms\": 10805.878, \"total_train_time_s\": 13.998773336410522}", "{\"n\": 9968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.92, \"learn_time_ms\": 10777.708, \"total_train_time_s\": 15.279157400131226}", "{\"n\": 9969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.72, \"learn_time_ms\": 10670.071, \"total_train_time_s\": 14.385616302490234}", "{\"n\": 9970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.72, \"learn_time_ms\": 10832.484, \"total_train_time_s\": 15.65595531463623}", "{\"n\": 9971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.88, \"learn_time_ms\": 10711.072, \"total_train_time_s\": 14.076234579086304}", "{\"n\": 9972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.37, \"learn_time_ms\": 10604.054, \"total_train_time_s\": 14.228854179382324}", "{\"n\": 9973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.37, \"learn_time_ms\": 10642.956, \"total_train_time_s\": 14.852101802825928}", "{\"n\": 9974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.83, \"learn_time_ms\": 10706.758, \"total_train_time_s\": 14.566892623901367}", "{\"n\": 9975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 10700.149, \"total_train_time_s\": 14.50971508026123}", "{\"n\": 9976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.46, \"learn_time_ms\": 10777.128, \"total_train_time_s\": 15.181163787841797}", "{\"n\": 9977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.46, \"learn_time_ms\": 10723.951, \"total_train_time_s\": 13.293280601501465}", "{\"n\": 9978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.4, \"learn_time_ms\": 10628.103, \"total_train_time_s\": 13.949700117111206}", "{\"n\": 9979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.59, \"learn_time_ms\": 10686.156, \"total_train_time_s\": 15.210498094558716}", "{\"n\": 9980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.59, \"learn_time_ms\": 10694.431, \"total_train_time_s\": 15.570621728897095}", "{\"n\": 9981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.65, \"learn_time_ms\": 10682.162, \"total_train_time_s\": 14.041895389556885}", "{\"n\": 9982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.91, \"learn_time_ms\": 10527.67, \"total_train_time_s\": 12.40822720527649}", "{\"n\": 9983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.52, \"learn_time_ms\": 10584.538, \"total_train_time_s\": 15.022171020507812}", "{\"n\": 9984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 10551.623, \"total_train_time_s\": 14.014167547225952}", "{\"n\": 9985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.71, \"learn_time_ms\": 10516.348, \"total_train_time_s\": 13.960885763168335}", "{\"n\": 9986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.42, \"learn_time_ms\": 10545.528, \"total_train_time_s\": 15.619934558868408}", "{\"n\": 9987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.42, \"learn_time_ms\": 10670.444, \"total_train_time_s\": 14.738811731338501}", "{\"n\": 9988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.63, \"learn_time_ms\": 10694.727, \"total_train_time_s\": 14.239142179489136}", "{\"n\": 9989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.21, \"learn_time_ms\": 10668.409, \"total_train_time_s\": 14.865395069122314}", "{\"n\": 9990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.21, \"learn_time_ms\": 10611.51, \"total_train_time_s\": 14.978456020355225}", "{\"n\": 9991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.19, \"learn_time_ms\": 10675.838, \"total_train_time_s\": 14.523998498916626}", "{\"n\": 9992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.09, \"learn_time_ms\": 10788.219, \"total_train_time_s\": 13.837004661560059}", "{\"n\": 9993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 10763.798, \"total_train_time_s\": 14.840004920959473}", "{\"n\": 9994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.28, \"learn_time_ms\": 10899.257, \"total_train_time_s\": 15.740564346313477}", "{\"n\": 9995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.28, \"learn_time_ms\": 10973.789, \"total_train_time_s\": 14.813472270965576}", "{\"n\": 9996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 10820.678, \"total_train_time_s\": 13.58633279800415}", "{\"n\": 9997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.98, \"learn_time_ms\": 10777.036, \"total_train_time_s\": 14.028619050979614}", "{\"n\": 9998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.39, \"learn_time_ms\": 10911.194, \"total_train_time_s\": 15.777442455291748}", "{\"n\": 9999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.39, \"learn_time_ms\": 10877.936, \"total_train_time_s\": 14.265607833862305}", "{\"n\": 10000, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.05, \"learn_time_ms\": 10834.02, \"total_train_time_s\": 14.528475046157837}", "{\"n\": 10001, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 10764.634, \"total_train_time_s\": 14.010204792022705}", "{\"n\": 10002, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.44, \"learn_time_ms\": 10922.461, \"total_train_time_s\": 15.131083250045776}", "{\"n\": 10003, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.75, \"learn_time_ms\": 10850.353, \"total_train_time_s\": 14.13821291923523}", "{\"n\": 10004, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.77, \"learn_time_ms\": 10762.105, \"total_train_time_s\": 14.76886796951294}", "{\"n\": 10005, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.39, \"learn_time_ms\": 10775.904, \"total_train_time_s\": 14.974579572677612}", "{\"n\": 10006, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.39, \"learn_time_ms\": 10820.775, \"total_train_time_s\": 14.18522310256958}", "{\"n\": 10007, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.7, \"learn_time_ms\": 10827.326, \"total_train_time_s\": 14.333309650421143}", "{\"n\": 10008, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.61, \"learn_time_ms\": 10613.019, \"total_train_time_s\": 13.571738243103027}", "{\"n\": 10009, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.74, \"learn_time_ms\": 10535.356, \"total_train_time_s\": 13.621742248535156}", "{\"n\": 10010, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.93, \"learn_time_ms\": 10483.577, \"total_train_time_s\": 14.169061660766602}", "{\"n\": 10011, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.93, \"learn_time_ms\": 10634.547, \"total_train_time_s\": 15.569536924362183}", "{\"n\": 10012, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.28, \"learn_time_ms\": 10563.127, \"total_train_time_s\": 14.554890632629395}", "{\"n\": 10013, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.8, \"learn_time_ms\": 10650.565, \"total_train_time_s\": 14.877022504806519}", "{\"n\": 10014, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.2, \"learn_time_ms\": 10556.018, \"total_train_time_s\": 13.541163444519043}", "{\"n\": 10015, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.2, \"learn_time_ms\": 10456.295, \"total_train_time_s\": 14.089230298995972}", "{\"n\": 10016, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.09, \"learn_time_ms\": 10568.146, \"total_train_time_s\": 15.314475059509277}", "{\"n\": 10017, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.52, \"learn_time_ms\": 10552.099, \"total_train_time_s\": 13.915296792984009}", "{\"n\": 10018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.52, \"learn_time_ms\": 10748.483, \"total_train_time_s\": 15.378199338912964}", "{\"n\": 10019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.38, \"learn_time_ms\": 10814.028, \"total_train_time_s\": 14.347503423690796}", "{\"n\": 10020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.2, \"learn_time_ms\": 10901.295, \"total_train_time_s\": 15.08467698097229}", "{\"n\": 10021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.3, \"learn_time_ms\": 10810.475, \"total_train_time_s\": 14.434935808181763}", "{\"n\": 10022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.3, \"learn_time_ms\": 10802.531, \"total_train_time_s\": 14.632042169570923}", "{\"n\": 10023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.37, \"learn_time_ms\": 10691.804, \"total_train_time_s\": 13.790899276733398}", "{\"n\": 10024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.39, \"learn_time_ms\": 10833.815, \"total_train_time_s\": 15.174028396606445}", "{\"n\": 10025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.39, \"learn_time_ms\": 10871.412, \"total_train_time_s\": 14.285853147506714}", "{\"n\": 10026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 10795.85, \"total_train_time_s\": 14.603894472122192}", "{\"n\": 10027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.63, \"learn_time_ms\": 10706.566, \"total_train_time_s\": 13.141010999679565}", "{\"n\": 10028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.34, \"learn_time_ms\": 10683.169, \"total_train_time_s\": 15.38001036643982}", "{\"n\": 10029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.34, \"learn_time_ms\": 10665.207, \"total_train_time_s\": 14.185489892959595}", "{\"n\": 10030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.41, \"learn_time_ms\": 10633.743, \"total_train_time_s\": 14.682158470153809}", "{\"n\": 10031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.41, \"learn_time_ms\": 10648.444, \"total_train_time_s\": 14.560328006744385}", "{\"n\": 10032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.8, \"learn_time_ms\": 10750.4, \"total_train_time_s\": 15.56127667427063}", "{\"n\": 10033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.8, \"learn_time_ms\": 10860.391, \"total_train_time_s\": 14.91160273551941}", "{\"n\": 10034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.15, \"learn_time_ms\": 10816.901, \"total_train_time_s\": 14.58996844291687}", "{\"n\": 10035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.31, \"learn_time_ms\": 10898.139, \"total_train_time_s\": 15.014556169509888}", "{\"n\": 10036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.01, \"learn_time_ms\": 10983.345, \"total_train_time_s\": 15.409388065338135}", "{\"n\": 10037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.95, \"learn_time_ms\": 11117.214, \"total_train_time_s\": 14.726116418838501}", "{\"n\": 10038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.95, \"learn_time_ms\": 11047.036, \"total_train_time_s\": 14.455228328704834}", "{\"n\": 10039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.05, \"learn_time_ms\": 11013.033, \"total_train_time_s\": 13.71972107887268}", "{\"n\": 10040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 11153.433, \"total_train_time_s\": 15.92203164100647}", "{\"n\": 10041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 11029.504, \"total_train_time_s\": 13.591188192367554}", "{\"n\": 10042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 10878.756, \"total_train_time_s\": 13.963391304016113}", "{\"n\": 10043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.53, \"learn_time_ms\": 10767.315, \"total_train_time_s\": 13.728497743606567}", "{\"n\": 10044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.38, \"learn_time_ms\": 10600.61, \"total_train_time_s\": 13.121839046478271}", "{\"n\": 10045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.38, \"learn_time_ms\": 10487.555, \"total_train_time_s\": 14.343371152877808}", "{\"n\": 10046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.25, \"learn_time_ms\": 10437.701, \"total_train_time_s\": 14.80539846420288}", "{\"n\": 10047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.25, \"learn_time_ms\": 10451.818, \"total_train_time_s\": 14.830159425735474}", "{\"n\": 10048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.7, \"learn_time_ms\": 10533.089, \"total_train_time_s\": 15.45448112487793}", "{\"n\": 10049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.33, \"learn_time_ms\": 10568.97, \"total_train_time_s\": 14.249570608139038}", "{\"n\": 10050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.71, \"learn_time_ms\": 10490.698, \"total_train_time_s\": 15.099625825881958}", "{\"n\": 10051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.71, \"learn_time_ms\": 10573.236, \"total_train_time_s\": 14.311250925064087}", "{\"n\": 10052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.65, \"learn_time_ms\": 10574.072, \"total_train_time_s\": 14.064356565475464}", "{\"n\": 10053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.6, \"learn_time_ms\": 10629.291, \"total_train_time_s\": 14.41528844833374}", "{\"n\": 10054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.04, \"learn_time_ms\": 10799.892, \"total_train_time_s\": 14.640540599822998}", "{\"n\": 10055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.04, \"learn_time_ms\": 10871.914, \"total_train_time_s\": 14.882984399795532}", "{\"n\": 10056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.94, \"learn_time_ms\": 10842.813, \"total_train_time_s\": 14.787319421768188}", "{\"n\": 10057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.4, \"learn_time_ms\": 10889.389, \"total_train_time_s\": 15.359745740890503}", "{\"n\": 10058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.93, \"learn_time_ms\": 10840.24, \"total_train_time_s\": 14.791550397872925}", "{\"n\": 10059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.93, \"learn_time_ms\": 10946.272, \"total_train_time_s\": 15.051195621490479}", "{\"n\": 10060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.29, \"learn_time_ms\": 10789.013, \"total_train_time_s\": 13.91277265548706}", "{\"n\": 10061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.99, \"learn_time_ms\": 10819.189, \"total_train_time_s\": 14.46467137336731}", "{\"n\": 10062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.08, \"learn_time_ms\": 10968.777, \"total_train_time_s\": 15.500056505203247}", "{\"n\": 10063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.44, \"learn_time_ms\": 11000.544, \"total_train_time_s\": 14.815636396408081}", "{\"n\": 10064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.5, \"learn_time_ms\": 10970.653, \"total_train_time_s\": 14.37935185432434}", "{\"n\": 10065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10984.973, \"total_train_time_s\": 15.262469291687012}", "{\"n\": 10066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.79, \"learn_time_ms\": 11011.308, \"total_train_time_s\": 14.83802580833435}", "{\"n\": 10067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.35, \"learn_time_ms\": 10879.261, \"total_train_time_s\": 13.742770195007324}", "{\"n\": 10068, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.96, \"learn_time_ms\": 10910.881, \"total_train_time_s\": 15.07881784439087}", "{\"n\": 10069, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.98, \"learn_time_ms\": 10947.874, \"total_train_time_s\": 15.620262145996094}", "{\"n\": 10070, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.25, \"learn_time_ms\": 11016.549, \"total_train_time_s\": 14.32367491722107}", "{\"n\": 10071, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.05, \"learn_time_ms\": 11057.43, \"total_train_time_s\": 14.991218566894531}", "{\"n\": 10072, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.05, \"learn_time_ms\": 10796.247, \"total_train_time_s\": 12.865579605102539}", "{\"n\": 10073, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.05, \"learn_time_ms\": 10851.784, \"total_train_time_s\": 15.285974502563477}", "{\"n\": 10074, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.65, \"learn_time_ms\": 10986.556, \"total_train_time_s\": 15.646564722061157}", "{\"n\": 10075, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.65, \"learn_time_ms\": 10884.934, \"total_train_time_s\": 14.122834205627441}", "{\"n\": 10076, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.09, \"learn_time_ms\": 10717.781, \"total_train_time_s\": 13.06618332862854}", "{\"n\": 10077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.75, \"learn_time_ms\": 10737.366, \"total_train_time_s\": 13.859844446182251}", "{\"n\": 10078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.75, \"learn_time_ms\": 10577.694, \"total_train_time_s\": 13.563031196594238}", "{\"n\": 10079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.79, \"learn_time_ms\": 10563.642, \"total_train_time_s\": 15.342628002166748}", "{\"n\": 10080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.53, \"learn_time_ms\": 10561.267, \"total_train_time_s\": 14.237782001495361}", "{\"n\": 10081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.51, \"learn_time_ms\": 10514.013, \"total_train_time_s\": 14.50018858909607}", "{\"n\": 10082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 10815.771, \"total_train_time_s\": 16.043830633163452}", "{\"n\": 10083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 10620.106, \"total_train_time_s\": 13.277463436126709}", "{\"n\": 10084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.71, \"learn_time_ms\": 10491.561, \"total_train_time_s\": 14.514456987380981}", "{\"n\": 10085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.93, \"learn_time_ms\": 10660.666, \"total_train_time_s\": 15.519284725189209}", "{\"n\": 10086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.27, \"learn_time_ms\": 10772.448, \"total_train_time_s\": 14.421268939971924}", "{\"n\": 10087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.27, \"learn_time_ms\": 10782.92, \"total_train_time_s\": 13.930609464645386}", "{\"n\": 10088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.96, \"learn_time_ms\": 10972.471, \"total_train_time_s\": 15.49378752708435}", "{\"n\": 10089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.15, \"learn_time_ms\": 10907.456, \"total_train_time_s\": 15.07720136642456}", "{\"n\": 10090, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.51, \"learn_time_ms\": 10980.961, \"total_train_time_s\": 15.153059720993042}", "{\"n\": 10091, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.02, \"learn_time_ms\": 10983.966, \"total_train_time_s\": 14.713045597076416}", "{\"n\": 10092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.77, \"learn_time_ms\": 10837.644, \"total_train_time_s\": 14.505970478057861}", "{\"n\": 10093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.77, \"learn_time_ms\": 10879.083, \"total_train_time_s\": 13.52147388458252}", "{\"n\": 10094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.62, \"learn_time_ms\": 10830.532, \"total_train_time_s\": 13.840991973876953}", "{\"n\": 10095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.52, \"learn_time_ms\": 10703.903, \"total_train_time_s\": 14.464157581329346}", "{\"n\": 10096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.44, \"learn_time_ms\": 10601.835, \"total_train_time_s\": 13.496987104415894}", "{\"n\": 10097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.44, \"learn_time_ms\": 10712.159, \"total_train_time_s\": 15.081138610839844}", "{\"n\": 10098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.12, \"learn_time_ms\": 10613.487, \"total_train_time_s\": 14.547054290771484}", "{\"n\": 10099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.37, \"learn_time_ms\": 10526.247, \"total_train_time_s\": 13.847068309783936}", "{\"n\": 10100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.28, \"learn_time_ms\": 10419.685, \"total_train_time_s\": 13.828179121017456}", "{\"n\": 10101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.28, \"learn_time_ms\": 10431.11, \"total_train_time_s\": 14.629372119903564}", "{\"n\": 10102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.4, \"learn_time_ms\": 10441.488, \"total_train_time_s\": 14.455161571502686}", "{\"n\": 10103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.24, \"learn_time_ms\": 10495.471, \"total_train_time_s\": 14.154966115951538}", "{\"n\": 10104, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.11, \"learn_time_ms\": 10464.352, \"total_train_time_s\": 13.764783143997192}", "{\"n\": 10105, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.28, \"learn_time_ms\": 10440.162, \"total_train_time_s\": 13.892046451568604}", "{\"n\": 10106, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.42, \"learn_time_ms\": 10479.106, \"total_train_time_s\": 13.76009225845337}", "{\"n\": 10107, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.42, \"learn_time_ms\": 10374.917, \"total_train_time_s\": 14.283050537109375}", "{\"n\": 10108, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.05, \"learn_time_ms\": 10429.629, \"total_train_time_s\": 14.967284202575684}", "{\"n\": 10109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.05, \"learn_time_ms\": 10486.634, \"total_train_time_s\": 14.624828100204468}", "{\"n\": 10110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.57, \"learn_time_ms\": 10542.334, \"total_train_time_s\": 14.475785732269287}", "{\"n\": 10111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.15, \"learn_time_ms\": 10548.569, \"total_train_time_s\": 14.73112678527832}", "{\"n\": 10112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.15, \"learn_time_ms\": 10603.929, \"total_train_time_s\": 15.278208255767822}", "{\"n\": 10113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.46, \"learn_time_ms\": 10578.545, \"total_train_time_s\": 14.041784048080444}", "{\"n\": 10114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.49, \"learn_time_ms\": 10557.026, \"total_train_time_s\": 13.594558477401733}", "{\"n\": 10115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.86, \"learn_time_ms\": 10741.538, \"total_train_time_s\": 15.769780397415161}", "{\"n\": 10116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.86, \"learn_time_ms\": 10918.956, \"total_train_time_s\": 15.791638135910034}", "{\"n\": 10117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.53, \"learn_time_ms\": 10849.203, \"total_train_time_s\": 13.660762310028076}", "{\"n\": 10118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.14, \"learn_time_ms\": 10715.114, \"total_train_time_s\": 13.818699836730957}", "{\"n\": 10119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.14, \"learn_time_ms\": 10755.436, \"total_train_time_s\": 14.773674488067627}", "{\"n\": 10120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3715.1, \"learn_time_ms\": 10761.017, \"total_train_time_s\": 14.831408739089966}", "{\"n\": 10121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3715.1, \"learn_time_ms\": 10699.364, \"total_train_time_s\": 14.05890154838562}", "{\"n\": 10122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.77, \"learn_time_ms\": 10566.104, \"total_train_time_s\": 14.048851251602173}", "{\"n\": 10123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.77, \"learn_time_ms\": 10737.548, \"total_train_time_s\": 15.524135112762451}", "{\"n\": 10124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.27, \"learn_time_ms\": 10741.589, \"total_train_time_s\": 13.39703917503357}", "{\"n\": 10125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.22, \"learn_time_ms\": 10606.29, \"total_train_time_s\": 14.497886657714844}", "{\"n\": 10126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.32, \"learn_time_ms\": 10480.509, \"total_train_time_s\": 14.441501140594482}", "{\"n\": 10127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.32, \"learn_time_ms\": 10670.92, \"total_train_time_s\": 15.598480463027954}", "{\"n\": 10128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.7, \"learn_time_ms\": 10790.667, \"total_train_time_s\": 14.861549615859985}", "{\"n\": 10129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.63, \"learn_time_ms\": 10857.693, \"total_train_time_s\": 15.597109317779541}", "{\"n\": 10130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 10935.789, \"total_train_time_s\": 15.625106811523438}", "{\"n\": 10131, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.48, \"learn_time_ms\": 10958.359, \"total_train_time_s\": 14.270452737808228}", "{\"n\": 10132, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.0, \"learn_time_ms\": 11084.499, \"total_train_time_s\": 14.888778448104858}", "{\"n\": 10133, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.0, \"learn_time_ms\": 10944.282, \"total_train_time_s\": 14.398389339447021}", "{\"n\": 10134, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.0, \"learn_time_ms\": 10955.372, \"total_train_time_s\": 13.765529870986938}", "{\"n\": 10135, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.88, \"learn_time_ms\": 10929.54, \"total_train_time_s\": 14.341735124588013}", "{\"n\": 10136, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.05, \"learn_time_ms\": 10925.038, \"total_train_time_s\": 14.134202480316162}", "{\"n\": 10137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.05, \"learn_time_ms\": 10742.219, \"total_train_time_s\": 13.522642612457275}", "{\"n\": 10138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3743.24, \"learn_time_ms\": 10775.332, \"total_train_time_s\": 15.302614688873291}", "{\"n\": 10139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3745.45, \"learn_time_ms\": 10559.368, \"total_train_time_s\": 13.553691148757935}", "{\"n\": 10140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3751.55, \"learn_time_ms\": 10480.405, \"total_train_time_s\": 14.48404860496521}", "{\"n\": 10141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3744.68, \"learn_time_ms\": 10525.058, \"total_train_time_s\": 15.015095472335815}", "{\"n\": 10142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3744.68, \"learn_time_ms\": 10560.563, \"total_train_time_s\": 15.201668500900269}", "{\"n\": 10143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3754.57, \"learn_time_ms\": 10691.543, \"total_train_time_s\": 15.55450963973999}", "{\"n\": 10144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3754.57, \"learn_time_ms\": 10759.685, \"total_train_time_s\": 14.316410303115845}", "{\"n\": 10145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3746.31, \"learn_time_ms\": 10724.648, \"total_train_time_s\": 14.04075026512146}", "{\"n\": 10146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3742.25, \"learn_time_ms\": 10695.768, \"total_train_time_s\": 14.050436973571777}", "{\"n\": 10147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.32, \"learn_time_ms\": 10835.059, \"total_train_time_s\": 14.857366561889648}", "{\"n\": 10148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3738.32, \"learn_time_ms\": 10826.15, \"total_train_time_s\": 15.55683159828186}", "{\"n\": 10149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3740.06, \"learn_time_ms\": 10896.494, \"total_train_time_s\": 14.133040428161621}", "{\"n\": 10150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3742.44, \"learn_time_ms\": 10846.844, \"total_train_time_s\": 14.181948900222778}", "{\"n\": 10151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.33, \"learn_time_ms\": 10669.645, \"total_train_time_s\": 12.956000804901123}", "{\"n\": 10152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.33, \"learn_time_ms\": 10607.302, \"total_train_time_s\": 15.009429931640625}", "{\"n\": 10153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.33, \"learn_time_ms\": 10512.746, \"total_train_time_s\": 14.730788469314575}", "{\"n\": 10154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.48, \"learn_time_ms\": 10502.419, \"total_train_time_s\": 14.177209377288818}", "{\"n\": 10155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.23, \"learn_time_ms\": 10526.349, \"total_train_time_s\": 14.065866470336914}", "{\"n\": 10156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.23, \"learn_time_ms\": 10670.522, \"total_train_time_s\": 15.44685697555542}", "{\"n\": 10157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3728.96, \"learn_time_ms\": 10710.29, \"total_train_time_s\": 15.61773681640625}", "{\"n\": 10158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.47, \"learn_time_ms\": 10617.839, \"total_train_time_s\": 14.403162240982056}", "{\"n\": 10159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.36, \"learn_time_ms\": 10692.311, \"total_train_time_s\": 14.832304239273071}", "{\"n\": 10160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.36, \"learn_time_ms\": 10590.417, \"total_train_time_s\": 13.089942216873169}", "{\"n\": 10161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.51, \"learn_time_ms\": 10743.233, \"total_train_time_s\": 14.476472616195679}", "{\"n\": 10162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.28, \"learn_time_ms\": 10874.352, \"total_train_time_s\": 15.944243907928467}", "{\"n\": 10163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.09, \"learn_time_ms\": 10910.679, \"total_train_time_s\": 15.0209641456604}", "{\"n\": 10164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.09, \"learn_time_ms\": 10929.776, \"total_train_time_s\": 14.589407920837402}", "{\"n\": 10165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.96, \"learn_time_ms\": 10898.99, \"total_train_time_s\": 13.882484197616577}", "{\"n\": 10166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3739.96, \"learn_time_ms\": 10917.458, \"total_train_time_s\": 15.515893459320068}", "{\"n\": 10167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3742.62, \"learn_time_ms\": 10864.037, \"total_train_time_s\": 15.040801763534546}", "{\"n\": 10168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3733.5, \"learn_time_ms\": 10832.81, \"total_train_time_s\": 14.158608198165894}", "{\"n\": 10169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.18, \"learn_time_ms\": 10673.085, \"total_train_time_s\": 13.347913265228271}", "{\"n\": 10170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.18, \"learn_time_ms\": 10845.502, \"total_train_time_s\": 15.204423666000366}", "{\"n\": 10171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.26, \"learn_time_ms\": 10973.367, \"total_train_time_s\": 15.820106506347656}", "{\"n\": 10172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.51, \"learn_time_ms\": 10920.74, \"total_train_time_s\": 15.492275476455688}", "{\"n\": 10173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.9, \"learn_time_ms\": 10884.548, \"total_train_time_s\": 14.652658462524414}", "{\"n\": 10174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.9, \"learn_time_ms\": 10886.935, \"total_train_time_s\": 14.28675627708435}", "{\"n\": 10175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.99, \"learn_time_ms\": 10924.132, \"total_train_time_s\": 14.125346660614014}", "{\"n\": 10176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.61, \"learn_time_ms\": 10847.916, \"total_train_time_s\": 14.839718103408813}", "{\"n\": 10177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.92, \"learn_time_ms\": 10948.751, \"total_train_time_s\": 15.987528800964355}", "{\"n\": 10178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.46, \"learn_time_ms\": 11041.862, \"total_train_time_s\": 15.136390447616577}", "{\"n\": 10179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3731.06, \"learn_time_ms\": 11084.485, \"total_train_time_s\": 13.719269752502441}", "{\"n\": 10180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3731.19, \"learn_time_ms\": 11058.693, \"total_train_time_s\": 14.742059469223022}", "{\"n\": 10181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3728.25, \"learn_time_ms\": 10842.011, \"total_train_time_s\": 13.625813961029053}", "{\"n\": 10182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3728.25, \"learn_time_ms\": 10763.167, \"total_train_time_s\": 14.893556833267212}", "{\"n\": 10183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3722.59, \"learn_time_ms\": 10824.699, \"total_train_time_s\": 15.317554235458374}", "{\"n\": 10184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.81, \"learn_time_ms\": 10807.985, \"total_train_time_s\": 14.174310445785522}", "{\"n\": 10185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.82, \"learn_time_ms\": 10874.636, \"total_train_time_s\": 14.948441505432129}", "{\"n\": 10186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.82, \"learn_time_ms\": 10886.769, \"total_train_time_s\": 14.733897686004639}", "{\"n\": 10187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3715.83, \"learn_time_ms\": 10868.044, \"total_train_time_s\": 15.551384687423706}", "{\"n\": 10188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.2, \"learn_time_ms\": 10877.25, \"total_train_time_s\": 15.096021175384521}", "{\"n\": 10189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.2, \"learn_time_ms\": 10937.872, \"total_train_time_s\": 14.3506019115448}", "{\"n\": 10190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.2, \"learn_time_ms\": 11054.537, \"total_train_time_s\": 15.585134029388428}", "{\"n\": 10191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 11192.213, \"total_train_time_s\": 15.040392637252808}", "{\"n\": 10192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 11235.894, \"total_train_time_s\": 15.053318500518799}", "{\"n\": 10193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 11104.659, \"total_train_time_s\": 14.17414140701294}", "{\"n\": 10194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.37, \"learn_time_ms\": 11238.014, \"total_train_time_s\": 15.675747156143188}", "{\"n\": 10195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.58, \"learn_time_ms\": 11266.807, \"total_train_time_s\": 15.300456762313843}", "{\"n\": 10196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.61, \"learn_time_ms\": 11166.559, \"total_train_time_s\": 13.909641742706299}", "{\"n\": 10197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.61, \"learn_time_ms\": 11166.952, \"total_train_time_s\": 15.620160102844238}", "{\"n\": 10198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.9, \"learn_time_ms\": 11105.459, \"total_train_time_s\": 14.275848865509033}", "{\"n\": 10199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.62, \"learn_time_ms\": 11187.154, \"total_train_time_s\": 15.076113939285278}", "{\"n\": 10200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.62, \"learn_time_ms\": 11200.293, \"total_train_time_s\": 15.66098165512085}", "{\"n\": 10201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.5, \"learn_time_ms\": 11142.391, \"total_train_time_s\": 14.380981206893921}", "{\"n\": 10202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.5, \"learn_time_ms\": 11198.821, \"total_train_time_s\": 15.86013388633728}", "{\"n\": 10203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.41, \"learn_time_ms\": 11247.868, \"total_train_time_s\": 14.285252571105957}", "{\"n\": 10204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.41, \"learn_time_ms\": 11186.002, \"total_train_time_s\": 14.7790367603302}", "{\"n\": 10205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.52, \"learn_time_ms\": 11106.431, \"total_train_time_s\": 14.446641206741333}", "{\"n\": 10206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.44, \"learn_time_ms\": 11102.986, \"total_train_time_s\": 13.698551416397095}", "{\"n\": 10207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.41, \"learn_time_ms\": 11035.754, \"total_train_time_s\": 15.310567378997803}", "{\"n\": 10208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.09, \"learn_time_ms\": 11034.69, \"total_train_time_s\": 14.670234680175781}", "{\"n\": 10209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.09, \"learn_time_ms\": 10943.587, \"total_train_time_s\": 14.36076545715332}", "{\"n\": 10210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.58, \"learn_time_ms\": 10740.953, \"total_train_time_s\": 13.87947130203247}", "{\"n\": 10211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.99, \"learn_time_ms\": 10696.129, \"total_train_time_s\": 14.098979711532593}", "{\"n\": 10212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.99, \"learn_time_ms\": 10694.58, \"total_train_time_s\": 15.641618728637695}", "{\"n\": 10213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.77, \"learn_time_ms\": 10723.758, \"total_train_time_s\": 14.864341974258423}", "{\"n\": 10214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.81, \"learn_time_ms\": 10709.246, \"total_train_time_s\": 14.673057317733765}", "{\"n\": 10215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.81, \"learn_time_ms\": 10842.21, \"total_train_time_s\": 15.650403261184692}", "{\"n\": 10216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3715.59, \"learn_time_ms\": 10899.752, \"total_train_time_s\": 14.261252403259277}", "{\"n\": 10217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3715.21, \"learn_time_ms\": 10852.775, \"total_train_time_s\": 14.850826740264893}", "{\"n\": 10218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.36, \"learn_time_ms\": 10826.81, \"total_train_time_s\": 14.186984300613403}", "{\"n\": 10219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.57, \"learn_time_ms\": 10786.799, \"total_train_time_s\": 13.774925231933594}", "{\"n\": 10220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.57, \"learn_time_ms\": 10814.912, \"total_train_time_s\": 14.301656007766724}", "{\"n\": 10221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.52, \"learn_time_ms\": 10875.851, \"total_train_time_s\": 14.616883277893066}", "{\"n\": 10222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.12, \"learn_time_ms\": 10773.463, \"total_train_time_s\": 14.564435958862305}", "{\"n\": 10223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.63, \"learn_time_ms\": 10754.466, \"total_train_time_s\": 14.688947439193726}", "{\"n\": 10224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.63, \"learn_time_ms\": 10680.728, \"total_train_time_s\": 13.946563243865967}", "{\"n\": 10225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.33, \"learn_time_ms\": 10511.793, \"total_train_time_s\": 13.92348027229309}", "{\"n\": 10226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.33, \"learn_time_ms\": 10508.33, \"total_train_time_s\": 14.465131044387817}", "{\"n\": 10227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.18, \"learn_time_ms\": 10432.478, \"total_train_time_s\": 13.940571069717407}", "{\"n\": 10228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.18, \"learn_time_ms\": 10556.163, \"total_train_time_s\": 15.152233362197876}", "{\"n\": 10229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.12, \"learn_time_ms\": 10518.883, \"total_train_time_s\": 13.367926597595215}", "{\"n\": 10230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.49, \"learn_time_ms\": 10695.129, \"total_train_time_s\": 15.911187648773193}", "{\"n\": 10231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.49, \"learn_time_ms\": 10588.269, \"total_train_time_s\": 13.817633867263794}", "{\"n\": 10232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.29, \"learn_time_ms\": 10658.037, \"total_train_time_s\": 15.299799919128418}", "{\"n\": 10233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.84, \"learn_time_ms\": 10761.22, \"total_train_time_s\": 15.553199529647827}", "{\"n\": 10234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.61, \"learn_time_ms\": 10824.548, \"total_train_time_s\": 14.698026657104492}", "{\"n\": 10235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.61, \"learn_time_ms\": 10945.488, \"total_train_time_s\": 15.431475400924683}", "{\"n\": 10236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.06, \"learn_time_ms\": 10961.854, \"total_train_time_s\": 14.708834886550903}", "{\"n\": 10237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.58, \"learn_time_ms\": 11074.714, \"total_train_time_s\": 14.72394323348999}", "{\"n\": 10238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.58, \"learn_time_ms\": 11000.442, \"total_train_time_s\": 14.41051197052002}", "{\"n\": 10239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.58, \"learn_time_ms\": 11101.294, \"total_train_time_s\": 14.317893266677856}", "{\"n\": 10240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.74, \"learn_time_ms\": 10892.205, \"total_train_time_s\": 13.811755657196045}", "{\"n\": 10241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.2, \"learn_time_ms\": 10947.682, \"total_train_time_s\": 14.317293405532837}", "{\"n\": 10242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.2, \"learn_time_ms\": 10844.041, \"total_train_time_s\": 14.494189739227295}", "{\"n\": 10243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.2, \"learn_time_ms\": 10807.071, \"total_train_time_s\": 15.372778415679932}", "{\"n\": 10244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.95, \"learn_time_ms\": 10732.851, \"total_train_time_s\": 13.999799251556396}", "{\"n\": 10245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.95, \"learn_time_ms\": 10756.738, \"total_train_time_s\": 15.507676124572754}", "{\"n\": 10246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.89, \"learn_time_ms\": 10806.55, \"total_train_time_s\": 15.079155206680298}", "{\"n\": 10247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.1, \"learn_time_ms\": 10748.358, \"total_train_time_s\": 14.573798894882202}", "{\"n\": 10248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3728.73, \"learn_time_ms\": 10804.325, \"total_train_time_s\": 15.105680704116821}", "{\"n\": 10249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3737.53, \"learn_time_ms\": 10861.934, \"total_train_time_s\": 15.130066394805908}"]