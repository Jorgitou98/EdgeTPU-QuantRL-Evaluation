["{\"n\": 1297, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10852.393, \"total_train_time_s\": 14.508043766021729}", "{\"n\": 1298, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10599.557, \"total_train_time_s\": 13.807889223098755}", "{\"n\": 1299, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10617.644, \"total_train_time_s\": 14.349099397659302}", "{\"n\": 1300, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10670.159, \"total_train_time_s\": 14.353034734725952}", "{\"n\": 1301, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10436.232, \"total_train_time_s\": 13.154028415679932}", "{\"n\": 1302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2798.5, \"learn_time_ms\": 10319.507, \"total_train_time_s\": 13.406124591827393}", "{\"n\": 1303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -10.666666666666666, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.6666666666665, \"learn_time_ms\": 10230.751, \"total_train_time_s\": 13.641531467437744}", "{\"n\": 1304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3449.0, \"learn_time_ms\": 10228.318, \"total_train_time_s\": 13.821574449539185}", "{\"n\": 1305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3292.0, \"learn_time_ms\": 10195.82, \"total_train_time_s\": 13.416656494140625}", "{\"n\": 1306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.428571428571429, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3226.714285714286, \"learn_time_ms\": 10279.82, \"total_train_time_s\": 14.52576208114624}", "{\"n\": 1307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.11111111111111, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.5555555555557, \"learn_time_ms\": 10341.231, \"total_train_time_s\": 14.988080739974976}", "{\"n\": 1308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.11111111111111, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.5555555555557, \"learn_time_ms\": 10351.208, \"total_train_time_s\": 14.18908166885376}", "{\"n\": 1309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.909090909090908, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3155.3636363636365, \"learn_time_ms\": 10420.72, \"total_train_time_s\": 15.185111284255981}", "{\"n\": 1310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.166666666666666, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.9166666666665, \"learn_time_ms\": 10458.708, \"total_train_time_s\": 14.998978614807129}", "{\"n\": 1311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.23076923076923, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3133.923076923077, \"learn_time_ms\": 10486.365, \"total_train_time_s\": 13.36708378791809}", "{\"n\": 1312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.214285714285714, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3131.1428571428573, \"learn_time_ms\": 10542.319, \"total_train_time_s\": 14.01149868965149}", "{\"n\": 1313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.133333333333333, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3130.8, \"learn_time_ms\": 10669.693, \"total_train_time_s\": 14.596394062042236}", "{\"n\": 1314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.944444444444445, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.3333333333335, \"learn_time_ms\": 10742.201, \"total_train_time_s\": 14.6331787109375}", "{\"n\": 1315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.944444444444445, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.3333333333335, \"learn_time_ms\": 10842.213, \"total_train_time_s\": 14.699628829956055}", "{\"n\": 1316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.894736842105264, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3174.0, \"learn_time_ms\": 10831.563, \"total_train_time_s\": 14.635343551635742}", "{\"n\": 1317, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3143.318181818182, \"learn_time_ms\": 10744.831, \"total_train_time_s\": 14.253226280212402}", "{\"n\": 1318, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3143.318181818182, \"learn_time_ms\": 10674.135, \"total_train_time_s\": 13.28505277633667}", "{\"n\": 1319, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.043478260869565, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3144.9565217391305, \"learn_time_ms\": 10553.136, \"total_train_time_s\": 13.805780172348022}", "{\"n\": 1320, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3124.52, \"learn_time_ms\": 10491.375, \"total_train_time_s\": 14.362295150756836}", "{\"n\": 1321, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.076923076923077, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3125.230769230769, \"learn_time_ms\": 10647.529, \"total_train_time_s\": 15.030141592025757}", "{\"n\": 1322, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.076923076923077, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3125.230769230769, \"learn_time_ms\": 10661.524, \"total_train_time_s\": 14.276933193206787}", "{\"n\": 1323, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.964285714285714, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3139.3928571428573, \"learn_time_ms\": 10662.487, \"total_train_time_s\": 14.746646165847778}", "{\"n\": 1324, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3137.344827586207, \"learn_time_ms\": 10531.898, \"total_train_time_s\": 13.30644702911377}", "{\"n\": 1325, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.833333333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3162.4333333333334, \"learn_time_ms\": 10520.717, \"total_train_time_s\": 14.552138566970825}", "{\"n\": 1326, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.709677419354838, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3183.483870967742, \"learn_time_ms\": 10438.759, \"total_train_time_s\": 13.908433437347412}", "{\"n\": 1327, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.441176470588236, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3219.6176470588234, \"learn_time_ms\": 10385.024, \"total_train_time_s\": 13.621061325073242}", "{\"n\": 1328, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.441176470588236, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3219.6176470588234, \"learn_time_ms\": 10426.987, \"total_train_time_s\": 13.640147924423218}", "{\"n\": 1329, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3226.114285714286, \"learn_time_ms\": 10530.378, \"total_train_time_s\": 14.74337887763977}", "{\"n\": 1330, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.243243243243244, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3227.2162162162163, \"learn_time_ms\": 10563.319, \"total_train_time_s\": 14.521702289581299}", "{\"n\": 1331, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.342105263157896, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3207.5, \"learn_time_ms\": 10453.333, \"total_train_time_s\": 13.86302661895752}", "{\"n\": 1332, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.435897435897436, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3186.051282051282, \"learn_time_ms\": 10543.471, \"total_train_time_s\": 14.975106716156006}", "{\"n\": 1333, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.390243902439025, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3181.731707317073, \"learn_time_ms\": 10461.869, \"total_train_time_s\": 13.791797876358032}", "{\"n\": 1334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3189.7380952380954, \"learn_time_ms\": 10603.488, \"total_train_time_s\": 14.669135332107544}", "{\"n\": 1335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.295454545454545, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3180.659090909091, \"learn_time_ms\": 10680.815, \"total_train_time_s\": 15.26671576499939}", "{\"n\": 1336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.222222222222221, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3183.488888888889, \"learn_time_ms\": 10686.813, \"total_train_time_s\": 13.788994312286377}", "{\"n\": 1337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23913043478261, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3182.108695652174, \"learn_time_ms\": 10765.608, \"total_train_time_s\": 14.604440212249756}", "{\"n\": 1338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.270833333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3176.2291666666665, \"learn_time_ms\": 10873.357, \"total_train_time_s\": 15.015285015106201}", "{\"n\": 1339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.306122448979592, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.4285714285716, \"learn_time_ms\": 10650.42, \"total_train_time_s\": 12.517850160598755}", "{\"n\": 1340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3165.76, \"learn_time_ms\": 10520.37, \"total_train_time_s\": 13.445672035217285}", "{\"n\": 1341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.288461538461538, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3158.5576923076924, \"learn_time_ms\": 10482.654, \"total_train_time_s\": 13.59383249282837}", "{\"n\": 1342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.30188679245283, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3159.301886792453, \"learn_time_ms\": 10441.585, \"total_train_time_s\": 14.635407447814941}", "{\"n\": 1343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38888888888889, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3144.8333333333335, \"learn_time_ms\": 10461.101, \"total_train_time_s\": 14.079174518585205}", "{\"n\": 1344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.392857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3140.7321428571427, \"learn_time_ms\": 10422.492, \"total_train_time_s\": 14.271700620651245}", "{\"n\": 1345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.368421052631579, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3136.7368421052633, \"learn_time_ms\": 10297.452, \"total_train_time_s\": 13.841882467269897}", "{\"n\": 1346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.362068965517242, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.1724137931033, \"learn_time_ms\": 10379.738, \"total_train_time_s\": 14.547860383987427}", "{\"n\": 1347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.362068965517242, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.1724137931033, \"learn_time_ms\": 10384.523, \"total_train_time_s\": 14.741921424865723}", "{\"n\": 1348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.40983606557377, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3133.1639344262294, \"learn_time_ms\": 10338.117, \"total_train_time_s\": 14.333167791366577}", "{\"n\": 1349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.403225806451612, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3133.8870967741937, \"learn_time_ms\": 10531.008, \"total_train_time_s\": 14.673632621765137}", "{\"n\": 1350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.403225806451612, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3133.8870967741937, \"learn_time_ms\": 10707.55, \"total_train_time_s\": 14.957328081130981}", "{\"n\": 1351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36923076923077, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.3846153846152, \"learn_time_ms\": 10778.37, \"total_train_time_s\": 14.484210014343262}", "{\"n\": 1352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36923076923077, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.3846153846152, \"learn_time_ms\": 10799.16, \"total_train_time_s\": 14.775177001953125}", "{\"n\": 1353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35820895522388, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.3880597014927, \"learn_time_ms\": 10861.945, \"total_train_time_s\": 14.781964540481567}", "{\"n\": 1354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.304347826086957, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3147.623188405797, \"learn_time_ms\": 10772.547, \"total_train_time_s\": 13.263222932815552}", "{\"n\": 1355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.304347826086957, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3147.623188405797, \"learn_time_ms\": 10721.754, \"total_train_time_s\": 13.326298236846924}", "{\"n\": 1356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.271428571428572, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3154.5285714285715, \"learn_time_ms\": 10622.274, \"total_train_time_s\": 13.677701473236084}", "{\"n\": 1357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36111111111111, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3142.0416666666665, \"learn_time_ms\": 10617.804, \"total_train_time_s\": 14.338271141052246}", "{\"n\": 1358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.342465753424657, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3148.246575342466, \"learn_time_ms\": 10599.506, \"total_train_time_s\": 14.268643856048584}", "{\"n\": 1359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.342465753424657, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3148.246575342466, \"learn_time_ms\": 10580.661, \"total_train_time_s\": 14.261583089828491}", "{\"n\": 1360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.328947368421053, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3153.7894736842104, \"learn_time_ms\": 10512.163, \"total_train_time_s\": 14.24189281463623}", "{\"n\": 1361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.272727272727273, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3164.1688311688313, \"learn_time_ms\": 10369.773, \"total_train_time_s\": 13.024558067321777}", "{\"n\": 1362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.272727272727273, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3164.1688311688313, \"learn_time_ms\": 10335.976, \"total_train_time_s\": 14.480742454528809}", "{\"n\": 1363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.30379746835443, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3162.0379746835442, \"learn_time_ms\": 10275.86, \"total_train_time_s\": 14.219475030899048}", "{\"n\": 1364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.679012345679, \"learn_time_ms\": 10388.849, \"total_train_time_s\": 14.436929941177368}", "{\"n\": 1365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.679012345679, \"learn_time_ms\": 10499.442, \"total_train_time_s\": 14.668835401535034}", "{\"n\": 1366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.301204819277109, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3166.0722891566265, \"learn_time_ms\": 10455.077, \"total_train_time_s\": 13.079664945602417}", "{\"n\": 1367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.301204819277109, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3166.0722891566265, \"learn_time_ms\": 10379.043, \"total_train_time_s\": 14.014318704605103}", "{\"n\": 1368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.211764705882352, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.0117647058823, \"learn_time_ms\": 10250.214, \"total_train_time_s\": 12.82489824295044}", "{\"n\": 1369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.244186046511627, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.8953488372094, \"learn_time_ms\": 10107.538, \"total_train_time_s\": 13.123287677764893}", "{\"n\": 1370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.218390804597702, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.4942528735633, \"learn_time_ms\": 10052.237, \"total_train_time_s\": 13.764382362365723}", "{\"n\": 1371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.123595505617978, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.2022471910113, \"learn_time_ms\": 10195.0, \"total_train_time_s\": 14.302193403244019}", "{\"n\": 1372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.133333333333333, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.3888888888887, \"learn_time_ms\": 10267.35, \"total_train_time_s\": 15.06486701965332}", "{\"n\": 1373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.142857142857142, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.967032967033, \"learn_time_ms\": 10199.284, \"total_train_time_s\": 13.26917576789856}", "{\"n\": 1374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.193548387096774, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.7849462365593, \"learn_time_ms\": 10175.427, \"total_train_time_s\": 14.659538507461548}", "{\"n\": 1375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.193548387096774, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.7849462365593, \"learn_time_ms\": 10165.817, \"total_train_time_s\": 14.354793071746826}", "{\"n\": 1376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23157894736842, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.915789473684, \"learn_time_ms\": 10202.112, \"total_train_time_s\": 13.4905104637146}", "{\"n\": 1377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.3645833333335, \"learn_time_ms\": 10155.835, \"total_train_time_s\": 13.124316215515137}", "{\"n\": 1378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.237113402061855, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.721649484536, \"learn_time_ms\": 10240.341, \"total_train_time_s\": 13.7557532787323}", "{\"n\": 1379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.171717171717171, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.757575757576, \"learn_time_ms\": 10350.791, \"total_train_time_s\": 13.917434215545654}", "{\"n\": 1380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.64, \"learn_time_ms\": 10419.312, \"total_train_time_s\": 14.841391563415527}", "{\"n\": 1381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.64, \"learn_time_ms\": 10451.151, \"total_train_time_s\": 14.652139902114868}", "{\"n\": 1382, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.95, \"learn_time_ms\": 10278.99, \"total_train_time_s\": 13.359497547149658}", "{\"n\": 1383, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.95, \"learn_time_ms\": 10455.597, \"total_train_time_s\": 15.297853231430054}", "{\"n\": 1384, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.95, \"learn_time_ms\": 10440.696, \"total_train_time_s\": 14.34780216217041}", "{\"n\": 1385, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.67, \"learn_time_ms\": 10455.36, \"total_train_time_s\": 14.51636028289795}", "{\"n\": 1386, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.67, \"learn_time_ms\": 10474.097, \"total_train_time_s\": 13.801339626312256}", "{\"n\": 1387, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.67, \"learn_time_ms\": 10493.665, \"total_train_time_s\": 13.432127714157104}", "{\"n\": 1388, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.35, \"learn_time_ms\": 10589.692, \"total_train_time_s\": 14.901970624923706}", "{\"n\": 1389, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.69, \"learn_time_ms\": 10712.268, \"total_train_time_s\": 15.14880084991455}", "{\"n\": 1390, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.69, \"learn_time_ms\": 10679.718, \"total_train_time_s\": 14.317158937454224}", "{\"n\": 1391, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 10569.719, \"total_train_time_s\": 13.383508920669556}", "{\"n\": 1392, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.67, \"learn_time_ms\": 10652.582, \"total_train_time_s\": 14.184080600738525}", "{\"n\": 1393, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.67, \"learn_time_ms\": 10579.046, \"total_train_time_s\": 14.498118162155151}", "{\"n\": 1394, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.3, \"learn_time_ms\": 10562.493, \"total_train_time_s\": 14.04195261001587}", "{\"n\": 1395, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.32, \"learn_time_ms\": 10614.498, \"total_train_time_s\": 15.11778450012207}", "{\"n\": 1396, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.72, \"learn_time_ms\": 10809.527, \"total_train_time_s\": 15.642778396606445}", "{\"n\": 1397, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.72, \"learn_time_ms\": 10881.153, \"total_train_time_s\": 14.178370475769043}", "{\"n\": 1398, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.43, \"learn_time_ms\": 10864.033, \"total_train_time_s\": 14.537099123001099}", "{\"n\": 1399, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.73, \"learn_time_ms\": 10749.985, \"total_train_time_s\": 14.101853370666504}", "{\"n\": 1400, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.89, \"learn_time_ms\": 10825.105, \"total_train_time_s\": 14.854594945907593}", "{\"n\": 1401, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.2, \"learn_time_ms\": 10922.898, \"total_train_time_s\": 14.658313274383545}", "{\"n\": 1402, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.41, \"learn_time_ms\": 10918.168, \"total_train_time_s\": 14.17289686203003}", "{\"n\": 1403, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.41, \"learn_time_ms\": 10821.1, \"total_train_time_s\": 13.498095273971558}", "{\"n\": 1404, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.27, \"learn_time_ms\": 10830.982, \"total_train_time_s\": 14.027175664901733}", "{\"n\": 1405, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.22, \"learn_time_ms\": 10699.828, \"total_train_time_s\": 13.783084630966187}", "{\"n\": 1406, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.16, \"learn_time_ms\": 10593.228, \"total_train_time_s\": 14.652251720428467}", "{\"n\": 1407, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.38, \"learn_time_ms\": 10681.092, \"total_train_time_s\": 15.010819673538208}", "{\"n\": 1408, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.38, \"learn_time_ms\": 10613.59, \"total_train_time_s\": 13.904196739196777}", "{\"n\": 1409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.3, \"learn_time_ms\": 10599.114, \"total_train_time_s\": 13.844202995300293}", "{\"n\": 1410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.3, \"learn_time_ms\": 10573.138, \"total_train_time_s\": 14.516830444335938}", "{\"n\": 1411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.24, \"learn_time_ms\": 10479.64, \"total_train_time_s\": 13.864331722259521}", "{\"n\": 1412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.92, \"learn_time_ms\": 10400.394, \"total_train_time_s\": 13.530051469802856}", "{\"n\": 1413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.78, \"learn_time_ms\": 10499.295, \"total_train_time_s\": 14.286331415176392}", "{\"n\": 1414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.5, \"learn_time_ms\": 10544.811, \"total_train_time_s\": 14.784518957138062}", "{\"n\": 1415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.66, \"learn_time_ms\": 10626.303, \"total_train_time_s\": 14.695491552352905}", "{\"n\": 1416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.66, \"learn_time_ms\": 10522.772, \"total_train_time_s\": 13.669222116470337}", "{\"n\": 1417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.59, \"learn_time_ms\": 10399.665, \"total_train_time_s\": 13.821037530899048}", "{\"n\": 1418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.98, \"learn_time_ms\": 10408.454, \"total_train_time_s\": 14.078188180923462}", "{\"n\": 1419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.98, \"learn_time_ms\": 10401.162, \"total_train_time_s\": 14.122836112976074}", "{\"n\": 1420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.92, \"learn_time_ms\": 10444.581, \"total_train_time_s\": 15.179773330688477}", "{\"n\": 1421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.75, \"learn_time_ms\": 10584.708, \"total_train_time_s\": 14.943665981292725}", "{\"n\": 1422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.75, \"learn_time_ms\": 10713.783, \"total_train_time_s\": 14.817270278930664}", "{\"n\": 1423, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.52, \"learn_time_ms\": 10753.423, \"total_train_time_s\": 14.951967000961304}", "{\"n\": 1424, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.3, \"learn_time_ms\": 10608.48, \"total_train_time_s\": 13.056024551391602}", "{\"n\": 1425, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.46, \"learn_time_ms\": 10493.823, \"total_train_time_s\": 13.525825500488281}", "{\"n\": 1426, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.55, \"learn_time_ms\": 10574.841, \"total_train_time_s\": 14.390899419784546}", "{\"n\": 1427, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.07, \"learn_time_ms\": 10662.218, \"total_train_time_s\": 14.605671644210815}", "{\"n\": 1428, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 10708.817, \"total_train_time_s\": 14.632808685302734}", "{\"n\": 1429, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.29, \"learn_time_ms\": 10786.113, \"total_train_time_s\": 14.632022142410278}", "{\"n\": 1430, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.72, \"learn_time_ms\": 10668.148, \"total_train_time_s\": 13.980268716812134}", "{\"n\": 1431, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.38, \"learn_time_ms\": 10561.173, \"total_train_time_s\": 14.031049489974976}", "{\"n\": 1432, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.95, \"learn_time_ms\": 10501.288, \"total_train_time_s\": 13.992704391479492}", "{\"n\": 1433, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.7, \"learn_time_ms\": 10464.806, \"total_train_time_s\": 14.46531081199646}", "{\"n\": 1434, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.64, \"learn_time_ms\": 10568.616, \"total_train_time_s\": 14.284351587295532}", "{\"n\": 1435, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 10628.648, \"total_train_time_s\": 14.006925582885742}", "{\"n\": 1436, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 10608.494, \"total_train_time_s\": 14.368764400482178}", "{\"n\": 1437, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.99, \"learn_time_ms\": 10574.572, \"total_train_time_s\": 14.346073150634766}", "{\"n\": 1438, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.85, \"learn_time_ms\": 10532.38, \"total_train_time_s\": 14.012633323669434}", "{\"n\": 1439, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.98, \"learn_time_ms\": 10482.753, \"total_train_time_s\": 14.052399635314941}", "{\"n\": 1440, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.16, \"learn_time_ms\": 10538.303, \"total_train_time_s\": 14.44016695022583}", "{\"n\": 1441, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.16, \"learn_time_ms\": 10607.647, \"total_train_time_s\": 14.48317551612854}", "{\"n\": 1442, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.73, \"learn_time_ms\": 10546.388, \"total_train_time_s\": 13.474823951721191}", "{\"n\": 1443, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.38, \"learn_time_ms\": 10550.558, \"total_train_time_s\": 14.609732151031494}", "{\"n\": 1444, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.38, \"learn_time_ms\": 10594.06, \"total_train_time_s\": 14.467002630233765}", "{\"n\": 1445, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.43, \"learn_time_ms\": 10579.877, \"total_train_time_s\": 14.01578426361084}", "{\"n\": 1446, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.77, \"learn_time_ms\": 10590.331, \"total_train_time_s\": 14.449944734573364}", "{\"n\": 1447, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.77, \"learn_time_ms\": 10536.293, \"total_train_time_s\": 13.720187425613403}", "{\"n\": 1448, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.92, \"learn_time_ms\": 10543.96, \"total_train_time_s\": 13.981670141220093}", "{\"n\": 1449, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.34, \"learn_time_ms\": 10565.682, \"total_train_time_s\": 14.29411268234253}", "{\"n\": 1450, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.14, \"learn_time_ms\": 10553.125, \"total_train_time_s\": 14.377510786056519}", "{\"n\": 1451, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.4, \"learn_time_ms\": 10503.476, \"total_train_time_s\": 14.055783033370972}", "{\"n\": 1452, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.54, \"learn_time_ms\": 10579.326, \"total_train_time_s\": 14.374825477600098}", "{\"n\": 1453, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.9, \"learn_time_ms\": 10505.115, \"total_train_time_s\": 13.828026056289673}", "{\"n\": 1454, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.9, \"learn_time_ms\": 10458.707, \"total_train_time_s\": 14.03097915649414}", "{\"n\": 1455, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.09, \"learn_time_ms\": 10488.424, \"total_train_time_s\": 14.199908018112183}", "{\"n\": 1456, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.14, \"learn_time_ms\": 10491.166, \"total_train_time_s\": 14.295706510543823}", "{\"n\": 1457, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.14, \"learn_time_ms\": 10579.498, \"total_train_time_s\": 14.806711435317993}", "{\"n\": 1458, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.2, \"learn_time_ms\": 10553.247, \"total_train_time_s\": 13.962901592254639}", "{\"n\": 1459, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.56, \"learn_time_ms\": 10581.049, \"total_train_time_s\": 14.617745399475098}", "{\"n\": 1460, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.56, \"learn_time_ms\": 10491.414, \"total_train_time_s\": 13.332525730133057}", "{\"n\": 1461, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.19, \"learn_time_ms\": 10600.222, \"total_train_time_s\": 15.083497285842896}", "{\"n\": 1462, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.82, \"learn_time_ms\": 10619.382, \"total_train_time_s\": 14.530990362167358}", "{\"n\": 1463, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.82, \"learn_time_ms\": 10739.748, \"total_train_time_s\": 14.98177194595337}", "{\"n\": 1464, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.13, \"learn_time_ms\": 10751.474, \"total_train_time_s\": 14.0434889793396}", "{\"n\": 1465, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.52, \"learn_time_ms\": 10690.747, \"total_train_time_s\": 13.545642375946045}", "{\"n\": 1466, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.56, \"learn_time_ms\": 10666.89, \"total_train_time_s\": 14.22040843963623}", "{\"n\": 1467, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.14, \"learn_time_ms\": 10619.215, \"total_train_time_s\": 14.143121004104614}", "{\"n\": 1468, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.14, \"learn_time_ms\": 10507.478, \"total_train_time_s\": 12.99430227279663}", "{\"n\": 1469, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.83, \"learn_time_ms\": 10469.277, \"total_train_time_s\": 14.292500257492065}", "{\"n\": 1470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.4, \"learn_time_ms\": 10489.58, \"total_train_time_s\": 13.646236658096313}", "{\"n\": 1471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.32, \"learn_time_ms\": 10394.604, \"total_train_time_s\": 14.028028726577759}", "{\"n\": 1472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.32, \"learn_time_ms\": 10394.768, \"total_train_time_s\": 14.654906988143921}", "{\"n\": 1473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.19, \"learn_time_ms\": 10204.062, \"total_train_time_s\": 13.159317255020142}", "{\"n\": 1474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.2, \"learn_time_ms\": 10254.77, \"total_train_time_s\": 14.596924304962158}", "{\"n\": 1475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.76, \"learn_time_ms\": 10370.816, \"total_train_time_s\": 14.672807931900024}", "{\"n\": 1476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.21, \"learn_time_ms\": 10493.798, \"total_train_time_s\": 15.317626476287842}", "{\"n\": 1477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.93, \"learn_time_ms\": 10368.838, \"total_train_time_s\": 12.906331539154053}", "{\"n\": 1478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.42, \"learn_time_ms\": 10532.137, \"total_train_time_s\": 14.368659496307373}", "{\"n\": 1479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.22, \"learn_time_ms\": 10501.01, \"total_train_time_s\": 14.164345264434814}", "{\"n\": 1480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.66, \"learn_time_ms\": 10554.84, \"total_train_time_s\": 14.15170669555664}", "{\"n\": 1481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.55, \"learn_time_ms\": 10523.301, \"total_train_time_s\": 14.008828401565552}", "{\"n\": 1482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.71, \"learn_time_ms\": 10405.503, \"total_train_time_s\": 13.201001405715942}", "{\"n\": 1483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.24, \"learn_time_ms\": 10435.391, \"total_train_time_s\": 13.568038702011108}", "{\"n\": 1484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.24, \"learn_time_ms\": 10305.575, \"total_train_time_s\": 13.627065181732178}", "{\"n\": 1485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.23, \"learn_time_ms\": 10095.748, \"total_train_time_s\": 12.637608766555786}", "{\"n\": 1486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.66, \"learn_time_ms\": 9913.383, \"total_train_time_s\": 13.65254807472229}", "{\"n\": 1487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.97, \"learn_time_ms\": 9978.744, \"total_train_time_s\": 14.07971715927124}", "{\"n\": 1488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.97, \"learn_time_ms\": 9878.989, \"total_train_time_s\": 13.212342977523804}", "{\"n\": 1489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.82, \"learn_time_ms\": 9931.582, \"total_train_time_s\": 14.422608375549316}", "{\"n\": 1490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.82, \"learn_time_ms\": 9950.346, \"total_train_time_s\": 14.51670241355896}", "{\"n\": 1491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.53, \"learn_time_ms\": 10072.002, \"total_train_time_s\": 15.36479377746582}", "{\"n\": 1492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.1, \"learn_time_ms\": 10392.895, \"total_train_time_s\": 16.64223003387451}", "{\"n\": 1493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.65, \"learn_time_ms\": 10440.188, \"total_train_time_s\": 13.66470718383789}", "{\"n\": 1494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.65, \"learn_time_ms\": 10487.866, \"total_train_time_s\": 13.865182876586914}", "{\"n\": 1495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.51, \"learn_time_ms\": 10650.202, \"total_train_time_s\": 14.29053783416748}", "{\"n\": 1496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 10867.631, \"total_train_time_s\": 15.713887691497803}", "{\"n\": 1497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 10973.111, \"total_train_time_s\": 14.536151647567749}", "{\"n\": 1498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.47, \"learn_time_ms\": 11097.361, \"total_train_time_s\": 14.495378971099854}", "{\"n\": 1499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.95, \"learn_time_ms\": 11080.477, \"total_train_time_s\": 14.439599990844727}", "{\"n\": 1500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.38, \"learn_time_ms\": 11037.239, \"total_train_time_s\": 13.79584550857544}", "{\"n\": 1501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.77, \"learn_time_ms\": 10957.695, \"total_train_time_s\": 14.254788637161255}", "{\"n\": 1502, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.94, \"learn_time_ms\": 10836.528, \"total_train_time_s\": 15.332746028900146}", "{\"n\": 1503, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3260.27, \"learn_time_ms\": 10904.466, \"total_train_time_s\": 14.380468606948853}", "{\"n\": 1504, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3260.27, \"learn_time_ms\": 10808.718, \"total_train_time_s\": 13.015177249908447}", "{\"n\": 1505, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.89, \"learn_time_ms\": 10869.084, \"total_train_time_s\": 14.818539142608643}", "{\"n\": 1506, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.89, \"learn_time_ms\": 10841.457, \"total_train_time_s\": 15.745312690734863}", "{\"n\": 1507, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3270.38, \"learn_time_ms\": 10752.84, \"total_train_time_s\": 13.793510437011719}", "{\"n\": 1508, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.54, \"learn_time_ms\": 10749.507, \"total_train_time_s\": 14.644604921340942}", "{\"n\": 1509, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.57, \"learn_time_ms\": 10762.914, \"total_train_time_s\": 14.42155146598816}", "{\"n\": 1510, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.39, \"learn_time_ms\": 10753.826, \"total_train_time_s\": 13.864839792251587}", "{\"n\": 1511, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.0, \"learn_time_ms\": 10656.157, \"total_train_time_s\": 13.234943866729736}", "{\"n\": 1512, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.44, \"learn_time_ms\": 10567.688, \"total_train_time_s\": 14.433781623840332}", "{\"n\": 1513, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.15, \"learn_time_ms\": 10456.571, \"total_train_time_s\": 13.42085862159729}", "{\"n\": 1514, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.98, \"learn_time_ms\": 10557.811, \"total_train_time_s\": 14.027040719985962}", "{\"n\": 1515, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.27, \"learn_time_ms\": 10378.081, \"total_train_time_s\": 13.113717794418335}", "{\"n\": 1516, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.27, \"learn_time_ms\": 10322.4, \"total_train_time_s\": 14.861027002334595}", "{\"n\": 1517, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.37, \"learn_time_ms\": 10357.362, \"total_train_time_s\": 14.424776554107666}", "{\"n\": 1518, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.37, \"learn_time_ms\": 10301.454, \"total_train_time_s\": 14.111486434936523}", "{\"n\": 1519, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.37, \"learn_time_ms\": 10235.724, \"total_train_time_s\": 13.936343669891357}", "{\"n\": 1520, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3265.08, \"learn_time_ms\": 10272.519, \"total_train_time_s\": 14.238364696502686}", "{\"n\": 1521, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.83, \"learn_time_ms\": 10296.02, \"total_train_time_s\": 13.448348760604858}", "{\"n\": 1522, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.17, \"learn_time_ms\": 10199.716, \"total_train_time_s\": 13.64549708366394}", "{\"n\": 1523, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3254.74, \"learn_time_ms\": 10286.582, \"total_train_time_s\": 14.431579113006592}", "{\"n\": 1524, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.98, \"learn_time_ms\": 10287.632, \"total_train_time_s\": 13.842893362045288}", "{\"n\": 1525, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.85, \"learn_time_ms\": 10347.441, \"total_train_time_s\": 13.748775482177734}", "{\"n\": 1526, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3246.71, \"learn_time_ms\": 10212.422, \"total_train_time_s\": 13.428528785705566}", "{\"n\": 1527, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3240.11, \"learn_time_ms\": 10278.693, \"total_train_time_s\": 14.769001960754395}", "{\"n\": 1528, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3237.27, \"learn_time_ms\": 10309.145, \"total_train_time_s\": 14.71712875366211}", "{\"n\": 1529, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3221.87, \"learn_time_ms\": 10257.1, \"total_train_time_s\": 13.30294942855835}", "{\"n\": 1530, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.04, \"learn_time_ms\": 10232.662, \"total_train_time_s\": 13.84867525100708}", "{\"n\": 1531, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.04, \"learn_time_ms\": 10158.66, \"total_train_time_s\": 12.814770698547363}", "{\"n\": 1532, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3218.44, \"learn_time_ms\": 10202.531, \"total_train_time_s\": 14.19365906715393}", "{\"n\": 1533, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3210.03, \"learn_time_ms\": 10240.781, \"total_train_time_s\": 14.54827070236206}", "{\"n\": 1534, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3210.82, \"learn_time_ms\": 10403.21, \"total_train_time_s\": 15.514026880264282}", "{\"n\": 1535, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3210.52, \"learn_time_ms\": 10372.853, \"total_train_time_s\": 13.386812210083008}", "{\"n\": 1536, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.95, \"learn_time_ms\": 10475.906, \"total_train_time_s\": 14.686387300491333}", "{\"n\": 1537, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.95, \"learn_time_ms\": 10454.681, \"total_train_time_s\": 14.443103551864624}", "{\"n\": 1538, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.08, \"learn_time_ms\": 10453.258, \"total_train_time_s\": 14.165611743927002}", "{\"n\": 1539, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.61, \"learn_time_ms\": 10506.152, \"total_train_time_s\": 13.842133045196533}", "{\"n\": 1540, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.94, \"learn_time_ms\": 10518.413, \"total_train_time_s\": 13.98996090888977}", "{\"n\": 1541, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.86, \"learn_time_ms\": 10682.774, \"total_train_time_s\": 14.495904207229614}", "{\"n\": 1542, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.9, \"learn_time_ms\": 10721.386, \"total_train_time_s\": 14.203469276428223}", "{\"n\": 1543, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.26, \"learn_time_ms\": 10721.058, \"total_train_time_s\": 14.525212287902832}", "{\"n\": 1544, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.95, \"learn_time_ms\": 10777.519, \"total_train_time_s\": 16.267810106277466}", "{\"n\": 1545, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.1, \"learn_time_ms\": 10809.543, \"total_train_time_s\": 13.70196795463562}", "{\"n\": 1546, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.1, \"learn_time_ms\": 10736.932, \"total_train_time_s\": 14.01590895652771}", "{\"n\": 1547, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.53, \"learn_time_ms\": 10759.498, \"total_train_time_s\": 14.857775688171387}", "{\"n\": 1548, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.81, \"learn_time_ms\": 10761.598, \"total_train_time_s\": 14.310715436935425}", "{\"n\": 1549, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.81, \"learn_time_ms\": 10807.033, \"total_train_time_s\": 14.334465742111206}", "{\"n\": 1550, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.35, \"learn_time_ms\": 10819.443, \"total_train_time_s\": 14.094793558120728}", "{\"n\": 1551, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.15, \"learn_time_ms\": 10717.443, \"total_train_time_s\": 13.578086614608765}", "{\"n\": 1552, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.15, \"learn_time_ms\": 10755.31, \"total_train_time_s\": 14.593038320541382}", "{\"n\": 1553, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.89, \"learn_time_ms\": 10755.047, \"total_train_time_s\": 14.592012643814087}", "{\"n\": 1554, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.34, \"learn_time_ms\": 10613.934, \"total_train_time_s\": 14.649133920669556}", "{\"n\": 1555, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.34, \"learn_time_ms\": 10725.8, \"total_train_time_s\": 15.062291145324707}", "{\"n\": 1556, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.34, \"learn_time_ms\": 10781.79, \"total_train_time_s\": 14.602277040481567}", "{\"n\": 1557, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.63, \"learn_time_ms\": 10774.633, \"total_train_time_s\": 14.998676538467407}", "{\"n\": 1558, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.63, \"learn_time_ms\": 10728.841, \"total_train_time_s\": 14.136373281478882}", "{\"n\": 1559, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.63, \"learn_time_ms\": 10754.44, \"total_train_time_s\": 14.733836650848389}", "{\"n\": 1560, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.42, \"learn_time_ms\": 10776.711, \"total_train_time_s\": 14.445014238357544}", "{\"n\": 1561, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.56, \"learn_time_ms\": 10867.132, \"total_train_time_s\": 14.473385572433472}", "{\"n\": 1562, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.56, \"learn_time_ms\": 10932.257, \"total_train_time_s\": 15.474229574203491}", "{\"n\": 1563, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.19, \"learn_time_ms\": 10863.166, \"total_train_time_s\": 14.148267984390259}", "{\"n\": 1564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.7, \"learn_time_ms\": 10887.211, \"total_train_time_s\": 14.977152824401855}", "{\"n\": 1565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.7, \"learn_time_ms\": 10815.036, \"total_train_time_s\": 14.196962833404541}", "{\"n\": 1566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.7, \"learn_time_ms\": 10826.858, \"total_train_time_s\": 14.68105959892273}", "{\"n\": 1567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.46, \"learn_time_ms\": 10795.987, \"total_train_time_s\": 14.335551738739014}", "{\"n\": 1568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.45, \"learn_time_ms\": 10738.807, \"total_train_time_s\": 13.59720516204834}", "{\"n\": 1569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.45, \"learn_time_ms\": 10663.903, \"total_train_time_s\": 13.628976106643677}", "{\"n\": 1570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.91, \"learn_time_ms\": 10674.845, \"total_train_time_s\": 14.448778629302979}", "{\"n\": 1571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.87, \"learn_time_ms\": 10598.608, \"total_train_time_s\": 13.518160104751587}", "{\"n\": 1572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.87, \"learn_time_ms\": 10487.971, \"total_train_time_s\": 14.27075457572937}", "{\"n\": 1573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.63, \"learn_time_ms\": 10474.723, \"total_train_time_s\": 14.044838666915894}", "{\"n\": 1574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.5, \"learn_time_ms\": 10392.252, \"total_train_time_s\": 14.182012557983398}", "{\"n\": 1575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.98, \"learn_time_ms\": 10317.511, \"total_train_time_s\": 13.294949293136597}", "{\"n\": 1576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.98, \"learn_time_ms\": 10179.991, \"total_train_time_s\": 12.962413549423218}", "{\"n\": 1577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.48, \"learn_time_ms\": 10092.776, \"total_train_time_s\": 13.741132736206055}", "{\"n\": 1578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.56, \"learn_time_ms\": 10139.735, \"total_train_time_s\": 13.781632900238037}", "{\"n\": 1579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.56, \"learn_time_ms\": 10209.789, \"total_train_time_s\": 14.844181537628174}", "{\"n\": 1580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.97, \"learn_time_ms\": 10228.281, \"total_train_time_s\": 14.844929695129395}", "{\"n\": 1581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.81, \"learn_time_ms\": 10235.278, \"total_train_time_s\": 13.61702036857605}", "{\"n\": 1582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.74, \"learn_time_ms\": 10255.29, \"total_train_time_s\": 14.259073257446289}", "{\"n\": 1583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.74, \"learn_time_ms\": 10286.053, \"total_train_time_s\": 14.387714385986328}", "{\"n\": 1584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.74, \"learn_time_ms\": 10236.859, \"total_train_time_s\": 13.68038821220398}", "{\"n\": 1585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.74, \"learn_time_ms\": 10331.338, \"total_train_time_s\": 14.228427171707153}", "{\"n\": 1586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.74, \"learn_time_ms\": 10327.403, \"total_train_time_s\": 12.967048406600952}", "{\"n\": 1587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.57, \"learn_time_ms\": 10385.25, \"total_train_time_s\": 14.113818645477295}", "{\"n\": 1588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.17, \"learn_time_ms\": 10444.78, \"total_train_time_s\": 14.335169315338135}", "{\"n\": 1589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.17, \"learn_time_ms\": 10553.752, \"total_train_time_s\": 15.404467582702637}", "{\"n\": 1590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.46, \"learn_time_ms\": 10399.186, \"total_train_time_s\": 13.346060037612915}", "{\"n\": 1591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.07, \"learn_time_ms\": 10425.987, \"total_train_time_s\": 13.845228672027588}", "{\"n\": 1592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.07, \"learn_time_ms\": 10356.983, \"total_train_time_s\": 13.818497657775879}", "{\"n\": 1593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.76, \"learn_time_ms\": 10385.019, \"total_train_time_s\": 14.497790098190308}", "{\"n\": 1594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.52, \"learn_time_ms\": 10476.902, \"total_train_time_s\": 14.537345886230469}", "{\"n\": 1595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.52, \"learn_time_ms\": 10508.587, \"total_train_time_s\": 14.633705377578735}", "{\"n\": 1596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.52, \"learn_time_ms\": 10689.846, \"total_train_time_s\": 15.044762372970581}", "{\"n\": 1597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.49, \"learn_time_ms\": 10710.425, \"total_train_time_s\": 14.359770774841309}", "{\"n\": 1598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.49, \"learn_time_ms\": 10671.378, \"total_train_time_s\": 13.941880702972412}", "{\"n\": 1599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.49, \"learn_time_ms\": 10642.411, \"total_train_time_s\": 15.118726968765259}", "{\"n\": 1600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.48, \"learn_time_ms\": 10674.21, \"total_train_time_s\": 13.492638349533081}", "{\"n\": 1601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.45, \"learn_time_ms\": 10668.657, \"total_train_time_s\": 13.71714973449707}", "{\"n\": 1602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.45, \"learn_time_ms\": 10794.636, \"total_train_time_s\": 15.16682481765747}", "{\"n\": 1603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.65, \"learn_time_ms\": 10704.2, \"total_train_time_s\": 13.55492877960205}", "{\"n\": 1604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.83, \"learn_time_ms\": 10664.977, \"total_train_time_s\": 14.047647714614868}", "{\"n\": 1605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.53, \"learn_time_ms\": 10526.963, \"total_train_time_s\": 13.212559938430786}", "{\"n\": 1606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.53, \"learn_time_ms\": 10398.276, \"total_train_time_s\": 13.46670937538147}", "{\"n\": 1607, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.04, \"learn_time_ms\": 10404.664, \"total_train_time_s\": 14.537909507751465}", "{\"n\": 1608, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.72, \"learn_time_ms\": 10462.595, \"total_train_time_s\": 14.621668100357056}", "{\"n\": 1609, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.72, \"learn_time_ms\": 10380.525, \"total_train_time_s\": 14.65444564819336}", "{\"n\": 1610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.55, \"learn_time_ms\": 10416.672, \"total_train_time_s\": 13.728275299072266}", "{\"n\": 1611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.44, \"learn_time_ms\": 10350.938, \"total_train_time_s\": 13.211796045303345}", "{\"n\": 1612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.44, \"learn_time_ms\": 10195.391, \"total_train_time_s\": 13.555821895599365}", "{\"n\": 1613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.51, \"learn_time_ms\": 10345.88, \"total_train_time_s\": 14.887176275253296}", "{\"n\": 1614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.79, \"learn_time_ms\": 10290.59, \"total_train_time_s\": 13.494678497314453}", "{\"n\": 1615, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.5, \"learn_time_ms\": 10297.909, \"total_train_time_s\": 13.434917449951172}", "{\"n\": 1616, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.94, \"learn_time_ms\": 10289.449, \"total_train_time_s\": 13.747193098068237}", "{\"n\": 1617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.51, \"learn_time_ms\": 10226.506, \"total_train_time_s\": 13.903175354003906}", "{\"n\": 1618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.51, \"learn_time_ms\": 10103.415, \"total_train_time_s\": 13.46426010131836}", "{\"n\": 1619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.94, \"learn_time_ms\": 10050.068, \"total_train_time_s\": 13.877993822097778}", "{\"n\": 1620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3309.36, \"learn_time_ms\": 10068.243, \"total_train_time_s\": 13.9710111618042}", "{\"n\": 1621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3315.03, \"learn_time_ms\": 10209.033, \"total_train_time_s\": 14.57019305229187}", "{\"n\": 1622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3315.03, \"learn_time_ms\": 10344.151, \"total_train_time_s\": 14.706281900405884}", "{\"n\": 1623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3330.38, \"learn_time_ms\": 10229.817, \"total_train_time_s\": 13.70347809791565}", "{\"n\": 1624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3315.9, \"learn_time_ms\": 10260.899, \"total_train_time_s\": 13.938002586364746}", "{\"n\": 1625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3315.9, \"learn_time_ms\": 10315.363, \"total_train_time_s\": 13.902271032333374}", "{\"n\": 1626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3319.17, \"learn_time_ms\": 10343.084, \"total_train_time_s\": 14.00663423538208}", "{\"n\": 1627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3319.17, \"learn_time_ms\": 10366.081, \"total_train_time_s\": 13.987540483474731}", "{\"n\": 1628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3329.63, \"learn_time_ms\": 10452.713, \"total_train_time_s\": 14.336987733840942}", "{\"n\": 1629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3336.66, \"learn_time_ms\": 10426.892, \"total_train_time_s\": 13.846076726913452}", "{\"n\": 1630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3328.99, \"learn_time_ms\": 10436.705, \"total_train_time_s\": 14.199218511581421}", "{\"n\": 1631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.81, \"learn_time_ms\": 10400.417, \"total_train_time_s\": 14.063180208206177}", "{\"n\": 1632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.81, \"learn_time_ms\": 10385.046, \"total_train_time_s\": 14.791972637176514}", "{\"n\": 1633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3341.86, \"learn_time_ms\": 10470.966, \"total_train_time_s\": 14.614371299743652}", "{\"n\": 1634, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3341.77, \"learn_time_ms\": 10557.077, \"total_train_time_s\": 14.926816701889038}", "{\"n\": 1635, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3341.77, \"learn_time_ms\": 10492.128, \"total_train_time_s\": 13.372745037078857}", "{\"n\": 1636, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3341.77, \"learn_time_ms\": 10408.082, \"total_train_time_s\": 12.99181580543518}", "{\"n\": 1637, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3345.49, \"learn_time_ms\": 10300.011, \"total_train_time_s\": 13.025564193725586}", "{\"n\": 1638, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.98, \"learn_time_ms\": 10295.295, \"total_train_time_s\": 14.013306617736816}", "{\"n\": 1639, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.98, \"learn_time_ms\": 10392.358, \"total_train_time_s\": 14.884076833724976}", "{\"n\": 1640, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.98, \"learn_time_ms\": 10434.434, \"total_train_time_s\": 14.569653034210205}", "{\"n\": 1641, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3365.18, \"learn_time_ms\": 10534.973, \"total_train_time_s\": 15.366881608963013}", "{\"n\": 1642, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 10438.631, \"total_train_time_s\": 13.692274808883667}", "{\"n\": 1643, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 10460.138, \"total_train_time_s\": 14.928035736083984}", "{\"n\": 1644, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3369.6, \"learn_time_ms\": 10470.272, \"total_train_time_s\": 15.135875225067139}", "{\"n\": 1645, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3387.56, \"learn_time_ms\": 10591.926, \"total_train_time_s\": 14.465169191360474}", "{\"n\": 1646, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3387.56, \"learn_time_ms\": 10825.807, \"total_train_time_s\": 15.365325212478638}", "{\"n\": 1647, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3387.56, \"learn_time_ms\": 10955.978, \"total_train_time_s\": 14.354653358459473}", "{\"n\": 1648, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3382.9, \"learn_time_ms\": 10981.717, \"total_train_time_s\": 14.234318256378174}", "{\"n\": 1649, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3381.89, \"learn_time_ms\": 10873.447, \"total_train_time_s\": 13.661519765853882}", "{\"n\": 1650, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3381.89, \"learn_time_ms\": 10778.29, \"total_train_time_s\": 13.899696826934814}", "{\"n\": 1651, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3378.87, \"learn_time_ms\": 10591.437, \"total_train_time_s\": 13.252858400344849}", "{\"n\": 1652, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3376.65, \"learn_time_ms\": 10723.186, \"total_train_time_s\": 15.023353099822998}", "{\"n\": 1653, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3376.65, \"learn_time_ms\": 10647.737, \"total_train_time_s\": 14.285635232925415}", "{\"n\": 1654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3370.48, \"learn_time_ms\": 10555.513, \"total_train_time_s\": 14.038029193878174}", "{\"n\": 1655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3376.04, \"learn_time_ms\": 10478.245, \"total_train_time_s\": 13.712024688720703}", "{\"n\": 1656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3376.04, \"learn_time_ms\": 10392.603, \"total_train_time_s\": 14.398106813430786}", "{\"n\": 1657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3364.43, \"learn_time_ms\": 10427.665, \"total_train_time_s\": 14.725579023361206}", "{\"n\": 1658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3360.82, \"learn_time_ms\": 10429.795, \"total_train_time_s\": 14.549386501312256}", "{\"n\": 1659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3366.25, \"learn_time_ms\": 10528.597, \"total_train_time_s\": 14.440298080444336}", "{\"n\": 1660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3361.29, \"learn_time_ms\": 10581.734, \"total_train_time_s\": 14.154356479644775}", "{\"n\": 1661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3357.76, \"learn_time_ms\": 10620.919, \"total_train_time_s\": 13.675163984298706}", "{\"n\": 1662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 10486.588, \"total_train_time_s\": 13.512698411941528}", "{\"n\": 1663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 10478.67, \"total_train_time_s\": 14.038615942001343}", "{\"n\": 1664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3361.22, \"learn_time_ms\": 10562.717, \"total_train_time_s\": 14.966652870178223}", "{\"n\": 1665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3356.38, \"learn_time_ms\": 10525.607, \"total_train_time_s\": 13.569316148757935}", "{\"n\": 1666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3356.38, \"learn_time_ms\": 10481.984, \"total_train_time_s\": 13.86589503288269}", "{\"n\": 1667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 10449.939, \"total_train_time_s\": 14.279473066329956}", "{\"n\": 1668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 10557.984, \"total_train_time_s\": 15.737213134765625}", "{\"n\": 1669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3352.73, \"learn_time_ms\": 10581.839, \"total_train_time_s\": 14.741002082824707}", "{\"n\": 1670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3353.52, \"learn_time_ms\": 10515.092, \"total_train_time_s\": 13.559991359710693}", "{\"n\": 1671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3367.11, \"learn_time_ms\": 10471.044, \"total_train_time_s\": 13.163802862167358}", "{\"n\": 1672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3367.11, \"learn_time_ms\": 10619.93, \"total_train_time_s\": 15.142882347106934}", "{\"n\": 1673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 10553.372, \"total_train_time_s\": 13.681032180786133}", "{\"n\": 1674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3360.35, \"learn_time_ms\": 10553.588, \"total_train_time_s\": 14.903988122940063}", "{\"n\": 1675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3360.68, \"learn_time_ms\": 10674.186, \"total_train_time_s\": 14.494467973709106}", "{\"n\": 1676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3363.88, \"learn_time_ms\": 10768.73, \"total_train_time_s\": 14.886948108673096}", "{\"n\": 1677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3362.11, \"learn_time_ms\": 10727.246, \"total_train_time_s\": 13.848738193511963}", "{\"n\": 1678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3358.29, \"learn_time_ms\": 10500.833, \"total_train_time_s\": 13.321957349777222}", "{\"n\": 1679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3352.15, \"learn_time_ms\": 10448.572, \"total_train_time_s\": 14.287902593612671}", "{\"n\": 1680, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3333.84, \"learn_time_ms\": 10620.451, \"total_train_time_s\": 15.020050764083862}", "{\"n\": 1681, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3349.94, \"learn_time_ms\": 10771.507, \"total_train_time_s\": 14.873322248458862}", "{\"n\": 1682, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3336.32, \"learn_time_ms\": 10680.293, \"total_train_time_s\": 14.136369466781616}", "{\"n\": 1683, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3336.32, \"learn_time_ms\": 10746.376, \"total_train_time_s\": 14.451620817184448}", "{\"n\": 1684, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3345.71, \"learn_time_ms\": 10729.637, \"total_train_time_s\": 14.883035659790039}", "{\"n\": 1685, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3347.84, \"learn_time_ms\": 10764.998, \"total_train_time_s\": 14.84586501121521}", "{\"n\": 1686, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.25, \"learn_time_ms\": 10779.498, \"total_train_time_s\": 15.004587650299072}", "{\"n\": 1687, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.25, \"learn_time_ms\": 10834.939, \"total_train_time_s\": 14.681103467941284}", "{\"n\": 1688, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.15, \"learn_time_ms\": 11025.557, \"total_train_time_s\": 15.099116563796997}", "{\"n\": 1689, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 11198.904, \"total_train_time_s\": 15.902164220809937}", "{\"n\": 1690, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 11142.356, \"total_train_time_s\": 14.470820426940918}", "{\"n\": 1691, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 11089.141, \"total_train_time_s\": 14.117941617965698}", "{\"n\": 1692, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 11124.94, \"total_train_time_s\": 14.379488945007324}", "{\"n\": 1693, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3334.61, \"learn_time_ms\": 11065.507, \"total_train_time_s\": 13.410051822662354}", "{\"n\": 1694, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3338.92, \"learn_time_ms\": 11073.108, \"total_train_time_s\": 14.858734607696533}", "{\"n\": 1695, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3345.99, \"learn_time_ms\": 10955.414, \"total_train_time_s\": 13.791479587554932}", "{\"n\": 1696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3349.21, \"learn_time_ms\": 10852.218, \"total_train_time_s\": 13.905800819396973}", "{\"n\": 1697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3344.41, \"learn_time_ms\": 10763.594, \"total_train_time_s\": 13.45865249633789}", "{\"n\": 1698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3331.22, \"learn_time_ms\": 10614.974, \"total_train_time_s\": 13.489272356033325}", "{\"n\": 1699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3325.47, \"learn_time_ms\": 10456.384, \"total_train_time_s\": 14.28109073638916}", "{\"n\": 1700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3328.34, \"learn_time_ms\": 10469.191, \"total_train_time_s\": 15.036719560623169}", "{\"n\": 1701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3323.79, \"learn_time_ms\": 10521.218, \"total_train_time_s\": 14.793169260025024}", "{\"n\": 1702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3330.65, \"learn_time_ms\": 10350.863, \"total_train_time_s\": 12.703817129135132}", "{\"n\": 1703, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3330.65, \"learn_time_ms\": 10379.024, \"total_train_time_s\": 13.919340372085571}", "{\"n\": 1704, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3324.36, \"learn_time_ms\": 10309.899, \"total_train_time_s\": 13.992948532104492}", "{\"n\": 1705, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3318.62, \"learn_time_ms\": 10376.068, \"total_train_time_s\": 14.364044189453125}", "{\"n\": 1706, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3318.62, \"learn_time_ms\": 10441.332, \"total_train_time_s\": 14.892059087753296}", "{\"n\": 1707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3319.62, \"learn_time_ms\": 10466.874, \"total_train_time_s\": 14.037096500396729}", "{\"n\": 1708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3319.62, \"learn_time_ms\": 10496.453, \"total_train_time_s\": 14.112439393997192}", "{\"n\": 1709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3324.33, \"learn_time_ms\": 10423.729, \"total_train_time_s\": 13.547897815704346}", "{\"n\": 1710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3324.33, \"learn_time_ms\": 10335.18, \"total_train_time_s\": 13.76425838470459}", "{\"n\": 1711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3309.77, \"learn_time_ms\": 10294.787, \"total_train_time_s\": 14.538527250289917}", "{\"n\": 1712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3309.77, \"learn_time_ms\": 10467.582, \"total_train_time_s\": 14.814507246017456}", "{\"n\": 1713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3309.77, \"learn_time_ms\": 10514.554, \"total_train_time_s\": 14.080178499221802}", "{\"n\": 1714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3321.7, \"learn_time_ms\": 10594.2, \"total_train_time_s\": 14.971863746643066}", "{\"n\": 1715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3321.7, \"learn_time_ms\": 10623.216, \"total_train_time_s\": 15.050881147384644}", "{\"n\": 1716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3309.85, \"learn_time_ms\": 10578.488, \"total_train_time_s\": 14.515421390533447}", "{\"n\": 1717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3301.67, \"learn_time_ms\": 10649.145, \"total_train_time_s\": 14.745546579360962}", "{\"n\": 1718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3295.42, \"learn_time_ms\": 10592.235, \"total_train_time_s\": 13.30635142326355}", "{\"n\": 1719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3285.34, \"learn_time_ms\": 10660.074, \"total_train_time_s\": 14.377434968948364}", "{\"n\": 1720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3282.63, \"learn_time_ms\": 10805.167, \"total_train_time_s\": 15.224814653396606}", "{\"n\": 1721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3270.14, \"learn_time_ms\": 10719.514, \"total_train_time_s\": 13.585355281829834}", "{\"n\": 1722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3260.69, \"learn_time_ms\": 10735.067, \"total_train_time_s\": 14.859651327133179}", "{\"n\": 1723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3259.81, \"learn_time_ms\": 10650.245, \"total_train_time_s\": 13.395397901535034}", "{\"n\": 1724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3259.81, \"learn_time_ms\": 10549.586, \"total_train_time_s\": 14.079993963241577}", "{\"n\": 1725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3249.6, \"learn_time_ms\": 10469.289, \"total_train_time_s\": 14.055238723754883}", "{\"n\": 1726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 10438.413, \"total_train_time_s\": 14.24028491973877}", "{\"n\": 1727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 10446.355, \"total_train_time_s\": 14.484890460968018}", "{\"n\": 1728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3239.81, \"learn_time_ms\": 10502.345, \"total_train_time_s\": 14.01713752746582}", "{\"n\": 1729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.1, \"learn_time_ms\": 10566.061, \"total_train_time_s\": 14.90166425704956}", "{\"n\": 1730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.89, \"learn_time_ms\": 10463.18, \"total_train_time_s\": 14.438369989395142}", "{\"n\": 1731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.92, \"learn_time_ms\": 10459.239, \"total_train_time_s\": 13.504761457443237}", "{\"n\": 1732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3250.25, \"learn_time_ms\": 10331.336, \"total_train_time_s\": 13.2876455783844}", "{\"n\": 1733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.34, \"learn_time_ms\": 10453.406, \"total_train_time_s\": 14.964525938034058}", "{\"n\": 1734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.64, \"learn_time_ms\": 10482.431, \"total_train_time_s\": 14.243993043899536}", "{\"n\": 1735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3246.05, \"learn_time_ms\": 10484.375, \"total_train_time_s\": 13.817261219024658}", "{\"n\": 1736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3237.79, \"learn_time_ms\": 10491.581, \"total_train_time_s\": 14.103213787078857}", "{\"n\": 1737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3234.69, \"learn_time_ms\": 10388.695, \"total_train_time_s\": 13.54251217842102}", "{\"n\": 1738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3238.34, \"learn_time_ms\": 10501.899, \"total_train_time_s\": 15.17632794380188}", "{\"n\": 1739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3231.52, \"learn_time_ms\": 10442.788, \"total_train_time_s\": 14.3193941116333}", "{\"n\": 1740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.3, \"learn_time_ms\": 10514.359, \"total_train_time_s\": 14.886040925979614}", "{\"n\": 1741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.41, \"learn_time_ms\": 10580.892, \"total_train_time_s\": 14.206272602081299}", "{\"n\": 1742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3226.41, \"learn_time_ms\": 10593.323, \"total_train_time_s\": 13.40498399734497}", "{\"n\": 1743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.64, \"learn_time_ms\": 10556.729, \"total_train_time_s\": 14.115931034088135}", "{\"n\": 1744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.64, \"learn_time_ms\": 10628.687, \"total_train_time_s\": 15.147722959518433}", "{\"n\": 1745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3215.85, \"learn_time_ms\": 10629.82, \"total_train_time_s\": 13.883154153823853}", "{\"n\": 1746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.38, \"learn_time_ms\": 10598.474, \"total_train_time_s\": 13.54416036605835}", "{\"n\": 1747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.38, \"learn_time_ms\": 10581.737, \"total_train_time_s\": 13.285892724990845}", "{\"n\": 1748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3214.85, \"learn_time_ms\": 10503.436, \"total_train_time_s\": 14.53926968574524}", "{\"n\": 1749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.71, \"learn_time_ms\": 10409.704, \"total_train_time_s\": 13.323065996170044}", "{\"n\": 1750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.71, \"learn_time_ms\": 10240.283, \"total_train_time_s\": 13.279277801513672}", "{\"n\": 1751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.71, \"learn_time_ms\": 10295.469, \"total_train_time_s\": 14.677697658538818}", "{\"n\": 1752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3213.59, \"learn_time_ms\": 10352.278, \"total_train_time_s\": 14.178738117218018}", "{\"n\": 1753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3213.59, \"learn_time_ms\": 10243.684, \"total_train_time_s\": 12.99862551689148}", "{\"n\": 1754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3216.83, \"learn_time_ms\": 10212.916, \"total_train_time_s\": 14.642443656921387}", "{\"n\": 1755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3226.0, \"learn_time_ms\": 10212.2, \"total_train_time_s\": 14.038926124572754}", "{\"n\": 1756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3228.73, \"learn_time_ms\": 10279.199, \"total_train_time_s\": 14.421805620193481}", "{\"n\": 1757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3238.76, \"learn_time_ms\": 10286.958, \"total_train_time_s\": 13.520979166030884}", "{\"n\": 1758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.39, \"learn_time_ms\": 10354.631, \"total_train_time_s\": 15.271425724029541}", "{\"n\": 1759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3240.49, \"learn_time_ms\": 10331.079, \"total_train_time_s\": 13.160404205322266}", "{\"n\": 1760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3240.49, \"learn_time_ms\": 10312.217, \"total_train_time_s\": 13.255231142044067}", "{\"n\": 1761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.02, \"learn_time_ms\": 10212.959, \"total_train_time_s\": 13.787277460098267}", "{\"n\": 1762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.05, \"learn_time_ms\": 10204.57, \"total_train_time_s\": 13.964481353759766}", "{\"n\": 1763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.99, \"learn_time_ms\": 10169.237, \"total_train_time_s\": 12.761158227920532}", "{\"n\": 1764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.99, \"learn_time_ms\": 10169.106, \"total_train_time_s\": 14.572482585906982}", "{\"n\": 1765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.3, \"learn_time_ms\": 10190.255, \"total_train_time_s\": 14.031910419464111}", "{\"n\": 1766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.3, \"learn_time_ms\": 10239.445, \"total_train_time_s\": 15.047159194946289}", "{\"n\": 1767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.64, \"learn_time_ms\": 10493.92, \"total_train_time_s\": 16.002280950546265}", "{\"n\": 1768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3252.16, \"learn_time_ms\": 10375.25, \"total_train_time_s\": 13.631172180175781}", "{\"n\": 1769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.31, \"learn_time_ms\": 10466.256, \"total_train_time_s\": 14.041366577148438}", "{\"n\": 1770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.45, \"learn_time_ms\": 10586.074, \"total_train_time_s\": 14.305089235305786}", "{\"n\": 1771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.45, \"learn_time_ms\": 10605.946, \"total_train_time_s\": 14.067435026168823}", "{\"n\": 1772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3254.63, \"learn_time_ms\": 10565.155, \"total_train_time_s\": 13.659846067428589}", "{\"n\": 1773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.15, \"learn_time_ms\": 10718.857, \"total_train_time_s\": 14.323176860809326}", "{\"n\": 1774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3250.45, \"learn_time_ms\": 10798.919, \"total_train_time_s\": 15.199520111083984}", "{\"n\": 1775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3249.2, \"learn_time_ms\": 10765.448, \"total_train_time_s\": 14.092187881469727}", "{\"n\": 1776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.26, \"learn_time_ms\": 10759.981, \"total_train_time_s\": 14.8312406539917}", "{\"n\": 1777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.26, \"learn_time_ms\": 10464.76, \"total_train_time_s\": 12.974225044250488}", "{\"n\": 1778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.53, \"learn_time_ms\": 10623.349, \"total_train_time_s\": 15.299016237258911}", "{\"n\": 1779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.6, \"learn_time_ms\": 10612.909, \"total_train_time_s\": 14.020075559616089}", "{\"n\": 1780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.6, \"learn_time_ms\": 10506.964, \"total_train_time_s\": 13.303040742874146}", "{\"n\": 1781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.94, \"learn_time_ms\": 10470.764, \"total_train_time_s\": 13.449295282363892}", "{\"n\": 1782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.94, \"learn_time_ms\": 10483.592, \"total_train_time_s\": 14.059195041656494}", "{\"n\": 1783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.84, \"learn_time_ms\": 10520.635, \"total_train_time_s\": 14.664969205856323}", "{\"n\": 1784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.77, \"learn_time_ms\": 10475.907, \"total_train_time_s\": 14.741377353668213}", "{\"n\": 1785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 10453.279, \"total_train_time_s\": 13.390438556671143}", "{\"n\": 1786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 10360.118, \"total_train_time_s\": 13.872709512710571}", "{\"n\": 1787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 10407.152, \"total_train_time_s\": 13.751511335372925}", "{\"n\": 1788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.43, \"learn_time_ms\": 10268.388, \"total_train_time_s\": 13.95449686050415}", "{\"n\": 1789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3269.06, \"learn_time_ms\": 10258.252, \"total_train_time_s\": 13.756788492202759}", "{\"n\": 1790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3269.06, \"learn_time_ms\": 10381.919, \"total_train_time_s\": 14.392779111862183}", "{\"n\": 1791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.19, \"learn_time_ms\": 10452.454, \"total_train_time_s\": 14.297033071517944}", "{\"n\": 1792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.19, \"learn_time_ms\": 10515.138, \"total_train_time_s\": 14.810292482376099}", "{\"n\": 1793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.61, \"learn_time_ms\": 10420.108, \"total_train_time_s\": 13.917400121688843}", "{\"n\": 1794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.13, \"learn_time_ms\": 10303.857, \"total_train_time_s\": 13.861687183380127}", "{\"n\": 1795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.13, \"learn_time_ms\": 10296.034, \"total_train_time_s\": 13.486530065536499}", "{\"n\": 1796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.23, \"learn_time_ms\": 10278.77, \"total_train_time_s\": 13.627225875854492}", "{\"n\": 1797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.31, \"learn_time_ms\": 10333.287, \"total_train_time_s\": 13.940589666366577}", "{\"n\": 1798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.46, \"learn_time_ms\": 10377.745, \"total_train_time_s\": 14.622962713241577}", "{\"n\": 1799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.46, \"learn_time_ms\": 10288.641, \"total_train_time_s\": 13.060196876525879}", "{\"n\": 1800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.95, \"learn_time_ms\": 10307.99, \"total_train_time_s\": 14.913813829421997}", "{\"n\": 1801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.82, \"learn_time_ms\": 10228.977, \"total_train_time_s\": 13.340956926345825}", "{\"n\": 1802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.48, \"learn_time_ms\": 10183.58, \"total_train_time_s\": 14.169538974761963}", "{\"n\": 1803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.48, \"learn_time_ms\": 10281.353, \"total_train_time_s\": 14.865373849868774}", "{\"n\": 1804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3338.26, \"learn_time_ms\": 10337.016, \"total_train_time_s\": 14.225996017456055}", "{\"n\": 1805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.24, \"learn_time_ms\": 10323.043, \"total_train_time_s\": 13.492346286773682}", "{\"n\": 1806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3330.73, \"learn_time_ms\": 10370.43, \"total_train_time_s\": 14.38792872428894}", "{\"n\": 1807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3330.73, \"learn_time_ms\": 10294.94, \"total_train_time_s\": 13.385286808013916}", "{\"n\": 1808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3323.51, \"learn_time_ms\": 9895.216, \"total_train_time_s\": 10.498152494430542}", "{\"n\": 1809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.06, \"learn_time_ms\": 9646.856, \"total_train_time_s\": 10.791011333465576}", "{\"n\": 1810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.49, \"learn_time_ms\": 9230.906, \"total_train_time_s\": 10.776129961013794}", "{\"n\": 1811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3319.8, \"learn_time_ms\": 8936.983, \"total_train_time_s\": 10.770443201065063}", "{\"n\": 1812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3319.8, \"learn_time_ms\": 8848.575, \"total_train_time_s\": 13.216671705245972}", "{\"n\": 1813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3326.56, \"learn_time_ms\": 8761.155, \"total_train_time_s\": 13.72947907447815}", "{\"n\": 1814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3323.87, \"learn_time_ms\": 8853.517, \"total_train_time_s\": 15.065845012664795}", "{\"n\": 1815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3323.87, \"learn_time_ms\": 8886.21, \"total_train_time_s\": 13.679843425750732}", "{\"n\": 1816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.74, \"learn_time_ms\": 8848.384, \"total_train_time_s\": 13.854482889175415}", "{\"n\": 1817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 8955.271, \"total_train_time_s\": 14.261659622192383}", "{\"n\": 1818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 9222.293, \"total_train_time_s\": 13.333199262619019}", "{\"n\": 1819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.84, \"learn_time_ms\": 9628.027, \"total_train_time_s\": 14.612890243530273}", "{\"n\": 1820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.87, \"learn_time_ms\": 10002.15, \"total_train_time_s\": 14.39493465423584}", "{\"n\": 1821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.87, \"learn_time_ms\": 10305.512, \"total_train_time_s\": 13.59917950630188}", "{\"n\": 1822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.87, \"learn_time_ms\": 10491.448, \"total_train_time_s\": 15.183377265930176}", "{\"n\": 1823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.87, \"learn_time_ms\": 10605.65, \"total_train_time_s\": 15.143078565597534}", "{\"n\": 1824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3356.69, \"learn_time_ms\": 10484.048, \"total_train_time_s\": 14.1270592212677}", "{\"n\": 1825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3356.69, \"learn_time_ms\": 10492.791, \"total_train_time_s\": 14.084434509277344}", "{\"n\": 1826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3356.69, \"learn_time_ms\": 10513.809, \"total_train_time_s\": 14.034720182418823}", "{\"n\": 1827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.57, \"learn_time_ms\": 10541.936, \"total_train_time_s\": 14.696038961410522}", "{\"n\": 1828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.15, \"learn_time_ms\": 10692.202, \"total_train_time_s\": 14.444183349609375}", "{\"n\": 1829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.89, \"learn_time_ms\": 10638.289, \"total_train_time_s\": 13.933067798614502}", "{\"n\": 1830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.89, \"learn_time_ms\": 10617.77, \"total_train_time_s\": 14.327412366867065}", "{\"n\": 1831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.76, \"learn_time_ms\": 10772.407, \"total_train_time_s\": 15.073301792144775}", "{\"n\": 1832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.76, \"learn_time_ms\": 10614.767, \"total_train_time_s\": 13.50626254081726}", "{\"n\": 1833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.23, \"learn_time_ms\": 10481.815, \"total_train_time_s\": 13.68340802192688}", "{\"n\": 1834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.15, \"learn_time_ms\": 10564.759, \"total_train_time_s\": 15.063539981842041}", "{\"n\": 1835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.15, \"learn_time_ms\": 10597.421, \"total_train_time_s\": 14.304677724838257}", "{\"n\": 1836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.94, \"learn_time_ms\": 10563.256, \"total_train_time_s\": 13.649276971817017}", "{\"n\": 1837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.35, \"learn_time_ms\": 10438.95, \"total_train_time_s\": 13.525591135025024}", "{\"n\": 1838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.35, \"learn_time_ms\": 10382.037, \"total_train_time_s\": 14.002329349517822}", "{\"n\": 1839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.72, \"learn_time_ms\": 10269.946, \"total_train_time_s\": 12.999217748641968}", "{\"n\": 1840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.42, \"learn_time_ms\": 10311.55, \"total_train_time_s\": 14.524808168411255}", "{\"n\": 1841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.42, \"learn_time_ms\": 10290.999, \"total_train_time_s\": 15.035045385360718}", "{\"n\": 1842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.66, \"learn_time_ms\": 10282.911, \"total_train_time_s\": 13.35123324394226}", "{\"n\": 1843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.61, \"learn_time_ms\": 10376.557, \"total_train_time_s\": 14.758779287338257}", "{\"n\": 1844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.61, \"learn_time_ms\": 10230.663, \"total_train_time_s\": 13.495116233825684}", "{\"n\": 1845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.19, \"learn_time_ms\": 10261.138, \"total_train_time_s\": 14.433780670166016}", "{\"n\": 1846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3332.31, \"learn_time_ms\": 10354.576, \"total_train_time_s\": 14.818353652954102}", "{\"n\": 1847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3332.14, \"learn_time_ms\": 10501.233, \"total_train_time_s\": 14.928314208984375}", "{\"n\": 1848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3332.14, \"learn_time_ms\": 10569.861, \"total_train_time_s\": 14.59526777267456}", "{\"n\": 1849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.39, \"learn_time_ms\": 10673.326, \"total_train_time_s\": 14.182827949523926}", "{\"n\": 1850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3354.43, \"learn_time_ms\": 10775.14, \"total_train_time_s\": 15.60091257095337}", "{\"n\": 1851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3354.43, \"learn_time_ms\": 10634.368, \"total_train_time_s\": 13.499142408370972}", "{\"n\": 1852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3361.02, \"learn_time_ms\": 10699.015, \"total_train_time_s\": 14.023163080215454}", "{\"n\": 1853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.78, \"learn_time_ms\": 10705.901, \"total_train_time_s\": 14.53281569480896}", "{\"n\": 1854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.28, \"learn_time_ms\": 10852.625, \"total_train_time_s\": 14.80421233177185}", "{\"n\": 1855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.28, \"learn_time_ms\": 10754.924, \"total_train_time_s\": 13.58042860031128}", "{\"n\": 1856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.15, \"learn_time_ms\": 10780.42, \"total_train_time_s\": 14.82559847831726}", "{\"n\": 1857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.72, \"learn_time_ms\": 10739.755, \"total_train_time_s\": 14.393152952194214}", "{\"n\": 1858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.72, \"learn_time_ms\": 10702.345, \"total_train_time_s\": 14.411178827285767}", "{\"n\": 1859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.13, \"learn_time_ms\": 10664.339, \"total_train_time_s\": 13.450067043304443}", "{\"n\": 1860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.54, \"learn_time_ms\": 10494.984, \"total_train_time_s\": 14.092923164367676}", "{\"n\": 1861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.56, \"learn_time_ms\": 10475.241, \"total_train_time_s\": 13.266868591308594}", "{\"n\": 1862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3355.95, \"learn_time_ms\": 10462.424, \"total_train_time_s\": 13.886044025421143}", "{\"n\": 1863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.93, \"learn_time_ms\": 10368.434, \"total_train_time_s\": 13.751222133636475}", "{\"n\": 1864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.99, \"learn_time_ms\": 10289.697, \"total_train_time_s\": 14.065061330795288}", "{\"n\": 1865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.99, \"learn_time_ms\": 10360.29, \"total_train_time_s\": 14.297825813293457}", "{\"n\": 1866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.37, \"learn_time_ms\": 10316.073, \"total_train_time_s\": 14.327188491821289}", "{\"n\": 1867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3363.33, \"learn_time_ms\": 10222.96, \"total_train_time_s\": 13.496901035308838}", "{\"n\": 1868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.85, \"learn_time_ms\": 10295.157, \"total_train_time_s\": 15.044754981994629}", "{\"n\": 1869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.3, \"learn_time_ms\": 10264.773, \"total_train_time_s\": 13.25040054321289}", "{\"n\": 1870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.3, \"learn_time_ms\": 10237.265, \"total_train_time_s\": 13.459390640258789}", "{\"n\": 1871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.19, \"learn_time_ms\": 10246.94, \"total_train_time_s\": 13.370096683502197}", "{\"n\": 1872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.48, \"learn_time_ms\": 10270.904, \"total_train_time_s\": 13.992574453353882}", "{\"n\": 1873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.48, \"learn_time_ms\": 10313.21, \"total_train_time_s\": 14.124534606933594}", "{\"n\": 1874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.97, \"learn_time_ms\": 10418.774, \"total_train_time_s\": 15.244874477386475}", "{\"n\": 1875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.36, \"learn_time_ms\": 10487.685, \"total_train_time_s\": 14.687324523925781}", "{\"n\": 1876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.75, \"learn_time_ms\": 10528.713, \"total_train_time_s\": 14.85459566116333}", "{\"n\": 1877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3396.44, \"learn_time_ms\": 10568.101, \"total_train_time_s\": 13.741792440414429}", "{\"n\": 1878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3402.42, \"learn_time_ms\": 10518.506, \"total_train_time_s\": 14.423704385757446}", "{\"n\": 1879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3402.42, \"learn_time_ms\": 10633.659, \"total_train_time_s\": 14.520606517791748}", "{\"n\": 1880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3380.79, \"learn_time_ms\": 10635.165, \"total_train_time_s\": 13.445063591003418}", "{\"n\": 1881, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3359.9, \"learn_time_ms\": 10780.393, \"total_train_time_s\": 14.839571475982666}", "{\"n\": 1882, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3359.9, \"learn_time_ms\": 10798.82, \"total_train_time_s\": 14.126835346221924}", "{\"n\": 1883, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3355.71, \"learn_time_ms\": 10851.875, \"total_train_time_s\": 14.773052453994751}", "{\"n\": 1884, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 10689.268, \"total_train_time_s\": 13.619645357131958}", "{\"n\": 1885, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 10664.136, \"total_train_time_s\": 14.616607427597046}", "{\"n\": 1886, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 10608.988, \"total_train_time_s\": 14.39450979232788}", "{\"n\": 1887, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3348.01, \"learn_time_ms\": 10490.46, \"total_train_time_s\": 12.714147090911865}", "{\"n\": 1888, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3346.48, \"learn_time_ms\": 10454.185, \"total_train_time_s\": 14.027669668197632}", "{\"n\": 1889, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3346.48, \"learn_time_ms\": 10376.642, \"total_train_time_s\": 13.730347156524658}", "{\"n\": 1890, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3350.29, \"learn_time_ms\": 10486.966, \"total_train_time_s\": 14.500526905059814}", "{\"n\": 1891, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3350.29, \"learn_time_ms\": 10381.78, \"total_train_time_s\": 13.908703088760376}", "{\"n\": 1892, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3354.04, \"learn_time_ms\": 10330.698, \"total_train_time_s\": 13.542715072631836}", "{\"n\": 1893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3346.26, \"learn_time_ms\": 10248.308, \"total_train_time_s\": 13.858570337295532}", "{\"n\": 1894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 10392.908, \"total_train_time_s\": 14.784382343292236}", "{\"n\": 1895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3327.29, \"learn_time_ms\": 10371.138, \"total_train_time_s\": 14.445768594741821}", "{\"n\": 1896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3337.03, \"learn_time_ms\": 10320.064, \"total_train_time_s\": 13.970783948898315}", "{\"n\": 1897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3334.82, \"learn_time_ms\": 10369.193, \"total_train_time_s\": 13.50991678237915}", "{\"n\": 1898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3328.76, \"learn_time_ms\": 10254.707, \"total_train_time_s\": 12.919678926467896}", "{\"n\": 1899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3326.12, \"learn_time_ms\": 10273.367, \"total_train_time_s\": 14.037708520889282}", "{\"n\": 1900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3317.51, \"learn_time_ms\": 10316.314, \"total_train_time_s\": 14.982180118560791}", "{\"n\": 1901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3324.08, \"learn_time_ms\": 10360.704, \"total_train_time_s\": 14.339282512664795}", "{\"n\": 1902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3323.85, \"learn_time_ms\": 10365.775, \"total_train_time_s\": 13.767443895339966}", "{\"n\": 1903, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3329.94, \"learn_time_ms\": 10361.544, \"total_train_time_s\": 13.924140214920044}", "{\"n\": 1904, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3335.08, \"learn_time_ms\": 10255.423, \"total_train_time_s\": 14.004838943481445}", "{\"n\": 1905, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3343.19, \"learn_time_ms\": 10209.573, \"total_train_time_s\": 13.730822324752808}", "{\"n\": 1906, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 10298.361, \"total_train_time_s\": 14.682376861572266}", "{\"n\": 1907, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 10315.062, \"total_train_time_s\": 13.606276512145996}", "{\"n\": 1908, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.62, \"learn_time_ms\": 10455.104, \"total_train_time_s\": 14.485599279403687}", "{\"n\": 1909, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.62, \"learn_time_ms\": 10553.411, \"total_train_time_s\": 15.032909870147705}", "{\"n\": 1910, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.39, \"learn_time_ms\": 10523.777, \"total_train_time_s\": 14.903464555740356}", "{\"n\": 1911, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.43, \"learn_time_ms\": 10582.494, \"total_train_time_s\": 14.691277742385864}", "{\"n\": 1912, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.78, \"learn_time_ms\": 10483.566, \"total_train_time_s\": 12.629882574081421}", "{\"n\": 1913, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.98, \"learn_time_ms\": 10459.841, \"total_train_time_s\": 13.448208808898926}", "{\"n\": 1914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.17, \"learn_time_ms\": 10415.066, \"total_train_time_s\": 13.594203472137451}", "{\"n\": 1915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.32, \"learn_time_ms\": 10451.031, \"total_train_time_s\": 14.19706416130066}", "{\"n\": 1916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.32, \"learn_time_ms\": 10449.467, \"total_train_time_s\": 14.98281192779541}", "{\"n\": 1917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.28, \"learn_time_ms\": 10442.97, \"total_train_time_s\": 13.593847513198853}", "{\"n\": 1918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.47, \"learn_time_ms\": 10363.864, \"total_train_time_s\": 13.665887594223022}", "{\"n\": 1919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.39, \"learn_time_ms\": 10234.311, \"total_train_time_s\": 13.551920413970947}", "{\"n\": 1920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 10125.876, \"total_train_time_s\": 13.596668004989624}", "{\"n\": 1921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 10122.32, \"total_train_time_s\": 14.951443195343018}", "{\"n\": 1922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.82, \"learn_time_ms\": 10207.241, \"total_train_time_s\": 13.580704689025879}", "{\"n\": 1923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.63, \"learn_time_ms\": 10286.605, \"total_train_time_s\": 14.628222942352295}", "{\"n\": 1924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.63, \"learn_time_ms\": 10465.653, \"total_train_time_s\": 15.307100534439087}", "{\"n\": 1925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 10474.254, \"total_train_time_s\": 14.38690447807312}", "{\"n\": 1926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.72, \"learn_time_ms\": 10375.423, \"total_train_time_s\": 13.58440637588501}", "{\"n\": 1927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.72, \"learn_time_ms\": 10386.646, \"total_train_time_s\": 13.583173513412476}", "{\"n\": 1928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.94, \"learn_time_ms\": 10365.091, \"total_train_time_s\": 13.455274820327759}", "{\"n\": 1929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.94, \"learn_time_ms\": 10449.728, \"total_train_time_s\": 14.522164106369019}", "{\"n\": 1930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.73, \"learn_time_ms\": 10462.442, \"total_train_time_s\": 13.784586191177368}", "{\"n\": 1931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.97, \"learn_time_ms\": 10333.538, \"total_train_time_s\": 13.478047609329224}", "{\"n\": 1932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.97, \"learn_time_ms\": 10270.854, \"total_train_time_s\": 13.053760051727295}", "{\"n\": 1933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.49, \"learn_time_ms\": 10256.95, \"total_train_time_s\": 14.298139333724976}", "{\"n\": 1934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.61, \"learn_time_ms\": 10281.294, \"total_train_time_s\": 15.64445161819458}", "{\"n\": 1935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.01, \"learn_time_ms\": 10278.5, \"total_train_time_s\": 14.21786642074585}", "{\"n\": 1936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.13, \"learn_time_ms\": 10324.614, \"total_train_time_s\": 14.198315858840942}", "{\"n\": 1937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.56, \"learn_time_ms\": 10299.269, \"total_train_time_s\": 13.339300870895386}", "{\"n\": 1938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.56, \"learn_time_ms\": 10429.613, \"total_train_time_s\": 14.618179321289062}", "{\"n\": 1939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.95, \"learn_time_ms\": 10362.471, \"total_train_time_s\": 13.712571859359741}", "{\"n\": 1940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.8, \"learn_time_ms\": 10353.767, \"total_train_time_s\": 13.889165878295898}", "{\"n\": 1941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.8, \"learn_time_ms\": 10384.145, \"total_train_time_s\": 14.07135796546936}", "{\"n\": 1942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.87, \"learn_time_ms\": 10535.799, \"total_train_time_s\": 14.584636211395264}", "{\"n\": 1943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.87, \"learn_time_ms\": 10477.996, \"total_train_time_s\": 13.79392409324646}", "{\"n\": 1944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.8, \"learn_time_ms\": 10384.611, \"total_train_time_s\": 14.489336013793945}", "{\"n\": 1945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.7, \"learn_time_ms\": 10283.508, \"total_train_time_s\": 13.164377927780151}", "{\"n\": 1946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.63, \"learn_time_ms\": 10213.691, \"total_train_time_s\": 13.465041637420654}", "{\"n\": 1947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.63, \"learn_time_ms\": 10389.377, \"total_train_time_s\": 15.110403537750244}", "{\"n\": 1948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.73, \"learn_time_ms\": 10330.209, \"total_train_time_s\": 14.245465517044067}", "{\"n\": 1949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.86, \"learn_time_ms\": 10445.387, \"total_train_time_s\": 14.90064811706543}", "{\"n\": 1950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.86, \"learn_time_ms\": 10418.487, \"total_train_time_s\": 13.607771158218384}", "{\"n\": 1951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.86, \"learn_time_ms\": 10399.469, \"total_train_time_s\": 14.003523349761963}", "{\"n\": 1952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.78, \"learn_time_ms\": 10416.476, \"total_train_time_s\": 14.61988878250122}", "{\"n\": 1953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.39, \"learn_time_ms\": 10471.71, \"total_train_time_s\": 14.19826626777649}", "{\"n\": 1954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.39, \"learn_time_ms\": 10482.459, \"total_train_time_s\": 14.770051717758179}", "{\"n\": 1955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.38, \"learn_time_ms\": 10582.98, \"total_train_time_s\": 14.311967134475708}", "{\"n\": 1956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.38, \"learn_time_ms\": 10655.865, \"total_train_time_s\": 14.118781328201294}", "{\"n\": 1957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.18, \"learn_time_ms\": 10491.358, \"total_train_time_s\": 13.219665288925171}", "{\"n\": 1958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.18, \"learn_time_ms\": 10452.545, \"total_train_time_s\": 13.716455698013306}", "{\"n\": 1959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.18, \"learn_time_ms\": 10451.217, \"total_train_time_s\": 14.763412952423096}", "{\"n\": 1960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 10503.75, \"total_train_time_s\": 14.036022663116455}", "{\"n\": 1961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 10475.891, \"total_train_time_s\": 13.164988994598389}", "{\"n\": 1962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 10533.797, \"total_train_time_s\": 15.371874809265137}", "{\"n\": 1963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.5, \"learn_time_ms\": 10522.114, \"total_train_time_s\": 13.992562055587769}", "{\"n\": 1964, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.77, \"learn_time_ms\": 10410.039, \"total_train_time_s\": 13.445268869400024}", "{\"n\": 1965, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.85, \"learn_time_ms\": 10357.885, \"total_train_time_s\": 13.618648290634155}", "{\"n\": 1966, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.27, \"learn_time_ms\": 10371.285, \"total_train_time_s\": 14.159272193908691}", "{\"n\": 1967, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.39, \"learn_time_ms\": 10421.545, \"total_train_time_s\": 13.86213493347168}", "{\"n\": 1968, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.39, \"learn_time_ms\": 10509.654, \"total_train_time_s\": 15.047102928161621}", "{\"n\": 1969, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.64, \"learn_time_ms\": 10404.479, \"total_train_time_s\": 13.752203941345215}", "{\"n\": 1970, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.86, \"learn_time_ms\": 10393.447, \"total_train_time_s\": 13.78463864326477}", "{\"n\": 1971, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.86, \"learn_time_ms\": 10394.933, \"total_train_time_s\": 13.432261228561401}", "{\"n\": 1972, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.46, \"learn_time_ms\": 10221.021, \"total_train_time_s\": 13.41778302192688}", "{\"n\": 1973, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.36, \"learn_time_ms\": 10177.435, \"total_train_time_s\": 13.655238628387451}", "{\"n\": 1974, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.35, \"learn_time_ms\": 10191.933, \"total_train_time_s\": 13.825068473815918}", "{\"n\": 1975, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.35, \"learn_time_ms\": 10330.935, \"total_train_time_s\": 15.254240274429321}", "{\"n\": 1976, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.09, \"learn_time_ms\": 10376.895, \"total_train_time_s\": 14.572339057922363}", "{\"n\": 1977, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.32, \"learn_time_ms\": 10416.355, \"total_train_time_s\": 14.340590953826904}", "{\"n\": 1978, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.32, \"learn_time_ms\": 10362.088, \"total_train_time_s\": 14.23872423171997}", "{\"n\": 1979, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.98, \"learn_time_ms\": 10364.942, \"total_train_time_s\": 13.827913761138916}", "{\"n\": 1980, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.62, \"learn_time_ms\": 10430.196, \"total_train_time_s\": 14.673652172088623}", "{\"n\": 1981, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.62, \"learn_time_ms\": 10612.121, \"total_train_time_s\": 15.022840738296509}", "{\"n\": 1982, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.62, \"learn_time_ms\": 10681.186, \"total_train_time_s\": 14.154104709625244}", "{\"n\": 1983, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 10710.868, \"total_train_time_s\": 13.96455979347229}", "{\"n\": 1984, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 10779.629, \"total_train_time_s\": 14.258745193481445}", "{\"n\": 1985, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.18, \"learn_time_ms\": 10650.073, \"total_train_time_s\": 13.826435804367065}", "{\"n\": 1986, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.63, \"learn_time_ms\": 10660.089, \"total_train_time_s\": 14.986116647720337}", "{\"n\": 1987, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.76, \"learn_time_ms\": 10671.923, \"total_train_time_s\": 14.3033127784729}", "{\"n\": 1988, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.76, \"learn_time_ms\": 10619.755, \"total_train_time_s\": 13.657999038696289}", "{\"n\": 1989, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.78, \"learn_time_ms\": 10722.126, \"total_train_time_s\": 14.902157306671143}", "{\"n\": 1990, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.41, \"learn_time_ms\": 10660.778, \"total_train_time_s\": 13.959705591201782}", "{\"n\": 1991, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.41, \"learn_time_ms\": 10559.751, \"total_train_time_s\": 14.268856048583984}", "{\"n\": 1992, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.12, \"learn_time_ms\": 10541.196, \"total_train_time_s\": 14.133074522018433}", "{\"n\": 1993, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.85, \"learn_time_ms\": 10641.188, \"total_train_time_s\": 14.842684507369995}", "{\"n\": 1994, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.68, \"learn_time_ms\": 10579.442, \"total_train_time_s\": 13.70246696472168}", "{\"n\": 1995, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.98, \"learn_time_ms\": 10602.793, \"total_train_time_s\": 13.948073625564575}", "{\"n\": 1996, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.44, \"learn_time_ms\": 10491.469, \"total_train_time_s\": 13.765971899032593}", "{\"n\": 1997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.57, \"learn_time_ms\": 10566.33, \"total_train_time_s\": 14.94675898551941}", "{\"n\": 1998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.57, \"learn_time_ms\": 10656.211, \"total_train_time_s\": 14.61508297920227}", "{\"n\": 1999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.5, \"learn_time_ms\": 10559.089, \"total_train_time_s\": 14.002250671386719}", "{\"n\": 2000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.28, \"learn_time_ms\": 10619.159, \"total_train_time_s\": 14.736016511917114}", "{\"n\": 2001, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.75, \"learn_time_ms\": 10517.204, \"total_train_time_s\": 13.013211488723755}", "{\"n\": 2002, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3312.08, \"learn_time_ms\": 10477.949, \"total_train_time_s\": 13.69517207145691}", "{\"n\": 2003, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3312.08, \"learn_time_ms\": 10357.419, \"total_train_time_s\": 13.639607191085815}", "{\"n\": 2004, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3307.83, \"learn_time_ms\": 10398.505, \"total_train_time_s\": 14.164134740829468}", "{\"n\": 2005, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.64, \"learn_time_ms\": 10454.025, \"total_train_time_s\": 14.679945230484009}", "{\"n\": 2006, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.64, \"learn_time_ms\": 10575.221, \"total_train_time_s\": 15.177951097488403}", "{\"n\": 2007, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.79, \"learn_time_ms\": 10539.711, \"total_train_time_s\": 14.59591031074524}", "{\"n\": 2008, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3319.67, \"learn_time_ms\": 10585.611, \"total_train_time_s\": 14.895354986190796}", "{\"n\": 2009, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3324.28, \"learn_time_ms\": 10668.475, \"total_train_time_s\": 14.60365915298462}", "{\"n\": 2010, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.99, \"learn_time_ms\": 10504.506, \"total_train_time_s\": 12.954641580581665}", "{\"n\": 2011, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.87, \"learn_time_ms\": 10535.796, \"total_train_time_s\": 13.343376159667969}", "{\"n\": 2012, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.13, \"learn_time_ms\": 10607.008, \"total_train_time_s\": 14.279866456985474}", "{\"n\": 2013, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.13, \"learn_time_ms\": 10617.85, \"total_train_time_s\": 13.686162948608398}", "{\"n\": 2014, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.33, \"learn_time_ms\": 10572.311, \"total_train_time_s\": 13.762048959732056}", "{\"n\": 2015, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.33, \"learn_time_ms\": 10494.178, \"total_train_time_s\": 13.78598690032959}", "{\"n\": 2016, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.92, \"learn_time_ms\": 10450.419, \"total_train_time_s\": 14.338000774383545}", "{\"n\": 2017, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3313.2, \"learn_time_ms\": 10453.545, \"total_train_time_s\": 14.732717275619507}", "{\"n\": 2018, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3313.2, \"learn_time_ms\": 10344.489, \"total_train_time_s\": 13.714271068572998}", "{\"n\": 2019, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.38, \"learn_time_ms\": 10266.356, \"total_train_time_s\": 13.89523696899414}", "{\"n\": 2020, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.39, \"learn_time_ms\": 10536.976, \"total_train_time_s\": 15.504364013671875}", "{\"n\": 2021, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.39, \"learn_time_ms\": 10615.491, \"total_train_time_s\": 14.213032245635986}", "{\"n\": 2022, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3314.47, \"learn_time_ms\": 10588.524, \"total_train_time_s\": 13.933569192886353}", "{\"n\": 2023, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3312.98, \"learn_time_ms\": 10572.586, \"total_train_time_s\": 13.86253309249878}", "{\"n\": 2024, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3312.98, \"learn_time_ms\": 10359.023, \"total_train_time_s\": 11.487345695495605}", "{\"n\": 2025, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3315.45, \"learn_time_ms\": 10021.105, \"total_train_time_s\": 10.469269752502441}", "{\"n\": 2026, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3294.93, \"learn_time_ms\": 10002.395, \"total_train_time_s\": 14.301502227783203}", "{\"n\": 2027, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3288.0, \"learn_time_ms\": 9915.933, \"total_train_time_s\": 14.005196809768677}", "{\"n\": 2028, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3288.04, \"learn_time_ms\": 9910.999, \"total_train_time_s\": 13.773712635040283}", "{\"n\": 2029, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3291.0, \"learn_time_ms\": 9879.123, \"total_train_time_s\": 13.740674257278442}", "{\"n\": 2030, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.02, \"learn_time_ms\": 9683.998, \"total_train_time_s\": 13.656371116638184}", "{\"n\": 2031, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.02, \"learn_time_ms\": 9699.346, \"total_train_time_s\": 14.490876913070679}", "{\"n\": 2032, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.1, \"learn_time_ms\": 9675.983, \"total_train_time_s\": 14.088305234909058}", "{\"n\": 2033, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3295.51, \"learn_time_ms\": 9772.863, \"total_train_time_s\": 14.730833053588867}", "{\"n\": 2034, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3295.08, \"learn_time_ms\": 9995.53, \"total_train_time_s\": 13.687530755996704}", "{\"n\": 2035, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.98, \"learn_time_ms\": 10379.776, \"total_train_time_s\": 14.200082302093506}", "{\"n\": 2036, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3299.7, \"learn_time_ms\": 10339.048, \"total_train_time_s\": 13.918639659881592}", "{\"n\": 2037, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3299.7, \"learn_time_ms\": 10274.692, \"total_train_time_s\": 13.351308584213257}", "{\"n\": 2038, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.21, \"learn_time_ms\": 10219.742, \"total_train_time_s\": 13.166425466537476}", "{\"n\": 2039, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.28, \"learn_time_ms\": 10286.417, \"total_train_time_s\": 14.250739574432373}", "{\"n\": 2040, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3285.92, \"learn_time_ms\": 10349.557, \"total_train_time_s\": 14.256580352783203}", "{\"n\": 2041, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3285.92, \"learn_time_ms\": 10443.13, \"total_train_time_s\": 15.463824987411499}", "{\"n\": 2042, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3286.73, \"learn_time_ms\": 10434.76, \"total_train_time_s\": 13.694178581237793}", "{\"n\": 2043, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3281.3, \"learn_time_ms\": 10421.767, \"total_train_time_s\": 14.617045879364014}", "{\"n\": 2044, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3281.3, \"learn_time_ms\": 10379.145, \"total_train_time_s\": 13.404017686843872}", "{\"n\": 2045, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3276.28, \"learn_time_ms\": 10350.55, \"total_train_time_s\": 14.142167806625366}", "{\"n\": 2046, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3276.88, \"learn_time_ms\": 10408.774, \"total_train_time_s\": 14.432363271713257}", "{\"n\": 2047, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.09, \"learn_time_ms\": 10607.119, \"total_train_time_s\": 15.135970115661621}", "{\"n\": 2048, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.56, \"learn_time_ms\": 10651.189, \"total_train_time_s\": 13.546029090881348}", "{\"n\": 2049, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3274.46, \"learn_time_ms\": 10552.134, \"total_train_time_s\": 13.36616039276123}", "{\"n\": 2050, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3274.46, \"learn_time_ms\": 10595.953, \"total_train_time_s\": 14.562718391418457}", "{\"n\": 2051, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3308.65, \"learn_time_ms\": 10374.451, \"total_train_time_s\": 13.154751539230347}", "{\"n\": 2052, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3308.65, \"learn_time_ms\": 10428.036, \"total_train_time_s\": 14.411602020263672}", "{\"n\": 2053, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3308.65, \"learn_time_ms\": 10437.013, \"total_train_time_s\": 14.63485598564148}", "{\"n\": 2054, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.1, \"learn_time_ms\": 10555.208, \"total_train_time_s\": 14.544643640518188}", "{\"n\": 2055, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.43, \"learn_time_ms\": 10560.814, \"total_train_time_s\": 14.046588659286499}", "{\"n\": 2056, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3291.18, \"learn_time_ms\": 10424.478, \"total_train_time_s\": 12.974021196365356}", "{\"n\": 2057, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3290.54, \"learn_time_ms\": 10222.938, \"total_train_time_s\": 13.229542255401611}", "{\"n\": 2058, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3302.99, \"learn_time_ms\": 10214.267, \"total_train_time_s\": 13.58295488357544}", "{\"n\": 2059, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.43, \"learn_time_ms\": 10311.84, \"total_train_time_s\": 14.253012418746948}", "{\"n\": 2060, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.43, \"learn_time_ms\": 10262.628, \"total_train_time_s\": 14.369306564331055}", "{\"n\": 2061, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.05, \"learn_time_ms\": 10320.831, \"total_train_time_s\": 13.582817792892456}", "{\"n\": 2062, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3280.08, \"learn_time_ms\": 10242.811, \"total_train_time_s\": 13.55387020111084}", "{\"n\": 2063, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3276.92, \"learn_time_ms\": 10229.839, \"total_train_time_s\": 14.405390977859497}", "{\"n\": 2064, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3296.28, \"learn_time_ms\": 10130.38, \"total_train_time_s\": 13.639637231826782}", "{\"n\": 2065, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3307.35, \"learn_time_ms\": 10117.885, \"total_train_time_s\": 13.918183088302612}", "{\"n\": 2066, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.27, \"learn_time_ms\": 10256.119, \"total_train_time_s\": 14.463118314743042}", "{\"n\": 2067, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.27, \"learn_time_ms\": 10355.562, \"total_train_time_s\": 14.346577167510986}", "{\"n\": 2068, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3295.21, \"learn_time_ms\": 10388.696, \"total_train_time_s\": 14.006579160690308}", "{\"n\": 2069, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.8, \"learn_time_ms\": 10303.5, \"total_train_time_s\": 13.365715026855469}", "{\"n\": 2070, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.8, \"learn_time_ms\": 10204.852, \"total_train_time_s\": 13.088347434997559}", "{\"n\": 2071, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.3, \"learn_time_ms\": 10302.909, \"total_train_time_s\": 14.967873573303223}", "{\"n\": 2072, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3315.96, \"learn_time_ms\": 10315.764, \"total_train_time_s\": 13.782950162887573}", "{\"n\": 2073, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3315.06, \"learn_time_ms\": 10249.09, \"total_train_time_s\": 13.7483229637146}", "{\"n\": 2074, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3313.54, \"learn_time_ms\": 10339.428, \"total_train_time_s\": 14.603515863418579}", "{\"n\": 2075, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3313.54, \"learn_time_ms\": 10327.118, \"total_train_time_s\": 13.99695110321045}", "{\"n\": 2076, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3309.66, \"learn_time_ms\": 10288.579, \"total_train_time_s\": 14.212172508239746}", "{\"n\": 2077, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3298.81, \"learn_time_ms\": 10218.02, \"total_train_time_s\": 13.433074712753296}", "{\"n\": 2078, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3298.81, \"learn_time_ms\": 10208.953, \"total_train_time_s\": 13.714216470718384}", "{\"n\": 2079, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.46, \"learn_time_ms\": 10283.986, \"total_train_time_s\": 14.280565738677979}", "{\"n\": 2080, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.46, \"learn_time_ms\": 10303.819, \"total_train_time_s\": 13.538933277130127}", "{\"n\": 2081, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3300.36, \"learn_time_ms\": 10179.09, \"total_train_time_s\": 13.277628898620605}", "{\"n\": 2082, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3287.99, \"learn_time_ms\": 10172.146, \"total_train_time_s\": 13.722861051559448}", "{\"n\": 2083, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.35, \"learn_time_ms\": 10269.775, \"total_train_time_s\": 14.748768329620361}", "{\"n\": 2084, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3282.35, \"learn_time_ms\": 10332.408, \"total_train_time_s\": 15.3340904712677}", "{\"n\": 2085, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3285.97, \"learn_time_ms\": 10400.351, \"total_train_time_s\": 14.651777267456055}", "{\"n\": 2086, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3272.36, \"learn_time_ms\": 10377.559, \"total_train_time_s\": 13.974130392074585}", "{\"n\": 2087, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3275.1, \"learn_time_ms\": 10493.588, \"total_train_time_s\": 14.789201498031616}", "{\"n\": 2088, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.52, \"learn_time_ms\": 10450.554, \"total_train_time_s\": 13.534582138061523}", "{\"n\": 2089, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3265.98, \"learn_time_ms\": 10434.625, \"total_train_time_s\": 13.965790033340454}", "{\"n\": 2090, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.26, \"learn_time_ms\": 10585.754, \"total_train_time_s\": 15.148051738739014}", "{\"n\": 2091, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.26, \"learn_time_ms\": 10659.819, \"total_train_time_s\": 14.389775514602661}", "{\"n\": 2092, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.81, \"learn_time_ms\": 10611.139, \"total_train_time_s\": 13.070214748382568}", "{\"n\": 2093, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.4, \"learn_time_ms\": 10519.139, \"total_train_time_s\": 13.983869314193726}", "{\"n\": 2094, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.4, \"learn_time_ms\": 10425.747, \"total_train_time_s\": 14.000434875488281}", "{\"n\": 2095, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.63, \"learn_time_ms\": 10308.371, \"total_train_time_s\": 13.310489177703857}", "{\"n\": 2096, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.63, \"learn_time_ms\": 10237.314, \"total_train_time_s\": 13.284199476242065}", "{\"n\": 2097, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.41, \"learn_time_ms\": 10120.229, \"total_train_time_s\": 13.723584413528442}", "{\"n\": 2098, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.76, \"learn_time_ms\": 10218.804, \"total_train_time_s\": 14.446394205093384}", "{\"n\": 2099, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.76, \"learn_time_ms\": 10238.458, \"total_train_time_s\": 14.228002309799194}", "{\"n\": 2100, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.76, \"learn_time_ms\": 10101.229, \"total_train_time_s\": 13.73836374282837}", "{\"n\": 2101, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.76, \"learn_time_ms\": 10019.488, \"total_train_time_s\": 13.459380149841309}", "{\"n\": 2102, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.79, \"learn_time_ms\": 10130.32, \"total_train_time_s\": 14.032226800918579}", "{\"n\": 2103, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.15, \"learn_time_ms\": 10173.008, \"total_train_time_s\": 14.272369623184204}", "{\"n\": 2104, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.8, \"learn_time_ms\": 10085.83, \"total_train_time_s\": 13.133172988891602}", "{\"n\": 2105, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.8, \"learn_time_ms\": 10155.182, \"total_train_time_s\": 13.944081783294678}", "{\"n\": 2106, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.4, \"learn_time_ms\": 10210.185, \"total_train_time_s\": 13.82426643371582}", "{\"n\": 2107, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.42, \"learn_time_ms\": 10263.066, \"total_train_time_s\": 14.121734142303467}", "{\"n\": 2108, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.42, \"learn_time_ms\": 10160.463, \"total_train_time_s\": 13.288209915161133}", "{\"n\": 2109, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.26, \"learn_time_ms\": 10135.404, \"total_train_time_s\": 13.827643632888794}", "{\"n\": 2110, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.65, \"learn_time_ms\": 10148.543, \"total_train_time_s\": 13.543033361434937}", "{\"n\": 2111, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.4, \"learn_time_ms\": 10346.265, \"total_train_time_s\": 15.338850736618042}", "{\"n\": 2112, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.79, \"learn_time_ms\": 10384.224, \"total_train_time_s\": 14.47291374206543}", "{\"n\": 2113, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.68, \"learn_time_ms\": 10321.273, \"total_train_time_s\": 13.684538841247559}", "{\"n\": 2114, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.58, \"learn_time_ms\": 10385.185, \"total_train_time_s\": 13.784529685974121}", "{\"n\": 2115, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.94, \"learn_time_ms\": 10519.051, \"total_train_time_s\": 15.484241008758545}", "{\"n\": 2116, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.94, \"learn_time_ms\": 10543.595, \"total_train_time_s\": 13.854854345321655}", "{\"n\": 2117, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.68, \"learn_time_ms\": 10564.675, \"total_train_time_s\": 14.081551551818848}", "{\"n\": 2118, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.62, \"learn_time_ms\": 10622.452, \"total_train_time_s\": 13.870173931121826}", "{\"n\": 2119, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.62, \"learn_time_ms\": 10534.921, \"total_train_time_s\": 13.1269371509552}", "{\"n\": 2120, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.89, \"learn_time_ms\": 10427.744, \"total_train_time_s\": 12.75326681137085}", "{\"n\": 2121, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.65, \"learn_time_ms\": 10193.259, \"total_train_time_s\": 12.98652172088623}", "{\"n\": 2122, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.28, \"learn_time_ms\": 10064.971, \"total_train_time_s\": 13.29254698753357}", "{\"n\": 2123, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.22, \"learn_time_ms\": 10164.971, \"total_train_time_s\": 14.733614206314087}", "{\"n\": 2124, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.61, \"learn_time_ms\": 10223.009, \"total_train_time_s\": 14.65077018737793}", "{\"n\": 2125, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.34, \"learn_time_ms\": 10193.159, \"total_train_time_s\": 14.941139459609985}", "{\"n\": 2126, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.34, \"learn_time_ms\": 10298.854, \"total_train_time_s\": 14.92333698272705}", "{\"n\": 2127, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.88, \"learn_time_ms\": 10216.884, \"total_train_time_s\": 13.38289999961853}", "{\"n\": 2128, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.44, \"learn_time_ms\": 10243.973, \"total_train_time_s\": 14.13154673576355}", "{\"n\": 2129, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.44, \"learn_time_ms\": 10301.442, \"total_train_time_s\": 13.621002197265625}", "{\"n\": 2130, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.81, \"learn_time_ms\": 10501.023, \"total_train_time_s\": 14.490904092788696}", "{\"n\": 2131, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.66, \"learn_time_ms\": 10599.917, \"total_train_time_s\": 14.013630867004395}", "{\"n\": 2132, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.66, \"learn_time_ms\": 10716.34, \"total_train_time_s\": 14.365036964416504}", "{\"n\": 2133, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.33, \"learn_time_ms\": 10731.014, \"total_train_time_s\": 14.83385419845581}", "{\"n\": 2134, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.33, \"learn_time_ms\": 10753.453, \"total_train_time_s\": 15.033890724182129}", "{\"n\": 2135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.08, \"learn_time_ms\": 10596.187, \"total_train_time_s\": 13.43432068824768}", "{\"n\": 2136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.64, \"learn_time_ms\": 10532.983, \"total_train_time_s\": 14.386452436447144}", "{\"n\": 2137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.91, \"learn_time_ms\": 10548.706, \"total_train_time_s\": 13.43533182144165}", "{\"n\": 2138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.66, \"learn_time_ms\": 10479.122, \"total_train_time_s\": 13.601183891296387}", "{\"n\": 2139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3174.72, \"learn_time_ms\": 10506.507, \"total_train_time_s\": 13.997556209564209}", "{\"n\": 2140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3174.72, \"learn_time_ms\": 10377.547, \"total_train_time_s\": 13.262706995010376}", "{\"n\": 2141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.35, \"learn_time_ms\": 10345.991, \"total_train_time_s\": 13.627592086791992}", "{\"n\": 2142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.45, \"learn_time_ms\": 10274.317, \"total_train_time_s\": 13.793482780456543}", "{\"n\": 2143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.45, \"learn_time_ms\": 10159.585, \"total_train_time_s\": 13.947355270385742}", "{\"n\": 2144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.67, \"learn_time_ms\": 10160.967, \"total_train_time_s\": 14.702842473983765}", "{\"n\": 2145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.47, \"learn_time_ms\": 10177.787, \"total_train_time_s\": 13.936399698257446}", "{\"n\": 2146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.26, \"learn_time_ms\": 10119.676, \"total_train_time_s\": 13.774837017059326}", "{\"n\": 2147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.96, \"learn_time_ms\": 10194.282, \"total_train_time_s\": 14.288744449615479}", "{\"n\": 2148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.96, \"learn_time_ms\": 10193.517, \"total_train_time_s\": 13.414873600006104}", "{\"n\": 2149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.97, \"learn_time_ms\": 10168.525, \"total_train_time_s\": 13.755346059799194}", "{\"n\": 2150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.97, \"learn_time_ms\": 10250.838, \"total_train_time_s\": 14.405040979385376}", "{\"n\": 2151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.47, \"learn_time_ms\": 10296.838, \"total_train_time_s\": 14.019616603851318}", "{\"n\": 2152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.35, \"learn_time_ms\": 10292.14, \"total_train_time_s\": 13.87049150466919}", "{\"n\": 2153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.12, \"learn_time_ms\": 10414.189, \"total_train_time_s\": 15.282349109649658}", "{\"n\": 2154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.18, \"learn_time_ms\": 10280.719, \"total_train_time_s\": 13.243052244186401}", "{\"n\": 2155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.74, \"learn_time_ms\": 10317.341, \"total_train_time_s\": 13.873119592666626}", "{\"n\": 2156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.74, \"learn_time_ms\": 10338.614, \"total_train_time_s\": 14.031059265136719}", "{\"n\": 2157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.89, \"learn_time_ms\": 10365.159, \"total_train_time_s\": 14.803311347961426}", "{\"n\": 2158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.4, \"learn_time_ms\": 10494.453, \"total_train_time_s\": 15.014598369598389}", "{\"n\": 2159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.94, \"learn_time_ms\": 10530.842, \"total_train_time_s\": 14.052710056304932}", "{\"n\": 2160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.09, \"learn_time_ms\": 10514.444, \"total_train_time_s\": 14.071157455444336}", "{\"n\": 2161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.93, \"learn_time_ms\": 10494.145, \"total_train_time_s\": 13.775863885879517}", "{\"n\": 2162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.93, \"learn_time_ms\": 10490.348, \"total_train_time_s\": 13.62851881980896}", "{\"n\": 2163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.6, \"learn_time_ms\": 10383.786, \"total_train_time_s\": 13.99353837966919}", "{\"n\": 2164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.79, \"learn_time_ms\": 10344.948, \"total_train_time_s\": 13.061208248138428}", "{\"n\": 2165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.32, \"learn_time_ms\": 10330.595, \"total_train_time_s\": 13.88257384300232}", "{\"n\": 2166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.18, \"learn_time_ms\": 10203.196, \"total_train_time_s\": 12.84802508354187}", "{\"n\": 2167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.18, \"learn_time_ms\": 10084.29, \"total_train_time_s\": 13.5659499168396}", "{\"n\": 2168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.2, \"learn_time_ms\": 10005.834, \"total_train_time_s\": 13.876779079437256}", "{\"n\": 2169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3194.69, \"learn_time_ms\": 9946.563, \"total_train_time_s\": 13.368870973587036}", "{\"n\": 2170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3194.69, \"learn_time_ms\": 9927.021, \"total_train_time_s\": 13.907110691070557}", "{\"n\": 2171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3200.27, \"learn_time_ms\": 10017.409, \"total_train_time_s\": 14.742923736572266}", "{\"n\": 2172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3200.27, \"learn_time_ms\": 10060.048, \"total_train_time_s\": 13.904653787612915}", "{\"n\": 2173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3201.0, \"learn_time_ms\": 10171.95, \"total_train_time_s\": 14.930813312530518}", "{\"n\": 2174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3191.85, \"learn_time_ms\": 10302.295, \"total_train_time_s\": 14.224979639053345}", "{\"n\": 2175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3181.24, \"learn_time_ms\": 10333.346, \"total_train_time_s\": 14.338210105895996}", "{\"n\": 2176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3188.08, \"learn_time_ms\": 10502.526, \"total_train_time_s\": 14.476421594619751}", "{\"n\": 2177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3190.1, \"learn_time_ms\": 10677.509, \"total_train_time_s\": 14.980947256088257}", "{\"n\": 2178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3194.79, \"learn_time_ms\": 10705.889, \"total_train_time_s\": 14.521827936172485}", "{\"n\": 2179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3198.67, \"learn_time_ms\": 10690.985, \"total_train_time_s\": 13.338998556137085}", "{\"n\": 2180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3207.46, \"learn_time_ms\": 10679.862, \"total_train_time_s\": 13.725398302078247}", "{\"n\": 2181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3209.15, \"learn_time_ms\": 10599.168, \"total_train_time_s\": 13.977645874023438}", "{\"n\": 2182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3217.44, \"learn_time_ms\": 10582.904, \"total_train_time_s\": 14.138182401657104}", "{\"n\": 2183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3225.54, \"learn_time_ms\": 10506.157, \"total_train_time_s\": 14.362589836120605}", "{\"n\": 2184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3218.47, \"learn_time_ms\": 10432.126, \"total_train_time_s\": 13.475650310516357}", "{\"n\": 2185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3216.65, \"learn_time_ms\": 10380.829, \"total_train_time_s\": 13.626312494277954}", "{\"n\": 2186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3216.65, \"learn_time_ms\": 10324.637, \"total_train_time_s\": 13.916367292404175}", "{\"n\": 2187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3246.2, \"learn_time_ms\": 10231.954, \"total_train_time_s\": 14.08893370628357}", "{\"n\": 2188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3248.84, \"learn_time_ms\": 10174.668, \"total_train_time_s\": 13.767082929611206}", "{\"n\": 2189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.8, \"learn_time_ms\": 10258.179, \"total_train_time_s\": 13.992108583450317}", "{\"n\": 2190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.8, \"learn_time_ms\": 10245.557, \"total_train_time_s\": 13.450061559677124}", "{\"n\": 2191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.13, \"learn_time_ms\": 10251.428, \"total_train_time_s\": 14.165371417999268}", "{\"n\": 2192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.34, \"learn_time_ms\": 10265.057, \"total_train_time_s\": 14.119531393051147}", "{\"n\": 2193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.91, \"learn_time_ms\": 10271.331, \"total_train_time_s\": 14.344807147979736}", "{\"n\": 2194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3270.97, \"learn_time_ms\": 10339.83, \"total_train_time_s\": 14.177457332611084}", "{\"n\": 2195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.23, \"learn_time_ms\": 10439.387, \"total_train_time_s\": 14.759078979492188}", "{\"n\": 2196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3272.56, \"learn_time_ms\": 10402.115, \"total_train_time_s\": 13.49631118774414}", "{\"n\": 2197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.19, \"learn_time_ms\": 10404.752, \"total_train_time_s\": 14.11305832862854}", "{\"n\": 2198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.93, \"learn_time_ms\": 10448.958, \"total_train_time_s\": 14.031217336654663}", "{\"n\": 2199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.69, \"learn_time_ms\": 10464.75, \"total_train_time_s\": 14.361850261688232}", "{\"n\": 2200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.15, \"learn_time_ms\": 10421.529, \"total_train_time_s\": 13.111648797988892}", "{\"n\": 2201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.15, \"learn_time_ms\": 10536.369, \"total_train_time_s\": 15.417353630065918}", "{\"n\": 2202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.82, \"learn_time_ms\": 10538.76, \"total_train_time_s\": 14.058172941207886}", "{\"n\": 2203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.82, \"learn_time_ms\": 10530.176, \"total_train_time_s\": 14.379660844802856}", "{\"n\": 2204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.88, \"learn_time_ms\": 10477.926, \"total_train_time_s\": 13.707745552062988}", "{\"n\": 2205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.88, \"learn_time_ms\": 10490.872, \"total_train_time_s\": 14.657267093658447}", "{\"n\": 2206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.34, \"learn_time_ms\": 10667.041, \"total_train_time_s\": 15.139720439910889}", "{\"n\": 2207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.98, \"learn_time_ms\": 10663.228, \"total_train_time_s\": 14.25462794303894}", "{\"n\": 2208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.66, \"learn_time_ms\": 10733.343, \"total_train_time_s\": 14.729552984237671}", "{\"n\": 2209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.5, \"learn_time_ms\": 10675.291, \"total_train_time_s\": 13.67292308807373}", "{\"n\": 2210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.69, \"learn_time_ms\": 10712.945, \"total_train_time_s\": 13.497430324554443}", "{\"n\": 2211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3261.5, \"learn_time_ms\": 10635.694, \"total_train_time_s\": 14.316632747650146}", "{\"n\": 2212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.48, \"learn_time_ms\": 10606.438, \"total_train_time_s\": 13.772139310836792}", "{\"n\": 2213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.48, \"learn_time_ms\": 10598.063, \"total_train_time_s\": 14.363080739974976}", "{\"n\": 2214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.45, \"learn_time_ms\": 10689.914, \"total_train_time_s\": 14.600079536437988}", "{\"n\": 2215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.75, \"learn_time_ms\": 10590.72, \"total_train_time_s\": 13.8930344581604}", "{\"n\": 2216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.51, \"learn_time_ms\": 10501.463, \"total_train_time_s\": 14.329476594924927}", "{\"n\": 2217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3269.9, \"learn_time_ms\": 10455.32, \"total_train_time_s\": 13.957794666290283}", "{\"n\": 2218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3281.45, \"learn_time_ms\": 10397.374, \"total_train_time_s\": 14.210592985153198}", "{\"n\": 2219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3281.45, \"learn_time_ms\": 10383.27, \"total_train_time_s\": 13.546098709106445}", "{\"n\": 2220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3272.31, \"learn_time_ms\": 10563.015, \"total_train_time_s\": 15.239013671875}", "{\"n\": 2221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3275.83, \"learn_time_ms\": 10583.155, \"total_train_time_s\": 14.608155012130737}", "{\"n\": 2222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3285.42, \"learn_time_ms\": 10636.996, \"total_train_time_s\": 14.204949855804443}", "{\"n\": 2223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3287.9, \"learn_time_ms\": 10582.756, \"total_train_time_s\": 13.696335554122925}", "{\"n\": 2224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3275.58, \"learn_time_ms\": 10551.65, \"total_train_time_s\": 14.40114450454712}", "{\"n\": 2225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3274.15, \"learn_time_ms\": 10575.384, \"total_train_time_s\": 14.094408512115479}", "{\"n\": 2226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3274.15, \"learn_time_ms\": 10491.017, \"total_train_time_s\": 13.805839538574219}", "{\"n\": 2227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3277.28, \"learn_time_ms\": 10505.247, \"total_train_time_s\": 13.915326833724976}", "{\"n\": 2228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.91, \"learn_time_ms\": 10445.651, \"total_train_time_s\": 13.573176860809326}", "{\"n\": 2229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.91, \"learn_time_ms\": 10514.48, \"total_train_time_s\": 14.32252311706543}", "{\"n\": 2230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3289.42, \"learn_time_ms\": 10420.925, \"total_train_time_s\": 14.33015775680542}", "{\"n\": 2231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3272.86, \"learn_time_ms\": 10427.286, \"total_train_time_s\": 14.839040040969849}", "{\"n\": 2232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.29, \"learn_time_ms\": 10446.302, \"total_train_time_s\": 14.639086723327637}", "{\"n\": 2233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.33, \"learn_time_ms\": 10544.631, \"total_train_time_s\": 14.412862777709961}", "{\"n\": 2234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.7, \"learn_time_ms\": 10599.582, \"total_train_time_s\": 14.91878890991211}", "{\"n\": 2235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.7, \"learn_time_ms\": 10543.841, \"total_train_time_s\": 13.5884370803833}", "{\"n\": 2236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3305.5, \"learn_time_ms\": 10739.96, \"total_train_time_s\": 15.587660074234009}", "{\"n\": 2237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.32, \"learn_time_ms\": 10737.834, \"total_train_time_s\": 13.728527069091797}", "{\"n\": 2238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3307.59, \"learn_time_ms\": 10789.064, \"total_train_time_s\": 14.158124446868896}", "{\"n\": 2239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3307.59, \"learn_time_ms\": 10757.145, \"total_train_time_s\": 14.016937255859375}", "{\"n\": 2240, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3317.11, \"learn_time_ms\": 10702.92, \"total_train_time_s\": 13.824212312698364}", "{\"n\": 2241, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.83, \"learn_time_ms\": 10617.94, \"total_train_time_s\": 14.003369092941284}", "{\"n\": 2242, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.83, \"learn_time_ms\": 10644.967, \"total_train_time_s\": 14.87967586517334}", "{\"n\": 2243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.83, \"learn_time_ms\": 10638.921, \"total_train_time_s\": 14.337736368179321}", "{\"n\": 2244, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.89, \"learn_time_ms\": 10557.847, \"total_train_time_s\": 14.217340469360352}", "{\"n\": 2245, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.89, \"learn_time_ms\": 10709.253, \"total_train_time_s\": 14.850686311721802}", "{\"n\": 2246, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.89, \"learn_time_ms\": 10432.596, \"total_train_time_s\": 12.82484221458435}", "{\"n\": 2247, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.14, \"learn_time_ms\": 10437.477, \"total_train_time_s\": 13.970685005187988}", "{\"n\": 2248, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.87, \"learn_time_ms\": 10315.769, \"total_train_time_s\": 13.066088914871216}", "{\"n\": 2249, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.31, \"learn_time_ms\": 10344.904, \"total_train_time_s\": 14.260029792785645}", "{\"n\": 2250, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3355.11, \"learn_time_ms\": 10392.923, \"total_train_time_s\": 14.194667100906372}", "{\"n\": 2251, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.33, \"learn_time_ms\": 10490.517, \"total_train_time_s\": 14.911476373672485}", "{\"n\": 2252, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.53, \"learn_time_ms\": 10482.879, \"total_train_time_s\": 14.573256254196167}", "{\"n\": 2253, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.58, \"learn_time_ms\": 10367.748, \"total_train_time_s\": 13.1719810962677}", "{\"n\": 2254, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.58, \"learn_time_ms\": 10465.369, \"total_train_time_s\": 15.251397132873535}", "{\"n\": 2255, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.89, \"learn_time_ms\": 10352.093, \"total_train_time_s\": 13.783902406692505}", "{\"n\": 2256, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.12, \"learn_time_ms\": 10463.398, \"total_train_time_s\": 13.789291381835938}", "{\"n\": 2257, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.99, \"learn_time_ms\": 10486.307, \"total_train_time_s\": 14.324950218200684}", "{\"n\": 2258, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.35, \"learn_time_ms\": 10572.651, \"total_train_time_s\": 14.040444612503052}", "{\"n\": 2259, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.47, \"learn_time_ms\": 10489.486, \"total_train_time_s\": 13.43985652923584}", "{\"n\": 2260, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.88, \"learn_time_ms\": 10454.309, \"total_train_time_s\": 13.990290641784668}", "{\"n\": 2261, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.88, \"learn_time_ms\": 10347.711, \"total_train_time_s\": 13.847029209136963}", "{\"n\": 2262, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.64, \"learn_time_ms\": 10416.547, \"total_train_time_s\": 15.435618162155151}", "{\"n\": 2263, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.64, \"learn_time_ms\": 10473.545, \"total_train_time_s\": 13.970562934875488}", "{\"n\": 2264, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.39, \"learn_time_ms\": 10319.436, \"total_train_time_s\": 13.717615127563477}", "{\"n\": 2265, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.53, \"learn_time_ms\": 10320.107, \"total_train_time_s\": 14.06363844871521}", "{\"n\": 2266, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.07, \"learn_time_ms\": 10238.968, \"total_train_time_s\": 12.860033512115479}", "{\"n\": 2267, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.07, \"learn_time_ms\": 10322.97, \"total_train_time_s\": 15.216558694839478}", "{\"n\": 2268, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.93, \"learn_time_ms\": 10248.365, \"total_train_time_s\": 13.353598356246948}", "{\"n\": 2269, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 10267.881, \"total_train_time_s\": 13.715786457061768}", "{\"n\": 2270, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.89, \"learn_time_ms\": 10263.467, \"total_train_time_s\": 13.980829238891602}", "{\"n\": 2271, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.06, \"learn_time_ms\": 10330.938, \"total_train_time_s\": 14.5993332862854}", "{\"n\": 2272, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.86, \"learn_time_ms\": 10265.95, \"total_train_time_s\": 14.619988918304443}", "{\"n\": 2273, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.11, \"learn_time_ms\": 10305.279, \"total_train_time_s\": 14.266448259353638}", "{\"n\": 2274, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.94, \"learn_time_ms\": 10407.497, \"total_train_time_s\": 14.534970760345459}", "{\"n\": 2275, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.94, \"learn_time_ms\": 10511.049, \"total_train_time_s\": 14.932189702987671}", "{\"n\": 2276, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.59, \"learn_time_ms\": 10531.477, \"total_train_time_s\": 13.217193841934204}", "{\"n\": 2277, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.72, \"learn_time_ms\": 10491.176, \"total_train_time_s\": 14.485618591308594}", "{\"n\": 2278, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.72, \"learn_time_ms\": 10577.752, \"total_train_time_s\": 14.332486391067505}", "{\"n\": 2279, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3407.64, \"learn_time_ms\": 10621.887, \"total_train_time_s\": 14.107413053512573}", "{\"n\": 2280, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3411.29, \"learn_time_ms\": 10627.783, \"total_train_time_s\": 14.044344663619995}", "{\"n\": 2281, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.76, \"learn_time_ms\": 10569.947, \"total_train_time_s\": 13.917739152908325}", "{\"n\": 2282, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3401.59, \"learn_time_ms\": 10444.78, \"total_train_time_s\": 13.594050407409668}", "{\"n\": 2283, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3410.54, \"learn_time_ms\": 10307.488, \"total_train_time_s\": 12.86043381690979}", "{\"n\": 2284, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.92, \"learn_time_ms\": 10274.354, \"total_train_time_s\": 14.10884404182434}", "{\"n\": 2285, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.23, \"learn_time_ms\": 10191.238, \"total_train_time_s\": 14.33718729019165}", "{\"n\": 2286, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3422.82, \"learn_time_ms\": 10219.958, \"total_train_time_s\": 13.370633602142334}", "{\"n\": 2287, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3422.82, \"learn_time_ms\": 10149.171, \"total_train_time_s\": 13.816540241241455}", "{\"n\": 2288, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.78, \"learn_time_ms\": 10071.883, \"total_train_time_s\": 13.206281661987305}", "{\"n\": 2289, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.87, \"learn_time_ms\": 10135.425, \"total_train_time_s\": 14.714704990386963}", "{\"n\": 2290, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.87, \"learn_time_ms\": 10112.434, \"total_train_time_s\": 13.790074586868286}", "{\"n\": 2291, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3438.87, \"learn_time_ms\": 10043.894, \"total_train_time_s\": 13.062670946121216}", "{\"n\": 2292, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3439.77, \"learn_time_ms\": 10105.565, \"total_train_time_s\": 14.033818244934082}", "{\"n\": 2293, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3430.68, \"learn_time_ms\": 10215.003, \"total_train_time_s\": 14.16977310180664}", "{\"n\": 2294, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.41, \"learn_time_ms\": 10119.802, \"total_train_time_s\": 13.463654518127441}", "{\"n\": 2295, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.36, \"learn_time_ms\": 9925.815, \"total_train_time_s\": 12.110132455825806}", "{\"n\": 2296, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.34, \"learn_time_ms\": 9910.744, \"total_train_time_s\": 13.480713129043579}", "{\"n\": 2297, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.34, \"learn_time_ms\": 9903.99, \"total_train_time_s\": 14.140877962112427}", "{\"n\": 2298, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.79, \"learn_time_ms\": 10062.19, \"total_train_time_s\": 14.866132020950317}", "{\"n\": 2299, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.79, \"learn_time_ms\": 9953.527, \"total_train_time_s\": 13.523414611816406}", "{\"n\": 2300, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.85, \"learn_time_ms\": 9924.786, \"total_train_time_s\": 13.476489305496216}", "{\"n\": 2301, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3439.18, \"learn_time_ms\": 10121.251, \"total_train_time_s\": 15.383631467819214}", "{\"n\": 2302, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3449.85, \"learn_time_ms\": 10195.531, \"total_train_time_s\": 14.732021570205688}", "{\"n\": 2303, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3462.36, \"learn_time_ms\": 10208.401, \"total_train_time_s\": 14.413394451141357}", "{\"n\": 2304, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3462.31, \"learn_time_ms\": 10223.826, \"total_train_time_s\": 13.263876914978027}", "{\"n\": 2305, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3472.83, \"learn_time_ms\": 10424.843, \"total_train_time_s\": 14.053935050964355}", "{\"n\": 2306, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3472.83, \"learn_time_ms\": 10484.06, \"total_train_time_s\": 13.90987491607666}", "{\"n\": 2307, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3474.1, \"learn_time_ms\": 10531.414, \"total_train_time_s\": 14.430775880813599}", "{\"n\": 2308, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3459.41, \"learn_time_ms\": 10484.993, \"total_train_time_s\": 14.225959777832031}", "{\"n\": 2309, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3459.41, \"learn_time_ms\": 10618.972, \"total_train_time_s\": 15.116530895233154}", "{\"n\": 2310, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3459.41, \"learn_time_ms\": 10700.612, \"total_train_time_s\": 14.241598129272461}", "{\"n\": 2311, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3470.99, \"learn_time_ms\": 10577.164, \"total_train_time_s\": 13.930577516555786}", "{\"n\": 2312, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 10599.645, \"total_train_time_s\": 15.016730546951294}", "{\"n\": 2313, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 10564.704, \"total_train_time_s\": 13.91022801399231}", "{\"n\": 2314, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3461.29, \"learn_time_ms\": 10725.427, \"total_train_time_s\": 15.13631796836853}", "{\"n\": 2315, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3467.1, \"learn_time_ms\": 10634.083, \"total_train_time_s\": 13.411473989486694}", "{\"n\": 2316, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3459.26, \"learn_time_ms\": 10610.722, \"total_train_time_s\": 13.812267541885376}", "{\"n\": 2317, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3443.49, \"learn_time_ms\": 10609.581, \"total_train_time_s\": 14.308796405792236}", "{\"n\": 2318, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.32, \"learn_time_ms\": 10611.13, \"total_train_time_s\": 14.571523666381836}", "{\"n\": 2319, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.72, \"learn_time_ms\": 10571.688, \"total_train_time_s\": 14.915644407272339}", "{\"n\": 2320, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3410.92, \"learn_time_ms\": 10509.339, \"total_train_time_s\": 13.762310266494751}", "{\"n\": 2321, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.53, \"learn_time_ms\": 10561.937, \"total_train_time_s\": 14.289828300476074}", "{\"n\": 2322, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.53, \"learn_time_ms\": 10356.678, \"total_train_time_s\": 13.093929767608643}", "{\"n\": 2323, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3399.44, \"learn_time_ms\": 10379.784, \"total_train_time_s\": 14.005375623703003}", "{\"n\": 2324, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.49, \"learn_time_ms\": 10337.014, \"total_train_time_s\": 14.476001024246216}", "{\"n\": 2325, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.49, \"learn_time_ms\": 10391.235, \"total_train_time_s\": 13.988881587982178}", "{\"n\": 2326, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.33, \"learn_time_ms\": 10458.841, \"total_train_time_s\": 14.27140212059021}", "{\"n\": 2327, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3407.7, \"learn_time_ms\": 10404.867, \"total_train_time_s\": 13.578384399414062}", "{\"n\": 2328, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.37, \"learn_time_ms\": 10275.202, \"total_train_time_s\": 12.919970750808716}", "{\"n\": 2329, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.37, \"learn_time_ms\": 10155.867, \"total_train_time_s\": 13.499658584594727}", "{\"n\": 2330, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.03, \"learn_time_ms\": 10137.784, \"total_train_time_s\": 13.519645690917969}", "{\"n\": 2331, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.58, \"learn_time_ms\": 10026.088, \"total_train_time_s\": 13.51963758468628}", "{\"n\": 2332, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.58, \"learn_time_ms\": 10076.587, \"total_train_time_s\": 13.601614475250244}", "{\"n\": 2333, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.91, \"learn_time_ms\": 9958.154, \"total_train_time_s\": 12.759373664855957}", "{\"n\": 2334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.1, \"learn_time_ms\": 9937.583, \"total_train_time_s\": 14.303339719772339}", "{\"n\": 2335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.1, \"learn_time_ms\": 10009.839, \"total_train_time_s\": 14.467291355133057}", "{\"n\": 2336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.01, \"learn_time_ms\": 9909.772, \"total_train_time_s\": 13.428629398345947}", "{\"n\": 2337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.43, \"learn_time_ms\": 9950.22, \"total_train_time_s\": 14.082639217376709}", "{\"n\": 2338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.6, \"learn_time_ms\": 10060.26, \"total_train_time_s\": 14.193434238433838}", "{\"n\": 2339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.54, \"learn_time_ms\": 10055.016, \"total_train_time_s\": 13.38545560836792}", "{\"n\": 2340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.29, \"learn_time_ms\": 10121.241, \"total_train_time_s\": 14.28167986869812}", "{\"n\": 2341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.32, \"learn_time_ms\": 10252.485, \"total_train_time_s\": 14.528380632400513}", "{\"n\": 2342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.21, \"learn_time_ms\": 10268.272, \"total_train_time_s\": 13.719441652297974}", "{\"n\": 2343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.21, \"learn_time_ms\": 10340.455, \"total_train_time_s\": 13.701037645339966}", "{\"n\": 2344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.3, \"learn_time_ms\": 10297.16, \"total_train_time_s\": 14.134667873382568}", "{\"n\": 2345, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.69, \"learn_time_ms\": 10325.366, \"total_train_time_s\": 14.790987968444824}", "{\"n\": 2346, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.99, \"learn_time_ms\": 10412.276, \"total_train_time_s\": 14.12381386756897}", "{\"n\": 2347, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3399.51, \"learn_time_ms\": 10307.914, \"total_train_time_s\": 13.333386182785034}", "{\"n\": 2348, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.91, \"learn_time_ms\": 10339.792, \"total_train_time_s\": 14.592913389205933}", "{\"n\": 2349, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.91, \"learn_time_ms\": 10492.038, \"total_train_time_s\": 15.067442417144775}", "{\"n\": 2350, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.13, \"learn_time_ms\": 10400.182, \"total_train_time_s\": 13.09046459197998}", "{\"n\": 2351, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.53, \"learn_time_ms\": 10272.764, \"total_train_time_s\": 13.351738691329956}", "{\"n\": 2352, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.53, \"learn_time_ms\": 10325.114, \"total_train_time_s\": 14.220272064208984}", "{\"n\": 2353, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.77, \"learn_time_ms\": 10327.979, \"total_train_time_s\": 13.669482231140137}", "{\"n\": 2354, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.37, \"learn_time_ms\": 10368.52, \"total_train_time_s\": 14.190879106521606}", "{\"n\": 2355, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.88, \"learn_time_ms\": 10337.075, \"total_train_time_s\": 14.570815563201904}", "{\"n\": 2356, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.14, \"learn_time_ms\": 10280.941, \"total_train_time_s\": 13.84487509727478}", "{\"n\": 2357, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.28, \"learn_time_ms\": 10424.95, \"total_train_time_s\": 14.847949504852295}", "{\"n\": 2358, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3342.31, \"learn_time_ms\": 10447.733, \"total_train_time_s\": 14.685429334640503}", "{\"n\": 2359, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.74, \"learn_time_ms\": 10376.189, \"total_train_time_s\": 14.162715435028076}", "{\"n\": 2360, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.74, \"learn_time_ms\": 10390.964, \"total_train_time_s\": 13.270571947097778}", "{\"n\": 2361, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.6, \"learn_time_ms\": 10533.481, \"total_train_time_s\": 14.759144067764282}", "{\"n\": 2362, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.35, \"learn_time_ms\": 10562.028, \"total_train_time_s\": 14.34312629699707}", "{\"n\": 2363, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3354.93, \"learn_time_ms\": 10589.164, \"total_train_time_s\": 13.933674097061157}", "{\"n\": 2364, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3354.39, \"learn_time_ms\": 10588.721, \"total_train_time_s\": 14.559557914733887}", "{\"n\": 2365, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.73, \"learn_time_ms\": 10485.053, \"total_train_time_s\": 13.395642757415771}", "{\"n\": 2366, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.17, \"learn_time_ms\": 10466.798, \"total_train_time_s\": 13.846803188323975}", "{\"n\": 2367, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.6, \"learn_time_ms\": 10444.432, \"total_train_time_s\": 14.340667247772217}", "{\"n\": 2368, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.6, \"learn_time_ms\": 10377.541, \"total_train_time_s\": 14.425765752792358}", "{\"n\": 2369, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.67, \"learn_time_ms\": 10375.098, \"total_train_time_s\": 13.896892786026001}", "{\"n\": 2370, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.38, \"learn_time_ms\": 10512.783, \"total_train_time_s\": 14.739096641540527}", "{\"n\": 2371, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.38, \"learn_time_ms\": 10373.83, \"total_train_time_s\": 13.713353633880615}", "{\"n\": 2372, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.0, \"learn_time_ms\": 10321.427, \"total_train_time_s\": 14.043686866760254}", "{\"n\": 2373, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.87, \"learn_time_ms\": 10353.912, \"total_train_time_s\": 14.148860216140747}", "{\"n\": 2374, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.87, \"learn_time_ms\": 10355.954, \"total_train_time_s\": 14.447869062423706}", "{\"n\": 2375, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.93, \"learn_time_ms\": 10427.956, \"total_train_time_s\": 14.339677810668945}", "{\"n\": 2376, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.93, \"learn_time_ms\": 10525.012, \"total_train_time_s\": 14.701431035995483}", "{\"n\": 2377, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.43, \"learn_time_ms\": 10582.703, \"total_train_time_s\": 14.820844888687134}", "{\"n\": 2378, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.43, \"learn_time_ms\": 10591.864, \"total_train_time_s\": 14.091167449951172}", "{\"n\": 2379, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.14, \"learn_time_ms\": 10552.56, \"total_train_time_s\": 13.525626420974731}", "{\"n\": 2380, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.42, \"learn_time_ms\": 10469.384, \"total_train_time_s\": 13.76204228401184}", "{\"n\": 2381, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.19, \"learn_time_ms\": 10564.576, \"total_train_time_s\": 14.29742956161499}", "{\"n\": 2382, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.0, \"learn_time_ms\": 10554.236, \"total_train_time_s\": 13.846457719802856}", "{\"n\": 2383, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.92, \"learn_time_ms\": 10534.836, \"total_train_time_s\": 14.102461814880371}", "{\"n\": 2384, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.72, \"learn_time_ms\": 10516.959, \"total_train_time_s\": 14.304461240768433}", "{\"n\": 2385, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3377.84, \"learn_time_ms\": 10402.122, \"total_train_time_s\": 13.057657957077026}", "{\"n\": 2386, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.97, \"learn_time_ms\": 10311.518, \"total_train_time_s\": 13.57518219947815}", "{\"n\": 2387, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3355.18, \"learn_time_ms\": 10247.842, \"total_train_time_s\": 14.503409624099731}", "{\"n\": 2388, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3356.4, \"learn_time_ms\": 10280.293, \"total_train_time_s\": 14.372464418411255}", "{\"n\": 2389, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3339.94, \"learn_time_ms\": 10391.412, \"total_train_time_s\": 14.790186643600464}", "{\"n\": 2390, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3345.54, \"learn_time_ms\": 10448.822, \"total_train_time_s\": 14.365042448043823}", "{\"n\": 2391, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.02, \"learn_time_ms\": 10423.316, \"total_train_time_s\": 13.996952772140503}", "{\"n\": 2392, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.99, \"learn_time_ms\": 10447.159, \"total_train_time_s\": 14.18480396270752}", "{\"n\": 2393, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.99, \"learn_time_ms\": 10440.516, \"total_train_time_s\": 13.949710845947266}", "{\"n\": 2394, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3347.94, \"learn_time_ms\": 10425.525, \"total_train_time_s\": 14.130609273910522}", "{\"n\": 2395, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.21, \"learn_time_ms\": 10504.648, \"total_train_time_s\": 13.767853260040283}", "{\"n\": 2396, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.21, \"learn_time_ms\": 10651.368, \"total_train_time_s\": 15.257269144058228}", "{\"n\": 2397, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.0, \"learn_time_ms\": 10709.137, \"total_train_time_s\": 14.786552906036377}", "{\"n\": 2398, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.81, \"learn_time_ms\": 10607.343, \"total_train_time_s\": 13.29707956314087}", "{\"n\": 2399, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3346.45, \"learn_time_ms\": 10554.711, \"total_train_time_s\": 14.397806167602539}", "{\"n\": 2400, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.19, \"learn_time_ms\": 10572.648, \"total_train_time_s\": 14.501497507095337}", "{\"n\": 2401, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3355.18, \"learn_time_ms\": 10478.771, \"total_train_time_s\": 13.369612693786621}", "{\"n\": 2402, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.12, \"learn_time_ms\": 10493.704, \"total_train_time_s\": 14.557464838027954}", "{\"n\": 2403, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.88, \"learn_time_ms\": 10524.72, \"total_train_time_s\": 14.367219686508179}", "{\"n\": 2404, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.88, \"learn_time_ms\": 10434.707, \"total_train_time_s\": 12.99711012840271}", "{\"n\": 2405, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.64, \"learn_time_ms\": 10350.439, \"total_train_time_s\": 12.872337341308594}", "{\"n\": 2406, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.64, \"learn_time_ms\": 10242.023, \"total_train_time_s\": 14.05723261833191}", "{\"n\": 2407, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.98, \"learn_time_ms\": 10120.725, \"total_train_time_s\": 13.694597482681274}", "{\"n\": 2408, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3363.06, \"learn_time_ms\": 10107.124, \"total_train_time_s\": 13.217203140258789}", "{\"n\": 2409, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3363.06, \"learn_time_ms\": 10090.728, \"total_train_time_s\": 14.004826545715332}", "{\"n\": 2410, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3353.73, \"learn_time_ms\": 10137.518, \"total_train_time_s\": 15.340503692626953}", "{\"n\": 2411, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.72, \"learn_time_ms\": 10256.469, \"total_train_time_s\": 14.370973348617554}", "{\"n\": 2412, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.72, \"learn_time_ms\": 10265.036, \"total_train_time_s\": 14.38476300239563}", "{\"n\": 2413, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.72, \"learn_time_ms\": 10243.934, \"total_train_time_s\": 13.933560132980347}", "{\"n\": 2414, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.52, \"learn_time_ms\": 10349.89, \"total_train_time_s\": 14.103572607040405}", "{\"n\": 2415, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.52, \"learn_time_ms\": 10564.926, \"total_train_time_s\": 15.270524978637695}", "{\"n\": 2416, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.59, \"learn_time_ms\": 10669.098, \"total_train_time_s\": 14.932400941848755}", "{\"n\": 2417, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.1, \"learn_time_ms\": 10737.019, \"total_train_time_s\": 14.434796810150146}", "{\"n\": 2418, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 10752.56, \"total_train_time_s\": 13.385170459747314}", "{\"n\": 2419, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3374.12, \"learn_time_ms\": 10777.834, \"total_train_time_s\": 14.17400074005127}", "{\"n\": 2420, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.91, \"learn_time_ms\": 10736.239, \"total_train_time_s\": 14.820487976074219}", "{\"n\": 2421, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.85, \"learn_time_ms\": 10729.467, \"total_train_time_s\": 14.330638885498047}", "{\"n\": 2422, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.44, \"learn_time_ms\": 10710.664, \"total_train_time_s\": 14.119346141815186}", "{\"n\": 2423, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.76, \"learn_time_ms\": 10643.25, \"total_train_time_s\": 13.622328519821167}", "{\"n\": 2424, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.04, \"learn_time_ms\": 10667.057, \"total_train_time_s\": 14.544631958007812}", "{\"n\": 2425, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.55, \"learn_time_ms\": 10573.119, \"total_train_time_s\": 14.329447031021118}", "{\"n\": 2426, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.55, \"learn_time_ms\": 10432.533, \"total_train_time_s\": 13.529565334320068}", "{\"n\": 2427, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.46, \"learn_time_ms\": 10400.702, \"total_train_time_s\": 14.049352407455444}", "{\"n\": 2428, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.55, \"learn_time_ms\": 10471.079, \"total_train_time_s\": 13.98897123336792}", "{\"n\": 2429, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.52, \"learn_time_ms\": 10505.998, \"total_train_time_s\": 14.652386903762817}", "{\"n\": 2430, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.52, \"learn_time_ms\": 10477.136, \"total_train_time_s\": 14.502286434173584}", "{\"n\": 2431, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3383.02, \"learn_time_ms\": 10340.416, \"total_train_time_s\": 12.977110624313354}", "{\"n\": 2432, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3383.02, \"learn_time_ms\": 10330.023, \"total_train_time_s\": 13.95926809310913}", "{\"n\": 2433, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3383.02, \"learn_time_ms\": 10379.339, \"total_train_time_s\": 13.781224727630615}", "{\"n\": 2434, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3383.57, \"learn_time_ms\": 10405.491, \"total_train_time_s\": 14.703113794326782}", "{\"n\": 2435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.46, \"learn_time_ms\": 10392.786, \"total_train_time_s\": 13.993558645248413}", "{\"n\": 2436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.46, \"learn_time_ms\": 10465.712, \"total_train_time_s\": 14.496466636657715}", "{\"n\": 2437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.45, \"learn_time_ms\": 10501.271, \"total_train_time_s\": 14.276606321334839}", "{\"n\": 2438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3413.26, \"learn_time_ms\": 10385.189, \"total_train_time_s\": 13.145386219024658}", "{\"n\": 2439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3415.48, \"learn_time_ms\": 10305.535, \"total_train_time_s\": 13.997729778289795}", "{\"n\": 2440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3422.07, \"learn_time_ms\": 10246.715, \"total_train_time_s\": 13.699915409088135}", "{\"n\": 2441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3422.07, \"learn_time_ms\": 10359.387, \"total_train_time_s\": 14.483548641204834}", "{\"n\": 2442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3421.5, \"learn_time_ms\": 10466.162, \"total_train_time_s\": 15.143684387207031}", "{\"n\": 2443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.42, \"learn_time_ms\": 10489.216, \"total_train_time_s\": 14.009360074996948}", "{\"n\": 2444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.91, \"learn_time_ms\": 10406.029, \"total_train_time_s\": 13.792776823043823}", "{\"n\": 2445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3410.28, \"learn_time_ms\": 10355.356, \"total_train_time_s\": 13.656656980514526}", "{\"n\": 2446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.21, \"learn_time_ms\": 10233.127, \"total_train_time_s\": 13.117788553237915}", "{\"n\": 2447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.21, \"learn_time_ms\": 10208.974, \"total_train_time_s\": 14.162822723388672}", "{\"n\": 2448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.21, \"learn_time_ms\": 10399.573, \"total_train_time_s\": 14.721326112747192}", "{\"n\": 2449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3388.37, \"learn_time_ms\": 10515.59, \"total_train_time_s\": 15.06561827659607}", "{\"n\": 2450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.45, \"learn_time_ms\": 10554.229, \"total_train_time_s\": 14.24758505821228}", "{\"n\": 2451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.51, \"learn_time_ms\": 10522.217, \"total_train_time_s\": 13.571815490722656}", "{\"n\": 2452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3363.71, \"learn_time_ms\": 10366.125, \"total_train_time_s\": 13.460883617401123}", "{\"n\": 2453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.84, \"learn_time_ms\": 10268.674, \"total_train_time_s\": 13.187864303588867}", "{\"n\": 2454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.82, \"learn_time_ms\": 10289.222, \"total_train_time_s\": 14.060738563537598}", "{\"n\": 2455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.82, \"learn_time_ms\": 10377.349, \"total_train_time_s\": 14.619828462600708}", "{\"n\": 2456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.25, \"learn_time_ms\": 10571.986, \"total_train_time_s\": 14.905708312988281}", "{\"n\": 2457, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.89, \"learn_time_ms\": 10608.249, \"total_train_time_s\": 14.305509567260742}", "{\"n\": 2458, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3363.25, \"learn_time_ms\": 10481.059, \"total_train_time_s\": 13.56183910369873}", "{\"n\": 2459, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.12, \"learn_time_ms\": 10307.13, \"total_train_time_s\": 13.208604097366333}", "{\"n\": 2460, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.18, \"learn_time_ms\": 10298.613, \"total_train_time_s\": 14.190732717514038}", "{\"n\": 2461, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.25, \"learn_time_ms\": 10280.062, \"total_train_time_s\": 13.560429573059082}", "{\"n\": 2462, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3361.81, \"learn_time_ms\": 10336.505, \"total_train_time_s\": 14.016042709350586}", "{\"n\": 2463, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.48, \"learn_time_ms\": 10510.494, \"total_train_time_s\": 14.991415739059448}", "{\"n\": 2464, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3361.71, \"learn_time_ms\": 10524.43, \"total_train_time_s\": 14.412881135940552}", "{\"n\": 2465, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.62, \"learn_time_ms\": 10519.101, \"total_train_time_s\": 14.248607397079468}", "{\"n\": 2466, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.62, \"learn_time_ms\": 10413.965, \"total_train_time_s\": 14.175405740737915}", "{\"n\": 2467, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.62, \"learn_time_ms\": 10354.367, \"total_train_time_s\": 14.039959907531738}", "{\"n\": 2468, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 10392.014, \"total_train_time_s\": 13.966174840927124}", "{\"n\": 2469, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 10551.68, \"total_train_time_s\": 14.773382425308228}", "{\"n\": 2470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 10551.206, \"total_train_time_s\": 14.36738133430481}", "{\"n\": 2471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.21, \"learn_time_ms\": 10624.62, \"total_train_time_s\": 14.201982736587524}", "{\"n\": 2472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.99, \"learn_time_ms\": 10625.901, \"total_train_time_s\": 13.959945678710938}", "{\"n\": 2473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.99, \"learn_time_ms\": 10487.425, \"total_train_time_s\": 13.338532447814941}", "{\"n\": 2474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3398.63, \"learn_time_ms\": 10450.869, \"total_train_time_s\": 14.017687320709229}", "{\"n\": 2475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3388.39, \"learn_time_ms\": 10383.952, \"total_train_time_s\": 13.628764867782593}", "{\"n\": 2476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.24, \"learn_time_ms\": 10439.244, \"total_train_time_s\": 14.575849771499634}", "{\"n\": 2477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3398.76, \"learn_time_ms\": 10463.574, \"total_train_time_s\": 13.964353084564209}", "{\"n\": 2478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3398.76, \"learn_time_ms\": 10466.149, \"total_train_time_s\": 14.168915033340454}", "{\"n\": 2479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.09, \"learn_time_ms\": 10377.347, \"total_train_time_s\": 14.004649877548218}", "{\"n\": 2480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.72, \"learn_time_ms\": 10408.086, \"total_train_time_s\": 14.266958236694336}", "{\"n\": 2481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.02, \"learn_time_ms\": 10390.041, \"total_train_time_s\": 14.075678825378418}", "{\"n\": 2482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.93, \"learn_time_ms\": 10386.07, \"total_train_time_s\": 13.961035013198853}", "{\"n\": 2483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.93, \"learn_time_ms\": 10455.953, \"total_train_time_s\": 14.182612419128418}", "{\"n\": 2484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 10381.801, \"total_train_time_s\": 13.159873723983765}", "{\"n\": 2485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.32, \"learn_time_ms\": 10490.181, \"total_train_time_s\": 14.925231456756592}", "{\"n\": 2486, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3398.87, \"learn_time_ms\": 10512.223, \"total_train_time_s\": 14.856236696243286}", "{\"n\": 2487, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.91, \"learn_time_ms\": 10513.083, \"total_train_time_s\": 14.12433648109436}", "{\"n\": 2488, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.91, \"learn_time_ms\": 10460.671, \"total_train_time_s\": 13.658214092254639}", "{\"n\": 2489, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.31, \"learn_time_ms\": 10486.825, \"total_train_time_s\": 14.269813776016235}", "{\"n\": 2490, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3416.95, \"learn_time_ms\": 10414.638, \"total_train_time_s\": 13.67012095451355}", "{\"n\": 2491, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3416.95, \"learn_time_ms\": 10414.219, \"total_train_time_s\": 14.383080005645752}", "{\"n\": 2492, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3420.19, \"learn_time_ms\": 10344.824, \"total_train_time_s\": 13.195832967758179}", "{\"n\": 2493, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3417.27, \"learn_time_ms\": 10271.427, \"total_train_time_s\": 13.502471208572388}", "{\"n\": 2494, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3422.9, \"learn_time_ms\": 10419.038, \"total_train_time_s\": 14.669895648956299}", "{\"n\": 2495, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3423.54, \"learn_time_ms\": 10361.401, \"total_train_time_s\": 14.370635747909546}", "{\"n\": 2496, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3423.54, \"learn_time_ms\": 10179.469, \"total_train_time_s\": 12.802510499954224}", "{\"n\": 2497, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 10067.761, \"total_train_time_s\": 13.060777187347412}", "{\"n\": 2498, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 10085.525, \"total_train_time_s\": 13.607640027999878}", "{\"n\": 2499, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3410.97, \"learn_time_ms\": 10100.207, \"total_train_time_s\": 14.465147256851196}", "{\"n\": 2500, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3421.56, \"learn_time_ms\": 10171.369, \"total_train_time_s\": 14.396518468856812}", "{\"n\": 2501, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3417.66, \"learn_time_ms\": 10146.519, \"total_train_time_s\": 13.671237468719482}", "{\"n\": 2502, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3417.66, \"learn_time_ms\": 10207.841, \"total_train_time_s\": 14.152824401855469}", "{\"n\": 2503, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.58, \"learn_time_ms\": 10361.493, \"total_train_time_s\": 14.855637550354004}", "{\"n\": 2504, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3393.73, \"learn_time_ms\": 10239.264, \"total_train_time_s\": 13.291328191757202}", "{\"n\": 2505, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.67, \"learn_time_ms\": 10208.68, \"total_train_time_s\": 13.992293119430542}", "{\"n\": 2506, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.67, \"learn_time_ms\": 10302.758, \"total_train_time_s\": 13.927910804748535}", "{\"n\": 2507, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3414.99, \"learn_time_ms\": 10487.463, \"total_train_time_s\": 14.771738529205322}", "{\"n\": 2508, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3423.45, \"learn_time_ms\": 10493.518, \"total_train_time_s\": 13.80145788192749}", "{\"n\": 2509, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3423.45, \"learn_time_ms\": 10501.917, \"total_train_time_s\": 14.543717861175537}", "{\"n\": 2510, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3428.64, \"learn_time_ms\": 10506.119, \"total_train_time_s\": 14.759984731674194}", "{\"n\": 2511, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3431.14, \"learn_time_ms\": 10503.931, \"total_train_time_s\": 13.90295147895813}", "{\"n\": 2512, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3431.14, \"learn_time_ms\": 10465.144, \"total_train_time_s\": 13.770394325256348}", "{\"n\": 2513, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3431.14, \"learn_time_ms\": 10380.595, \"total_train_time_s\": 14.039570093154907}", "{\"n\": 2514, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3434.33, \"learn_time_ms\": 10554.365, \"total_train_time_s\": 15.286940336227417}", "{\"n\": 2515, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.85, \"learn_time_ms\": 10604.505, \"total_train_time_s\": 14.383527994155884}", "{\"n\": 2516, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3436.99, \"learn_time_ms\": 10581.86, \"total_train_time_s\": 13.610227108001709}", "{\"n\": 2517, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3431.02, \"learn_time_ms\": 10506.028, \"total_train_time_s\": 14.1554594039917}", "{\"n\": 2518, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.47, \"learn_time_ms\": 10559.756, \"total_train_time_s\": 14.444843053817749}", "{\"n\": 2519, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3455.15, \"learn_time_ms\": 10499.596, \"total_train_time_s\": 14.221132040023804}", "{\"n\": 2520, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3441.7, \"learn_time_ms\": 10494.13, \"total_train_time_s\": 14.448860168457031}", "{\"n\": 2521, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3451.16, \"learn_time_ms\": 10487.574, \"total_train_time_s\": 13.68333888053894}", "{\"n\": 2522, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3463.2, \"learn_time_ms\": 10484.307, \"total_train_time_s\": 13.467278003692627}", "{\"n\": 2523, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3462.03, \"learn_time_ms\": 10473.309, \"total_train_time_s\": 13.837612390518188}", "{\"n\": 2524, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.01, \"learn_time_ms\": 10408.447, \"total_train_time_s\": 14.36230206489563}", "{\"n\": 2525, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.01, \"learn_time_ms\": 10401.676, \"total_train_time_s\": 14.383807182312012}", "{\"n\": 2526, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3457.03, \"learn_time_ms\": 10381.567, \"total_train_time_s\": 13.348958253860474}", "{\"n\": 2527, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3466.7, \"learn_time_ms\": 10306.98, \"total_train_time_s\": 13.28048062324524}", "{\"n\": 2528, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3463.0, \"learn_time_ms\": 10311.661, \"total_train_time_s\": 14.180248737335205}", "{\"n\": 2529, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3466.46, \"learn_time_ms\": 10448.518, \"total_train_time_s\": 15.212054967880249}", "{\"n\": 2530, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3475.39, \"learn_time_ms\": 10436.255, \"total_train_time_s\": 14.136703252792358}", "{\"n\": 2531, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3465.56, \"learn_time_ms\": 10440.829, \"total_train_time_s\": 13.655890941619873}", "{\"n\": 2532, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3470.36, \"learn_time_ms\": 10440.958, \"total_train_time_s\": 13.688502788543701}", "{\"n\": 2533, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3484.88, \"learn_time_ms\": 10492.746, \"total_train_time_s\": 14.579596996307373}", "{\"n\": 2534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3484.88, \"learn_time_ms\": 10544.174, \"total_train_time_s\": 14.971530437469482}", "{\"n\": 2535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3484.88, \"learn_time_ms\": 10460.549, \"total_train_time_s\": 13.592616558074951}", "{\"n\": 2536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3481.05, \"learn_time_ms\": 10577.0, \"total_train_time_s\": 14.60570216178894}", "{\"n\": 2537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3483.05, \"learn_time_ms\": 10717.515, \"total_train_time_s\": 14.572451114654541}", "{\"n\": 2538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3483.05, \"learn_time_ms\": 10715.142, \"total_train_time_s\": 14.482118368148804}", "{\"n\": 2539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3501.17, \"learn_time_ms\": 10537.315, \"total_train_time_s\": 13.529339790344238}", "{\"n\": 2540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3485.37, \"learn_time_ms\": 10545.053, \"total_train_time_s\": 14.350501537322998}", "{\"n\": 2541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3485.37, \"learn_time_ms\": 10599.83, \"total_train_time_s\": 14.264736652374268}", "{\"n\": 2542, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3492.89, \"learn_time_ms\": 10725.092, \"total_train_time_s\": 14.933556079864502}", "{\"n\": 2543, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3492.89, \"learn_time_ms\": 10708.127, \"total_train_time_s\": 14.61612057685852}", "{\"n\": 2544, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3510.52, \"learn_time_ms\": 10544.776, \"total_train_time_s\": 13.283382177352905}", "{\"n\": 2545, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3508.22, \"learn_time_ms\": 10590.477, \"total_train_time_s\": 14.00801420211792}", "{\"n\": 2546, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3498.88, \"learn_time_ms\": 10563.26, \"total_train_time_s\": 14.246384143829346}", "{\"n\": 2547, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3498.88, \"learn_time_ms\": 10477.834, \"total_train_time_s\": 14.260991334915161}", "{\"n\": 2548, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3507.69, \"learn_time_ms\": 10453.72, \"total_train_time_s\": 14.044097423553467}", "{\"n\": 2549, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3518.1, \"learn_time_ms\": 10424.357, \"total_train_time_s\": 13.188724994659424}", "{\"n\": 2550, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.4, \"learn_time_ms\": 10385.817, \"total_train_time_s\": 14.368323564529419}", "{\"n\": 2551, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.4, \"learn_time_ms\": 10419.265, \"total_train_time_s\": 14.855758428573608}", "{\"n\": 2552, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3510.6, \"learn_time_ms\": 10336.499, \"total_train_time_s\": 13.871850490570068}", "{\"n\": 2553, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3506.31, \"learn_time_ms\": 10297.703, \"total_train_time_s\": 13.815247058868408}", "{\"n\": 2554, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3499.91, \"learn_time_ms\": 10445.291, \"total_train_time_s\": 14.832741737365723}", "{\"n\": 2555, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3507.2, \"learn_time_ms\": 10459.457, \"total_train_time_s\": 14.228135824203491}", "{\"n\": 2556, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3512.59, \"learn_time_ms\": 10321.352, \"total_train_time_s\": 12.864070892333984}", "{\"n\": 2557, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3520.91, \"learn_time_ms\": 10353.409, \"total_train_time_s\": 14.059814691543579}", "{\"n\": 2558, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3520.39, \"learn_time_ms\": 10404.992, \"total_train_time_s\": 14.819495916366577}", "{\"n\": 2559, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3520.39, \"learn_time_ms\": 10556.713, \"total_train_time_s\": 15.029837369918823}", "{\"n\": 2560, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3516.04, \"learn_time_ms\": 10594.495, \"total_train_time_s\": 14.326725006103516}", "{\"n\": 2561, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3516.04, \"learn_time_ms\": 10424.72, \"total_train_time_s\": 13.052433013916016}", "{\"n\": 2562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3515.52, \"learn_time_ms\": 10475.15, \"total_train_time_s\": 14.400662660598755}", "{\"n\": 2563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3507.47, \"learn_time_ms\": 10490.56, \"total_train_time_s\": 14.091294288635254}", "{\"n\": 2564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3503.31, \"learn_time_ms\": 10318.043, \"total_train_time_s\": 13.194345474243164}", "{\"n\": 2565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3512.99, \"learn_time_ms\": 10364.357, \"total_train_time_s\": 14.866386890411377}", "{\"n\": 2566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3500.72, \"learn_time_ms\": 10572.692, \"total_train_time_s\": 15.202867269515991}", "{\"n\": 2567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3497.49, \"learn_time_ms\": 10535.858, \"total_train_time_s\": 13.98835301399231}", "{\"n\": 2568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3492.93, \"learn_time_ms\": 10423.836, \"total_train_time_s\": 13.515811920166016}", "{\"n\": 2569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3485.19, \"learn_time_ms\": 10417.506, \"total_train_time_s\": 14.525012016296387}", "{\"n\": 2570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3502.13, \"learn_time_ms\": 10478.672, \"total_train_time_s\": 14.978107690811157}", "{\"n\": 2571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3490.28, \"learn_time_ms\": 10503.256, \"total_train_time_s\": 13.146231174468994}", "{\"n\": 2572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3490.28, \"learn_time_ms\": 10427.697, \"total_train_time_s\": 13.753154754638672}", "{\"n\": 2573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3503.07, \"learn_time_ms\": 10458.573, \"total_train_time_s\": 14.411906480789185}", "{\"n\": 2574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3500.54, \"learn_time_ms\": 10577.85, \"total_train_time_s\": 14.14891242980957}", "{\"n\": 2575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3492.24, \"learn_time_ms\": 10548.6, \"total_train_time_s\": 14.283864259719849}", "{\"n\": 2576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3479.87, \"learn_time_ms\": 10405.619, \"total_train_time_s\": 13.487886905670166}", "{\"n\": 2577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3491.79, \"learn_time_ms\": 10503.231, \"total_train_time_s\": 14.672573328018188}", "{\"n\": 2578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3491.79, \"learn_time_ms\": 10616.758, \"total_train_time_s\": 14.805379867553711}", "{\"n\": 2579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3492.32, \"learn_time_ms\": 10587.405, \"total_train_time_s\": 14.52342176437378}", "{\"n\": 2580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3487.91, \"learn_time_ms\": 10544.313, \"total_train_time_s\": 14.391560316085815}", "{\"n\": 2581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3482.52, \"learn_time_ms\": 10581.476, \"total_train_time_s\": 13.57264518737793}", "{\"n\": 2582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3482.52, \"learn_time_ms\": 10598.801, \"total_train_time_s\": 13.884841680526733}", "{\"n\": 2583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3491.83, \"learn_time_ms\": 10509.938, \"total_train_time_s\": 13.606092929840088}", "{\"n\": 2584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3492.03, \"learn_time_ms\": 10566.671, \"total_train_time_s\": 14.722228050231934}", "{\"n\": 2585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3492.03, \"learn_time_ms\": 10625.917, \"total_train_time_s\": 15.128528356552124}", "{\"n\": 2586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3497.55, \"learn_time_ms\": 10757.032, \"total_train_time_s\": 15.137894630432129}", "{\"n\": 2587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3482.22, \"learn_time_ms\": 10688.927, \"total_train_time_s\": 14.110990047454834}", "{\"n\": 2588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3481.44, \"learn_time_ms\": 10690.711, \"total_train_time_s\": 14.750012874603271}", "{\"n\": 2589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3476.61, \"learn_time_ms\": 10587.642, \"total_train_time_s\": 13.334001064300537}", "{\"n\": 2590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3489.0, \"learn_time_ms\": 10558.085, \"total_train_time_s\": 14.281086206436157}", "{\"n\": 2591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3489.0, \"learn_time_ms\": 10691.546, \"total_train_time_s\": 14.927021741867065}", "{\"n\": 2592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3497.36, \"learn_time_ms\": 10709.299, \"total_train_time_s\": 14.315144300460815}", "{\"n\": 2593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3497.36, \"learn_time_ms\": 10821.35, \"total_train_time_s\": 14.497027158737183}", "{\"n\": 2594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3481.22, \"learn_time_ms\": 10732.026, \"total_train_time_s\": 13.943362712860107}", "{\"n\": 2595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3481.22, \"learn_time_ms\": 10613.132, \"total_train_time_s\": 13.576788663864136}", "{\"n\": 2596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3486.69, \"learn_time_ms\": 10557.249, \"total_train_time_s\": 14.479719638824463}", "{\"n\": 2597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3489.47, \"learn_time_ms\": 10516.306, \"total_train_time_s\": 13.916130304336548}", "{\"n\": 2598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3489.47, \"learn_time_ms\": 10416.742, \"total_train_time_s\": 13.482152223587036}", "{\"n\": 2599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3487.63, \"learn_time_ms\": 10396.445, \"total_train_time_s\": 13.117611646652222}", "{\"n\": 2600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3487.63, \"learn_time_ms\": 10337.611, \"total_train_time_s\": 13.62844705581665}", "{\"n\": 2601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3487.67, \"learn_time_ms\": 10123.543, \"total_train_time_s\": 12.778267621994019}", "{\"n\": 2602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3482.18, \"learn_time_ms\": 10108.24, \"total_train_time_s\": 13.882852554321289}", "{\"n\": 2603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3480.26, \"learn_time_ms\": 10109.785, \"total_train_time_s\": 14.648616075515747}", "{\"n\": 2604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3480.55, \"learn_time_ms\": 10117.67, \"total_train_time_s\": 14.017231225967407}", "{\"n\": 2605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3488.65, \"learn_time_ms\": 10181.473, \"total_train_time_s\": 14.455920457839966}", "{\"n\": 2606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3488.65, \"learn_time_ms\": 10142.146, \"total_train_time_s\": 14.072911262512207}", "{\"n\": 2607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3495.2, \"learn_time_ms\": 10197.964, \"total_train_time_s\": 14.198923587799072}", "{\"n\": 2608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3483.61, \"learn_time_ms\": 10204.291, \"total_train_time_s\": 13.776682376861572}", "{\"n\": 2609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3483.61, \"learn_time_ms\": 10242.1, \"total_train_time_s\": 13.609185934066772}", "{\"n\": 2610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3483.61, \"learn_time_ms\": 10345.911, \"total_train_time_s\": 15.028521060943604}", "{\"n\": 2611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3500.35, \"learn_time_ms\": 10533.338, \"total_train_time_s\": 14.780982494354248}", "{\"n\": 2612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3499.22, \"learn_time_ms\": 10657.214, \"total_train_time_s\": 15.23511004447937}", "{\"n\": 2613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3499.22, \"learn_time_ms\": 10556.352, \"total_train_time_s\": 13.491842269897461}", "{\"n\": 2614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3499.59, \"learn_time_ms\": 10610.891, \"total_train_time_s\": 14.547869205474854}", "{\"n\": 2615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3501.74, \"learn_time_ms\": 10494.19, \"total_train_time_s\": 13.047794580459595}", "{\"n\": 2616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3501.74, \"learn_time_ms\": 10576.879, \"total_train_time_s\": 14.951753854751587}", "{\"n\": 2617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3510.29, \"learn_time_ms\": 10509.452, \"total_train_time_s\": 13.743478775024414}", "{\"n\": 2618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3506.32, \"learn_time_ms\": 10542.096, \"total_train_time_s\": 13.924230337142944}", "{\"n\": 2619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3506.32, \"learn_time_ms\": 10577.138, \"total_train_time_s\": 13.698638439178467}", "{\"n\": 2620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3479.46, \"learn_time_ms\": 10476.07, \"total_train_time_s\": 13.56795358657837}", "{\"n\": 2621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3477.73, \"learn_time_ms\": 10481.12, \"total_train_time_s\": 14.589484214782715}", "{\"n\": 2622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3475.81, \"learn_time_ms\": 10362.155, \"total_train_time_s\": 14.005972385406494}", "{\"n\": 2623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3475.58, \"learn_time_ms\": 10463.208, \"total_train_time_s\": 14.607812643051147}", "{\"n\": 2624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3485.64, \"learn_time_ms\": 10482.575, \"total_train_time_s\": 14.869207382202148}", "{\"n\": 2625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3475.49, \"learn_time_ms\": 10524.541, \"total_train_time_s\": 13.404563426971436}", "{\"n\": 2626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3470.82, \"learn_time_ms\": 10381.454, \"total_train_time_s\": 13.541059017181396}", "{\"n\": 2627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3471.64, \"learn_time_ms\": 10441.942, \"total_train_time_s\": 14.281938076019287}", "{\"n\": 2628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3468.29, \"learn_time_ms\": 10467.273, \"total_train_time_s\": 14.3695650100708}", "{\"n\": 2629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3475.57, \"learn_time_ms\": 10459.434, \"total_train_time_s\": 13.66826605796814}", "{\"n\": 2630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3479.2, \"learn_time_ms\": 10414.065, \"total_train_time_s\": 13.218955039978027}", "{\"n\": 2631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3480.64, \"learn_time_ms\": 10375.699, \"total_train_time_s\": 14.173322677612305}", "{\"n\": 2632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3495.1, \"learn_time_ms\": 10321.092, \"total_train_time_s\": 13.369501829147339}", "{\"n\": 2633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3509.52, \"learn_time_ms\": 10154.736, \"total_train_time_s\": 12.881312608718872}", "{\"n\": 2634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3506.62, \"learn_time_ms\": 10027.854, \"total_train_time_s\": 13.355807304382324}", "{\"n\": 2635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3506.21, \"learn_time_ms\": 10030.335, \"total_train_time_s\": 13.780011653900146}", "{\"n\": 2636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3503.64, \"learn_time_ms\": 10049.19, \"total_train_time_s\": 13.870606660842896}", "{\"n\": 2637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3494.35, \"learn_time_ms\": 10131.537, \"total_train_time_s\": 15.055092811584473}", "{\"n\": 2638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3491.08, \"learn_time_ms\": 10125.123, \"total_train_time_s\": 14.296401023864746}", "{\"n\": 2639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3491.29, \"learn_time_ms\": 10130.003, \"total_train_time_s\": 13.727776527404785}", "{\"n\": 2640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3493.05, \"learn_time_ms\": 10253.891, \"total_train_time_s\": 14.327045679092407}", "{\"n\": 2641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3493.05, \"learn_time_ms\": 10293.555, \"total_train_time_s\": 14.686848163604736}", "{\"n\": 2642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3493.05, \"learn_time_ms\": 10481.654, \"total_train_time_s\": 15.362531185150146}", "{\"n\": 2643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3493.08, \"learn_time_ms\": 10516.852, \"total_train_time_s\": 13.391835927963257}", "{\"n\": 2644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3485.05, \"learn_time_ms\": 10634.973, \"total_train_time_s\": 14.569376468658447}", "{\"n\": 2645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3485.05, \"learn_time_ms\": 10760.622, \"total_train_time_s\": 15.05653715133667}", "{\"n\": 2646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3495.94, \"learn_time_ms\": 10828.342, \"total_train_time_s\": 14.360832214355469}", "{\"n\": 2647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3498.02, \"learn_time_ms\": 10752.412, \"total_train_time_s\": 14.450683355331421}", "{\"n\": 2648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3501.53, \"learn_time_ms\": 10728.697, \"total_train_time_s\": 14.060321807861328}", "{\"n\": 2649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3501.53, \"learn_time_ms\": 10767.026, \"total_train_time_s\": 14.357072591781616}", "{\"n\": 2650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3507.32, \"learn_time_ms\": 10621.996, \"total_train_time_s\": 12.998815774917603}", "{\"n\": 2651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3528.3, \"learn_time_ms\": 10529.644, \"total_train_time_s\": 14.100693941116333}", "{\"n\": 2652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3528.3, \"learn_time_ms\": 10344.695, \"total_train_time_s\": 13.400843381881714}", "{\"n\": 2653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3528.3, \"learn_time_ms\": 10424.63, \"total_train_time_s\": 14.283063888549805}", "{\"n\": 2654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.68, \"learn_time_ms\": 10315.36, \"total_train_time_s\": 13.495522499084473}", "{\"n\": 2655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3527.7, \"learn_time_ms\": 10161.768, \"total_train_time_s\": 13.386302947998047}", "{\"n\": 2656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3527.7, \"learn_time_ms\": 10152.003, \"total_train_time_s\": 14.160954236984253}", "{\"n\": 2657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3544.03, \"learn_time_ms\": 10086.829, \"total_train_time_s\": 13.488139867782593}", "{\"n\": 2658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3547.07, \"learn_time_ms\": 10037.131, \"total_train_time_s\": 13.496382713317871}", "{\"n\": 2659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3547.07, \"learn_time_ms\": 9986.093, \"total_train_time_s\": 13.775131702423096}", "{\"n\": 2660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3540.24, \"learn_time_ms\": 10054.783, \"total_train_time_s\": 13.618001222610474}", "{\"n\": 2661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3549.1, \"learn_time_ms\": 10133.785, \"total_train_time_s\": 14.598827838897705}", "{\"n\": 2662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3555.97, \"learn_time_ms\": 10225.309, \"total_train_time_s\": 14.30592393875122}", "{\"n\": 2663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3554.63, \"learn_time_ms\": 10190.464, \"total_train_time_s\": 13.898697853088379}", "{\"n\": 2664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3554.63, \"learn_time_ms\": 10203.598, \"total_train_time_s\": 13.531035423278809}", "{\"n\": 2665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3533.22, \"learn_time_ms\": 10336.345, \"total_train_time_s\": 14.527639389038086}", "{\"n\": 2666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.82, \"learn_time_ms\": 10239.447, \"total_train_time_s\": 13.284165143966675}", "{\"n\": 2667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.82, \"learn_time_ms\": 10246.824, \"total_train_time_s\": 13.621615171432495}", "{\"n\": 2668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3536.5, \"learn_time_ms\": 10333.216, \"total_train_time_s\": 14.238078355789185}", "{\"n\": 2669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3541.36, \"learn_time_ms\": 10320.937, \"total_train_time_s\": 13.581663370132446}", "{\"n\": 2670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3535.08, \"learn_time_ms\": 10295.067, \"total_train_time_s\": 13.32248330116272}", "{\"n\": 2671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3518.89, \"learn_time_ms\": 10295.922, \"total_train_time_s\": 14.717883110046387}", "{\"n\": 2672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.33, \"learn_time_ms\": 10363.884, \"total_train_time_s\": 14.983499526977539}", "{\"n\": 2673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.99, \"learn_time_ms\": 10413.544, \"total_train_time_s\": 14.360672235488892}", "{\"n\": 2674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.94, \"learn_time_ms\": 10503.577, \"total_train_time_s\": 14.557170391082764}", "{\"n\": 2675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3520.85, \"learn_time_ms\": 10412.347, \"total_train_time_s\": 13.685981750488281}", "{\"n\": 2676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3524.45, \"learn_time_ms\": 10509.278, \"total_train_time_s\": 14.154255867004395}", "{\"n\": 2677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.06, \"learn_time_ms\": 10565.809, \"total_train_time_s\": 14.171926736831665}", "{\"n\": 2678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.06, \"learn_time_ms\": 10516.575, \"total_train_time_s\": 14.015775442123413}", "{\"n\": 2679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.91, \"learn_time_ms\": 10539.032, \"total_train_time_s\": 14.155824899673462}", "{\"n\": 2680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.91, \"learn_time_ms\": 10560.183, \"total_train_time_s\": 13.554561853408813}", "{\"n\": 2681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3528.97, \"learn_time_ms\": 10447.834, \"total_train_time_s\": 13.628700494766235}", "{\"n\": 2682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3531.49, \"learn_time_ms\": 10345.327, \"total_train_time_s\": 14.031429290771484}", "{\"n\": 2683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3549.71, \"learn_time_ms\": 10416.942, \"total_train_time_s\": 14.989121913909912}", "{\"n\": 2684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 10305.643, \"total_train_time_s\": 13.391685009002686}", "{\"n\": 2685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3540.26, \"learn_time_ms\": 10289.914, \"total_train_time_s\": 13.639748811721802}", "{\"n\": 2686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 10280.97, \"total_train_time_s\": 14.465697050094604}", "{\"n\": 2687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3552.96, \"learn_time_ms\": 10268.983, \"total_train_time_s\": 14.28217077255249}", "{\"n\": 2688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3564.95, \"learn_time_ms\": 10241.08, \"total_train_time_s\": 13.496229410171509}", "{\"n\": 2689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3564.95, \"learn_time_ms\": 10276.818, \"total_train_time_s\": 14.256458759307861}", "{\"n\": 2690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3555.87, \"learn_time_ms\": 10212.822, \"total_train_time_s\": 13.022538423538208}", "{\"n\": 2691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3560.55, \"learn_time_ms\": 10323.234, \"total_train_time_s\": 14.46671199798584}", "{\"n\": 2692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3552.37, \"learn_time_ms\": 10464.94, \"total_train_time_s\": 15.418761014938354}", "{\"n\": 2693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3528.28, \"learn_time_ms\": 10434.533, \"total_train_time_s\": 14.82599925994873}", "{\"n\": 2694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.61, \"learn_time_ms\": 10510.811, \"total_train_time_s\": 14.113619089126587}", "{\"n\": 2695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3524.95, \"learn_time_ms\": 10534.16, \"total_train_time_s\": 13.897700309753418}", "{\"n\": 2696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3510.31, \"learn_time_ms\": 10506.717, \"total_train_time_s\": 13.800600528717041}", "{\"n\": 2697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3495.41, \"learn_time_ms\": 10476.393, \"total_train_time_s\": 13.785575866699219}", "{\"n\": 2698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3495.41, \"learn_time_ms\": 10603.822, \"total_train_time_s\": 14.873784065246582}", "{\"n\": 2699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3497.64, \"learn_time_ms\": 10556.116, \"total_train_time_s\": 13.596235036849976}", "{\"n\": 2700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.03, \"learn_time_ms\": 10595.471, \"total_train_time_s\": 13.418654203414917}", "{\"n\": 2701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3476.78, \"learn_time_ms\": 10655.843, \"total_train_time_s\": 15.4173104763031}", "{\"n\": 2702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3469.44, \"learn_time_ms\": 10474.008, \"total_train_time_s\": 13.75829029083252}", "{\"n\": 2703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3465.8, \"learn_time_ms\": 10413.52, \"total_train_time_s\": 14.004449367523193}", "{\"n\": 2704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.82, \"learn_time_ms\": 10335.798, \"total_train_time_s\": 13.783193111419678}", "{\"n\": 2705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.82, \"learn_time_ms\": 10315.661, \"total_train_time_s\": 13.569759607315063}", "{\"n\": 2706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3477.82, \"learn_time_ms\": 10354.648, \"total_train_time_s\": 14.01862359046936}", "{\"n\": 2707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3486.1, \"learn_time_ms\": 10458.409, \"total_train_time_s\": 14.7648024559021}", "{\"n\": 2708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3486.1, \"learn_time_ms\": 10432.761, \"total_train_time_s\": 14.658967733383179}", "{\"n\": 2709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3476.48, \"learn_time_ms\": 10506.375, \"total_train_time_s\": 14.35829210281372}", "{\"n\": 2710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3479.7, \"learn_time_ms\": 10534.323, \"total_train_time_s\": 13.60831332206726}", "{\"n\": 2711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3479.7, \"learn_time_ms\": 10467.354, \"total_train_time_s\": 14.54894471168518}", "{\"n\": 2712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.94, \"learn_time_ms\": 10571.335, \"total_train_time_s\": 14.579712152481079}", "{\"n\": 2713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3499.95, \"learn_time_ms\": 10573.434, \"total_train_time_s\": 14.165526628494263}", "{\"n\": 2714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3499.95, \"learn_time_ms\": 10733.277, \"total_train_time_s\": 14.9223952293396}", "{\"n\": 2715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.58, \"learn_time_ms\": 10719.546, \"total_train_time_s\": 13.35092544555664}", "{\"n\": 2716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.58, \"learn_time_ms\": 10669.846, \"total_train_time_s\": 13.901133060455322}", "{\"n\": 2717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.58, \"learn_time_ms\": 10634.53, \"total_train_time_s\": 14.510589838027954}", "{\"n\": 2718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3415.89, \"learn_time_ms\": 10574.313, \"total_train_time_s\": 14.028300285339355}", "{\"n\": 2719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.35, \"learn_time_ms\": 10608.889, \"total_train_time_s\": 14.632361888885498}", "{\"n\": 2720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.35, \"learn_time_ms\": 10616.047, \"total_train_time_s\": 13.795981168746948}", "{\"n\": 2721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3409.52, \"learn_time_ms\": 10561.326, \"total_train_time_s\": 13.998503684997559}", "{\"n\": 2722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.84, \"learn_time_ms\": 10594.525, \"total_train_time_s\": 15.053544998168945}", "{\"n\": 2723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.84, \"learn_time_ms\": 10629.815, \"total_train_time_s\": 14.472577571868896}", "{\"n\": 2724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.84, \"learn_time_ms\": 10608.369, \"total_train_time_s\": 15.243428707122803}", "{\"n\": 2725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.91, \"learn_time_ms\": 10675.265, \"total_train_time_s\": 14.191466569900513}", "{\"n\": 2726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.91, \"learn_time_ms\": 10716.967, \"total_train_time_s\": 14.09253215789795}", "{\"n\": 2727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.61, \"learn_time_ms\": 10788.144, \"total_train_time_s\": 15.285945892333984}", "{\"n\": 2728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.84, \"learn_time_ms\": 10819.213, \"total_train_time_s\": 14.173130750656128}", "{\"n\": 2729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3389.0, \"learn_time_ms\": 10713.762, \"total_train_time_s\": 13.875593185424805}", "{\"n\": 2730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.42, \"learn_time_ms\": 10815.226, \"total_train_time_s\": 14.79212760925293}", "{\"n\": 2731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.42, \"learn_time_ms\": 10838.463, \"total_train_time_s\": 14.270460367202759}", "{\"n\": 2732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.61, \"learn_time_ms\": 10776.862, \"total_train_time_s\": 14.334214687347412}", "{\"n\": 2733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.32, \"learn_time_ms\": 10725.688, \"total_train_time_s\": 13.985921382904053}", "{\"n\": 2734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.61, \"learn_time_ms\": 10692.028, \"total_train_time_s\": 14.366080284118652}", "{\"n\": 2735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3374.99, \"learn_time_ms\": 10709.347, \"total_train_time_s\": 14.738552808761597}", "{\"n\": 2736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.37, \"learn_time_ms\": 10732.499, \"total_train_time_s\": 14.353646755218506}", "{\"n\": 2737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3373.37, \"learn_time_ms\": 10711.197, \"total_train_time_s\": 15.18155574798584}", "{\"n\": 2738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.75, \"learn_time_ms\": 10726.977, \"total_train_time_s\": 14.476584434509277}", "{\"n\": 2739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.21, \"learn_time_ms\": 10752.003, \"total_train_time_s\": 14.047842502593994}", "{\"n\": 2740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.21, \"learn_time_ms\": 10639.678, \"total_train_time_s\": 13.723572254180908}", "{\"n\": 2741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.57, \"learn_time_ms\": 10599.784, \"total_train_time_s\": 13.684772968292236}", "{\"n\": 2742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3355.51, \"learn_time_ms\": 10563.091, \"total_train_time_s\": 14.187588930130005}", "{\"n\": 2743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.55, \"learn_time_ms\": 10547.904, \"total_train_time_s\": 13.817838668823242}", "{\"n\": 2744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3356.12, \"learn_time_ms\": 10542.861, \"total_train_time_s\": 14.539731502532959}", "{\"n\": 2745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3349.89, \"learn_time_ms\": 10605.928, \"total_train_time_s\": 15.155818223953247}", "{\"n\": 2746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3346.5, \"learn_time_ms\": 10626.403, \"total_train_time_s\": 14.81268835067749}", "{\"n\": 2747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.23, \"learn_time_ms\": 10724.557, \"total_train_time_s\": 15.965776681900024}", "{\"n\": 2748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.72, \"learn_time_ms\": 10677.858, \"total_train_time_s\": 14.323358297348022}", "{\"n\": 2749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.38, \"learn_time_ms\": 10645.811, \"total_train_time_s\": 13.70753288269043}", "{\"n\": 2750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 10664.723, \"total_train_time_s\": 13.951534986495972}", "{\"n\": 2751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 10664.318, \"total_train_time_s\": 13.758826494216919}", "{\"n\": 2752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 10756.673, \"total_train_time_s\": 15.03088116645813}", "{\"n\": 2753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.53, \"learn_time_ms\": 10889.139, \"total_train_time_s\": 15.169696569442749}", "{\"n\": 2754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.53, \"learn_time_ms\": 10859.478, \"total_train_time_s\": 14.454858779907227}", "{\"n\": 2755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.53, \"learn_time_ms\": 10872.858, \"total_train_time_s\": 14.903454065322876}", "{\"n\": 2756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.3, \"learn_time_ms\": 10871.57, \"total_train_time_s\": 14.57682466506958}", "{\"n\": 2757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3347.32, \"learn_time_ms\": 10734.289, \"total_train_time_s\": 14.507903814315796}", "{\"n\": 2758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3366.21, \"learn_time_ms\": 10683.967, \"total_train_time_s\": 13.377190113067627}", "{\"n\": 2759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.26, \"learn_time_ms\": 10782.396, \"total_train_time_s\": 14.503563642501831}", "{\"n\": 2760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.71, \"learn_time_ms\": 10857.268, \"total_train_time_s\": 14.667862892150879}", "{\"n\": 2761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.82, \"learn_time_ms\": 10869.23, \"total_train_time_s\": 13.874104499816895}", "{\"n\": 2762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.42, \"learn_time_ms\": 10832.108, \"total_train_time_s\": 14.567458868026733}", "{\"n\": 2763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.42, \"learn_time_ms\": 10681.672, \"total_train_time_s\": 13.557180404663086}", "{\"n\": 2764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.68, \"learn_time_ms\": 10652.397, \"total_train_time_s\": 14.01219630241394}", "{\"n\": 2765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.78, \"learn_time_ms\": 10532.086, \"total_train_time_s\": 13.894409418106079}", "{\"n\": 2766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3317.8, \"learn_time_ms\": 10525.851, \"total_train_time_s\": 14.552534103393555}", "{\"n\": 2767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3311.01, \"learn_time_ms\": 10435.685, \"total_train_time_s\": 13.687086820602417}", "{\"n\": 2768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3311.01, \"learn_time_ms\": 10604.757, \"total_train_time_s\": 15.201080083847046}", "{\"n\": 2769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.28, \"learn_time_ms\": 10561.813, \"total_train_time_s\": 14.247371435165405}", "{\"n\": 2770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.13, \"learn_time_ms\": 10522.73, \"total_train_time_s\": 14.261603116989136}", "{\"n\": 2771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.13, \"learn_time_ms\": 10472.925, \"total_train_time_s\": 13.520020961761475}", "{\"n\": 2772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.99, \"learn_time_ms\": 10420.492, \"total_train_time_s\": 14.19784688949585}", "{\"n\": 2773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.29, \"learn_time_ms\": 10494.189, \"total_train_time_s\": 14.40347170829773}", "{\"n\": 2774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.29, \"learn_time_ms\": 10539.719, \"total_train_time_s\": 14.545129299163818}", "{\"n\": 2775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.22, \"learn_time_ms\": 10556.534, \"total_train_time_s\": 14.060943126678467}", "{\"n\": 2776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.02, \"learn_time_ms\": 10358.667, \"total_train_time_s\": 12.734614133834839}", "{\"n\": 2777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3293.12, \"learn_time_ms\": 10285.827, \"total_train_time_s\": 12.977356195449829}", "{\"n\": 2778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.26, \"learn_time_ms\": 10109.97, \"total_train_time_s\": 13.253123760223389}", "{\"n\": 2779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.1, \"learn_time_ms\": 10084.171, \"total_train_time_s\": 13.842120885848999}", "{\"n\": 2780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.1, \"learn_time_ms\": 9957.287, \"total_train_time_s\": 13.100112915039062}", "{\"n\": 2781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.1, \"learn_time_ms\": 9936.421, \"total_train_time_s\": 13.367753982543945}", "{\"n\": 2782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.22, \"learn_time_ms\": 9887.467, \"total_train_time_s\": 13.505395650863647}", "{\"n\": 2783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.22, \"learn_time_ms\": 9739.19, \"total_train_time_s\": 12.838647365570068}", "{\"n\": 2784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.27, \"learn_time_ms\": 9685.651, \"total_train_time_s\": 13.658663034439087}", "{\"n\": 2785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3326.09, \"learn_time_ms\": 9692.68, \"total_train_time_s\": 14.20160961151123}", "{\"n\": 2786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3322.88, \"learn_time_ms\": 9846.25, \"total_train_time_s\": 14.179847240447998}", "{\"n\": 2787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.9, \"learn_time_ms\": 9983.448, \"total_train_time_s\": 14.238430500030518}", "{\"n\": 2788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3341.88, \"learn_time_ms\": 9969.193, \"total_train_time_s\": 13.33100962638855}", "{\"n\": 2789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3350.18, \"learn_time_ms\": 9959.72, \"total_train_time_s\": 13.971768140792847}", "{\"n\": 2790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3348.24, \"learn_time_ms\": 10011.125, \"total_train_time_s\": 13.31260085105896}", "{\"n\": 2791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3350.82, \"learn_time_ms\": 10222.939, \"total_train_time_s\": 15.396122694015503}", "{\"n\": 2792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.19, \"learn_time_ms\": 10234.64, \"total_train_time_s\": 13.612855911254883}", "{\"n\": 2793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.99, \"learn_time_ms\": 10331.716, \"total_train_time_s\": 13.752870082855225}", "{\"n\": 2794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.62, \"learn_time_ms\": 10342.383, \"total_train_time_s\": 14.244027137756348}", "{\"n\": 2795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.42, \"learn_time_ms\": 10318.514, \"total_train_time_s\": 13.817855834960938}", "{\"n\": 2796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.42, \"learn_time_ms\": 10328.128, \"total_train_time_s\": 14.361008405685425}", "{\"n\": 2797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.18, \"learn_time_ms\": 10251.942, \"total_train_time_s\": 13.503257036209106}", "{\"n\": 2798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3350.13, \"learn_time_ms\": 10354.375, \"total_train_time_s\": 14.140736818313599}", "{\"n\": 2799, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3350.13, \"learn_time_ms\": 10464.205, \"total_train_time_s\": 14.898721933364868}", "{\"n\": 2800, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3361.24, \"learn_time_ms\": 10489.48, \"total_train_time_s\": 13.725719690322876}", "{\"n\": 2801, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.72, \"learn_time_ms\": 10431.389, \"total_train_time_s\": 14.616605281829834}", "{\"n\": 2802, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.97, \"learn_time_ms\": 10440.02, \"total_train_time_s\": 13.747485160827637}", "{\"n\": 2803, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.42, \"learn_time_ms\": 10478.444, \"total_train_time_s\": 14.530704259872437}", "{\"n\": 2804, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 10552.781, \"total_train_time_s\": 14.556904077529907}", "{\"n\": 2805, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 10569.625, \"total_train_time_s\": 13.973089456558228}", "{\"n\": 2806, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 10595.863, \"total_train_time_s\": 14.524101734161377}", "{\"n\": 2807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.13, \"learn_time_ms\": 10598.104, \"total_train_time_s\": 13.706348896026611}", "{\"n\": 2808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.9, \"learn_time_ms\": 10537.957, \"total_train_time_s\": 13.624547481536865}", "{\"n\": 2809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.9, \"learn_time_ms\": 10556.74, \"total_train_time_s\": 15.04965329170227}", "{\"n\": 2810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.98, \"learn_time_ms\": 10534.566, \"total_train_time_s\": 13.41525936126709}", "{\"n\": 2811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3374.15, \"learn_time_ms\": 10523.562, \"total_train_time_s\": 14.674835443496704}", "{\"n\": 2812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3377.33, \"learn_time_ms\": 10517.612, \"total_train_time_s\": 13.703952074050903}", "{\"n\": 2813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.19, \"learn_time_ms\": 10471.94, \"total_train_time_s\": 13.955739259719849}", "{\"n\": 2814, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 10350.003, \"total_train_time_s\": 13.281428337097168}", "{\"n\": 2815, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 10353.912, \"total_train_time_s\": 14.14918828010559}", "{\"n\": 2816, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.98, \"learn_time_ms\": 10425.284, \"total_train_time_s\": 15.225976467132568}", "{\"n\": 2817, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.83, \"learn_time_ms\": 10494.543, \"total_train_time_s\": 14.277631998062134}", "{\"n\": 2818, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.83, \"learn_time_ms\": 10540.14, \"total_train_time_s\": 14.315924644470215}", "{\"n\": 2819, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.85, \"learn_time_ms\": 10409.418, \"total_train_time_s\": 13.88032865524292}", "{\"n\": 2820, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.79, \"learn_time_ms\": 10446.935, \"total_train_time_s\": 13.86470890045166}", "{\"n\": 2821, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.79, \"learn_time_ms\": 10397.805, \"total_train_time_s\": 14.107914686203003}", "{\"n\": 2822, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.79, \"learn_time_ms\": 10496.01, \"total_train_time_s\": 14.751367568969727}", "{\"n\": 2823, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.24, \"learn_time_ms\": 10544.332, \"total_train_time_s\": 14.273458480834961}", "{\"n\": 2824, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 10573.085, \"total_train_time_s\": 13.69779634475708}", "{\"n\": 2825, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 10616.497, \"total_train_time_s\": 14.55821418762207}", "{\"n\": 2826, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 10538.698, \"total_train_time_s\": 14.444581985473633}", "{\"n\": 2827, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.88, \"learn_time_ms\": 10494.208, \"total_train_time_s\": 13.84904670715332}", "{\"n\": 2828, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.88, \"learn_time_ms\": 10570.319, \"total_train_time_s\": 15.077361583709717}", "{\"n\": 2829, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.34, \"learn_time_ms\": 10596.143, \"total_train_time_s\": 14.273277044296265}", "{\"n\": 2830, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.15, \"learn_time_ms\": 10618.757, \"total_train_time_s\": 14.281759262084961}", "{\"n\": 2831, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.4, \"learn_time_ms\": 10468.593, \"total_train_time_s\": 12.652828693389893}", "{\"n\": 2832, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.4, \"learn_time_ms\": 10374.925, \"total_train_time_s\": 13.901538848876953}", "{\"n\": 2833, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.4, \"learn_time_ms\": 10339.23, \"total_train_time_s\": 14.032235860824585}", "{\"n\": 2834, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3374.62, \"learn_time_ms\": 10388.381, \"total_train_time_s\": 14.174185037612915}", "{\"n\": 2835, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 10408.979, \"total_train_time_s\": 14.638279438018799}", "{\"n\": 2836, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 10316.743, \"total_train_time_s\": 13.573471069335938}", "{\"n\": 2837, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3388.53, \"learn_time_ms\": 10258.567, \"total_train_time_s\": 13.365835189819336}", "{\"n\": 2838, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.02, \"learn_time_ms\": 10177.3, \"total_train_time_s\": 14.127877712249756}", "{\"n\": 2839, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3425.13, \"learn_time_ms\": 10007.27, \"total_train_time_s\": 12.662819862365723}", "{\"n\": 2840, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3425.13, \"learn_time_ms\": 9972.774, \"total_train_time_s\": 13.799063682556152}", "{\"n\": 2841, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3409.9, \"learn_time_ms\": 10114.0, \"total_train_time_s\": 14.11358094215393}", "{\"n\": 2842, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3427.24, \"learn_time_ms\": 10182.464, \"total_train_time_s\": 14.490823984146118}", "{\"n\": 2843, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3427.24, \"learn_time_ms\": 10308.65, \"total_train_time_s\": 15.356059789657593}", "{\"n\": 2844, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3427.24, \"learn_time_ms\": 10294.292, \"total_train_time_s\": 14.144338369369507}", "{\"n\": 2845, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3428.24, \"learn_time_ms\": 10329.226, \"total_train_time_s\": 15.272048711776733}", "{\"n\": 2846, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.23, \"learn_time_ms\": 10438.947, \"total_train_time_s\": 14.880531072616577}", "{\"n\": 2847, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.23, \"learn_time_ms\": 10438.81, \"total_train_time_s\": 13.166774988174438}", "{\"n\": 2848, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3440.64, \"learn_time_ms\": 10453.797, \"total_train_time_s\": 14.441665410995483}", "{\"n\": 2849, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3463.08, \"learn_time_ms\": 10721.244, \"total_train_time_s\": 15.148407220840454}", "{\"n\": 2850, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3458.33, \"learn_time_ms\": 10923.241, \"total_train_time_s\": 15.673173666000366}", "{\"n\": 2851, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3458.33, \"learn_time_ms\": 11009.15, \"total_train_time_s\": 14.774067878723145}", "{\"n\": 2852, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3470.02, \"learn_time_ms\": 10951.077, \"total_train_time_s\": 13.817930221557617}", "{\"n\": 2853, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3478.07, \"learn_time_ms\": 10869.613, \"total_train_time_s\": 14.36251425743103}", "{\"n\": 2854, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3478.07, \"learn_time_ms\": 10886.096, \"total_train_time_s\": 14.069956064224243}", "{\"n\": 2855, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3479.04, \"learn_time_ms\": 10749.635, \"total_train_time_s\": 13.732622146606445}", "{\"n\": 2856, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3479.04, \"learn_time_ms\": 10671.55, \"total_train_time_s\": 13.72196340560913}", "{\"n\": 2857, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.68, \"learn_time_ms\": 10806.477, \"total_train_time_s\": 14.887023210525513}", "{\"n\": 2858, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.99, \"learn_time_ms\": 10727.85, \"total_train_time_s\": 13.494513034820557}", "{\"n\": 2859, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.99, \"learn_time_ms\": 10675.556, \"total_train_time_s\": 14.364063739776611}", "{\"n\": 2860, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3488.67, \"learn_time_ms\": 10546.316, \"total_train_time_s\": 14.563037395477295}", "{\"n\": 2861, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3489.92, \"learn_time_ms\": 10430.326, \"total_train_time_s\": 13.648840188980103}", "{\"n\": 2862, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.05, \"learn_time_ms\": 10537.826, \"total_train_time_s\": 14.879180431365967}", "{\"n\": 2863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.05, \"learn_time_ms\": 10523.409, \"total_train_time_s\": 14.13998818397522}", "{\"n\": 2864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3506.58, \"learn_time_ms\": 10614.165, \"total_train_time_s\": 15.096785306930542}", "{\"n\": 2865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 10592.309, \"total_train_time_s\": 13.731617212295532}", "{\"n\": 2866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 10628.774, \"total_train_time_s\": 14.238731145858765}", "{\"n\": 2867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.0, \"learn_time_ms\": 10586.144, \"total_train_time_s\": 14.2153639793396}", "{\"n\": 2868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.86, \"learn_time_ms\": 10665.079, \"total_train_time_s\": 14.29642629623413}", "{\"n\": 2869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3522.86, \"learn_time_ms\": 10667.033, \"total_train_time_s\": 14.652642488479614}", "{\"n\": 2870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3514.2, \"learn_time_ms\": 10625.66, \"total_train_time_s\": 14.209948062896729}", "{\"n\": 2871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.0, \"learn_time_ms\": 10712.724, \"total_train_time_s\": 14.6999192237854}", "{\"n\": 2872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3504.59, \"learn_time_ms\": 10649.845, \"total_train_time_s\": 14.314326047897339}", "{\"n\": 2873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3506.9, \"learn_time_ms\": 10639.571, \"total_train_time_s\": 13.969336748123169}", "{\"n\": 2874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3500.22, \"learn_time_ms\": 10593.739, \"total_train_time_s\": 14.652255535125732}", "{\"n\": 2875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.35, \"learn_time_ms\": 10640.336, \"total_train_time_s\": 14.043194770812988}", "{\"n\": 2876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3490.32, \"learn_time_ms\": 10700.207, \"total_train_time_s\": 14.804606199264526}", "{\"n\": 2877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3489.16, \"learn_time_ms\": 10742.171, \"total_train_time_s\": 14.533607959747314}", "{\"n\": 2878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3477.71, \"learn_time_ms\": 10740.326, \"total_train_time_s\": 14.33368968963623}", "{\"n\": 2879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3477.71, \"learn_time_ms\": 10613.873, \"total_train_time_s\": 13.488573551177979}", "{\"n\": 2880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3470.22, \"learn_time_ms\": 10681.534, \"total_train_time_s\": 14.848058223724365}", "{\"n\": 2881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.73, \"learn_time_ms\": 10656.622, \"total_train_time_s\": 14.334731101989746}", "{\"n\": 2882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3486.57, \"learn_time_ms\": 10574.067, \"total_train_time_s\": 13.412699222564697}", "{\"n\": 2883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3486.57, \"learn_time_ms\": 10571.938, \"total_train_time_s\": 14.231858015060425}", "{\"n\": 2884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.92, \"learn_time_ms\": 10493.984, \"total_train_time_s\": 13.872714519500732}", "{\"n\": 2885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.34, \"learn_time_ms\": 10586.164, \"total_train_time_s\": 14.720157384872437}", "{\"n\": 2886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.34, \"learn_time_ms\": 10522.405, \"total_train_time_s\": 14.18391466140747}", "{\"n\": 2887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3488.27, \"learn_time_ms\": 10437.599, \"total_train_time_s\": 13.994885206222534}", "{\"n\": 2888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3493.51, \"learn_time_ms\": 10408.054, \"total_train_time_s\": 13.818634271621704}", "{\"n\": 2889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.28, \"learn_time_ms\": 10550.602, \"total_train_time_s\": 14.771517992019653}", "{\"n\": 2890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3494.93, \"learn_time_ms\": 10552.31, \"total_train_time_s\": 14.782501935958862}", "{\"n\": 2891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3492.67, \"learn_time_ms\": 10435.206, \"total_train_time_s\": 13.06123971939087}", "{\"n\": 2892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3510.43, \"learn_time_ms\": 10482.088, \"total_train_time_s\": 13.89905071258545}", "{\"n\": 2893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3509.48, \"learn_time_ms\": 10435.152, \"total_train_time_s\": 13.683716535568237}", "{\"n\": 2894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3517.68, \"learn_time_ms\": 10439.689, \"total_train_time_s\": 13.877089262008667}", "{\"n\": 2895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3524.17, \"learn_time_ms\": 10433.975, \"total_train_time_s\": 15.050297021865845}", "{\"n\": 2896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3524.17, \"learn_time_ms\": 10494.65, \"total_train_time_s\": 14.900537014007568}", "{\"n\": 2897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3500.86, \"learn_time_ms\": 10579.109, \"total_train_time_s\": 14.69692873954773}", "{\"n\": 2898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3500.27, \"learn_time_ms\": 10534.187, \"total_train_time_s\": 13.41899037361145}", "{\"n\": 2899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3493.38, \"learn_time_ms\": 10529.056, \"total_train_time_s\": 14.665317296981812}", "{\"n\": 2900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3491.24, \"learn_time_ms\": 10471.704, \"total_train_time_s\": 14.510618925094604}", "{\"n\": 2901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.53, \"learn_time_ms\": 10501.284, \"total_train_time_s\": 13.734282493591309}", "{\"n\": 2902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.53, \"learn_time_ms\": 10441.123, \"total_train_time_s\": 13.51486086845398}", "{\"n\": 2903, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3501.85, \"learn_time_ms\": 10516.118, \"total_train_time_s\": 14.625115394592285}", "{\"n\": 2904, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3496.39, \"learn_time_ms\": 10589.086, \"total_train_time_s\": 14.684505462646484}", "{\"n\": 2905, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3502.0, \"learn_time_ms\": 10524.762, \"total_train_time_s\": 14.265306949615479}", "{\"n\": 2906, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3508.56, \"learn_time_ms\": 10484.719, \"total_train_time_s\": 14.420996904373169}", "{\"n\": 2907, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3508.56, \"learn_time_ms\": 10494.802, \"total_train_time_s\": 14.926274538040161}", "{\"n\": 2908, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3505.84, \"learn_time_ms\": 10560.549, \"total_train_time_s\": 14.30994701385498}", "{\"n\": 2909, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3507.5, \"learn_time_ms\": 10553.471, \"total_train_time_s\": 14.538503170013428}", "{\"n\": 2910, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3507.5, \"learn_time_ms\": 10574.358, \"total_train_time_s\": 14.455614566802979}", "{\"n\": 2911, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3498.39, \"learn_time_ms\": 10680.166, \"total_train_time_s\": 14.390039443969727}", "{\"n\": 2912, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3523.58, \"learn_time_ms\": 10680.911, \"total_train_time_s\": 13.598622798919678}", "{\"n\": 2913, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3523.26, \"learn_time_ms\": 10663.45, \"total_train_time_s\": 14.135762453079224}", "{\"n\": 2914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.71, \"learn_time_ms\": 10577.119, \"total_train_time_s\": 13.946998834609985}", "{\"n\": 2915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3512.76, \"learn_time_ms\": 10608.786, \"total_train_time_s\": 14.448010683059692}", "{\"n\": 2916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3517.84, \"learn_time_ms\": 10670.033, \"total_train_time_s\": 14.983401536941528}", "{\"n\": 2917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3517.84, \"learn_time_ms\": 10505.533, \"total_train_time_s\": 12.938780546188354}", "{\"n\": 2918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3511.61, \"learn_time_ms\": 10474.896, \"total_train_time_s\": 13.799265146255493}", "{\"n\": 2919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3511.74, \"learn_time_ms\": 10463.012, \"total_train_time_s\": 14.631449460983276}", "{\"n\": 2920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3531.14, \"learn_time_ms\": 10409.06, \"total_train_time_s\": 13.670616149902344}", "{\"n\": 2921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3531.14, \"learn_time_ms\": 10330.582, \"total_train_time_s\": 14.095746517181396}", "{\"n\": 2922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3531.4, \"learn_time_ms\": 10383.465, \"total_train_time_s\": 14.236103296279907}", "{\"n\": 2923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3525.8, \"learn_time_ms\": 10351.595, \"total_train_time_s\": 13.92562198638916}", "{\"n\": 2924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3506.58, \"learn_time_ms\": 10383.259, \"total_train_time_s\": 14.047541856765747}", "{\"n\": 2925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3504.44, \"learn_time_ms\": 10411.915, \"total_train_time_s\": 14.705094575881958}", "{\"n\": 2926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3499.44, \"learn_time_ms\": 10373.996, \"total_train_time_s\": 14.461158752441406}", "{\"n\": 2927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3512.56, \"learn_time_ms\": 10490.067, \"total_train_time_s\": 14.335440874099731}", "{\"n\": 2928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3519.08, \"learn_time_ms\": 10524.629, \"total_train_time_s\": 14.29500699043274}", "{\"n\": 2929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3494.11, \"learn_time_ms\": 10592.703, \"total_train_time_s\": 15.428420066833496}", "{\"n\": 2930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3494.11, \"learn_time_ms\": 10618.728, \"total_train_time_s\": 14.092809200286865}", "{\"n\": 2931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3494.11, \"learn_time_ms\": 10620.669, \"total_train_time_s\": 13.879349946975708}", "{\"n\": 2932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3481.89, \"learn_time_ms\": 10706.892, \"total_train_time_s\": 15.11667776107788}", "{\"n\": 2933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3481.89, \"learn_time_ms\": 10627.245, \"total_train_time_s\": 13.0071120262146}", "{\"n\": 2934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3477.53, \"learn_time_ms\": 10623.825, \"total_train_time_s\": 14.037799596786499}", "{\"n\": 2935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3487.8, \"learn_time_ms\": 10501.437, \"total_train_time_s\": 13.628527402877808}", "{\"n\": 2936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3480.81, \"learn_time_ms\": 10489.071, \"total_train_time_s\": 14.519624471664429}", "{\"n\": 2937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3480.81, \"learn_time_ms\": 10415.568, \"total_train_time_s\": 13.741016626358032}", "{\"n\": 2938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3492.85, \"learn_time_ms\": 10321.455, \"total_train_time_s\": 13.264035701751709}", "{\"n\": 2939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3492.03, \"learn_time_ms\": 10125.826, \"total_train_time_s\": 13.059608459472656}", "{\"n\": 2940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3495.27, \"learn_time_ms\": 10161.788, \"total_train_time_s\": 14.448040962219238}", "{\"n\": 2941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3481.42, \"learn_time_ms\": 10245.444, \"total_train_time_s\": 14.933025360107422}", "{\"n\": 2942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.17, \"learn_time_ms\": 10200.249, \"total_train_time_s\": 14.231030225753784}", "{\"n\": 2943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3483.22, \"learn_time_ms\": 10283.089, \"total_train_time_s\": 14.067092418670654}", "{\"n\": 2944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3472.27, \"learn_time_ms\": 10324.031, \"total_train_time_s\": 14.584227561950684}", "{\"n\": 2945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3474.02, \"learn_time_ms\": 10420.435, \"total_train_time_s\": 14.479002952575684}", "{\"n\": 2946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.88, \"learn_time_ms\": 10297.029, \"total_train_time_s\": 13.122087955474854}", "{\"n\": 2947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.88, \"learn_time_ms\": 10356.216, \"total_train_time_s\": 14.166642904281616}", "{\"n\": 2948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.88, \"learn_time_ms\": 10447.615, \"total_train_time_s\": 14.407472848892212}", "{\"n\": 2949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3453.64, \"learn_time_ms\": 10504.053, \"total_train_time_s\": 13.717612504959106}", "{\"n\": 2950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3449.24, \"learn_time_ms\": 10472.625, \"total_train_time_s\": 14.215250015258789}", "{\"n\": 2951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3449.24, \"learn_time_ms\": 10352.21, \"total_train_time_s\": 13.307206392288208}", "{\"n\": 2952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3447.07, \"learn_time_ms\": 10365.91, \"total_train_time_s\": 14.670305252075195}", "{\"n\": 2953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3444.8, \"learn_time_ms\": 10420.653, \"total_train_time_s\": 14.471437454223633}", "{\"n\": 2954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3444.8, \"learn_time_ms\": 10303.65, \"total_train_time_s\": 13.608175277709961}", "{\"n\": 2955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3446.11, \"learn_time_ms\": 10227.593, \"total_train_time_s\": 13.8485426902771}", "{\"n\": 2956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.52, \"learn_time_ms\": 10303.431, \"total_train_time_s\": 13.837353706359863}", "{\"n\": 2957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3443.36, \"learn_time_ms\": 10299.628, \"total_train_time_s\": 14.092846393585205}", "{\"n\": 2958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3458.45, \"learn_time_ms\": 10260.652, \"total_train_time_s\": 13.985132932662964}", "{\"n\": 2959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3458.45, \"learn_time_ms\": 10276.74, \"total_train_time_s\": 13.864708423614502}", "{\"n\": 2960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3456.05, \"learn_time_ms\": 10245.934, \"total_train_time_s\": 13.88779330253601}", "{\"n\": 2961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.87, \"learn_time_ms\": 10293.218, \"total_train_time_s\": 13.920289754867554}", "{\"n\": 2962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3460.77, \"learn_time_ms\": 10280.598, \"total_train_time_s\": 14.636021137237549}", "{\"n\": 2963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3472.74, \"learn_time_ms\": 10207.794, \"total_train_time_s\": 13.562103986740112}", "{\"n\": 2964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3473.41, \"learn_time_ms\": 10251.856, \"total_train_time_s\": 13.73888635635376}", "{\"n\": 2965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.14, \"learn_time_ms\": 10210.175, \"total_train_time_s\": 13.470801830291748}", "{\"n\": 2966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.03, \"learn_time_ms\": 10264.137, \"total_train_time_s\": 14.512619018554688}", "{\"n\": 2967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.03, \"learn_time_ms\": 10328.362, \"total_train_time_s\": 14.798242092132568}", "{\"n\": 2968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3483.02, \"learn_time_ms\": 10287.939, \"total_train_time_s\": 13.3518807888031}", "{\"n\": 2969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3495.14, \"learn_time_ms\": 10372.855, \"total_train_time_s\": 14.687106370925903}", "{\"n\": 2970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.57, \"learn_time_ms\": 10432.773, \"total_train_time_s\": 14.43842601776123}", "{\"n\": 2971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.28, \"learn_time_ms\": 10351.375, \"total_train_time_s\": 13.049612998962402}", "{\"n\": 2972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3488.44, \"learn_time_ms\": 10342.962, \"total_train_time_s\": 14.424278497695923}", "{\"n\": 2973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.94, \"learn_time_ms\": 10304.402, \"total_train_time_s\": 13.527632713317871}", "{\"n\": 2974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.94, \"learn_time_ms\": 10290.253, \"total_train_time_s\": 13.804451942443848}", "{\"n\": 2975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.83, \"learn_time_ms\": 10262.596, \"total_train_time_s\": 13.128004550933838}", "{\"n\": 2976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3489.8, \"learn_time_ms\": 10149.643, \"total_train_time_s\": 13.267459869384766}", "{\"n\": 2977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3495.22, \"learn_time_ms\": 10046.522, \"total_train_time_s\": 13.543007612228394}", "{\"n\": 2978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.98, \"learn_time_ms\": 10216.636, \"total_train_time_s\": 14.990598440170288}", "{\"n\": 2979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.09, \"learn_time_ms\": 10245.456, \"total_train_time_s\": 15.334567546844482}", "{\"n\": 2980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.09, \"learn_time_ms\": 10204.15, \"total_train_time_s\": 13.978010416030884}", "{\"n\": 2981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3469.74, \"learn_time_ms\": 10275.31, \"total_train_time_s\": 13.847300291061401}", "{\"n\": 2982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3469.74, \"learn_time_ms\": 10300.705, \"total_train_time_s\": 14.412509679794312}", "{\"n\": 2983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.22, \"learn_time_ms\": 10400.512, \"total_train_time_s\": 14.458061218261719}", "{\"n\": 2984, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3477.9, \"learn_time_ms\": 10464.152, \"total_train_time_s\": 14.139701843261719}", "{\"n\": 2985, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3475.06, \"learn_time_ms\": 10738.388, \"total_train_time_s\": 15.837623834609985}", "{\"n\": 2986, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3475.06, \"learn_time_ms\": 10765.492, \"total_train_time_s\": 13.885923385620117}", "{\"n\": 2987, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3476.34, \"learn_time_ms\": 10845.821, \"total_train_time_s\": 14.354029417037964}", "{\"n\": 2988, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3487.57, \"learn_time_ms\": 10748.786, \"total_train_time_s\": 14.222880601882935}", "{\"n\": 2989, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3474.41, \"learn_time_ms\": 10574.063, \"total_train_time_s\": 13.34635329246521}", "{\"n\": 2990, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3471.03, \"learn_time_ms\": 10582.068, \"total_train_time_s\": 14.130740642547607}", "{\"n\": 2991, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3488.04, \"learn_time_ms\": 10708.837, \"total_train_time_s\": 15.193826675415039}", "{\"n\": 2992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3492.47, \"learn_time_ms\": 10579.811, \"total_train_time_s\": 13.17296814918518}", "{\"n\": 2993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3492.47, \"learn_time_ms\": 10555.337, \"total_train_time_s\": 14.04207706451416}", "{\"n\": 2994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3495.26, \"learn_time_ms\": 10595.696, \"total_train_time_s\": 14.69433856010437}", "{\"n\": 2995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.86, \"learn_time_ms\": 10387.465, \"total_train_time_s\": 13.597273111343384}", "{\"n\": 2996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.86, \"learn_time_ms\": 10446.999, \"total_train_time_s\": 14.362266302108765}", "{\"n\": 2997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3504.58, \"learn_time_ms\": 10506.564, \"total_train_time_s\": 15.13114309310913}", "{\"n\": 2998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3493.53, \"learn_time_ms\": 10384.791, \"total_train_time_s\": 12.751219749450684}", "{\"n\": 2999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3493.53, \"learn_time_ms\": 10493.712, \"total_train_time_s\": 14.63696575164795}", "{\"n\": 3000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.16, \"learn_time_ms\": 10551.6, \"total_train_time_s\": 14.680521488189697}", "{\"n\": 3001, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.42, \"learn_time_ms\": 10536.817, \"total_train_time_s\": 15.021799087524414}", "{\"n\": 3002, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.42, \"learn_time_ms\": 10545.298, \"total_train_time_s\": 13.160645484924316}", "{\"n\": 3003, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3465.61, \"learn_time_ms\": 10568.851, \"total_train_time_s\": 14.204209804534912}", "{\"n\": 3004, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3473.34, \"learn_time_ms\": 10486.91, \"total_train_time_s\": 13.687148809432983}", "{\"n\": 3005, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3473.34, \"learn_time_ms\": 10497.314, \"total_train_time_s\": 13.84436559677124}", "{\"n\": 3006, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.11, \"learn_time_ms\": 10588.764, \"total_train_time_s\": 15.179914951324463}", "{\"n\": 3007, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3474.48, \"learn_time_ms\": 10460.94, \"total_train_time_s\": 13.849090576171875}", "{\"n\": 3008, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3469.81, \"learn_time_ms\": 10552.033, \"total_train_time_s\": 13.760248184204102}", "{\"n\": 3009, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3467.13, \"learn_time_ms\": 10570.11, \"total_train_time_s\": 14.941858768463135}", "{\"n\": 3010, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3466.05, \"learn_time_ms\": 10511.617, \"total_train_time_s\": 13.961305141448975}", "{\"n\": 3011, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.67, \"learn_time_ms\": 10450.071, \"total_train_time_s\": 14.287161111831665}", "{\"n\": 3012, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.67, \"learn_time_ms\": 10525.135, \"total_train_time_s\": 14.247452974319458}", "{\"n\": 3013, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3456.16, \"learn_time_ms\": 10493.152, \"total_train_time_s\": 14.228406190872192}", "{\"n\": 3014, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.64, \"learn_time_ms\": 10506.002, \"total_train_time_s\": 14.078120231628418}", "{\"n\": 3015, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3452.04, \"learn_time_ms\": 10611.755, \"total_train_time_s\": 14.942220449447632}", "{\"n\": 3016, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3445.95, \"learn_time_ms\": 10466.261, \"total_train_time_s\": 13.817366600036621}", "{\"n\": 3017, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3452.2, \"learn_time_ms\": 10486.618, \"total_train_time_s\": 14.003927946090698}", "{\"n\": 3018, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3452.2, \"learn_time_ms\": 10591.051, \"total_train_time_s\": 14.792771577835083}", "{\"n\": 3019, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3437.62, \"learn_time_ms\": 10614.802, \"total_train_time_s\": 14.836293935775757}", "{\"n\": 3020, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3437.62, \"learn_time_ms\": 10550.429, \"total_train_time_s\": 13.524375438690186}", "{\"n\": 3021, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3432.06, \"learn_time_ms\": 10484.221, \"total_train_time_s\": 13.49018406867981}", "{\"n\": 3022, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3425.63, \"learn_time_ms\": 10495.032, \"total_train_time_s\": 14.16846227645874}", "{\"n\": 3023, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.47, \"learn_time_ms\": 10455.077, \"total_train_time_s\": 13.431947708129883}", "{\"n\": 3024, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.47, \"learn_time_ms\": 10439.509, \"total_train_time_s\": 13.652666330337524}", "{\"n\": 3025, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.37, \"learn_time_ms\": 10363.378, \"total_train_time_s\": 14.012049674987793}", "{\"n\": 3026, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.05, \"learn_time_ms\": 10490.197, \"total_train_time_s\": 14.98621654510498}", "{\"n\": 3027, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.05, \"learn_time_ms\": 10535.104, \"total_train_time_s\": 14.375548124313354}", "{\"n\": 3028, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.94, \"learn_time_ms\": 10349.574, \"total_train_time_s\": 12.94706916809082}", "{\"n\": 3029, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.7, \"learn_time_ms\": 10261.199, \"total_train_time_s\": 13.821047306060791}", "{\"n\": 3030, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.7, \"learn_time_ms\": 10381.279, \"total_train_time_s\": 14.596304416656494}", "{\"n\": 3031, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.82, \"learn_time_ms\": 10376.237, \"total_train_time_s\": 13.496153354644775}", "{\"n\": 3032, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.95, \"learn_time_ms\": 10284.662, \"total_train_time_s\": 13.524258136749268}", "{\"n\": 3033, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.95, \"learn_time_ms\": 10398.416, \"total_train_time_s\": 14.865459680557251}", "{\"n\": 3034, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3452.41, \"learn_time_ms\": 10473.139, \"total_train_time_s\": 14.648469924926758}", "{\"n\": 3035, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3466.35, \"learn_time_ms\": 10548.208, \"total_train_time_s\": 15.020257711410522}", "{\"n\": 3036, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3457.52, \"learn_time_ms\": 10433.773, \"total_train_time_s\": 13.880870580673218}", "{\"n\": 3037, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3469.28, \"learn_time_ms\": 10435.985, \"total_train_time_s\": 14.52872347831726}", "{\"n\": 3038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3484.76, \"learn_time_ms\": 10553.955, \"total_train_time_s\": 14.407109260559082}", "{\"n\": 3039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3484.76, \"learn_time_ms\": 10504.3, \"total_train_time_s\": 13.634877681732178}", "{\"n\": 3040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3481.75, \"learn_time_ms\": 10504.7, \"total_train_time_s\": 14.66824221611023}", "{\"n\": 3041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3481.75, \"learn_time_ms\": 10557.614, \"total_train_time_s\": 14.010245561599731}", "{\"n\": 3042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3480.86, \"learn_time_ms\": 10717.717, \"total_train_time_s\": 14.817028522491455}", "{\"n\": 3043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.92, \"learn_time_ms\": 10717.273, \"total_train_time_s\": 14.772456169128418}", "{\"n\": 3044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.92, \"learn_time_ms\": 10717.244, \"total_train_time_s\": 14.628389120101929}", "{\"n\": 3045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.99, \"learn_time_ms\": 10694.217, \"total_train_time_s\": 14.926200866699219}", "{\"n\": 3046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.43, \"learn_time_ms\": 10730.425, \"total_train_time_s\": 14.172108173370361}", "{\"n\": 3047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.69, \"learn_time_ms\": 10723.104, \"total_train_time_s\": 14.453436136245728}", "{\"n\": 3048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.69, \"learn_time_ms\": 10744.507, \"total_train_time_s\": 14.39022970199585}", "{\"n\": 3049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.57, \"learn_time_ms\": 10844.168, \"total_train_time_s\": 14.335428953170776}", "{\"n\": 3050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.9, \"learn_time_ms\": 10840.95, \"total_train_time_s\": 14.605709314346313}", "{\"n\": 3051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.9, \"learn_time_ms\": 10833.506, \"total_train_time_s\": 14.053537368774414}", "{\"n\": 3052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.72, \"learn_time_ms\": 10750.765, \"total_train_time_s\": 13.852094888687134}", "{\"n\": 3053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.72, \"learn_time_ms\": 10617.911, \"total_train_time_s\": 13.602838039398193}", "{\"n\": 3054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.9, \"learn_time_ms\": 10525.53, \"total_train_time_s\": 13.745456218719482}", "{\"n\": 3055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.04, \"learn_time_ms\": 10434.211, \"total_train_time_s\": 13.86680555343628}", "{\"n\": 3056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.38, \"learn_time_ms\": 10387.626, \"total_train_time_s\": 13.757258176803589}", "{\"n\": 3057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.57, \"learn_time_ms\": 10392.379, \"total_train_time_s\": 14.502124547958374}", "{\"n\": 3058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.97, \"learn_time_ms\": 10282.259, \"total_train_time_s\": 13.110918283462524}", "{\"n\": 3059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.97, \"learn_time_ms\": 10146.88, \"total_train_time_s\": 13.081808805465698}", "{\"n\": 3060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.04, \"learn_time_ms\": 10034.45, \"total_train_time_s\": 13.571154117584229}", "{\"n\": 3061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.89, \"learn_time_ms\": 9927.213, \"total_train_time_s\": 13.06036901473999}", "{\"n\": 3062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.89, \"learn_time_ms\": 9901.502, \"total_train_time_s\": 13.67825198173523}", "{\"n\": 3063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.89, \"learn_time_ms\": 9923.805, \"total_train_time_s\": 13.785446643829346}", "{\"n\": 3064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.95, \"learn_time_ms\": 9992.407, \"total_train_time_s\": 14.236141681671143}", "{\"n\": 3065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.95, \"learn_time_ms\": 10027.256, \"total_train_time_s\": 13.995749235153198}", "{\"n\": 3066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.95, \"learn_time_ms\": 10138.471, \"total_train_time_s\": 14.93345594406128}", "{\"n\": 3067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.59, \"learn_time_ms\": 10166.103, \"total_train_time_s\": 14.654883623123169}", "{\"n\": 3068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.26, \"learn_time_ms\": 10269.475, \"total_train_time_s\": 14.317368268966675}", "{\"n\": 3069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.26, \"learn_time_ms\": 10371.214, \"total_train_time_s\": 14.314040660858154}", "{\"n\": 3070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.4, \"learn_time_ms\": 10441.051, \"total_train_time_s\": 14.259299039840698}", "{\"n\": 3071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3515.29, \"learn_time_ms\": 10629.965, \"total_train_time_s\": 14.880317449569702}", "{\"n\": 3072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 10714.53, \"total_train_time_s\": 14.592383623123169}", "{\"n\": 3073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.06, \"learn_time_ms\": 10797.761, \"total_train_time_s\": 14.399249792098999}", "{\"n\": 3074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.14, \"learn_time_ms\": 10807.333, \"total_train_time_s\": 14.515533208847046}", "{\"n\": 3075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.14, \"learn_time_ms\": 10938.635, \"total_train_time_s\": 15.290560483932495}", "{\"n\": 3076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3498.83, \"learn_time_ms\": 10864.643, \"total_train_time_s\": 13.951363563537598}", "{\"n\": 3077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3459.69, \"learn_time_ms\": 10830.067, \"total_train_time_s\": 14.434715032577515}", "{\"n\": 3078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3459.69, \"learn_time_ms\": 10712.427, \"total_train_time_s\": 13.433688879013062}", "{\"n\": 3079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3445.9, \"learn_time_ms\": 10800.024, \"total_train_time_s\": 14.83679986000061}", "{\"n\": 3080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3451.06, \"learn_time_ms\": 10663.066, \"total_train_time_s\": 12.994714260101318}", "{\"n\": 3081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3462.96, \"learn_time_ms\": 10590.488, \"total_train_time_s\": 14.090080738067627}", "{\"n\": 3082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3462.96, \"learn_time_ms\": 10587.431, \"total_train_time_s\": 14.67939567565918}", "{\"n\": 3083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3446.79, \"learn_time_ms\": 10496.207, \"total_train_time_s\": 13.54569697380066}", "{\"n\": 3084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3451.88, \"learn_time_ms\": 10400.867, \"total_train_time_s\": 13.565908908843994}", "{\"n\": 3085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3451.88, \"learn_time_ms\": 10261.599, \"total_train_time_s\": 14.096137046813965}", "{\"n\": 3086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3459.31, \"learn_time_ms\": 10246.581, \"total_train_time_s\": 13.787081003189087}", "{\"n\": 3087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3460.44, \"learn_time_ms\": 10172.245, \"total_train_time_s\": 13.806392908096313}", "{\"n\": 3088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3460.13, \"learn_time_ms\": 10282.555, \"total_train_time_s\": 14.154335498809814}", "{\"n\": 3089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.69, \"learn_time_ms\": 10267.677, \"total_train_time_s\": 14.754046440124512}", "{\"n\": 3090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3457.82, \"learn_time_ms\": 10456.57, \"total_train_time_s\": 14.55782699584961}", "{\"n\": 3091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3451.86, \"learn_time_ms\": 10401.839, \"total_train_time_s\": 13.50176477432251}", "{\"n\": 3092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3446.95, \"learn_time_ms\": 10334.438, \"total_train_time_s\": 14.017441511154175}", "{\"n\": 3093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3447.99, \"learn_time_ms\": 10405.709, \"total_train_time_s\": 14.479036092758179}", "{\"n\": 3094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.93, \"learn_time_ms\": 10462.22, \"total_train_time_s\": 14.10147476196289}", "{\"n\": 3095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.21, \"learn_time_ms\": 10496.627, \"total_train_time_s\": 14.646263360977173}", "{\"n\": 3096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.21, \"learn_time_ms\": 10581.799, \"total_train_time_s\": 14.661595106124878}", "{\"n\": 3097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3447.44, \"learn_time_ms\": 10558.083, \"total_train_time_s\": 13.515270709991455}", "{\"n\": 3098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3444.34, \"learn_time_ms\": 10504.435, \"total_train_time_s\": 13.559370040893555}", "{\"n\": 3099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.04, \"learn_time_ms\": 10407.358, \"total_train_time_s\": 13.969437837600708}", "{\"n\": 3100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3441.41, \"learn_time_ms\": 10374.412, \"total_train_time_s\": 14.33250379562378}", "{\"n\": 3101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3454.3, \"learn_time_ms\": 10411.115, \"total_train_time_s\": 13.947033405303955}", "{\"n\": 3102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3449.28, \"learn_time_ms\": 10470.171, \"total_train_time_s\": 14.77809739112854}", "{\"n\": 3103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3434.06, \"learn_time_ms\": 10557.308, \"total_train_time_s\": 15.300657033920288}", "{\"n\": 3104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3434.06, \"learn_time_ms\": 10601.914, \"total_train_time_s\": 14.581435918807983}", "{\"n\": 3105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3431.19, \"learn_time_ms\": 10576.691, \"total_train_time_s\": 14.033834218978882}", "{\"n\": 3106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3420.29, \"learn_time_ms\": 10517.594, \"total_train_time_s\": 14.037850379943848}", "{\"n\": 3107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3420.29, \"learn_time_ms\": 10570.657, \"total_train_time_s\": 14.143752336502075}", "{\"n\": 3108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.33, \"learn_time_ms\": 10591.6, \"total_train_time_s\": 14.140095949172974}", "{\"n\": 3109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3414.0, \"learn_time_ms\": 10677.713, \"total_train_time_s\": 14.630461692810059}", "{\"n\": 3110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.38, \"learn_time_ms\": 10658.428, \"total_train_time_s\": 14.173532009124756}", "{\"n\": 3111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.56, \"learn_time_ms\": 10715.233, \"total_train_time_s\": 14.619465112686157}", "{\"n\": 3112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.56, \"learn_time_ms\": 10734.193, \"total_train_time_s\": 14.62148904800415}", "{\"n\": 3113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.24, \"learn_time_ms\": 10548.743, \"total_train_time_s\": 13.320420980453491}", "{\"n\": 3114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.09, \"learn_time_ms\": 10526.405, \"total_train_time_s\": 14.433021068572998}", "{\"n\": 3115, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.47, \"learn_time_ms\": 10515.371, \"total_train_time_s\": 13.949058532714844}", "{\"n\": 3116, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.47, \"learn_time_ms\": 10572.245, \"total_train_time_s\": 14.755634307861328}", "{\"n\": 3117, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3354.65, \"learn_time_ms\": 10511.971, \"total_train_time_s\": 13.178803443908691}", "{\"n\": 3118, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3362.05, \"learn_time_ms\": 10516.733, \"total_train_time_s\": 14.071146011352539}", "{\"n\": 3119, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3358.45, \"learn_time_ms\": 10427.494, \"total_train_time_s\": 13.919745206832886}", "{\"n\": 3120, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3344.11, \"learn_time_ms\": 10466.414, \"total_train_time_s\": 14.72372317314148}", "{\"n\": 3121, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3324.22, \"learn_time_ms\": 10410.499, \"total_train_time_s\": 13.854217290878296}", "{\"n\": 3122, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.65, \"learn_time_ms\": 10405.875, \"total_train_time_s\": 14.762251853942871}", "{\"n\": 3123, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3317.99, \"learn_time_ms\": 10539.223, \"total_train_time_s\": 14.818413972854614}", "{\"n\": 3124, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3327.79, \"learn_time_ms\": 10548.728, \"total_train_time_s\": 14.224034786224365}", "{\"n\": 3125, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.32, \"learn_time_ms\": 10532.742, \"total_train_time_s\": 13.70107650756836}", "{\"n\": 3126, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3326.17, \"learn_time_ms\": 10444.379, \"total_train_time_s\": 13.759438753128052}", "{\"n\": 3127, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.24, \"learn_time_ms\": 10600.583, \"total_train_time_s\": 15.096772193908691}", "{\"n\": 3128, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.72, \"learn_time_ms\": 10658.598, \"total_train_time_s\": 14.56648302078247}", "{\"n\": 3129, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.18, \"learn_time_ms\": 10648.059, \"total_train_time_s\": 13.732281684875488}", "{\"n\": 3130, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3312.93, \"learn_time_ms\": 10696.74, \"total_train_time_s\": 15.21688199043274}", "{\"n\": 3131, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3312.73, \"learn_time_ms\": 10704.4, \"total_train_time_s\": 13.979102611541748}", "{\"n\": 3132, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 10615.295, \"total_train_time_s\": 13.67576789855957}", "{\"n\": 3133, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 10561.842, \"total_train_time_s\": 14.103390455245972}", "{\"n\": 3134, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.23, \"learn_time_ms\": 10540.97, \"total_train_time_s\": 14.082709312438965}", "{\"n\": 3135, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.05, \"learn_time_ms\": 10624.825, \"total_train_time_s\": 14.861291885375977}", "{\"n\": 3136, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.05, \"learn_time_ms\": 10649.152, \"total_train_time_s\": 14.287848949432373}", "{\"n\": 3137, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.75, \"learn_time_ms\": 10726.332, \"total_train_time_s\": 15.600597858428955}", "{\"n\": 3138, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3290.88, \"learn_time_ms\": 10546.166, \"total_train_time_s\": 12.707084655761719}", "{\"n\": 3139, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.73, \"learn_time_ms\": 10635.095, \"total_train_time_s\": 14.769204139709473}", "{\"n\": 3140, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.73, \"learn_time_ms\": 10620.095, \"total_train_time_s\": 15.025899171829224}", "{\"n\": 3141, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.86, \"learn_time_ms\": 10678.911, \"total_train_time_s\": 14.580783605575562}", "{\"n\": 3142, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.82, \"learn_time_ms\": 10666.17, \"total_train_time_s\": 13.513504981994629}", "{\"n\": 3143, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.82, \"learn_time_ms\": 10581.081, \"total_train_time_s\": 13.189004898071289}", "{\"n\": 3144, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.81, \"learn_time_ms\": 10544.454, \"total_train_time_s\": 14.113276720046997}", "{\"n\": 3145, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.93, \"learn_time_ms\": 10505.486, \"total_train_time_s\": 14.309529304504395}", "{\"n\": 3146, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.73, \"learn_time_ms\": 10498.789, \"total_train_time_s\": 14.12178897857666}", "{\"n\": 3147, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.42, \"learn_time_ms\": 10377.133, \"total_train_time_s\": 14.601473093032837}", "{\"n\": 3148, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3257.83, \"learn_time_ms\": 10585.985, \"total_train_time_s\": 14.683200120925903}", "{\"n\": 3149, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.18, \"learn_time_ms\": 10545.603, \"total_train_time_s\": 14.065381288528442}", "{\"n\": 3150, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.83, \"learn_time_ms\": 10477.365, \"total_train_time_s\": 14.263975381851196}", "{\"n\": 3151, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.27, \"learn_time_ms\": 10415.782, \"total_train_time_s\": 14.158116817474365}", "{\"n\": 3152, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.82, \"learn_time_ms\": 10414.112, \"total_train_time_s\": 13.63344931602478}", "{\"n\": 3153, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.16, \"learn_time_ms\": 10630.876, \"total_train_time_s\": 15.302618026733398}", "{\"n\": 3154, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.16, \"learn_time_ms\": 10747.569, \"total_train_time_s\": 14.946783542633057}", "{\"n\": 3155, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.1, \"learn_time_ms\": 10733.563, \"total_train_time_s\": 14.0231614112854}", "{\"n\": 3156, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 10674.534, \"total_train_time_s\": 13.521173477172852}", "{\"n\": 3157, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 10639.077, \"total_train_time_s\": 14.344390392303467}", "{\"n\": 3158, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.87, \"learn_time_ms\": 10632.718, \"total_train_time_s\": 14.831431150436401}", "{\"n\": 3159, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.54, \"learn_time_ms\": 10623.848, \"total_train_time_s\": 14.004048585891724}", "{\"n\": 3160, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.29, \"learn_time_ms\": 10552.541, \"total_train_time_s\": 13.406612396240234}", "{\"n\": 3161, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.29, \"learn_time_ms\": 10667.694, \"total_train_time_s\": 15.1400625705719}", "{\"n\": 3162, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.6, \"learn_time_ms\": 10786.581, \"total_train_time_s\": 14.647008419036865}", "{\"n\": 3163, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.6, \"learn_time_ms\": 10683.023, \"total_train_time_s\": 14.359899759292603}", "{\"n\": 3164, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.01, \"learn_time_ms\": 10524.693, \"total_train_time_s\": 13.497801780700684}", "{\"n\": 3165, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.62, \"learn_time_ms\": 10506.613, \"total_train_time_s\": 13.89099383354187}", "{\"n\": 3166, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.62, \"learn_time_ms\": 10565.704, \"total_train_time_s\": 13.973485469818115}", "{\"n\": 3167, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.34, \"learn_time_ms\": 10488.14, \"total_train_time_s\": 13.338406085968018}", "{\"n\": 3168, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.14, \"learn_time_ms\": 10411.29, \"total_train_time_s\": 14.035228252410889}", "{\"n\": 3169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.58, \"learn_time_ms\": 10473.516, \"total_train_time_s\": 14.940629959106445}", "{\"n\": 3170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.84, \"learn_time_ms\": 10535.597, \"total_train_time_s\": 14.088215589523315}", "{\"n\": 3171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.84, \"learn_time_ms\": 10324.587, \"total_train_time_s\": 13.200881958007812}", "{\"n\": 3172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.45, \"learn_time_ms\": 10256.131, \"total_train_time_s\": 14.170782327651978}", "{\"n\": 3173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.45, \"learn_time_ms\": 10199.95, \"total_train_time_s\": 13.94377589225769}", "{\"n\": 3174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.45, \"learn_time_ms\": 10270.053, \"total_train_time_s\": 14.192001581192017}", "{\"n\": 3175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.08, \"learn_time_ms\": 10269.617, \"total_train_time_s\": 14.023153066635132}", "{\"n\": 3176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.03, \"learn_time_ms\": 10352.902, \"total_train_time_s\": 15.059500217437744}", "{\"n\": 3177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.45, \"learn_time_ms\": 10442.167, \"total_train_time_s\": 14.06597638130188}", "{\"n\": 3178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.45, \"learn_time_ms\": 10378.14, \"total_train_time_s\": 13.455342769622803}", "{\"n\": 3179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.66, \"learn_time_ms\": 10362.059, \"total_train_time_s\": 14.529555559158325}", "{\"n\": 3180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.3, \"learn_time_ms\": 10384.162, \"total_train_time_s\": 14.496233463287354}", "{\"n\": 3181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.3, \"learn_time_ms\": 10446.839, \"total_train_time_s\": 13.537991285324097}", "{\"n\": 3182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 10467.811, \"total_train_time_s\": 14.460345268249512}", "{\"n\": 3183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.91, \"learn_time_ms\": 10437.913, \"total_train_time_s\": 13.653274059295654}", "{\"n\": 3184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.29, \"learn_time_ms\": 10481.69, \"total_train_time_s\": 14.659494876861572}", "{\"n\": 3185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.29, \"learn_time_ms\": 10502.903, \"total_train_time_s\": 14.330768346786499}", "{\"n\": 3186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.89, \"learn_time_ms\": 10401.146, \"total_train_time_s\": 13.992589473724365}", "{\"n\": 3187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.72, \"learn_time_ms\": 10355.727, \"total_train_time_s\": 13.892842054367065}", "{\"n\": 3188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.71, \"learn_time_ms\": 10406.228, \"total_train_time_s\": 13.827551364898682}", "{\"n\": 3189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.71, \"learn_time_ms\": 10362.578, \"total_train_time_s\": 14.563392162322998}", "{\"n\": 3190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.71, \"learn_time_ms\": 10347.198, \"total_train_time_s\": 14.40975570678711}", "{\"n\": 3191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.94, \"learn_time_ms\": 10393.266, \"total_train_time_s\": 14.197788000106812}", "{\"n\": 3192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.94, \"learn_time_ms\": 10356.649, \"total_train_time_s\": 13.95618486404419}", "{\"n\": 3193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.9, \"learn_time_ms\": 10487.046, \"total_train_time_s\": 15.085561752319336}", "{\"n\": 3194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3242.32, \"learn_time_ms\": 10428.671, \"total_train_time_s\": 13.912057161331177}", "{\"n\": 3195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.52, \"learn_time_ms\": 10556.453, \"total_train_time_s\": 15.532512903213501}", "{\"n\": 3196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.52, \"learn_time_ms\": 10489.577, \"total_train_time_s\": 13.184964418411255}", "{\"n\": 3197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.3, \"learn_time_ms\": 10480.066, \"total_train_time_s\": 13.59050440788269}", "{\"n\": 3198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.3, \"learn_time_ms\": 10598.137, \"total_train_time_s\": 14.839987516403198}", "{\"n\": 3199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3268.0, \"learn_time_ms\": 10533.659, \"total_train_time_s\": 13.574602842330933}", "{\"n\": 3200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.53, \"learn_time_ms\": 10572.656, \"total_train_time_s\": 14.639609575271606}", "{\"n\": 3201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.53, \"learn_time_ms\": 10606.084, \"total_train_time_s\": 14.697244644165039}", "{\"n\": 3202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.16, \"learn_time_ms\": 10734.385, \"total_train_time_s\": 15.33446455001831}", "{\"n\": 3203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.85, \"learn_time_ms\": 10594.578, \"total_train_time_s\": 13.302303314208984}", "{\"n\": 3204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.59, \"learn_time_ms\": 10692.195, \"total_train_time_s\": 14.724793195724487}", "{\"n\": 3205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.59, \"learn_time_ms\": 10653.158, \"total_train_time_s\": 15.472321271896362}", "{\"n\": 3206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.08, \"learn_time_ms\": 10696.714, \"total_train_time_s\": 13.796123504638672}", "{\"n\": 3207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.62, \"learn_time_ms\": 10673.926, \"total_train_time_s\": 13.473337650299072}", "{\"n\": 3208, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.35, \"learn_time_ms\": 10554.828, \"total_train_time_s\": 13.71750020980835}", "{\"n\": 3209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.35, \"learn_time_ms\": 10729.296, \"total_train_time_s\": 15.478801965713501}", "{\"n\": 3210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.35, \"learn_time_ms\": 10713.974, \"total_train_time_s\": 14.435215473175049}", "{\"n\": 3211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.85, \"learn_time_ms\": 10599.649, \"total_train_time_s\": 13.2551429271698}", "{\"n\": 3212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 10503.886, \"total_train_time_s\": 14.372838735580444}", "{\"n\": 3213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 10611.304, \"total_train_time_s\": 14.357940196990967}", "{\"n\": 3214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.92, \"learn_time_ms\": 10528.964, \"total_train_time_s\": 13.973001480102539}", "{\"n\": 3215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.89, \"learn_time_ms\": 10455.705, \"total_train_time_s\": 14.180945873260498}", "{\"n\": 3216, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.26, \"learn_time_ms\": 10518.321, \"total_train_time_s\": 14.512114763259888}", "{\"n\": 3217, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3336.48, \"learn_time_ms\": 10595.191, \"total_train_time_s\": 14.167771816253662}", "{\"n\": 3218, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.0, \"learn_time_ms\": 10598.686, \"total_train_time_s\": 13.853661298751831}", "{\"n\": 3219, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.32, \"learn_time_ms\": 10569.402, \"total_train_time_s\": 15.006273031234741}", "{\"n\": 3220, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.32, \"learn_time_ms\": 10451.005, \"total_train_time_s\": 13.450926780700684}", "{\"n\": 3221, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.54, \"learn_time_ms\": 10552.568, \"total_train_time_s\": 14.260266304016113}", "{\"n\": 3222, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.73, \"learn_time_ms\": 10499.007, \"total_train_time_s\": 13.832857608795166}", "{\"n\": 3223, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3307.25, \"learn_time_ms\": 10520.301, \"total_train_time_s\": 14.69401240348816}", "{\"n\": 3224, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.62, \"learn_time_ms\": 10547.238, \"total_train_time_s\": 14.626300573348999}", "{\"n\": 3225, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.35, \"learn_time_ms\": 10545.435, \"total_train_time_s\": 14.32602596282959}", "{\"n\": 3226, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.35, \"learn_time_ms\": 10536.185, \"total_train_time_s\": 14.23092269897461}", "{\"n\": 3227, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3323.18, \"learn_time_ms\": 10548.54, \"total_train_time_s\": 14.359244108200073}", "{\"n\": 3228, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.96, \"learn_time_ms\": 10610.633, \"total_train_time_s\": 14.399163722991943}", "{\"n\": 3229, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.61, \"learn_time_ms\": 10427.009, \"total_train_time_s\": 12.964424133300781}", "{\"n\": 3230, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3338.52, \"learn_time_ms\": 10493.722, \"total_train_time_s\": 13.802916049957275}", "{\"n\": 3231, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3330.14, \"learn_time_ms\": 10471.46, \"total_train_time_s\": 14.317440509796143}", "{\"n\": 3232, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.34, \"learn_time_ms\": 10529.281, \"total_train_time_s\": 14.288240432739258}", "{\"n\": 3233, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.34, \"learn_time_ms\": 10563.454, \"total_train_time_s\": 15.132097482681274}", "{\"n\": 3234, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.09, \"learn_time_ms\": 10554.047, \"total_train_time_s\": 14.30383849143982}", "{\"n\": 3235, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3340.09, \"learn_time_ms\": 10447.975, \"total_train_time_s\": 13.323923826217651}", "{\"n\": 3236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3348.38, \"learn_time_ms\": 10517.985, \"total_train_time_s\": 14.732691049575806}", "{\"n\": 3237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3351.73, \"learn_time_ms\": 10483.932, \"total_train_time_s\": 14.033111333847046}", "{\"n\": 3238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3365.49, \"learn_time_ms\": 10506.282, \"total_train_time_s\": 14.614001750946045}", "{\"n\": 3239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 10615.541, \"total_train_time_s\": 14.388290405273438}", "{\"n\": 3240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.51, \"learn_time_ms\": 10545.836, \"total_train_time_s\": 13.099690675735474}", "{\"n\": 3241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3385.39, \"learn_time_ms\": 10562.295, \"total_train_time_s\": 14.127388000488281}", "{\"n\": 3242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.92, \"learn_time_ms\": 10622.802, \"total_train_time_s\": 14.76893925666809}", "{\"n\": 3243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3380.92, \"learn_time_ms\": 10622.203, \"total_train_time_s\": 15.188109636306763}", "{\"n\": 3244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.75, \"learn_time_ms\": 10537.133, \"total_train_time_s\": 13.341336488723755}", "{\"n\": 3245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.46, \"learn_time_ms\": 10500.605, \"total_train_time_s\": 12.721229791641235}", "{\"n\": 3246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3377.79, \"learn_time_ms\": 10449.812, \"total_train_time_s\": 14.18340253829956}", "{\"n\": 3247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.73, \"learn_time_ms\": 10426.09, \"total_train_time_s\": 13.707282066345215}", "{\"n\": 3248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.73, \"learn_time_ms\": 10395.001, \"total_train_time_s\": 14.622814893722534}", "{\"n\": 3249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.14, \"learn_time_ms\": 10444.205, \"total_train_time_s\": 14.877822637557983}", "{\"n\": 3250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 10681.389, \"total_train_time_s\": 15.860392332077026}", "{\"n\": 3251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.1, \"learn_time_ms\": 10701.321, \"total_train_time_s\": 14.455116033554077}", "{\"n\": 3252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.74, \"learn_time_ms\": 10666.195, \"total_train_time_s\": 14.482403755187988}", "{\"n\": 3253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.95, \"learn_time_ms\": 10568.022, \"total_train_time_s\": 14.036943197250366}", "{\"n\": 3254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3413.69, \"learn_time_ms\": 10696.319, \"total_train_time_s\": 14.877866268157959}", "{\"n\": 3255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3413.69, \"learn_time_ms\": 10754.886, \"total_train_time_s\": 13.655757188796997}", "{\"n\": 3256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3416.03, \"learn_time_ms\": 10742.863, \"total_train_time_s\": 14.205572366714478}", "{\"n\": 3257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3433.5, \"learn_time_ms\": 10795.345, \"total_train_time_s\": 14.307136058807373}", "{\"n\": 3258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3448.17, \"learn_time_ms\": 10747.232, \"total_train_time_s\": 14.024451732635498}", "{\"n\": 3259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3450.38, \"learn_time_ms\": 10709.5, \"total_train_time_s\": 14.28078317642212}", "{\"n\": 3260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3458.51, \"learn_time_ms\": 10570.87, \"total_train_time_s\": 14.157967567443848}", "{\"n\": 3261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3458.51, \"learn_time_ms\": 10582.888, \"total_train_time_s\": 14.513217687606812}", "{\"n\": 3262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3458.51, \"learn_time_ms\": 10538.988, \"total_train_time_s\": 14.414465427398682}", "{\"n\": 3263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.84, \"learn_time_ms\": 10540.228, \"total_train_time_s\": 13.96248722076416}", "{\"n\": 3264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.95, \"learn_time_ms\": 10540.013, \"total_train_time_s\": 14.571904182434082}", "{\"n\": 3265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.95, \"learn_time_ms\": 10578.118, \"total_train_time_s\": 13.946139097213745}", "{\"n\": 3266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3433.12, \"learn_time_ms\": 10626.156, \"total_train_time_s\": 14.596800088882446}", "{\"n\": 3267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.2, \"learn_time_ms\": 10615.33, \"total_train_time_s\": 14.07081651687622}", "{\"n\": 3268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.2, \"learn_time_ms\": 10731.127, \"total_train_time_s\": 15.27402114868164}", "{\"n\": 3269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3464.2, \"learn_time_ms\": 10748.165, \"total_train_time_s\": 14.519932985305786}", "{\"n\": 3270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3455.25, \"learn_time_ms\": 10697.03, \"total_train_time_s\": 13.86250925064087}", "{\"n\": 3271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.42, \"learn_time_ms\": 10617.112, \"total_train_time_s\": 13.877044677734375}", "{\"n\": 3272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3456.42, \"learn_time_ms\": 10692.215, \"total_train_time_s\": 14.799702405929565}", "{\"n\": 3273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3463.25, \"learn_time_ms\": 10681.396, \"total_train_time_s\": 13.855953454971313}", "{\"n\": 3274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3472.61, \"learn_time_ms\": 10716.171, \"total_train_time_s\": 15.048315048217773}", "{\"n\": 3275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3481.5, \"learn_time_ms\": 10695.235, \"total_train_time_s\": 13.560612440109253}", "{\"n\": 3276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3481.52, \"learn_time_ms\": 10655.0, \"total_train_time_s\": 14.430087327957153}", "{\"n\": 3277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3480.49, \"learn_time_ms\": 10711.852, \"total_train_time_s\": 14.628068923950195}", "{\"n\": 3278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3480.49, \"learn_time_ms\": 10592.641, \"total_train_time_s\": 13.838386297225952}", "{\"n\": 3279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3491.22, \"learn_time_ms\": 10468.048, \"total_train_time_s\": 13.459517002105713}", "{\"n\": 3280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3487.26, \"learn_time_ms\": 10544.371, \"total_train_time_s\": 14.382296562194824}", "{\"n\": 3281, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3486.63, \"learn_time_ms\": 10613.567, \"total_train_time_s\": 14.598307609558105}", "{\"n\": 3282, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3484.53, \"learn_time_ms\": 10463.134, \"total_train_time_s\": 13.220963478088379}", "{\"n\": 3283, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3474.55, \"learn_time_ms\": 10540.611, \"total_train_time_s\": 14.787741899490356}", "{\"n\": 3284, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3480.36, \"learn_time_ms\": 10474.118, \"total_train_time_s\": 14.252669334411621}", "{\"n\": 3285, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3480.36, \"learn_time_ms\": 10492.699, \"total_train_time_s\": 13.779970169067383}", "{\"n\": 3286, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3476.54, \"learn_time_ms\": 10493.384, \"total_train_time_s\": 14.339946985244751}", "{\"n\": 3287, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3499.76, \"learn_time_ms\": 10492.512, \"total_train_time_s\": 14.813738346099854}", "{\"n\": 3288, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3502.16, \"learn_time_ms\": 10499.599, \"total_train_time_s\": 13.896050214767456}", "{\"n\": 3289, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3502.16, \"learn_time_ms\": 10637.417, \"total_train_time_s\": 14.846278667449951}", "{\"n\": 3290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3500.12, \"learn_time_ms\": 10626.063, \"total_train_time_s\": 14.59103798866272}", "{\"n\": 3291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3506.32, \"learn_time_ms\": 10564.445, \"total_train_time_s\": 13.953380107879639}", "{\"n\": 3292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.17, \"learn_time_ms\": 10600.916, \"total_train_time_s\": 13.845746517181396}", "{\"n\": 3293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.17, \"learn_time_ms\": 10467.589, \"total_train_time_s\": 13.379648923873901}", "{\"n\": 3294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3527.63, \"learn_time_ms\": 10428.857, \"total_train_time_s\": 14.037401676177979}", "{\"n\": 3295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3527.63, \"learn_time_ms\": 10566.045, \"total_train_time_s\": 15.089686155319214}", "{\"n\": 3296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3530.34, \"learn_time_ms\": 10514.159, \"total_train_time_s\": 13.661133527755737}", "{\"n\": 3297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3530.34, \"learn_time_ms\": 10491.807, \"total_train_time_s\": 14.327148914337158}", "{\"n\": 3298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3529.32, \"learn_time_ms\": 10586.446, \"total_train_time_s\": 14.801605701446533}", "{\"n\": 3299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3529.32, \"learn_time_ms\": 10522.219, \"total_train_time_s\": 14.10247015953064}", "{\"n\": 3300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.29, \"learn_time_ms\": 10416.425, \"total_train_time_s\": 13.147113800048828}", "{\"n\": 3301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3519.97, \"learn_time_ms\": 10502.07, \"total_train_time_s\": 14.935737133026123}", "{\"n\": 3302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.24, \"learn_time_ms\": 10547.87, \"total_train_time_s\": 14.076828479766846}", "{\"n\": 3303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3525.24, \"learn_time_ms\": 10661.466, \"total_train_time_s\": 14.695099592208862}", "{\"n\": 3304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3532.24, \"learn_time_ms\": 10665.247, \"total_train_time_s\": 14.124536991119385}", "{\"n\": 3305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3532.24, \"learn_time_ms\": 10509.9, \"total_train_time_s\": 13.799793720245361}", "{\"n\": 3306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3533.84, \"learn_time_ms\": 10587.015, \"total_train_time_s\": 14.466988801956177}", "{\"n\": 3307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3539.64, \"learn_time_ms\": 10513.073, \"total_train_time_s\": 13.709221839904785}", "{\"n\": 3308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3545.27, \"learn_time_ms\": 10472.189, \"total_train_time_s\": 14.468991756439209}", "{\"n\": 3309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3566.15, \"learn_time_ms\": 10551.32, \"total_train_time_s\": 14.961882829666138}", "{\"n\": 3310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3582.76, \"learn_time_ms\": 10767.295, \"total_train_time_s\": 15.59790849685669}", "{\"n\": 3311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10665.597, \"total_train_time_s\": 13.644930601119995}", "{\"n\": 3312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10677.126, \"total_train_time_s\": 14.544319868087769}", "{\"n\": 3313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3582.5, \"learn_time_ms\": 10698.248, \"total_train_time_s\": 14.823248386383057}", "{\"n\": 3314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3578.71, \"learn_time_ms\": 10831.129, \"total_train_time_s\": 15.545987844467163}", "{\"n\": 3315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3578.71, \"learn_time_ms\": 10907.014, \"total_train_time_s\": 14.626529455184937}", "{\"n\": 3316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3584.74, \"learn_time_ms\": 10898.553, \"total_train_time_s\": 14.679844856262207}", "{\"n\": 3317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.06, \"learn_time_ms\": 10915.729, \"total_train_time_s\": 13.88971495628357}", "{\"n\": 3318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3584.63, \"learn_time_ms\": 10980.333, \"total_train_time_s\": 15.305394411087036}", "{\"n\": 3319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3589.91, \"learn_time_ms\": 10954.952, \"total_train_time_s\": 14.412870407104492}", "{\"n\": 3320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.79, \"learn_time_ms\": 10854.593, \"total_train_time_s\": 14.401537418365479}", "{\"n\": 3321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.32, \"learn_time_ms\": 10896.346, \"total_train_time_s\": 14.091476917266846}", "{\"n\": 3322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.61, \"learn_time_ms\": 10915.958, \"total_train_time_s\": 14.87889575958252}", "{\"n\": 3323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.61, \"learn_time_ms\": 10743.588, \"total_train_time_s\": 13.261032581329346}", "{\"n\": 3324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.61, \"learn_time_ms\": 10631.521, \"total_train_time_s\": 14.376770257949829}", "{\"n\": 3325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3628.46, \"learn_time_ms\": 10584.047, \"total_train_time_s\": 13.866456508636475}", "{\"n\": 3326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3634.08, \"learn_time_ms\": 10510.624, \"total_train_time_s\": 13.866819858551025}", "{\"n\": 3327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3634.08, \"learn_time_ms\": 10564.719, \"total_train_time_s\": 14.503361225128174}", "{\"n\": 3328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3639.97, \"learn_time_ms\": 10463.01, \"total_train_time_s\": 14.132239580154419}", "{\"n\": 3329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3639.97, \"learn_time_ms\": 10473.444, \"total_train_time_s\": 14.492729902267456}", "{\"n\": 3330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.24, \"learn_time_ms\": 10422.572, \"total_train_time_s\": 13.907384872436523}", "{\"n\": 3331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.24, \"learn_time_ms\": 10353.759, \"total_train_time_s\": 13.619789838790894}", "{\"n\": 3332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3663.22, \"learn_time_ms\": 10299.195, \"total_train_time_s\": 13.993053197860718}", "{\"n\": 3333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3660.2, \"learn_time_ms\": 10372.746, \"total_train_time_s\": 13.62434434890747}", "{\"n\": 3334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3660.2, \"learn_time_ms\": 10337.407, \"total_train_time_s\": 13.755836963653564}", "{\"n\": 3335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3663.19, \"learn_time_ms\": 10318.774, \"total_train_time_s\": 13.65387225151062}", "{\"n\": 3336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3672.18, \"learn_time_ms\": 10398.412, \"total_train_time_s\": 14.62935757637024}", "{\"n\": 3337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3672.18, \"learn_time_ms\": 10376.686, \"total_train_time_s\": 14.213083028793335}", "{\"n\": 3338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3696.09, \"learn_time_ms\": 10391.889, \"total_train_time_s\": 14.174476861953735}", "{\"n\": 3339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3692.1, \"learn_time_ms\": 10412.528, \"total_train_time_s\": 14.796570777893066}", "{\"n\": 3340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3683.47, \"learn_time_ms\": 10505.807, \"total_train_time_s\": 14.850383281707764}", "{\"n\": 3341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3676.01, \"learn_time_ms\": 10497.366, \"total_train_time_s\": 13.399370193481445}", "{\"n\": 3342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3676.01, \"learn_time_ms\": 10511.972, \"total_train_time_s\": 14.20514702796936}", "{\"n\": 3343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3680.65, \"learn_time_ms\": 10563.175, \"total_train_time_s\": 14.244288921356201}", "{\"n\": 3344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3670.38, \"learn_time_ms\": 10570.933, \"total_train_time_s\": 13.860630989074707}", "{\"n\": 3345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3670.38, \"learn_time_ms\": 10597.307, \"total_train_time_s\": 14.135524988174438}", "{\"n\": 3346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3663.68, \"learn_time_ms\": 10527.666, \"total_train_time_s\": 13.646605968475342}", "{\"n\": 3347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.94, \"learn_time_ms\": 10575.45, \"total_train_time_s\": 14.795745849609375}", "{\"n\": 3348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3656.03, \"learn_time_ms\": 10624.808, \"total_train_time_s\": 14.635277509689331}", "{\"n\": 3349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3656.03, \"learn_time_ms\": 10672.427, \"total_train_time_s\": 15.371244192123413}", "{\"n\": 3350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3644.29, \"learn_time_ms\": 10636.1, \"total_train_time_s\": 14.498785495758057}", "{\"n\": 3351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.0, \"learn_time_ms\": 10660.505, \"total_train_time_s\": 13.67544174194336}", "{\"n\": 3352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.0, \"learn_time_ms\": 10772.338, \"total_train_time_s\": 15.253182649612427}", "{\"n\": 3353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3654.16, \"learn_time_ms\": 10816.251, \"total_train_time_s\": 14.66785454750061}", "{\"n\": 3354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3673.36, \"learn_time_ms\": 10812.431, \"total_train_time_s\": 13.765344142913818}", "{\"n\": 3355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3673.36, \"learn_time_ms\": 10824.041, \"total_train_time_s\": 14.321148157119751}", "{\"n\": 3356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3671.9, \"learn_time_ms\": 10823.71, \"total_train_time_s\": 14.01267147064209}", "{\"n\": 3357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3680.33, \"learn_time_ms\": 10833.977, \"total_train_time_s\": 14.698217153549194}", "{\"n\": 3358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3680.33, \"learn_time_ms\": 10716.608, \"total_train_time_s\": 13.531761169433594}", "{\"n\": 3359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3680.33, \"learn_time_ms\": 10580.072, \"total_train_time_s\": 13.834717273712158}", "{\"n\": 3360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3672.36, \"learn_time_ms\": 10538.197, \"total_train_time_s\": 14.164735794067383}", "{\"n\": 3361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3693.22, \"learn_time_ms\": 10594.371, \"total_train_time_s\": 14.093350887298584}", "{\"n\": 3362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3693.22, \"learn_time_ms\": 10421.605, \"total_train_time_s\": 13.382621049880981}", "{\"n\": 3363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3698.64, \"learn_time_ms\": 10415.434, \"total_train_time_s\": 14.6820228099823}", "{\"n\": 3364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3696.9, \"learn_time_ms\": 10383.792, \"total_train_time_s\": 13.647748470306396}", "{\"n\": 3365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3701.21, \"learn_time_ms\": 10367.334, \"total_train_time_s\": 14.03352689743042}", "{\"n\": 3366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3683.37, \"learn_time_ms\": 10434.677, \"total_train_time_s\": 14.340829610824585}", "{\"n\": 3367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3683.37, \"learn_time_ms\": 10330.254, \"total_train_time_s\": 13.671624422073364}", "{\"n\": 3368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3690.6, \"learn_time_ms\": 10385.553, \"total_train_time_s\": 14.331131219863892}", "{\"n\": 3369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3710.34, \"learn_time_ms\": 10419.088, \"total_train_time_s\": 14.331563472747803}", "{\"n\": 3370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3710.33, \"learn_time_ms\": 10480.409, \"total_train_time_s\": 14.843263626098633}", "{\"n\": 3371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3711.11, \"learn_time_ms\": 10512.11, \"total_train_time_s\": 14.626555681228638}", "{\"n\": 3372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3720.89, \"learn_time_ms\": 10697.551, \"total_train_time_s\": 15.33563232421875}", "{\"n\": 3373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3725.04, \"learn_time_ms\": 10647.208, \"total_train_time_s\": 14.050088882446289}", "{\"n\": 3374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3709.2, \"learn_time_ms\": 10739.084, \"total_train_time_s\": 14.362379789352417}", "{\"n\": 3375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3709.2, \"learn_time_ms\": 10700.986, \"total_train_time_s\": 13.884167194366455}", "{\"n\": 3376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3726.26, \"learn_time_ms\": 10632.236, \"total_train_time_s\": 13.735644102096558}", "{\"n\": 3377, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3726.26, \"learn_time_ms\": 10684.965, \"total_train_time_s\": 14.221490859985352}", "{\"n\": 3378, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3712.9, \"learn_time_ms\": 10683.177, \"total_train_time_s\": 14.031522989273071}", "{\"n\": 3379, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3703.53, \"learn_time_ms\": 10701.659, \"total_train_time_s\": 14.727356910705566}", "{\"n\": 3380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3700.33, \"learn_time_ms\": 10756.157, \"total_train_time_s\": 15.19352102279663}", "{\"n\": 3381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3706.9, \"learn_time_ms\": 10711.363, \"total_train_time_s\": 14.003800630569458}", "{\"n\": 3382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.12, \"learn_time_ms\": 10581.673, \"total_train_time_s\": 13.946162462234497}", "{\"n\": 3383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.12, \"learn_time_ms\": 10509.609, \"total_train_time_s\": 13.308886289596558}", "{\"n\": 3384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.12, \"learn_time_ms\": 10668.535, \"total_train_time_s\": 16.052658796310425}", "{\"n\": 3385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3710.29, \"learn_time_ms\": 10798.994, \"total_train_time_s\": 14.729669094085693}", "{\"n\": 3386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3711.29, \"learn_time_ms\": 10926.834, \"total_train_time_s\": 15.044034481048584}", "{\"n\": 3387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3711.29, \"learn_time_ms\": 10875.454, \"total_train_time_s\": 13.89023494720459}", "{\"n\": 3388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3726.69, \"learn_time_ms\": 10882.967, \"total_train_time_s\": 14.232660055160522}", "{\"n\": 3389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3717.63, \"learn_time_ms\": 10866.354, \"total_train_time_s\": 14.4451904296875}", "{\"n\": 3390, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3733.83, \"learn_time_ms\": 10779.064, \"total_train_time_s\": 14.363611221313477}", "{\"n\": 3391, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3733.83, \"learn_time_ms\": 10703.214, \"total_train_time_s\": 13.147916793823242}", "{\"n\": 3392, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3723.89, \"learn_time_ms\": 10720.806, \"total_train_time_s\": 14.085577964782715}", "{\"n\": 3393, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3730.68, \"learn_time_ms\": 10832.562, \"total_train_time_s\": 14.711308002471924}", "{\"n\": 3394, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3721.31, \"learn_time_ms\": 10637.105, \"total_train_time_s\": 14.114943981170654}", "{\"n\": 3395, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3721.31, \"learn_time_ms\": 10606.567, \"total_train_time_s\": 14.436186075210571}", "{\"n\": 3396, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3717.12, \"learn_time_ms\": 10553.219, \"total_train_time_s\": 14.63531494140625}", "{\"n\": 3397, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3711.22, \"learn_time_ms\": 10588.793, \"total_train_time_s\": 14.464033365249634}", "{\"n\": 3398, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3704.16, \"learn_time_ms\": 10526.386, \"total_train_time_s\": 13.488625288009644}", "{\"n\": 3399, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3704.16, \"learn_time_ms\": 10578.365, \"total_train_time_s\": 14.663938045501709}", "{\"n\": 3400, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3701.19, \"learn_time_ms\": 10499.321, \"total_train_time_s\": 13.70339035987854}", "{\"n\": 3401, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3701.97, \"learn_time_ms\": 10570.842, \"total_train_time_s\": 14.149606943130493}", "{\"n\": 3402, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3698.6, \"learn_time_ms\": 10621.164, \"total_train_time_s\": 14.7484610080719}", "{\"n\": 3403, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3698.6, \"learn_time_ms\": 10492.323, \"total_train_time_s\": 13.112462997436523}", "{\"n\": 3404, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3697.0, \"learn_time_ms\": 10468.455, \"total_train_time_s\": 13.923083782196045}", "{\"n\": 3405, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3707.94, \"learn_time_ms\": 10526.598, \"total_train_time_s\": 14.982418537139893}", "{\"n\": 3406, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3707.94, \"learn_time_ms\": 10534.493, \"total_train_time_s\": 14.835679769515991}", "{\"n\": 3407, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3707.94, \"learn_time_ms\": 10544.972, \"total_train_time_s\": 14.122906684875488}", "{\"n\": 3408, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3712.33, \"learn_time_ms\": 10582.317, \"total_train_time_s\": 14.066583156585693}", "{\"n\": 3409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3698.53, \"learn_time_ms\": 10519.407, \"total_train_time_s\": 14.110426664352417}", "{\"n\": 3410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3698.53, \"learn_time_ms\": 10583.288, \"total_train_time_s\": 14.151758670806885}", "{\"n\": 3411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3709.74, \"learn_time_ms\": 10567.368, \"total_train_time_s\": 13.66928505897522}", "{\"n\": 3412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3714.73, \"learn_time_ms\": 10497.374, \"total_train_time_s\": 13.96701431274414}", "{\"n\": 3413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3708.37, \"learn_time_ms\": 10553.303, \"total_train_time_s\": 13.653926372528076}", "{\"n\": 3414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3708.37, \"learn_time_ms\": 10522.716, \"total_train_time_s\": 13.851137399673462}", "{\"n\": 3415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3689.51, \"learn_time_ms\": 10407.986, \"total_train_time_s\": 13.906066656112671}", "{\"n\": 3416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3670.54, \"learn_time_ms\": 10399.741, \"total_train_time_s\": 14.446701765060425}", "{\"n\": 3417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3670.27, \"learn_time_ms\": 10478.244, \"total_train_time_s\": 15.02511739730835}", "{\"n\": 3418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.55, \"learn_time_ms\": 10574.742, \"total_train_time_s\": 14.956046104431152}", "{\"n\": 3419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.55, \"learn_time_ms\": 10508.804, \"total_train_time_s\": 13.89766240119934}", "{\"n\": 3420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3663.06, \"learn_time_ms\": 10478.503, \"total_train_time_s\": 13.848949193954468}", "{\"n\": 3421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3651.38, \"learn_time_ms\": 10539.738, \"total_train_time_s\": 14.5984525680542}", "{\"n\": 3422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3648.85, \"learn_time_ms\": 10463.5, \"total_train_time_s\": 13.114993810653687}", "{\"n\": 3423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3652.07, \"learn_time_ms\": 10471.452, \"total_train_time_s\": 13.770796060562134}", "{\"n\": 3424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3652.07, \"learn_time_ms\": 10545.125, \"total_train_time_s\": 14.53767442703247}", "{\"n\": 3425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3661.87, \"learn_time_ms\": 10495.952, \"total_train_time_s\": 13.46073842048645}", "{\"n\": 3426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3661.87, \"learn_time_ms\": 10328.516, \"total_train_time_s\": 12.783174276351929}", "{\"n\": 3427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3650.74, \"learn_time_ms\": 10139.566, \"total_train_time_s\": 13.345931053161621}", "{\"n\": 3428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3637.85, \"learn_time_ms\": 10085.469, \"total_train_time_s\": 14.45543885231018}", "{\"n\": 3429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3638.46, \"learn_time_ms\": 10136.706, \"total_train_time_s\": 14.117118120193481}", "{\"n\": 3430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3638.46, \"learn_time_ms\": 10297.317, \"total_train_time_s\": 15.8577721118927}", "{\"n\": 3431, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3630.67, \"learn_time_ms\": 10283.56, \"total_train_time_s\": 14.235858678817749}", "{\"n\": 3432, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3630.67, \"learn_time_ms\": 10399.318, \"total_train_time_s\": 14.345141410827637}", "{\"n\": 3433, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3630.67, \"learn_time_ms\": 10382.893, \"total_train_time_s\": 13.720130205154419}", "{\"n\": 3434, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3625.26, \"learn_time_ms\": 10340.229, \"total_train_time_s\": 13.957152366638184}", "{\"n\": 3435, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3625.86, \"learn_time_ms\": 10356.146, \"total_train_time_s\": 13.613785028457642}", "{\"n\": 3436, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3636.04, \"learn_time_ms\": 10408.404, \"total_train_time_s\": 13.342629194259644}", "{\"n\": 3437, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3648.61, \"learn_time_ms\": 10437.606, \"total_train_time_s\": 13.695271492004395}", "{\"n\": 3438, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3658.74, \"learn_time_ms\": 10406.757, \"total_train_time_s\": 14.173062562942505}", "{\"n\": 3439, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3658.74, \"learn_time_ms\": 10434.657, \"total_train_time_s\": 14.417096614837646}", "{\"n\": 3440, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3663.62, \"learn_time_ms\": 10207.768, \"total_train_time_s\": 13.2391357421875}", "{\"n\": 3441, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3669.59, \"learn_time_ms\": 10123.927, \"total_train_time_s\": 13.400858163833618}", "{\"n\": 3442, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3669.59, \"learn_time_ms\": 10060.482, \"total_train_time_s\": 13.865865230560303}", "{\"n\": 3443, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3676.74, \"learn_time_ms\": 10096.059, \"total_train_time_s\": 13.92363691329956}", "{\"n\": 3444, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3676.73, \"learn_time_ms\": 10044.855, \"total_train_time_s\": 13.259117841720581}", "{\"n\": 3445, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3676.73, \"learn_time_ms\": 10124.443, \"total_train_time_s\": 14.611064910888672}", "{\"n\": 3446, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3689.17, \"learn_time_ms\": 10043.085, \"total_train_time_s\": 12.659241199493408}", "{\"n\": 3447, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3689.17, \"learn_time_ms\": 10078.637, \"total_train_time_s\": 13.926581859588623}", "{\"n\": 3448, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3675.43, \"learn_time_ms\": 10104.207, \"total_train_time_s\": 14.217712879180908}", "{\"n\": 3449, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.97, \"learn_time_ms\": 10018.009, \"total_train_time_s\": 13.508639574050903}", "{\"n\": 3450, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3680.31, \"learn_time_ms\": 10147.027, \"total_train_time_s\": 14.494484424591064}", "{\"n\": 3451, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3689.89, \"learn_time_ms\": 10309.269, \"total_train_time_s\": 15.017560005187988}", "{\"n\": 3452, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3689.89, \"learn_time_ms\": 10300.7, \"total_train_time_s\": 13.544463634490967}", "{\"n\": 3453, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3680.2, \"learn_time_ms\": 10219.563, \"total_train_time_s\": 13.312608003616333}", "{\"n\": 3454, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3680.2, \"learn_time_ms\": 10286.442, \"total_train_time_s\": 14.20620584487915}", "{\"n\": 3455, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3681.24, \"learn_time_ms\": 10301.907, \"total_train_time_s\": 14.901153326034546}", "{\"n\": 3456, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3683.7, \"learn_time_ms\": 10525.798, \"total_train_time_s\": 14.831398487091064}", "{\"n\": 3457, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3683.7, \"learn_time_ms\": 10480.755, \"total_train_time_s\": 13.432268857955933}", "{\"n\": 3458, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3678.24, \"learn_time_ms\": 10538.726, \"total_train_time_s\": 14.993213653564453}", "{\"n\": 3459, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3688.49, \"learn_time_ms\": 10602.441, \"total_train_time_s\": 13.966650009155273}", "{\"n\": 3460, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3685.15, \"learn_time_ms\": 10499.258, \"total_train_time_s\": 13.507242679595947}", "{\"n\": 3461, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3686.89, \"learn_time_ms\": 10407.809, \"total_train_time_s\": 14.320167064666748}", "{\"n\": 3462, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3695.05, \"learn_time_ms\": 10586.106, \"total_train_time_s\": 15.50061583518982}", "{\"n\": 3463, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3693.54, \"learn_time_ms\": 10578.577, \"total_train_time_s\": 13.125188112258911}", "{\"n\": 3464, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 10555.997, \"total_train_time_s\": 14.02107572555542}", "{\"n\": 3465, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.68, \"learn_time_ms\": 10410.277, \"total_train_time_s\": 13.440972089767456}", "{\"n\": 3466, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3690.4, \"learn_time_ms\": 10367.605, \"total_train_time_s\": 14.446146249771118}", "{\"n\": 3467, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.45, \"learn_time_ms\": 10540.622, \"total_train_time_s\": 15.302639722824097}", "{\"n\": 3468, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.45, \"learn_time_ms\": 10479.672, \"total_train_time_s\": 14.213301658630371}", "{\"n\": 3469, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.45, \"learn_time_ms\": 10464.432, \"total_train_time_s\": 14.135853052139282}", "{\"n\": 3470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.59, \"learn_time_ms\": 10506.391, \"total_train_time_s\": 13.849742412567139}", "{\"n\": 3471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3710.96, \"learn_time_ms\": 10419.588, \"total_train_time_s\": 13.287678003311157}", "{\"n\": 3472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3710.96, \"learn_time_ms\": 10263.115, \"total_train_time_s\": 13.97807502746582}", "{\"n\": 3473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3710.96, \"learn_time_ms\": 10303.005, \"total_train_time_s\": 13.47333812713623}", "{\"n\": 3474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3703.01, \"learn_time_ms\": 10474.494, \"total_train_time_s\": 15.674391031265259}", "{\"n\": 3475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3707.1, \"learn_time_ms\": 10642.3, \"total_train_time_s\": 14.899483919143677}", "{\"n\": 3476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3707.1, \"learn_time_ms\": 10554.825, \"total_train_time_s\": 13.586239576339722}", "{\"n\": 3477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3707.53, \"learn_time_ms\": 10383.166, \"total_train_time_s\": 13.333721399307251}", "{\"n\": 3478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3702.67, \"learn_time_ms\": 10303.182, \"total_train_time_s\": 13.368458032608032}", "{\"n\": 3479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3691.04, \"learn_time_ms\": 10378.686, \"total_train_time_s\": 14.717223405838013}", "{\"n\": 3480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.03, \"learn_time_ms\": 10449.597, \"total_train_time_s\": 14.889942646026611}", "{\"n\": 3481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3675.44, \"learn_time_ms\": 10524.794, \"total_train_time_s\": 14.20274043083191}", "{\"n\": 3482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3691.59, \"learn_time_ms\": 10531.416, \"total_train_time_s\": 13.943127393722534}", "{\"n\": 3483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3675.88, \"learn_time_ms\": 10608.935, \"total_train_time_s\": 14.52536940574646}", "{\"n\": 3484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3675.33, \"learn_time_ms\": 10570.773, \"total_train_time_s\": 15.11040997505188}", "{\"n\": 3485, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3659.17, \"learn_time_ms\": 10451.175, \"total_train_time_s\": 13.638127565383911}", "{\"n\": 3486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3657.64, \"learn_time_ms\": 10589.143, \"total_train_time_s\": 15.013148307800293}", "{\"n\": 3487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3650.33, \"learn_time_ms\": 10660.228, \"total_train_time_s\": 13.931012868881226}", "{\"n\": 3488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3665.93, \"learn_time_ms\": 10774.967, \"total_train_time_s\": 14.639960527420044}", "{\"n\": 3489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3663.68, \"learn_time_ms\": 10666.237, \"total_train_time_s\": 13.732293367385864}", "{\"n\": 3490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3663.68, \"learn_time_ms\": 10601.69, \"total_train_time_s\": 14.089542865753174}", "{\"n\": 3491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3657.22, \"learn_time_ms\": 10587.76, \"total_train_time_s\": 13.999923944473267}", "{\"n\": 3492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3648.5, \"learn_time_ms\": 10557.331, \"total_train_time_s\": 13.815368890762329}", "{\"n\": 3493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3648.5, \"learn_time_ms\": 10513.972, \"total_train_time_s\": 13.95696234703064}", "{\"n\": 3494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3632.87, \"learn_time_ms\": 10329.541, \"total_train_time_s\": 13.351332902908325}", "{\"n\": 3495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3627.61, \"learn_time_ms\": 10280.596, \"total_train_time_s\": 13.047605276107788}", "{\"n\": 3496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3627.61, \"learn_time_ms\": 10165.883, \"total_train_time_s\": 13.599838495254517}", "{\"n\": 3497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3604.26, \"learn_time_ms\": 10218.046, \"total_train_time_s\": 14.583408832550049}", "{\"n\": 3498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 10138.455, \"total_train_time_s\": 13.667399406433105}", "{\"n\": 3499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 10238.587, \"total_train_time_s\": 14.618468999862671}", "{\"n\": 3500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3600.16, \"learn_time_ms\": 10164.971, \"total_train_time_s\": 13.424112558364868}", "{\"n\": 3501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3600.16, \"learn_time_ms\": 10254.926, \"total_train_time_s\": 15.104659795761108}", "{\"n\": 3502, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 10221.173, \"total_train_time_s\": 13.37373685836792}", "{\"n\": 3503, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.54, \"learn_time_ms\": 10184.799, \"total_train_time_s\": 13.631543159484863}", "{\"n\": 3504, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.54, \"learn_time_ms\": 10291.122, \"total_train_time_s\": 14.754491806030273}", "{\"n\": 3505, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.2, \"learn_time_ms\": 10332.828, \"total_train_time_s\": 13.6422119140625}", "{\"n\": 3506, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3588.65, \"learn_time_ms\": 10449.515, \"total_train_time_s\": 14.891554594039917}", "{\"n\": 3507, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3581.82, \"learn_time_ms\": 10323.684, \"total_train_time_s\": 13.252144575119019}", "{\"n\": 3508, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.42, \"learn_time_ms\": 10317.541, \"total_train_time_s\": 13.851079225540161}", "{\"n\": 3509, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 10264.893, \"total_train_time_s\": 13.953748226165771}", "{\"n\": 3510, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 10340.031, \"total_train_time_s\": 13.9676194190979}", "{\"n\": 3511, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3586.23, \"learn_time_ms\": 10290.438, \"total_train_time_s\": 14.409595727920532}", "{\"n\": 3512, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3594.83, \"learn_time_ms\": 10361.035, \"total_train_time_s\": 13.958308696746826}", "{\"n\": 3513, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.57, \"learn_time_ms\": 10370.497, \"total_train_time_s\": 13.900628089904785}", "{\"n\": 3514, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.57, \"learn_time_ms\": 10226.496, \"total_train_time_s\": 13.00521469116211}", "{\"n\": 3515, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.57, \"learn_time_ms\": 10175.73, \"total_train_time_s\": 13.009198188781738}", "{\"n\": 3516, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3577.37, \"learn_time_ms\": 10075.968, \"total_train_time_s\": 13.992780685424805}", "{\"n\": 3517, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3598.08, \"learn_time_ms\": 10143.51, \"total_train_time_s\": 14.009157419204712}", "{\"n\": 3518, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3598.08, \"learn_time_ms\": 10223.791, \"total_train_time_s\": 14.479681253433228}", "{\"n\": 3519, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.03, \"learn_time_ms\": 10207.989, \"total_train_time_s\": 13.84769892692566}", "{\"n\": 3520, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.03, \"learn_time_ms\": 10300.195, \"total_train_time_s\": 14.807417869567871}", "{\"n\": 3521, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.34, \"learn_time_ms\": 10248.949, \"total_train_time_s\": 13.898482084274292}", "{\"n\": 3522, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.82, \"learn_time_ms\": 10189.04, \"total_train_time_s\": 13.779547929763794}", "{\"n\": 3523, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.82, \"learn_time_ms\": 10209.141, \"total_train_time_s\": 14.017037391662598}", "{\"n\": 3524, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3629.5, \"learn_time_ms\": 10287.69, \"total_train_time_s\": 13.615419387817383}", "{\"n\": 3525, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3639.03, \"learn_time_ms\": 10292.508, \"total_train_time_s\": 13.271146535873413}", "{\"n\": 3526, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3639.03, \"learn_time_ms\": 10361.645, \"total_train_time_s\": 14.691231727600098}", "{\"n\": 3527, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3624.55, \"learn_time_ms\": 10348.461, \"total_train_time_s\": 14.066499710083008}", "{\"n\": 3528, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3624.55, \"learn_time_ms\": 10332.848, \"total_train_time_s\": 14.540144443511963}", "{\"n\": 3529, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.91, \"learn_time_ms\": 10370.639, \"total_train_time_s\": 14.454404830932617}", "{\"n\": 3530, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.91, \"learn_time_ms\": 10209.858, \"total_train_time_s\": 13.28976058959961}", "{\"n\": 3531, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.96, \"learn_time_ms\": 10378.469, \"total_train_time_s\": 15.37251615524292}", "{\"n\": 3532, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.96, \"learn_time_ms\": 10470.739, \"total_train_time_s\": 14.225798845291138}", "{\"n\": 3533, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3625.59, \"learn_time_ms\": 10479.749, \"total_train_time_s\": 13.90831208229065}", "{\"n\": 3534, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3638.91, \"learn_time_ms\": 10627.391, \"total_train_time_s\": 15.231300830841064}", "{\"n\": 3535, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.72, \"learn_time_ms\": 10674.358, \"total_train_time_s\": 13.749985933303833}", "{\"n\": 3536, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.72, \"learn_time_ms\": 10647.953, \"total_train_time_s\": 14.59468960762024}", "{\"n\": 3537, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.32, \"learn_time_ms\": 10708.188, \"total_train_time_s\": 14.38776969909668}", "{\"n\": 3538, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.32, \"learn_time_ms\": 10755.172, \"total_train_time_s\": 14.759989023208618}", "{\"n\": 3539, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3632.58, \"learn_time_ms\": 10742.315, \"total_train_time_s\": 14.095520257949829}", "{\"n\": 3540, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3612.54, \"learn_time_ms\": 10782.733, \"total_train_time_s\": 13.65880012512207}", "{\"n\": 3541, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3612.54, \"learn_time_ms\": 10636.693, \"total_train_time_s\": 13.921367168426514}", "{\"n\": 3542, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3612.54, \"learn_time_ms\": 10634.458, \"total_train_time_s\": 14.284061431884766}", "{\"n\": 3543, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3617.72, \"learn_time_ms\": 10583.91, \"total_train_time_s\": 13.735285997390747}", "{\"n\": 3544, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3618.73, \"learn_time_ms\": 10495.179, \"total_train_time_s\": 14.389312505722046}", "{\"n\": 3545, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3623.83, \"learn_time_ms\": 10489.943, \"total_train_time_s\": 13.642650127410889}", "{\"n\": 3546, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.14, \"learn_time_ms\": 10533.86, \"total_train_time_s\": 14.81892728805542}", "{\"n\": 3547, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.91, \"learn_time_ms\": 10547.077, \"total_train_time_s\": 14.91860318183899}", "{\"n\": 3548, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3643.9, \"learn_time_ms\": 10569.051, \"total_train_time_s\": 15.02006983757019}", "{\"n\": 3549, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10494.248, \"total_train_time_s\": 13.407013654708862}", "{\"n\": 3550, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3644.72, \"learn_time_ms\": 10572.134, \"total_train_time_s\": 14.475738525390625}", "{\"n\": 3551, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3644.72, \"learn_time_ms\": 10693.702, \"total_train_time_s\": 15.21985936164856}", "{\"n\": 3552, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3618.53, \"learn_time_ms\": 10607.254, \"total_train_time_s\": 13.4126296043396}", "{\"n\": 3553, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.04, \"learn_time_ms\": 10711.35, \"total_train_time_s\": 14.728792190551758}", "{\"n\": 3554, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.41, \"learn_time_ms\": 10680.19, \"total_train_time_s\": 14.039907455444336}", "{\"n\": 3555, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3613.4, \"learn_time_ms\": 10757.355, \"total_train_time_s\": 14.403803825378418}", "{\"n\": 3556, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3612.66, \"learn_time_ms\": 10703.362, \"total_train_time_s\": 14.08138108253479}", "{\"n\": 3557, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.05, \"learn_time_ms\": 10589.578, \"total_train_time_s\": 13.546703815460205}", "{\"n\": 3558, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.05, \"learn_time_ms\": 10547.67, \"total_train_time_s\": 15.066568374633789}", "{\"n\": 3559, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 10570.721, \"total_train_time_s\": 13.674783945083618}", "{\"n\": 3560, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3631.69, \"learn_time_ms\": 10448.336, \"total_train_time_s\": 13.175537586212158}", "{\"n\": 3561, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3631.69, \"learn_time_ms\": 10367.801, \"total_train_time_s\": 14.294970035552979}", "{\"n\": 3562, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.06, \"learn_time_ms\": 10436.277, \"total_train_time_s\": 14.469442129135132}", "{\"n\": 3563, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3622.54, \"learn_time_ms\": 10358.686, \"total_train_time_s\": 13.676557779312134}", "{\"n\": 3564, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.78, \"learn_time_ms\": 10344.329, \"total_train_time_s\": 13.858677625656128}", "{\"n\": 3565, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3621.64, \"learn_time_ms\": 10385.546, \"total_train_time_s\": 14.898560523986816}", "{\"n\": 3566, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.47, \"learn_time_ms\": 10394.221, \"total_train_time_s\": 14.468856573104858}", "{\"n\": 3567, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3629.12, \"learn_time_ms\": 10410.258, \"total_train_time_s\": 13.930516958236694}", "{\"n\": 3568, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3629.12, \"learn_time_ms\": 10335.641, \"total_train_time_s\": 14.266167402267456}", "{\"n\": 3569, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3624.17, \"learn_time_ms\": 10523.089, \"total_train_time_s\": 15.602340936660767}", "{\"n\": 3570, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.32, \"learn_time_ms\": 10594.19, \"total_train_time_s\": 13.861470937728882}", "{\"n\": 3571, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.83, \"learn_time_ms\": 10645.1, \"total_train_time_s\": 14.849857091903687}", "{\"n\": 3572, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3631.39, \"learn_time_ms\": 10607.561, \"total_train_time_s\": 13.695589065551758}", "{\"n\": 3573, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.1, \"learn_time_ms\": 10709.188, \"total_train_time_s\": 14.801512479782104}", "{\"n\": 3574, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.1, \"learn_time_ms\": 10743.802, \"total_train_time_s\": 14.2626953125}", "{\"n\": 3575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.24, \"learn_time_ms\": 10713.142, \"total_train_time_s\": 14.408572912216187}", "{\"n\": 3576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 10669.78, \"total_train_time_s\": 13.894296407699585}", "{\"n\": 3577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 10667.227, \"total_train_time_s\": 13.628359079360962}", "{\"n\": 3578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3622.22, \"learn_time_ms\": 10669.521, \"total_train_time_s\": 13.814955711364746}", "{\"n\": 3579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3617.62, \"learn_time_ms\": 10533.313, \"total_train_time_s\": 14.336463212966919}", "{\"n\": 3580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3609.32, \"learn_time_ms\": 10532.754, \"total_train_time_s\": 13.927582025527954}", "{\"n\": 3581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10477.043, \"total_train_time_s\": 14.267735719680786}", "{\"n\": 3582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10434.138, \"total_train_time_s\": 13.471333265304565}", "{\"n\": 3583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3612.76, \"learn_time_ms\": 10347.515, \"total_train_time_s\": 13.78070592880249}", "{\"n\": 3584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.15, \"learn_time_ms\": 10370.189, \"total_train_time_s\": 14.715892314910889}", "{\"n\": 3585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.15, \"learn_time_ms\": 10332.754, \"total_train_time_s\": 14.225108861923218}", "{\"n\": 3586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.55, \"learn_time_ms\": 10440.655, \"total_train_time_s\": 14.848694086074829}", "{\"n\": 3587, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.79, \"learn_time_ms\": 10558.616, \"total_train_time_s\": 14.68937087059021}", "{\"n\": 3588, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.79, \"learn_time_ms\": 10572.828, \"total_train_time_s\": 14.487251996994019}", "{\"n\": 3589, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 10663.166, \"total_train_time_s\": 15.054027318954468}", "{\"n\": 3590, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.85, \"learn_time_ms\": 10685.689, \"total_train_time_s\": 14.20598554611206}", "{\"n\": 3591, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.32, \"learn_time_ms\": 10531.356, \"total_train_time_s\": 12.955992937088013}", "{\"n\": 3592, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.32, \"learn_time_ms\": 10599.548, \"total_train_time_s\": 14.025933980941772}", "{\"n\": 3593, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.28, \"learn_time_ms\": 10619.24, \"total_train_time_s\": 14.011653661727905}", "{\"n\": 3594, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.36, \"learn_time_ms\": 10520.627, \"total_train_time_s\": 13.65555453300476}", "{\"n\": 3595, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3663.57, \"learn_time_ms\": 10571.384, \"total_train_time_s\": 14.476059675216675}", "{\"n\": 3596, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3663.57, \"learn_time_ms\": 10526.322, \"total_train_time_s\": 14.572037935256958}", "{\"n\": 3597, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3662.73, \"learn_time_ms\": 10385.75, \"total_train_time_s\": 13.287258386611938}", "{\"n\": 3598, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3664.75, \"learn_time_ms\": 10322.029, \"total_train_time_s\": 13.36695384979248}", "{\"n\": 3599, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3677.33, \"learn_time_ms\": 10312.927, \"total_train_time_s\": 15.012351989746094}", "{\"n\": 3600, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.37, \"learn_time_ms\": 10323.001, \"total_train_time_s\": 14.321263313293457}", "{\"n\": 3601, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10463.669, \"total_train_time_s\": 14.309216499328613}", "{\"n\": 3602, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3664.63, \"learn_time_ms\": 10428.189, \"total_train_time_s\": 13.928500652313232}", "{\"n\": 3603, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3665.87, \"learn_time_ms\": 10385.575, \"total_train_time_s\": 13.58467984199524}", "{\"n\": 3604, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3673.7, \"learn_time_ms\": 10413.493, \"total_train_time_s\": 13.910054683685303}", "{\"n\": 3605, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3673.7, \"learn_time_ms\": 10364.44, \"total_train_time_s\": 14.157599925994873}", "{\"n\": 3606, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3678.56, \"learn_time_ms\": 10314.205, \"total_train_time_s\": 13.891429662704468}", "{\"n\": 3607, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3666.05, \"learn_time_ms\": 10492.025, \"total_train_time_s\": 15.128201961517334}", "{\"n\": 3608, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3666.05, \"learn_time_ms\": 10622.471, \"total_train_time_s\": 14.927141427993774}", "{\"n\": 3609, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3658.17, \"learn_time_ms\": 10526.191, \"total_train_time_s\": 14.026676654815674}", "{\"n\": 3610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10524.111, \"total_train_time_s\": 14.295514345169067}", "{\"n\": 3611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.54, \"learn_time_ms\": 10583.175, \"total_train_time_s\": 14.917513608932495}", "{\"n\": 3612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3635.54, \"learn_time_ms\": 10602.126, \"total_train_time_s\": 13.937549591064453}", "{\"n\": 3613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3650.51, \"learn_time_ms\": 10597.819, \"total_train_time_s\": 13.51588749885559}", "{\"n\": 3614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.22, \"learn_time_ms\": 10648.088, \"total_train_time_s\": 14.233454942703247}", "{\"n\": 3615, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.22, \"learn_time_ms\": 10711.651, \"total_train_time_s\": 14.626843214035034}", "{\"n\": 3616, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3646.53, \"learn_time_ms\": 10712.843, \"total_train_time_s\": 14.07723331451416}", "{\"n\": 3617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3648.82, \"learn_time_ms\": 10621.51, \"total_train_time_s\": 14.427268266677856}", "{\"n\": 3618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3658.41, \"learn_time_ms\": 10576.487, \"total_train_time_s\": 14.515569686889648}", "{\"n\": 3619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3658.41, \"learn_time_ms\": 10536.488, \"total_train_time_s\": 13.459131956100464}", "{\"n\": 3620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3649.06, \"learn_time_ms\": 10481.42, \"total_train_time_s\": 13.692160844802856}", "{\"n\": 3621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.87, \"learn_time_ms\": 10280.552, \"total_train_time_s\": 12.903565883636475}", "{\"n\": 3622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.87, \"learn_time_ms\": 10307.122, \"total_train_time_s\": 14.070096731185913}", "{\"n\": 3623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.68, \"learn_time_ms\": 10451.999, \"total_train_time_s\": 14.994481325149536}", "{\"n\": 3624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.68, \"learn_time_ms\": 10443.529, \"total_train_time_s\": 14.434628963470459}", "{\"n\": 3625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3621.04, \"learn_time_ms\": 10351.475, \"total_train_time_s\": 13.760997295379639}", "{\"n\": 3626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.62, \"learn_time_ms\": 10433.734, \"total_train_time_s\": 14.754103183746338}", "{\"n\": 3627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.62, \"learn_time_ms\": 10426.69, \"total_train_time_s\": 14.425740957260132}", "{\"n\": 3628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.62, \"learn_time_ms\": 10463.69, \"total_train_time_s\": 15.014160871505737}", "{\"n\": 3629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.54, \"learn_time_ms\": 10515.337, \"total_train_time_s\": 14.129923343658447}", "{\"n\": 3630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.54, \"learn_time_ms\": 10583.767, \"total_train_time_s\": 14.582946538925171}", "{\"n\": 3631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.54, \"learn_time_ms\": 10659.115, \"total_train_time_s\": 13.486633062362671}", "{\"n\": 3632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.99, \"learn_time_ms\": 10559.238, \"total_train_time_s\": 13.331107378005981}", "{\"n\": 3633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3642.26, \"learn_time_ms\": 10432.47, \"total_train_time_s\": 13.660054206848145}", "{\"n\": 3634, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3642.26, \"learn_time_ms\": 10377.526, \"total_train_time_s\": 13.63843846321106}", "{\"n\": 3635, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3649.48, \"learn_time_ms\": 10450.68, \"total_train_time_s\": 14.378699541091919}", "{\"n\": 3636, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 10401.126, \"total_train_time_s\": 14.397364616394043}", "{\"n\": 3637, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.81, \"learn_time_ms\": 10479.574, \"total_train_time_s\": 15.132721185684204}", "{\"n\": 3638, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.81, \"learn_time_ms\": 10411.792, \"total_train_time_s\": 13.90590238571167}", "{\"n\": 3639, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3588.28, \"learn_time_ms\": 10413.726, \"total_train_time_s\": 14.159213066101074}", "{\"n\": 3640, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10409.496, \"total_train_time_s\": 14.422232151031494}", "{\"n\": 3641, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10393.927, \"total_train_time_s\": 13.545629978179932}", "{\"n\": 3642, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3615.33, \"learn_time_ms\": 10401.008, \"total_train_time_s\": 13.295667171478271}", "{\"n\": 3643, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3616.88, \"learn_time_ms\": 10356.06, \"total_train_time_s\": 13.663973808288574}", "{\"n\": 3644, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3616.18, \"learn_time_ms\": 10263.991, \"total_train_time_s\": 12.650041818618774}", "{\"n\": 3645, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3613.88, \"learn_time_ms\": 10208.16, \"total_train_time_s\": 13.7942214012146}", "{\"n\": 3646, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3613.88, \"learn_time_ms\": 10216.231, \"total_train_time_s\": 14.488851547241211}", "{\"n\": 3647, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3598.56, \"learn_time_ms\": 10127.916, \"total_train_time_s\": 14.073161125183105}", "{\"n\": 3648, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3598.56, \"learn_time_ms\": 10193.625, \"total_train_time_s\": 14.667377948760986}", "{\"n\": 3649, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 10086.259, \"total_train_time_s\": 13.196218490600586}", "{\"n\": 3650, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 10029.236, \"total_train_time_s\": 13.704479932785034}", "{\"n\": 3651, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3591.44, \"learn_time_ms\": 10137.228, \"total_train_time_s\": 14.473304986953735}", "{\"n\": 3652, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3591.38, \"learn_time_ms\": 10229.27, \"total_train_time_s\": 14.338403940200806}", "{\"n\": 3653, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3596.61, \"learn_time_ms\": 10365.279, \"total_train_time_s\": 14.800027132034302}", "{\"n\": 3654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3604.33, \"learn_time_ms\": 10575.605, \"total_train_time_s\": 14.67142105102539}", "{\"n\": 3655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3602.03, \"learn_time_ms\": 10523.947, \"total_train_time_s\": 13.379690408706665}", "{\"n\": 3656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.63, \"learn_time_ms\": 10503.358, \"total_train_time_s\": 14.474829196929932}", "{\"n\": 3657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.05, \"learn_time_ms\": 10518.657, \"total_train_time_s\": 14.388734102249146}", "{\"n\": 3658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3604.17, \"learn_time_ms\": 10539.432, \"total_train_time_s\": 14.775977849960327}", "{\"n\": 3659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3618.36, \"learn_time_ms\": 10616.177, \"total_train_time_s\": 13.70738410949707}", "{\"n\": 3660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3629.13, \"learn_time_ms\": 10614.361, \"total_train_time_s\": 13.679553031921387}", "{\"n\": 3661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3629.13, \"learn_time_ms\": 10693.867, \"total_train_time_s\": 15.331843852996826}", "{\"n\": 3662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3620.6, \"learn_time_ms\": 10697.092, \"total_train_time_s\": 14.014402866363525}", "{\"n\": 3663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3618.81, \"learn_time_ms\": 10580.162, \"total_train_time_s\": 13.530974388122559}", "{\"n\": 3664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.09, \"learn_time_ms\": 10451.788, \"total_train_time_s\": 13.432486534118652}", "{\"n\": 3665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.09, \"learn_time_ms\": 10502.284, \"total_train_time_s\": 13.967495203018188}", "{\"n\": 3666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.49, \"learn_time_ms\": 10435.911, \"total_train_time_s\": 13.438328742980957}", "{\"n\": 3667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.87, \"learn_time_ms\": 10557.35, \"total_train_time_s\": 15.590269804000854}", "{\"n\": 3668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.87, \"learn_time_ms\": 10479.168, \"total_train_time_s\": 14.411059379577637}", "{\"n\": 3669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.87, \"learn_time_ms\": 10504.953, \"total_train_time_s\": 14.25660252571106}", "{\"n\": 3670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3620.05, \"learn_time_ms\": 10547.912, \"total_train_time_s\": 14.23621129989624}", "{\"n\": 3671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3633.94, \"learn_time_ms\": 10457.264, \"total_train_time_s\": 14.461158514022827}", "{\"n\": 3672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3633.94, \"learn_time_ms\": 10494.078, \"total_train_time_s\": 14.585206270217896}", "{\"n\": 3673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3636.32, \"learn_time_ms\": 10474.969, \"total_train_time_s\": 13.570020914077759}", "{\"n\": 3674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3636.95, \"learn_time_ms\": 10570.213, \"total_train_time_s\": 14.514627456665039}", "{\"n\": 3675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.87, \"learn_time_ms\": 10582.911, \"total_train_time_s\": 13.999057054519653}", "{\"n\": 3676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.87, \"learn_time_ms\": 10632.415, \"total_train_time_s\": 14.277750015258789}", "{\"n\": 3677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3650.17, \"learn_time_ms\": 10494.452, \"total_train_time_s\": 14.132153511047363}", "{\"n\": 3678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.63, \"learn_time_ms\": 10548.863, \"total_train_time_s\": 14.623490810394287}", "{\"n\": 3679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3653.63, \"learn_time_ms\": 10453.517, \"total_train_time_s\": 13.354817152023315}", "{\"n\": 3680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3638.99, \"learn_time_ms\": 10497.54, \"total_train_time_s\": 14.681809663772583}", "{\"n\": 3681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3632.31, \"learn_time_ms\": 10479.756, \"total_train_time_s\": 14.328873872756958}", "{\"n\": 3682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3632.31, \"learn_time_ms\": 10444.978, \"total_train_time_s\": 14.145936012268066}", "{\"n\": 3683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3645.69, \"learn_time_ms\": 10627.104, \"total_train_time_s\": 15.079735040664673}", "{\"n\": 3684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3642.58, \"learn_time_ms\": 10642.259, \"total_train_time_s\": 14.705399751663208}", "{\"n\": 3685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3642.58, \"learn_time_ms\": 10672.388, \"total_train_time_s\": 14.405312299728394}", "{\"n\": 3686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3640.35, \"learn_time_ms\": 10686.932, \"total_train_time_s\": 14.026369571685791}", "{\"n\": 3687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3649.12, \"learn_time_ms\": 10623.889, \"total_train_time_s\": 13.57185983657837}", "{\"n\": 3688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3648.07, \"learn_time_ms\": 10535.845, \"total_train_time_s\": 14.151353120803833}", "{\"n\": 3689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3648.07, \"learn_time_ms\": 10684.405, \"total_train_time_s\": 15.007174491882324}", "{\"n\": 3690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3656.97, \"learn_time_ms\": 10591.667, \"total_train_time_s\": 13.57921814918518}", "{\"n\": 3691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3653.17, \"learn_time_ms\": 10555.277, \"total_train_time_s\": 13.753363847732544}", "{\"n\": 3692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10541.575, \"total_train_time_s\": 13.960894584655762}", "{\"n\": 3693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3662.23, \"learn_time_ms\": 10422.578, \"total_train_time_s\": 14.184104204177856}", "{\"n\": 3694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3666.56, \"learn_time_ms\": 10371.617, \"total_train_time_s\": 14.033622026443481}", "{\"n\": 3695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3663.93, \"learn_time_ms\": 10442.136, \"total_train_time_s\": 15.106083154678345}", "{\"n\": 3696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3664.39, \"learn_time_ms\": 10578.795, \"total_train_time_s\": 15.476534843444824}", "{\"n\": 3697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3664.39, \"learn_time_ms\": 10696.784, \"total_train_time_s\": 14.821856260299683}", "{\"n\": 3698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3664.22, \"learn_time_ms\": 10665.552, \"total_train_time_s\": 13.480070114135742}", "{\"n\": 3699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3674.8, \"learn_time_ms\": 10663.311, \"total_train_time_s\": 14.485554218292236}", "{\"n\": 3700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3674.8, \"learn_time_ms\": 10787.328, \"total_train_time_s\": 14.822150945663452}", "{\"n\": 3701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3674.8, \"learn_time_ms\": 10822.738, \"total_train_time_s\": 14.235321283340454}", "{\"n\": 3702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3681.76, \"learn_time_ms\": 10823.913, \"total_train_time_s\": 14.04227352142334}", "{\"n\": 3703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3683.82, \"learn_time_ms\": 10856.808, \"total_train_time_s\": 14.121510982513428}", "{\"n\": 3704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3669.03, \"learn_time_ms\": 10933.242, \"total_train_time_s\": 14.807741403579712}", "{\"n\": 3705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3663.03, \"learn_time_ms\": 10806.258, \"total_train_time_s\": 13.783544778823853}", "{\"n\": 3706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3666.17, \"learn_time_ms\": 10682.715, \"total_train_time_s\": 14.212393522262573}", "{\"n\": 3707, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3685.63, \"learn_time_ms\": 10671.488, \"total_train_time_s\": 14.491136312484741}", "{\"n\": 3708, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3685.63, \"learn_time_ms\": 10683.444, \"total_train_time_s\": 13.737556457519531}", "{\"n\": 3709, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3683.47, \"learn_time_ms\": 10682.448, \"total_train_time_s\": 14.78512167930603}", "{\"n\": 3710, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3674.58, \"learn_time_ms\": 10559.391, \"total_train_time_s\": 13.779655694961548}", "{\"n\": 3711, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3687.75, \"learn_time_ms\": 10610.951, \"total_train_time_s\": 14.805261611938477}", "{\"n\": 3712, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3687.53, \"learn_time_ms\": 10521.019, \"total_train_time_s\": 13.081225872039795}", "{\"n\": 3713, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3683.77, \"learn_time_ms\": 10572.438, \"total_train_time_s\": 14.747528791427612}", "{\"n\": 3714, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3679.5, \"learn_time_ms\": 10502.747, \"total_train_time_s\": 14.164579153060913}", "{\"n\": 3715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3671.73, \"learn_time_ms\": 10560.834, \"total_train_time_s\": 14.52167010307312}", "{\"n\": 3716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3668.39, \"learn_time_ms\": 10409.878, \"total_train_time_s\": 12.766214847564697}", "{\"n\": 3717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3667.11, \"learn_time_ms\": 10401.665, \"total_train_time_s\": 14.525647640228271}", "{\"n\": 3718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3659.56, \"learn_time_ms\": 10432.199, \"total_train_time_s\": 13.823121070861816}", "{\"n\": 3719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3651.97, \"learn_time_ms\": 10465.072, \"total_train_time_s\": 15.10563325881958}", "{\"n\": 3720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3648.91, \"learn_time_ms\": 10534.488, \"total_train_time_s\": 14.461045742034912}", "{\"n\": 3721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3639.85, \"learn_time_ms\": 10466.987, \"total_train_time_s\": 14.078996896743774}", "{\"n\": 3722, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3639.85, \"learn_time_ms\": 10549.055, \"total_train_time_s\": 13.957090139389038}", "{\"n\": 3723, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3639.85, \"learn_time_ms\": 10544.342, \"total_train_time_s\": 14.839025020599365}", "{\"n\": 3724, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3633.65, \"learn_time_ms\": 10614.172, \"total_train_time_s\": 14.707042932510376}", "{\"n\": 3725, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3626.97, \"learn_time_ms\": 10582.778, \"total_train_time_s\": 13.971184730529785}", "{\"n\": 3726, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3626.97, \"learn_time_ms\": 10654.254, \"total_train_time_s\": 13.371554851531982}", "{\"n\": 3727, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3634.45, \"learn_time_ms\": 10665.109, \"total_train_time_s\": 14.581533908843994}", "{\"n\": 3728, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3644.83, \"learn_time_ms\": 10725.522, \"total_train_time_s\": 14.330009937286377}", "{\"n\": 3729, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3652.36, \"learn_time_ms\": 10568.783, \"total_train_time_s\": 13.583894491195679}", "{\"n\": 3730, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3651.58, \"learn_time_ms\": 10512.515, \"total_train_time_s\": 13.763942241668701}", "{\"n\": 3731, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3657.5, \"learn_time_ms\": 10501.422, \"total_train_time_s\": 14.120263814926147}", "{\"n\": 3732, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3647.06, \"learn_time_ms\": 10537.089, \"total_train_time_s\": 14.587989568710327}", "{\"n\": 3733, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3654.71, \"learn_time_ms\": 10459.824, \"total_train_time_s\": 13.930217981338501}", "{\"n\": 3734, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3655.22, \"learn_time_ms\": 10312.456, \"total_train_time_s\": 13.446528196334839}", "{\"n\": 3735, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3655.22, \"learn_time_ms\": 10366.508, \"total_train_time_s\": 14.57550597190857}", "{\"n\": 3736, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3662.56, \"learn_time_ms\": 10425.759, \"total_train_time_s\": 14.06764841079712}", "{\"n\": 3737, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3662.56, \"learn_time_ms\": 10294.867, \"total_train_time_s\": 13.367555379867554}", "{\"n\": 3738, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3667.04, \"learn_time_ms\": 10304.902, \"total_train_time_s\": 14.635017156600952}", "{\"n\": 3739, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3656.68, \"learn_time_ms\": 10281.831, \"total_train_time_s\": 13.314324855804443}", "{\"n\": 3740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3672.28, \"learn_time_ms\": 10290.396, \"total_train_time_s\": 13.895363569259644}", "{\"n\": 3741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3677.48, \"learn_time_ms\": 10282.763, \"total_train_time_s\": 13.933329582214355}", "{\"n\": 3742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3672.85, \"learn_time_ms\": 10215.719, \"total_train_time_s\": 13.9740891456604}", "{\"n\": 3743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3672.32, \"learn_time_ms\": 10273.49, \"total_train_time_s\": 14.66461181640625}", "{\"n\": 3744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3674.03, \"learn_time_ms\": 10284.42, \"total_train_time_s\": 13.39704155921936}", "{\"n\": 3745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3666.85, \"learn_time_ms\": 10258.608, \"total_train_time_s\": 14.432493925094604}", "{\"n\": 3746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3652.23, \"learn_time_ms\": 10277.436, \"total_train_time_s\": 14.574325799942017}", "{\"n\": 3747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3657.29, \"learn_time_ms\": 10327.131, \"total_train_time_s\": 13.793479204177856}", "{\"n\": 3748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3657.29, \"learn_time_ms\": 10282.525, \"total_train_time_s\": 14.161802530288696}", "{\"n\": 3749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3655.08, \"learn_time_ms\": 10311.062, \"total_train_time_s\": 13.644877195358276}", "{\"n\": 3750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3655.08, \"learn_time_ms\": 10303.046, \"total_train_time_s\": 14.075432538986206}", "{\"n\": 3751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3645.46, \"learn_time_ms\": 10249.746, \"total_train_time_s\": 13.320557355880737}", "{\"n\": 3752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3639.14, \"learn_time_ms\": 10139.088, \"total_train_time_s\": 12.511778116226196}", "{\"n\": 3753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3636.45, \"learn_time_ms\": 10021.692, \"total_train_time_s\": 13.6532883644104}", "{\"n\": 3754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3636.45, \"learn_time_ms\": 10105.758, \"total_train_time_s\": 14.522984981536865}", "{\"n\": 3755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3646.43, \"learn_time_ms\": 10141.454, \"total_train_time_s\": 14.789164781570435}", "{\"n\": 3756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3669.97, \"learn_time_ms\": 10113.829, \"total_train_time_s\": 13.956307172775269}", "{\"n\": 3757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3681.78, \"learn_time_ms\": 10225.503, \"total_train_time_s\": 15.042858123779297}", "{\"n\": 3758, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3684.1, \"learn_time_ms\": 10247.608, \"total_train_time_s\": 14.540973424911499}", "{\"n\": 3759, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3690.59, \"learn_time_ms\": 10323.026, \"total_train_time_s\": 14.025590181350708}", "{\"n\": 3760, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3690.59, \"learn_time_ms\": 10290.446, \"total_train_time_s\": 13.507874488830566}", "{\"n\": 3761, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3685.65, \"learn_time_ms\": 10415.404, \"total_train_time_s\": 14.870419979095459}", "{\"n\": 3762, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3685.65, \"learn_time_ms\": 10523.994, \"total_train_time_s\": 13.58151388168335}", "{\"n\": 3763, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3680.01, \"learn_time_ms\": 10630.271, \"total_train_time_s\": 14.526159286499023}", "{\"n\": 3764, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3680.01, \"learn_time_ms\": 10599.925, \"total_train_time_s\": 14.116904735565186}", "{\"n\": 3765, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 10596.399, \"total_train_time_s\": 14.556775331497192}", "{\"n\": 3766, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 10495.842, \"total_train_time_s\": 13.001527786254883}", "{\"n\": 3767, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3684.65, \"learn_time_ms\": 10511.165, \"total_train_time_s\": 15.100033283233643}", "{\"n\": 3768, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3683.55, \"learn_time_ms\": 10479.73, \"total_train_time_s\": 14.141319274902344}", "{\"n\": 3769, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3673.04, \"learn_time_ms\": 10433.971, \"total_train_time_s\": 13.632426977157593}", "{\"n\": 3770, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3666.04, \"learn_time_ms\": 10500.423, \"total_train_time_s\": 14.416147947311401}", "{\"n\": 3771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3671.07, \"learn_time_ms\": 10426.164, \"total_train_time_s\": 13.829786539077759}", "{\"n\": 3772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3665.6, \"learn_time_ms\": 10361.538, \"total_train_time_s\": 13.080179691314697}", "{\"n\": 3773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3673.78, \"learn_time_ms\": 10298.719, \"total_train_time_s\": 14.00076150894165}", "{\"n\": 3774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3673.78, \"learn_time_ms\": 10328.426, \"total_train_time_s\": 14.218727350234985}", "{\"n\": 3775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3679.85, \"learn_time_ms\": 10314.761, \"total_train_time_s\": 14.476876020431519}", "{\"n\": 3776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3681.85, \"learn_time_ms\": 10462.517, \"total_train_time_s\": 14.468929767608643}", "{\"n\": 3777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3661.21, \"learn_time_ms\": 10360.974, \"total_train_time_s\": 14.21739149093628}", "{\"n\": 3778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3653.13, \"learn_time_ms\": 10338.417, \"total_train_time_s\": 13.782949924468994}", "{\"n\": 3779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3638.5, \"learn_time_ms\": 10433.358, \"total_train_time_s\": 14.593295335769653}", "{\"n\": 3780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3638.04, \"learn_time_ms\": 10461.766, \"total_train_time_s\": 14.49374532699585}", "{\"n\": 3781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3637.92, \"learn_time_ms\": 10440.615, \"total_train_time_s\": 13.75868844985962}", "{\"n\": 3782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3624.96, \"learn_time_ms\": 10588.75, \"total_train_time_s\": 14.594202995300293}", "{\"n\": 3783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3619.21, \"learn_time_ms\": 10599.149, \"total_train_time_s\": 13.903869152069092}", "{\"n\": 3784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.16, \"learn_time_ms\": 10613.892, \"total_train_time_s\": 14.450278282165527}", "{\"n\": 3785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.4, \"learn_time_ms\": 10643.664, \"total_train_time_s\": 14.922459840774536}", "{\"n\": 3786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.4, \"learn_time_ms\": 10673.137, \"total_train_time_s\": 14.957703113555908}", "{\"n\": 3787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3616.46, \"learn_time_ms\": 10666.669, \"total_train_time_s\": 14.001252174377441}", "{\"n\": 3788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3602.7, \"learn_time_ms\": 10685.034, \"total_train_time_s\": 14.005390167236328}", "{\"n\": 3789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3602.7, \"learn_time_ms\": 10743.837, \"total_train_time_s\": 15.25054121017456}", "{\"n\": 3790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3602.7, \"learn_time_ms\": 10668.442, \"total_train_time_s\": 13.952324867248535}", "{\"n\": 3791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3588.43, \"learn_time_ms\": 10679.292, \"total_train_time_s\": 13.727882146835327}", "{\"n\": 3792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.94, \"learn_time_ms\": 10631.749, \"total_train_time_s\": 13.901111364364624}", "{\"n\": 3793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.94, \"learn_time_ms\": 10652.032, \"total_train_time_s\": 14.031741619110107}", "{\"n\": 3794, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3577.54, \"learn_time_ms\": 10488.893, \"total_train_time_s\": 12.904396057128906}", "{\"n\": 3795, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3574.08, \"learn_time_ms\": 10350.772, \"total_train_time_s\": 13.619001865386963}", "{\"n\": 3796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3574.08, \"learn_time_ms\": 10193.538, \"total_train_time_s\": 13.595331192016602}", "{\"n\": 3797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3574.08, \"learn_time_ms\": 10195.185, \"total_train_time_s\": 13.828882217407227}", "{\"n\": 3798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3575.6, \"learn_time_ms\": 10167.494, \"total_train_time_s\": 13.575992584228516}", "{\"n\": 3799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.81, \"learn_time_ms\": 10011.371, \"total_train_time_s\": 13.550177335739136}", "{\"n\": 3800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3563.45, \"learn_time_ms\": 10024.182, \"total_train_time_s\": 13.77646803855896}", "{\"n\": 3801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3563.45, \"learn_time_ms\": 9944.107, \"total_train_time_s\": 13.069557905197144}", "{\"n\": 3802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3570.67, \"learn_time_ms\": 9931.479, \"total_train_time_s\": 13.89896297454834}", "{\"n\": 3803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3575.84, \"learn_time_ms\": 10020.759, \"total_train_time_s\": 15.031477689743042}", "{\"n\": 3804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3579.32, \"learn_time_ms\": 10226.451, \"total_train_time_s\": 14.825443744659424}", "{\"n\": 3805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3574.17, \"learn_time_ms\": 10262.987, \"total_train_time_s\": 13.884728193283081}", "{\"n\": 3806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3575.13, \"learn_time_ms\": 10327.483, \"total_train_time_s\": 13.766664743423462}", "{\"n\": 3807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3572.77, \"learn_time_ms\": 10452.517, \"total_train_time_s\": 15.038294076919556}", "{\"n\": 3808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3572.77, \"learn_time_ms\": 10514.513, \"total_train_time_s\": 14.490245342254639}", "{\"n\": 3809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3570.22, \"learn_time_ms\": 10561.693, \"total_train_time_s\": 14.261375427246094}", "{\"n\": 3810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3587.2, \"learn_time_ms\": 10576.638, \"total_train_time_s\": 13.921118021011353}", "{\"n\": 3811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.35, \"learn_time_ms\": 10739.499, \"total_train_time_s\": 14.559845209121704}", "{\"n\": 3812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.35, \"learn_time_ms\": 10699.213, \"total_train_time_s\": 13.491071701049805}", "{\"n\": 3813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3588.52, \"learn_time_ms\": 10744.212, \"total_train_time_s\": 15.480435609817505}", "{\"n\": 3814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3593.37, \"learn_time_ms\": 10619.384, \"total_train_time_s\": 13.890856981277466}", "{\"n\": 3815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3593.37, \"learn_time_ms\": 10603.033, \"total_train_time_s\": 13.799920558929443}", "{\"n\": 3816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.96, \"learn_time_ms\": 10543.238, \"total_train_time_s\": 13.1090669631958}", "{\"n\": 3817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3589.43, \"learn_time_ms\": 10440.201, \"total_train_time_s\": 14.116774797439575}", "{\"n\": 3818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.41, \"learn_time_ms\": 10411.09, \"total_train_time_s\": 13.986227750778198}", "{\"n\": 3819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.41, \"learn_time_ms\": 10313.764, \"total_train_time_s\": 13.339924812316895}", "{\"n\": 3820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3587.14, \"learn_time_ms\": 10350.581, \"total_train_time_s\": 14.458124876022339}", "{\"n\": 3821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.91, \"learn_time_ms\": 10267.256, \"total_train_time_s\": 13.602740049362183}", "{\"n\": 3822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.91, \"learn_time_ms\": 10365.834, \"total_train_time_s\": 14.463905572891235}", "{\"n\": 3823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.91, \"learn_time_ms\": 10244.295, \"total_train_time_s\": 14.254894256591797}", "{\"n\": 3824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.16, \"learn_time_ms\": 10305.959, \"total_train_time_s\": 14.283106565475464}", "{\"n\": 3825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.12, \"learn_time_ms\": 10358.528, \"total_train_time_s\": 14.361115455627441}", "{\"n\": 3826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.12, \"learn_time_ms\": 10476.66, \"total_train_time_s\": 14.318055629730225}", "{\"n\": 3827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.37, \"learn_time_ms\": 10480.692, \"total_train_time_s\": 14.35814118385315}", "{\"n\": 3828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3572.6, \"learn_time_ms\": 10487.437, \"total_train_time_s\": 14.197535276412964}", "{\"n\": 3829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3572.6, \"learn_time_ms\": 10523.422, \"total_train_time_s\": 13.462399005889893}", "{\"n\": 3830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3571.14, \"learn_time_ms\": 10543.417, \"total_train_time_s\": 14.784013509750366}", "{\"n\": 3831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3563.77, \"learn_time_ms\": 10561.818, \"total_train_time_s\": 13.79982590675354}", "{\"n\": 3832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3555.62, \"learn_time_ms\": 10630.182, \"total_train_time_s\": 15.414433002471924}", "{\"n\": 3833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3555.62, \"learn_time_ms\": 10612.107, \"total_train_time_s\": 14.176321029663086}", "{\"n\": 3834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3555.99, \"learn_time_ms\": 10564.075, \"total_train_time_s\": 13.717887878417969}", "{\"n\": 3835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3556.14, \"learn_time_ms\": 10600.584, \"total_train_time_s\": 14.766294002532959}", "{\"n\": 3836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3555.13, \"learn_time_ms\": 10536.282, \"total_train_time_s\": 13.706889629364014}", "{\"n\": 3837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3559.45, \"learn_time_ms\": 10467.234, \"total_train_time_s\": 13.783989191055298}", "{\"n\": 3838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3560.67, \"learn_time_ms\": 10423.391, \"total_train_time_s\": 13.616072654724121}", "{\"n\": 3839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3560.67, \"learn_time_ms\": 10415.841, \"total_train_time_s\": 13.34796929359436}", "{\"n\": 3840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3562.12, \"learn_time_ms\": 10379.092, \"total_train_time_s\": 14.334338665008545}", "{\"n\": 3841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3547.09, \"learn_time_ms\": 10416.077, \"total_train_time_s\": 14.337008714675903}", "{\"n\": 3842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3547.09, \"learn_time_ms\": 10293.359, \"total_train_time_s\": 13.968844890594482}", "{\"n\": 3843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3538.26, \"learn_time_ms\": 10257.6, \"total_train_time_s\": 14.097792863845825}", "{\"n\": 3844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3544.44, \"learn_time_ms\": 10239.661, \"total_train_time_s\": 13.68968152999878}", "{\"n\": 3845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3528.47, \"learn_time_ms\": 10187.651, \"total_train_time_s\": 14.19913125038147}", "{\"n\": 3846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3528.47, \"learn_time_ms\": 10172.488, \"total_train_time_s\": 13.627956867218018}", "{\"n\": 3847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3516.79, \"learn_time_ms\": 10339.432, \"total_train_time_s\": 15.120003461837769}", "{\"n\": 3848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3531.67, \"learn_time_ms\": 10401.958, \"total_train_time_s\": 14.169532537460327}", "{\"n\": 3849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3531.67, \"learn_time_ms\": 10470.918, \"total_train_time_s\": 14.096599340438843}", "{\"n\": 3850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3531.67, \"learn_time_ms\": 10431.714, \"total_train_time_s\": 13.698173999786377}", "{\"n\": 3851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3532.66, \"learn_time_ms\": 10472.507, \"total_train_time_s\": 14.685771703720093}", "{\"n\": 3852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3532.66, \"learn_time_ms\": 10473.11, \"total_train_time_s\": 14.28969931602478}", "{\"n\": 3853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3534.2, \"learn_time_ms\": 10608.321, \"total_train_time_s\": 14.915088891983032}", "{\"n\": 3854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3534.2, \"learn_time_ms\": 10584.835, \"total_train_time_s\": 13.272006750106812}", "{\"n\": 3855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3534.8, \"learn_time_ms\": 10682.141, \"total_train_time_s\": 15.179524421691895}", "{\"n\": 3856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3541.79, \"learn_time_ms\": 10715.069, \"total_train_time_s\": 13.981977224349976}", "{\"n\": 3857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3563.17, \"learn_time_ms\": 10524.012, \"total_train_time_s\": 13.418004512786865}", "{\"n\": 3858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3553.24, \"learn_time_ms\": 10523.014, \"total_train_time_s\": 14.492405652999878}", "{\"n\": 3859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.75, \"learn_time_ms\": 10483.436, \"total_train_time_s\": 13.848017930984497}", "{\"n\": 3860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.75, \"learn_time_ms\": 10561.237, \"total_train_time_s\": 14.794878959655762}", "{\"n\": 3861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.2, \"learn_time_ms\": 10506.07, \"total_train_time_s\": 14.478689908981323}", "{\"n\": 3862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3569.48, \"learn_time_ms\": 10540.218, \"total_train_time_s\": 14.397197961807251}", "{\"n\": 3863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3569.48, \"learn_time_ms\": 10443.42, \"total_train_time_s\": 14.07066798210144}", "{\"n\": 3864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3574.48, \"learn_time_ms\": 10473.821, \"total_train_time_s\": 13.577003717422485}", "{\"n\": 3865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3574.48, \"learn_time_ms\": 10345.406, \"total_train_time_s\": 14.069836378097534}", "{\"n\": 3866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3571.51, \"learn_time_ms\": 10292.382, \"total_train_time_s\": 13.709722757339478}", "{\"n\": 3867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.21, \"learn_time_ms\": 10350.876, \"total_train_time_s\": 13.998977899551392}", "{\"n\": 3868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3605.01, \"learn_time_ms\": 10256.341, \"total_train_time_s\": 13.296407222747803}", "{\"n\": 3869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.5, \"learn_time_ms\": 10262.452, \"total_train_time_s\": 13.882383108139038}", "{\"n\": 3870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.5, \"learn_time_ms\": 10229.991, \"total_train_time_s\": 14.499603033065796}", "{\"n\": 3871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.73, \"learn_time_ms\": 10238.439, \"total_train_time_s\": 14.40696907043457}", "{\"n\": 3872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3628.64, \"learn_time_ms\": 10209.353, \"total_train_time_s\": 14.009696006774902}", "{\"n\": 3873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3624.13, \"learn_time_ms\": 10212.354, \"total_train_time_s\": 14.188056230545044}", "{\"n\": 3874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3624.13, \"learn_time_ms\": 10192.627, \"total_train_time_s\": 13.5809485912323}", "{\"n\": 3875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3630.62, \"learn_time_ms\": 10262.667, \"total_train_time_s\": 14.400134325027466}", "{\"n\": 3876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3633.04, \"learn_time_ms\": 10187.89, \"total_train_time_s\": 12.564253568649292}", "{\"n\": 3877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3633.04, \"learn_time_ms\": 10227.27, \"total_train_time_s\": 14.107997417449951}", "{\"n\": 3878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3628.75, \"learn_time_ms\": 10313.213, \"total_train_time_s\": 14.210243225097656}", "{\"n\": 3879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3625.23, \"learn_time_ms\": 10234.737, \"total_train_time_s\": 13.057781219482422}", "{\"n\": 3880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3625.23, \"learn_time_ms\": 10268.82, \"total_train_time_s\": 14.476186752319336}", "{\"n\": 3881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3618.95, \"learn_time_ms\": 10294.265, \"total_train_time_s\": 14.463205575942993}", "{\"n\": 3882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3615.35, \"learn_time_ms\": 10309.541, \"total_train_time_s\": 14.017228841781616}", "{\"n\": 3883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3616.45, \"learn_time_ms\": 10295.89, \"total_train_time_s\": 14.032859802246094}", "{\"n\": 3884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 10285.699, \"total_train_time_s\": 13.28281855583191}", "{\"n\": 3885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3595.67, \"learn_time_ms\": 10293.247, \"total_train_time_s\": 14.455209970474243}", "{\"n\": 3886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3595.67, \"learn_time_ms\": 10409.114, \"total_train_time_s\": 13.795683145523071}", "{\"n\": 3887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3595.67, \"learn_time_ms\": 10288.462, \"total_train_time_s\": 13.307486534118652}", "{\"n\": 3888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3579.56, \"learn_time_ms\": 10276.881, \"total_train_time_s\": 14.154686450958252}", "{\"n\": 3889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3580.94, \"learn_time_ms\": 10456.946, \"total_train_time_s\": 14.761378765106201}", "{\"n\": 3890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3580.94, \"learn_time_ms\": 10397.376, \"total_train_time_s\": 14.000147342681885}", "{\"n\": 3891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3584.15, \"learn_time_ms\": 10364.252, \"total_train_time_s\": 14.139948844909668}", "{\"n\": 3892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3608.33, \"learn_time_ms\": 10407.344, \"total_train_time_s\": 14.406585216522217}", "{\"n\": 3893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3608.33, \"learn_time_ms\": 10428.653, \"total_train_time_s\": 14.043516874313354}", "{\"n\": 3894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3606.7, \"learn_time_ms\": 10532.761, \"total_train_time_s\": 14.47382926940918}", "{\"n\": 3895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.85, \"learn_time_ms\": 10449.52, \"total_train_time_s\": 13.479519367218018}", "{\"n\": 3896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.61, \"learn_time_ms\": 10565.072, \"total_train_time_s\": 15.282443284988403}", "{\"n\": 3897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.61, \"learn_time_ms\": 10677.164, \"total_train_time_s\": 14.229526996612549}", "{\"n\": 3898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3619.57, \"learn_time_ms\": 10627.886, \"total_train_time_s\": 13.486037969589233}", "{\"n\": 3899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.47, \"learn_time_ms\": 10558.515, \"total_train_time_s\": 14.339003562927246}", "{\"n\": 3900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3614.47, \"learn_time_ms\": 10573.76, \"total_train_time_s\": 14.115105152130127}", "{\"n\": 3901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3602.57, \"learn_time_ms\": 10469.235, \"total_train_time_s\": 13.066741228103638}", "{\"n\": 3902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3602.57, \"learn_time_ms\": 10432.393, \"total_train_time_s\": 14.375306367874146}", "{\"n\": 3903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3618.64, \"learn_time_ms\": 10333.501, \"total_train_time_s\": 13.258473873138428}", "{\"n\": 3904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3609.84, \"learn_time_ms\": 10312.035, \"total_train_time_s\": 14.089351177215576}", "{\"n\": 3905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3602.49, \"learn_time_ms\": 10429.062, \"total_train_time_s\": 14.819894313812256}", "{\"n\": 3906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3595.59, \"learn_time_ms\": 10280.121, \"total_train_time_s\": 13.524145126342773}", "{\"n\": 3907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3601.51, \"learn_time_ms\": 10235.98, \"total_train_time_s\": 13.611176013946533}", "{\"n\": 3908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.19, \"learn_time_ms\": 10331.682, \"total_train_time_s\": 14.427941083908081}", "{\"n\": 3909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.19, \"learn_time_ms\": 10414.099, \"total_train_time_s\": 15.329197406768799}", "{\"n\": 3910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3582.89, \"learn_time_ms\": 10444.065, \"total_train_time_s\": 14.762876987457275}", "{\"n\": 3911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3573.56, \"learn_time_ms\": 10623.685, \"total_train_time_s\": 15.217000484466553}", "{\"n\": 3912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.4, \"learn_time_ms\": 10662.633, \"total_train_time_s\": 14.65432620048523}", "{\"n\": 3913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3581.6, \"learn_time_ms\": 10847.773, \"total_train_time_s\": 15.14646053314209}", "{\"n\": 3914, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3581.6, \"learn_time_ms\": 10843.652, \"total_train_time_s\": 14.253699779510498}", "{\"n\": 3915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.57, \"learn_time_ms\": 10688.449, \"total_train_time_s\": 13.38897442817688}", "{\"n\": 3916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3580.85, \"learn_time_ms\": 10651.12, \"total_train_time_s\": 13.04696798324585}", "{\"n\": 3917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3580.85, \"learn_time_ms\": 10683.771, \"total_train_time_s\": 14.210942268371582}", "{\"n\": 3918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3582.74, \"learn_time_ms\": 10535.532, \"total_train_time_s\": 13.190956830978394}", "{\"n\": 3919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.45, \"learn_time_ms\": 10489.033, \"total_train_time_s\": 14.550158262252808}", "{\"n\": 3920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.13, \"learn_time_ms\": 10414.092, \"total_train_time_s\": 13.915361881256104}", "{\"n\": 3921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.13, \"learn_time_ms\": 10295.747, \"total_train_time_s\": 13.912353277206421}", "{\"n\": 3922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3571.54, \"learn_time_ms\": 10229.689, \"total_train_time_s\": 14.055765867233276}", "{\"n\": 3923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3571.54, \"learn_time_ms\": 10142.426, \"total_train_time_s\": 14.08356761932373}", "{\"n\": 3924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3565.54, \"learn_time_ms\": 10131.722, \"total_train_time_s\": 14.098138570785522}", "{\"n\": 3925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3556.99, \"learn_time_ms\": 10243.995, \"total_train_time_s\": 14.43892216682434}", "{\"n\": 3926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3556.99, \"learn_time_ms\": 10398.099, \"total_train_time_s\": 14.892188787460327}", "{\"n\": 3927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3560.01, \"learn_time_ms\": 10454.185, \"total_train_time_s\": 15.069357633590698}", "{\"n\": 3928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3573.6, \"learn_time_ms\": 10577.656, \"total_train_time_s\": 14.650178909301758}", "{\"n\": 3929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.1, \"learn_time_ms\": 10505.127, \"total_train_time_s\": 13.899837017059326}", "{\"n\": 3930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.1, \"learn_time_ms\": 10670.608, \"total_train_time_s\": 15.361752986907959}", "{\"n\": 3931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3565.85, \"learn_time_ms\": 10615.683, \"total_train_time_s\": 13.078390121459961}", "{\"n\": 3932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3586.57, \"learn_time_ms\": 10563.044, \"total_train_time_s\": 13.405457258224487}", "{\"n\": 3933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3583.57, \"learn_time_ms\": 10530.733, \"total_train_time_s\": 13.861093759536743}", "{\"n\": 3934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3583.57, \"learn_time_ms\": 10544.469, \"total_train_time_s\": 14.18787956237793}", "{\"n\": 3935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3602.2, \"learn_time_ms\": 10482.687, \"total_train_time_s\": 13.872097969055176}", "{\"n\": 3936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.93, \"learn_time_ms\": 10305.767, \"total_train_time_s\": 13.393425703048706}", "{\"n\": 3937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.93, \"learn_time_ms\": 10342.995, \"total_train_time_s\": 14.980616331100464}", "{\"n\": 3938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3590.79, \"learn_time_ms\": 10368.102, \"total_train_time_s\": 14.647436380386353}", "{\"n\": 3939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 10377.363, \"total_train_time_s\": 13.829002618789673}", "{\"n\": 3940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 10176.83, \"total_train_time_s\": 13.455420732498169}", "{\"n\": 3941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 10224.713, \"total_train_time_s\": 13.562558650970459}", "{\"n\": 3942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3577.66, \"learn_time_ms\": 10296.125, \"total_train_time_s\": 14.112984418869019}", "{\"n\": 3943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.58, \"learn_time_ms\": 10373.23, \"total_train_time_s\": 14.688895225524902}", "{\"n\": 3944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.08, \"learn_time_ms\": 10331.488, \"total_train_time_s\": 13.665014028549194}", "{\"n\": 3945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3554.93, \"learn_time_ms\": 10297.722, \"total_train_time_s\": 13.644269466400146}", "{\"n\": 3946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.73, \"learn_time_ms\": 10462.711, \"total_train_time_s\": 14.612987995147705}", "{\"n\": 3947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3557.17, \"learn_time_ms\": 10353.967, \"total_train_time_s\": 13.933567762374878}", "{\"n\": 3948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.89, \"learn_time_ms\": 10250.168, \"total_train_time_s\": 13.519745588302612}", "{\"n\": 3949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3551.57, \"learn_time_ms\": 10304.262, \"total_train_time_s\": 14.30727744102478}", "{\"n\": 3950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.27, \"learn_time_ms\": 10304.735, \"total_train_time_s\": 13.312081813812256}", "{\"n\": 3951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3578.17, \"learn_time_ms\": 10435.037, \"total_train_time_s\": 14.820688724517822}", "{\"n\": 3952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3578.17, \"learn_time_ms\": 10413.029, \"total_train_time_s\": 14.098493814468384}", "{\"n\": 3953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.43, \"learn_time_ms\": 10387.434, \"total_train_time_s\": 14.332561492919922}", "{\"n\": 3954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.15, \"learn_time_ms\": 10364.423, \"total_train_time_s\": 13.69122052192688}", "{\"n\": 3955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.15, \"learn_time_ms\": 10408.294, \"total_train_time_s\": 13.865358591079712}", "{\"n\": 3956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.75, \"learn_time_ms\": 10332.196, \"total_train_time_s\": 13.950153112411499}", "{\"n\": 3957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.75, \"learn_time_ms\": 10404.308, \"total_train_time_s\": 14.632304668426514}", "{\"n\": 3958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3546.14, \"learn_time_ms\": 10418.574, \"total_train_time_s\": 13.74424409866333}", "{\"n\": 3959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3546.14, \"learn_time_ms\": 10379.07, \"total_train_time_s\": 13.939667463302612}", "{\"n\": 3960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3546.14, \"learn_time_ms\": 10520.009, \"total_train_time_s\": 15.05949878692627}", "{\"n\": 3961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.22, \"learn_time_ms\": 10406.268, \"total_train_time_s\": 13.76731562614441}", "{\"n\": 3962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3531.3, \"learn_time_ms\": 10505.323, \"total_train_time_s\": 14.816413402557373}", "{\"n\": 3963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3531.3, \"learn_time_ms\": 10333.623, \"total_train_time_s\": 12.776378631591797}", "{\"n\": 3964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3528.11, \"learn_time_ms\": 10320.04, \"total_train_time_s\": 13.484056949615479}", "{\"n\": 3965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3520.32, \"learn_time_ms\": 10397.008, \"total_train_time_s\": 14.547837734222412}", "{\"n\": 3966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3521.16, \"learn_time_ms\": 10414.266, \"total_train_time_s\": 14.0544593334198}", "{\"n\": 3967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3531.01, \"learn_time_ms\": 10394.75, \"total_train_time_s\": 14.462711095809937}", "{\"n\": 3968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3531.01, \"learn_time_ms\": 10520.667, \"total_train_time_s\": 14.778778314590454}", "{\"n\": 3969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3536.26, \"learn_time_ms\": 10564.095, \"total_train_time_s\": 14.589309453964233}", "{\"n\": 3970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3541.6, \"learn_time_ms\": 10474.608, \"total_train_time_s\": 13.976544618606567}", "{\"n\": 3971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3559.57, \"learn_time_ms\": 10575.26, \"total_train_time_s\": 14.707467317581177}", "{\"n\": 3972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.9, \"learn_time_ms\": 10554.491, \"total_train_time_s\": 14.591912031173706}", "{\"n\": 3973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.62, \"learn_time_ms\": 10556.704, \"total_train_time_s\": 12.715360879898071}", "{\"n\": 3974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3576.49, \"learn_time_ms\": 10573.768, \"total_train_time_s\": 13.673105001449585}", "{\"n\": 3975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3576.49, \"learn_time_ms\": 10441.916, \"total_train_time_s\": 13.27678894996643}", "{\"n\": 3976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3578.83, \"learn_time_ms\": 10497.241, \"total_train_time_s\": 14.565448760986328}", "{\"n\": 3977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.48, \"learn_time_ms\": 10533.841, \"total_train_time_s\": 14.694408178329468}", "{\"n\": 3978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.08, \"learn_time_ms\": 10440.934, \"total_train_time_s\": 13.905351877212524}", "{\"n\": 3979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.08, \"learn_time_ms\": 10360.316, \"total_train_time_s\": 13.969290971755981}", "{\"n\": 3980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3562.35, \"learn_time_ms\": 10355.226, \"total_train_time_s\": 13.7757728099823}", "{\"n\": 3981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3562.35, \"learn_time_ms\": 10115.308, \"total_train_time_s\": 12.48713493347168}", "{\"n\": 3982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3562.35, \"learn_time_ms\": 10110.18, \"total_train_time_s\": 14.720749378204346}", "{\"n\": 3983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3567.05, \"learn_time_ms\": 10182.997, \"total_train_time_s\": 13.324345350265503}", "{\"n\": 3984, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3553.18, \"learn_time_ms\": 10309.463, \"total_train_time_s\": 14.92545199394226}", "{\"n\": 3985, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3551.53, \"learn_time_ms\": 10366.891, \"total_train_time_s\": 13.75571084022522}", "{\"n\": 3986, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3556.95, \"learn_time_ms\": 10335.904, \"total_train_time_s\": 14.092202425003052}", "{\"n\": 3987, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.67, \"learn_time_ms\": 10236.427, \"total_train_time_s\": 13.70600414276123}", "{\"n\": 3988, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.89, \"learn_time_ms\": 10441.675, \"total_train_time_s\": 15.93724250793457}", "{\"n\": 3989, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.5, \"learn_time_ms\": 10442.145, \"total_train_time_s\": 13.752690076828003}", "{\"n\": 3990, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.5, \"learn_time_ms\": 10435.927, \"total_train_time_s\": 13.635199069976807}", "{\"n\": 3991, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3559.79, \"learn_time_ms\": 10602.869, \"total_train_time_s\": 14.106485605239868}", "{\"n\": 3992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3547.21, \"learn_time_ms\": 10659.052, \"total_train_time_s\": 15.157058238983154}", "{\"n\": 3993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3547.28, \"learn_time_ms\": 10707.263, \"total_train_time_s\": 14.03973937034607}", "{\"n\": 3994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3553.86, \"learn_time_ms\": 10693.725, \"total_train_time_s\": 14.83048701286316}", "{\"n\": 3995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3553.86, \"learn_time_ms\": 10739.276, \"total_train_time_s\": 14.433597803115845}", "{\"n\": 3996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.46, \"learn_time_ms\": 10810.466, \"total_train_time_s\": 14.865188121795654}", "{\"n\": 3997, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.46, \"learn_time_ms\": 10851.927, \"total_train_time_s\": 14.360188007354736}", "{\"n\": 3998, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.87, \"learn_time_ms\": 10635.26, \"total_train_time_s\": 13.735454559326172}", "{\"n\": 3999, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3580.46, \"learn_time_ms\": 10753.963, \"total_train_time_s\": 14.737649202346802}", "{\"n\": 4000, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.54, \"learn_time_ms\": 10868.67, \"total_train_time_s\": 15.204999446868896}", "{\"n\": 4001, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.54, \"learn_time_ms\": 10957.236, \"total_train_time_s\": 15.273463487625122}", "{\"n\": 4002, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.49, \"learn_time_ms\": 10965.636, \"total_train_time_s\": 15.189952611923218}", "{\"n\": 4003, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.55, \"learn_time_ms\": 10867.377, \"total_train_time_s\": 12.92080545425415}", "{\"n\": 4004, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.55, \"learn_time_ms\": 10800.547, \"total_train_time_s\": 14.310880184173584}", "{\"n\": 4005, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3596.51, \"learn_time_ms\": 10805.229, \"total_train_time_s\": 14.28403091430664}", "{\"n\": 4006, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.76, \"learn_time_ms\": 10698.418, \"total_train_time_s\": 14.052769184112549}", "{\"n\": 4007, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.76, \"learn_time_ms\": 10807.971, \"total_train_time_s\": 15.382987976074219}", "{\"n\": 4008, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3564.67, \"learn_time_ms\": 10831.131, \"total_train_time_s\": 14.121700286865234}", "{\"n\": 4009, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3569.08, \"learn_time_ms\": 10765.907, \"total_train_time_s\": 14.267510652542114}", "{\"n\": 4010, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.72, \"learn_time_ms\": 10811.232, \"total_train_time_s\": 15.358672618865967}", "{\"n\": 4011, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3573.72, \"learn_time_ms\": 10849.943, \"total_train_time_s\": 15.257832288742065}", "{\"n\": 4012, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.63, \"learn_time_ms\": 10815.798, \"total_train_time_s\": 14.985953092575073}", "{\"n\": 4013, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.85, \"learn_time_ms\": 10987.295, \"total_train_time_s\": 14.731449842453003}", "{\"n\": 4014, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.85, \"learn_time_ms\": 10945.599, \"total_train_time_s\": 13.73069715499878}", "{\"n\": 4015, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3594.96, \"learn_time_ms\": 10864.4, \"total_train_time_s\": 13.443885326385498}", "{\"n\": 4016, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3586.25, \"learn_time_ms\": 10813.051, \"total_train_time_s\": 13.362786054611206}", "{\"n\": 4017, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3586.24, \"learn_time_ms\": 10741.64, \"total_train_time_s\": 14.511089324951172}", "{\"n\": 4018, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3587.03, \"learn_time_ms\": 10720.155, \"total_train_time_s\": 13.866996049880981}", "{\"n\": 4019, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3581.84, \"learn_time_ms\": 10832.168, \"total_train_time_s\": 15.160779476165771}", "{\"n\": 4020, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3569.29, \"learn_time_ms\": 10647.104, \"total_train_time_s\": 13.57521939277649}", "{\"n\": 4021, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3557.79, \"learn_time_ms\": 10559.79, \"total_train_time_s\": 14.843380689620972}", "{\"n\": 4022, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3545.29, \"learn_time_ms\": 10474.958, \"total_train_time_s\": 14.177712202072144}", "{\"n\": 4023, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3541.45, \"learn_time_ms\": 10439.557, \"total_train_time_s\": 14.218249797821045}", "{\"n\": 4024, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3535.0, \"learn_time_ms\": 10561.126, \"total_train_time_s\": 14.917368412017822}", "{\"n\": 4025, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3531.0, \"learn_time_ms\": 10576.777, \"total_train_time_s\": 13.675408601760864}", "{\"n\": 4026, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3531.0, \"learn_time_ms\": 10601.058, \"total_train_time_s\": 13.82981562614441}", "{\"n\": 4027, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3521.08, \"learn_time_ms\": 10591.343, \"total_train_time_s\": 14.335268497467041}", "{\"n\": 4028, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3531.54, \"learn_time_ms\": 10512.165, \"total_train_time_s\": 13.05571961402893}", "{\"n\": 4029, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3531.54, \"learn_time_ms\": 10356.891, \"total_train_time_s\": 13.743222951889038}", "{\"n\": 4030, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 10404.545, \"total_train_time_s\": 14.000259399414062}", "{\"n\": 4031, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 10432.547, \"total_train_time_s\": 14.71632981300354}", "{\"n\": 4032, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3555.15, \"learn_time_ms\": 10471.442, \"total_train_time_s\": 14.510834455490112}", "{\"n\": 4033, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3558.04, \"learn_time_ms\": 10466.26, \"total_train_time_s\": 14.134348392486572}", "{\"n\": 4034, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3551.88, \"learn_time_ms\": 10306.432, \"total_train_time_s\": 13.370097160339355}", "{\"n\": 4035, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3560.56, \"learn_time_ms\": 10366.378, \"total_train_time_s\": 14.478523015975952}", "{\"n\": 4036, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3556.96, \"learn_time_ms\": 10473.635, \"total_train_time_s\": 14.84106159210205}", "{\"n\": 4037, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3556.96, \"learn_time_ms\": 10484.242, \"total_train_time_s\": 14.538751125335693}", "{\"n\": 4038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3556.56, \"learn_time_ms\": 10661.617, \"total_train_time_s\": 14.74912405014038}", "{\"n\": 4039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3537.96, \"learn_time_ms\": 10645.097, \"total_train_time_s\": 13.434523582458496}", "{\"n\": 4040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3537.96, \"learn_time_ms\": 10667.214, \"total_train_time_s\": 14.47857928276062}", "{\"n\": 4041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3533.82, \"learn_time_ms\": 10611.389, \"total_train_time_s\": 14.420405149459839}", "{\"n\": 4042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3537.04, \"learn_time_ms\": 10579.243, \"total_train_time_s\": 14.16834568977356}", "{\"n\": 4043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3549.54, \"learn_time_ms\": 10542.108, \"total_train_time_s\": 13.823374032974243}", "{\"n\": 4044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3549.54, \"learn_time_ms\": 10675.563, \"total_train_time_s\": 14.808436155319214}", "{\"n\": 4045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3547.18, \"learn_time_ms\": 10718.368, \"total_train_time_s\": 14.874347448348999}", "{\"n\": 4046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.51, \"learn_time_ms\": 10592.104, \"total_train_time_s\": 13.58557939529419}", "{\"n\": 4047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.51, \"learn_time_ms\": 10511.852, \"total_train_time_s\": 13.965770483016968}", "{\"n\": 4048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.51, \"learn_time_ms\": 10384.438, \"total_train_time_s\": 13.73024868965149}", "{\"n\": 4049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3549.76, \"learn_time_ms\": 10416.083, \"total_train_time_s\": 13.87769627571106}", "{\"n\": 4050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.93, \"learn_time_ms\": 10374.287, \"total_train_time_s\": 13.905832052230835}", "{\"n\": 4051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.93, \"learn_time_ms\": 10380.337, \"total_train_time_s\": 14.297988176345825}", "{\"n\": 4052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3550.93, \"learn_time_ms\": 10356.339, \"total_train_time_s\": 13.95943546295166}", "{\"n\": 4053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3568.93, \"learn_time_ms\": 10388.468, \"total_train_time_s\": 14.169004678726196}", "{\"n\": 4054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3568.6, \"learn_time_ms\": 10365.276, \"total_train_time_s\": 14.397529125213623}", "{\"n\": 4055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3576.77, \"learn_time_ms\": 10400.13, \"total_train_time_s\": 15.20428466796875}", "{\"n\": 4056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3577.16, \"learn_time_ms\": 10426.216, \"total_train_time_s\": 13.72859501838684}", "{\"n\": 4057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.15, \"learn_time_ms\": 10530.515, \"total_train_time_s\": 14.890398263931274}", "{\"n\": 4058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3575.15, \"learn_time_ms\": 10560.934, \"total_train_time_s\": 13.793975353240967}", "{\"n\": 4059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3586.58, \"learn_time_ms\": 10492.614, \"total_train_time_s\": 13.51584529876709}", "{\"n\": 4060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3546.22, \"learn_time_ms\": 10573.278, \"total_train_time_s\": 14.491600751876831}", "{\"n\": 4061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3546.22, \"learn_time_ms\": 10615.403, \"total_train_time_s\": 14.568720817565918}", "{\"n\": 4062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3543.94, \"learn_time_ms\": 10580.866, \"total_train_time_s\": 13.650968790054321}", "{\"n\": 4063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3542.75, \"learn_time_ms\": 10679.474, \"total_train_time_s\": 15.506927251815796}", "{\"n\": 4064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3549.65, \"learn_time_ms\": 10731.628, \"total_train_time_s\": 14.793946504592896}", "{\"n\": 4065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3549.65, \"learn_time_ms\": 10710.312, \"total_train_time_s\": 14.774960041046143}", "{\"n\": 4066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 10758.426, \"total_train_time_s\": 14.075436353683472}", "{\"n\": 4067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3534.31, \"learn_time_ms\": 10664.786, \"total_train_time_s\": 13.951287746429443}", "{\"n\": 4068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3546.58, \"learn_time_ms\": 10724.324, \"total_train_time_s\": 14.408921003341675}", "{\"n\": 4069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3539.01, \"learn_time_ms\": 10839.263, \"total_train_time_s\": 14.331837177276611}", "{\"n\": 4070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3557.45, \"learn_time_ms\": 10900.497, \"total_train_time_s\": 15.32804560661316}", "{\"n\": 4071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3556.75, \"learn_time_ms\": 10828.37, \"total_train_time_s\": 14.223919868469238}", "{\"n\": 4072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3556.75, \"learn_time_ms\": 10860.273, \"total_train_time_s\": 14.049235343933105}", "{\"n\": 4073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.33, \"learn_time_ms\": 10734.512, \"total_train_time_s\": 13.978971481323242}", "{\"n\": 4074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3575.48, \"learn_time_ms\": 10647.753, \"total_train_time_s\": 14.266221046447754}", "{\"n\": 4075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.01, \"learn_time_ms\": 10634.761, \"total_train_time_s\": 14.716026782989502}", "{\"n\": 4076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3581.77, \"learn_time_ms\": 10682.87, \"total_train_time_s\": 14.562612533569336}", "{\"n\": 4077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3587.39, \"learn_time_ms\": 10703.702, \"total_train_time_s\": 14.018728017807007}", "{\"n\": 4078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3584.76, \"learn_time_ms\": 10654.471, \"total_train_time_s\": 13.970938682556152}", "{\"n\": 4079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3583.16, \"learn_time_ms\": 10657.244, \"total_train_time_s\": 14.348158121109009}", "{\"n\": 4080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3602.22, \"learn_time_ms\": 10484.662, \"total_train_time_s\": 13.692120790481567}", "{\"n\": 4081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.53, \"learn_time_ms\": 10488.103, \"total_train_time_s\": 14.109461307525635}", "{\"n\": 4082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3619.23, \"learn_time_ms\": 10506.957, \"total_train_time_s\": 14.007696866989136}", "{\"n\": 4083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3619.23, \"learn_time_ms\": 10601.977, \"total_train_time_s\": 14.87539529800415}", "{\"n\": 4084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3634.78, \"learn_time_ms\": 10554.736, \"total_train_time_s\": 13.401078939437866}", "{\"n\": 4085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3634.78, \"learn_time_ms\": 10454.887, \"total_train_time_s\": 13.824878215789795}", "{\"n\": 4086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3629.7, \"learn_time_ms\": 10333.943, \"total_train_time_s\": 13.466120719909668}", "{\"n\": 4087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3611.24, \"learn_time_ms\": 10334.579, \"total_train_time_s\": 14.112679481506348}", "{\"n\": 4088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3616.52, \"learn_time_ms\": 10404.082, \"total_train_time_s\": 14.82455325126648}", "{\"n\": 4089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.79, \"learn_time_ms\": 10486.895, \"total_train_time_s\": 15.316617012023926}", "{\"n\": 4090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.79, \"learn_time_ms\": 10496.32, \"total_train_time_s\": 13.87349557876587}", "{\"n\": 4091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3609.08, \"learn_time_ms\": 10473.234, \"total_train_time_s\": 13.854492664337158}", "{\"n\": 4092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3611.13, \"learn_time_ms\": 10548.032, \"total_train_time_s\": 14.928497552871704}", "{\"n\": 4093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3612.09, \"learn_time_ms\": 10497.393, \"total_train_time_s\": 14.403465270996094}", "{\"n\": 4094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3617.32, \"learn_time_ms\": 10535.633, \"total_train_time_s\": 13.827037811279297}", "{\"n\": 4095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3628.16, \"learn_time_ms\": 10592.279, \"total_train_time_s\": 14.33493947982788}", "{\"n\": 4096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3628.16, \"learn_time_ms\": 10675.407, \"total_train_time_s\": 14.12264347076416}", "{\"n\": 4097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3623.05, \"learn_time_ms\": 10719.239, \"total_train_time_s\": 14.690650701522827}", "{\"n\": 4098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3623.05, \"learn_time_ms\": 10742.677, \"total_train_time_s\": 14.849000453948975}", "{\"n\": 4099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3631.99, \"learn_time_ms\": 10744.545, \"total_train_time_s\": 15.31693410873413}", "{\"n\": 4100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3634.39, \"learn_time_ms\": 10862.591, \"total_train_time_s\": 14.713963747024536}", "{\"n\": 4101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3634.39, \"learn_time_ms\": 10852.719, \"total_train_time_s\": 13.534821510314941}", "{\"n\": 4102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3614.84, \"learn_time_ms\": 10799.004, \"total_train_time_s\": 14.360345840454102}", "{\"n\": 4103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3643.94, \"learn_time_ms\": 10827.882, \"total_train_time_s\": 14.585335493087769}", "{\"n\": 4104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3643.25, \"learn_time_ms\": 10810.363, \"total_train_time_s\": 13.68857741355896}", "{\"n\": 4105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.65, \"learn_time_ms\": 10842.381, \"total_train_time_s\": 14.893732070922852}", "{\"n\": 4106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3627.37, \"learn_time_ms\": 10799.795, \"total_train_time_s\": 13.877066135406494}", "{\"n\": 4107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.14, \"learn_time_ms\": 10749.0, \"total_train_time_s\": 14.069941759109497}", "{\"n\": 4108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.55, \"learn_time_ms\": 10661.377, \"total_train_time_s\": 14.17155146598816}", "{\"n\": 4109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.8, \"learn_time_ms\": 10576.444, \"total_train_time_s\": 14.301710605621338}", "{\"n\": 4110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3612.8, \"learn_time_ms\": 10492.092, \"total_train_time_s\": 13.856441974639893}", "{\"n\": 4111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3612.8, \"learn_time_ms\": 10605.088, \"total_train_time_s\": 14.851061582565308}", "{\"n\": 4112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.84, \"learn_time_ms\": 10595.292, \"total_train_time_s\": 14.2888765335083}", "{\"n\": 4113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 10550.866, \"total_train_time_s\": 14.243062973022461}", "{\"n\": 4114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 10543.014, \"total_train_time_s\": 13.600306987762451}", "{\"n\": 4115, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.39, \"learn_time_ms\": 10526.613, \"total_train_time_s\": 14.687078714370728}", "{\"n\": 4116, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.69, \"learn_time_ms\": 10442.583, \"total_train_time_s\": 12.899044513702393}", "{\"n\": 4117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3641.27, \"learn_time_ms\": 10420.682, \"total_train_time_s\": 13.671183347702026}", "{\"n\": 4118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3641.27, \"learn_time_ms\": 10369.927, \"total_train_time_s\": 13.629563093185425}", "{\"n\": 4119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.47, \"learn_time_ms\": 10420.732, \"total_train_time_s\": 14.907838582992554}", "{\"n\": 4120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.47, \"learn_time_ms\": 10410.525, \"total_train_time_s\": 14.09305739402771}", "{\"n\": 4121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3612.33, \"learn_time_ms\": 10319.639, \"total_train_time_s\": 13.890408039093018}", "{\"n\": 4122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.77, \"learn_time_ms\": 10373.525, \"total_train_time_s\": 14.795263767242432}", "{\"n\": 4123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.77, \"learn_time_ms\": 10407.502, \"total_train_time_s\": 14.596532106399536}", "{\"n\": 4124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.77, \"learn_time_ms\": 10495.821, \"total_train_time_s\": 14.594240188598633}", "{\"n\": 4125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.92, \"learn_time_ms\": 10431.348, \"total_train_time_s\": 13.920259952545166}", "{\"n\": 4126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3610.63, \"learn_time_ms\": 10558.248, \"total_train_time_s\": 14.14505386352539}", "{\"n\": 4127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3610.63, \"learn_time_ms\": 10570.655, \"total_train_time_s\": 14.06952714920044}", "{\"n\": 4128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.16, \"learn_time_ms\": 10565.187, \"total_train_time_s\": 13.6218740940094}", "{\"n\": 4129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.32, \"learn_time_ms\": 10448.43, \"total_train_time_s\": 13.720568418502808}", "{\"n\": 4130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3620.24, \"learn_time_ms\": 10550.436, \"total_train_time_s\": 14.971871614456177}", "{\"n\": 4131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3620.24, \"learn_time_ms\": 10508.963, \"total_train_time_s\": 13.567868947982788}", "{\"n\": 4132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3600.69, \"learn_time_ms\": 10498.495, \"total_train_time_s\": 14.625338554382324}", "{\"n\": 4133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3604.83, \"learn_time_ms\": 10454.57, \"total_train_time_s\": 14.058207273483276}", "{\"n\": 4134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3610.46, \"learn_time_ms\": 10451.369, \"total_train_time_s\": 14.563227891921997}", "{\"n\": 4135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3610.46, \"learn_time_ms\": 10392.84, \"total_train_time_s\": 13.231386661529541}", "{\"n\": 4136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3620.21, \"learn_time_ms\": 10308.153, \"total_train_time_s\": 13.311243534088135}", "{\"n\": 4137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.24, \"learn_time_ms\": 10260.479, \"total_train_time_s\": 13.461091756820679}", "{\"n\": 4138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.24, \"learn_time_ms\": 10270.158, \"total_train_time_s\": 13.635708808898926}", "{\"n\": 4139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3620.93, \"learn_time_ms\": 10342.864, \"total_train_time_s\": 14.64486026763916}", "{\"n\": 4140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.77, \"learn_time_ms\": 10232.556, \"total_train_time_s\": 13.692379713058472}", "{\"n\": 4141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10189.872, \"total_train_time_s\": 12.935133457183838}", "{\"n\": 4142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10139.996, \"total_train_time_s\": 14.174455404281616}", "{\"n\": 4143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3628.88, \"learn_time_ms\": 10136.318, \"total_train_time_s\": 13.973907709121704}", "{\"n\": 4144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3628.88, \"learn_time_ms\": 10181.815, \"total_train_time_s\": 15.06526494026184}", "{\"n\": 4145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.0, \"learn_time_ms\": 10205.648, \"total_train_time_s\": 13.66844367980957}", "{\"n\": 4146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3628.45, \"learn_time_ms\": 10254.996, \"total_train_time_s\": 13.799597263336182}", "{\"n\": 4147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.94, \"learn_time_ms\": 10347.252, \"total_train_time_s\": 14.247400760650635}", "{\"n\": 4148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.94, \"learn_time_ms\": 10322.421, \"total_train_time_s\": 13.21907639503479}", "{\"n\": 4149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.37, \"learn_time_ms\": 10315.399, \"total_train_time_s\": 14.339723587036133}", "{\"n\": 4150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.37, \"learn_time_ms\": 10254.282, \"total_train_time_s\": 13.350732803344727}", "{\"n\": 4151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 10321.349, \"total_train_time_s\": 13.920571088790894}", "{\"n\": 4152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3645.45, \"learn_time_ms\": 10301.255, \"total_train_time_s\": 13.931342124938965}", "{\"n\": 4153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.47, \"learn_time_ms\": 10252.707, \"total_train_time_s\": 13.770478963851929}", "{\"n\": 4154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.47, \"learn_time_ms\": 10051.711, \"total_train_time_s\": 12.98745083808899}", "{\"n\": 4155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3638.11, \"learn_time_ms\": 10064.262, \"total_train_time_s\": 13.637609481811523}", "{\"n\": 4156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.6, \"learn_time_ms\": 10122.651, \"total_train_time_s\": 14.582203149795532}", "{\"n\": 4157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.83, \"learn_time_ms\": 10220.87, \"total_train_time_s\": 15.261776447296143}", "{\"n\": 4158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.83, \"learn_time_ms\": 10305.973, \"total_train_time_s\": 14.312885999679565}", "{\"n\": 4159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.68, \"learn_time_ms\": 10320.577, \"total_train_time_s\": 14.644495964050293}", "{\"n\": 4160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.98, \"learn_time_ms\": 10294.373, \"total_train_time_s\": 12.937817811965942}", "{\"n\": 4161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.98, \"learn_time_ms\": 10379.482, \"total_train_time_s\": 14.563259840011597}", "{\"n\": 4162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.98, \"learn_time_ms\": 10392.838, \"total_train_time_s\": 14.248051643371582}", "{\"n\": 4163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3642.25, \"learn_time_ms\": 10513.223, \"total_train_time_s\": 14.693139553070068}", "{\"n\": 4164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3647.55, \"learn_time_ms\": 10624.793, \"total_train_time_s\": 14.074462652206421}", "{\"n\": 4165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3647.55, \"learn_time_ms\": 10731.318, \"total_train_time_s\": 15.083052158355713}", "{\"n\": 4166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3649.46, \"learn_time_ms\": 10779.973, \"total_train_time_s\": 15.045981884002686}", "{\"n\": 4167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3649.46, \"learn_time_ms\": 10624.068, \"total_train_time_s\": 13.904711246490479}", "{\"n\": 4168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.14, \"learn_time_ms\": 10647.308, \"total_train_time_s\": 14.423874378204346}", "{\"n\": 4169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.14, \"learn_time_ms\": 10635.88, \"total_train_time_s\": 14.534241914749146}", "{\"n\": 4170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.23, \"learn_time_ms\": 10678.794, \"total_train_time_s\": 13.560110569000244}", "{\"n\": 4171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3625.16, \"learn_time_ms\": 10530.687, \"total_train_time_s\": 13.280749320983887}", "{\"n\": 4172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3625.34, \"learn_time_ms\": 10549.576, \"total_train_time_s\": 14.3231201171875}", "{\"n\": 4173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3625.34, \"learn_time_ms\": 10508.853, \"total_train_time_s\": 14.280046224594116}", "{\"n\": 4174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.75, \"learn_time_ms\": 10439.13, \"total_train_time_s\": 13.442257642745972}", "{\"n\": 4175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.81, \"learn_time_ms\": 10412.806, \"total_train_time_s\": 14.345629930496216}", "{\"n\": 4176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3632.67, \"learn_time_ms\": 10307.913, \"total_train_time_s\": 14.259581089019775}", "{\"n\": 4177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3632.67, \"learn_time_ms\": 10354.285, \"total_train_time_s\": 14.234266996383667}", "{\"n\": 4178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3645.53, \"learn_time_ms\": 10373.378, \"total_train_time_s\": 14.521199464797974}", "{\"n\": 4179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.05, \"learn_time_ms\": 10361.511, \"total_train_time_s\": 14.267838478088379}", "{\"n\": 4180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.05, \"learn_time_ms\": 10463.414, \"total_train_time_s\": 14.453713178634644}", "{\"n\": 4181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.53, \"learn_time_ms\": 10514.372, \"total_train_time_s\": 13.762495517730713}", "{\"n\": 4182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3642.21, \"learn_time_ms\": 10526.345, \"total_train_time_s\": 14.375670433044434}", "{\"n\": 4183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.87, \"learn_time_ms\": 10498.328, \"total_train_time_s\": 14.04462742805481}", "{\"n\": 4184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.87, \"learn_time_ms\": 10604.938, \"total_train_time_s\": 14.303245544433594}", "{\"n\": 4185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.07, \"learn_time_ms\": 10719.638, \"total_train_time_s\": 15.705363750457764}", "{\"n\": 4186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.67, \"learn_time_ms\": 10703.006, \"total_train_time_s\": 13.858943700790405}", "{\"n\": 4187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3645.71, \"learn_time_ms\": 10654.21, \"total_train_time_s\": 13.68810510635376}", "{\"n\": 4188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3645.71, \"learn_time_ms\": 10566.388, \"total_train_time_s\": 13.990439176559448}", "{\"n\": 4189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3653.86, \"learn_time_ms\": 10608.768, \"total_train_time_s\": 14.879568576812744}", "{\"n\": 4190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3654.83, \"learn_time_ms\": 10645.859, \"total_train_time_s\": 14.87312126159668}", "{\"n\": 4191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3666.21, \"learn_time_ms\": 10816.925, \"total_train_time_s\": 15.290662288665771}", "{\"n\": 4192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3674.88, \"learn_time_ms\": 10719.017, \"total_train_time_s\": 13.262927293777466}", "{\"n\": 4193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3682.94, \"learn_time_ms\": 10667.297, \"total_train_time_s\": 13.496752500534058}", "{\"n\": 4194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3698.77, \"learn_time_ms\": 10660.687, \"total_train_time_s\": 14.303832530975342}", "{\"n\": 4195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3698.04, \"learn_time_ms\": 10516.785, \"total_train_time_s\": 14.257550239562988}", "{\"n\": 4196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3691.77, \"learn_time_ms\": 10581.264, \"total_train_time_s\": 14.369502544403076}", "{\"n\": 4197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3696.86, \"learn_time_ms\": 10673.785, \"total_train_time_s\": 14.737672805786133}", "{\"n\": 4198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3692.84, \"learn_time_ms\": 10707.959, \"total_train_time_s\": 14.158432960510254}", "{\"n\": 4199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3696.02, \"learn_time_ms\": 10658.001, \"total_train_time_s\": 14.324936389923096}", "{\"n\": 4200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3703.09, \"learn_time_ms\": 10581.239, \"total_train_time_s\": 13.902859449386597}", "{\"n\": 4201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3703.09, \"learn_time_ms\": 10352.061, \"total_train_time_s\": 13.084860801696777}", "{\"n\": 4202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3703.43, \"learn_time_ms\": 10412.885, \"total_train_time_s\": 14.041691780090332}", "{\"n\": 4203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3712.89, \"learn_time_ms\": 10462.343, \"total_train_time_s\": 14.029362916946411}", "{\"n\": 4204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3709.51, \"learn_time_ms\": 10461.978, \"total_train_time_s\": 14.38478970527649}", "{\"n\": 4205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3719.01, \"learn_time_ms\": 10444.775, \"total_train_time_s\": 13.873073816299438}", "{\"n\": 4206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3725.19, \"learn_time_ms\": 10315.914, \"total_train_time_s\": 13.323050022125244}", "{\"n\": 4207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3724.16, \"learn_time_ms\": 10297.391, \"total_train_time_s\": 14.883076190948486}", "{\"n\": 4208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3730.58, \"learn_time_ms\": 10349.466, \"total_train_time_s\": 15.027238607406616}", "{\"n\": 4209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3712.32, \"learn_time_ms\": 10265.449, \"total_train_time_s\": 13.283593654632568}", "{\"n\": 4210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3712.32, \"learn_time_ms\": 10205.329, \"total_train_time_s\": 13.291815519332886}", "{\"n\": 4211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3716.28, \"learn_time_ms\": 10339.036, \"total_train_time_s\": 14.743951797485352}", "{\"n\": 4212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3706.58, \"learn_time_ms\": 10295.608, \"total_train_time_s\": 13.405358791351318}", "{\"n\": 4213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3706.58, \"learn_time_ms\": 10335.402, \"total_train_time_s\": 14.38654637336731}", "{\"n\": 4214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3706.58, \"learn_time_ms\": 10343.505, \"total_train_time_s\": 14.426433563232422}", "{\"n\": 4215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3707.37, \"learn_time_ms\": 10415.048, \"total_train_time_s\": 14.534831762313843}", "{\"n\": 4216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3702.66, \"learn_time_ms\": 10519.424, \"total_train_time_s\": 14.06397795677185}", "{\"n\": 4217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3702.66, \"learn_time_ms\": 10548.758, \"total_train_time_s\": 14.68380069732666}", "{\"n\": 4218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3704.35, \"learn_time_ms\": 10475.677, \"total_train_time_s\": 13.903299808502197}", "{\"n\": 4219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3699.22, \"learn_time_ms\": 10551.779, \"total_train_time_s\": 14.117743253707886}", "{\"n\": 4220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3684.09, \"learn_time_ms\": 10653.662, \"total_train_time_s\": 14.369398593902588}", "{\"n\": 4221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3684.09, \"learn_time_ms\": 10702.959, \"total_train_time_s\": 14.987218618392944}", "{\"n\": 4222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3685.69, \"learn_time_ms\": 10704.31, \"total_train_time_s\": 13.522829532623291}", "{\"n\": 4223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3685.69, \"learn_time_ms\": 10642.018, \"total_train_time_s\": 13.75897216796875}", "{\"n\": 4224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 10569.354, \"total_train_time_s\": 13.669820547103882}", "{\"n\": 4225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 10463.511, \"total_train_time_s\": 13.56778073310852}", "{\"n\": 4226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.78, \"learn_time_ms\": 10453.446, \"total_train_time_s\": 14.167807817459106}", "{\"n\": 4227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.7, \"learn_time_ms\": 10415.049, \"total_train_time_s\": 14.503255605697632}", "{\"n\": 4228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.7, \"learn_time_ms\": 10408.241, \"total_train_time_s\": 14.050668001174927}", "{\"n\": 4229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3676.34, \"learn_time_ms\": 10383.89, \"total_train_time_s\": 13.900242805480957}", "{\"n\": 4230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 10432.486, \"total_train_time_s\": 15.11389422416687}", "{\"n\": 4231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 10243.505, \"total_train_time_s\": 13.169662952423096}", "{\"n\": 4232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 10212.926, \"total_train_time_s\": 13.213348627090454}", "{\"n\": 4233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.86, \"learn_time_ms\": 10256.175, \"total_train_time_s\": 14.403947830200195}", "{\"n\": 4234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10324.924, \"total_train_time_s\": 14.673795700073242}", "{\"n\": 4235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3642.42, \"learn_time_ms\": 10380.92, \"total_train_time_s\": 14.038506746292114}", "{\"n\": 4236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3639.73, \"learn_time_ms\": 10328.405, \"total_train_time_s\": 13.554746389389038}", "{\"n\": 4237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 10299.845, \"total_train_time_s\": 14.055114507675171}", "{\"n\": 4238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10359.677, \"total_train_time_s\": 14.584912061691284}", "{\"n\": 4239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10367.476, \"total_train_time_s\": 14.16174578666687}", "{\"n\": 4240, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3654.43, \"learn_time_ms\": 10322.119, \"total_train_time_s\": 14.50060248374939}", "{\"n\": 4241, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3659.11, \"learn_time_ms\": 10423.461, \"total_train_time_s\": 14.029145002365112}", "{\"n\": 4242, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3664.12, \"learn_time_ms\": 10566.611, \"total_train_time_s\": 14.79058313369751}", "{\"n\": 4243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3666.11, \"learn_time_ms\": 10481.69, \"total_train_time_s\": 13.456961393356323}", "{\"n\": 4244, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3666.79, \"learn_time_ms\": 10448.428, \"total_train_time_s\": 14.262988805770874}", "{\"n\": 4245, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 10487.167, \"total_train_time_s\": 14.417687177658081}", "{\"n\": 4246, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3674.61, \"learn_time_ms\": 10641.488, \"total_train_time_s\": 14.982372999191284}", "{\"n\": 4247, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3674.61, \"learn_time_ms\": 10637.121, \"total_train_time_s\": 13.996570110321045}", "{\"n\": 4248, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3666.57, \"learn_time_ms\": 10559.2, \"total_train_time_s\": 13.536884784698486}", "{\"n\": 4249, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3669.18, \"learn_time_ms\": 10742.253, \"total_train_time_s\": 15.679192066192627}", "{\"n\": 4250, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.96, \"learn_time_ms\": 10643.076, \"total_train_time_s\": 13.410938024520874}", "{\"n\": 4251, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.96, \"learn_time_ms\": 10640.819, \"total_train_time_s\": 14.143666982650757}", "{\"n\": 4252, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3678.64, \"learn_time_ms\": 10599.724, \"total_train_time_s\": 14.241350650787354}", "{\"n\": 4253, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10708.231, \"total_train_time_s\": 14.405726671218872}", "{\"n\": 4254, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10677.383, \"total_train_time_s\": 13.971013307571411}", "{\"n\": 4255, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3651.4, \"learn_time_ms\": 10589.666, \"total_train_time_s\": 13.757558345794678}", "{\"n\": 4256, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3651.11, \"learn_time_ms\": 10482.713, \"total_train_time_s\": 14.192325115203857}", "{\"n\": 4257, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3647.26, \"learn_time_ms\": 10526.83, \"total_train_time_s\": 14.653480768203735}", "{\"n\": 4258, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3647.26, \"learn_time_ms\": 10590.33, \"total_train_time_s\": 14.518993616104126}", "{\"n\": 4259, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3654.53, \"learn_time_ms\": 10440.396, \"total_train_time_s\": 14.390427112579346}", "{\"n\": 4260, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.64, \"learn_time_ms\": 10404.544, \"total_train_time_s\": 13.335597276687622}", "{\"n\": 4261, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3654.64, \"learn_time_ms\": 10422.32, \"total_train_time_s\": 14.074860334396362}", "{\"n\": 4262, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3654.64, \"learn_time_ms\": 10394.059, \"total_train_time_s\": 14.030687093734741}", "{\"n\": 4263, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.35, \"learn_time_ms\": 10364.539, \"total_train_time_s\": 14.322244882583618}", "{\"n\": 4264, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10413.625, \"total_train_time_s\": 14.236922025680542}", "{\"n\": 4265, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10406.02, \"total_train_time_s\": 13.701968669891357}", "{\"n\": 4266, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10510.971, \"total_train_time_s\": 15.115497589111328}", "{\"n\": 4267, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10516.897, \"total_train_time_s\": 14.608500242233276}", "{\"n\": 4268, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.81, \"learn_time_ms\": 10515.726, \"total_train_time_s\": 14.335120439529419}", "{\"n\": 4269, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.81, \"learn_time_ms\": 10440.293, \"total_train_time_s\": 13.427687644958496}", "{\"n\": 4270, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3650.57, \"learn_time_ms\": 10549.711, \"total_train_time_s\": 14.251802206039429}", "{\"n\": 4271, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10605.463, \"total_train_time_s\": 14.802124738693237}", "{\"n\": 4272, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.55, \"learn_time_ms\": 10555.258, \"total_train_time_s\": 13.667725324630737}", "{\"n\": 4273, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.03, \"learn_time_ms\": 10713.936, \"total_train_time_s\": 15.963954210281372}", "{\"n\": 4274, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.03, \"learn_time_ms\": 10736.648, \"total_train_time_s\": 14.651081562042236}", "{\"n\": 4275, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3636.03, \"learn_time_ms\": 10873.157, \"total_train_time_s\": 15.155122995376587}", "{\"n\": 4276, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.09, \"learn_time_ms\": 10792.628, \"total_train_time_s\": 14.36823558807373}", "{\"n\": 4277, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.48, \"learn_time_ms\": 10753.925, \"total_train_time_s\": 14.528234958648682}", "{\"n\": 4278, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3640.48, \"learn_time_ms\": 10811.585, \"total_train_time_s\": 15.126110076904297}", "{\"n\": 4279, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3628.2, \"learn_time_ms\": 11057.036, \"total_train_time_s\": 16.019961833953857}", "{\"n\": 4280, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 10934.304, \"total_train_time_s\": 12.804852724075317}", "{\"n\": 4281, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 10758.82, \"total_train_time_s\": 13.100383281707764}", "{\"n\": 4282, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3595.99, \"learn_time_ms\": 10793.892, \"total_train_time_s\": 13.950264692306519}", "{\"n\": 4283, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.23, \"learn_time_ms\": 10633.177, \"total_train_time_s\": 14.194164991378784}", "{\"n\": 4284, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3577.19, \"learn_time_ms\": 10609.92, \"total_train_time_s\": 14.312037229537964}", "{\"n\": 4285, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3572.94, \"learn_time_ms\": 10519.451, \"total_train_time_s\": 14.239279985427856}", "{\"n\": 4286, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3576.76, \"learn_time_ms\": 10569.336, \"total_train_time_s\": 14.927783012390137}", "{\"n\": 4287, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3571.98, \"learn_time_ms\": 10601.521, \"total_train_time_s\": 14.592018604278564}", "{\"n\": 4288, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.07, \"learn_time_ms\": 10469.089, \"total_train_time_s\": 13.776543140411377}", "{\"n\": 4289, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3569.07, \"learn_time_ms\": 10265.425, \"total_train_time_s\": 13.85629940032959}", "{\"n\": 4290, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3582.81, \"learn_time_ms\": 10414.298, \"total_train_time_s\": 14.405915975570679}", "{\"n\": 4291, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3571.28, \"learn_time_ms\": 10519.768, \"total_train_time_s\": 14.059236288070679}", "{\"n\": 4292, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.12, \"learn_time_ms\": 10578.65, \"total_train_time_s\": 14.469711542129517}", "{\"n\": 4293, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3580.21, \"learn_time_ms\": 10530.993, \"total_train_time_s\": 13.731240510940552}", "{\"n\": 4294, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 10581.434, \"total_train_time_s\": 14.752513885498047}", "{\"n\": 4295, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3579.83, \"learn_time_ms\": 10491.151, \"total_train_time_s\": 13.482247591018677}", "{\"n\": 4296, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3578.65, \"learn_time_ms\": 10467.886, \"total_train_time_s\": 14.617016553878784}"]