["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 1674.976, \"total_train_time_s\": 2.446032762527466}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.408200740814209}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3878755569458008}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.3714008331298828}", "{\"n\": 5, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.481107234954834}", "{\"n\": 6, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.3787760734558105}", "{\"n\": 7, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.242, \"total_train_time_s\": 1.3734607696533203}", "{\"n\": 8, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3740270137786865}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1087.0, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4072215557098389}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1145.0, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.3896942138671875}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1285.25, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3976731300354004}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1285.25, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.3875010013580322}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1285.25, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.378391981124878}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1270.0, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.3970201015472412}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.142857142857142, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1276.7142857142858, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.3814692497253418}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1263.5, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.399707317352295}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1263.5, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.381333351135254}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11111111111111, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1257.6666666666667, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4080462455749512}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11111111111111, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1257.6666666666667, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4076499938964844}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.272727272727273, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1250.090909090909, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3910341262817383}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.272727272727273, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1250.090909090909, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4662559032440186}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.307692307692307, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1242.6153846153845, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.3944518566131592}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.307692307692307, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1242.6153846153845, \"learn_time_ms\": 4.215, \"total_train_time_s\": 1.3942742347717285}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.357142857142858, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1238.142857142857, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4064280986785889}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.266666666666666, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1239.4, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4256508350372314}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.294117647058822, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1239.0588235294117, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.417797565460205}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.294117647058822, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1239.0588235294117, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3690063953399658}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.333333333333332, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1231.388888888889, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.3814282417297363}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36842105263158, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1222.6842105263158, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.3905632495880127}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36842105263158, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1222.6842105263158, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.3955910205841064}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.428571428571427, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1212.142857142857, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.414332389831543}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.428571428571427, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1212.142857142857, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.373443841934204}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.40909090909091, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.6818181818182, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4086089134216309}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.434782608695652, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1207.695652173913, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.410463571548462}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.434782608695652, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1207.695652173913, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3858728408813477}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1199.6, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3939409255981445}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46153846153846, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.1923076923076, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3850033283233643}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48148148148148, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.5925925925926, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.411893606185913}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48148148148148, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.5925925925926, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3629865646362305}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.448275862068964, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1200.2758620689656, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.3932344913482666}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.466666666666665, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1196.5333333333333, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.5140268802642822}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.483870967741936, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1193.1935483870968, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.425266981124878}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.483870967741936, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1193.1935483870968, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4125194549560547}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.875, \"learn_time_ms\": 4.223, \"total_train_time_s\": 1.402726411819458}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.484848484848484, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1186.3030303030303, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4001774787902832}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.1764705882354, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4340391159057617}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.514285714285716, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.5142857142857, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.417292833328247}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52777777777778, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.6666666666667, \"learn_time_ms\": 4.201, \"total_train_time_s\": 1.41038179397583}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54054054054054, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1182.5945945945946, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4061474800109863}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.526315789473685, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.5526315789473, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4059135913848877}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.512820512820515, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.820512820513, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.375969409942627}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.512820512820515, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.820512820513, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3703019618988037}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.525, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.75, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.3925180435180664}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.547619047619047, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.8809523809523, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.399582862854004}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.547619047619047, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.8809523809523, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3888945579528809}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53488372093023, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.0232558139535, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4019825458526611}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.545454545454547, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.2272727272727, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.390807867050171}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.545454545454547, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.2272727272727, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.3750154972076416}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.543478260869566, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.0652173913043, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4003069400787354}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.543478260869566, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.0652173913043, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.3932735919952393}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53191489361702, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1172.3617021276596, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3861281871795654}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.541666666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.8125, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3870177268981934}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.551020408163264, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.3469387755101, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.3847408294677734}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.88, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3949222564697266}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.529411764705884, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.6274509803923, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.3839707374572754}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51923076923077, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.4807692307693, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.3853819370269775}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51923076923077, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.4807692307693, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.3931596279144287}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51851851851852, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.648148148148, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3932709693908691}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.527272727272727, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.4545454545455, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.397590160369873}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.527272727272727, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.4545454545455, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.3721461296081543}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.527272727272727, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.4545454545455, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.3861303329467773}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.551724137931036, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1168.7931034482758, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.422755479812622}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.559322033898304, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.2372881355932, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4052040576934814}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.559322033898304, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.2372881355932, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3722350597381592}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.559322033898304, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.2372881355932, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4058780670166016}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.580645161290324, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.3387096774193, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4363129138946533}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58730158730159, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1165.3174603174602, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3801703453063965}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58730158730159, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1165.3174603174602, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.387498378753662}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58730158730159, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1165.3174603174602, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.3756160736083984}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58730158730159, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1165.3174603174602, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4010121822357178}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59090909090909, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.2272727272727, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4011592864990234}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597014925373134, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.7014925373135, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3864631652832031}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597014925373134, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.7014925373135, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3718972206115723}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597014925373134, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.7014925373135, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4189181327819824}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.857142857143, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4813082218170166}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.591549295774648, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.7605633802816, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.412954330444336}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.591549295774648, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.7605633802816, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.3966214656829834}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.591549295774648, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.7605633802816, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3744747638702393}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.575342465753426, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.3972602739725, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4181783199310303}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58108108108108, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.581081081081, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.3730263710021973}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.586666666666666, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.9466666666667, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4003729820251465}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.586666666666666, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.9466666666667, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.3867785930633545}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.592105263157894, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.078947368421, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3894538879394531}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5974025974026, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.8311688311687, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4037115573883057}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.60759493670886, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.8481012658228, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4111428260803223}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.60759493670886, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.8481012658228, \"learn_time_ms\": 4.573, \"total_train_time_s\": 1.3876826763153076}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.60759493670886, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.8481012658228, \"learn_time_ms\": 4.214, \"total_train_time_s\": 1.3664953708648682}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.5125, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.3795654773712158}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.602409638554217, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.7228915662652, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4195334911346436}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.602409638554217, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.7228915662652, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3809082508087158}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.602409638554217, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.7228915662652, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3669519424438477}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.595238095238095, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.1785714285713, \"learn_time_ms\": 4.211, \"total_train_time_s\": 1.3843581676483154}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.4823529411765, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.390634536743164}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597701149425287, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.4942528735633, \"learn_time_ms\": 4.242, \"total_train_time_s\": 1.415494680404663}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597701149425287, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.4942528735633, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.391242504119873}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597701149425287, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.4942528735633, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4056861400604248}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.602272727272727, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.9886363636363, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.394641399383545}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.0, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4172828197479248}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.0, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4280967712402344}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.604395604395606, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.142857142857, \"learn_time_ms\": 4.215, \"total_train_time_s\": 1.4161388874053955}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.597826086956523, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.4130434782608, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.401193380355835}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.602150537634408, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.9569892473119, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.3915607929229736}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.595744680851062, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.287234042553, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.3861029148101807}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.589473684210525, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.6631578947367, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.395009994506836}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59375, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.9791666666667, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4033544063568115}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59375, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.9791666666667, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4043066501617432}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.591836734693878, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.9795918367347, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4015748500823975}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.591836734693878, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.9795918367347, \"learn_time_ms\": 4.211, \"total_train_time_s\": 1.388139009475708}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.585858585858585, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.888888888889, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.3912041187286377}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.585858585858585, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.888888888889, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.374114751815796}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.06, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.41062593460083}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.86, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.403473138809204}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1161.86, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.3988227844238281}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.49, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3958740234375}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.97, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.3914425373077393}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.47, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.3791563510894775}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.47, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.38181471824646}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.98, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4134037494659424}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.66, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.3983044624328613}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.72, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.402531385421753}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.29, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.386336088180542}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.29, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.385991096496582}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.12, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4019975662231445}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.98, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.3888797760009766}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.98, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.3806161880493164}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.34, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.402876377105713}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.34, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.382392406463623}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.62, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3937904834747314}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.62, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.42665696144104}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1160.4, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.3969566822052002}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1161.73, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.393329381942749}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1164.45, \"learn_time_ms\": 4.549, \"total_train_time_s\": 1.4144208431243896}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1164.45, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4003000259399414}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1167.24, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3847336769104004}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1167.91, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4369637966156006}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.04, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3938555717468262}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.18, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.41579270362854}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.18, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.3708741664886475}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1171.97, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.3994455337524414}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1174.02, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4267466068267822}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1173.24, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4207227230072021}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1173.24, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4083609580993652}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1173.24, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.3840112686157227}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1173.92, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4095540046691895}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1171.88, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4093289375305176}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1171.61, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3895668983459473}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1171.61, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.445314645767212}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.82, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.3995280265808105}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.82, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.3947865962982178}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1178.16, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4393703937530518}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1178.16, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3720588684082031}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.39, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4138619899749756}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.39, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.3987033367156982}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.39, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.3911635875701904}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1178.25, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4255614280700684}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1178.59, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4038708209991455}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.06, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3871443271636963}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.06, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.3932578563690186}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.06, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.3970611095428467}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.29, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.415029764175415}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.29, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.3589413166046143}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.37, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4036107063293457}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.37, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.3945775032043457}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.69, \"learn_time_ms\": 4.228, \"total_train_time_s\": 1.395456314086914}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.4, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4000418186187744}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.4, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4063808917999268}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.1, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4158833026885986}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.1, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3968780040740967}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.34, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4160780906677246}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1188.18, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4144353866577148}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.29, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4010145664215088}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.29, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.378129482269287}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.29, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.388319730758667}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.07, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.5054516792297363}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.07, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3846099376678467}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.56, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.415924072265625}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.56, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.37984299659729}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.13, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.3860664367675781}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.71, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3935163021087646}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.0, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4112458229064941}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.0, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4136693477630615}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.0, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4010341167449951}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.21, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.449556827545166}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.85, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3927528858184814}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.85, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3824448585510254}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.85, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.3762366771697998}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.61, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4217593669891357}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.46, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4325249195098877}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.46, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4173603057861328}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.46, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4203333854675293}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.08, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4096107482910156}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.45, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4207653999328613}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.75, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4112114906311035}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.75, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.3797962665557861}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.75, \"learn_time_ms\": 4.236, \"total_train_time_s\": 1.3864142894744873}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.3, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4255154132843018}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.67, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4330956935882568}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.67, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3929569721221924}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.67, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.38999342918396}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1197.13, \"learn_time_ms\": 4.51, \"total_train_time_s\": 1.4134125709533691}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.65, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4358201026916504}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.65, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3794867992401123}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.65, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.3985331058502197}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1197.57, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3972539901733398}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1193.92, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4314961433410645}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1193.92, \"learn_time_ms\": 4.546, \"total_train_time_s\": 1.4208152294158936}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1193.92, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4011034965515137}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1193.92, \"learn_time_ms\": 4.243, \"total_train_time_s\": 1.382516622543335}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.64, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4631078243255615}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.64, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4127466678619385}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.64, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4260094165802002}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.64, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.412764549255371}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.69, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4978599548339844}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.29, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4410500526428223}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.29, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.3768222332000732}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.29, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.3726904392242432}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1183.76, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4666616916656494}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.03, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4124486446380615}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.03, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4206907749176025}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.03, \"learn_time_ms\": 4.592, \"total_train_time_s\": 1.3994324207305908}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.41, \"learn_time_ms\": 4.552, \"total_train_time_s\": 1.4258582592010498}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.41, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3695192337036133}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.41, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4058592319488525}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.41, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.3845784664154053}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1166.94, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4528319835662842}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1166.94, \"learn_time_ms\": 4.245, \"total_train_time_s\": 1.3981764316558838}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1166.94, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4150893688201904}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1166.94, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4120128154754639}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1161.47, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.436500072479248}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1161.47, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.3810842037200928}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1161.47, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4027454853057861}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1161.47, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.3910925388336182}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.13, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.435605525970459}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.13, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3817415237426758}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.13, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.407033920288086}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.13, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.4142160415649414}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1140.02, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.451066493988037}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1140.02, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.3886775970458984}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1140.02, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4144001007080078}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1140.02, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3875067234039307}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1130.94, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4356365203857422}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1127.92, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4122381210327148}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1127.92, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.3941092491149902}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1127.92, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3858661651611328}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.87, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.416142225265503}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.32, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.434229850769043}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.32, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4067862033843994}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.32, \"learn_time_ms\": 4.16, \"total_train_time_s\": 1.385303258895874}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1114.93, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4278452396392822}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1112.65, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.3841633796691895}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1112.65, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.3926210403442383}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1112.65, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.413362741470337}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1108.18, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4371013641357422}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1108.18, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.3836910724639893}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1108.18, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4191930294036865}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1108.18, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3933415412902832}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1100.82, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4217841625213623}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1100.82, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.3983607292175293}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1100.82, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.3758265972137451}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1100.82, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3689396381378174}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1093.65, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4473838806152344}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1093.65, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4339730739593506}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1093.65, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.3802521228790283}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1093.65, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4204914569854736}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1084.29, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4406864643096924}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1082.46, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.421046495437622}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1082.46, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3884503841400146}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1082.46, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.3952765464782715}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1079.06, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.42299485206604}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1077.51, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4137792587280273}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1077.51, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4079322814941406}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1077.51, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.401256799697876}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1071.08, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4369385242462158}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1069.26, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4260215759277344}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1069.26, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4145188331604004}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1069.26, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3856525421142578}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1063.93, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.418997049331665}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.58, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4058256149291992}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.58, \"learn_time_ms\": 4.209, \"total_train_time_s\": 1.3972692489624023}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.58, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.3617794513702393}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.14, \"learn_time_ms\": 4.55, \"total_train_time_s\": 1.4455475807189941}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.14, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4991378784179688}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.14, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.424393653869629}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.14, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.3954215049743652}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.2, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4195318222045898}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.77, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.414590835571289}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.77, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4090075492858887}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.77, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.3743581771850586}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.33, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4573748111724854}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.91, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4264843463897705}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.91, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.5845017433166504}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.91, \"learn_time_ms\": 4.19, \"total_train_time_s\": 1.4061009883880615}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.24, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.442317247390747}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.59, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4232754707336426}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.59, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4602839946746826}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.59, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4623615741729736}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.25, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4517168998718262}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.06, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4319210052490234}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.06, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4020400047302246}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.06, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.3945074081420898}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4454727172851562}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.05, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3874716758728027}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.05, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.3813817501068115}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.05, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4251329898834229}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4560973644256592}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.3888239860534668}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.431190013885498}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.378429889678955}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4345338344573975}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.40977144241333}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4156172275543213}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.3911993503570557}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4508147239685059}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.3983681201934814}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3943138122558594}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4168808460235596}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4472460746765137}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.404322862625122}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.236, \"total_train_time_s\": 1.4007971286773682}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.3945159912109375}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.425532579421997}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.3780760765075684}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4052925109863281}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4164929389953613}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.21, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4369182586669922}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.21, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4160449504852295}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.21, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4232115745544434}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.21, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4104602336883545}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.86, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4406623840332031}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.86, \"learn_time_ms\": 4.233, \"total_train_time_s\": 1.401686191558838}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.86, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.3897032737731934}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.86, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.3874704837799072}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.37, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4296908378601074}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.37, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4251010417938232}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.37, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.388739824295044}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.37, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.3895137310028076}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.36, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4536728858947754}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.36, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3961312770843506}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.36, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.3764674663543701}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.36, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.4028174877166748}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.24, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.426349401473999}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.24, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.381134033203125}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.24, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4127638339996338}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.24, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4194984436035156}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.14, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4616894721984863}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.14, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4294071197509766}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.14, \"learn_time_ms\": 4.235, \"total_train_time_s\": 1.3950297832489014}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.14, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4037063121795654}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.94, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4564704895019531}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.94, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.3981375694274902}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.94, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3807744979858398}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.94, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.415649175643921}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.68, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.495323657989502}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.59, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4323666095733643}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.59, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.3928401470184326}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.59, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4086158275604248}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.04, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4745137691497803}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.51, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4070444107055664}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.51, \"learn_time_ms\": 4.209, \"total_train_time_s\": 1.4018845558166504}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.51, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.5059130191802979}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.12, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4214167594909668}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4243996143341064}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.3800296783447266}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.369917392730713}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.410102367401123}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4370670318603516}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.385967493057251}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.389103651046753}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4625310897827148}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.6, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4238696098327637}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.48, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4045166969299316}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.48, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4195055961608887}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.38, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.424194097518921}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.49, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4537951946258545}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.87, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.423717737197876}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.87, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.406151533126831}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4449152946472168}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.420438528060913}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4071459770202637}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.395172357559204}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4437954425811768}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.3950233459472656}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4100935459136963}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4133358001708984}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4065563678741455}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.4205811023712158}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4017343521118164}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.410933494567871}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.66, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.424631118774414}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.29, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3921818733215332}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4035024642944336}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.3934667110443115}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4268009662628174}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4289255142211914}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.2, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4107179641723633}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.2, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.3889403343200684}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.15, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4294495582580566}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.11, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4339351654052734}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.26, \"learn_time_ms\": 4.517, \"total_train_time_s\": 1.4130587577819824}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.26, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.3915033340454102}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4097051620483398}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.03, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4345736503601074}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.95, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4112434387207031}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.95, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.427644968032837}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.415369987487793}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4285409450531006}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.4187641143798828}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4181029796600342}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.454003095626831}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.01, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.413379192352295}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.664975881576538}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.4084479808807373}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4083728790283203}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.7, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4323794841766357}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4216511249542236}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.3965904712677002}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.47, \"learn_time_ms\": 4.581, \"total_train_time_s\": 1.4369215965270996}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4166150093078613}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.3899896144866943}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3990898132324219}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.7, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4110896587371826}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4366493225097656}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.79, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3914823532104492}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.79, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4322490692138672}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.01, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.418215274810791}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.06, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4351751804351807}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.3739726543426514}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.400071620941162}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.0, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4335131645202637}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4127228260040283}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.13, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.3931853771209717}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.13, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.397735357284546}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.33, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4375760555267334}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.33, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.379183292388916}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.429473638534546}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.3809597492218018}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.1, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4335269927978516}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.1, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4063396453857422}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.0, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.399176836013794}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.0, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4103350639343262}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.83, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4450185298919678}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.83, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.4055395126342773}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.58, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3906395435333252}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.58, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.4180877208709717}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4024643898010254}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.413637399673462}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.402928352355957}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4071767330169678}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.25, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4303815364837646}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.25, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.3919405937194824}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4187915325164795}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4043340682983398}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4394772052764893}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.41957426071167}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4045794010162354}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.231, \"total_train_time_s\": 1.397127628326416}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.76, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4157891273498535}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.76, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4031338691711426}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.214, \"total_train_time_s\": 1.405897617340088}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.3996946811676025}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.91, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4212870597839355}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.91, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3977770805358887}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4190735816955566}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4166553020477295}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.0, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4238801002502441}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.0, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4164817333221436}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4117789268493652}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.383167028427124}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.92, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.434894323348999}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.92, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3860821723937988}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.458921194076538}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4097425937652588}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4250431060791016}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4045968055725098}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3973071575164795}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.53, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4107515811920166}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.46, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4120802879333496}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4085896015167236}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4074900150299072}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4478237628936768}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.99, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4043056964874268}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.79, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4150960445404053}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.79, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.389463186264038}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.3908963203430176}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.1, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.421433925628662}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.03, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4014427661895752}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.03, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4147274494171143}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.86, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4039278030395508}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4289393424987793}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4163541793823242}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4090778827667236}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.73, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4375367164611816}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.417792558670044}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.59, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.401456356048584}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.59, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.389125108718872}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4240739345550537}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4041781425476074}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4562351703643799}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4062998294830322}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.405118465423584}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.3750483989715576}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4339990615844727}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.381051778793335}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4238128662109375}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4030976295471191}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.21, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4032220840454102}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.11, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4235897064208984}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.401808738708496}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4090490341186523}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.31, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.4183895587921143}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.31, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3907012939453125}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.411886215209961}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.397373914718628}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4388353824615479}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4016845226287842}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4129998683929443}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.63, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4092893600463867}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4500455856323242}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.394258737564087}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4088268280029297}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.392463207244873}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.48, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4127686023712158}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.48, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4039313793182373}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.48, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3996379375457764}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.32, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4327988624572754}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4073283672332764}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4191832542419434}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.3913516998291016}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.2, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4280409812927246}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.94, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4097974300384521}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.94, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.3961505889892578}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.94, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4059205055236816}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.9, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4463250637054443}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.81, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.5050334930419922}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.81, \"learn_time_ms\": 4.217, \"total_train_time_s\": 1.3883063793182373}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.81, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3862805366516113}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.69, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.426436424255371}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.98, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4369268417358398}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.98, \"learn_time_ms\": 4.229, \"total_train_time_s\": 1.3986310958862305}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.98, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4062788486480713}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.27, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4311540126800537}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.65, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.436051607131958}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.65, \"learn_time_ms\": 4.196, \"total_train_time_s\": 1.4002807140350342}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.65, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4133219718933105}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.83, \"learn_time_ms\": 4.225, \"total_train_time_s\": 1.3871169090270996}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4346094131469727}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4122846126556396}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3833045959472656}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.17, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.381913185119629}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.3, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.419870138168335}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3957722187042236}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.396864652633667}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4009616374969482}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.87, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4060568809509277}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4218008518218994}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.522, \"total_train_time_s\": 1.414076328277588}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.34, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.3975942134857178}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4284687042236328}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3892512321472168}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4026737213134766}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.49, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4017369747161865}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.53, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4412691593170166}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.53, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4217443466186523}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.53, \"learn_time_ms\": 4.221, \"total_train_time_s\": 1.400883674621582}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4069123268127441}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.58, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4212696552276611}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.58, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.391740322113037}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.58, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.399627923965454}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.57, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4216535091400146}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.57, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.415555715560913}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.67, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4084620475769043}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.67, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4086213111877441}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.6, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4297099113464355}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.4360792636871338}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.41133713722229}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4070203304290771}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.393949031829834}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.95, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4102797508239746}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4176788330078125}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4200432300567627}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.9, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4229366779327393}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.62, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4035205841064453}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.521, \"total_train_time_s\": 1.4151279926300049}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.402073860168457}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4022796154022217}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4336743354797363}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4117989540100098}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4243769645690918}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.95, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4355103969573975}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.31, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4159235954284668}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.54, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.408416748046875}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.54, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4316086769104004}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.58, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4152135848999023}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.58, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.3852362632751465}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.92, \"learn_time_ms\": 4.222, \"total_train_time_s\": 1.4116573333740234}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.92, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4097638130187988}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.05, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4326255321502686}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.93, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3905186653137207}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.88, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4035427570343018}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.88, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4054710865020752}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3963932991027832}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4117844104766846}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4216530323028564}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.416459321975708}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4319241046905518}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4034538269042969}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4399824142456055}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.415687084197998}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.3776161670684814}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.412590742111206}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4377381801605225}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4183893203735352}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.430994987487793}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4185411930084229}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.45, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4249072074890137}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.45, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4059417247772217}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4094057083129883}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.4, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4295251369476318}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.11, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.423964500427246}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.11, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4238026142120361}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.13, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4023633003234863}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.14, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.3893678188323975}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4219839572906494}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3885836601257324}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4242887496948242}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.46, \"learn_time_ms\": 4.593, \"total_train_time_s\": 1.4285693168640137}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.403183937072754}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4209134578704834}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.68, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.399533748626709}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.84, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.424360752105713}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4189281463623047}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.430776596069336}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.407947063446045}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.544, \"total_train_time_s\": 1.4366207122802734}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4238646030426025}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.06, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4225363731384277}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4288289546966553}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4083681106567383}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.427539348602295}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4158363342285156}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.32, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4352569580078125}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.32, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4968483448028564}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.18, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.3956613540649414}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.98, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4271211624145508}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4202666282653809}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4035959243774414}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4360566139221191}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.406203031539917}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.78, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4038951396942139}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.78, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3903388977050781}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.456611156463623}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.73, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.3912334442138672}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4027400016784668}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4010107517242432}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4040989875793457}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.36, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4236481189727783}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.58, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.3959412574768066}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.58, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.3945996761322021}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.5, \"learn_time_ms\": 4.215, \"total_train_time_s\": 1.419646978378296}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.465132713317871}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4140663146972656}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.393458366394043}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.1, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4176852703094482}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.12, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4559578895568848}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4211704730987549}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.3846511840820312}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.73, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3942108154296875}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.431865930557251}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.6, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.407045841217041}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.6, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4056618213653564}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.56, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4138336181640625}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.77, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4320013523101807}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.7, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4014666080474854}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.7, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4165267944335938}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4213166236877441}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.4, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4384312629699707}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4341533184051514}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4251930713653564}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.24, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4129788875579834}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.18, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4283795356750488}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4280781745910645}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.371107816696167}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.0, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4085934162139893}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.96, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.4168422222137451}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.13, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4118998050689697}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.13, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4334020614624023}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4337308406829834}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4336118698120117}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.34, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4436094760894775}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.34, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4312489032745361}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.95, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.47869873046875}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.15, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4756755828857422}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4358901977539062}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.237, \"total_train_time_s\": 1.401454210281372}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.76, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4354214668273926}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4549462795257568}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.54, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4151225090026855}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.54, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.3820481300354004}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.5, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.3975296020507812}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.15, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4154038429260254}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.47, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.385918378829956}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.47, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4065887928009033}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4186615943908691}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.420734167098999}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4088270664215088}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.3964409828186035}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4225945472717285}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.59, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4398138523101807}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.42, \"learn_time_ms\": 4.169, \"total_train_time_s\": 1.4222593307495117}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.42, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4067094326019287}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4086363315582275}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.52, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.420531988143921}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3941473960876465}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4227252006530762}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.398012399673462}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.192, \"total_train_time_s\": 1.424311876296997}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.32, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4236464500427246}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.32, \"learn_time_ms\": 4.225, \"total_train_time_s\": 1.3955714702606201}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4071240425109863}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4193143844604492}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.56, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4353954792022705}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.56, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4110565185546875}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.58, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4147326946258545}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.13, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4433484077453613}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.99, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4278523921966553}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.99, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4323601722717285}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.0, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.429593801498413}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.89, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.390730619430542}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.76, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4074018001556396}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.76, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4006030559539795}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.87, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4443111419677734}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.59, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4426898956298828}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4205994606018066}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4285690784454346}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4153985977172852}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.438770055770874}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.83, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4042820930480957}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.83, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.3960890769958496}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.74, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.3956146240234375}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.54, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4170222282409668}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.48, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4537010192871094}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.48, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4009697437286377}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.48, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.3999443054199219}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.66, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4293386936187744}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.35, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4328224658966064}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.35, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.3992018699645996}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.35, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4089529514312744}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.17, \"learn_time_ms\": 4.216, \"total_train_time_s\": 1.4303324222564697}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.29, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4295625686645508}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.29, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.5150609016418457}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.29, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.3936405181884766}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.71, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4248356819152832}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4151484966278076}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3932230472564697}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.395005226135254}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4346837997436523}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.245, \"total_train_time_s\": 1.3995230197906494}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.401099443435669}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.412811517715454}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.15, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4002208709716797}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4159095287322998}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4147653579711914}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.35, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.407344102859497}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.37, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4309031963348389}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4338183403015137}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.422447919845581}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4487433433532715}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.32, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4550495147705078}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.22, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4535412788391113}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.22, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.413715124130249}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4101321697235107}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.433098554611206}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.4054269790649414}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4069695472717285}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4138951301574707}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.15, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4085264205932617}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.11, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4450278282165527}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.11, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.404836893081665}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.31, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.402461290359497}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4160175323486328}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4088754653930664}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4088304042816162}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4136900901794434}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.59, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3962371349334717}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.69, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4207608699798584}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.69, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4279139041900635}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.99, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3995683193206787}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.13, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.398144245147705}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.14, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.404435634613037}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.3828115463256836}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.55, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4020054340362549}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.19, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4030752182006836}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4118046760559082}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.07, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4373424053192139}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.05, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4417636394500732}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.08, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4229373931884766}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4132211208343506}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.4411208629608154}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.44, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4190406799316406}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.43, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4147999286651611}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4282474517822266}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.3961725234985352}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4061906337738037}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.3, \"learn_time_ms\": 4.194, \"total_train_time_s\": 1.4291470050811768}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4314141273498535}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.39, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4188554286956787}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4255177974700928}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4315598011016846}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4186489582061768}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.56, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.458735704421997}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.61, \"learn_time_ms\": 4.212, \"total_train_time_s\": 1.408200979232788}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.57, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3943204879760742}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.66, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4274649620056152}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.63, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.401564598083496}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.61, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.415351390838623}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4190850257873535}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.408046007156372}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.74, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.422306776046753}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.67, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4091839790344238}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4048891067504883}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.82, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4007532596588135}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4245336055755615}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.3878757953643799}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.59, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4238946437835693}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.94, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4040236473083496}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.98, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4498178958892822}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.417966604232788}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.91, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4126245975494385}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4030985832214355}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.27, \"learn_time_ms\": 4.236, \"total_train_time_s\": 1.3953642845153809}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4026968479156494}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.38, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.416813611984253}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.32, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4115440845489502}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.3870172500610352}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.6745920181274414}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4082114696502686}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4011943340301514}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.3958940505981445}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4223065376281738}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.94, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4267747402191162}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.95, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4220950603485107}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.76, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4096949100494385}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.62, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4030406475067139}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.53, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4080455303192139}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.61, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4135160446166992}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.73, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4266564846038818}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4039463996887207}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4102723598480225}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4122602939605713}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4276375770568848}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.85, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4478530883789062}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4143364429473877}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.66, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.412839651107788}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.73, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.420867681503296}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.35, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4027953147888184}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.45, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4277384281158447}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.66, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.419196367263794}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.73, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4115087985992432}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.66, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4026737213134766}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4175589084625244}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.73, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.3921222686767578}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.13, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4102721214294434}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.0, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4001331329345703}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.0, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.3899602890014648}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.37, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4282193183898926}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.4, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4055454730987549}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.3912441730499268}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4215881824493408}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.13, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4382708072662354}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.39, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4175479412078857}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4232988357543945}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.3843061923980713}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.414912223815918}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.74, \"learn_time_ms\": 4.25, \"total_train_time_s\": 1.3917210102081299}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4249694347381592}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4073400497436523}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4245071411132812}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.406430721282959}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.84, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.395174264907837}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.84, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3970613479614258}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4416353702545166}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.96, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4302866458892822}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4159634113311768}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4128928184509277}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4273147583007812}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.49, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3852639198303223}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.19, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4212629795074463}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.98, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4469077587127686}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.420396327972412}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.5, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.406559944152832}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.68, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.3938179016113281}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4400184154510498}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4193611145019531}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.09, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4195079803466797}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.01, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.3994026184082031}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.54, \"total_train_time_s\": 1.444563388824463}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4157013893127441}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.06, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.3921785354614258}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.98, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4068667888641357}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.21, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4341399669647217}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 4.236, \"total_train_time_s\": 1.4134700298309326}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.58, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.411496639251709}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.63, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4378273487091064}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.77, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.41856050491333}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.71, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4171462059020996}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4091823101043701}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4138810634613037}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4262425899505615}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.448023796081543}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.75, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4377710819244385}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4293241500854492}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.556, \"total_train_time_s\": 1.4110233783721924}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.0, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.417497158050537}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.98, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.446483850479126}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.411649465560913}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.3886973857879639}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.8, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4148259162902832}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.69, \"learn_time_ms\": 4.549, \"total_train_time_s\": 1.425616979598999}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.413499355316162}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.409120798110962}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.95, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4134738445281982}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.1, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.413085699081421}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4224615097045898}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3962571620941162}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.38, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4162423610687256}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4157264232635498}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.61, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4339179992675781}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.61, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.388732671737671}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.54, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4133455753326416}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.427140712738037}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4420990943908691}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.41859769821167}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4163527488708496}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4075913429260254}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.29, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4272422790527344}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.29, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4125325679779053}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4428489208221436}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4035768508911133}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.35, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4344258308410645}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.35, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4138908386230469}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4555821418762207}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4211726188659668}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4351181983947754}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4083795547485352}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4267652034759521}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.529, \"total_train_time_s\": 1.4313490390777588}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.73, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4301865100860596}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.73, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4060149192810059}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.406956434249878}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4284272193908691}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.18, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.436415672302246}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.18, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3808095455169678}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.19, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.424771785736084}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4308032989501953}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.75, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.39615797996521}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.75, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4293782711029053}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.67, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.429990291595459}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.95, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4239630699157715}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.98, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.526280403137207}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.98, \"learn_time_ms\": 4.521, \"total_train_time_s\": 1.4042119979858398}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.86, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.418691873550415}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.98, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4142115116119385}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.62, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.3981239795684814}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.62, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.407435655593872}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.57, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4452784061431885}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.49, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.417893409729004}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.59, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.438115119934082}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.88, \"learn_time_ms\": 4.243, \"total_train_time_s\": 1.4237313270568848}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.48, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4091417789459229}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.06, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.431159496307373}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.86, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4338600635528564}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4464387893676758}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.64, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4337708950042725}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4272964000701904}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.02, \"learn_time_ms\": 4.832, \"total_train_time_s\": 1.4454560279846191}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.03, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4406931400299072}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.03, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.400557279586792}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.97, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4348692893981934}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.04, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.418229341506958}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4208683967590332}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.358837366104126}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4235343933105469}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4196434020996094}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4153542518615723}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4136497974395752}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.421570062637329}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4582831859588623}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.96, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4235424995422363}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.96, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.38681960105896}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.99, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.412989854812622}", "{\"n\": 1001, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4182002544403076}", "{\"n\": 1002, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4408843517303467}", "{\"n\": 1003, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.372220516204834}", "{\"n\": 1004, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.09, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.407594919204712}", "{\"n\": 1005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4364643096923828}", "{\"n\": 1006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.69, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.40472412109375}", "{\"n\": 1007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.69, \"learn_time_ms\": 4.516, \"total_train_time_s\": 1.4363348484039307}", "{\"n\": 1008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.82, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3818438053131104}", "{\"n\": 1009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4338622093200684}", "{\"n\": 1010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.3931143283843994}", "{\"n\": 1011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.7, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.410996437072754}", "{\"n\": 1012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.55, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4359376430511475}", "{\"n\": 1013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.87, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4141533374786377}", "{\"n\": 1014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.87, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4279563426971436}", "{\"n\": 1015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.86, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.422070026397705}", "{\"n\": 1016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.48, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4314022064208984}", "{\"n\": 1017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.62, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4334805011749268}", "{\"n\": 1018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.62, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4227654933929443}", "{\"n\": 1019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.38, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.404306411743164}", "{\"n\": 1020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.1, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4498827457427979}", "{\"n\": 1021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.07, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4521441459655762}", "{\"n\": 1022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.07, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.389535903930664}", "{\"n\": 1023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4581782817840576}", "{\"n\": 1024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.08, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.418820858001709}", "{\"n\": 1025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4187953472137451}", "{\"n\": 1026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.406670331954956}", "{\"n\": 1027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.33, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.421499252319336}", "{\"n\": 1028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.32, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4323596954345703}", "{\"n\": 1029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4088771343231201}", "{\"n\": 1030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.31, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.41377854347229}", "{\"n\": 1031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.31, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4157373905181885}", "{\"n\": 1032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.02, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4397594928741455}", "{\"n\": 1033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.66, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4263496398925781}", "{\"n\": 1034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4427833557128906}", "{\"n\": 1035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4019110202789307}", "{\"n\": 1036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.51, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4269695281982422}", "{\"n\": 1037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.53, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.414926528930664}", "{\"n\": 1038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.31, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4338481426239014}", "{\"n\": 1039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.31, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4070587158203125}", "{\"n\": 1040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.24, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4164648056030273}", "{\"n\": 1041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.28, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4095525741577148}", "{\"n\": 1042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4120566844940186}", "{\"n\": 1043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.415252685546875}", "{\"n\": 1044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.61, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.422476053237915}", "{\"n\": 1045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.3974578380584717}", "{\"n\": 1046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.59, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.3893799781799316}", "{\"n\": 1047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.59, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4304752349853516}", "{\"n\": 1048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.435753345489502}", "{\"n\": 1049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.95, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4063756465911865}", "{\"n\": 1050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.09, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4157214164733887}", "{\"n\": 1051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.09, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4328372478485107}", "{\"n\": 1052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.96, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.396977186203003}", "{\"n\": 1053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.0, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4313080310821533}", "{\"n\": 1054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.19, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4125597476959229}", "{\"n\": 1055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.19, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.420562505722046}", "{\"n\": 1056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.11, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4065930843353271}", "{\"n\": 1057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.27, \"learn_time_ms\": 4.512, \"total_train_time_s\": 1.4082179069519043}", "{\"n\": 1058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.4265658855438232}", "{\"n\": 1059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.403893232345581}", "{\"n\": 1060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4026944637298584}", "{\"n\": 1061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.96, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4413490295410156}", "{\"n\": 1062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4066851139068604}", "{\"n\": 1063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4121019840240479}", "{\"n\": 1064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4088847637176514}", "{\"n\": 1065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.76, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4079041481018066}", "{\"n\": 1066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.3972694873809814}", "{\"n\": 1067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3950448036193848}", "{\"n\": 1068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4168531894683838}", "{\"n\": 1069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4107356071472168}", "{\"n\": 1070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.06, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4254944324493408}", "{\"n\": 1071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.06, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.3811118602752686}", "{\"n\": 1072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.02, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4307496547698975}", "{\"n\": 1073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.88, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4202337265014648}", "{\"n\": 1074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.88, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4220802783966064}", "{\"n\": 1075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.19, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4092330932617188}", "{\"n\": 1076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.01, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.414994478225708}", "{\"n\": 1077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.5696711540222168}", "{\"n\": 1078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3882007598876953}", "{\"n\": 1079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.62, \"learn_time_ms\": 4.562, \"total_train_time_s\": 1.405144453048706}", "{\"n\": 1080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.61, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4079108238220215}", "{\"n\": 1081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.39, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4200811386108398}", "{\"n\": 1082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.39, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.424164056777954}", "{\"n\": 1083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.88, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4203534126281738}", "{\"n\": 1084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.3995373249053955}", "{\"n\": 1085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.04, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4484035968780518}", "{\"n\": 1086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.04, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4112179279327393}", "{\"n\": 1087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.19, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4262375831604004}", "{\"n\": 1088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.34, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4287545680999756}", "{\"n\": 1089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.01, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.429765224456787}", "{\"n\": 1090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.01, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.419396162033081}", "{\"n\": 1091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.05, \"learn_time_ms\": 4.502, \"total_train_time_s\": 1.404585599899292}", "{\"n\": 1092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.07, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.407768726348877}", "{\"n\": 1093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.74, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4206912517547607}", "{\"n\": 1094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.74, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.3843622207641602}", "{\"n\": 1095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4524955749511719}", "{\"n\": 1096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.59, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3967068195343018}", "{\"n\": 1097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.24, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.40775728225708}", "{\"n\": 1098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.24, \"learn_time_ms\": 4.239, \"total_train_time_s\": 1.4123055934906006}", "{\"n\": 1099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.24, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.3977887630462646}", "{\"n\": 1100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.25, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.433140516281128}", "{\"n\": 1101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.15, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4200589656829834}", "{\"n\": 1102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.26, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4281508922576904}", "{\"n\": 1103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.32, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4298298358917236}", "{\"n\": 1104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.31, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4024789333343506}", "{\"n\": 1105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.38, \"learn_time_ms\": 4.512, \"total_train_time_s\": 1.4121086597442627}", "{\"n\": 1106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.37, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4001355171203613}", "{\"n\": 1107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4226422309875488}", "{\"n\": 1108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4216859340667725}", "{\"n\": 1109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.6, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.405045509338379}", "{\"n\": 1110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.412031888961792}", "{\"n\": 1111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4133069515228271}", "{\"n\": 1112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.409271240234375}", "{\"n\": 1113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.89, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.443068027496338}", "{\"n\": 1114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.94, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4277901649475098}", "{\"n\": 1115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4486572742462158}", "{\"n\": 1116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.21, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.3970303535461426}", "{\"n\": 1117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.31, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4419856071472168}", "{\"n\": 1118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.39, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.4325270652770996}", "{\"n\": 1119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.26, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.4133710861206055}", "{\"n\": 1120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.26, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4439067840576172}", "{\"n\": 1121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.36, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4419691562652588}", "{\"n\": 1122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4376204013824463}", "{\"n\": 1123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3847055435180664}", "{\"n\": 1124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.3871567249298096}", "{\"n\": 1125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4421501159667969}", "{\"n\": 1126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4288344383239746}", "{\"n\": 1127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.23, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3941748142242432}", "{\"n\": 1128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.23, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4059746265411377}", "{\"n\": 1129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.23, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4126636981964111}", "{\"n\": 1130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.45, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4489786624908447}", "{\"n\": 1131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.205, \"total_train_time_s\": 1.4191107749938965}", "{\"n\": 1132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4139373302459717}", "{\"n\": 1133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.408165693283081}", "{\"n\": 1134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.94, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4218626022338867}", "{\"n\": 1135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4093124866485596}", "{\"n\": 1136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.3613998889923096}", "{\"n\": 1137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4419541358947754}", "{\"n\": 1138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4284069538116455}", "{\"n\": 1139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.8, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4084501266479492}", "{\"n\": 1140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.8, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4189271926879883}", "{\"n\": 1141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.85, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4033358097076416}", "{\"n\": 1142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.81, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4343554973602295}", "{\"n\": 1143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.72, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4079687595367432}", "{\"n\": 1144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.57, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4084572792053223}", "{\"n\": 1145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.64, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4265625476837158}", "{\"n\": 1146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4037790298461914}", "{\"n\": 1147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.37, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4219591617584229}", "{\"n\": 1148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.37, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.409388542175293}", "{\"n\": 1149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.97, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4610860347747803}", "{\"n\": 1150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.93, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4052119255065918}", "{\"n\": 1151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.77, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4382104873657227}", "{\"n\": 1152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.77, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.3936781883239746}", "{\"n\": 1153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.86, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4066171646118164}", "{\"n\": 1154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.63, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4192466735839844}", "{\"n\": 1155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.47, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.404426097869873}", "{\"n\": 1156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.47, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.393836498260498}", "{\"n\": 1157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.57, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4377164840698242}", "{\"n\": 1158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.54, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4402239322662354}", "{\"n\": 1159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4185709953308105}", "{\"n\": 1160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4110946655273438}", "{\"n\": 1161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.48, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4206740856170654}", "{\"n\": 1162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.47, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.3951830863952637}", "{\"n\": 1163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.57, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4807054996490479}", "{\"n\": 1164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.57, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.390615701675415}", "{\"n\": 1165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.57, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.3804442882537842}", "{\"n\": 1166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.66, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.416895866394043}", "{\"n\": 1167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4424552917480469}", "{\"n\": 1168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4136662483215332}", "{\"n\": 1169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4240005016326904}", "{\"n\": 1170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.34, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4090654850006104}", "{\"n\": 1171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4219903945922852}", "{\"n\": 1172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.3838560581207275}", "{\"n\": 1173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.54, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.3917746543884277}", "{\"n\": 1174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.3, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4201908111572266}", "{\"n\": 1175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.16, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4156131744384766}", "{\"n\": 1176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.16, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.41825270652771}", "{\"n\": 1177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.16, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.3919916152954102}", "{\"n\": 1178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.45, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4168694019317627}", "{\"n\": 1179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.24, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4406304359436035}", "{\"n\": 1180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.24, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4007203578948975}", "{\"n\": 1181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.31, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4062304496765137}", "{\"n\": 1182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.6, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.408308744430542}", "{\"n\": 1183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.6, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.435436725616455}", "{\"n\": 1184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.6, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4164235591888428}", "{\"n\": 1185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.38, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.518141508102417}", "{\"n\": 1186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.4151496887207031}", "{\"n\": 1187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.43, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4086148738861084}", "{\"n\": 1188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.43, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4150822162628174}", "{\"n\": 1189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.38, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4223973751068115}", "{\"n\": 1190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.415487289428711}", "{\"n\": 1191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.88, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4261870384216309}", "{\"n\": 1192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.88, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4282326698303223}", "{\"n\": 1193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.67, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.464061975479126}", "{\"n\": 1194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.86, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4200830459594727}", "{\"n\": 1195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.4204134941101074}", "{\"n\": 1196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.401728630065918}", "{\"n\": 1197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.65, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4166886806488037}", "{\"n\": 1198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4017987251281738}", "{\"n\": 1199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.57, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.418271541595459}", "{\"n\": 1200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.54, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4225115776062012}", "{\"n\": 1201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.69, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4240868091583252}", "{\"n\": 1202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.66, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4362568855285645}", "{\"n\": 1203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.47, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4499680995941162}", "{\"n\": 1204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.47, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4027435779571533}", "{\"n\": 1205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4318904876708984}", "{\"n\": 1206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4320042133331299}", "{\"n\": 1207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.53, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4212169647216797}", "{\"n\": 1208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.53, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.3893136978149414}", "{\"n\": 1209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.52, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.407280683517456}", "{\"n\": 1210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.51, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4060866832733154}", "{\"n\": 1211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.39, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4233131408691406}", "{\"n\": 1212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.39, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4171760082244873}", "{\"n\": 1213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.6, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.421987533569336}", "{\"n\": 1214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.39, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4275844097137451}", "{\"n\": 1215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.33, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.429009199142456}", "{\"n\": 1216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.33, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.3876073360443115}", "{\"n\": 1217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.37, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4236340522766113}", "{\"n\": 1218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.36, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.404569387435913}", "{\"n\": 1219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.12, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.3830101490020752}", "{\"n\": 1220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.12, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.401806354522705}", "{\"n\": 1221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.24, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4431343078613281}", "{\"n\": 1222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4060487747192383}", "{\"n\": 1223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4180657863616943}", "{\"n\": 1224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4090595245361328}", "{\"n\": 1225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.423288345336914}", "{\"n\": 1226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.408357858657837}", "{\"n\": 1227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4169747829437256}", "{\"n\": 1228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.4, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.433450698852539}", "{\"n\": 1229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.0, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.409395456314087}", "{\"n\": 1230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.04, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4437265396118164}", "{\"n\": 1231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.04, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3889577388763428}", "{\"n\": 1232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.49, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4133963584899902}", "{\"n\": 1233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.49, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.3960320949554443}", "{\"n\": 1234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.417043685913086}", "{\"n\": 1235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.3970820903778076}", "{\"n\": 1236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4266471862792969}", "{\"n\": 1237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.399580478668213}", "{\"n\": 1238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.84, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.415235996246338}", "{\"n\": 1239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.436023473739624}", "{\"n\": 1240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.82, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4197704792022705}", "{\"n\": 1241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.82, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4160161018371582}", "{\"n\": 1242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.87, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3988349437713623}", "{\"n\": 1243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.19, \"learn_time_ms\": 4.554, \"total_train_time_s\": 1.430363416671753}", "{\"n\": 1244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.15, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4006335735321045}", "{\"n\": 1245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.06, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4101481437683105}", "{\"n\": 1246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.07, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.3905344009399414}", "{\"n\": 1247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.03, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4081547260284424}", "{\"n\": 1248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.27, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.422743797302246}", "{\"n\": 1249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.95, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.4467072486877441}", "{\"n\": 1250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.95, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4098055362701416}", "{\"n\": 1251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.84, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.406275987625122}", "{\"n\": 1252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.398740291595459}", "{\"n\": 1253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.91, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4113516807556152}", "{\"n\": 1254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.91, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4217565059661865}", "{\"n\": 1255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4225852489471436}", "{\"n\": 1256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.04, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3927910327911377}", "{\"n\": 1257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.81, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4417166709899902}", "{\"n\": 1258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.81, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4140217304229736}", "{\"n\": 1259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.91, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.393157720565796}", "{\"n\": 1260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.85, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3933148384094238}", "{\"n\": 1261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.8, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.427262783050537}", "{\"n\": 1262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.83, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.3881151676177979}", "{\"n\": 1263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.83, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.400008201599121}", "{\"n\": 1264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.85, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4180686473846436}", "{\"n\": 1265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4396979808807373}", "{\"n\": 1266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.21, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4254443645477295}", "{\"n\": 1267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.21, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3932113647460938}", "{\"n\": 1268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.36, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.6607646942138672}", "{\"n\": 1269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.26, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4181022644042969}", "{\"n\": 1270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4054231643676758}", "{\"n\": 1271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.3984205722808838}", "{\"n\": 1272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.417576789855957}", "{\"n\": 1273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.79, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4360251426696777}", "{\"n\": 1274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.3993315696716309}", "{\"n\": 1275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.42134428024292}", "{\"n\": 1276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4298076629638672}", "{\"n\": 1277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.246, \"total_train_time_s\": 1.3858978748321533}", "{\"n\": 1278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4032995700836182}", "{\"n\": 1279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.383756399154663}", "{\"n\": 1280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.34, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.433152437210083}", "{\"n\": 1281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.27, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.413233757019043}", "{\"n\": 1282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.27, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.3877694606781006}", "{\"n\": 1283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.05, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.398273229598999}", "{\"n\": 1284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4292325973510742}", "{\"n\": 1285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4007656574249268}", "{\"n\": 1286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.04, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.420151710510254}", "{\"n\": 1287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.76, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4136583805084229}", "{\"n\": 1288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3841919898986816}", "{\"n\": 1289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.81, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4389572143554688}", "{\"n\": 1290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4363608360290527}", "{\"n\": 1291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4017720222473145}", "{\"n\": 1292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.3936083316802979}", "{\"n\": 1293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4291636943817139}", "{\"n\": 1294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.14, \"learn_time_ms\": 4.226, \"total_train_time_s\": 1.3998277187347412}", "{\"n\": 1295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.14, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4091804027557373}", "{\"n\": 1296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.69, \"learn_time_ms\": 4.2, \"total_train_time_s\": 1.3991799354553223}", "{\"n\": 1297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.0, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.410285234451294}", "{\"n\": 1298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.1, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.410459041595459}", "{\"n\": 1299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.1, \"learn_time_ms\": 4.522, \"total_train_time_s\": 1.418962001800537}", "{\"n\": 1300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.9, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4457030296325684}", "{\"n\": 1301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4184544086456299}", "{\"n\": 1302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.13, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4364533424377441}", "{\"n\": 1303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.13, \"learn_time_ms\": 4.538, \"total_train_time_s\": 1.4226658344268799}", "{\"n\": 1304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.02, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4116599559783936}", "{\"n\": 1305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.05, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4184463024139404}", "{\"n\": 1306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4459569454193115}", "{\"n\": 1307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.391200304031372}", "{\"n\": 1308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.99, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4022247791290283}", "{\"n\": 1309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4514992237091064}", "{\"n\": 1310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4359471797943115}", "{\"n\": 1311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4261162281036377}", "{\"n\": 1312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.99, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4315955638885498}", "{\"n\": 1313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.31, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.3894891738891602}", "{\"n\": 1314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.3986449241638184}", "{\"n\": 1315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4103386402130127}", "{\"n\": 1316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.18, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4124157428741455}", "{\"n\": 1317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.34, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4209098815917969}", "{\"n\": 1318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.2, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3972861766815186}", "{\"n\": 1319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.2, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4152755737304688}", "{\"n\": 1320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4392650127410889}", "{\"n\": 1321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.17, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4114456176757812}", "{\"n\": 1322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.429499626159668}", "{\"n\": 1323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4032235145568848}", "{\"n\": 1324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.15, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4112598896026611}", "{\"n\": 1325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.33, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4160990715026855}", "{\"n\": 1326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4063911437988281}", "{\"n\": 1327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4095618724822998}", "{\"n\": 1328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.412672758102417}", "{\"n\": 1329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.4, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.431002140045166}", "{\"n\": 1330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4098575115203857}", "{\"n\": 1331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4095511436462402}", "{\"n\": 1332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.39, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4027268886566162}", "{\"n\": 1333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.32, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.411454677581787}", "{\"n\": 1334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.23, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3884258270263672}", "{\"n\": 1335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.23, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.405254602432251}", "{\"n\": 1336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4313063621520996}", "{\"n\": 1337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.76, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4348170757293701}", "{\"n\": 1338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.426482915878296}", "{\"n\": 1339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.536, \"total_train_time_s\": 1.4099066257476807}", "{\"n\": 1340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.01, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4053454399108887}", "{\"n\": 1341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.31, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.428790807723999}", "{\"n\": 1342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.455320119857788}", "{\"n\": 1343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3930463790893555}", "{\"n\": 1344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.443511724472046}", "{\"n\": 1345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.3962721824645996}", "{\"n\": 1346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4206969738006592}", "{\"n\": 1347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.421053409576416}", "{\"n\": 1348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.53, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4560730457305908}", "{\"n\": 1349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.81, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.409316062927246}", "{\"n\": 1350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4191720485687256}", "{\"n\": 1351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.411182165145874}", "{\"n\": 1352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.414315938949585}", "{\"n\": 1353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4239325523376465}", "{\"n\": 1354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4149549007415771}", "{\"n\": 1355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3927619457244873}", "{\"n\": 1356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.82, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.43953537940979}", "{\"n\": 1357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.41550612449646}", "{\"n\": 1358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.89, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.400895118713379}", "{\"n\": 1359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.89, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3912005424499512}", "{\"n\": 1360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.436300277709961}", "{\"n\": 1361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.04, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3971476554870605}", "{\"n\": 1362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.3985199928283691}", "{\"n\": 1363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4078526496887207}", "{\"n\": 1364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4203076362609863}", "{\"n\": 1365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.1, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4654655456542969}", "{\"n\": 1366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.68, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.394505500793457}", "{\"n\": 1367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.68, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4102206230163574}", "{\"n\": 1368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4310784339904785}", "{\"n\": 1369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.75, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.3871731758117676}", "{\"n\": 1370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4146645069122314}", "{\"n\": 1371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4368252754211426}", "{\"n\": 1372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.430018424987793}", "{\"n\": 1373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.13, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4133808612823486}", "{\"n\": 1374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.426980972290039}", "{\"n\": 1375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4124207496643066}", "{\"n\": 1376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.32, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.408799171447754}", "{\"n\": 1377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.415839433670044}", "{\"n\": 1378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.3971304893493652}", "{\"n\": 1379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4064569473266602}", "{\"n\": 1380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4373526573181152}", "{\"n\": 1381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.420917272567749}", "{\"n\": 1382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4273195266723633}", "{\"n\": 1383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4386954307556152}", "{\"n\": 1384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4124829769134521}", "{\"n\": 1385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4155197143554688}", "{\"n\": 1386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.406867504119873}", "{\"n\": 1387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.403244972229004}", "{\"n\": 1388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.37, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.445371150970459}", "{\"n\": 1389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4073052406311035}", "{\"n\": 1390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3879785537719727}", "{\"n\": 1391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4401588439941406}", "{\"n\": 1392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.5030899047851562}", "{\"n\": 1393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.2, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4263184070587158}", "{\"n\": 1394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.15, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.395869255065918}", "{\"n\": 1395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.15, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.390371561050415}", "{\"n\": 1396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.27, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4255695343017578}", "{\"n\": 1397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4020092487335205}", "{\"n\": 1398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.36, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3866360187530518}", "{\"n\": 1399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.36, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4095709323883057}", "{\"n\": 1400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4277863502502441}", "{\"n\": 1401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.43, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4244842529296875}", "{\"n\": 1402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.47, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4119255542755127}", "{\"n\": 1403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.47, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.417253017425537}", "{\"n\": 1404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4074130058288574}", "{\"n\": 1405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.448810338973999}", "{\"n\": 1406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.98, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.414825201034546}", "{\"n\": 1407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.98, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4201991558074951}", "{\"n\": 1408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.94, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4101920127868652}", "{\"n\": 1409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.404822826385498}", "{\"n\": 1410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.81, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4162182807922363}", "{\"n\": 1411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.81, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.3871066570281982}", "{\"n\": 1412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4229764938354492}", "{\"n\": 1413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.40181565284729}", "{\"n\": 1414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.46, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.424368143081665}", "{\"n\": 1415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.46, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4157838821411133}", "{\"n\": 1416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4096131324768066}", "{\"n\": 1417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4190118312835693}", "{\"n\": 1418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.38, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4151837825775146}", "{\"n\": 1419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.38, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4357521533966064}", "{\"n\": 1420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4131171703338623}", "{\"n\": 1421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.45, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4357359409332275}", "{\"n\": 1422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.42146897315979}", "{\"n\": 1423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4154052734375}", "{\"n\": 1424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.64, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.3999450206756592}", "{\"n\": 1425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4376604557037354}", "{\"n\": 1426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.407193899154663}", "{\"n\": 1427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4024298191070557}", "{\"n\": 1428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.54, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.393305778503418}", "{\"n\": 1429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.73, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.3998684883117676}", "{\"n\": 1430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.432706594467163}", "{\"n\": 1431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3954436779022217}", "{\"n\": 1432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.26, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4303677082061768}", "{\"n\": 1433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.08, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4263978004455566}", "{\"n\": 1434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4355244636535645}", "{\"n\": 1435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4273083209991455}", "{\"n\": 1436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.3983051776885986}", "{\"n\": 1437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4252333641052246}", "{\"n\": 1438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4198353290557861}", "{\"n\": 1439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4157848358154297}", "{\"n\": 1440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.566, \"total_train_time_s\": 1.3959879875183105}", "{\"n\": 1441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.409705400466919}", "{\"n\": 1442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.68, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.487966537475586}", "{\"n\": 1443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.55, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4199507236480713}", "{\"n\": 1444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.55, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4090979099273682}", "{\"n\": 1445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.55, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3913910388946533}", "{\"n\": 1446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.471419334411621}", "{\"n\": 1447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.427206039428711}", "{\"n\": 1448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4330260753631592}", "{\"n\": 1449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4013426303863525}", "{\"n\": 1450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.574, \"total_train_time_s\": 1.4344305992126465}", "{\"n\": 1451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.43, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4310150146484375}", "{\"n\": 1452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.43, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.3949015140533447}", "{\"n\": 1453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.43, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.3964693546295166}", "{\"n\": 1454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.71, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4682643413543701}", "{\"n\": 1455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4159328937530518}", "{\"n\": 1456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.531, \"total_train_time_s\": 1.4045462608337402}", "{\"n\": 1457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.385136365890503}", "{\"n\": 1458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.85, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.452873945236206}", "{\"n\": 1459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.93, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.395822286605835}", "{\"n\": 1460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.93, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.3687644004821777}", "{\"n\": 1461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.93, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4005200862884521}", "{\"n\": 1462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.65, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.436899185180664}", "{\"n\": 1463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4520492553710938}", "{\"n\": 1464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4321930408477783}", "{\"n\": 1465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.413609266281128}", "{\"n\": 1466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.64, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4486358165740967}", "{\"n\": 1467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4067802429199219}", "{\"n\": 1468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4317100048065186}", "{\"n\": 1469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.3972101211547852}", "{\"n\": 1470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.75, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.436147689819336}", "{\"n\": 1471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4314489364624023}", "{\"n\": 1472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.396254539489746}", "{\"n\": 1473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.423116683959961}", "{\"n\": 1474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.74, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.43910813331604}", "{\"n\": 1475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.6, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4059536457061768}", "{\"n\": 1476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.6, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4137284755706787}", "{\"n\": 1477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.6, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4401164054870605}", "{\"n\": 1478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.66, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4508755207061768}", "{\"n\": 1479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.52, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4267029762268066}", "{\"n\": 1480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.52, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4258339405059814}", "{\"n\": 1481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.52, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.414426565170288}", "{\"n\": 1482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.4575445652008057}", "{\"n\": 1483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4104111194610596}", "{\"n\": 1484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.3965177536010742}", "{\"n\": 1485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.69, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4207971096038818}", "{\"n\": 1486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.48, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.4204633235931396}", "{\"n\": 1487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4073834419250488}", "{\"n\": 1488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4023511409759521}", "{\"n\": 1489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.46, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3914783000946045}", "{\"n\": 1490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.33, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.4582586288452148}", "{\"n\": 1491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.23, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4252238273620605}", "{\"n\": 1492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.23, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.400669813156128}", "{\"n\": 1493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1038.23, \"learn_time_ms\": 4.55, \"total_train_time_s\": 1.4058940410614014}", "{\"n\": 1494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4442005157470703}", "{\"n\": 1495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4199187755584717}", "{\"n\": 1496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4112663269042969}", "{\"n\": 1497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4046878814697266}", "{\"n\": 1498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.09, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.440124750137329}", "{\"n\": 1499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4180870056152344}", "{\"n\": 1500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4846947193145752}", "{\"n\": 1501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.31, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4182355403900146}", "{\"n\": 1502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4098362922668457}", "{\"n\": 1503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4038257598876953}", "{\"n\": 1504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4068577289581299}", "{\"n\": 1505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.437788486480713}", "{\"n\": 1506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.37, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4239118099212646}", "{\"n\": 1507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.15, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.410400629043579}", "{\"n\": 1508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.15, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4119281768798828}", "{\"n\": 1509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.409085988998413}", "{\"n\": 1510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.56, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4268584251403809}", "{\"n\": 1511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.78, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.3911380767822266}", "{\"n\": 1512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.78, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4151906967163086}", "{\"n\": 1513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4302117824554443}", "{\"n\": 1514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.37, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4122705459594727}", "{\"n\": 1515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.3962833881378174}", "{\"n\": 1516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.420339584350586}", "{\"n\": 1517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.69, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4153523445129395}", "{\"n\": 1518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.46, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4382216930389404}", "{\"n\": 1519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.57, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4090421199798584}", "{\"n\": 1520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.57, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.3904798030853271}", "{\"n\": 1521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.52, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4103243350982666}", "{\"n\": 1522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.71, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4218132495880127}", "{\"n\": 1523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4359917640686035}", "{\"n\": 1524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.3972394466400146}", "{\"n\": 1525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.89, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4389641284942627}", "{\"n\": 1526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.59, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4559762477874756}", "{\"n\": 1527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.77, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.446028709411621}", "{\"n\": 1528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.77, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.3965327739715576}", "{\"n\": 1529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.75, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4054434299468994}", "{\"n\": 1530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.92, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4477369785308838}", "{\"n\": 1531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.388993740081787}", "{\"n\": 1532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4060750007629395}", "{\"n\": 1533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4149599075317383}", "{\"n\": 1534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4279460906982422}", "{\"n\": 1535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.81, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4441545009613037}", "{\"n\": 1536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.81, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4202611446380615}", "{\"n\": 1537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4087581634521484}", "{\"n\": 1538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.84, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4168288707733154}", "{\"n\": 1539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.88, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4021153450012207}", "{\"n\": 1540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.88, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4188871383666992}", "{\"n\": 1541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.25, \"total_train_time_s\": 1.4177320003509521}", "{\"n\": 1542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4436395168304443}", "{\"n\": 1543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4352812767028809}", "{\"n\": 1544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4176557064056396}", "{\"n\": 1545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.76, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.406484603881836}", "{\"n\": 1546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.76, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4422132968902588}", "{\"n\": 1547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.43674898147583}", "{\"n\": 1548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4219975471496582}", "{\"n\": 1549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.41, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.3945293426513672}", "{\"n\": 1550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.85, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.3813817501068115}", "{\"n\": 1551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.71, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4316887855529785}", "{\"n\": 1552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.71, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4170851707458496}", "{\"n\": 1553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.53, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4052131175994873}", "{\"n\": 1554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.6, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4145987033843994}", "{\"n\": 1555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4333412647247314}", "{\"n\": 1556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.401061773300171}", "{\"n\": 1557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.28, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4219584465026855}", "{\"n\": 1558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.28, \"learn_time_ms\": 4.504, \"total_train_time_s\": 1.415722370147705}", "{\"n\": 1559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4487342834472656}", "{\"n\": 1560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4325637817382812}", "{\"n\": 1561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.92, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4213626384735107}", "{\"n\": 1562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4266741275787354}", "{\"n\": 1563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4384968280792236}", "{\"n\": 1564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.397458553314209}", "{\"n\": 1565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4052062034606934}", "{\"n\": 1566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.04, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4227170944213867}", "{\"n\": 1567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.17, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4386601448059082}", "{\"n\": 1568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.17, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4305229187011719}", "{\"n\": 1569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.17, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4008865356445312}", "{\"n\": 1570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.35, \"learn_time_ms\": 4.542, \"total_train_time_s\": 1.4496536254882812}", "{\"n\": 1571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4214580059051514}", "{\"n\": 1572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4163732528686523}", "{\"n\": 1573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.3788416385650635}", "{\"n\": 1574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.12, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.455909252166748}", "{\"n\": 1575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4415855407714844}", "{\"n\": 1576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.389601230621338}", "{\"n\": 1577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4161150455474854}", "{\"n\": 1578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.83, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4508154392242432}", "{\"n\": 1579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.84, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4094433784484863}", "{\"n\": 1580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.84, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4105865955352783}", "{\"n\": 1581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.84, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4386911392211914}", "{\"n\": 1582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.55, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.459148645401001}", "{\"n\": 1583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4151155948638916}", "{\"n\": 1584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.3880431652069092}", "{\"n\": 1585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.3901522159576416}", "{\"n\": 1586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.98, \"learn_time_ms\": 4.25, \"total_train_time_s\": 1.4264616966247559}", "{\"n\": 1587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.95, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4256045818328857}", "{\"n\": 1588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.95, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4089617729187012}", "{\"n\": 1589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.95, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.413268804550171}", "{\"n\": 1590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.16, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4490814208984375}", "{\"n\": 1591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3992102146148682}", "{\"n\": 1592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.3955051898956299}", "{\"n\": 1593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4208192825317383}", "{\"n\": 1594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.21, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4106249809265137}", "{\"n\": 1595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4054474830627441}", "{\"n\": 1596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4050264358520508}", "{\"n\": 1597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.3954484462738037}", "{\"n\": 1598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4285612106323242}", "{\"n\": 1599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4216713905334473}", "{\"n\": 1600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.3923258781433105}", "{\"n\": 1601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4059195518493652}", "{\"n\": 1602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4459848403930664}", "{\"n\": 1603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.407317876815796}", "{\"n\": 1604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4195878505706787}", "{\"n\": 1605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4161205291748047}", "{\"n\": 1606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4287045001983643}", "{\"n\": 1607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4011285305023193}", "{\"n\": 1608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.508077621459961}", "{\"n\": 1609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.57, \"total_train_time_s\": 1.405822515487671}", "{\"n\": 1610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4234390258789062}", "{\"n\": 1611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.3958218097686768}", "{\"n\": 1612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4081010818481445}", "{\"n\": 1613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3967058658599854}", "{\"n\": 1614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.11, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4431962966918945}", "{\"n\": 1615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.11, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3943812847137451}", "{\"n\": 1616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.22, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.3932640552520752}", "{\"n\": 1617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4070923328399658}", "{\"n\": 1618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4429161548614502}", "{\"n\": 1619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.3929383754730225}", "{\"n\": 1620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4179229736328125}", "{\"n\": 1621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.26, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.431891679763794}", "{\"n\": 1622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.435736894607544}", "{\"n\": 1623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.377420425415039}", "{\"n\": 1624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.16, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4158756732940674}", "{\"n\": 1625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.1, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4261000156402588}", "{\"n\": 1626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4292452335357666}", "{\"n\": 1627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.11, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4231040477752686}", "{\"n\": 1628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.11, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4193902015686035}", "{\"n\": 1629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.15, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4099085330963135}", "{\"n\": 1630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.08, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4264352321624756}", "{\"n\": 1631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.08, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4001340866088867}", "{\"n\": 1632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.08, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.3928487300872803}", "{\"n\": 1633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4231898784637451}", "{\"n\": 1634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4174020290374756}", "{\"n\": 1635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4247040748596191}", "{\"n\": 1636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.412667989730835}", "{\"n\": 1637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4240925312042236}", "{\"n\": 1638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4315316677093506}", "{\"n\": 1639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4013066291809082}", "{\"n\": 1640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.3948187828063965}", "{\"n\": 1641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4139599800109863}", "{\"n\": 1642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4161136150360107}", "{\"n\": 1643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4204423427581787}", "{\"n\": 1644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4066078662872314}", "{\"n\": 1645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.35, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4318251609802246}", "{\"n\": 1646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.441329002380371}", "{\"n\": 1647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4078238010406494}", "{\"n\": 1648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.422473430633545}", "{\"n\": 1649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4335694313049316}", "{\"n\": 1650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.59, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4272291660308838}", "{\"n\": 1651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.59, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3978023529052734}", "{\"n\": 1652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.59, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4290337562561035}", "{\"n\": 1653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4119760990142822}", "{\"n\": 1654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.385303258895874}", "{\"n\": 1655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4221751689910889}", "{\"n\": 1656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4125034809112549}", "{\"n\": 1657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.57, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4082045555114746}", "{\"n\": 1658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.42, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.396348476409912}", "{\"n\": 1659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.98, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4374940395355225}", "{\"n\": 1660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.98, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4263291358947754}", "{\"n\": 1661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.410884141921997}", "{\"n\": 1662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4222581386566162}", "{\"n\": 1663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.64, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4207360744476318}", "{\"n\": 1664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4254124164581299}", "{\"n\": 1665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.48, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4339942932128906}", "{\"n\": 1666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.48, \"learn_time_ms\": 4.537, \"total_train_time_s\": 1.4089953899383545}", "{\"n\": 1667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.7, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.410994052886963}", "{\"n\": 1668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.82, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4161059856414795}", "{\"n\": 1669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.59, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4384586811065674}", "{\"n\": 1670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.59, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4179959297180176}", "{\"n\": 1671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.5, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4295833110809326}", "{\"n\": 1672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.49, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4205021858215332}", "{\"n\": 1673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.234, \"total_train_time_s\": 1.4080710411071777}", "{\"n\": 1674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4096148014068604}", "{\"n\": 1675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.71, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4295563697814941}", "{\"n\": 1676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.78, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4176912307739258}", "{\"n\": 1677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.03, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.428856372833252}", "{\"n\": 1678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.31, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4240715503692627}", "{\"n\": 1679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.31, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4030570983886719}", "{\"n\": 1680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.420058012008667}", "{\"n\": 1681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.6, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.399336814880371}", "{\"n\": 1682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.6, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.3951799869537354}", "{\"n\": 1683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.35, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.416780710220337}", "{\"n\": 1684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4044723510742188}", "{\"n\": 1685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.24, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4197673797607422}", "{\"n\": 1686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.24, \"learn_time_ms\": 4.246, \"total_train_time_s\": 1.42287015914917}", "{\"n\": 1687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.2, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4101243019104004}", "{\"n\": 1688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.1, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.3958539962768555}", "{\"n\": 1689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4346933364868164}", "{\"n\": 1690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.3925671577453613}", "{\"n\": 1691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.6583831310272217}", "{\"n\": 1692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.4170160293579102}", "{\"n\": 1693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.32, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4169590473175049}", "{\"n\": 1694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.32, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4106507301330566}", "{\"n\": 1695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.44, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4156150817871094}", "{\"n\": 1696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.25, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4008469581604004}", "{\"n\": 1697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4166746139526367}", "{\"n\": 1698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4249505996704102}", "{\"n\": 1699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.07, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.415689468383789}", "{\"n\": 1700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.26, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4375669956207275}", "{\"n\": 1701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4198870658874512}", "{\"n\": 1702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.421609878540039}", "{\"n\": 1703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.28, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4260454177856445}", "{\"n\": 1704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.4, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4133882522583008}", "{\"n\": 1705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.33, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.420973539352417}", "{\"n\": 1706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.33, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4440367221832275}", "{\"n\": 1707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4251365661621094}", "{\"n\": 1708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4098970890045166}", "{\"n\": 1709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.84, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4168124198913574}", "{\"n\": 1710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.84, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4240174293518066}", "{\"n\": 1711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4284389019012451}", "{\"n\": 1712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.73, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.415501356124878}", "{\"n\": 1713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4109952449798584}", "{\"n\": 1714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.4, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4385712146759033}", "{\"n\": 1715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4343945980072021}", "{\"n\": 1716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4091675281524658}", "{\"n\": 1717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.27, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4287657737731934}", "{\"n\": 1718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4273860454559326}", "{\"n\": 1719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.01, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4441065788269043}", "{\"n\": 1720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.01, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.415696144104004}", "{\"n\": 1721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.14, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4248943328857422}", "{\"n\": 1722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.14, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.3885793685913086}", "{\"n\": 1723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4245047569274902}", "{\"n\": 1724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.86, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4531564712524414}", "{\"n\": 1725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.85, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4093117713928223}", "{\"n\": 1726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.85, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4160237312316895}", "{\"n\": 1727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4052186012268066}", "{\"n\": 1728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.41, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.452709436416626}", "{\"n\": 1729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.73, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.3964557647705078}", "{\"n\": 1730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.73, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4219110012054443}", "{\"n\": 1731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.58, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4335219860076904}", "{\"n\": 1732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.3966150283813477}", "{\"n\": 1733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.91, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4410271644592285}", "{\"n\": 1734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.91, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3896558284759521}", "{\"n\": 1735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.84, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4191420078277588}", "{\"n\": 1736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.0, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4198949337005615}", "{\"n\": 1737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.08, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.3937911987304688}", "{\"n\": 1738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.08, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4040789604187012}", "{\"n\": 1739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.08, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.3880295753479004}", "{\"n\": 1740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.32, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4672634601593018}", "{\"n\": 1741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.32, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4034972190856934}", "{\"n\": 1742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.25, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.426530361175537}", "{\"n\": 1743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.25, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.3976469039916992}", "{\"n\": 1744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.35, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.4190196990966797}", "{\"n\": 1745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.35, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3794856071472168}", "{\"n\": 1746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.91, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4191107749938965}", "{\"n\": 1747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.91, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.391336441040039}", "{\"n\": 1748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.22, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4488906860351562}", "{\"n\": 1749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.22, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.4118359088897705}", "{\"n\": 1750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.15, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.408801555633545}", "{\"n\": 1751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.15, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4279615879058838}", "{\"n\": 1752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.18, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.430006504058838}", "{\"n\": 1753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.18, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.3924944400787354}", "{\"n\": 1754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.01, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.401885986328125}", "{\"n\": 1755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.27, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4192500114440918}", "{\"n\": 1756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.32, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4348435401916504}", "{\"n\": 1757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.32, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.402489423751831}", "{\"n\": 1758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.58, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4079084396362305}", "{\"n\": 1759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.48, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4201853275299072}", "{\"n\": 1760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.79, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4245274066925049}", "{\"n\": 1761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.79, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4011194705963135}", "{\"n\": 1762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.41, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.438788652420044}", "{\"n\": 1763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.37, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4269962310791016}", "{\"n\": 1764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.53, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4272661209106445}", "{\"n\": 1765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.53, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4154529571533203}", "{\"n\": 1766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.45, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4158365726470947}", "{\"n\": 1767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.37, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3987669944763184}", "{\"n\": 1768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.98, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4182448387145996}", "{\"n\": 1769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.98, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3991656303405762}", "{\"n\": 1770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4244999885559082}", "{\"n\": 1771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4287230968475342}", "{\"n\": 1772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.229, \"total_train_time_s\": 1.4243412017822266}", "{\"n\": 1773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4061250686645508}", "{\"n\": 1774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.44, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.403846263885498}", "{\"n\": 1775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4122507572174072}", "{\"n\": 1776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.31, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4119329452514648}", "{\"n\": 1777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.31, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.428637981414795}", "{\"n\": 1778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.31, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4239356517791748}", "{\"n\": 1779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.24, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4317457675933838}", "{\"n\": 1780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4437901973724365}", "{\"n\": 1781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.386770248413086}", "{\"n\": 1782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.8, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.423490285873413}", "{\"n\": 1783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.8, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3905024528503418}", "{\"n\": 1784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.63, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.420280933380127}", "{\"n\": 1785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.78, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4117062091827393}", "{\"n\": 1786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.78, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3762855529785156}", "{\"n\": 1787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.8, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4228293895721436}", "{\"n\": 1788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4076285362243652}", "{\"n\": 1789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.394810676574707}", "{\"n\": 1790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.73, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.390716552734375}", "{\"n\": 1791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.8, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.396164894104004}", "{\"n\": 1792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.79, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.3944165706634521}", "{\"n\": 1793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.1, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4329476356506348}", "{\"n\": 1794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.1, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.3981256484985352}", "{\"n\": 1795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.2, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4155848026275635}", "{\"n\": 1796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.442246437072754}", "{\"n\": 1797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.86, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4186651706695557}", "{\"n\": 1798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.86, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.380600929260254}", "{\"n\": 1799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3881847858428955}", "{\"n\": 1800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.05, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4146208763122559}", "{\"n\": 1801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.84, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.403230905532837}", "{\"n\": 1802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.84, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.392711877822876}", "{\"n\": 1803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4175238609313965}", "{\"n\": 1804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4164135456085205}", "{\"n\": 1805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.2, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4389450550079346}", "{\"n\": 1806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.2, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.3974196910858154}", "{\"n\": 1807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4014992713928223}", "{\"n\": 1808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.33, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4195780754089355}", "{\"n\": 1809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.33, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.3879368305206299}", "{\"n\": 1810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.34, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.474766731262207}", "{\"n\": 1811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4510047435760498}", "{\"n\": 1812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.68, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4432408809661865}", "{\"n\": 1813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.436516284942627}", "{\"n\": 1814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.556, \"total_train_time_s\": 1.535294771194458}", "{\"n\": 1815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4186172485351562}", "{\"n\": 1816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.38, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3997282981872559}", "{\"n\": 1817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.38, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.3916161060333252}", "{\"n\": 1818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.53, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4300117492675781}", "{\"n\": 1819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4040889739990234}", "{\"n\": 1820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.01, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.434075117111206}", "{\"n\": 1821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.01, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.3991641998291016}", "{\"n\": 1822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.04, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4190700054168701}", "{\"n\": 1823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.3, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4574837684631348}", "{\"n\": 1824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.3, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4245617389678955}", "{\"n\": 1825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.3, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3980236053466797}", "{\"n\": 1826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.38, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4145715236663818}", "{\"n\": 1827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4450962543487549}", "{\"n\": 1828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.423577070236206}", "{\"n\": 1829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4016413688659668}", "{\"n\": 1830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.81, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4189209938049316}", "{\"n\": 1831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.83, \"learn_time_ms\": 4.93, \"total_train_time_s\": 1.424816608428955}", "{\"n\": 1832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.3, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4251015186309814}", "{\"n\": 1833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.3, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.421694278717041}", "{\"n\": 1834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.29, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4178147315979004}", "{\"n\": 1835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.79, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4200310707092285}", "{\"n\": 1836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.74, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4184818267822266}", "{\"n\": 1837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.74, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4098789691925049}", "{\"n\": 1838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.74, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.3925886154174805}", "{\"n\": 1839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.45, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4314641952514648}", "{\"n\": 1840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4344232082366943}", "{\"n\": 1841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4238758087158203}", "{\"n\": 1842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4048233032226562}", "{\"n\": 1843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.07, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4200444221496582}", "{\"n\": 1844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4174530506134033}", "{\"n\": 1845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4003472328186035}", "{\"n\": 1846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4131386280059814}", "{\"n\": 1847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.61, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.432269811630249}", "{\"n\": 1848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.438354253768921}", "{\"n\": 1849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4100475311279297}", "{\"n\": 1850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4189198017120361}", "{\"n\": 1851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4417788982391357}", "{\"n\": 1852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.738, \"total_train_time_s\": 1.4596004486083984}", "{\"n\": 1853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4121358394622803}", "{\"n\": 1854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.55, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4325182437896729}", "{\"n\": 1855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.55, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.416649580001831}", "{\"n\": 1856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4245493412017822}", "{\"n\": 1857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.410799503326416}", "{\"n\": 1858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.51, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4699101448059082}", "{\"n\": 1859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.63, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4215617179870605}", "{\"n\": 1860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.437995433807373}", "{\"n\": 1861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.3929638862609863}", "{\"n\": 1862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.73, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4254274368286133}", "{\"n\": 1863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.83, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4060654640197754}", "{\"n\": 1864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.63, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4163336753845215}", "{\"n\": 1865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.63, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.3929738998413086}", "{\"n\": 1866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4097554683685303}", "{\"n\": 1867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4057235717773438}", "{\"n\": 1868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.4407808780670166}", "{\"n\": 1869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4125914573669434}", "{\"n\": 1870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4274120330810547}", "{\"n\": 1871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4508004188537598}", "{\"n\": 1872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.927, \"total_train_time_s\": 1.4550042152404785}", "{\"n\": 1873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4079225063323975}", "{\"n\": 1874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.52, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4332606792449951}", "{\"n\": 1875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4163782596588135}", "{\"n\": 1876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.419222116470337}", "{\"n\": 1877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.412398338317871}", "{\"n\": 1878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.01, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4139909744262695}", "{\"n\": 1879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4340996742248535}", "{\"n\": 1880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.28, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4272468090057373}", "{\"n\": 1881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.28, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.38149094581604}", "{\"n\": 1882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.3, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4085776805877686}", "{\"n\": 1883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4233925342559814}", "{\"n\": 1884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.36, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.425549030303955}", "{\"n\": 1885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.36, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4209299087524414}", "{\"n\": 1886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4590659141540527}", "{\"n\": 1887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.19, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4087793827056885}", "{\"n\": 1888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.48, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.444340467453003}", "{\"n\": 1889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.48, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.3828094005584717}", "{\"n\": 1890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4019770622253418}", "{\"n\": 1891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.62, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.416048288345337}", "{\"n\": 1892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.79, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.4099013805389404}", "{\"n\": 1893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.79, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.467069149017334}", "{\"n\": 1894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3989965915679932}", "{\"n\": 1895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.66, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4224071502685547}", "{\"n\": 1896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4168615341186523}", "{\"n\": 1897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4099092483520508}", "{\"n\": 1898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.09, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.407820463180542}", "{\"n\": 1899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.02, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4109299182891846}", "{\"n\": 1900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.02, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4354636669158936}", "{\"n\": 1901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.02, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4063739776611328}", "{\"n\": 1902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.13, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.410917043685913}", "{\"n\": 1903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4078004360198975}", "{\"n\": 1904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4208855628967285}", "{\"n\": 1905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4024403095245361}", "{\"n\": 1906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.93, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4032032489776611}", "{\"n\": 1907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.98, \"learn_time_ms\": 4.508, \"total_train_time_s\": 1.433643102645874}", "{\"n\": 1908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4332830905914307}", "{\"n\": 1909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.3831512928009033}", "{\"n\": 1910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.98, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.420149326324463}", "{\"n\": 1911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.91, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4100072383880615}", "{\"n\": 1912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.82, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.424346923828125}", "{\"n\": 1913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.82, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4423108100891113}", "{\"n\": 1914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.99, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4289567470550537}", "{\"n\": 1915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.01, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4361770153045654}", "{\"n\": 1916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4360177516937256}", "{\"n\": 1917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.02, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.3888211250305176}", "{\"n\": 1918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.93, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.435638666152954}", "{\"n\": 1919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.96, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4347054958343506}", "{\"n\": 1920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.72, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4144668579101562}", "{\"n\": 1921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.72, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4316749572753906}", "{\"n\": 1922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.87, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.5238265991210938}", "{\"n\": 1923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.225, \"total_train_time_s\": 1.4120426177978516}", "{\"n\": 1924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.79, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.433739185333252}", "{\"n\": 1925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.79, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4188685417175293}", "{\"n\": 1926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.8, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4328405857086182}", "{\"n\": 1927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.96, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.3899459838867188}", "{\"n\": 1928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.28, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4308793544769287}", "{\"n\": 1929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.28, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4260382652282715}", "{\"n\": 1930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.54, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4219274520874023}", "{\"n\": 1931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.6, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4303805828094482}", "{\"n\": 1932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.06, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.400846004486084}", "{\"n\": 1933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.06, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.3955185413360596}", "{\"n\": 1934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.17, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3966178894042969}", "{\"n\": 1935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.31, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.439847707748413}", "{\"n\": 1936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.41, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4371991157531738}", "{\"n\": 1937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.41, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4401586055755615}", "{\"n\": 1938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.68, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4058709144592285}", "{\"n\": 1939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.78, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4065639972686768}", "{\"n\": 1940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.15, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4435946941375732}", "{\"n\": 1941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.15, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4071910381317139}", "{\"n\": 1942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.42, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4086012840270996}", "{\"n\": 1943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.26, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4133038520812988}", "{\"n\": 1944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.33, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4465243816375732}", "{\"n\": 1945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.33, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3925819396972656}", "{\"n\": 1946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.98, \"learn_time_ms\": 4.235, \"total_train_time_s\": 1.406355619430542}", "{\"n\": 1947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.76, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4012706279754639}", "{\"n\": 1948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.6, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4129347801208496}", "{\"n\": 1949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.6, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4318737983703613}", "{\"n\": 1950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.48, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4389004707336426}", "{\"n\": 1951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.6, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4119954109191895}", "{\"n\": 1952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.74, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4293701648712158}", "{\"n\": 1953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.74, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4267408847808838}", "{\"n\": 1954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.97, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4355874061584473}", "{\"n\": 1955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.93, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4025108814239502}", "{\"n\": 1956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.81, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4108757972717285}", "{\"n\": 1957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.77, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.4154767990112305}", "{\"n\": 1958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.87, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4247081279754639}", "{\"n\": 1959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.77, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4126644134521484}", "{\"n\": 1960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.76, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.420130729675293}", "{\"n\": 1961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.8, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4038352966308594}", "{\"n\": 1962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.8, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4186115264892578}", "{\"n\": 1963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.88, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.41166090965271}", "{\"n\": 1964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.84, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4097034931182861}", "{\"n\": 1965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4223415851593018}", "{\"n\": 1966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4143590927124023}", "{\"n\": 1967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.01, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4281044006347656}", "{\"n\": 1968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.01, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.445847749710083}", "{\"n\": 1969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.08, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.3979508876800537}", "{\"n\": 1970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4320781230926514}", "{\"n\": 1971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.04, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4112975597381592}", "{\"n\": 1972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.16, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4201910495758057}", "{\"n\": 1973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.98, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.400583028793335}", "{\"n\": 1974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.09, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4218604564666748}", "{\"n\": 1975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4212915897369385}", "{\"n\": 1976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.05, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4263215065002441}", "{\"n\": 1977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4311103820800781}", "{\"n\": 1978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.57, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4198715686798096}", "{\"n\": 1979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.52, \"learn_time_ms\": 4.544, \"total_train_time_s\": 1.4255869388580322}", "{\"n\": 1980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.56, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.400886058807373}", "{\"n\": 1981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.3891847133636475}", "{\"n\": 1982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4159965515136719}", "{\"n\": 1983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.42, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4105489253997803}", "{\"n\": 1984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.44, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.3972296714782715}", "{\"n\": 1985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.62, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4180312156677246}", "{\"n\": 1986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.61, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.395024299621582}", "{\"n\": 1987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.63, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4230384826660156}", "{\"n\": 1988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.46, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.426095962524414}", "{\"n\": 1989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.54, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4060297012329102}", "{\"n\": 1990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.58, \"learn_time_ms\": 4.226, \"total_train_time_s\": 1.4413037300109863}", "{\"n\": 1991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4399604797363281}", "{\"n\": 1992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.31, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4117443561553955}", "{\"n\": 1993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4288990497589111}", "{\"n\": 1994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.12, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4340033531188965}", "{\"n\": 1995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.01, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4420506954193115}", "{\"n\": 1996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.01, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.3955094814300537}", "{\"n\": 1997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.82, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4331564903259277}", "{\"n\": 1998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.67, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.412022590637207}", "{\"n\": 1999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.73, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.404296636581421}", "{\"n\": 2000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.89, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4254770278930664}", "{\"n\": 2001, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.88, \"learn_time_ms\": 4.229, \"total_train_time_s\": 1.431325912475586}", "{\"n\": 2002, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.4157273769378662}", "{\"n\": 2003, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.96, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4502537250518799}", "{\"n\": 2004, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.94, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4160706996917725}", "{\"n\": 2005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.98, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4135184288024902}", "{\"n\": 2006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.14, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.3992791175842285}", "{\"n\": 2007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.04, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.412559986114502}", "{\"n\": 2008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4473512172698975}", "{\"n\": 2009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4172492027282715}", "{\"n\": 2010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.03, \"learn_time_ms\": 4.628, \"total_train_time_s\": 1.4349303245544434}", "{\"n\": 2011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4304165840148926}", "{\"n\": 2012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4350550174713135}", "{\"n\": 2013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4239287376403809}", "{\"n\": 2014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.04, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4371919631958008}", "{\"n\": 2015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.98, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4344797134399414}", "{\"n\": 2016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.97, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.446075439453125}", "{\"n\": 2017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.96, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4151711463928223}", "{\"n\": 2018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.3996050357818604}", "{\"n\": 2019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.97, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4392776489257812}", "{\"n\": 2020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.83, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4287981986999512}", "{\"n\": 2021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.02, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.441810131072998}", "{\"n\": 2022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.79, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4146625995635986}", "{\"n\": 2023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.7, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4218370914459229}", "{\"n\": 2024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.52, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4341259002685547}", "{\"n\": 2025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.42, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4391825199127197}", "{\"n\": 2026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.32, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.3950517177581787}", "{\"n\": 2027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.16, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4108424186706543}", "{\"n\": 2028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.26, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4180634021759033}", "{\"n\": 2029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.51, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.400268793106079}", "{\"n\": 2030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.55, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.5396034717559814}", "{\"n\": 2031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.63, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.413947343826294}", "{\"n\": 2032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.34, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4291784763336182}", "{\"n\": 2033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.43, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4291703701019287}", "{\"n\": 2034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.52, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4232966899871826}", "{\"n\": 2035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.44, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4243583679199219}", "{\"n\": 2036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.45, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4136126041412354}", "{\"n\": 2037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.45, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.400895357131958}", "{\"n\": 2038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.51, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4230964183807373}", "{\"n\": 2039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.36, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4291701316833496}", "{\"n\": 2040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.23, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4343531131744385}", "{\"n\": 2041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.23, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.428884744644165}", "{\"n\": 2042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.0, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.415752649307251}", "{\"n\": 2043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.05, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4565579891204834}", "{\"n\": 2044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.49, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4229748249053955}", "{\"n\": 2045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.49, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.406254768371582}", "{\"n\": 2046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.52, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4197132587432861}", "{\"n\": 2047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.76, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4109570980072021}", "{\"n\": 2048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.78, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.471181869506836}", "{\"n\": 2049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.71, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4075031280517578}", "{\"n\": 2050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.76, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4100961685180664}", "{\"n\": 2051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.76, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.3979144096374512}", "{\"n\": 2052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.71, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4203102588653564}", "{\"n\": 2053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.58, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4506378173828125}", "{\"n\": 2054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.39, \"learn_time_ms\": 4.595, \"total_train_time_s\": 1.4320933818817139}", "{\"n\": 2055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.39, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.3952584266662598}", "{\"n\": 2056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.39, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4122676849365234}", "{\"n\": 2057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4669673442840576}", "{\"n\": 2058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3981800079345703}", "{\"n\": 2059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4079949855804443}", "{\"n\": 2060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.3938183784484863}", "{\"n\": 2061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.424037218093872}", "{\"n\": 2062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.419579029083252}", "{\"n\": 2063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.440476894378662}", "{\"n\": 2064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4286413192749023}", "{\"n\": 2065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4331767559051514}", "{\"n\": 2066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.55, \"total_train_time_s\": 1.4585981369018555}", "{\"n\": 2067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.399123191833496}", "{\"n\": 2068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4396696090698242}", "{\"n\": 2069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.4, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4285075664520264}", "{\"n\": 2070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.4, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4551441669464111}", "{\"n\": 2071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.4510481357574463}", "{\"n\": 2072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.398144245147705}", "{\"n\": 2073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.03, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4241487979888916}", "{\"n\": 2074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3943254947662354}", "{\"n\": 2075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.62, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.432952642440796}", "{\"n\": 2076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.62, \"learn_time_ms\": 4.552, \"total_train_time_s\": 1.4549264907836914}", "{\"n\": 2077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4119207859039307}", "{\"n\": 2078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.35, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.414975881576538}", "{\"n\": 2079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4197275638580322}", "{\"n\": 2080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.408036231994629}", "{\"n\": 2081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.27, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4291768074035645}", "{\"n\": 2082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.38, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4167835712432861}", "{\"n\": 2083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.35, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4029428958892822}", "{\"n\": 2084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.35, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4093377590179443}", "{\"n\": 2085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4218165874481201}", "{\"n\": 2086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.405463457107544}", "{\"n\": 2087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.28, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4141132831573486}", "{\"n\": 2088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.28, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.406102180480957}", "{\"n\": 2089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.25, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4059557914733887}", "{\"n\": 2090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4292731285095215}", "{\"n\": 2091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.01, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4136989116668701}", "{\"n\": 2092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.01, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4290592670440674}", "{\"n\": 2093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.28, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4438250064849854}", "{\"n\": 2094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.29, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.424405813217163}", "{\"n\": 2095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.27, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4373490810394287}", "{\"n\": 2096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.27, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4211719036102295}", "{\"n\": 2097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.16, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4458322525024414}", "{\"n\": 2098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.16, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4113445281982422}", "{\"n\": 2099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.11, \"learn_time_ms\": 4.523, \"total_train_time_s\": 1.4172053337097168}", "{\"n\": 2100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.05, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.41363525390625}", "{\"n\": 2101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.02, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.4528591632843018}", "{\"n\": 2102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.02, \"learn_time_ms\": 4.219, \"total_train_time_s\": 1.4101929664611816}", "{\"n\": 2103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.05, \"learn_time_ms\": 4.523, \"total_train_time_s\": 1.3884317874908447}", "{\"n\": 2104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.436720371246338}", "{\"n\": 2105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4055399894714355}", "{\"n\": 2106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.403764247894287}", "{\"n\": 2107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4045708179473877}", "{\"n\": 2108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.7, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4105334281921387}", "{\"n\": 2109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 4.239, \"total_train_time_s\": 1.4199302196502686}", "{\"n\": 2110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4151809215545654}", "{\"n\": 2111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.81, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4211645126342773}", "{\"n\": 2112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4246411323547363}", "{\"n\": 2113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.63, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.6882457733154297}", "{\"n\": 2114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.63, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.3962295055389404}", "{\"n\": 2115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.55, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4022846221923828}", "{\"n\": 2116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.4, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.3722779750823975}", "{\"n\": 2117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.41, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4447307586669922}", "{\"n\": 2118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.41, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4054503440856934}", "{\"n\": 2119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.45, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.413835048675537}", "{\"n\": 2120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.48, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4306459426879883}", "{\"n\": 2121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.38, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4191563129425049}", "{\"n\": 2122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.38, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.3973474502563477}", "{\"n\": 2123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.43, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4033994674682617}", "{\"n\": 2124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.5, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.430004358291626}", "{\"n\": 2125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.95, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.417008638381958}", "{\"n\": 2126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.95, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.3854265213012695}", "{\"n\": 2127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4190936088562012}", "{\"n\": 2128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.1, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4257166385650635}", "{\"n\": 2129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.2, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3946170806884766}", "{\"n\": 2130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.57, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.452587604522705}", "{\"n\": 2131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.51, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3995344638824463}", "{\"n\": 2132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.35, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4133291244506836}", "{\"n\": 2133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.35, \"learn_time_ms\": 4.558, \"total_train_time_s\": 1.4193904399871826}", "{\"n\": 2134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.49, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4506044387817383}", "{\"n\": 2135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4211552143096924}", "{\"n\": 2136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.3, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4121713638305664}", "{\"n\": 2137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.45, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.436750888824463}", "{\"n\": 2138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.31, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.3824172019958496}", "{\"n\": 2139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4293675422668457}", "{\"n\": 2140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.4, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4129743576049805}", "{\"n\": 2141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.4, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4261984825134277}", "{\"n\": 2142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.31, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4171967506408691}", "{\"n\": 2143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.5, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3992202281951904}", "{\"n\": 2144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.55, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4209318161010742}", "{\"n\": 2145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.66, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.427734136581421}", "{\"n\": 2146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.22, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4204270839691162}", "{\"n\": 2147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.26, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.425309419631958}", "{\"n\": 2148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.15, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4262299537658691}", "{\"n\": 2149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.15, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.406599998474121}", "{\"n\": 2150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.08, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.448065996170044}", "{\"n\": 2151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.98, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4043338298797607}", "{\"n\": 2152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.98, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.408012866973877}", "{\"n\": 2153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.99, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4181602001190186}", "{\"n\": 2154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.73, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4252848625183105}", "{\"n\": 2155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4285664558410645}", "{\"n\": 2156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.97, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.3959360122680664}", "{\"n\": 2157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.03, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4240984916687012}", "{\"n\": 2158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.91, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4000892639160156}", "{\"n\": 2159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.3931708335876465}", "{\"n\": 2160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3997137546539307}", "{\"n\": 2161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.06, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4113507270812988}", "{\"n\": 2162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4396240711212158}", "{\"n\": 2163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.08, \"learn_time_ms\": 4.233, \"total_train_time_s\": 1.4321708679199219}", "{\"n\": 2164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.08, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.416034460067749}", "{\"n\": 2165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4085710048675537}", "{\"n\": 2166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.7, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.3862102031707764}", "{\"n\": 2167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.53, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4230163097381592}", "{\"n\": 2168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.53, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4020955562591553}", "{\"n\": 2169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.89, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4007844924926758}", "{\"n\": 2170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4135661125183105}", "{\"n\": 2171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.37, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.424067497253418}", "{\"n\": 2172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.37, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4185729026794434}", "{\"n\": 2173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.37, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4247899055480957}", "{\"n\": 2174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.35, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4407496452331543}", "{\"n\": 2175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.35, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4311726093292236}", "{\"n\": 2176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.82, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4089760780334473}", "{\"n\": 2177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.82, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4042484760284424}", "{\"n\": 2178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.42006516456604}", "{\"n\": 2179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.3815631866455078}", "{\"n\": 2180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4290170669555664}", "{\"n\": 2181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.399580478668213}", "{\"n\": 2182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.11, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.435823917388916}", "{\"n\": 2183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.11, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4019691944122314}", "{\"n\": 2184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4380481243133545}", "{\"n\": 2185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4017794132232666}", "{\"n\": 2186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.43, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.420546054840088}", "{\"n\": 2187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.43, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4254658222198486}", "{\"n\": 2188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4313225746154785}", "{\"n\": 2189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4152886867523193}", "{\"n\": 2190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.37, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4140095710754395}", "{\"n\": 2191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.19, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4558911323547363}", "{\"n\": 2192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4108834266662598}", "{\"n\": 2193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4054696559906006}", "{\"n\": 2194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4194509983062744}", "{\"n\": 2195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.79, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.397963285446167}", "{\"n\": 2196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.41152024269104}", "{\"n\": 2197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4039630889892578}", "{\"n\": 2198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.22, \"total_train_time_s\": 1.4088103771209717}", "{\"n\": 2199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.429713249206543}", "{\"n\": 2200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.79, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4624242782592773}", "{\"n\": 2201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.34, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.433072566986084}", "{\"n\": 2202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.25, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.3787949085235596}", "{\"n\": 2203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.25, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.3822269439697266}", "{\"n\": 2204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.75, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4048049449920654}", "{\"n\": 2205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.3978328704833984}", "{\"n\": 2206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.56, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4174954891204834}", "{\"n\": 2207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.56, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.400606393814087}", "{\"n\": 2208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.53, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4451653957366943}", "{\"n\": 2209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.58, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4177353382110596}", "{\"n\": 2210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.73, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.411928653717041}", "{\"n\": 2211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.73, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.397932767868042}", "{\"n\": 2212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.47, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4187595844268799}", "{\"n\": 2213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.61, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4137635231018066}", "{\"n\": 2214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.68, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4147696495056152}", "{\"n\": 2215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.68, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4034676551818848}", "{\"n\": 2216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4353885650634766}", "{\"n\": 2217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.18, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4237825870513916}", "{\"n\": 2218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.97, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4305529594421387}", "{\"n\": 2219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.97, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.4010350704193115}", "{\"n\": 2220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.79, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4177148342132568}", "{\"n\": 2221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.86, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4220521450042725}", "{\"n\": 2222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.91, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4050891399383545}", "{\"n\": 2223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.91, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.3971278667449951}", "{\"n\": 2224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.82, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4183008670806885}", "{\"n\": 2225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.85, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4155397415161133}", "{\"n\": 2226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.89, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.41190505027771}", "{\"n\": 2227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.89, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4179468154907227}", "{\"n\": 2228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.97, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4391372203826904}", "{\"n\": 2229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.93, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3875529766082764}", "{\"n\": 2230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.74, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.414039134979248}", "{\"n\": 2231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.74, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.377016544342041}", "{\"n\": 2232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.31, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4157850742340088}", "{\"n\": 2233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.32, \"learn_time_ms\": 4.199, \"total_train_time_s\": 1.4281840324401855}", "{\"n\": 2234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.27, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.391193151473999}", "{\"n\": 2235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.27, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.3980133533477783}", "{\"n\": 2236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.02, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.514636754989624}", "{\"n\": 2237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.13, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4374289512634277}", "{\"n\": 2238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4044373035430908}", "{\"n\": 2239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.3996477127075195}", "{\"n\": 2240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.01, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4130442142486572}", "{\"n\": 2241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.99, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4114229679107666}", "{\"n\": 2242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.98, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4103286266326904}", "{\"n\": 2243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.98, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4169464111328125}", "{\"n\": 2244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.04, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4241602420806885}", "{\"n\": 2245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.07, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4028728008270264}", "{\"n\": 2246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.85, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.408693552017212}", "{\"n\": 2247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.85, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3818614482879639}", "{\"n\": 2248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4294917583465576}", "{\"n\": 2249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4219999313354492}", "{\"n\": 2250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.04, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4066753387451172}", "{\"n\": 2251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.04, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.40863037109375}", "{\"n\": 2252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.87, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.406231164932251}", "{\"n\": 2253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.82, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4230949878692627}", "{\"n\": 2254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.35, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4173948764801025}", "{\"n\": 2255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.35, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4186580181121826}", "{\"n\": 2256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.23, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4247262477874756}", "{\"n\": 2257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4290924072265625}", "{\"n\": 2258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.32, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.422806739807129}", "{\"n\": 2259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.32, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4308059215545654}", "{\"n\": 2260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.07, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4123656749725342}", "{\"n\": 2261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.88, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.3971917629241943}", "{\"n\": 2262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.86, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4074227809906006}", "{\"n\": 2263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.86, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4383108615875244}", "{\"n\": 2264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3957102298736572}", "{\"n\": 2265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.48, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4579157829284668}", "{\"n\": 2266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4154934883117676}", "{\"n\": 2267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4083728790283203}", "{\"n\": 2268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.66, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4025347232818604}", "{\"n\": 2269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.39, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4035282135009766}", "{\"n\": 2270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.406714916229248}", "{\"n\": 2271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.408724069595337}", "{\"n\": 2272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.17, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4532475471496582}", "{\"n\": 2273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.38, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4248218536376953}", "{\"n\": 2274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.79, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.3951525688171387}", "{\"n\": 2275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.79, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4045460224151611}", "{\"n\": 2276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4116263389587402}", "{\"n\": 2277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4052486419677734}", "{\"n\": 2278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4066100120544434}", "{\"n\": 2279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4248950481414795}", "{\"n\": 2280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.6, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4442894458770752}", "{\"n\": 2281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.83, \"learn_time_ms\": 4.222, \"total_train_time_s\": 1.4442603588104248}", "{\"n\": 2282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4152193069458008}", "{\"n\": 2283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4030978679656982}", "{\"n\": 2284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.69, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4048073291778564}", "{\"n\": 2285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4049553871154785}", "{\"n\": 2286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.42950439453125}", "{\"n\": 2287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.386359691619873}", "{\"n\": 2288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.64, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4048693180084229}", "{\"n\": 2289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.58, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.414675235748291}", "{\"n\": 2290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4290797710418701}", "{\"n\": 2291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4078149795532227}", "{\"n\": 2292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.14, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4221501350402832}", "{\"n\": 2293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.04, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4140398502349854}", "{\"n\": 2294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4022607803344727}", "{\"n\": 2295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.3749585151672363}", "{\"n\": 2296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.31, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4338879585266113}", "{\"n\": 2297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.31, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4008872509002686}", "{\"n\": 2298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4019932746887207}", "{\"n\": 2299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4102668762207031}", "{\"n\": 2300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.45, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4042887687683105}", "{\"n\": 2301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.45, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4188172817230225}", "{\"n\": 2302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.418834924697876}", "{\"n\": 2303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.7, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4486310482025146}", "{\"n\": 2304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.61, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.4142413139343262}", "{\"n\": 2305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.61, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.3799748420715332}", "{\"n\": 2306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.78, \"learn_time_ms\": 4.497, \"total_train_time_s\": 1.4402873516082764}", "{\"n\": 2307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.52, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4128057956695557}", "{\"n\": 2308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.56, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4441802501678467}", "{\"n\": 2309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.56, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.402230978012085}", "{\"n\": 2310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.55, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4282214641571045}", "{\"n\": 2311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.7, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4184422492980957}", "{\"n\": 2312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.87, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4235146045684814}", "{\"n\": 2313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.87, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.3937156200408936}", "{\"n\": 2314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.84, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4225335121154785}", "{\"n\": 2315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.48, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.41923189163208}", "{\"n\": 2316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4149553775787354}", "{\"n\": 2317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4242448806762695}", "{\"n\": 2318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.65, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.4169561862945557}", "{\"n\": 2319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.01, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4631340503692627}", "{\"n\": 2320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.87, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4138011932373047}", "{\"n\": 2321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.87, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.3914170265197754}", "{\"n\": 2322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.87, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4200522899627686}", "{\"n\": 2323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.94, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4089696407318115}", "{\"n\": 2324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.94, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.400374174118042}", "{\"n\": 2325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.94, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.3951451778411865}", "{\"n\": 2326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.72, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.479564905166626}", "{\"n\": 2327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.72, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4210841655731201}", "{\"n\": 2328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.48, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4359087944030762}", "{\"n\": 2329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.48, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.409545660018921}", "{\"n\": 2330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.3, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4240031242370605}", "{\"n\": 2331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.31, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3852665424346924}", "{\"n\": 2332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.4, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.442626714706421}", "{\"n\": 2333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.4, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4189517498016357}", "{\"n\": 2334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.45, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.3920581340789795}", "{\"n\": 2335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.526, \"total_train_time_s\": 1.4331746101379395}", "{\"n\": 2336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.19, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4085884094238281}", "{\"n\": 2337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.19, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4034345149993896}", "{\"n\": 2338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.25, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4197351932525635}", "{\"n\": 2339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.26, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4346845149993896}", "{\"n\": 2340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.99, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4414589405059814}", "{\"n\": 2341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.99, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.395688533782959}", "{\"n\": 2342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.91, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4076192378997803}", "{\"n\": 2343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4035789966583252}", "{\"n\": 2344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.5383195877075195}", "{\"n\": 2345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.3796322345733643}", "{\"n\": 2346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.98, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4521305561065674}", "{\"n\": 2347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.523, \"total_train_time_s\": 1.4409220218658447}", "{\"n\": 2348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.26, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4272501468658447}", "{\"n\": 2349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.26, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.41801118850708}", "{\"n\": 2350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4166805744171143}", "{\"n\": 2351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.31, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4384279251098633}", "{\"n\": 2352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.45, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.424203634262085}", "{\"n\": 2353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.45, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.4123034477233887}", "{\"n\": 2354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.38, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4453654289245605}", "{\"n\": 2355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.43, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3926959037780762}", "{\"n\": 2356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4235494136810303}", "{\"n\": 2357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.430433750152588}", "{\"n\": 2358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4368867874145508}", "{\"n\": 2359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.237, \"total_train_time_s\": 1.398911476135254}", "{\"n\": 2360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.24, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4202907085418701}", "{\"n\": 2361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.24, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.3837471008300781}", "{\"n\": 2362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.45, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4369909763336182}", "{\"n\": 2363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.36, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3976614475250244}", "{\"n\": 2364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4411096572875977}", "{\"n\": 2365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4191505908966064}", "{\"n\": 2366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.2, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.428598165512085}", "{\"n\": 2367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4288594722747803}", "{\"n\": 2368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.17, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4371185302734375}", "{\"n\": 2369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.17, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.3772053718566895}", "{\"n\": 2370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.14, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4084656238555908}", "{\"n\": 2371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.4423928260803223}", "{\"n\": 2372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.2, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.433669090270996}", "{\"n\": 2373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.2, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4233412742614746}", "{\"n\": 2374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.401904582977295}", "{\"n\": 2375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4593658447265625}", "{\"n\": 2376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.84, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4136617183685303}", "{\"n\": 2377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.76, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.40419340133667}", "{\"n\": 2378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.76, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4142911434173584}", "{\"n\": 2379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4124906063079834}", "{\"n\": 2380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.09, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4432487487792969}", "{\"n\": 2381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4156112670898438}", "{\"n\": 2382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.440277099609375}", "{\"n\": 2383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.77, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4139649868011475}", "{\"n\": 2384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.63, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4302639961242676}", "{\"n\": 2385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.48, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.413994550704956}", "{\"n\": 2386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.48, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4057621955871582}", "{\"n\": 2387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.53, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4283571243286133}", "{\"n\": 2388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4377310276031494}", "{\"n\": 2389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.16, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4382388591766357}", "{\"n\": 2390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.16, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4083049297332764}", "{\"n\": 2391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.03, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.408569097518921}", "{\"n\": 2392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.0, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.432856559753418}", "{\"n\": 2393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4137918949127197}", "{\"n\": 2394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.411780834197998}", "{\"n\": 2395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4062423706054688}", "{\"n\": 2396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.06, \"learn_time_ms\": 4.23, \"total_train_time_s\": 1.397123098373413}", "{\"n\": 2397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.3985977172851562}", "{\"n\": 2398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4395568370819092}", "{\"n\": 2399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.28, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.416097640991211}", "{\"n\": 2400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.36, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4115278720855713}", "{\"n\": 2401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.3885557651519775}", "{\"n\": 2402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3768584728240967}", "{\"n\": 2403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.8, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4140942096710205}", "{\"n\": 2404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.396101713180542}", "{\"n\": 2405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.42368745803833}", "{\"n\": 2406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.88, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.389164924621582}", "{\"n\": 2407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.89, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4268560409545898}", "{\"n\": 2408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4181816577911377}", "{\"n\": 2409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4006836414337158}", "{\"n\": 2410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4400954246520996}", "{\"n\": 2411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4200890064239502}", "{\"n\": 2412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4243698120117188}", "{\"n\": 2413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.67, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.39703369140625}", "{\"n\": 2414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.67, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3944227695465088}", "{\"n\": 2415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.01, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4300336837768555}", "{\"n\": 2416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.15, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.441776990890503}", "{\"n\": 2417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.3, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4175565242767334}", "{\"n\": 2418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.3, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4091029167175293}", "{\"n\": 2419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.54, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4031596183776855}", "{\"n\": 2420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.52, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4304571151733398}", "{\"n\": 2421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.39, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.396524429321289}", "{\"n\": 2422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.39, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.389690637588501}", "{\"n\": 2423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.41, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4033229351043701}", "{\"n\": 2424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.74, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4142649173736572}", "{\"n\": 2425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4030554294586182}", "{\"n\": 2426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4137599468231201}", "{\"n\": 2427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.89, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4177958965301514}", "{\"n\": 2428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.9, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.419358253479004}", "{\"n\": 2429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.58, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4327211380004883}", "{\"n\": 2430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.58, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.430492877960205}", "{\"n\": 2431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3984923362731934}", "{\"n\": 2432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.61, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4034650325775146}", "{\"n\": 2433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4284892082214355}", "{\"n\": 2434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4092860221862793}", "{\"n\": 2435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.3998615741729736}", "{\"n\": 2436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.59, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.424515724182129}", "{\"n\": 2437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.16, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4382035732269287}", "{\"n\": 2438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.16, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4277245998382568}", "{\"n\": 2439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.16, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4185080528259277}", "{\"n\": 2440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4405605792999268}", "{\"n\": 2441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4328291416168213}", "{\"n\": 2442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3975505828857422}", "{\"n\": 2443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4140801429748535}", "{\"n\": 2444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.95, \"learn_time_ms\": 4.246, \"total_train_time_s\": 1.4149210453033447}", "{\"n\": 2445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4309334754943848}", "{\"n\": 2446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.4123783111572266}", "{\"n\": 2447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4181501865386963}", "{\"n\": 2448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.4328880310058594}", "{\"n\": 2449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.19, \"learn_time_ms\": 4.535, \"total_train_time_s\": 1.4472768306732178}", "{\"n\": 2450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.19, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.409595251083374}", "{\"n\": 2451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.19, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4030787944793701}", "{\"n\": 2452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.5198910236358643}", "{\"n\": 2453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4319629669189453}", "{\"n\": 2454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3756709098815918}", "{\"n\": 2455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.501, \"total_train_time_s\": 1.4092621803283691}", "{\"n\": 2456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.77, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4235506057739258}", "{\"n\": 2457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.44, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4352424144744873}", "{\"n\": 2458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.44, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4174885749816895}", "{\"n\": 2459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.44, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4232456684112549}", "{\"n\": 2460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.39, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4427456855773926}", "{\"n\": 2461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.442448377609253}", "{\"n\": 2462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.396477460861206}", "{\"n\": 2463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4170246124267578}", "{\"n\": 2464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.41440749168396}", "{\"n\": 2465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.428429126739502}", "{\"n\": 2466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4016168117523193}", "{\"n\": 2467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.3, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4261305332183838}", "{\"n\": 2468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4196393489837646}", "{\"n\": 2469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.421018123626709}", "{\"n\": 2470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.416865348815918}", "{\"n\": 2471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.388641595840454}", "{\"n\": 2472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.412397861480713}", "{\"n\": 2473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4072270393371582}", "{\"n\": 2474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.3947808742523193}", "{\"n\": 2475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.69, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.4228184223175049}", "{\"n\": 2476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.78, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4028480052947998}", "{\"n\": 2477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.91, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4270832538604736}", "{\"n\": 2478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.91, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.3904471397399902}", "{\"n\": 2479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.95, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.408149003982544}", "{\"n\": 2480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4264421463012695}", "{\"n\": 2481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.91, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4151782989501953}", "{\"n\": 2482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.91, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4066026210784912}", "{\"n\": 2483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.83, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4079458713531494}", "{\"n\": 2484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.72, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4068214893341064}", "{\"n\": 2485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.422203540802002}", "{\"n\": 2486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.197, \"total_train_time_s\": 1.3846795558929443}", "{\"n\": 2487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.66, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3980402946472168}", "{\"n\": 2488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.79, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.41355299949646}", "{\"n\": 2489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.98, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4424264430999756}", "{\"n\": 2490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.98, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4231743812561035}", "{\"n\": 2491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.91, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.3917734622955322}", "{\"n\": 2492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.03, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.3890907764434814}", "{\"n\": 2493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.85, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4424281120300293}", "{\"n\": 2494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.85, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.382767915725708}", "{\"n\": 2495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.97, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4084019660949707}", "{\"n\": 2496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.89, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.422300100326538}", "{\"n\": 2497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.97, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4237520694732666}", "{\"n\": 2498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.97, \"learn_time_ms\": 4.186, \"total_train_time_s\": 1.3930776119232178}", "{\"n\": 2499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.88, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4122798442840576}", "{\"n\": 2500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.79, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4026706218719482}", "{\"n\": 2501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.83, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.4326133728027344}", "{\"n\": 2502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.83, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4025304317474365}", "{\"n\": 2503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.408271074295044}", "{\"n\": 2504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3993489742279053}", "{\"n\": 2505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.93, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4137585163116455}", "{\"n\": 2506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.93, \"learn_time_ms\": 4.538, \"total_train_time_s\": 1.4217844009399414}", "{\"n\": 2507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.95, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4212806224822998}", "{\"n\": 2508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4063777923583984}", "{\"n\": 2509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.414482593536377}", "{\"n\": 2510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.410731554031372}", "{\"n\": 2511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.76, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4233369827270508}", "{\"n\": 2512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.4, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4178128242492676}", "{\"n\": 2513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.3812553882598877}", "{\"n\": 2514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.397221326828003}", "{\"n\": 2515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4124541282653809}", "{\"n\": 2516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.25, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4017775058746338}", "{\"n\": 2517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4212405681610107}", "{\"n\": 2518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4020843505859375}", "{\"n\": 2519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.51, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4178624153137207}", "{\"n\": 2520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.67, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4209883213043213}", "{\"n\": 2521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4060721397399902}", "{\"n\": 2522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.97, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3962020874023438}", "{\"n\": 2523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.13, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.3914296627044678}", "{\"n\": 2524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4464550018310547}", "{\"n\": 2525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4210877418518066}", "{\"n\": 2526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.3902606964111328}", "{\"n\": 2527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.1, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.434389591217041}", "{\"n\": 2528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.23, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.404698133468628}", "{\"n\": 2529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.68, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4212772846221924}", "{\"n\": 2530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.68, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.396878957748413}", "{\"n\": 2531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.74, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4213495254516602}", "{\"n\": 2532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.76, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4346849918365479}", "{\"n\": 2533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.547, \"total_train_time_s\": 1.4313011169433594}", "{\"n\": 2534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.3909556865692139}", "{\"n\": 2535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.13, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4130487442016602}", "{\"n\": 2536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.427555799484253}", "{\"n\": 2537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.67, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.696378231048584}", "{\"n\": 2538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.7, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4096827507019043}", "{\"n\": 2539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.65, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.419445514678955}", "{\"n\": 2540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.87, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4122123718261719}", "{\"n\": 2541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.98, \"learn_time_ms\": 4.231, \"total_train_time_s\": 1.4071648120880127}", "{\"n\": 2542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.76, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4161229133605957}", "{\"n\": 2543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.72, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4171245098114014}", "{\"n\": 2544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.79, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4168076515197754}", "{\"n\": 2545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.0, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4035074710845947}", "{\"n\": 2546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.88, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4087095260620117}", "{\"n\": 2547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.83, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.418060541152954}", "{\"n\": 2548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.69, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3964331150054932}", "{\"n\": 2549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.37, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4102089405059814}", "{\"n\": 2550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.05, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.3927702903747559}", "{\"n\": 2551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.02, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4016802310943604}", "{\"n\": 2552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.15, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.3958053588867188}", "{\"n\": 2553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.15, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4074151515960693}", "{\"n\": 2554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4237935543060303}", "{\"n\": 2555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4240875244140625}", "{\"n\": 2556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4187958240509033}", "{\"n\": 2557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4097366333007812}", "{\"n\": 2558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.08, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4171648025512695}", "{\"n\": 2559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.426074743270874}", "{\"n\": 2560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4103600978851318}", "{\"n\": 2561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.403672218322754}", "{\"n\": 2562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.61, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.421309232711792}", "{\"n\": 2563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.66, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.406217336654663}", "{\"n\": 2564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.63, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4229261875152588}", "{\"n\": 2565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.63, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4165668487548828}", "{\"n\": 2566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.83, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.410649299621582}", "{\"n\": 2567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4077184200286865}", "{\"n\": 2568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.64, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4134488105773926}", "{\"n\": 2569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.64, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.3904893398284912}", "{\"n\": 2570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4680452346801758}", "{\"n\": 2571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4160490036010742}", "{\"n\": 2572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.93, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4120564460754395}", "{\"n\": 2573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.93, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.4078116416931152}", "{\"n\": 2574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.4429075717926025}", "{\"n\": 2575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3768322467803955}", "{\"n\": 2576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.420527696609497}", "{\"n\": 2577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.388786792755127}", "{\"n\": 2578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.245, \"total_train_time_s\": 1.4063889980316162}", "{\"n\": 2579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4369125366210938}", "{\"n\": 2580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4141597747802734}", "{\"n\": 2581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.387908935546875}", "{\"n\": 2582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4335994720458984}", "{\"n\": 2583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4279067516326904}", "{\"n\": 2584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4422245025634766}", "{\"n\": 2585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4037752151489258}", "{\"n\": 2586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.61, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4518840312957764}", "{\"n\": 2587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.61, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.412076473236084}", "{\"n\": 2588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.53, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4441287517547607}", "{\"n\": 2589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.76, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.400512933731079}", "{\"n\": 2590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.82, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4272396564483643}", "{\"n\": 2591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.82, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4122178554534912}", "{\"n\": 2592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.87, \"learn_time_ms\": 4.544, \"total_train_time_s\": 1.4119632244110107}", "{\"n\": 2593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.75, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4128656387329102}", "{\"n\": 2594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.412078619003296}", "{\"n\": 2595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.187, \"total_train_time_s\": 1.3906028270721436}", "{\"n\": 2596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4040722846984863}", "{\"n\": 2597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4315159320831299}", "{\"n\": 2598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.440014123916626}", "{\"n\": 2599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4266531467437744}", "{\"n\": 2600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4214353561401367}", "{\"n\": 2601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4120867252349854}", "{\"n\": 2602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.18, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.3786094188690186}", "{\"n\": 2603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.18, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.3848061561584473}", "{\"n\": 2604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.418375015258789}", "{\"n\": 2605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4097223281860352}", "{\"n\": 2606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.86, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4325459003448486}", "{\"n\": 2607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.7, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4129555225372314}", "{\"n\": 2608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.77, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4243395328521729}", "{\"n\": 2609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.53, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4106090068817139}", "{\"n\": 2610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.65, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4448308944702148}", "{\"n\": 2611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.65, \"learn_time_ms\": 4.225, \"total_train_time_s\": 1.3787000179290771}", "{\"n\": 2612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.32, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.41483473777771}", "{\"n\": 2613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.9, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4160213470458984}", "{\"n\": 2614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.99, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4172513484954834}", "{\"n\": 2615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.18, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4225194454193115}", "{\"n\": 2616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.15, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4064688682556152}", "{\"n\": 2617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.2, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4135684967041016}", "{\"n\": 2618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.27, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.419010877609253}", "{\"n\": 2619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.73, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.399548053741455}", "{\"n\": 2620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.83, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.426710844039917}", "{\"n\": 2621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.71, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4193897247314453}", "{\"n\": 2622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.72, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4212472438812256}", "{\"n\": 2623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.44, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.402512550354004}", "{\"n\": 2624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.15, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.400916337966919}", "{\"n\": 2625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.03, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4194884300231934}", "{\"n\": 2626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.02, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4203777313232422}", "{\"n\": 2627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.85, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.3874056339263916}", "{\"n\": 2628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.81, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4118356704711914}", "{\"n\": 2629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.72, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.424048662185669}", "{\"n\": 2630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.83, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.431408405303955}", "{\"n\": 2631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.85, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4152116775512695}", "{\"n\": 2632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.74, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.3843028545379639}", "{\"n\": 2633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4290385246276855}", "{\"n\": 2634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.04, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.401104211807251}", "{\"n\": 2635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4370205402374268}", "{\"n\": 2636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.83, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.405761480331421}", "{\"n\": 2637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.83, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.38511323928833}", "{\"n\": 2638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.92, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.418182134628296}", "{\"n\": 2639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.78, \"learn_time_ms\": 4.549, \"total_train_time_s\": 1.4103050231933594}", "{\"n\": 2640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.7, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4231903553009033}", "{\"n\": 2641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.7, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4024274349212646}", "{\"n\": 2642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.79, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4106521606445312}", "{\"n\": 2643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.25, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4031357765197754}", "{\"n\": 2644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.25, \"learn_time_ms\": 4.541, \"total_train_time_s\": 1.425482988357544}", "{\"n\": 2645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.26, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4244539737701416}", "{\"n\": 2646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.27, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4140393733978271}", "{\"n\": 2647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.29, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.408479928970337}", "{\"n\": 2648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.29, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4243249893188477}", "{\"n\": 2649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.2, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.415196418762207}", "{\"n\": 2650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.48, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.421004295349121}", "{\"n\": 2651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.48, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4091086387634277}", "{\"n\": 2652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.3902747631072998}", "{\"n\": 2653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.07, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.3992359638214111}", "{\"n\": 2654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.27, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4160199165344238}", "{\"n\": 2655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.27, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.3927607536315918}", "{\"n\": 2656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.51, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.423872709274292}", "{\"n\": 2657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.48, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.412527322769165}", "{\"n\": 2658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.78, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4073505401611328}", "{\"n\": 2659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.78, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.400228500366211}", "{\"n\": 2660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.68, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4997766017913818}", "{\"n\": 2661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.14, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4129612445831299}", "{\"n\": 2662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.14, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.392822027206421}", "{\"n\": 2663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.09, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.412458896636963}", "{\"n\": 2664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.54, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.437995195388794}", "{\"n\": 2665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.31, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4060776233673096}", "{\"n\": 2666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.31, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4127166271209717}", "{\"n\": 2667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.78, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.429914951324463}", "{\"n\": 2668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.73, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4492220878601074}", "{\"n\": 2669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.86, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4312665462493896}", "{\"n\": 2670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.86, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.405709981918335}", "{\"n\": 2671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.69, \"learn_time_ms\": 4.208, \"total_train_time_s\": 1.4148893356323242}", "{\"n\": 2672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.54, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4199256896972656}", "{\"n\": 2673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.51, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4114885330200195}", "{\"n\": 2674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.51, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4068858623504639}", "{\"n\": 2675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.27, \"learn_time_ms\": 4.521, \"total_train_time_s\": 1.4290134906768799}", "{\"n\": 2676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4454376697540283}", "{\"n\": 2677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.37, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4175987243652344}", "{\"n\": 2678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.37, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4282801151275635}", "{\"n\": 2679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.47, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.412372350692749}", "{\"n\": 2680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.26, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4332160949707031}", "{\"n\": 2681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.35, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.431518316268921}", "{\"n\": 2682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.35, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.4177258014678955}", "{\"n\": 2683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.4, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.413327693939209}", "{\"n\": 2684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.41, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4234721660614014}", "{\"n\": 2685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.3, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4350037574768066}", "{\"n\": 2686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.3, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4174206256866455}", "{\"n\": 2687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.21, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.444526195526123}", "{\"n\": 2688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.18, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.408994436264038}", "{\"n\": 2689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.54, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.436093807220459}", "{\"n\": 2690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.54, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4107029438018799}", "{\"n\": 2691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.3750202655792236}", "{\"n\": 2692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.25, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4050259590148926}", "{\"n\": 2693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.57, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4078295230865479}", "{\"n\": 2694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.57, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.3707466125488281}", "{\"n\": 2695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.53, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4204978942871094}", "{\"n\": 2696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.83, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4120628833770752}", "{\"n\": 2697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.92, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4366705417633057}", "{\"n\": 2698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.92, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3833186626434326}", "{\"n\": 2699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.28, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4110846519470215}", "{\"n\": 2700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.43, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4286091327667236}", "{\"n\": 2701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.45, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.424224853515625}", "{\"n\": 2702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.45, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.3862223625183105}", "{\"n\": 2703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.27, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4028053283691406}", "{\"n\": 2704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.22, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3989841938018799}", "{\"n\": 2705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.41, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4233732223510742}", "{\"n\": 2706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.41, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4046285152435303}", "{\"n\": 2707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.74, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.395885705947876}", "{\"n\": 2708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4410371780395508}", "{\"n\": 2709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.400575876235962}", "{\"n\": 2710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.3911807537078857}", "{\"n\": 2711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.21, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4398813247680664}", "{\"n\": 2712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.448061227798462}", "{\"n\": 2713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.43021821975708}", "{\"n\": 2714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4543578624725342}", "{\"n\": 2715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4198317527770996}", "{\"n\": 2716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.67, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.427417516708374}", "{\"n\": 2717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.49, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.425133228302002}", "{\"n\": 2718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.49, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4063401222229004}", "{\"n\": 2719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 4.553, \"total_train_time_s\": 1.43436598777771}", "{\"n\": 2720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.24, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4282917976379395}", "{\"n\": 2721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4141762256622314}", "{\"n\": 2722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4118454456329346}", "{\"n\": 2723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4393904209136963}", "{\"n\": 2724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.37, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4252150058746338}", "{\"n\": 2725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.18, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4187180995941162}", "{\"n\": 2726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.18, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4075462818145752}", "{\"n\": 2727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.24, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.400907039642334}", "{\"n\": 2728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4381251335144043}", "{\"n\": 2729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4127204418182373}", "{\"n\": 2730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.193, \"total_train_time_s\": 1.3898413181304932}", "{\"n\": 2731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.35, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4164717197418213}", "{\"n\": 2732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.1, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4589791297912598}", "{\"n\": 2733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.424626350402832}", "{\"n\": 2734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.3973956108093262}", "{\"n\": 2735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.6, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4355292320251465}", "{\"n\": 2736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.63, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4243643283843994}", "{\"n\": 2737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.85, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.422067403793335}", "{\"n\": 2738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.85, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.3988842964172363}", "{\"n\": 2739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.53, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.435640811920166}", "{\"n\": 2740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4411115646362305}", "{\"n\": 2741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4300658702850342}", "{\"n\": 2742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4064996242523193}", "{\"n\": 2743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.65, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4061157703399658}", "{\"n\": 2744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.409846544265747}", "{\"n\": 2745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4271008968353271}", "{\"n\": 2746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.3822133541107178}", "{\"n\": 2747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.64, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4254467487335205}", "{\"n\": 2748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.26, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4423046112060547}", "{\"n\": 2749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.407679557800293}", "{\"n\": 2750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4478988647460938}", "{\"n\": 2751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.3, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.440371036529541}", "{\"n\": 2752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4089665412902832}", "{\"n\": 2753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4137225151062012}", "{\"n\": 2754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.539, \"total_train_time_s\": 1.4065325260162354}", "{\"n\": 2755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.25, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4167635440826416}", "{\"n\": 2756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.19, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4324989318847656}", "{\"n\": 2757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.426943302154541}", "{\"n\": 2758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4170889854431152}", "{\"n\": 2759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.2, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4324672222137451}", "{\"n\": 2760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.2, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.413762092590332}", "{\"n\": 2761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4422898292541504}", "{\"n\": 2762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4061293601989746}", "{\"n\": 2763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4105167388916016}", "{\"n\": 2764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4352409839630127}", "{\"n\": 2765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4425995349884033}", "{\"n\": 2766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4130702018737793}", "{\"n\": 2767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4525985717773438}", "{\"n\": 2768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.503401517868042}", "{\"n\": 2769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4594240188598633}", "{\"n\": 2770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3975481986999512}", "{\"n\": 2771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.417616367340088}", "{\"n\": 2772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4106183052062988}", "{\"n\": 2773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.45290207862854}", "{\"n\": 2774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4184765815734863}", "{\"n\": 2775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.67, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4091787338256836}", "{\"n\": 2776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.67, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4080352783203125}", "{\"n\": 2777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4690027236938477}", "{\"n\": 2778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.417475700378418}", "{\"n\": 2779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3961129188537598}", "{\"n\": 2780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.3972651958465576}", "{\"n\": 2781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4199137687683105}", "{\"n\": 2782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4322071075439453}", "{\"n\": 2783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.28, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.434910535812378}", "{\"n\": 2784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.28, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.436194658279419}", "{\"n\": 2785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.09, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.46649169921875}", "{\"n\": 2786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.09, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.436777114868164}", "{\"n\": 2787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.42722487449646}", "{\"n\": 2788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4146316051483154}", "{\"n\": 2789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.77, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4364650249481201}", "{\"n\": 2790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.77, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4237091541290283}", "{\"n\": 2791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4080138206481934}", "{\"n\": 2792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4140534400939941}", "{\"n\": 2793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4250645637512207}", "{\"n\": 2794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.3912944793701172}", "{\"n\": 2795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.16, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4343523979187012}", "{\"n\": 2796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.16, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4213554859161377}", "{\"n\": 2797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4496324062347412}", "{\"n\": 2798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4274623394012451}", "{\"n\": 2799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.443260669708252}", "{\"n\": 2800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.504, \"total_train_time_s\": 1.429560661315918}", "{\"n\": 2801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.83, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.430755615234375}", "{\"n\": 2802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.83, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4066052436828613}", "{\"n\": 2803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4153969287872314}", "{\"n\": 2804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.197, \"total_train_time_s\": 1.4013035297393799}", "{\"n\": 2805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.456852912902832}", "{\"n\": 2806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4103708267211914}", "{\"n\": 2807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.45, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.4255530834197998}", "{\"n\": 2808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.45, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.424302577972412}", "{\"n\": 2809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4388127326965332}", "{\"n\": 2810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.3975579738616943}", "{\"n\": 2811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4047186374664307}", "{\"n\": 2812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.413193702697754}", "{\"n\": 2813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.4, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.440502405166626}", "{\"n\": 2814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.4, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.421705961227417}", "{\"n\": 2815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.37, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4063773155212402}", "{\"n\": 2816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.37, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4237055778503418}", "{\"n\": 2817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.65, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.435286283493042}", "{\"n\": 2818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.65, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4028513431549072}", "{\"n\": 2819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3967111110687256}", "{\"n\": 2820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.412898063659668}", "{\"n\": 2821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.432004690170288}", "{\"n\": 2822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.78, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4371230602264404}", "{\"n\": 2823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4001541137695312}", "{\"n\": 2824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4231781959533691}", "{\"n\": 2825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4640870094299316}", "{\"n\": 2826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4221770763397217}", "{\"n\": 2827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.84, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4264326095581055}", "{\"n\": 2828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.84, \"learn_time_ms\": 4.503, \"total_train_time_s\": 1.4091570377349854}", "{\"n\": 2829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4527215957641602}", "{\"n\": 2830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.3906290531158447}", "{\"n\": 2831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.431441307067871}", "{\"n\": 2832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4114952087402344}", "{\"n\": 2833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.55, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.45512056350708}", "{\"n\": 2834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.55, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.407827615737915}", "{\"n\": 2835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4049315452575684}", "{\"n\": 2836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.3829412460327148}", "{\"n\": 2837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.516, \"total_train_time_s\": 1.4402117729187012}", "{\"n\": 2838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.412243366241455}", "{\"n\": 2839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4120965003967285}", "{\"n\": 2840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.517, \"total_train_time_s\": 1.4381625652313232}", "{\"n\": 2841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.02, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.448596477508545}", "{\"n\": 2842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.02, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.410212516784668}", "{\"n\": 2843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.05, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.417231798171997}", "{\"n\": 2844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.05, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.399784803390503}", "{\"n\": 2845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.0, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.451883316040039}", "{\"n\": 2846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.0, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4182116985321045}", "{\"n\": 2847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.93, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4443471431732178}", "{\"n\": 2848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.93, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4322776794433594}", "{\"n\": 2849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4148328304290771}", "{\"n\": 2850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.79, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4279968738555908}", "{\"n\": 2851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4145755767822266}", "{\"n\": 2852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.390432596206665}", "{\"n\": 2853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4192121028900146}", "{\"n\": 2854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.08, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4329469203948975}", "{\"n\": 2855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.06, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4305164813995361}", "{\"n\": 2856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.06, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4063138961791992}", "{\"n\": 2857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.93, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4244580268859863}", "{\"n\": 2858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.567, \"total_train_time_s\": 1.4567410945892334}", "{\"n\": 2859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.05, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4221923351287842}", "{\"n\": 2860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.05, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4190881252288818}", "{\"n\": 2861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.03, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4025380611419678}", "{\"n\": 2862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.17, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.4293911457061768}", "{\"n\": 2863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.41, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.417126178741455}", "{\"n\": 2864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4236316680908203}", "{\"n\": 2865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4189870357513428}", "{\"n\": 2866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.86, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4422428607940674}", "{\"n\": 2867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.85, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4132816791534424}", "{\"n\": 2868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.87, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4123573303222656}", "{\"n\": 2869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.74, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.414125680923462}", "{\"n\": 2870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.71, \"learn_time_ms\": 4.537, \"total_train_time_s\": 1.4148619174957275}", "{\"n\": 2871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.62, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4028398990631104}", "{\"n\": 2872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.74, \"learn_time_ms\": 4.543, \"total_train_time_s\": 1.4086134433746338}", "{\"n\": 2873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.74, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4259190559387207}", "{\"n\": 2874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.74, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4253005981445312}", "{\"n\": 2875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.66, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4222331047058105}", "{\"n\": 2876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.5192036628723145}", "{\"n\": 2877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.71, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4272048473358154}", "{\"n\": 2878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.441849708557129}", "{\"n\": 2879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.82, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4358162879943848}", "{\"n\": 2880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.36, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4155430793762207}", "{\"n\": 2881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.36, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4159400463104248}", "{\"n\": 2882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4186465740203857}", "{\"n\": 2883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4114928245544434}", "{\"n\": 2884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.6, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.3830106258392334}", "{\"n\": 2885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4473986625671387}", "{\"n\": 2886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.13, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4217212200164795}", "{\"n\": 2887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.75, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4207096099853516}", "{\"n\": 2888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.85, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4210519790649414}", "{\"n\": 2889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.74, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.39955735206604}", "{\"n\": 2890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.67, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4240469932556152}", "{\"n\": 2891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.96, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4228119850158691}", "{\"n\": 2892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4391756057739258}", "{\"n\": 2893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.68, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.3980140686035156}", "{\"n\": 2894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.47, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4453792572021484}", "{\"n\": 2895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.32, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4141695499420166}", "{\"n\": 2896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4189043045043945}", "{\"n\": 2897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.4, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4033105373382568}", "{\"n\": 2898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.29, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4095244407653809}", "{\"n\": 2899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.35, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4218780994415283}", "{\"n\": 2900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.31, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.414473533630371}", "{\"n\": 2901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.53, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4134066104888916}", "{\"n\": 2902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.43, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.415787935256958}", "{\"n\": 2903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4471898078918457}", "{\"n\": 2904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.4, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4075958728790283}", "{\"n\": 2905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.32, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.413200855255127}", "{\"n\": 2906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.37, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4270892143249512}", "{\"n\": 2907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.52, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4219210147857666}", "{\"n\": 2908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.69, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4115755558013916}", "{\"n\": 2909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.55, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4181311130523682}", "{\"n\": 2910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.69, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4122235774993896}", "{\"n\": 2911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.412473201751709}", "{\"n\": 2912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.63, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4153540134429932}", "{\"n\": 2913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.545, \"total_train_time_s\": 1.4048206806182861}", "{\"n\": 2914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4126160144805908}", "{\"n\": 2915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.522, \"total_train_time_s\": 1.412132978439331}", "{\"n\": 2916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.446239948272705}", "{\"n\": 2917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.4401485919952393}", "{\"n\": 2918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4467339515686035}", "{\"n\": 2919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.3966410160064697}", "{\"n\": 2920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4199800491333008}", "{\"n\": 2921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.81, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.415497064590454}", "{\"n\": 2922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.65, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4212160110473633}", "{\"n\": 2923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.43, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4297075271606445}", "{\"n\": 2924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.55, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4367997646331787}", "{\"n\": 2925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.4, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4583020210266113}", "{\"n\": 2926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.56, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4289884567260742}", "{\"n\": 2927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4385333061218262}", "{\"n\": 2928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.502, \"total_train_time_s\": 1.424755573272705}", "{\"n\": 2929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.92, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4312825202941895}", "{\"n\": 2930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.525, \"total_train_time_s\": 1.460296869277954}", "{\"n\": 2931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.4156906604766846}", "{\"n\": 2932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.07, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4114654064178467}", "{\"n\": 2933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4575023651123047}", "{\"n\": 2934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.21, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4051809310913086}", "{\"n\": 2935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.11, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4277093410491943}", "{\"n\": 2936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.23, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.4099833965301514}", "{\"n\": 2937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4108757972717285}", "{\"n\": 2938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4185702800750732}", "{\"n\": 2939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4346604347229004}", "{\"n\": 2940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.41, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4481549263000488}", "{\"n\": 2941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.32, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4067342281341553}", "{\"n\": 2942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.47, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.411059856414795}", "{\"n\": 2943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.5, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4303309917449951}", "{\"n\": 2944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.92, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.404554843902588}", "{\"n\": 2945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.39, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4372236728668213}", "{\"n\": 2946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.24, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.424891471862793}", "{\"n\": 2947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.27, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4040539264678955}", "{\"n\": 2948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.66, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4491724967956543}", "{\"n\": 2949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.83, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.3896219730377197}", "{\"n\": 2950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.61, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.3943750858306885}", "{\"n\": 2951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.77, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.405881643295288}", "{\"n\": 2952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.77, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4043493270874023}", "{\"n\": 2953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.71, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4226043224334717}", "{\"n\": 2954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.27, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4147958755493164}", "{\"n\": 2955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.85, \"learn_time_ms\": 4.239, \"total_train_time_s\": 1.4127061367034912}", "{\"n\": 2956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.85, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4122521877288818}", "{\"n\": 2957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4281744956970215}", "{\"n\": 2958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.84, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.389500379562378}", "{\"n\": 2959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.73, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.69036865234375}", "{\"n\": 2960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.73, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.3978791236877441}", "{\"n\": 2961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.27, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4586801528930664}", "{\"n\": 2962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.26, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4063878059387207}", "{\"n\": 2963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3997867107391357}", "{\"n\": 2964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.3946466445922852}", "{\"n\": 2965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.81, \"learn_time_ms\": 4.544, \"total_train_time_s\": 1.4398064613342285}", "{\"n\": 2966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4020683765411377}", "{\"n\": 2967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4496424198150635}", "{\"n\": 2968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.3988173007965088}", "{\"n\": 2969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.99, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4392225742340088}", "{\"n\": 2970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4380743503570557}", "{\"n\": 2971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.15, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4215288162231445}", "{\"n\": 2972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.15, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.3923983573913574}", "{\"n\": 2973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4174041748046875}", "{\"n\": 2974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.3999333381652832}", "{\"n\": 2975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4095745086669922}", "{\"n\": 2976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.419564962387085}", "{\"n\": 2977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.25, \"learn_time_ms\": 4.187, \"total_train_time_s\": 1.4273207187652588}", "{\"n\": 2978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.43, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.3865454196929932}", "{\"n\": 2979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4253261089324951}", "{\"n\": 2980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.3993744850158691}", "{\"n\": 2981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.28, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4396905899047852}", "{\"n\": 2982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.19, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.430619716644287}", "{\"n\": 2983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.08, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4203546047210693}", "{\"n\": 2984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.08, \"learn_time_ms\": 4.544, \"total_train_time_s\": 1.4189305305480957}", "{\"n\": 2985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.08, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4372000694274902}", "{\"n\": 2986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4295833110809326}", "{\"n\": 2987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4203717708587646}", "{\"n\": 2988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.27, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4076869487762451}", "{\"n\": 2989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.41, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.413996696472168}", "{\"n\": 2990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.68, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4345033168792725}", "{\"n\": 2991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4045403003692627}", "{\"n\": 2992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4142210483551025}", "{\"n\": 2993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.56, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4219608306884766}", "{\"n\": 2994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.73, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4017236232757568}", "{\"n\": 2995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4128642082214355}", "{\"n\": 2996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.66, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.3806915283203125}", "{\"n\": 2997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.61, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4428980350494385}", "{\"n\": 2998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.69, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4040942192077637}", "{\"n\": 2999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.77, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.3988089561462402}", "{\"n\": 3000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.77, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.394136905670166}", "{\"n\": 3001, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.61, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4174859523773193}", "{\"n\": 3002, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.6, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4062309265136719}", "{\"n\": 3003, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.81, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.419823169708252}", "{\"n\": 3004, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4257783889770508}", "{\"n\": 3005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4084482192993164}", "{\"n\": 3006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4218096733093262}", "{\"n\": 3007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.81, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4263129234313965}", "{\"n\": 3008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.71, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4022753238677979}", "{\"n\": 3009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.507, \"total_train_time_s\": 1.4416241645812988}", "{\"n\": 3010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4362943172454834}", "{\"n\": 3011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.186, \"total_train_time_s\": 1.4071905612945557}", "{\"n\": 3012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.94, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.416853427886963}", "{\"n\": 3013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.1, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4293947219848633}", "{\"n\": 3014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.410630464553833}", "{\"n\": 3015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.07, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4327309131622314}", "{\"n\": 3016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4167532920837402}", "{\"n\": 3017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4123997688293457}", "{\"n\": 3018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.87, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.433239221572876}", "{\"n\": 3019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.79, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.408947229385376}", "{\"n\": 3020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.96, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.3985648155212402}", "{\"n\": 3021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.443019151687622}", "{\"n\": 3022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.402101993560791}", "{\"n\": 3023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.66, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4247260093688965}", "{\"n\": 3024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.49, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4196979999542236}", "{\"n\": 3025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.38, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.41727614402771}", "{\"n\": 3026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.44, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3986637592315674}", "{\"n\": 3027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.05, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4191107749938965}", "{\"n\": 3028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4134907722473145}", "{\"n\": 3029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.3953626155853271}", "{\"n\": 3030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.94, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4284825325012207}", "{\"n\": 3031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.04, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4095571041107178}", "{\"n\": 3032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4179651737213135}", "{\"n\": 3033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4111146926879883}", "{\"n\": 3034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4149107933044434}", "{\"n\": 3035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.68, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.428401231765747}", "{\"n\": 3036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.68, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3982634544372559}", "{\"n\": 3037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.64, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.42134428024292}", "{\"n\": 3038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4083209037780762}", "{\"n\": 3039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.98, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4422378540039062}", "{\"n\": 3040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.395045518875122}", "{\"n\": 3041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.40596342086792}", "{\"n\": 3042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.46, \"learn_time_ms\": 4.539, \"total_train_time_s\": 1.4341211318969727}", "{\"n\": 3043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.3, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4157564640045166}", "{\"n\": 3044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.8, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4142389297485352}", "{\"n\": 3045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.8, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3986828327178955}", "{\"n\": 3046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.34, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4027843475341797}", "{\"n\": 3047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.48, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4381654262542725}", "{\"n\": 3048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.36, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4295988082885742}", "{\"n\": 3049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.3949623107910156}", "{\"n\": 3050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.47, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4288341999053955}", "{\"n\": 3051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.76, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4197893142700195}", "{\"n\": 3052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.66, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4008774757385254}", "{\"n\": 3053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.17, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.408571481704712}", "{\"n\": 3054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.33, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4222965240478516}", "{\"n\": 3055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.441112756729126}", "{\"n\": 3056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.33, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4131419658660889}", "{\"n\": 3057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.27, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4416441917419434}", "{\"n\": 3058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4138858318328857}", "{\"n\": 3059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4226219654083252}", "{\"n\": 3060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4123308658599854}", "{\"n\": 3061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.3, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4173216819763184}", "{\"n\": 3062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.05, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4045004844665527}", "{\"n\": 3063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.05, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4111921787261963}", "{\"n\": 3064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.33, \"learn_time_ms\": 4.232, \"total_train_time_s\": 1.4275717735290527}", "{\"n\": 3065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.48, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4299890995025635}", "{\"n\": 3066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.45, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.437436819076538}", "{\"n\": 3067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.45, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4030520915985107}", "{\"n\": 3068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.63, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.44881010055542}", "{\"n\": 3069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.62, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4172120094299316}", "{\"n\": 3070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.38, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4252634048461914}", "{\"n\": 3071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.38, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4104242324829102}", "{\"n\": 3072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.32, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4279990196228027}", "{\"n\": 3073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.22, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4366087913513184}", "{\"n\": 3074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4276340007781982}", "{\"n\": 3075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.446544885635376}", "{\"n\": 3076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.19, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.436418056488037}", "{\"n\": 3077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.19, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4104859828948975}", "{\"n\": 3078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.15, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4079594612121582}", "{\"n\": 3079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.15, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4079809188842773}", "{\"n\": 3080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.2, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4379239082336426}", "{\"n\": 3081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.2, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4246389865875244}", "{\"n\": 3082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.4247932434082031}", "{\"n\": 3083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4102380275726318}", "{\"n\": 3084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4936180114746094}", "{\"n\": 3085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.92, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.439009189605713}", "{\"n\": 3086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.516, \"total_train_time_s\": 1.4346940517425537}", "{\"n\": 3087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4469928741455078}", "{\"n\": 3088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4136290550231934}", "{\"n\": 3089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.04, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4032702445983887}", "{\"n\": 3090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.07, \"learn_time_ms\": 4.199, \"total_train_time_s\": 1.419424295425415}", "{\"n\": 3091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.07, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4069180488586426}", "{\"n\": 3092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.82, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4156358242034912}", "{\"n\": 3093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4272820949554443}", "{\"n\": 3094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.26, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.402111530303955}", "{\"n\": 3095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.26, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4172861576080322}", "{\"n\": 3096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.26, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4045050144195557}", "{\"n\": 3097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.42, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.429276704788208}", "{\"n\": 3098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.44, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4283630847930908}", "{\"n\": 3099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.44, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4169278144836426}", "{\"n\": 3100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.28, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.425689458847046}", "{\"n\": 3101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.95, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4203107357025146}", "{\"n\": 3102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.95, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.453303575515747}", "{\"n\": 3103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.95, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4170849323272705}", "{\"n\": 3104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.21, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4289472103118896}", "{\"n\": 3105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.38, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4107575416564941}", "{\"n\": 3106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.32, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4122331142425537}", "{\"n\": 3107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.32, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.406540870666504}", "{\"n\": 3108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.17, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4242141246795654}", "{\"n\": 3109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.4437825679779053}", "{\"n\": 3110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.41, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4300761222839355}", "{\"n\": 3111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.41, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4450838565826416}", "{\"n\": 3112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.42, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4027159214019775}", "{\"n\": 3113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.62, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4226038455963135}", "{\"n\": 3114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.6, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4280688762664795}", "{\"n\": 3115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.6, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.406480073928833}", "{\"n\": 3116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.48, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4016661643981934}", "{\"n\": 3117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.48, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.406001329421997}", "{\"n\": 3118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.37, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4117841720581055}", "{\"n\": 3119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.37, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4162640571594238}", "{\"n\": 3120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4313535690307617}", "{\"n\": 3121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.47, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4234697818756104}", "{\"n\": 3122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.7, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4148163795471191}", "{\"n\": 3123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.7, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.3698992729187012}", "{\"n\": 3124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.01, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4178342819213867}", "{\"n\": 3125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.88, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4291863441467285}", "{\"n\": 3126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.97, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.41367769241333}", "{\"n\": 3127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.97, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4099698066711426}", "{\"n\": 3128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.17, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.3911149501800537}", "{\"n\": 3129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.52, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4330315589904785}", "{\"n\": 3130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.59, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.40445876121521}", "{\"n\": 3131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.59, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.3974189758300781}", "{\"n\": 3132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.42677640914917}", "{\"n\": 3133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.54, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4507551193237305}", "{\"n\": 3134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.35, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4135215282440186}", "{\"n\": 3135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.35, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3932814598083496}", "{\"n\": 3136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.26, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.4385755062103271}", "{\"n\": 3137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4272809028625488}", "{\"n\": 3138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4503719806671143}", "{\"n\": 3139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4104719161987305}", "{\"n\": 3140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.41074800491333}", "{\"n\": 3141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4180269241333008}", "{\"n\": 3142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.81, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4310226440429688}", "{\"n\": 3143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.81, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4096612930297852}", "{\"n\": 3144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.59, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4422814846038818}", "{\"n\": 3145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.02, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.411970615386963}", "{\"n\": 3146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.421339750289917}", "{\"n\": 3147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4159760475158691}", "{\"n\": 3148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4119477272033691}", "{\"n\": 3149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.56, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4288239479064941}", "{\"n\": 3150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.427405595779419}", "{\"n\": 3151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4090216159820557}", "{\"n\": 3152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4109172821044922}", "{\"n\": 3153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.45, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4412634372711182}", "{\"n\": 3154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4393234252929688}", "{\"n\": 3155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.391143560409546}", "{\"n\": 3156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3931875228881836}", "{\"n\": 3157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.448613166809082}", "{\"n\": 3158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4227204322814941}", "{\"n\": 3159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.19, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.422940969467163}", "{\"n\": 3160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.19, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.412118673324585}", "{\"n\": 3161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.1, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4551987648010254}", "{\"n\": 3162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.1, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4227237701416016}", "{\"n\": 3163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.46, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.409980297088623}", "{\"n\": 3164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.46, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.414930820465088}", "{\"n\": 3165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.83, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4349517822265625}", "{\"n\": 3166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.36, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.3964755535125732}", "{\"n\": 3167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4425535202026367}", "{\"n\": 3168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.72, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.4250953197479248}", "{\"n\": 3169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.73, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.434497594833374}", "{\"n\": 3170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.75, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4032413959503174}", "{\"n\": 3171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.68, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4008684158325195}", "{\"n\": 3172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.68, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.397961139678955}", "{\"n\": 3173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.3973894119262695}", "{\"n\": 3174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.08, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.455918788909912}", "{\"n\": 3175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.26, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4007792472839355}", "{\"n\": 3176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.26, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.402853012084961}", "{\"n\": 3177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.01, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4212462902069092}", "{\"n\": 3178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.64, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.430180549621582}", "{\"n\": 3179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.62, \"learn_time_ms\": 4.233, \"total_train_time_s\": 1.4217896461486816}", "{\"n\": 3180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.62, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3849565982818604}", "{\"n\": 3181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.19, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4132540225982666}", "{\"n\": 3182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.99, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4255988597869873}", "{\"n\": 3183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.38, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.4071617126464844}", "{\"n\": 3184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.38, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4159317016601562}", "{\"n\": 3185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.33, \"learn_time_ms\": 4.51, \"total_train_time_s\": 1.4332616329193115}", "{\"n\": 3186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.18, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.459425926208496}", "{\"n\": 3187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.42201566696167}", "{\"n\": 3188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.221, \"total_train_time_s\": 1.4236171245574951}", "{\"n\": 3189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4205386638641357}", "{\"n\": 3190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.45, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4604761600494385}", "{\"n\": 3191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4227118492126465}", "{\"n\": 3192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.5165488719940186}", "{\"n\": 3193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.17, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4098231792449951}", "{\"n\": 3194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.3, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4121181964874268}", "{\"n\": 3195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.23, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4196529388427734}", "{\"n\": 3196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.23, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4119596481323242}", "{\"n\": 3197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.23, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.404327392578125}", "{\"n\": 3198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1039.7, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4350237846374512}", "{\"n\": 3199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.2, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4113271236419678}", "{\"n\": 3200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.2, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4180524349212646}", "{\"n\": 3201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.2, \"learn_time_ms\": 4.541, \"total_train_time_s\": 1.3948512077331543}", "{\"n\": 3202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.21, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4222285747528076}", "{\"n\": 3203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.46, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4402928352355957}", "{\"n\": 3204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.46, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4227728843688965}", "{\"n\": 3205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.46, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4069421291351318}", "{\"n\": 3206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.28, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4081027507781982}", "{\"n\": 3207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4201736450195312}", "{\"n\": 3208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4286770820617676}", "{\"n\": 3209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4100759029388428}", "{\"n\": 3210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.462754487991333}", "{\"n\": 3211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.450610637664795}", "{\"n\": 3212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4257378578186035}", "{\"n\": 3213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4086472988128662}", "{\"n\": 3214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.04, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4297089576721191}", "{\"n\": 3215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4194164276123047}", "{\"n\": 3216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4189889430999756}", "{\"n\": 3217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.413172721862793}", "{\"n\": 3218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1037.96, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4504175186157227}", "{\"n\": 3219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.02, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4533002376556396}", "{\"n\": 3220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.05, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.419999599456787}", "{\"n\": 3221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.05, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.419205665588379}", "{\"n\": 3222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.79, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4464774131774902}", "{\"n\": 3223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.59, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4293458461761475}", "{\"n\": 3224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.29, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.4217212200164795}", "{\"n\": 3225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.29, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4147553443908691}", "{\"n\": 3226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.22, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4102497100830078}", "{\"n\": 3227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.43, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4275898933410645}", "{\"n\": 3228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.46, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4263408184051514}", "{\"n\": 3229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.46, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4047350883483887}", "{\"n\": 3230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.14, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4023492336273193}", "{\"n\": 3231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.17, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4319264888763428}", "{\"n\": 3232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.04, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4293811321258545}", "{\"n\": 3233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.04, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.397200584411621}", "{\"n\": 3234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.04, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.386537790298462}", "{\"n\": 3235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.63, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.4274678230285645}", "{\"n\": 3236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.55, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4264864921569824}", "{\"n\": 3237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.55, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4165420532226562}", "{\"n\": 3238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.66, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4018805027008057}", "{\"n\": 3239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.72, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4346580505371094}", "{\"n\": 3240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.58, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4054734706878662}", "{\"n\": 3241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.29, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.437800645828247}", "{\"n\": 3242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.37, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3986966609954834}", "{\"n\": 3243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1046.1, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.423330545425415}", "{\"n\": 3244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.46, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4040837287902832}", "{\"n\": 3245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1050.09, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4273123741149902}", "{\"n\": 3246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1049.3, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.440800428390503}", "{\"n\": 3247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1049.47, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4106171131134033}", "{\"n\": 3248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1049.53, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4138972759246826}", "{\"n\": 3249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.72, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4260978698730469}", "{\"n\": 3250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.71, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4134397506713867}", "{\"n\": 3251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.77, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4076869487762451}", "{\"n\": 3252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.83, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.3873491287231445}", "{\"n\": 3253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.99, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4242889881134033}", "{\"n\": 3254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.82, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4147148132324219}", "{\"n\": 3255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1047.87, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4113991260528564}", "{\"n\": 3256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1047.9, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.456071138381958}", "{\"n\": 3257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.08, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4010734558105469}", "{\"n\": 3258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.02, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4220411777496338}", "{\"n\": 3259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1047.97, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.3870079517364502}", "{\"n\": 3260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1047.9, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4067246913909912}", "{\"n\": 3261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1048.14, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.425365924835205}", "{\"n\": 3262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1047.53, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4083223342895508}", "{\"n\": 3263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1046.69, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4136130809783936}", "{\"n\": 3264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1046.24, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.414750337600708}", "{\"n\": 3265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.07, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4006226062774658}", "{\"n\": 3266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.25, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4163272380828857}", "{\"n\": 3267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.3, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4060351848602295}", "{\"n\": 3268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1045.1, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4199981689453125}", "{\"n\": 3269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1044.91, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4104857444763184}", "{\"n\": 3270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1044.81, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4076273441314697}", "{\"n\": 3271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1044.71, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4233477115631104}", "{\"n\": 3272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.81, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.4374797344207764}", "{\"n\": 3273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.81, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4281244277954102}", "{\"n\": 3274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.8, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.451754093170166}", "{\"n\": 3275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.8, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.425210952758789}", "{\"n\": 3276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.72, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4146852493286133}", "{\"n\": 3277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1043.67, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.3990285396575928}", "{\"n\": 3278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.03, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.425184726715088}", "{\"n\": 3279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.03, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.415649175643921}", "{\"n\": 3280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.2, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4432382583618164}", "{\"n\": 3281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1042.15, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4366936683654785}", "{\"n\": 3282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.39, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4557404518127441}", "{\"n\": 3283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.39, \"learn_time_ms\": 4.552, \"total_train_time_s\": 1.414444923400879}", "{\"n\": 3284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.35, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.444904088973999}", "{\"n\": 3285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.28, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.447383165359497}", "{\"n\": 3286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.38, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4192132949829102}", "{\"n\": 3287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.38, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.3987219333648682}", "{\"n\": 3288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.21, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.3931889533996582}", "{\"n\": 3289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.31, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4118499755859375}", "{\"n\": 3290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.11, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4179866313934326}", "{\"n\": 3291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1041.11, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.428600549697876}", "{\"n\": 3292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.84, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4317753314971924}", "{\"n\": 3293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1040.01, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4392039775848389}", "{\"n\": 3294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.431767463684082}", "{\"n\": 3295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4102933406829834}", "{\"n\": 3296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4115490913391113}", "{\"n\": 3297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.52, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.414050817489624}", "{\"n\": 3298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.62, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4140279293060303}", "{\"n\": 3299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.62, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.389009952545166}", "{\"n\": 3300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.11, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.537191390991211}", "{\"n\": 3301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.18, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4052190780639648}", "{\"n\": 3302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.380159854888916}", "{\"n\": 3303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.3899013996124268}", "{\"n\": 3304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.36, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4072685241699219}", "{\"n\": 3305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4099795818328857}", "{\"n\": 3306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4218406677246094}", "{\"n\": 3307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.408752202987671}", "{\"n\": 3308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4117884635925293}", "{\"n\": 3309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.03, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4355659484863281}", "{\"n\": 3310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4352693557739258}", "{\"n\": 3311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.439065933227539}", "{\"n\": 3312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4210865497589111}", "{\"n\": 3313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.426314115524292}", "{\"n\": 3314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4464235305786133}", "{\"n\": 3315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.226, \"total_train_time_s\": 1.4074485301971436}", "{\"n\": 3316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.49, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4305968284606934}", "{\"n\": 3317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.48, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4201714992523193}", "{\"n\": 3318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.89, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4157989025115967}", "{\"n\": 3319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.89, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4043006896972656}", "{\"n\": 3320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.77, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4177451133728027}", "{\"n\": 3321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.77, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4169096946716309}", "{\"n\": 3322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.442366123199463}", "{\"n\": 3323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.394542932510376}", "{\"n\": 3324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.4, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4422950744628906}", "{\"n\": 3325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.4, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.3923251628875732}", "{\"n\": 3326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.43495774269104}", "{\"n\": 3327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.34, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.4250378608703613}", "{\"n\": 3328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4503018856048584}", "{\"n\": 3329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.3876867294311523}", "{\"n\": 3330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.55, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4386634826660156}", "{\"n\": 3331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.55, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4146382808685303}", "{\"n\": 3332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4435820579528809}", "{\"n\": 3333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4003264904022217}", "{\"n\": 3334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.68, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4176592826843262}", "{\"n\": 3335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.68, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4075472354888916}", "{\"n\": 3336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.75, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4647855758666992}", "{\"n\": 3337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.75, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4095427989959717}", "{\"n\": 3338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.18, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4313859939575195}", "{\"n\": 3339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.18, \"learn_time_ms\": 4.513, \"total_train_time_s\": 1.4147143363952637}", "{\"n\": 3340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4293413162231445}", "{\"n\": 3341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.430065393447876}", "{\"n\": 3342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.94, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4446494579315186}", "{\"n\": 3343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.94, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3669888973236084}", "{\"n\": 3344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.36, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.4180352687835693}", "{\"n\": 3345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.68, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.440516471862793}", "{\"n\": 3346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.42, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4190905094146729}", "{\"n\": 3347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.42, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.3924124240875244}", "{\"n\": 3348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.26, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4105806350708008}", "{\"n\": 3349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.03, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4456415176391602}", "{\"n\": 3350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.19, \"learn_time_ms\": 4.516, \"total_train_time_s\": 1.4257006645202637}", "{\"n\": 3351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.19, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.3931074142456055}", "{\"n\": 3352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.5, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4217135906219482}", "{\"n\": 3353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.21, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.431685209274292}", "{\"n\": 3354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.57, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.442469835281372}", "{\"n\": 3355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.57, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.3894736766815186}", "{\"n\": 3356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.64, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.449841022491455}", "{\"n\": 3357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.57, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4226770401000977}", "{\"n\": 3358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.67, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.4298300743103027}", "{\"n\": 3359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.67, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.411153793334961}", "{\"n\": 3360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.84, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4127755165100098}", "{\"n\": 3361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.86, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4041411876678467}", "{\"n\": 3362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.7, \"learn_time_ms\": 4.538, \"total_train_time_s\": 1.4595541954040527}", "{\"n\": 3363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.7, \"learn_time_ms\": 4.508, \"total_train_time_s\": 1.4269721508026123}", "{\"n\": 3364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.74, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4094328880310059}", "{\"n\": 3365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.82, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4166457653045654}", "{\"n\": 3366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.99, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4010307788848877}", "{\"n\": 3367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.99, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4042561054229736}", "{\"n\": 3368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.74, \"learn_time_ms\": 4.521, \"total_train_time_s\": 1.4149665832519531}", "{\"n\": 3369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.242, \"total_train_time_s\": 1.4143834114074707}", "{\"n\": 3370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4210295677185059}", "{\"n\": 3371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4297924041748047}", "{\"n\": 3372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.17, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4175853729248047}", "{\"n\": 3373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4350719451904297}", "{\"n\": 3374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4016952514648438}", "{\"n\": 3375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4166579246520996}", "{\"n\": 3376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.09, \"learn_time_ms\": 4.171, \"total_train_time_s\": 1.4247167110443115}", "{\"n\": 3377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.12, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.3892838954925537}", "{\"n\": 3378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4264962673187256}", "{\"n\": 3379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3815736770629883}", "{\"n\": 3380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4380958080291748}", "{\"n\": 3381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.05, \"learn_time_ms\": 4.631, \"total_train_time_s\": 1.7086434364318848}", "{\"n\": 3382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.4230492115020752}", "{\"n\": 3383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4004290103912354}", "{\"n\": 3384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3998427391052246}", "{\"n\": 3385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.414499044418335}", "{\"n\": 3386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.42, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.400968074798584}", "{\"n\": 3387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.42, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4234025478363037}", "{\"n\": 3388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4186313152313232}", "{\"n\": 3389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.46, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4089467525482178}", "{\"n\": 3390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.417881965637207}", "{\"n\": 3391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.383286952972412}", "{\"n\": 3392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.07, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3982396125793457}", "{\"n\": 3393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.14, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.404378890991211}", "{\"n\": 3394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4073193073272705}", "{\"n\": 3395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4261019229888916}", "{\"n\": 3396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4439480304718018}", "{\"n\": 3397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.46, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4123589992523193}", "{\"n\": 3398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4200749397277832}", "{\"n\": 3399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.86, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4198832511901855}", "{\"n\": 3400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.79, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4231350421905518}", "{\"n\": 3401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.62, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4120478630065918}", "{\"n\": 3402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4306159019470215}", "{\"n\": 3403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.403921127319336}", "{\"n\": 3404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.18, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.427295207977295}", "{\"n\": 3405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4396812915802002}", "{\"n\": 3406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.31, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4085676670074463}", "{\"n\": 3407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.508, \"total_train_time_s\": 1.4178690910339355}", "{\"n\": 3408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4059202671051025}", "{\"n\": 3409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.31, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4421610832214355}", "{\"n\": 3410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.42, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.427309274673462}", "{\"n\": 3411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.42, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.3856086730957031}", "{\"n\": 3412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.502, \"total_train_time_s\": 1.4537019729614258}", "{\"n\": 3413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4125969409942627}", "{\"n\": 3414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4343180656433105}", "{\"n\": 3415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4161453247070312}", "{\"n\": 3416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4083566665649414}", "{\"n\": 3417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.6, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4217162132263184}", "{\"n\": 3418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4178273677825928}", "{\"n\": 3419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4214563369750977}", "{\"n\": 3420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4077186584472656}", "{\"n\": 3421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.403813123703003}", "{\"n\": 3422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.24, \"learn_time_ms\": 4.525, \"total_train_time_s\": 1.4172728061676025}", "{\"n\": 3423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.415466547012329}", "{\"n\": 3424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4101555347442627}", "{\"n\": 3425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4002535343170166}", "{\"n\": 3426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.25, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4298226833343506}", "{\"n\": 3427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.501, \"total_train_time_s\": 1.4073054790496826}", "{\"n\": 3428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4288785457611084}", "{\"n\": 3429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4127626419067383}", "{\"n\": 3430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.06, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.455371618270874}", "{\"n\": 3431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.92, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.417240858078003}", "{\"n\": 3432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.92, \"learn_time_ms\": 4.551, \"total_train_time_s\": 1.4476897716522217}", "{\"n\": 3433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.17, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4364547729492188}", "{\"n\": 3434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4120535850524902}", "{\"n\": 3435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.41, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4046154022216797}", "{\"n\": 3436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.41, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4049806594848633}", "{\"n\": 3437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.67, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4005441665649414}", "{\"n\": 3438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4309024810791016}", "{\"n\": 3439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4112248420715332}", "{\"n\": 3440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.38, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3942532539367676}", "{\"n\": 3441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4456682205200195}", "{\"n\": 3442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.48, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4143805503845215}", "{\"n\": 3443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.65, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4042003154754639}", "{\"n\": 3444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.65, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4089744091033936}", "{\"n\": 3445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.82, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4214746952056885}", "{\"n\": 3446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.81, \"learn_time_ms\": 4.228, \"total_train_time_s\": 1.42452073097229}", "{\"n\": 3447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.77, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4031364917755127}", "{\"n\": 3448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.77, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3875212669372559}", "{\"n\": 3449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.2, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4303405284881592}", "{\"n\": 3450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.18, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4243464469909668}", "{\"n\": 3451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.89, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4314401149749756}", "{\"n\": 3452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.89, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.379361629486084}", "{\"n\": 3453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.09, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.418893575668335}", "{\"n\": 3454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.97, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4161913394927979}", "{\"n\": 3455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.89, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4186720848083496}", "{\"n\": 3456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.89, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4075291156768799}", "{\"n\": 3457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.89, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4358618259429932}", "{\"n\": 3458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.78, \"learn_time_ms\": 4.576, \"total_train_time_s\": 1.4346752166748047}", "{\"n\": 3459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.55, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4389588832855225}", "{\"n\": 3460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.55, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.3888897895812988}", "{\"n\": 3461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.57, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4265351295471191}", "{\"n\": 3462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.84, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.4129974842071533}", "{\"n\": 3463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.8, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.414327621459961}", "{\"n\": 3464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.8, \"learn_time_ms\": 4.572, \"total_train_time_s\": 1.4167416095733643}", "{\"n\": 3465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.8, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4325299263000488}", "{\"n\": 3466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.71, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4195375442504883}", "{\"n\": 3467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.83, \"learn_time_ms\": 4.541, \"total_train_time_s\": 1.4188315868377686}", "{\"n\": 3468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.83, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4292664527893066}", "{\"n\": 3469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.05, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.4311425685882568}", "{\"n\": 3470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.08, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4235005378723145}", "{\"n\": 3471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.94, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4206633567810059}", "{\"n\": 3472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.94, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.402254343032837}", "{\"n\": 3473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.89, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4106378555297852}", "{\"n\": 3474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.87, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4209346771240234}", "{\"n\": 3475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.97, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.3916006088256836}", "{\"n\": 3476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.97, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.3996598720550537}", "{\"n\": 3477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.87, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4455502033233643}", "{\"n\": 3478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.91, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4145021438598633}", "{\"n\": 3479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.38, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4393000602722168}", "{\"n\": 3480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.38, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4081175327301025}", "{\"n\": 3481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.21, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4075915813446045}", "{\"n\": 3482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.0, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4024813175201416}", "{\"n\": 3483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.0, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.41495943069458}", "{\"n\": 3484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.01, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.3985707759857178}", "{\"n\": 3485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.11, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4167497158050537}", "{\"n\": 3486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.22, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4556725025177002}", "{\"n\": 3487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.22, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4204466342926025}", "{\"n\": 3488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.18, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4135022163391113}", "{\"n\": 3489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.21, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.423628807067871}", "{\"n\": 3490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.22, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.3970286846160889}", "{\"n\": 3491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.22, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.425060510635376}", "{\"n\": 3492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.23, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3933205604553223}", "{\"n\": 3493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.24, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.429948329925537}", "{\"n\": 3494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.08, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.445066213607788}", "{\"n\": 3495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.08, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.414811611175537}", "{\"n\": 3496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.98, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4028737545013428}", "{\"n\": 3497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.86, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4490511417388916}", "{\"n\": 3498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.35, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.433821439743042}", "{\"n\": 3499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.35, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4378423690795898}", "{\"n\": 3500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.59, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4252476692199707}", "{\"n\": 3501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4097449779510498}", "{\"n\": 3502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.35, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.425807237625122}", "{\"n\": 3503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.35, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.3862218856811523}", "{\"n\": 3504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.5281469821929932}", "{\"n\": 3505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.4150772094726562}", "{\"n\": 3506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.89, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4433629512786865}", "{\"n\": 3507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.96, \"learn_time_ms\": 4.549, \"total_train_time_s\": 1.4462921619415283}", "{\"n\": 3508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4226324558258057}", "{\"n\": 3509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4071369171142578}", "{\"n\": 3510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4505054950714111}", "{\"n\": 3511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4230170249938965}", "{\"n\": 3512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4142863750457764}", "{\"n\": 3513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4193127155303955}", "{\"n\": 3514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4185478687286377}", "{\"n\": 3515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.19, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4047119617462158}", "{\"n\": 3516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.01, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4134783744812012}", "{\"n\": 3517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.01, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.388601541519165}", "{\"n\": 3518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.09, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.406566858291626}", "{\"n\": 3519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.420285940170288}", "{\"n\": 3520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4228923320770264}", "{\"n\": 3521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.3827180862426758}", "{\"n\": 3522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4218528270721436}", "{\"n\": 3523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4501159191131592}", "{\"n\": 3524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4308688640594482}", "{\"n\": 3525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4177322387695312}", "{\"n\": 3526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.95, \"learn_time_ms\": 4.237, \"total_train_time_s\": 1.3862404823303223}", "{\"n\": 3527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.03, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4170610904693604}", "{\"n\": 3528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.427685260772705}", "{\"n\": 3529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.3859310150146484}", "{\"n\": 3530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4186031818389893}", "{\"n\": 3531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.14, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.434149980545044}", "{\"n\": 3532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.26, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4125921726226807}", "{\"n\": 3533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.26, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.446190357208252}", "{\"n\": 3534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.2, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4046618938446045}", "{\"n\": 3535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.93, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4465432167053223}", "{\"n\": 3536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4107444286346436}", "{\"n\": 3537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.3922021389007568}", "{\"n\": 3538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.432112455368042}", "{\"n\": 3539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3944542407989502}", "{\"n\": 3540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 4.504, \"total_train_time_s\": 1.4461524486541748}", "{\"n\": 3541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4056618213653564}", "{\"n\": 3542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.16, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.4224772453308105}", "{\"n\": 3543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4306228160858154}", "{\"n\": 3544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4143412113189697}", "{\"n\": 3545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.409409761428833}", "{\"n\": 3546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4257824420928955}", "{\"n\": 3547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.84, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4221134185791016}", "{\"n\": 3548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.92, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4007234573364258}", "{\"n\": 3549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.92, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.3886103630065918}", "{\"n\": 3550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.78, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4091312885284424}", "{\"n\": 3551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.68, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.430654525756836}", "{\"n\": 3552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4158928394317627}", "{\"n\": 3553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.424060583114624}", "{\"n\": 3554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.51, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4283335208892822}", "{\"n\": 3555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.56, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.440788745880127}", "{\"n\": 3556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4357380867004395}", "{\"n\": 3557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4497461318969727}", "{\"n\": 3558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.38, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.414172887802124}", "{\"n\": 3559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4226398468017578}", "{\"n\": 3560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.67, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4117286205291748}", "{\"n\": 3561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.67, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4037566184997559}", "{\"n\": 3562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.61, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4170410633087158}", "{\"n\": 3563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.34, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4355742931365967}", "{\"n\": 3564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4338853359222412}", "{\"n\": 3565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4257383346557617}", "{\"n\": 3566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.02, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4203567504882812}", "{\"n\": 3567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4480772018432617}", "{\"n\": 3568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4409878253936768}", "{\"n\": 3569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4274101257324219}", "{\"n\": 3570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.32, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.4143085479736328}", "{\"n\": 3571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.35, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.421792984008789}", "{\"n\": 3572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4219026565551758}", "{\"n\": 3573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.401496171951294}", "{\"n\": 3574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4409632682800293}", "{\"n\": 3575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.48, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.394449234008789}", "{\"n\": 3576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.44, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4493191242218018}", "{\"n\": 3577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.44, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.437709093093872}", "{\"n\": 3578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.18, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4334721565246582}", "{\"n\": 3579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.22, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4086461067199707}", "{\"n\": 3580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4402997493743896}", "{\"n\": 3581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4101901054382324}", "{\"n\": 3582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4188776016235352}", "{\"n\": 3583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.84, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4121119976043701}", "{\"n\": 3584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.4210968017578125}", "{\"n\": 3585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.3997714519500732}", "{\"n\": 3586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.04, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4243841171264648}", "{\"n\": 3587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.401066541671753}", "{\"n\": 3588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.85, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4120137691497803}", "{\"n\": 3589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.85, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4011294841766357}", "{\"n\": 3590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.82, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4124975204467773}", "{\"n\": 3591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.93, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.395923376083374}", "{\"n\": 3592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4133579730987549}", "{\"n\": 3593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3964126110076904}", "{\"n\": 3594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.05, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4246351718902588}", "{\"n\": 3595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.1, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4249026775360107}", "{\"n\": 3596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4083306789398193}", "{\"n\": 3597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.3998043537139893}", "{\"n\": 3598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.503, \"total_train_time_s\": 1.4569308757781982}", "{\"n\": 3599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4150640964508057}", "{\"n\": 3600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.17, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.3879363536834717}", "{\"n\": 3601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.17, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.3987576961517334}", "{\"n\": 3602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.62, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4109704494476318}", "{\"n\": 3603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.63, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4106056690216064}", "{\"n\": 3604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.7, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3905448913574219}", "{\"n\": 3605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.7, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.3995327949523926}", "{\"n\": 3606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.79, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4181714057922363}", "{\"n\": 3607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.89, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4065077304840088}", "{\"n\": 3608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.89, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.397536277770996}", "{\"n\": 3609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.84, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4357712268829346}", "{\"n\": 3610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.84, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4405288696289062}", "{\"n\": 3611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.21, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4337668418884277}", "{\"n\": 3612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.5288662910461426}", "{\"n\": 3613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.27, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4144999980926514}", "{\"n\": 3614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4224672317504883}", "{\"n\": 3615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4547748565673828}", "{\"n\": 3616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.32, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.422391414642334}", "{\"n\": 3617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4074676036834717}", "{\"n\": 3618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.18, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4259974956512451}", "{\"n\": 3619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.27, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.43393874168396}", "{\"n\": 3620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4031622409820557}", "{\"n\": 3621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.53, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.437821865081787}", "{\"n\": 3622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3988282680511475}", "{\"n\": 3623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.67, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4005775451660156}", "{\"n\": 3624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.407637119293213}", "{\"n\": 3625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.430100917816162}", "{\"n\": 3626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4107191562652588}", "{\"n\": 3627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.18, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.411743402481079}", "{\"n\": 3628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.8, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4138829708099365}", "{\"n\": 3629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.69, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.4330742359161377}", "{\"n\": 3630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.79, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4484493732452393}", "{\"n\": 3631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.89, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.438631534576416}", "{\"n\": 3632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.541, \"total_train_time_s\": 1.413635015487671}", "{\"n\": 3633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.73, \"learn_time_ms\": 4.245, \"total_train_time_s\": 1.4009082317352295}", "{\"n\": 3634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.73, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.386277198791504}", "{\"n\": 3635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4561951160430908}", "{\"n\": 3636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.417494773864746}", "{\"n\": 3637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.75, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.429847002029419}", "{\"n\": 3638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.75, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4096570014953613}", "{\"n\": 3639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.19, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.425074815750122}", "{\"n\": 3640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.19, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4286060333251953}", "{\"n\": 3641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.26, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4392075538635254}", "{\"n\": 3642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.26, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.425367832183838}", "{\"n\": 3643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.81, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4453489780426025}", "{\"n\": 3644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.81, \"learn_time_ms\": 4.51, \"total_train_time_s\": 1.39316725730896}", "{\"n\": 3645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.37, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.45357346534729}", "{\"n\": 3646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.37, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.388322114944458}", "{\"n\": 3647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4316296577453613}", "{\"n\": 3648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.164, \"total_train_time_s\": 1.423701286315918}", "{\"n\": 3649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4306755065917969}", "{\"n\": 3650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4065189361572266}", "{\"n\": 3651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.67, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4156403541564941}", "{\"n\": 3652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.65, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4200048446655273}", "{\"n\": 3653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.84, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.4295835494995117}", "{\"n\": 3654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.5, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4266247749328613}", "{\"n\": 3655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.3992269039154053}", "{\"n\": 3656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.76, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3902587890625}", "{\"n\": 3657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.82, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4544472694396973}", "{\"n\": 3658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.389582872390747}", "{\"n\": 3659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.79, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.412222146987915}", "{\"n\": 3660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4226648807525635}", "{\"n\": 3661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.40494704246521}", "{\"n\": 3662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4238154888153076}", "{\"n\": 3663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.96, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.42160964012146}", "{\"n\": 3664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.72, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4267065525054932}", "{\"n\": 3665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.62, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.395204782485962}", "{\"n\": 3666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.76, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.4230842590332031}", "{\"n\": 3667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.76, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.3920261859893799}", "{\"n\": 3668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.34, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4267914295196533}", "{\"n\": 3669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.56, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4137723445892334}", "{\"n\": 3670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.59, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.411426305770874}", "{\"n\": 3671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.59, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4427814483642578}", "{\"n\": 3672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.48, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4318063259124756}", "{\"n\": 3673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.11, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4147489070892334}", "{\"n\": 3674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.99, \"learn_time_ms\": 4.551, \"total_train_time_s\": 1.442819595336914}", "{\"n\": 3675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.99, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4281299114227295}", "{\"n\": 3676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.13, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4552531242370605}", "{\"n\": 3677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.94, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.423356056213379}", "{\"n\": 3678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.03, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.452558994293213}", "{\"n\": 3679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.03, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4027385711669922}", "{\"n\": 3680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.43, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4482877254486084}", "{\"n\": 3681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.2, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.400726079940796}", "{\"n\": 3682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.03, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4268555641174316}", "{\"n\": 3683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.03, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4277880191802979}", "{\"n\": 3684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.31, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4391989707946777}", "{\"n\": 3685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.34, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4311838150024414}", "{\"n\": 3686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.21, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.389190912246704}", "{\"n\": 3687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.21, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4013211727142334}", "{\"n\": 3688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.93, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4371285438537598}", "{\"n\": 3689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.08, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4107539653778076}", "{\"n\": 3690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.23, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4183061122894287}", "{\"n\": 3691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.23, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4349732398986816}", "{\"n\": 3692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.32, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4277887344360352}", "{\"n\": 3693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.37, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4507808685302734}", "{\"n\": 3694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.37, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.416137933731079}", "{\"n\": 3695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.37, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4065723419189453}", "{\"n\": 3696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.5, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4055004119873047}", "{\"n\": 3697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.42, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4226722717285156}", "{\"n\": 3698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.38, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4496417045593262}", "{\"n\": 3699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.38, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4042706489562988}", "{\"n\": 3700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.38, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.441429853439331}", "{\"n\": 3701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.25, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4247345924377441}", "{\"n\": 3702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.34, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.432654857635498}", "{\"n\": 3703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.34, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.3802638053894043}", "{\"n\": 3704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.38, \"learn_time_ms\": 4.513, \"total_train_time_s\": 1.4355695247650146}", "{\"n\": 3705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.41, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4013993740081787}", "{\"n\": 3706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.4, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4166386127471924}", "{\"n\": 3707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.4, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4009547233581543}", "{\"n\": 3708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.63, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4338295459747314}", "{\"n\": 3709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.61, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.401688575744629}", "{\"n\": 3710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.79, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.42341947555542}", "{\"n\": 3711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.79, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4201207160949707}", "{\"n\": 3712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.76, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4149258136749268}", "{\"n\": 3713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.86, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.410304307937622}", "{\"n\": 3714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.67, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4159431457519531}", "{\"n\": 3715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.67, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4143633842468262}", "{\"n\": 3716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.38, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4131908416748047}", "{\"n\": 3717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.93, \"learn_time_ms\": 4.565, \"total_train_time_s\": 1.4092400074005127}", "{\"n\": 3718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.407257080078125}", "{\"n\": 3719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4249064922332764}", "{\"n\": 3720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.529660940170288}", "{\"n\": 3721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.83, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4390900135040283}", "{\"n\": 3722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.79, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4113154411315918}", "{\"n\": 3723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.79, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4192070960998535}", "{\"n\": 3724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.08, \"learn_time_ms\": 4.556, \"total_train_time_s\": 1.4328579902648926}", "{\"n\": 3725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.15, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4080095291137695}", "{\"n\": 3726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.1, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.396268606185913}", "{\"n\": 3727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.1, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4089739322662354}", "{\"n\": 3728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.01, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4202213287353516}", "{\"n\": 3729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.81, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.4427704811096191}", "{\"n\": 3730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.448943853378296}", "{\"n\": 3731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.8, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3847854137420654}", "{\"n\": 3732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.77, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.396169662475586}", "{\"n\": 3733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.75, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4122138023376465}", "{\"n\": 3734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.56, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4006545543670654}", "{\"n\": 3735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.56, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.388622522354126}", "{\"n\": 3736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4343624114990234}", "{\"n\": 3737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.45, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4120416641235352}", "{\"n\": 3738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.51, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4589519500732422}", "{\"n\": 3739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.51, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4288809299468994}", "{\"n\": 3740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.28, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.386906623840332}", "{\"n\": 3741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4339542388916016}", "{\"n\": 3742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.535, \"total_train_time_s\": 1.4088971614837646}", "{\"n\": 3743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4159770011901855}", "{\"n\": 3744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.99, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4469869136810303}", "{\"n\": 3745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4173645973205566}", "{\"n\": 3746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4347410202026367}", "{\"n\": 3747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3950831890106201}", "{\"n\": 3748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4176995754241943}", "{\"n\": 3749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.420116662979126}", "{\"n\": 3750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.410041093826294}", "{\"n\": 3751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.3884999752044678}", "{\"n\": 3752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.3, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.442976474761963}", "{\"n\": 3753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4343993663787842}", "{\"n\": 3754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.8, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4079463481903076}", "{\"n\": 3755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 4.26, \"total_train_time_s\": 1.407029151916504}", "{\"n\": 3756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.64, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4153311252593994}", "{\"n\": 3757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.53, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4237477779388428}", "{\"n\": 3758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.53, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.391730546951294}", "{\"n\": 3759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.53, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4282746315002441}", "{\"n\": 3760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.39, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4208757877349854}", "{\"n\": 3761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.13, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.3978521823883057}", "{\"n\": 3762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.9, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4209201335906982}", "{\"n\": 3763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.9, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.3935315608978271}", "{\"n\": 3764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.5, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4447181224822998}", "{\"n\": 3765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.52, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4144577980041504}", "{\"n\": 3766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.526, \"total_train_time_s\": 1.4227771759033203}", "{\"n\": 3767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.3932807445526123}", "{\"n\": 3768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.83, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.4300494194030762}", "{\"n\": 3769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.71, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.422990083694458}", "{\"n\": 3770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.57, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.415513515472412}", "{\"n\": 3771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.57, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4091591835021973}", "{\"n\": 3772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.5, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4352977275848389}", "{\"n\": 3773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.94, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.413548231124878}", "{\"n\": 3774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.94, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.415947675704956}", "{\"n\": 3775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.91, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4300272464752197}", "{\"n\": 3776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.87, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.409529447555542}", "{\"n\": 3777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.87, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4236047267913818}", "{\"n\": 3778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.98, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.43756103515625}", "{\"n\": 3779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.0, \"learn_time_ms\": 4.523, \"total_train_time_s\": 1.416210412979126}", "{\"n\": 3780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.68, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4174983501434326}", "{\"n\": 3781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.64, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4044499397277832}", "{\"n\": 3782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.57, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4198131561279297}", "{\"n\": 3783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.59, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4260852336883545}", "{\"n\": 3784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.18, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.414726734161377}", "{\"n\": 3785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.18, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.393341302871704}", "{\"n\": 3786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.18, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4001755714416504}", "{\"n\": 3787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4018919467926025}", "{\"n\": 3788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.243, \"total_train_time_s\": 1.4153659343719482}", "{\"n\": 3789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.370305061340332}", "{\"n\": 3790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4393222332000732}", "{\"n\": 3791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.64, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.404066562652588}", "{\"n\": 3792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.86, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4540629386901855}", "{\"n\": 3793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.86, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.3905842304229736}", "{\"n\": 3794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4281694889068604}", "{\"n\": 3795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4011571407318115}", "{\"n\": 3796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4295871257781982}", "{\"n\": 3797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4058542251586914}", "{\"n\": 3798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4368362426757812}", "{\"n\": 3799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4271466732025146}", "{\"n\": 3800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4371988773345947}", "{\"n\": 3801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4334392547607422}", "{\"n\": 3802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4098966121673584}", "{\"n\": 3803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.3883514404296875}", "{\"n\": 3804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.16, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.7022373676300049}", "{\"n\": 3805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.3941547870635986}", "{\"n\": 3806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.87, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4077422618865967}", "{\"n\": 3807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.87, \"learn_time_ms\": 4.525, \"total_train_time_s\": 1.4300506114959717}", "{\"n\": 3808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.66, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.428581953048706}", "{\"n\": 3809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.511, \"total_train_time_s\": 1.4465529918670654}", "{\"n\": 3810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.06, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.407726526260376}", "{\"n\": 3811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.06, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4181690216064453}", "{\"n\": 3812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.82, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4386138916015625}", "{\"n\": 3813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4380130767822266}", "{\"n\": 3814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4058916568756104}", "{\"n\": 3815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.3853838443756104}", "{\"n\": 3816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4046556949615479}", "{\"n\": 3817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.71, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4404339790344238}", "{\"n\": 3818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.404526710510254}", "{\"n\": 3819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.4399511814117432}", "{\"n\": 3820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.78, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.443678855895996}", "{\"n\": 3821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.78, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4137978553771973}", "{\"n\": 3822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.71, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4217352867126465}", "{\"n\": 3823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4033215045928955}", "{\"n\": 3824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.51, \"learn_time_ms\": 4.243, \"total_train_time_s\": 1.4324500560760498}", "{\"n\": 3825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.26, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4202799797058105}", "{\"n\": 3826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.29, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4051084518432617}", "{\"n\": 3827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.26, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4108588695526123}", "{\"n\": 3828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.14, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4328606128692627}", "{\"n\": 3829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.397209882736206}", "{\"n\": 3830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.39, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4178309440612793}", "{\"n\": 3831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.27, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4223971366882324}", "{\"n\": 3832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.41, \"learn_time_ms\": 4.204, \"total_train_time_s\": 1.389423131942749}", "{\"n\": 3833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.38, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4281904697418213}", "{\"n\": 3834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.414729118347168}", "{\"n\": 3835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.47, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.392758846282959}", "{\"n\": 3836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4203696250915527}", "{\"n\": 3837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.78, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.3983235359191895}", "{\"n\": 3838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.7, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.407698154449463}", "{\"n\": 3839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.66, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.412553310394287}", "{\"n\": 3840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.45, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4125277996063232}", "{\"n\": 3841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4196903705596924}", "{\"n\": 3842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.24, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4010636806488037}", "{\"n\": 3843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.96, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.440751075744629}", "{\"n\": 3844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.03, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4173800945281982}", "{\"n\": 3845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.1, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4283654689788818}", "{\"n\": 3846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.08, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4648077487945557}", "{\"n\": 3847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.07, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4352748394012451}", "{\"n\": 3848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.07, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4030275344848633}", "{\"n\": 3849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4136250019073486}", "{\"n\": 3850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.29, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4175686836242676}", "{\"n\": 3851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4078495502471924}", "{\"n\": 3852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.502, \"total_train_time_s\": 1.4235589504241943}", "{\"n\": 3853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.51, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4358677864074707}", "{\"n\": 3854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.34, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4260108470916748}", "{\"n\": 3855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.35, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4467735290527344}", "{\"n\": 3856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.35, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4120252132415771}", "{\"n\": 3857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.36, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4059793949127197}", "{\"n\": 3858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.33, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.3854689598083496}", "{\"n\": 3859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.29, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.3931703567504883}", "{\"n\": 3860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.29, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.390031337738037}", "{\"n\": 3861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.433091163635254}", "{\"n\": 3862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.71, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3866167068481445}", "{\"n\": 3863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.3913652896881104}", "{\"n\": 3864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4202473163604736}", "{\"n\": 3865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.56, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4278085231781006}", "{\"n\": 3866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.59, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4088032245635986}", "{\"n\": 3867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4150352478027344}", "{\"n\": 3868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.93, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4201185703277588}", "{\"n\": 3869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.63, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4086828231811523}", "{\"n\": 3870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.68, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4182417392730713}", "{\"n\": 3871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.83, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4074208736419678}", "{\"n\": 3872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.83, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4266433715820312}", "{\"n\": 3873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.1, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4098823070526123}", "{\"n\": 3874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.16, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.3932926654815674}", "{\"n\": 3875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.16, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.3885958194732666}", "{\"n\": 3876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.3, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.39909029006958}", "{\"n\": 3877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.3, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4214966297149658}", "{\"n\": 3878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4063324928283691}", "{\"n\": 3879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.3985114097595215}", "{\"n\": 3880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.41314697265625}", "{\"n\": 3881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.32, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4350485801696777}", "{\"n\": 3882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.41807222366333}", "{\"n\": 3883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.42, \"learn_time_ms\": 4.508, \"total_train_time_s\": 1.3908307552337646}", "{\"n\": 3884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.94, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4442203044891357}", "{\"n\": 3885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4401462078094482}", "{\"n\": 3886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.5, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.3966362476348877}", "{\"n\": 3887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.5, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4071338176727295}", "{\"n\": 3888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.49, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.432584524154663}", "{\"n\": 3889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4148809909820557}", "{\"n\": 3890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.26, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4192419052124023}", "{\"n\": 3891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.26, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4234020709991455}", "{\"n\": 3892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.419464349746704}", "{\"n\": 3893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.87, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4409558773040771}", "{\"n\": 3894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.88, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4290363788604736}", "{\"n\": 3895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.88, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4049153327941895}", "{\"n\": 3896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.19, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4286260604858398}", "{\"n\": 3897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.86, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4273037910461426}", "{\"n\": 3898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4200196266174316}", "{\"n\": 3899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4337852001190186}", "{\"n\": 3900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.4529807567596436}", "{\"n\": 3901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.97, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.412644624710083}", "{\"n\": 3902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.88, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.419586420059204}", "{\"n\": 3903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.88, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4011974334716797}", "{\"n\": 3904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.95, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4097039699554443}", "{\"n\": 3905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4162287712097168}", "{\"n\": 3906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4454994201660156}", "{\"n\": 3907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4133880138397217}", "{\"n\": 3908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4012808799743652}", "{\"n\": 3909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.15, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.446263313293457}", "{\"n\": 3910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.39, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.4249329566955566}", "{\"n\": 3911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.39, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.400038719177246}", "{\"n\": 3912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4274251461029053}", "{\"n\": 3913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.71, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4099156856536865}", "{\"n\": 3914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.238, \"total_train_time_s\": 1.3790209293365479}", "{\"n\": 3915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.3862745761871338}", "{\"n\": 3916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.69, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4068074226379395}", "{\"n\": 3917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.74, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4394590854644775}", "{\"n\": 3918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.59, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4280197620391846}", "{\"n\": 3919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.59, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.393235445022583}", "{\"n\": 3920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4359803199768066}", "{\"n\": 3921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.66, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4241576194763184}", "{\"n\": 3922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.67, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4192476272583008}", "{\"n\": 3923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.67, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4049909114837646}", "{\"n\": 3924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.63, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4098281860351562}", "{\"n\": 3925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4205372333526611}", "{\"n\": 3926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.41, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3932185173034668}", "{\"n\": 3927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.41, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.5173015594482422}", "{\"n\": 3928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.36, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.443563461303711}", "{\"n\": 3929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.4, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.4171926975250244}", "{\"n\": 3930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4073922634124756}", "{\"n\": 3931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4135096073150635}", "{\"n\": 3932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.07, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4433519840240479}", "{\"n\": 3933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.03, \"learn_time_ms\": 4.538, \"total_train_time_s\": 1.4276607036590576}", "{\"n\": 3934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4197165966033936}", "{\"n\": 3935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4099431037902832}", "{\"n\": 3936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.14, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4310731887817383}", "{\"n\": 3937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.16, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4130539894104004}", "{\"n\": 3938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.2, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4186301231384277}", "{\"n\": 3939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.2, \"learn_time_ms\": 4.535, \"total_train_time_s\": 1.4037082195281982}", "{\"n\": 3940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.409006118774414}", "{\"n\": 3941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4340760707855225}", "{\"n\": 3942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4038569927215576}", "{\"n\": 3943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.394606351852417}", "{\"n\": 3944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.07, \"learn_time_ms\": 4.534, \"total_train_time_s\": 1.4137723445892334}", "{\"n\": 3945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.22, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4328091144561768}", "{\"n\": 3946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4268524646759033}", "{\"n\": 3947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.398611307144165}", "{\"n\": 3948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.444753885269165}", "{\"n\": 3949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.2, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.3910019397735596}", "{\"n\": 3950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.18, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4307620525360107}", "{\"n\": 3951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.18, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.4266605377197266}", "{\"n\": 3952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4442567825317383}", "{\"n\": 3953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.88, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4282822608947754}", "{\"n\": 3954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4178588390350342}", "{\"n\": 3955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4112179279327393}", "{\"n\": 3956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.97, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4168751239776611}", "{\"n\": 3957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.81, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4308786392211914}", "{\"n\": 3958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.420384407043457}", "{\"n\": 3959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4135043621063232}", "{\"n\": 3960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4128086566925049}", "{\"n\": 3961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.65, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.407205581665039}", "{\"n\": 3962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.9, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.3936247825622559}", "{\"n\": 3963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.9, \"learn_time_ms\": 4.503, \"total_train_time_s\": 1.412999153137207}", "{\"n\": 3964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4183142185211182}", "{\"n\": 3965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.83, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.439436674118042}", "{\"n\": 3966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.87, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4102723598480225}", "{\"n\": 3967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.87, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3908607959747314}", "{\"n\": 3968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.68, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4104695320129395}", "{\"n\": 3969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.81, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4213330745697021}", "{\"n\": 3970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4359889030456543}", "{\"n\": 3971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4320943355560303}", "{\"n\": 3972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.83, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.417069911956787}", "{\"n\": 3973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.7, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.401564359664917}", "{\"n\": 3974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.418149471282959}", "{\"n\": 3975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3913249969482422}", "{\"n\": 3976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.224, \"total_train_time_s\": 1.401613712310791}", "{\"n\": 3977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.51, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4351646900177002}", "{\"n\": 3978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.63, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4328923225402832}", "{\"n\": 3979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.63, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.3877437114715576}", "{\"n\": 3980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.5, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4211227893829346}", "{\"n\": 3981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.58, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4085054397583008}", "{\"n\": 3982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.504, \"total_train_time_s\": 1.4140355587005615}", "{\"n\": 3983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4001874923706055}", "{\"n\": 3984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3995366096496582}", "{\"n\": 3985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.75, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.3844683170318604}", "{\"n\": 3986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.57, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4065606594085693}", "{\"n\": 3987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.57, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.399496078491211}", "{\"n\": 3988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.6, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4213616847991943}", "{\"n\": 3989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.66, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.418771743774414}", "{\"n\": 3990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.432288646697998}", "{\"n\": 3991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.68, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4487991333007812}", "{\"n\": 3992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.89, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4135632514953613}", "{\"n\": 3993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.79, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4473774433135986}", "{\"n\": 3994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.03, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.414351463317871}", "{\"n\": 3995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.03, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.3839912414550781}", "{\"n\": 3996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.73, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4247856140136719}", "{\"n\": 3997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4209458827972412}", "{\"n\": 3998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.522, \"total_train_time_s\": 1.4234328269958496}", "{\"n\": 3999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.67, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4104020595550537}", "{\"n\": 4000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.27, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.3985185623168945}", "{\"n\": 4001, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.55, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4311738014221191}", "{\"n\": 4002, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.435112476348877}", "{\"n\": 4003, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4257240295410156}", "{\"n\": 4004, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.77, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4237966537475586}", "{\"n\": 4005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4351975917816162}", "{\"n\": 4006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.54, \"learn_time_ms\": 4.501, \"total_train_time_s\": 1.4176106452941895}", "{\"n\": 4007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.54, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4150922298431396}", "{\"n\": 4008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.37, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.450669765472412}", "{\"n\": 4009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.37, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4147758483886719}", "{\"n\": 4010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.443528175354004}", "{\"n\": 4011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.411712408065796}", "{\"n\": 4012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4366307258605957}", "{\"n\": 4013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.08, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.4312474727630615}", "{\"n\": 4014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4423019886016846}", "{\"n\": 4015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4035849571228027}", "{\"n\": 4016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4057135581970215}", "{\"n\": 4017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4592955112457275}", "{\"n\": 4018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4219248294830322}", "{\"n\": 4019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4093286991119385}", "{\"n\": 4020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.82, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4112138748168945}", "{\"n\": 4021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.28, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4374995231628418}", "{\"n\": 4022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.418076515197754}", "{\"n\": 4023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4183166027069092}", "{\"n\": 4024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.390763282775879}", "{\"n\": 4025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.43, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4252872467041016}", "{\"n\": 4026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.44, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4082751274108887}", "{\"n\": 4027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.5, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4005651473999023}", "{\"n\": 4028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.5, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.3761365413665771}", "{\"n\": 4029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.66, \"learn_time_ms\": 4.207, \"total_train_time_s\": 1.4247539043426514}", "{\"n\": 4030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4044578075408936}", "{\"n\": 4031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.94, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.425584316253662}", "{\"n\": 4032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.94, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4016129970550537}", "{\"n\": 4033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.95, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4317173957824707}", "{\"n\": 4034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.236, \"total_train_time_s\": 1.4147720336914062}", "{\"n\": 4035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.5152692794799805}", "{\"n\": 4036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.415879726409912}", "{\"n\": 4037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4297597408294678}", "{\"n\": 4038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.392641305923462}", "{\"n\": 4039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.3987526893615723}", "{\"n\": 4040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.52, \"learn_time_ms\": 4.513, \"total_train_time_s\": 1.4376599788665771}", "{\"n\": 4041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.51, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4229254722595215}", "{\"n\": 4042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.53, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4093255996704102}", "{\"n\": 4043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.53, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.3954534530639648}", "{\"n\": 4044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4267468452453613}", "{\"n\": 4045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.46, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.434713363647461}", "{\"n\": 4046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.3, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4364690780639648}", "{\"n\": 4047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.3, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4165589809417725}", "{\"n\": 4048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.52, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4086973667144775}", "{\"n\": 4049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.537, \"total_train_time_s\": 1.4478254318237305}", "{\"n\": 4050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4207873344421387}", "{\"n\": 4051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4139771461486816}", "{\"n\": 4052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.31, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4218075275421143}", "{\"n\": 4053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.34, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4196746349334717}", "{\"n\": 4054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.415031909942627}", "{\"n\": 4055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.3877556324005127}", "{\"n\": 4056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4350552558898926}", "{\"n\": 4057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.43424654006958}", "{\"n\": 4058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4157483577728271}", "{\"n\": 4059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.5, \"learn_time_ms\": 4.553, \"total_train_time_s\": 1.4014599323272705}", "{\"n\": 4060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.51, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4196059703826904}", "{\"n\": 4061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.51, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4327867031097412}", "{\"n\": 4062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4280574321746826}", "{\"n\": 4063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.29, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4166555404663086}", "{\"n\": 4064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4310925006866455}", "{\"n\": 4065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.23, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.403566837310791}", "{\"n\": 4066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.59, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4205057621002197}", "{\"n\": 4067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4060308933258057}", "{\"n\": 4068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4162144660949707}", "{\"n\": 4069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4195244312286377}", "{\"n\": 4070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.36, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4153883457183838}", "{\"n\": 4071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4060730934143066}", "{\"n\": 4072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.58, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4197359085083008}", "{\"n\": 4073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.58, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4207208156585693}", "{\"n\": 4074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.35, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4095652103424072}", "{\"n\": 4075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.49, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4421122074127197}", "{\"n\": 4076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.48, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.429253339767456}", "{\"n\": 4077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.48, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.403238296508789}", "{\"n\": 4078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.57, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4092450141906738}", "{\"n\": 4079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.44, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4248073101043701}", "{\"n\": 4080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.25, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4258389472961426}", "{\"n\": 4081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.25, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4093053340911865}", "{\"n\": 4082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.39, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4148097038269043}", "{\"n\": 4083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.89, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4052255153656006}", "{\"n\": 4084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4047772884368896}", "{\"n\": 4085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4006438255310059}", "{\"n\": 4086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.41855788230896}", "{\"n\": 4087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.79, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4407098293304443}", "{\"n\": 4088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4299166202545166}", "{\"n\": 4089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.409785270690918}", "{\"n\": 4090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.45, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.402681827545166}", "{\"n\": 4091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4043707847595215}", "{\"n\": 4092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.399132490158081}", "{\"n\": 4093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.23, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.418095350265503}", "{\"n\": 4094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.92, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4119303226470947}", "{\"n\": 4095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4216172695159912}", "{\"n\": 4096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4152538776397705}", "{\"n\": 4097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.85, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.4415960311889648}", "{\"n\": 4098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4155690670013428}", "{\"n\": 4099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.3855342864990234}", "{\"n\": 4100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.8, \"learn_time_ms\": 4.58, \"total_train_time_s\": 1.4128010272979736}", "{\"n\": 4101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.47, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4267499446868896}", "{\"n\": 4102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.53, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4189531803131104}", "{\"n\": 4103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4271190166473389}", "{\"n\": 4104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.3890807628631592}", "{\"n\": 4105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.09, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.429962396621704}", "{\"n\": 4106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.07, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.4186055660247803}", "{\"n\": 4107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.242, \"total_train_time_s\": 1.4249000549316406}", "{\"n\": 4108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.405456781387329}", "{\"n\": 4109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.96, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.406681776046753}", "{\"n\": 4110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.405644178390503}", "{\"n\": 4111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.394622564315796}", "{\"n\": 4112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.02, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.417332649230957}", "{\"n\": 4113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.09, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4042065143585205}", "{\"n\": 4114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.05, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.3935606479644775}", "{\"n\": 4115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.93, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4362497329711914}", "{\"n\": 4116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.93, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.423213243484497}", "{\"n\": 4117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.72, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.422348976135254}", "{\"n\": 4118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.7, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.41983962059021}", "{\"n\": 4119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.9, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4297642707824707}", "{\"n\": 4120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.9, \"learn_time_ms\": 4.514, \"total_train_time_s\": 1.4280378818511963}", "{\"n\": 4121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.3, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4267544746398926}", "{\"n\": 4122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.24, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.431361436843872}", "{\"n\": 4123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.420170545578003}", "{\"n\": 4124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.414891004562378}", "{\"n\": 4125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4601242542266846}", "{\"n\": 4126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.28, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.398587703704834}", "{\"n\": 4127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.21, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.394348382949829}", "{\"n\": 4128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.21, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4207754135131836}", "{\"n\": 4129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.35, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.418081521987915}", "{\"n\": 4130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.22, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4139695167541504}", "{\"n\": 4131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.17, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4158854484558105}", "{\"n\": 4132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.17, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4231469631195068}", "{\"n\": 4133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.05, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4189317226409912}", "{\"n\": 4134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.21, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.444833755493164}", "{\"n\": 4135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.13, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.429711103439331}", "{\"n\": 4136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.13, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.3977413177490234}", "{\"n\": 4137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.4, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4736788272857666}", "{\"n\": 4138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.42, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.397303581237793}", "{\"n\": 4139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.69, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4104478359222412}", "{\"n\": 4140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.69, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.374105453491211}", "{\"n\": 4141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.14, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4059031009674072}", "{\"n\": 4142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.03, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4514930248260498}", "{\"n\": 4143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.36, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.5267562866210938}", "{\"n\": 4144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.36, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4155550003051758}", "{\"n\": 4145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.29, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.430497169494629}", "{\"n\": 4146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.24, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.421868085861206}", "{\"n\": 4147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.15, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.418811559677124}", "{\"n\": 4148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.13, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4186642169952393}", "{\"n\": 4149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.14, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.403559923171997}", "{\"n\": 4150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.23, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4446361064910889}", "{\"n\": 4151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.22, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4393510818481445}", "{\"n\": 4152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.22, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4398596286773682}", "{\"n\": 4153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.08, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4276556968688965}", "{\"n\": 4154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.07, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.446484088897705}", "{\"n\": 4155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.13, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4201295375823975}", "{\"n\": 4156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.13, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4036495685577393}", "{\"n\": 4157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.42, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4429211616516113}", "{\"n\": 4158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.44, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4262139797210693}", "{\"n\": 4159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.53, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.394744634628296}", "{\"n\": 4160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.46, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.3996644020080566}", "{\"n\": 4161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.37, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.434455394744873}", "{\"n\": 4162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.53, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4378149509429932}", "{\"n\": 4163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.58, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4030840396881104}", "{\"n\": 4164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.58, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4166655540466309}", "{\"n\": 4165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.58, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4351670742034912}", "{\"n\": 4166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.31, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4121272563934326}", "{\"n\": 4167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.4, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4090073108673096}", "{\"n\": 4168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.37, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.404557466506958}", "{\"n\": 4169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.51, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.416917324066162}", "{\"n\": 4170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.44, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4281527996063232}", "{\"n\": 4171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.78, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4110965728759766}", "{\"n\": 4172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.66, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4207606315612793}", "{\"n\": 4173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.66, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.410510540008545}", "{\"n\": 4174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.86, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.431736946105957}", "{\"n\": 4175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.53, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.407705545425415}", "{\"n\": 4176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.56, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4219002723693848}", "{\"n\": 4177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.72, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4043991565704346}", "{\"n\": 4178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.85, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4295737743377686}", "{\"n\": 4179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.93, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4313082695007324}", "{\"n\": 4180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.78, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4220869541168213}", "{\"n\": 4181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.64, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.401625633239746}", "{\"n\": 4182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.24, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4482965469360352}", "{\"n\": 4183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4331495761871338}", "{\"n\": 4184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.58, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.406540870666504}", "{\"n\": 4185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.45, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.417768955230713}", "{\"n\": 4186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.54, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.402129888534546}", "{\"n\": 4187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.37, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4223816394805908}", "{\"n\": 4188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.27, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.43105149269104}", "{\"n\": 4189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.32, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4125125408172607}", "{\"n\": 4190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.33, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3940839767456055}", "{\"n\": 4191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.44, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4208154678344727}", "{\"n\": 4192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.55, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4069221019744873}", "{\"n\": 4193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.22, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4176557064056396}", "{\"n\": 4194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4266626834869385}", "{\"n\": 4195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.15, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4066722393035889}", "{\"n\": 4196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.3, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.424340009689331}", "{\"n\": 4197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.46, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4241302013397217}", "{\"n\": 4198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.57, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4105780124664307}", "{\"n\": 4199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.53, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.405142068862915}", "{\"n\": 4200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.72, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4381029605865479}", "{\"n\": 4201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.72, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4336662292480469}", "{\"n\": 4202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4184863567352295}", "{\"n\": 4203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3984451293945312}", "{\"n\": 4204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4024477005004883}", "{\"n\": 4205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.94, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.443612813949585}", "{\"n\": 4206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4599204063415527}", "{\"n\": 4207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4006316661834717}", "{\"n\": 4208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.23, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.3946073055267334}", "{\"n\": 4209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4352943897247314}", "{\"n\": 4210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4461631774902344}", "{\"n\": 4211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.3836205005645752}", "{\"n\": 4212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4184703826904297}", "{\"n\": 4213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4019525051116943}", "{\"n\": 4214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.62, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4564337730407715}", "{\"n\": 4215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.62, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4308555126190186}", "{\"n\": 4216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4028370380401611}", "{\"n\": 4217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.65, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4285273551940918}", "{\"n\": 4218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.69, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4377715587615967}", "{\"n\": 4219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.69, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4082601070404053}", "{\"n\": 4220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.71, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3980340957641602}", "{\"n\": 4221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.71, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.4008662700653076}", "{\"n\": 4222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4430222511291504}", "{\"n\": 4223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4056396484375}", "{\"n\": 4224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.67, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4372146129608154}", "{\"n\": 4225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.53, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4308102130889893}", "{\"n\": 4226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.7, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4342892169952393}", "{\"n\": 4227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.7, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.6763746738433838}", "{\"n\": 4228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.73, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4310064315795898}", "{\"n\": 4229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.51, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4144322872161865}", "{\"n\": 4230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4235663414001465}", "{\"n\": 4231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4006352424621582}", "{\"n\": 4232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.26, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3982086181640625}", "{\"n\": 4233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.39, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4309871196746826}", "{\"n\": 4234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.6, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4136998653411865}", "{\"n\": 4235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.6, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.4283387660980225}", "{\"n\": 4236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.3985884189605713}", "{\"n\": 4237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.3, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4414353370666504}", "{\"n\": 4238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.41, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.406257152557373}", "{\"n\": 4239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.41, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.383155107498169}", "{\"n\": 4240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.35, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4436359405517578}", "{\"n\": 4241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.13, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.427306890487671}", "{\"n\": 4242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.07, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4658899307250977}", "{\"n\": 4243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.07, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.404449701309204}", "{\"n\": 4244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.18, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4355461597442627}", "{\"n\": 4245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4146625995635986}", "{\"n\": 4246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4286844730377197}", "{\"n\": 4247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.3985099792480469}", "{\"n\": 4248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.39, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4120628833770752}", "{\"n\": 4249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.444037914276123}", "{\"n\": 4250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.61, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4148411750793457}", "{\"n\": 4251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.61, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4369587898254395}", "{\"n\": 4252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.67, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4226903915405273}", "{\"n\": 4253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.58, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4157631397247314}", "{\"n\": 4254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.62, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.427933931350708}", "{\"n\": 4255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.62, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.3969357013702393}", "{\"n\": 4256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.47, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4136638641357422}", "{\"n\": 4257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 4.208, \"total_train_time_s\": 1.4102702140808105}", "{\"n\": 4258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.11, \"learn_time_ms\": 4.508, \"total_train_time_s\": 1.4182958602905273}", "{\"n\": 4259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.11, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.435271978378296}", "{\"n\": 4260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.12, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4227015972137451}", "{\"n\": 4261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.11, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4158661365509033}", "{\"n\": 4262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4299685955047607}", "{\"n\": 4263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.21, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4290359020233154}", "{\"n\": 4264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.12, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.415499210357666}", "{\"n\": 4265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.18, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4087657928466797}", "{\"n\": 4266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.15, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.452759027481079}", "{\"n\": 4267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.15, \"learn_time_ms\": 4.202, \"total_train_time_s\": 1.4001216888427734}", "{\"n\": 4268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.33, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.459888219833374}", "{\"n\": 4269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.4, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4342362880706787}", "{\"n\": 4270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4192404747009277}", "{\"n\": 4271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.03, \"learn_time_ms\": 4.578, \"total_train_time_s\": 1.428678035736084}", "{\"n\": 4272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4393181800842285}", "{\"n\": 4273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4170160293579102}", "{\"n\": 4274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.76, \"learn_time_ms\": 4.234, \"total_train_time_s\": 1.4018306732177734}", "{\"n\": 4275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.86, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4333593845367432}", "{\"n\": 4276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.78, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4135048389434814}", "{\"n\": 4277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.78, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4383111000061035}", "{\"n\": 4278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.97, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4347317218780518}", "{\"n\": 4279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4125120639801025}", "{\"n\": 4280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.33, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4042320251464844}", "{\"n\": 4281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.33, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4042646884918213}", "{\"n\": 4282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.33, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.3977859020233154}", "{\"n\": 4283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.49, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4295532703399658}", "{\"n\": 4284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4387261867523193}", "{\"n\": 4285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4063880443572998}", "{\"n\": 4286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4108495712280273}", "{\"n\": 4287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.84, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4182915687561035}", "{\"n\": 4288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.69, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.408493995666504}", "{\"n\": 4289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.69, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4043984413146973}", "{\"n\": 4290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.69, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4333786964416504}", "{\"n\": 4291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.69, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.3810069561004639}", "{\"n\": 4292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.546, \"total_train_time_s\": 1.4213619232177734}", "{\"n\": 4293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4309256076812744}", "{\"n\": 4294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3764593601226807}", "{\"n\": 4295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.512, \"total_train_time_s\": 1.4488275051116943}", "{\"n\": 4296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4347949028015137}", "{\"n\": 4297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.428039789199829}", "{\"n\": 4298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4037578105926514}", "{\"n\": 4299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.93, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4393999576568604}", "{\"n\": 4300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.9, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4030320644378662}", "{\"n\": 4301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.9, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.43367600440979}", "{\"n\": 4302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.9, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4013450145721436}", "{\"n\": 4303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.91, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4217555522918701}", "{\"n\": 4304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4549453258514404}", "{\"n\": 4305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.535, \"total_train_time_s\": 1.411757230758667}", "{\"n\": 4306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4213378429412842}", "{\"n\": 4307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.96, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4209251403808594}", "{\"n\": 4308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4216399192810059}", "{\"n\": 4309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.383923053741455}", "{\"n\": 4310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4220333099365234}", "{\"n\": 4311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.1, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.434861183166504}", "{\"n\": 4312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.93, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4307091236114502}", "{\"n\": 4313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.93, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4256761074066162}", "{\"n\": 4314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.93, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4158236980438232}", "{\"n\": 4315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.44, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4120385646820068}", "{\"n\": 4316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.47, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4363012313842773}", "{\"n\": 4317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.47, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4040098190307617}", "{\"n\": 4318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.47, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.397843599319458}", "{\"n\": 4319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.57, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4011237621307373}", "{\"n\": 4320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.36, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4251039028167725}", "{\"n\": 4321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.36, \"learn_time_ms\": 4.514, \"total_train_time_s\": 1.400604009628296}", "{\"n\": 4322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.36, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4143218994140625}", "{\"n\": 4323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.35, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4009287357330322}", "{\"n\": 4324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4541845321655273}", "{\"n\": 4325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.564, \"total_train_time_s\": 1.434790849685669}", "{\"n\": 4326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.416076421737671}", "{\"n\": 4327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.64, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.445063829421997}", "{\"n\": 4328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.214, \"total_train_time_s\": 1.4407002925872803}", "{\"n\": 4329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4038574695587158}", "{\"n\": 4330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4156193733215332}", "{\"n\": 4331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.44, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4511675834655762}", "{\"n\": 4332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4405272006988525}", "{\"n\": 4333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3838558197021484}", "{\"n\": 4334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3944876194000244}", "{\"n\": 4335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.43, \"learn_time_ms\": 4.221, \"total_train_time_s\": 1.4195349216461182}", "{\"n\": 4336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4478669166564941}", "{\"n\": 4337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4124107360839844}", "{\"n\": 4338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4140219688415527}", "{\"n\": 4339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.39, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.3773918151855469}", "{\"n\": 4340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4624550342559814}", "{\"n\": 4341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.405327320098877}", "{\"n\": 4342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4065353870391846}", "{\"n\": 4343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.24, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4105100631713867}", "{\"n\": 4344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.24, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4509103298187256}", "{\"n\": 4345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.24, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.421663522720337}", "{\"n\": 4346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.24, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.412796974182129}", "{\"n\": 4347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.24, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.3943707942962646}", "{\"n\": 4348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4469547271728516}", "{\"n\": 4349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.5171568393707275}", "{\"n\": 4350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4108185768127441}", "{\"n\": 4351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.51, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4014277458190918}", "{\"n\": 4352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.13, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4293408393859863}", "{\"n\": 4353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.13, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.3900697231292725}", "{\"n\": 4354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.13, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.420236349105835}", "{\"n\": 4355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.13, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.3994696140289307}", "{\"n\": 4356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4148011207580566}", "{\"n\": 4357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4212098121643066}", "{\"n\": 4358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4162545204162598}", "{\"n\": 4359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.417614221572876}", "{\"n\": 4360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4593515396118164}", "{\"n\": 4361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.397383451461792}", "{\"n\": 4362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4047067165374756}", "{\"n\": 4363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1042.39, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.403691291809082}", "{\"n\": 4364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.03, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4610295295715332}", "{\"n\": 4365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.03, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4184577465057373}", "{\"n\": 4366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.03, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4250903129577637}", "{\"n\": 4367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.03, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4465155601501465}", "{\"n\": 4368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.76, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.435612678527832}", "{\"n\": 4369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.76, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.3864498138427734}", "{\"n\": 4370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.76, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4045186042785645}", "{\"n\": 4371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.76, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.412637710571289}", "{\"n\": 4372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.19, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.4424958229064941}", "{\"n\": 4373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.19, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4034764766693115}", "{\"n\": 4374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.19, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4074842929840088}", "{\"n\": 4375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.19, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4257385730743408}", "{\"n\": 4376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.26, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4589834213256836}", "{\"n\": 4377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.26, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4174256324768066}", "{\"n\": 4378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.26, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.424032211303711}", "{\"n\": 4379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.26, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.399059772491455}", "{\"n\": 4380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.72, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.47678542137146}", "{\"n\": 4381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.72, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4227049350738525}", "{\"n\": 4382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.72, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.400998830795288}", "{\"n\": 4383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.72, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.403108835220337}", "{\"n\": 4384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.82, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4407691955566406}", "{\"n\": 4385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.82, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.440011978149414}", "{\"n\": 4386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.82, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4070651531219482}", "{\"n\": 4387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.82, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4071753025054932}", "{\"n\": 4388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4735517501831055}", "{\"n\": 4389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3950836658477783}", "{\"n\": 4390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.3949449062347412}", "{\"n\": 4391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4049484729766846}", "{\"n\": 4392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.44203519821167}", "{\"n\": 4393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.3986709117889404}", "{\"n\": 4394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4181227684020996}", "{\"n\": 4395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.3972017765045166}", "{\"n\": 4396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4622416496276855}", "{\"n\": 4397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4246926307678223}", "{\"n\": 4398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3958461284637451}", "{\"n\": 4399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4260280132293701}", "{\"n\": 4400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.4594287872314453}", "{\"n\": 4401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.404571533203125}", "{\"n\": 4402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4107224941253662}", "{\"n\": 4403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.72, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.423708200454712}", "{\"n\": 4404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.459320068359375}", "{\"n\": 4405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.421483039855957}", "{\"n\": 4406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4245619773864746}", "{\"n\": 4407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3938512802124023}", "{\"n\": 4408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4715795516967773}", "{\"n\": 4409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4248085021972656}", "{\"n\": 4410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4332091808319092}", "{\"n\": 4411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4262685775756836}", "{\"n\": 4412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.89, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4671709537506104}", "{\"n\": 4413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.89, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4141006469726562}", "{\"n\": 4414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.89, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4169533252716064}", "{\"n\": 4415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.48, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.420161247253418}", "{\"n\": 4416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.48, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4123420715332031}", "{\"n\": 4417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.48, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.3989455699920654}", "{\"n\": 4418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.48, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4045355319976807}", "{\"n\": 4419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.38, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4040625095367432}", "{\"n\": 4420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4456062316894531}", "{\"n\": 4421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4125165939331055}", "{\"n\": 4422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4183354377746582}", "{\"n\": 4423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.29, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.3958568572998047}", "{\"n\": 4424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.425154685974121}", "{\"n\": 4425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.231, \"total_train_time_s\": 1.4106090068817139}", "{\"n\": 4426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.435337781906128}", "{\"n\": 4427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.81, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4187259674072266}", "{\"n\": 4428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.58, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4177260398864746}", "{\"n\": 4429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.93, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4221396446228027}", "{\"n\": 4430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.93, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4274399280548096}", "{\"n\": 4431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.4267144203186035}", "{\"n\": 4432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.84, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4189727306365967}", "{\"n\": 4433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.71, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4217078685760498}", "{\"n\": 4434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.558, \"total_train_time_s\": 1.4365999698638916}", "{\"n\": 4435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.3834764957427979}", "{\"n\": 4436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.22, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4209141731262207}", "{\"n\": 4437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.16, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.432044267654419}", "{\"n\": 4438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.16, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4148268699645996}", "{\"n\": 4439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.86, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4155573844909668}", "{\"n\": 4440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.08, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4330520629882812}", "{\"n\": 4441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4161264896392822}", "{\"n\": 4442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.18, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4213075637817383}", "{\"n\": 4443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.74, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.383225917816162}", "{\"n\": 4444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.71, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4478545188903809}", "{\"n\": 4445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.561, \"total_train_time_s\": 1.4144973754882812}", "{\"n\": 4446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4156267642974854}", "{\"n\": 4447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.89, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4205396175384521}", "{\"n\": 4448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.466, \"total_train_time_s\": 1.4725873470306396}", "{\"n\": 4449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4048361778259277}", "{\"n\": 4450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.408935308456421}", "{\"n\": 4451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.219, \"total_train_time_s\": 1.411125659942627}", "{\"n\": 4452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.44, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4382133483886719}", "{\"n\": 4453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.44, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.428602933883667}", "{\"n\": 4454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.99, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.435192584991455}", "{\"n\": 4455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.99, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.404637098312378}", "{\"n\": 4456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.93, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.428098440170288}", "{\"n\": 4457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.93, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.5163049697875977}", "{\"n\": 4458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.62, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4200913906097412}", "{\"n\": 4459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.62, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.3997409343719482}", "{\"n\": 4460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4432258605957031}", "{\"n\": 4461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.3991870880126953}", "{\"n\": 4462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.02, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4271037578582764}", "{\"n\": 4463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.02, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4106345176696777}", "{\"n\": 4464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.24, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4836173057556152}", "{\"n\": 4465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.24, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4136176109313965}", "{\"n\": 4466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.426307201385498}", "{\"n\": 4467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.4, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4058730602264404}", "{\"n\": 4468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.36, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4422192573547363}", "{\"n\": 4469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.36, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.389106273651123}", "{\"n\": 4470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4002318382263184}", "{\"n\": 4471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3884093761444092}", "{\"n\": 4472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.14, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4436945915222168}", "{\"n\": 4473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.14, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4166042804718018}", "{\"n\": 4474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.22, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.420776605606079}", "{\"n\": 4475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.22, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.3982179164886475}", "{\"n\": 4476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.88, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4174678325653076}", "{\"n\": 4477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.88, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4144206047058105}", "{\"n\": 4478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.87, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4102981090545654}", "{\"n\": 4479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.87, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.393894910812378}", "{\"n\": 4480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.12, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4391703605651855}", "{\"n\": 4481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.12, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.432877779006958}", "{\"n\": 4482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4684531688690186}", "{\"n\": 4483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.46, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4036412239074707}", "{\"n\": 4484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4745738506317139}", "{\"n\": 4485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.65, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.3901340961456299}", "{\"n\": 4486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.405777931213379}", "{\"n\": 4487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4419853687286377}", "{\"n\": 4488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4338500499725342}", "{\"n\": 4489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.58, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4106605052947998}", "{\"n\": 4490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4265508651733398}", "{\"n\": 4491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.391477108001709}", "{\"n\": 4492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.426710605621338}", "{\"n\": 4493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4121372699737549}", "{\"n\": 4494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.417405128479004}", "{\"n\": 4495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.401679515838623}", "{\"n\": 4496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4319641590118408}", "{\"n\": 4497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.421483039855957}", "{\"n\": 4498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4075770378112793}", "{\"n\": 4499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.3985493183135986}", "{\"n\": 4500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4330034255981445}", "{\"n\": 4501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4184141159057617}", "{\"n\": 4502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4134726524353027}", "{\"n\": 4503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4283437728881836}", "{\"n\": 4504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4135119915008545}", "{\"n\": 4505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.53, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.414057731628418}", "{\"n\": 4506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.407139539718628}", "{\"n\": 4507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.3779301643371582}", "{\"n\": 4508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.604, \"total_train_time_s\": 1.4604523181915283}", "{\"n\": 4509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.410409927368164}", "{\"n\": 4510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.542, \"total_train_time_s\": 1.4485437870025635}", "{\"n\": 4511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.521, \"total_train_time_s\": 1.4429242610931396}", "{\"n\": 4512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4228603839874268}", "{\"n\": 4513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.54, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4222664833068848}", "{\"n\": 4514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4356300830841064}", "{\"n\": 4515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4323813915252686}", "{\"n\": 4516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4279325008392334}", "{\"n\": 4517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4225118160247803}", "{\"n\": 4518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.3949792385101318}", "{\"n\": 4519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4037995338439941}", "{\"n\": 4520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.83, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4587368965148926}", "{\"n\": 4521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.83, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.3827240467071533}", "{\"n\": 4522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.84, \"learn_time_ms\": 4.503, \"total_train_time_s\": 1.43367338180542}", "{\"n\": 4523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.84, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.415902853012085}", "{\"n\": 4524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.56, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4588291645050049}", "{\"n\": 4525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.56, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.4119079113006592}", "{\"n\": 4526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.453819990158081}", "{\"n\": 4527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.410693883895874}", "{\"n\": 4528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.66, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.421522617340088}", "{\"n\": 4529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.66, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4238624572753906}", "{\"n\": 4530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.399714708328247}", "{\"n\": 4531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.3801922798156738}", "{\"n\": 4532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.85, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4263949394226074}", "{\"n\": 4533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.85, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4047503471374512}", "{\"n\": 4534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.3854825496673584}", "{\"n\": 4535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.48, \"learn_time_ms\": 4.455, \"total_train_time_s\": 1.4397528171539307}", "{\"n\": 4536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.427711009979248}", "{\"n\": 4537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.27, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.406217098236084}", "{\"n\": 4538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.53, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4441556930541992}", "{\"n\": 4539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.53, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.4373276233673096}", "{\"n\": 4540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.39, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.4190576076507568}", "{\"n\": 4541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.39, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4145739078521729}", "{\"n\": 4542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.79, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4141449928283691}", "{\"n\": 4543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.79, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4072964191436768}", "{\"n\": 4544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.55, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4465599060058594}", "{\"n\": 4545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.55, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4156322479248047}", "{\"n\": 4546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.53, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4190309047698975}", "{\"n\": 4547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.53, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.45274019241333}", "{\"n\": 4548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.448500633239746}", "{\"n\": 4549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.43495512008667}", "{\"n\": 4550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.54, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4146473407745361}", "{\"n\": 4551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.54, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4147632122039795}", "{\"n\": 4552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.78, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.431638479232788}", "{\"n\": 4553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.78, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4112820625305176}", "{\"n\": 4554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.91, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4190421104431152}", "{\"n\": 4555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.91, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.3801512718200684}", "{\"n\": 4556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.39, \"learn_time_ms\": 4.22, \"total_train_time_s\": 1.4607672691345215}", "{\"n\": 4557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.39, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.4032039642333984}", "{\"n\": 4558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.65, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4059889316558838}", "{\"n\": 4559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.65, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.3807477951049805}", "{\"n\": 4560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.74, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4347014427185059}", "{\"n\": 4561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.63, \"learn_time_ms\": 4.251, \"total_train_time_s\": 1.4073150157928467}", "{\"n\": 4562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.4, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.420701265335083}", "{\"n\": 4563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.4, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.3958258628845215}", "{\"n\": 4564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.33, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4391264915466309}", "{\"n\": 4565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.06, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.5359833240509033}", "{\"n\": 4566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.14, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4514045715332031}", "{\"n\": 4567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.14, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3922221660614014}", "{\"n\": 4568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.27, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4367964267730713}", "{\"n\": 4569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.31, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4440176486968994}", "{\"n\": 4570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.49, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4228990077972412}", "{\"n\": 4571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.49, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.3950448036193848}", "{\"n\": 4572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.36, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4006757736206055}", "{\"n\": 4573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.422224998474121}", "{\"n\": 4574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 4.445, \"total_train_time_s\": 1.461268424987793}", "{\"n\": 4575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4279820919036865}", "{\"n\": 4576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.5, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4361865520477295}", "{\"n\": 4577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.72, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.429560661315918}", "{\"n\": 4578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.83, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4182169437408447}", "{\"n\": 4579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.83, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4034984111785889}", "{\"n\": 4580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.12, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4251363277435303}", "{\"n\": 4581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.03, \"learn_time_ms\": 4.501, \"total_train_time_s\": 1.4237463474273682}", "{\"n\": 4582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.43, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4354455471038818}", "{\"n\": 4583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.43, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4202828407287598}", "{\"n\": 4584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.62, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4408073425292969}", "{\"n\": 4585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.82, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4195220470428467}", "{\"n\": 4586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.17, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.43827486038208}", "{\"n\": 4587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.17, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4240398406982422}", "{\"n\": 4588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.35, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4000117778778076}", "{\"n\": 4589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.35, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4030461311340332}", "{\"n\": 4590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4284226894378662}", "{\"n\": 4591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.2, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.413562297821045}", "{\"n\": 4592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.443993330001831}", "{\"n\": 4593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.421980857849121}", "{\"n\": 4594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4273977279663086}", "{\"n\": 4595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.45, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4237704277038574}", "{\"n\": 4596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.42, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4187641143798828}", "{\"n\": 4597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.42, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4036555290222168}", "{\"n\": 4598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.74, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4231517314910889}", "{\"n\": 4599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.74, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4078834056854248}", "{\"n\": 4600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4612364768981934}", "{\"n\": 4601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4155917167663574}", "{\"n\": 4602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.12, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4324884414672852}", "{\"n\": 4603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.12, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.407893180847168}", "{\"n\": 4604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4107279777526855}", "{\"n\": 4605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.8, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4456884860992432}", "{\"n\": 4606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4234895706176758}", "{\"n\": 4607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.3946270942687988}", "{\"n\": 4608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.65, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4315087795257568}", "{\"n\": 4609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.94, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4236655235290527}", "{\"n\": 4610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.28, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4427361488342285}", "{\"n\": 4611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.28, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4219181537628174}", "{\"n\": 4612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.18, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4007456302642822}", "{\"n\": 4613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.19, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.41690993309021}", "{\"n\": 4614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4341113567352295}", "{\"n\": 4615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4109272956848145}", "{\"n\": 4616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4268860816955566}", "{\"n\": 4617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.3974664211273193}", "{\"n\": 4618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4305720329284668}", "{\"n\": 4619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4081032276153564}", "{\"n\": 4620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4124929904937744}", "{\"n\": 4621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.206, \"total_train_time_s\": 1.3791489601135254}", "{\"n\": 4622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4132122993469238}", "{\"n\": 4623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.84, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4219272136688232}", "{\"n\": 4624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.3975882530212402}", "{\"n\": 4625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4208011627197266}", "{\"n\": 4626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4162354469299316}", "{\"n\": 4627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.49, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.437185287475586}", "{\"n\": 4628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4283928871154785}", "{\"n\": 4629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4261858463287354}", "{\"n\": 4630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.53, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4294216632843018}", "{\"n\": 4631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.49, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4085009098052979}", "{\"n\": 4632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.37, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.407353401184082}", "{\"n\": 4633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.54, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4142510890960693}", "{\"n\": 4634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4096078872680664}", "{\"n\": 4635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.6, \"learn_time_ms\": 4.394, \"total_train_time_s\": 1.409292221069336}", "{\"n\": 4636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.56, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4232831001281738}", "{\"n\": 4637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4269840717315674}", "{\"n\": 4638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.62, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.4237279891967773}", "{\"n\": 4639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.89, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4168107509613037}", "{\"n\": 4640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.76, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4176409244537354}", "{\"n\": 4641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.01, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4120478630065918}", "{\"n\": 4642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4182429313659668}", "{\"n\": 4643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4086518287658691}", "{\"n\": 4644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4023280143737793}", "{\"n\": 4645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.96, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.415426254272461}", "{\"n\": 4646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.07, \"learn_time_ms\": 4.186, \"total_train_time_s\": 1.419100046157837}", "{\"n\": 4647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.08, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.3928091526031494}", "{\"n\": 4648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.24, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4461371898651123}", "{\"n\": 4649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.39, \"learn_time_ms\": 4.528, \"total_train_time_s\": 1.6796457767486572}", "{\"n\": 4650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.54, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4346222877502441}", "{\"n\": 4651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4197888374328613}", "{\"n\": 4652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.64, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4041602611541748}", "{\"n\": 4653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.98, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4192173480987549}", "{\"n\": 4654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.98, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.3992915153503418}", "{\"n\": 4655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.432427167892456}", "{\"n\": 4656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.45, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4291107654571533}", "{\"n\": 4657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4484972953796387}", "{\"n\": 4658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.28, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4107005596160889}", "{\"n\": 4659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.23, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.402036428451538}", "{\"n\": 4660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.12, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3903446197509766}", "{\"n\": 4661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4090070724487305}", "{\"n\": 4662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.26, \"learn_time_ms\": 4.503, \"total_train_time_s\": 1.4124090671539307}", "{\"n\": 4663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4660422801971436}", "{\"n\": 4664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.404585838317871}", "{\"n\": 4665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4255988597869873}", "{\"n\": 4666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.403669834136963}", "{\"n\": 4667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.36, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4126460552215576}", "{\"n\": 4668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.53, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.404695749282837}", "{\"n\": 4669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4371070861816406}", "{\"n\": 4670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.48, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.4277875423431396}", "{\"n\": 4671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.4, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3949317932128906}", "{\"n\": 4672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4725141525268555}", "{\"n\": 4673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.3, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4255664348602295}", "{\"n\": 4674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4142966270446777}", "{\"n\": 4675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.98, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3912639617919922}", "{\"n\": 4676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.98, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4087333679199219}", "{\"n\": 4677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.15, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4218456745147705}", "{\"n\": 4678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.434507131576538}", "{\"n\": 4679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4359519481658936}", "{\"n\": 4680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.97, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4161956310272217}", "{\"n\": 4681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4543955326080322}", "{\"n\": 4682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.79, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4125335216522217}", "{\"n\": 4683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.1, \"learn_time_ms\": 4.507, \"total_train_time_s\": 1.4178214073181152}", "{\"n\": 4684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.05, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4179625511169434}", "{\"n\": 4685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.9, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4233405590057373}", "{\"n\": 4686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.56, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4289240837097168}", "{\"n\": 4687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.49, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4515349864959717}", "{\"n\": 4688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.85, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4228386878967285}", "{\"n\": 4689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.78, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.395850658416748}", "{\"n\": 4690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.94, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4461259841918945}", "{\"n\": 4691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.04, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.3972282409667969}", "{\"n\": 4692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.14, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4258975982666016}", "{\"n\": 4693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.32, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4085988998413086}", "{\"n\": 4694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.37, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4192368984222412}", "{\"n\": 4695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.02, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.42409348487854}", "{\"n\": 4696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.89, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4135205745697021}", "{\"n\": 4697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.94, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4175033569335938}", "{\"n\": 4698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.28, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.395902156829834}", "{\"n\": 4699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.97, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4750890731811523}", "{\"n\": 4700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.01, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.3861665725708008}", "{\"n\": 4701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.36, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4073200225830078}", "{\"n\": 4702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.54, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4340555667877197}", "{\"n\": 4703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.43, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4163188934326172}", "{\"n\": 4704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.36, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4002647399902344}", "{\"n\": 4705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.437847375869751}", "{\"n\": 4706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.437391757965088}", "{\"n\": 4707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4295811653137207}", "{\"n\": 4708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.404576063156128}", "{\"n\": 4709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3991076946258545}", "{\"n\": 4710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.08, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4147837162017822}", "{\"n\": 4711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.09, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4093375205993652}", "{\"n\": 4712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.09, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.403573989868164}", "{\"n\": 4713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.79, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4252252578735352}", "{\"n\": 4714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4298725128173828}", "{\"n\": 4715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.3804621696472168}", "{\"n\": 4716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.22, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.401090145111084}", "{\"n\": 4717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4240412712097168}", "{\"n\": 4718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.18, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4171433448791504}", "{\"n\": 4719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.19, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.3988473415374756}", "{\"n\": 4720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.0, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.402634859085083}", "{\"n\": 4721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.2, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4542393684387207}", "{\"n\": 4722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.2, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4268898963928223}", "{\"n\": 4723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.91, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4496006965637207}", "{\"n\": 4724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.69, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4205927848815918}", "{\"n\": 4725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.57, \"learn_time_ms\": 4.497, \"total_train_time_s\": 1.4038021564483643}", "{\"n\": 4726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.57, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4157226085662842}", "{\"n\": 4727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.27, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4601349830627441}", "{\"n\": 4728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4167358875274658}", "{\"n\": 4729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4129135608673096}", "{\"n\": 4730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.3888828754425049}", "{\"n\": 4731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.67, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4248466491699219}", "{\"n\": 4732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.57, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.425638198852539}", "{\"n\": 4733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.57, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.4327361583709717}", "{\"n\": 4734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.57, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3911592960357666}", "{\"n\": 4735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.548, \"total_train_time_s\": 1.436957597732544}", "{\"n\": 4736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4156136512756348}", "{\"n\": 4737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.4, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4125444889068604}", "{\"n\": 4738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.4, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.39469313621521}", "{\"n\": 4739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.34, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4446048736572266}", "{\"n\": 4740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4056081771850586}", "{\"n\": 4741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4446163177490234}", "{\"n\": 4742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.41, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.408381700515747}", "{\"n\": 4743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.37, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4187326431274414}", "{\"n\": 4744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.53, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4405908584594727}", "{\"n\": 4745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.440810203552246}", "{\"n\": 4746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4262385368347168}", "{\"n\": 4747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4036707878112793}", "{\"n\": 4748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4013161659240723}", "{\"n\": 4749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.33, \"learn_time_ms\": 4.516, \"total_train_time_s\": 1.441354751586914}", "{\"n\": 4750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.33, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.3994083404541016}", "{\"n\": 4751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.43519926071167}", "{\"n\": 4752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.42, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4075276851654053}", "{\"n\": 4753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.85, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.451033115386963}", "{\"n\": 4754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.85, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.3916761875152588}", "{\"n\": 4755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4035720825195312}", "{\"n\": 4756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.418137550354004}", "{\"n\": 4757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.2, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4101123809814453}", "{\"n\": 4758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.2, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4252402782440186}", "{\"n\": 4759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.0, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.434887170791626}", "{\"n\": 4760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.87, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.3827323913574219}", "{\"n\": 4761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.83, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4354770183563232}", "{\"n\": 4762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.83, \"learn_time_ms\": 4.542, \"total_train_time_s\": 1.4214606285095215}", "{\"n\": 4763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.4195027351379395}", "{\"n\": 4764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.66, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4263997077941895}", "{\"n\": 4765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.85, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4312992095947266}", "{\"n\": 4766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.85, \"learn_time_ms\": 4.512, \"total_train_time_s\": 1.415924310684204}", "{\"n\": 4767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.89, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4251503944396973}", "{\"n\": 4768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.01, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4217958450317383}", "{\"n\": 4769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4332530498504639}", "{\"n\": 4770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4196078777313232}", "{\"n\": 4771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.6, \"learn_time_ms\": 4.55, \"total_train_time_s\": 1.5362341403961182}", "{\"n\": 4772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.66, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4081099033355713}", "{\"n\": 4773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.76, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4284794330596924}", "{\"n\": 4774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.76, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.409663438796997}", "{\"n\": 4775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.419694185256958}", "{\"n\": 4776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.96, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4196274280548096}", "{\"n\": 4777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.421769618988037}", "{\"n\": 4778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4041924476623535}", "{\"n\": 4779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.266, \"total_train_time_s\": 1.4324002265930176}", "{\"n\": 4780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4347376823425293}", "{\"n\": 4781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4468228816986084}", "{\"n\": 4782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4058210849761963}", "{\"n\": 4783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.68, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4322364330291748}", "{\"n\": 4784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4003078937530518}", "{\"n\": 4785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4096176624298096}", "{\"n\": 4786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.3998243808746338}", "{\"n\": 4787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.53, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4454965591430664}", "{\"n\": 4788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.531, \"total_train_time_s\": 1.4288215637207031}", "{\"n\": 4789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4537086486816406}", "{\"n\": 4790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4123785495758057}", "{\"n\": 4791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.67, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4370918273925781}", "{\"n\": 4792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.66, \"learn_time_ms\": 4.336, \"total_train_time_s\": 1.4193737506866455}", "{\"n\": 4793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.57, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4216294288635254}", "{\"n\": 4794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4271693229675293}", "{\"n\": 4795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.59, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4353399276733398}", "{\"n\": 4796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.82, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4276297092437744}", "{\"n\": 4797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4155583381652832}", "{\"n\": 4798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4500846862792969}", "{\"n\": 4799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.56, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4509825706481934}", "{\"n\": 4800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.46, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4304072856903076}", "{\"n\": 4801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.46, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4001426696777344}", "{\"n\": 4802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.26, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.435960292816162}", "{\"n\": 4803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.97, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3903000354766846}", "{\"n\": 4804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.424490213394165}", "{\"n\": 4805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.98, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4207603931427002}", "{\"n\": 4806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.97, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4063496589660645}", "{\"n\": 4807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.99, \"learn_time_ms\": 4.248, \"total_train_time_s\": 1.4297325611114502}", "{\"n\": 4808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4410269260406494}", "{\"n\": 4809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4337677955627441}", "{\"n\": 4810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4070539474487305}", "{\"n\": 4811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.27, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.4408965110778809}", "{\"n\": 4812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4455056190490723}", "{\"n\": 4813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.399717092514038}", "{\"n\": 4814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.41, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4298982620239258}", "{\"n\": 4815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.32, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4184563159942627}", "{\"n\": 4816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4349794387817383}", "{\"n\": 4817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4144656658172607}", "{\"n\": 4818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.419954776763916}", "{\"n\": 4819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.4465115070343018}", "{\"n\": 4820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4116361141204834}", "{\"n\": 4821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.427128791809082}", "{\"n\": 4822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.85, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4248147010803223}", "{\"n\": 4823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.4452290534973145}", "{\"n\": 4824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.7, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4342994689941406}", "{\"n\": 4825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.7, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.417985200881958}", "{\"n\": 4826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.7, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.410902500152588}", "{\"n\": 4827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.03, \"learn_time_ms\": 4.534, \"total_train_time_s\": 1.4268476963043213}", "{\"n\": 4828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4520649909973145}", "{\"n\": 4829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.92, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.402949333190918}", "{\"n\": 4830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4267635345458984}", "{\"n\": 4831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4087824821472168}", "{\"n\": 4832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4147918224334717}", "{\"n\": 4833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4298672676086426}", "{\"n\": 4834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.59, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.446434497833252}", "{\"n\": 4835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.65, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4447157382965088}", "{\"n\": 4836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4231889247894287}", "{\"n\": 4837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.421449899673462}", "{\"n\": 4838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4351537227630615}", "{\"n\": 4839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.5, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4097576141357422}", "{\"n\": 4840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.54, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4042243957519531}", "{\"n\": 4841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.54, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4087214469909668}", "{\"n\": 4842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.36, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4528615474700928}", "{\"n\": 4843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.36, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4301068782806396}", "{\"n\": 4844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.17, \"learn_time_ms\": 4.518, \"total_train_time_s\": 1.433030366897583}", "{\"n\": 4845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.17, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4021315574645996}", "{\"n\": 4846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.06, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4253456592559814}", "{\"n\": 4847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.441239356994629}", "{\"n\": 4848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4168949127197266}", "{\"n\": 4849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4210407733917236}", "{\"n\": 4850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.09, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4193003177642822}", "{\"n\": 4851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.0, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.4354021549224854}", "{\"n\": 4852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.34, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.451080560684204}", "{\"n\": 4853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.34, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4241185188293457}", "{\"n\": 4854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.37, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4461171627044678}", "{\"n\": 4855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.46, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4253768920898438}", "{\"n\": 4856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.52, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.451157569885254}", "{\"n\": 4857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.52, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4389772415161133}", "{\"n\": 4858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.45, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4126064777374268}", "{\"n\": 4859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.72, \"learn_time_ms\": 4.23, \"total_train_time_s\": 1.3976051807403564}", "{\"n\": 4860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.424173355102539}", "{\"n\": 4861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4061126708984375}", "{\"n\": 4862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.01, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4300570487976074}", "{\"n\": 4863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.93, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4284520149230957}", "{\"n\": 4864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4141995906829834}", "{\"n\": 4865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.1, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4185240268707275}", "{\"n\": 4866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.37, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4147944450378418}", "{\"n\": 4867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.39, \"learn_time_ms\": 4.539, \"total_train_time_s\": 1.4193952083587646}", "{\"n\": 4868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4309704303741455}", "{\"n\": 4869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.396040678024292}", "{\"n\": 4870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.14, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.4297397136688232}", "{\"n\": 4871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.16, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4048714637756348}", "{\"n\": 4872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.92, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.41347074508667}", "{\"n\": 4873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.92, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.3870596885681152}", "{\"n\": 4874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.1, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.435802698135376}", "{\"n\": 4875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.36, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4194684028625488}", "{\"n\": 4876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.412555456161499}", "{\"n\": 4877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.4, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4124739170074463}", "{\"n\": 4878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.436861276626587}", "{\"n\": 4879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.5248141288757324}", "{\"n\": 4880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.96, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4272642135620117}", "{\"n\": 4881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4148008823394775}", "{\"n\": 4882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.432652235031128}", "{\"n\": 4883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.27, \"learn_time_ms\": 4.46, \"total_train_time_s\": 1.4165940284729004}", "{\"n\": 4884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.36, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4177405834197998}", "{\"n\": 4885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.74, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4105582237243652}", "{\"n\": 4886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.64, \"learn_time_ms\": 4.471, \"total_train_time_s\": 1.4171819686889648}", "{\"n\": 4887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.39, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4342663288116455}", "{\"n\": 4888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.29, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4413633346557617}", "{\"n\": 4889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.59, \"learn_time_ms\": 4.412, \"total_train_time_s\": 1.4323968887329102}", "{\"n\": 4890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.8, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4375600814819336}", "{\"n\": 4891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4162235260009766}", "{\"n\": 4892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.07, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4182813167572021}", "{\"n\": 4893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.11, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4105713367462158}", "{\"n\": 4894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.02, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4309909343719482}", "{\"n\": 4895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.02, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.391474962234497}", "{\"n\": 4896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.99, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4138734340667725}", "{\"n\": 4897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.57, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4168851375579834}", "{\"n\": 4898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.76, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4260187149047852}", "{\"n\": 4899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4008777141571045}", "{\"n\": 4900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.05, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4234411716461182}", "{\"n\": 4901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.12, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4118931293487549}", "{\"n\": 4902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.61, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.414470911026001}", "{\"n\": 4903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.421546220779419}", "{\"n\": 4904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.57, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.3929479122161865}", "{\"n\": 4905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.64, \"learn_time_ms\": 4.48, \"total_train_time_s\": 1.4167282581329346}", "{\"n\": 4906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.78, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.4434092044830322}", "{\"n\": 4907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.81, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4427707195281982}", "{\"n\": 4908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.81, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.3874919414520264}", "{\"n\": 4909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.75, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4388322830200195}", "{\"n\": 4910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.72, \"learn_time_ms\": 4.576, \"total_train_time_s\": 1.4072229862213135}", "{\"n\": 4911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.6, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4238007068634033}", "{\"n\": 4912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.6, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.417759656906128}", "{\"n\": 4913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.57, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.395279884338379}", "{\"n\": 4914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.57, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4070730209350586}", "{\"n\": 4915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.45, \"learn_time_ms\": 4.461, \"total_train_time_s\": 1.442497730255127}", "{\"n\": 4916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.422318696975708}", "{\"n\": 4917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4150254726409912}", "{\"n\": 4918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.12, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4377400875091553}", "{\"n\": 4919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.41, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.450319528579712}", "{\"n\": 4920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.34, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4050896167755127}", "{\"n\": 4921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.32, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4122159481048584}", "{\"n\": 4922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.32, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.3956916332244873}", "{\"n\": 4923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.13, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4246852397918701}", "{\"n\": 4924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.26, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4384429454803467}", "{\"n\": 4925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4175395965576172}", "{\"n\": 4926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3961853981018066}", "{\"n\": 4927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.404667854309082}", "{\"n\": 4928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.3999817371368408}", "{\"n\": 4929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4248859882354736}", "{\"n\": 4930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.391477108001709}", "{\"n\": 4931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.68, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4449987411499023}", "{\"n\": 4932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.62, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.399806022644043}", "{\"n\": 4933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4158456325531006}", "{\"n\": 4934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4050188064575195}", "{\"n\": 4935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4370431900024414}", "{\"n\": 4936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.44, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4147143363952637}", "{\"n\": 4937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.54, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4034521579742432}", "{\"n\": 4938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.54, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.395707368850708}", "{\"n\": 4939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4033255577087402}", "{\"n\": 4940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4200356006622314}", "{\"n\": 4941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4288747310638428}", "{\"n\": 4942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4071109294891357}", "{\"n\": 4943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.9, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.423516035079956}", "{\"n\": 4944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.87, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4190430641174316}", "{\"n\": 4945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4195430278778076}", "{\"n\": 4946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4014859199523926}", "{\"n\": 4947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.92, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4003822803497314}", "{\"n\": 4948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.92, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.417708396911621}", "{\"n\": 4949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.4178171157836914}", "{\"n\": 4950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.235, \"total_train_time_s\": 1.3881044387817383}", "{\"n\": 4951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.92, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4252991676330566}", "{\"n\": 4952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4100227355957031}", "{\"n\": 4953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.08, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.405167818069458}", "{\"n\": 4954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.99, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.391963005065918}", "{\"n\": 4955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4143009185791016}", "{\"n\": 4956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.74, \"learn_time_ms\": 4.22, \"total_train_time_s\": 1.4054758548736572}", "{\"n\": 4957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.65, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4080896377563477}", "{\"n\": 4958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4120688438415527}", "{\"n\": 4959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.42, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4169793128967285}", "{\"n\": 4960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1031.46, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4070255756378174}", "{\"n\": 4961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.24, \"total_train_time_s\": 1.3836510181427002}", "{\"n\": 4962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4025707244873047}", "{\"n\": 4963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.61, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4257423877716064}", "{\"n\": 4964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.6, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.427724838256836}", "{\"n\": 4965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.6, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4222800731658936}", "{\"n\": 4966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4079725742340088}", "{\"n\": 4967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.48, \"learn_time_ms\": 4.456, \"total_train_time_s\": 1.4261646270751953}", "{\"n\": 4968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4320530891418457}", "{\"n\": 4969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1029.62, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4041752815246582}", "{\"n\": 4970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1029.62, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4102718830108643}", "{\"n\": 4971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.6, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4328815937042236}", "{\"n\": 4972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.6, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4058969020843506}", "{\"n\": 4973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4101934432983398}", "{\"n\": 4974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4350049495697021}", "{\"n\": 4975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.44, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.420776128768921}", "{\"n\": 4976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.18, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4297244548797607}", "{\"n\": 4977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4064810276031494}", "{\"n\": 4978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4153807163238525}", "{\"n\": 4979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.01, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4157483577728271}", "{\"n\": 4980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.52, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.4178807735443115}", "{\"n\": 4981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.09, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4084789752960205}", "{\"n\": 4982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.09, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.3984620571136475}", "{\"n\": 4983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.84, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4258697032928467}", "{\"n\": 4984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.63, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4227142333984375}", "{\"n\": 4985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.58, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4092445373535156}", "{\"n\": 4986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.58, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4125618934631348}", "{\"n\": 4987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.77, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.5430567264556885}", "{\"n\": 4988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.6, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.453045129776001}", "{\"n\": 4989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.72, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.3948214054107666}", "{\"n\": 4990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.72, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4231467247009277}", "{\"n\": 4991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.53, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4028797149658203}", "{\"n\": 4992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.413898229598999}", "{\"n\": 4993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4411046504974365}", "{\"n\": 4994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.414903163909912}", "{\"n\": 4995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.09, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.392277479171753}", "{\"n\": 4996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.05, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.427258014678955}", "{\"n\": 4997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.08, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4173965454101562}", "{\"n\": 4998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.08, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4070513248443604}", "{\"n\": 4999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.25, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4175279140472412}", "{\"n\": 5000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.68, \"learn_time_ms\": 4.598, \"total_train_time_s\": 1.4250733852386475}", "{\"n\": 5001, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.404327392578125}", "{\"n\": 5002, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4167253971099854}", "{\"n\": 5003, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.15, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4025132656097412}", "{\"n\": 5004, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.71, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.418468713760376}", "{\"n\": 5005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.445044994354248}", "{\"n\": 5006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.55, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4240171909332275}", "{\"n\": 5007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.77, \"learn_time_ms\": 4.476, \"total_train_time_s\": 1.414367437362671}", "{\"n\": 5008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.8, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4068894386291504}", "{\"n\": 5009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.231, \"total_train_time_s\": 1.4040157794952393}", "{\"n\": 5010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.411893606185913}", "{\"n\": 5011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.18, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4133033752441406}", "{\"n\": 5012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.17, \"learn_time_ms\": 4.252, \"total_train_time_s\": 1.4412360191345215}", "{\"n\": 5013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.421872854232788}", "{\"n\": 5014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.22, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.449080467224121}", "{\"n\": 5015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.56, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4243814945220947}", "{\"n\": 5016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.3917968273162842}", "{\"n\": 5017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3934450149536133}", "{\"n\": 5018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4433140754699707}", "{\"n\": 5019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.68, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4198689460754395}", "{\"n\": 5020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.31, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4190647602081299}", "{\"n\": 5021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.4147396087646484}", "{\"n\": 5022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4261701107025146}", "{\"n\": 5023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4424285888671875}", "{\"n\": 5024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.49, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.43359375}", "{\"n\": 5025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.79, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4511563777923584}", "{\"n\": 5026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.79, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4145779609680176}", "{\"n\": 5027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.79, \"learn_time_ms\": 4.235, \"total_train_time_s\": 1.4148223400115967}", "{\"n\": 5028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.420609474182129}", "{\"n\": 5029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.79, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4371075630187988}", "{\"n\": 5030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.79, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.3914401531219482}", "{\"n\": 5031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.79, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.3976151943206787}", "{\"n\": 5032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.56, \"learn_time_ms\": 4.554, \"total_train_time_s\": 1.4577982425689697}", "{\"n\": 5033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.33, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.436469554901123}", "{\"n\": 5034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.33, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.394831895828247}", "{\"n\": 5035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.16, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.3912303447723389}", "{\"n\": 5036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.17, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4119625091552734}", "{\"n\": 5037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4285342693328857}", "{\"n\": 5038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4203708171844482}", "{\"n\": 5039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3868052959442139}", "{\"n\": 5040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.45, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.3981695175170898}", "{\"n\": 5041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.24, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4374845027923584}", "{\"n\": 5042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.25, \"learn_time_ms\": 4.514, \"total_train_time_s\": 1.4161286354064941}", "{\"n\": 5043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.2, \"learn_time_ms\": 4.189, \"total_train_time_s\": 1.412792682647705}", "{\"n\": 5044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.19, \"learn_time_ms\": 4.569, \"total_train_time_s\": 1.4557156562805176}", "{\"n\": 5045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.34, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.420893669128418}", "{\"n\": 5046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.42, \"learn_time_ms\": 4.214, \"total_train_time_s\": 1.404524564743042}", "{\"n\": 5047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.33, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.4164886474609375}", "{\"n\": 5048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.3, \"learn_time_ms\": 4.262, \"total_train_time_s\": 1.4011225700378418}", "{\"n\": 5049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.28, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4150779247283936}", "{\"n\": 5050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.8, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.3863723278045654}", "{\"n\": 5051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.83, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4310128688812256}", "{\"n\": 5052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.98, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4145421981811523}", "{\"n\": 5053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.82, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4225101470947266}", "{\"n\": 5054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.82, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.3869493007659912}", "{\"n\": 5055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.77, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4407875537872314}", "{\"n\": 5056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.89, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4284543991088867}", "{\"n\": 5057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.95, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4244239330291748}", "{\"n\": 5058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.95, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.3954551219940186}", "{\"n\": 5059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.07, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4276933670043945}", "{\"n\": 5060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.02, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4106431007385254}", "{\"n\": 5061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.97, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4072811603546143}", "{\"n\": 5062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.97, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.392852544784546}", "{\"n\": 5063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.94, \"learn_time_ms\": 4.483, \"total_train_time_s\": 1.397063970565796}", "{\"n\": 5064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.67, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4225223064422607}", "{\"n\": 5065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.53, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4426217079162598}", "{\"n\": 5066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.53, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.386185646057129}", "{\"n\": 5067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.66, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4016079902648926}", "{\"n\": 5068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.72, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.43638277053833}", "{\"n\": 5069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.55, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4162733554840088}", "{\"n\": 5070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.71, \"learn_time_ms\": 4.489, \"total_train_time_s\": 1.428079605102539}", "{\"n\": 5071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.09, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.7256193161010742}", "{\"n\": 5072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.37, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4239904880523682}", "{\"n\": 5073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.99, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4080729484558105}", "{\"n\": 5074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.45, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4358875751495361}", "{\"n\": 5075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.54, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.40199875831604}", "{\"n\": 5076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.21, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4177253246307373}", "{\"n\": 5077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.21, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.4184093475341797}", "{\"n\": 5078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.02, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4111015796661377}", "{\"n\": 5079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.7, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.437673568725586}", "{\"n\": 5080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.83, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4147069454193115}", "{\"n\": 5081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.83, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.3870785236358643}", "{\"n\": 5082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.64, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4287407398223877}", "{\"n\": 5083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.49, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4024415016174316}", "{\"n\": 5084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.64, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.420710802078247}", "{\"n\": 5085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.64, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4252293109893799}", "{\"n\": 5086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4274516105651855}", "{\"n\": 5087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.84, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4340076446533203}", "{\"n\": 5088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.91, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4563493728637695}", "{\"n\": 5089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.91, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4147017002105713}", "{\"n\": 5090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.9, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4061293601989746}", "{\"n\": 5091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.34, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4097957611083984}", "{\"n\": 5092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.26, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4445533752441406}", "{\"n\": 5093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.26, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4179041385650635}", "{\"n\": 5094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.28, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.3997278213500977}", "{\"n\": 5095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.47, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4335355758666992}", "{\"n\": 5096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.62, \"learn_time_ms\": 4.209, \"total_train_time_s\": 1.425271987915039}", "{\"n\": 5097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.62, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4006266593933105}", "{\"n\": 5098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.81, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4184088706970215}", "{\"n\": 5099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.81, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.405170202255249}", "{\"n\": 5100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.95, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4229364395141602}", "{\"n\": 5101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.95, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4011344909667969}", "{\"n\": 5102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4053854942321777}", "{\"n\": 5103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.86, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4038052558898926}", "{\"n\": 5104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.464, \"total_train_time_s\": 1.429758071899414}", "{\"n\": 5105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.77, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4057106971740723}", "{\"n\": 5106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4161620140075684}", "{\"n\": 5107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4017047882080078}", "{\"n\": 5108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.19, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4510209560394287}", "{\"n\": 5109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.19, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.3855023384094238}", "{\"n\": 5110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.6, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4389100074768066}", "{\"n\": 5111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.6, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4023199081420898}", "{\"n\": 5112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.36, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4235782623291016}", "{\"n\": 5113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.36, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.3877999782562256}", "{\"n\": 5114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4309263229370117}", "{\"n\": 5115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.16, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4106454849243164}", "{\"n\": 5116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.07, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4251534938812256}", "{\"n\": 5117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.07, \"learn_time_ms\": 4.484, \"total_train_time_s\": 1.4203217029571533}", "{\"n\": 5118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4350244998931885}", "{\"n\": 5119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.12, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4092340469360352}", "{\"n\": 5120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.36, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.440185785293579}", "{\"n\": 5121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.36, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4120209217071533}", "{\"n\": 5122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.26, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4098410606384277}", "{\"n\": 5123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.26, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.3916676044464111}", "{\"n\": 5124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.29, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4385285377502441}", "{\"n\": 5125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.29, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4113500118255615}", "{\"n\": 5126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.99, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.432832956314087}", "{\"n\": 5127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.99, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.409731149673462}", "{\"n\": 5128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.0, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4093468189239502}", "{\"n\": 5129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.0, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4037129878997803}", "{\"n\": 5130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.437067985534668}", "{\"n\": 5131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4205384254455566}", "{\"n\": 5132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4332728385925293}", "{\"n\": 5133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.6, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4536981582641602}", "{\"n\": 5134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.51, \"total_train_time_s\": 1.4197375774383545}", "{\"n\": 5135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.55, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4248571395874023}", "{\"n\": 5136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4175596237182617}", "{\"n\": 5137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.67, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.4395415782928467}", "{\"n\": 5138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.5, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4193856716156006}", "{\"n\": 5139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.5, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4178848266601562}", "{\"n\": 5140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.45, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4425296783447266}", "{\"n\": 5141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4137146472930908}", "{\"n\": 5142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.49, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4480681419372559}", "{\"n\": 5143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.49, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4051003456115723}", "{\"n\": 5144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.52, \"learn_time_ms\": 4.388, \"total_train_time_s\": 1.4446415901184082}", "{\"n\": 5145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.4235994815826416}", "{\"n\": 5146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.48, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4221935272216797}", "{\"n\": 5147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.48, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.3891627788543701}", "{\"n\": 5148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.85, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4438645839691162}", "{\"n\": 5149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.95, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4379661083221436}", "{\"n\": 5150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.4, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4109938144683838}", "{\"n\": 5151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.4, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4132192134857178}", "{\"n\": 5152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.42, \"learn_time_ms\": 4.534, \"total_train_time_s\": 1.4272572994232178}", "{\"n\": 5153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.37, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.435868740081787}", "{\"n\": 5154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.46, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4252047538757324}", "{\"n\": 5155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.46, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4070677757263184}", "{\"n\": 5156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.57, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4416837692260742}", "{\"n\": 5157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4313175678253174}", "{\"n\": 5158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.49, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.42661714553833}", "{\"n\": 5159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.49, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4183201789855957}", "{\"n\": 5160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4288158416748047}", "{\"n\": 5161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.33, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.415565013885498}", "{\"n\": 5162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.458, \"total_train_time_s\": 1.4311301708221436}", "{\"n\": 5163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.32, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4086723327636719}", "{\"n\": 5164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4447975158691406}", "{\"n\": 5165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.67, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.3992795944213867}", "{\"n\": 5166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.75, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4234273433685303}", "{\"n\": 5167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.75, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4168615341186523}", "{\"n\": 5168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.414630651473999}", "{\"n\": 5169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.68, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4381952285766602}", "{\"n\": 5170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.64, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4208202362060547}", "{\"n\": 5171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.64, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.393418312072754}", "{\"n\": 5172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4568393230438232}", "{\"n\": 5173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.71, \"learn_time_ms\": 4.494, \"total_train_time_s\": 1.4366521835327148}", "{\"n\": 5174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.526, \"total_train_time_s\": 1.4392166137695312}", "{\"n\": 5175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.78, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.3894126415252686}", "{\"n\": 5176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.54, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4112045764923096}", "{\"n\": 5177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4137706756591797}", "{\"n\": 5178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.3991611003875732}", "{\"n\": 5179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.373406171798706}", "{\"n\": 5180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4842393398284912}", "{\"n\": 5181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.27, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.422191858291626}", "{\"n\": 5182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.27, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.388200044631958}", "{\"n\": 5183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.03, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4161922931671143}", "{\"n\": 5184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.7, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4344749450683594}", "{\"n\": 5185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.64, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.3961951732635498}", "{\"n\": 5186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.64, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4219708442687988}", "{\"n\": 5187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.403376579284668}", "{\"n\": 5188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4223651885986328}", "{\"n\": 5189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.11, \"learn_time_ms\": 4.438, \"total_train_time_s\": 1.4188363552093506}", "{\"n\": 5190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.11, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.430750846862793}", "{\"n\": 5191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.11, \"learn_time_ms\": 4.505, \"total_train_time_s\": 1.4024722576141357}", "{\"n\": 5192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.4409584999084473}", "{\"n\": 5193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4151034355163574}", "{\"n\": 5194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.34, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.3919751644134521}", "{\"n\": 5195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.32, \"learn_time_ms\": 4.433, \"total_train_time_s\": 1.404097080230713}", "{\"n\": 5196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.523817777633667}", "{\"n\": 5197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.31, \"learn_time_ms\": 4.194, \"total_train_time_s\": 1.4127466678619385}", "{\"n\": 5198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.03, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.394820213317871}", "{\"n\": 5199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.92, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.420386791229248}", "{\"n\": 5200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4207303524017334}", "{\"n\": 5201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.3808724880218506}", "{\"n\": 5202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.48, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.399442434310913}", "{\"n\": 5203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 4.529, \"total_train_time_s\": 1.4118995666503906}", "{\"n\": 5204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.428900957107544}", "{\"n\": 5205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.37, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4297194480895996}", "{\"n\": 5206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4013962745666504}", "{\"n\": 5207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.44, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4086072444915771}", "{\"n\": 5208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.4610071182250977}", "{\"n\": 5209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.4281165599822998}", "{\"n\": 5210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.78, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4089345932006836}", "{\"n\": 5211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.85, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4242527484893799}", "{\"n\": 5212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4307169914245605}", "{\"n\": 5213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4076228141784668}", "{\"n\": 5214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.0, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.405139446258545}", "{\"n\": 5215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.01, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4014544486999512}", "{\"n\": 5216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4148471355438232}", "{\"n\": 5217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4208455085754395}", "{\"n\": 5218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.93, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.3940768241882324}", "{\"n\": 5219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.87, \"learn_time_ms\": 4.204, \"total_train_time_s\": 1.4336819648742676}", "{\"n\": 5220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.4115283489227295}", "{\"n\": 5221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.75, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.38619065284729}", "{\"n\": 5222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.77, \"learn_time_ms\": 4.515, \"total_train_time_s\": 1.4095103740692139}", "{\"n\": 5223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.68, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4330661296844482}", "{\"n\": 5224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.423839807510376}", "{\"n\": 5225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.3976500034332275}", "{\"n\": 5226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.36, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.3970019817352295}", "{\"n\": 5227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.47, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4147801399230957}", "{\"n\": 5228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.31, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4361047744750977}", "{\"n\": 5229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.31, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.398291826248169}", "{\"n\": 5230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.2, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.4121465682983398}", "{\"n\": 5231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.33, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.4070007801055908}", "{\"n\": 5232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.4436986446380615}", "{\"n\": 5233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.96, \"learn_time_ms\": 4.536, \"total_train_time_s\": 1.4134266376495361}", "{\"n\": 5234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4250459671020508}", "{\"n\": 5235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.83, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4262135028839111}", "{\"n\": 5236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.416849136352539}", "{\"n\": 5237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4146029949188232}", "{\"n\": 5238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.59, \"learn_time_ms\": 4.368, \"total_train_time_s\": 1.4166040420532227}", "{\"n\": 5239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.79, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.397585391998291}", "{\"n\": 5240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.79, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.413788080215454}", "{\"n\": 5241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.66, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4268798828125}", "{\"n\": 5242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.4146792888641357}", "{\"n\": 5243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.61, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.39695405960083}", "{\"n\": 5244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4502770900726318}", "{\"n\": 5245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.97, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.41786789894104}", "{\"n\": 5246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4071695804595947}", "{\"n\": 5247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.399951457977295}", "{\"n\": 5248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.9, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4363956451416016}", "{\"n\": 5249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.9, \"learn_time_ms\": 4.487, \"total_train_time_s\": 1.4200925827026367}", "{\"n\": 5250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.9, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4408245086669922}", "{\"n\": 5251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.76, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4252548217773438}", "{\"n\": 5252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.37, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4388010501861572}", "{\"n\": 5253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.1, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4268319606781006}", "{\"n\": 5254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.1, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4169859886169434}", "{\"n\": 5255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.63, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4262514114379883}", "{\"n\": 5256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.46, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4156849384307861}", "{\"n\": 5257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.44, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4084792137145996}", "{\"n\": 5258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.44, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.3978893756866455}", "{\"n\": 5259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.92, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4349870681762695}", "{\"n\": 5260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4447922706604004}", "{\"n\": 5261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.4297254085540771}", "{\"n\": 5262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 4.618, \"total_train_time_s\": 1.410050392150879}", "{\"n\": 5263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.39, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4096217155456543}", "{\"n\": 5264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4298861026763916}", "{\"n\": 5265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4162566661834717}", "{\"n\": 5266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4230031967163086}", "{\"n\": 5267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.21, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4267199039459229}", "{\"n\": 5268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4677972793579102}", "{\"n\": 5269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4030389785766602}", "{\"n\": 5270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.11, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4036672115325928}", "{\"n\": 5271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.01, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.4153950214385986}", "{\"n\": 5272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.83, \"learn_time_ms\": 4.27, \"total_train_time_s\": 1.4147894382476807}", "{\"n\": 5273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.83, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.383662223815918}", "{\"n\": 5274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4054255485534668}", "{\"n\": 5275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4128961563110352}", "{\"n\": 5276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4294495582580566}", "{\"n\": 5277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.4199447631835938}", "{\"n\": 5278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.95, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4311928749084473}", "{\"n\": 5279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.95, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4084861278533936}", "{\"n\": 5280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.02, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4282031059265137}", "{\"n\": 5281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.02, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4185612201690674}", "{\"n\": 5282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.04, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4329988956451416}", "{\"n\": 5283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.04, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.408130168914795}", "{\"n\": 5284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.88, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.448625087738037}", "{\"n\": 5285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.88, \"learn_time_ms\": 4.255, \"total_train_time_s\": 1.4176924228668213}", "{\"n\": 5286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.88, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4288604259490967}", "{\"n\": 5287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.71, \"learn_time_ms\": 4.475, \"total_train_time_s\": 1.410388469696045}", "{\"n\": 5288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4389135837554932}", "{\"n\": 5289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4041743278503418}", "{\"n\": 5290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.42799973487854}", "{\"n\": 5291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.35, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4183695316314697}", "{\"n\": 5292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.446455478668213}", "{\"n\": 5293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.413343906402588}", "{\"n\": 5294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4121506214141846}", "{\"n\": 5295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4139282703399658}", "{\"n\": 5296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4430274963378906}", "{\"n\": 5297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.4339015483856201}", "{\"n\": 5298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4051854610443115}", "{\"n\": 5299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.72, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4041776657104492}", "{\"n\": 5300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4337644577026367}", "{\"n\": 5301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4169790744781494}", "{\"n\": 5302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.77, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.3914790153503418}", "{\"n\": 5303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.16, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4118828773498535}", "{\"n\": 5304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.531050682067871}", "{\"n\": 5305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4014933109283447}", "{\"n\": 5306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.42, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.3967766761779785}", "{\"n\": 5307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.57, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4025459289550781}", "{\"n\": 5308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.54, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4357588291168213}", "{\"n\": 5309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.54, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.411217451095581}", "{\"n\": 5310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.54, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4191744327545166}", "{\"n\": 5311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4407172203063965}", "{\"n\": 5312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4411582946777344}", "{\"n\": 5313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.443507194519043}", "{\"n\": 5314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.5, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.3860151767730713}", "{\"n\": 5315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.6, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4221985340118408}", "{\"n\": 5316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.62, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4350569248199463}", "{\"n\": 5317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4184036254882812}", "{\"n\": 5318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.51, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.3925597667694092}", "{\"n\": 5319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.45, \"learn_time_ms\": 4.477, \"total_train_time_s\": 1.4453086853027344}", "{\"n\": 5320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.7, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4229600429534912}", "{\"n\": 5321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.7, \"learn_time_ms\": 4.481, \"total_train_time_s\": 1.4119641780853271}", "{\"n\": 5322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.7, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4131646156311035}", "{\"n\": 5323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.73, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4101197719573975}", "{\"n\": 5324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.455552339553833}", "{\"n\": 5325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.3952898979187012}", "{\"n\": 5326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.3988423347473145}", "{\"n\": 5327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.41, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.4004871845245361}", "{\"n\": 5328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4444079399108887}", "{\"n\": 5329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.415179967880249}", "{\"n\": 5330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.399857759475708}", "{\"n\": 5331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.82, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4391851425170898}", "{\"n\": 5332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.96, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.4526355266571045}", "{\"n\": 5333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4052772521972656}", "{\"n\": 5334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.406639575958252}", "{\"n\": 5335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.3921010494232178}", "{\"n\": 5336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.3937702178955078}", "{\"n\": 5337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.61, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4251234531402588}", "{\"n\": 5338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.61, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.3968009948730469}", "{\"n\": 5339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.61, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.432035207748413}", "{\"n\": 5340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.19, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4301042556762695}", "{\"n\": 5341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.415708303451538}", "{\"n\": 5342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.3965013027191162}", "{\"n\": 5343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.41, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4308815002441406}", "{\"n\": 5344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.6, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4375336170196533}", "{\"n\": 5345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4155888557434082}", "{\"n\": 5346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.391, \"total_train_time_s\": 1.4094693660736084}", "{\"n\": 5347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.406996488571167}", "{\"n\": 5348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.45, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4166765213012695}", "{\"n\": 5349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.77, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4541592597961426}", "{\"n\": 5350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.77, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4153776168823242}", "{\"n\": 5351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.77, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4061598777770996}", "{\"n\": 5352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.79, \"learn_time_ms\": 4.308, \"total_train_time_s\": 1.4178454875946045}", "{\"n\": 5353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4523379802703857}", "{\"n\": 5354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.451, \"total_train_time_s\": 1.3844237327575684}", "{\"n\": 5355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.229, \"total_train_time_s\": 1.4145960807800293}", "{\"n\": 5356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.35, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.3941349983215332}", "{\"n\": 5357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4515795707702637}", "{\"n\": 5358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.25, \"total_train_time_s\": 1.4116322994232178}", "{\"n\": 5359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.43, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.3852510452270508}", "{\"n\": 5360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.85, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4181277751922607}", "{\"n\": 5361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4342782497406006}", "{\"n\": 5362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.541, \"total_train_time_s\": 1.4073452949523926}", "{\"n\": 5363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4040956497192383}", "{\"n\": 5364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.82, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4315245151519775}", "{\"n\": 5365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.75, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4080138206481934}", "{\"n\": 5366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.75, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4296691417694092}", "{\"n\": 5367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.75, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4181840419769287}", "{\"n\": 5368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.61, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4464867115020752}", "{\"n\": 5369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.54, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4169464111328125}", "{\"n\": 5370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.54, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4127576351165771}", "{\"n\": 5371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.54, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.4118409156799316}", "{\"n\": 5372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.84, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4558119773864746}", "{\"n\": 5373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.58, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.4486489295959473}", "{\"n\": 5374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.58, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4318509101867676}", "{\"n\": 5375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.38, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4282619953155518}", "{\"n\": 5376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.25, \"learn_time_ms\": 4.22, \"total_train_time_s\": 1.4383134841918945}", "{\"n\": 5377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.33, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4332385063171387}", "{\"n\": 5378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.33, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4184160232543945}", "{\"n\": 5379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.18, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.417104721069336}", "{\"n\": 5380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.08, \"learn_time_ms\": 4.498, \"total_train_time_s\": 1.4342496395111084}", "{\"n\": 5381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.14, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4360549449920654}", "{\"n\": 5382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.14, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.417024850845337}", "{\"n\": 5383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.15, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4043936729431152}", "{\"n\": 5384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.4055418968200684}", "{\"n\": 5385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.15, \"learn_time_ms\": 4.403, \"total_train_time_s\": 1.464691400527954}", "{\"n\": 5386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.15, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.3998103141784668}", "{\"n\": 5387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.2, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.411163330078125}", "{\"n\": 5388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.3, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.426361083984375}", "{\"n\": 5389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.24, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4243137836456299}", "{\"n\": 5390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.24, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4069290161132812}", "{\"n\": 5391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.32, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4466743469238281}", "{\"n\": 5392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.51, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4295811653137207}", "{\"n\": 5393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4130454063415527}", "{\"n\": 5394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.58, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.416377305984497}", "{\"n\": 5395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.1, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4271132946014404}", "{\"n\": 5396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.4240520000457764}", "{\"n\": 5397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4596889019012451}", "{\"n\": 5398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.31, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.412895679473877}", "{\"n\": 5399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.35, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4279320240020752}", "{\"n\": 5400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.28, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4443471431732178}", "{\"n\": 5401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4493811130523682}", "{\"n\": 5402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 4.426, \"total_train_time_s\": 1.4168546199798584}", "{\"n\": 5403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.3, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4398934841156006}", "{\"n\": 5404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.17, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4273102283477783}", "{\"n\": 5405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.398771047592163}", "{\"n\": 5406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.46, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4246461391448975}", "{\"n\": 5407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.424682855606079}", "{\"n\": 5408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.52, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4195764064788818}", "{\"n\": 5409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.420191764831543}", "{\"n\": 5410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.398484706878662}", "{\"n\": 5411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.43, \"learn_time_ms\": 4.567, \"total_train_time_s\": 1.4251887798309326}", "{\"n\": 5412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.58, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.5523262023925781}", "{\"n\": 5413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.59, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4068505764007568}", "{\"n\": 5414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.59, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.3982925415039062}", "{\"n\": 5415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.56, \"learn_time_ms\": 4.436, \"total_train_time_s\": 1.4644594192504883}", "{\"n\": 5416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.4227204322814941}", "{\"n\": 5417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4061226844787598}", "{\"n\": 5418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4182653427124023}", "{\"n\": 5419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.49, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.410557746887207}", "{\"n\": 5420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.45, \"learn_time_ms\": 4.4, \"total_train_time_s\": 1.4114413261413574}", "{\"n\": 5421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4354827404022217}", "{\"n\": 5422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.32, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.417978048324585}", "{\"n\": 5423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.33, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4372026920318604}", "{\"n\": 5424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.57, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4189677238464355}", "{\"n\": 5425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.400521993637085}", "{\"n\": 5426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.3968770503997803}", "{\"n\": 5427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 4.272, \"total_train_time_s\": 1.4144008159637451}", "{\"n\": 5428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4244508743286133}", "{\"n\": 5429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.44, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4154918193817139}", "{\"n\": 5430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.12, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.418726921081543}", "{\"n\": 5431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.2, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4096834659576416}", "{\"n\": 5432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.09, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4138145446777344}", "{\"n\": 5433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.91, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4056854248046875}", "{\"n\": 5434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.29, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4560248851776123}", "{\"n\": 5435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.94, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.398991584777832}", "{\"n\": 5436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.77, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4244897365570068}", "{\"n\": 5437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.03, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.435462236404419}", "{\"n\": 5438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4191007614135742}", "{\"n\": 5439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.06, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.4536242485046387}", "{\"n\": 5440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.58, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4366683959960938}", "{\"n\": 5441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.61, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4374735355377197}", "{\"n\": 5442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.3921685218811035}", "{\"n\": 5443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.38, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4107420444488525}", "{\"n\": 5444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.07, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4097371101379395}", "{\"n\": 5445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.96, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4002459049224854}", "{\"n\": 5446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4110565185546875}", "{\"n\": 5447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.01, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4196529388427734}", "{\"n\": 5448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.16, \"learn_time_ms\": 4.282, \"total_train_time_s\": 1.4450106620788574}", "{\"n\": 5449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.449345350265503}", "{\"n\": 5450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4183201789855957}", "{\"n\": 5451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.04, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.3973147869110107}", "{\"n\": 5452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.4116315841674805}", "{\"n\": 5453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.65, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.414445400238037}", "{\"n\": 5454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4380648136138916}", "{\"n\": 5455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.63, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4111621379852295}", "{\"n\": 5456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.44, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4121744632720947}", "{\"n\": 5457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.536, \"total_train_time_s\": 1.4564344882965088}", "{\"n\": 5458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.3972868919372559}", "{\"n\": 5459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.3866918087005615}", "{\"n\": 5460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.45, \"learn_time_ms\": 4.431, \"total_train_time_s\": 1.3877031803131104}", "{\"n\": 5461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.51, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4229371547698975}", "{\"n\": 5462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4098389148712158}", "{\"n\": 5463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.47, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.3923137187957764}", "{\"n\": 5464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.37, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.405454158782959}", "{\"n\": 5465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.43, \"learn_time_ms\": 4.539, \"total_train_time_s\": 1.439976692199707}", "{\"n\": 5466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.15, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.443986415863037}", "{\"n\": 5467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.15, \"learn_time_ms\": 4.381, \"total_train_time_s\": 1.4040143489837646}", "{\"n\": 5468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.94, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4277067184448242}", "{\"n\": 5469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.15, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4260749816894531}", "{\"n\": 5470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4369182586669922}", "{\"n\": 5471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.396482229232788}", "{\"n\": 5472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.36, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4101428985595703}", "{\"n\": 5473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.39, \"learn_time_ms\": 4.271, \"total_train_time_s\": 1.4202589988708496}", "{\"n\": 5474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.56, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4089136123657227}", "{\"n\": 5475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.56, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.410938024520874}", "{\"n\": 5476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.57, \"learn_time_ms\": 4.246, \"total_train_time_s\": 1.414989948272705}", "{\"n\": 5477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.38, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4067940711975098}", "{\"n\": 5478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.49, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4261560440063477}", "{\"n\": 5479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.49, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4056541919708252}", "{\"n\": 5480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.296, \"total_train_time_s\": 1.3938045501708984}", "{\"n\": 5481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.72, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.408998727798462}", "{\"n\": 5482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.59, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4044501781463623}", "{\"n\": 5483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.59, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.390411615371704}", "{\"n\": 5484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.66, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4109106063842773}", "{\"n\": 5485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.55, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4375736713409424}", "{\"n\": 5486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.536, \"total_train_time_s\": 1.4344985485076904}", "{\"n\": 5487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4201765060424805}", "{\"n\": 5488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.7, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4237158298492432}", "{\"n\": 5489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.68, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4419915676116943}", "{\"n\": 5490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3990676403045654}", "{\"n\": 5491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.73, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.3998572826385498}", "{\"n\": 5492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.76, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4185466766357422}", "{\"n\": 5493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.91, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.7053179740905762}", "{\"n\": 5494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.88, \"learn_time_ms\": 4.479, \"total_train_time_s\": 1.4341015815734863}", "{\"n\": 5495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.88, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.3798127174377441}", "{\"n\": 5496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.88, \"learn_time_ms\": 4.366, \"total_train_time_s\": 1.3964059352874756}", "{\"n\": 5497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4083967208862305}", "{\"n\": 5498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.428361177444458}", "{\"n\": 5499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.256, \"total_train_time_s\": 1.4077587127685547}", "{\"n\": 5500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.84, \"learn_time_ms\": 4.446, \"total_train_time_s\": 1.4110946655273438}", "{\"n\": 5501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.66, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.441124677658081}", "{\"n\": 5502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.331, \"total_train_time_s\": 1.4392287731170654}", "{\"n\": 5503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.367006778717041}", "{\"n\": 5504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.74, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.4084889888763428}", "{\"n\": 5505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.57, \"learn_time_ms\": 4.443, \"total_train_time_s\": 1.437809705734253}", "{\"n\": 5506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.4036405086517334}", "{\"n\": 5507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.401521921157837}", "{\"n\": 5508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.32, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.3928356170654297}", "{\"n\": 5509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.19, \"learn_time_ms\": 4.339, \"total_train_time_s\": 1.463637351989746}", "{\"n\": 5510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.02, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4176900386810303}", "{\"n\": 5511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.02, \"learn_time_ms\": 4.583, \"total_train_time_s\": 1.4195668697357178}", "{\"n\": 5512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.02, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4152605533599854}", "{\"n\": 5513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.05, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.425199031829834}", "{\"n\": 5514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.93, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.4357409477233887}", "{\"n\": 5515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.93, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.4093225002288818}", "{\"n\": 5516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.86, \"learn_time_ms\": 4.376, \"total_train_time_s\": 1.446199893951416}", "{\"n\": 5517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.04, \"learn_time_ms\": 4.53, \"total_train_time_s\": 1.4237089157104492}", "{\"n\": 5518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.11, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4684336185455322}", "{\"n\": 5519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.11, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.375891923904419}", "{\"n\": 5520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.23, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.3905789852142334}", "{\"n\": 5521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.99, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4012751579284668}", "{\"n\": 5522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4217135906219482}", "{\"n\": 5523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.4107463359832764}", "{\"n\": 5524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.86, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4210588932037354}", "{\"n\": 5525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.13, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4134624004364014}", "{\"n\": 5526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.0, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4363713264465332}", "{\"n\": 5527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.0, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4088876247406006}", "{\"n\": 5528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.11, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4049677848815918}", "{\"n\": 5529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.17, \"learn_time_ms\": 4.384, \"total_train_time_s\": 1.4110500812530518}", "{\"n\": 5530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.47, \"learn_time_ms\": 4.281, \"total_train_time_s\": 1.4100921154022217}", "{\"n\": 5531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.47, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.3888905048370361}", "{\"n\": 5532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.43, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.408374309539795}", "{\"n\": 5533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.36, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4417781829833984}", "{\"n\": 5534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.15, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.419187068939209}", "{\"n\": 5535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.15, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4246511459350586}", "{\"n\": 5536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.09, \"learn_time_ms\": 4.268, \"total_train_time_s\": 1.450758934020996}", "{\"n\": 5537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.88, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4369676113128662}", "{\"n\": 5538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.01, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4352977275848389}", "{\"n\": 5539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.01, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.3984930515289307}", "{\"n\": 5540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.83, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4282920360565186}", "{\"n\": 5541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.93, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4096710681915283}", "{\"n\": 5542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4374969005584717}", "{\"n\": 5543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.14, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4035568237304688}", "{\"n\": 5544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.3855972290039062}", "{\"n\": 5545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.2, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4246044158935547}", "{\"n\": 5546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4119625091552734}", "{\"n\": 5547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.21, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.413341999053955}", "{\"n\": 5548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.27, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.3938398361206055}", "{\"n\": 5549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.07, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4245269298553467}", "{\"n\": 5550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4593279361724854}", "{\"n\": 5551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.3943803310394287}", "{\"n\": 5552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.42, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.4052906036376953}", "{\"n\": 5553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.432924509048462}", "{\"n\": 5554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4165887832641602}", "{\"n\": 5555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.55, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.3955285549163818}", "{\"n\": 5556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.37, \"learn_time_ms\": 4.524, \"total_train_time_s\": 1.41475248336792}", "{\"n\": 5557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.07, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4226458072662354}", "{\"n\": 5558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4250493049621582}", "{\"n\": 5559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.04, \"learn_time_ms\": 4.548, \"total_train_time_s\": 1.436403512954712}", "{\"n\": 5560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.13, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4052412509918213}", "{\"n\": 5561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.22, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4240808486938477}", "{\"n\": 5562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4347901344299316}", "{\"n\": 5563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.467, \"total_train_time_s\": 1.4734528064727783}", "{\"n\": 5564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4546241760253906}", "{\"n\": 5565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.39, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4301552772521973}", "{\"n\": 5566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.65, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4435107707977295}", "{\"n\": 5567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.65, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.4035634994506836}", "{\"n\": 5568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.98, \"learn_time_ms\": 4.242, \"total_train_time_s\": 1.4044394493103027}", "{\"n\": 5569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.92, \"learn_time_ms\": 4.31, \"total_train_time_s\": 1.4355311393737793}", "{\"n\": 5570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.43, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4475009441375732}", "{\"n\": 5571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.43, \"learn_time_ms\": 4.473, \"total_train_time_s\": 1.4192836284637451}", "{\"n\": 5572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.66, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4200608730316162}", "{\"n\": 5573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.53, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.3965528011322021}", "{\"n\": 5574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.48, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4151501655578613}", "{\"n\": 5575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.48, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4241859912872314}", "{\"n\": 5576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.66, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4015545845031738}", "{\"n\": 5577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.96, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4390296936035156}", "{\"n\": 5578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.95, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4349725246429443}", "{\"n\": 5579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.95, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.4333202838897705}", "{\"n\": 5580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.95, \"learn_time_ms\": 4.514, \"total_train_time_s\": 1.4415090084075928}", "{\"n\": 5581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.61, \"learn_time_ms\": 4.244, \"total_train_time_s\": 1.4555790424346924}", "{\"n\": 5582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.7, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4378464221954346}", "{\"n\": 5583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.7, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.3969898223876953}", "{\"n\": 5584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.7, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.415832757949829}", "{\"n\": 5585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.25, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.437732219696045}", "{\"n\": 5586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.15, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4183454513549805}", "{\"n\": 5587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.15, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4180452823638916}", "{\"n\": 5588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.15, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4113459587097168}", "{\"n\": 5589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.92, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4013252258300781}", "{\"n\": 5590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.4344704151153564}", "{\"n\": 5591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4060766696929932}", "{\"n\": 5592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.85, \"learn_time_ms\": 4.237, \"total_train_time_s\": 1.3926525115966797}", "{\"n\": 5593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.52, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.426159143447876}", "{\"n\": 5594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.47, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4030885696411133}", "{\"n\": 5595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.47, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4076018333435059}", "{\"n\": 5596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.47, \"learn_time_ms\": 4.347, \"total_train_time_s\": 1.396578073501587}", "{\"n\": 5597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.49, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4453036785125732}", "{\"n\": 5598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.55, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4187922477722168}", "{\"n\": 5599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.55, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.424696683883667}", "{\"n\": 5600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.55, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4139366149902344}", "{\"n\": 5601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.48, \"learn_time_ms\": 4.371, \"total_train_time_s\": 1.4546818733215332}", "{\"n\": 5602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.4, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4117491245269775}", "{\"n\": 5603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.4, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4113786220550537}", "{\"n\": 5604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.4, \"learn_time_ms\": 4.39, \"total_train_time_s\": 1.4318444728851318}", "{\"n\": 5605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.58, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4663293361663818}", "{\"n\": 5606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.393225908279419}", "{\"n\": 5607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.4132490158081055}", "{\"n\": 5608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.81, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.423327922821045}", "{\"n\": 5609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.84, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4546270370483398}", "{\"n\": 5610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.263, \"total_train_time_s\": 1.4488282203674316}", "{\"n\": 5611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4089345932006836}", "{\"n\": 5612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4210329055786133}", "{\"n\": 5613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4235475063323975}", "{\"n\": 5614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4294676780700684}", "{\"n\": 5615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.527, \"total_train_time_s\": 1.4130465984344482}", "{\"n\": 5616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.71, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4139559268951416}", "{\"n\": 5617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.58, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.5335180759429932}", "{\"n\": 5618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4252641201019287}", "{\"n\": 5619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.4272186756134033}", "{\"n\": 5620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.57, \"learn_time_ms\": 4.318, \"total_train_time_s\": 1.3983664512634277}", "{\"n\": 5621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.68, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.4194331169128418}", "{\"n\": 5622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.495, \"total_train_time_s\": 1.4246008396148682}", "{\"n\": 5623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.444, \"total_train_time_s\": 1.4097537994384766}", "{\"n\": 5624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.7, \"learn_time_ms\": 4.509, \"total_train_time_s\": 1.417525291442871}", "{\"n\": 5625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.22, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4420630931854248}", "{\"n\": 5626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.07, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4373297691345215}", "{\"n\": 5627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.07, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4028091430664062}", "{\"n\": 5628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.07, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.419130802154541}", "{\"n\": 5629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.433396816253662}", "{\"n\": 5630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.36, \"total_train_time_s\": 1.4372162818908691}", "{\"n\": 5631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.4206311702728271}", "{\"n\": 5632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.91, \"learn_time_ms\": 4.233, \"total_train_time_s\": 1.4214520454406738}", "{\"n\": 5633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.274, \"total_train_time_s\": 1.4243333339691162}", "{\"n\": 5634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.525, \"total_train_time_s\": 1.4558675289154053}", "{\"n\": 5635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4153249263763428}", "{\"n\": 5636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.93, \"learn_time_ms\": 4.277, \"total_train_time_s\": 1.4187753200531006}", "{\"n\": 5637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.31, \"learn_time_ms\": 4.258, \"total_train_time_s\": 1.3896067142486572}", "{\"n\": 5638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.218, \"total_train_time_s\": 1.4250035285949707}", "{\"n\": 5639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4209215641021729}", "{\"n\": 5640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.6, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4227039813995361}", "{\"n\": 5641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.77, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4160947799682617}", "{\"n\": 5642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.425, \"total_train_time_s\": 1.4473583698272705}", "{\"n\": 5643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.428654432296753}", "{\"n\": 5644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.404350757598877}", "{\"n\": 5645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.54, \"learn_time_ms\": 4.28, \"total_train_time_s\": 1.4218816757202148}", "{\"n\": 5646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.73, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4315974712371826}", "{\"n\": 5647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.73, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.416430950164795}", "{\"n\": 5648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.73, \"learn_time_ms\": 4.5, \"total_train_time_s\": 1.425008773803711}", "{\"n\": 5649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.63, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.393359661102295}", "{\"n\": 5650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4305009841918945}", "{\"n\": 5651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.346, \"total_train_time_s\": 1.402228593826294}", "{\"n\": 5652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.47, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4355528354644775}", "{\"n\": 5653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.61, \"learn_time_ms\": 4.261, \"total_train_time_s\": 1.4244730472564697}", "{\"n\": 5654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.465, \"total_train_time_s\": 1.4520995616912842}", "{\"n\": 5655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.423, \"total_train_time_s\": 1.4062285423278809}", "{\"n\": 5656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.25, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.3970222473144531}", "{\"n\": 5657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.49, \"learn_time_ms\": 4.493, \"total_train_time_s\": 1.433934211730957}", "{\"n\": 5658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.284, \"total_train_time_s\": 1.4529268741607666}", "{\"n\": 5659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.4204745292663574}", "{\"n\": 5660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4148719310760498}", "{\"n\": 5661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.07, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4360005855560303}", "{\"n\": 5662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.4496147632598877}", "{\"n\": 5663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.463, \"total_train_time_s\": 1.4445242881774902}", "{\"n\": 5664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.25, \"learn_time_ms\": 4.396, \"total_train_time_s\": 1.4187722206115723}", "{\"n\": 5665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.98, \"learn_time_ms\": 4.269, \"total_train_time_s\": 1.4247629642486572}", "{\"n\": 5666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4215154647827148}", "{\"n\": 5667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.3946828842163086}", "{\"n\": 5668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.97, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4009184837341309}", "{\"n\": 5669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.86, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.3990914821624756}", "{\"n\": 5670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.455251693725586}", "{\"n\": 5671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.276, \"total_train_time_s\": 1.4335846900939941}", "{\"n\": 5672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.72, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3784635066986084}", "{\"n\": 5673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.75, \"learn_time_ms\": 4.289, \"total_train_time_s\": 1.4236350059509277}", "{\"n\": 5674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.468, \"total_train_time_s\": 1.4400267601013184}", "{\"n\": 5675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.207, \"total_train_time_s\": 1.4196240901947021}", "{\"n\": 5676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.8, \"learn_time_ms\": 4.383, \"total_train_time_s\": 1.431525468826294}", "{\"n\": 5677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4254932403564453}", "{\"n\": 5678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.72, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4229788780212402}", "{\"n\": 5679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.72, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.4095861911773682}", "{\"n\": 5680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.72, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.4216980934143066}", "{\"n\": 5681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.94, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4221904277801514}", "{\"n\": 5682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.254, \"total_train_time_s\": 1.4289770126342773}", "{\"n\": 5683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.526, \"total_train_time_s\": 1.4310407638549805}", "{\"n\": 5684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.08, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4004135131835938}", "{\"n\": 5685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.41, \"learn_time_ms\": 4.338, \"total_train_time_s\": 1.4025590419769287}", "{\"n\": 5686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4186327457427979}", "{\"n\": 5687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.327, \"total_train_time_s\": 1.424452304840088}", "{\"n\": 5688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.53, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4243292808532715}", "{\"n\": 5689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.62, \"learn_time_ms\": 4.291, \"total_train_time_s\": 1.432171106338501}", "{\"n\": 5690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4124736785888672}", "{\"n\": 5691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.406578540802002}", "{\"n\": 5692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.6, \"learn_time_ms\": 4.273, \"total_train_time_s\": 1.4063706398010254}", "{\"n\": 5693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.73, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.412212610244751}", "{\"n\": 5694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.65, \"learn_time_ms\": 4.419, \"total_train_time_s\": 1.4116318225860596}", "{\"n\": 5695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.65, \"learn_time_ms\": 4.37, \"total_train_time_s\": 1.4064421653747559}", "{\"n\": 5696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.65, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4024436473846436}", "{\"n\": 5697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.7, \"learn_time_ms\": 4.229, \"total_train_time_s\": 1.4065604209899902}", "{\"n\": 5698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.64, \"learn_time_ms\": 4.249, \"total_train_time_s\": 1.4398295879364014}", "{\"n\": 5699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.57, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4180171489715576}", "{\"n\": 5700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.57, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.430567979812622}", "{\"n\": 5701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.57, \"learn_time_ms\": 4.421, \"total_train_time_s\": 1.4335687160491943}", "{\"n\": 5702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.28, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4248828887939453}", "{\"n\": 5703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.42, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.4328794479370117}", "{\"n\": 5704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.42, \"learn_time_ms\": 4.344, \"total_train_time_s\": 1.3938477039337158}", "{\"n\": 5705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.42, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4125757217407227}", "{\"n\": 5706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.56, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.408332109451294}", "{\"n\": 5707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.316, \"total_train_time_s\": 1.4242682456970215}", "{\"n\": 5708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.405, \"total_train_time_s\": 1.4017984867095947}", "{\"n\": 5709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.13, \"learn_time_ms\": 4.379, \"total_train_time_s\": 1.4183526039123535}", "{\"n\": 5710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.18, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4242908954620361}", "{\"n\": 5711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.79, \"learn_time_ms\": 4.323, \"total_train_time_s\": 1.392683982849121}", "{\"n\": 5712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.79, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.409266710281372}", "{\"n\": 5713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.79, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.4204013347625732}", "{\"n\": 5714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.64, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4001004695892334}", "{\"n\": 5715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4267253875732422}", "{\"n\": 5716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4463918209075928}", "{\"n\": 5717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.5, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4152271747589111}", "{\"n\": 5718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.34, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.4286081790924072}", "{\"n\": 5719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.4458425045013428}", "{\"n\": 5720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.398, \"total_train_time_s\": 1.4009456634521484}", "{\"n\": 5721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.3968594074249268}", "{\"n\": 5722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.3941395282745361}", "{\"n\": 5723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.304, \"total_train_time_s\": 1.439380407333374}", "{\"n\": 5724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.3949620723724365}", "{\"n\": 5725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.5307707786560059}", "{\"n\": 5726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.459, \"total_train_time_s\": 1.385049819946289}", "{\"n\": 5727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.73, \"learn_time_ms\": 4.492, \"total_train_time_s\": 1.4389333724975586}", "{\"n\": 5728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.18, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.3959739208221436}", "{\"n\": 5729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.18, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.4080393314361572}", "{\"n\": 5730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.18, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4241580963134766}", "{\"n\": 5731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.48, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.4462835788726807}", "{\"n\": 5732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.14, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4053874015808105}", "{\"n\": 5733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.14, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4098963737487793}", "{\"n\": 5734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.14, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4179792404174805}", "{\"n\": 5735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.443532943725586}", "{\"n\": 5736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.11, \"learn_time_ms\": 4.499, \"total_train_time_s\": 1.4353196620941162}", "{\"n\": 5737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.11, \"learn_time_ms\": 4.632, \"total_train_time_s\": 1.406757116317749}", "{\"n\": 5738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.11, \"learn_time_ms\": 4.278, \"total_train_time_s\": 1.4252979755401611}", "{\"n\": 5739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4232816696166992}", "{\"n\": 5740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4383113384246826}", "{\"n\": 5741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.353, \"total_train_time_s\": 1.4124269485473633}", "{\"n\": 5742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.03, \"learn_time_ms\": 4.411, \"total_train_time_s\": 1.386892557144165}", "{\"n\": 5743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.18, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4463698863983154}", "{\"n\": 5744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.436509132385254}", "{\"n\": 5745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.38997220993042}", "{\"n\": 5746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.549, \"total_train_time_s\": 1.4132661819458008}", "{\"n\": 5747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.28, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4508204460144043}", "{\"n\": 5748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.3880131244659424}", "{\"n\": 5749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.3899173736572266}", "{\"n\": 5750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.441, \"total_train_time_s\": 1.4155805110931396}", "{\"n\": 5751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.7, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4366869926452637}", "{\"n\": 5752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4344792366027832}", "{\"n\": 5753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.89, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.400160551071167}", "{\"n\": 5754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.68, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.400409460067749}", "{\"n\": 5755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.98, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4251949787139893}", "{\"n\": 5756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.417527675628662}", "{\"n\": 5757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4343235492706299}", "{\"n\": 5758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.427891731262207}", "{\"n\": 5759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.4, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4068324565887451}", "{\"n\": 5760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.4082458019256592}", "{\"n\": 5761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 4.42, \"total_train_time_s\": 1.4230835437774658}", "{\"n\": 5762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 4.312, \"total_train_time_s\": 1.4145283699035645}", "{\"n\": 5763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.77, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.433689832687378}", "{\"n\": 5764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4016058444976807}", "{\"n\": 5765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.95, \"learn_time_ms\": 4.227, \"total_train_time_s\": 1.4139883518218994}", "{\"n\": 5766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.99, \"learn_time_ms\": 4.232, \"total_train_time_s\": 1.4042608737945557}", "{\"n\": 5767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.04, \"learn_time_ms\": 4.311, \"total_train_time_s\": 1.4100537300109863}", "{\"n\": 5768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4172494411468506}", "{\"n\": 5769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.06, \"learn_time_ms\": 4.285, \"total_train_time_s\": 1.393517017364502}", "{\"n\": 5770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.0, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4302482604980469}", "{\"n\": 5771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.39, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4543275833129883}", "{\"n\": 5772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.43, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4131932258605957}", "{\"n\": 5773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.43, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4174211025238037}", "{\"n\": 5774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.15, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.415435791015625}", "{\"n\": 5775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.11, \"learn_time_ms\": 4.247, \"total_train_time_s\": 1.4264953136444092}", "{\"n\": 5776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.414, \"total_train_time_s\": 1.4274966716766357}", "{\"n\": 5777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4095699787139893}", "{\"n\": 5778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.16, \"learn_time_ms\": 4.309, \"total_train_time_s\": 1.3969333171844482}", "{\"n\": 5779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.18, \"learn_time_ms\": 4.301, \"total_train_time_s\": 1.4623615741729736}", "{\"n\": 5780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.17, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4193806648254395}", "{\"n\": 5781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.17, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4324116706848145}", "{\"n\": 5782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.17, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.4106125831604004}", "{\"n\": 5783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.91, \"learn_time_ms\": 4.293, \"total_train_time_s\": 1.4297072887420654}", "{\"n\": 5784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.33, \"total_train_time_s\": 1.425901174545288}", "{\"n\": 5785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.454, \"total_train_time_s\": 1.4142811298370361}", "{\"n\": 5786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.4207332134246826}", "{\"n\": 5787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4514801502227783}", "{\"n\": 5788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.439396619796753}", "{\"n\": 5789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.324, \"total_train_time_s\": 1.4089722633361816}", "{\"n\": 5790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.410841703414917}", "{\"n\": 5791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.08, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.4236688613891602}", "{\"n\": 5792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.354, \"total_train_time_s\": 1.4383196830749512}", "{\"n\": 5793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.478, \"total_train_time_s\": 1.387382984161377}", "{\"n\": 5794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.21, \"learn_time_ms\": 4.437, \"total_train_time_s\": 1.4329259395599365}", "{\"n\": 5795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.0, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4337005615234375}", "{\"n\": 5796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.523, \"total_train_time_s\": 1.4638497829437256}", "{\"n\": 5797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4315075874328613}", "{\"n\": 5798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.97, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4132401943206787}", "{\"n\": 5799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.06, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4112813472747803}", "{\"n\": 5800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.15, \"learn_time_ms\": 4.44, \"total_train_time_s\": 1.436042070388794}", "{\"n\": 5801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.15, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.3954827785491943}", "{\"n\": 5802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.15, \"learn_time_ms\": 4.45, \"total_train_time_s\": 1.4377532005310059}", "{\"n\": 5803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.18, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.422987699508667}", "{\"n\": 5804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.34, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.445711612701416}", "{\"n\": 5805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.34, \"learn_time_ms\": 4.35, \"total_train_time_s\": 1.3969643115997314}", "{\"n\": 5806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.34, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4197678565979004}", "{\"n\": 5807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.12, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4074985980987549}", "{\"n\": 5808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.46, \"learn_time_ms\": 4.319, \"total_train_time_s\": 1.4582810401916504}", "{\"n\": 5809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.46, \"learn_time_ms\": 4.453, \"total_train_time_s\": 1.4069809913635254}", "{\"n\": 5810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.57, \"learn_time_ms\": 4.439, \"total_train_time_s\": 1.42631196975708}", "{\"n\": 5811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.1, \"learn_time_ms\": 4.377, \"total_train_time_s\": 1.4130077362060547}", "{\"n\": 5812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.98, \"learn_time_ms\": 4.415, \"total_train_time_s\": 1.4462110996246338}", "{\"n\": 5813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.98, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3903110027313232}", "{\"n\": 5814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.07, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.4362263679504395}", "{\"n\": 5815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.17, \"learn_time_ms\": 4.358, \"total_train_time_s\": 1.4278345108032227}", "{\"n\": 5816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.46, \"learn_time_ms\": 4.364, \"total_train_time_s\": 1.4389779567718506}", "{\"n\": 5817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.46, \"learn_time_ms\": 4.52, \"total_train_time_s\": 1.3956499099731445}", "{\"n\": 5818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.46, \"learn_time_ms\": 4.317, \"total_train_time_s\": 1.4129083156585693}", "{\"n\": 5819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.69, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4191479682922363}", "{\"n\": 5820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.23, \"learn_time_ms\": 4.342, \"total_train_time_s\": 1.4173533916473389}", "{\"n\": 5821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.23, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.4197640419006348}", "{\"n\": 5822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.96, \"learn_time_ms\": 4.369, \"total_train_time_s\": 1.443678855895996}", "{\"n\": 5823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.95, \"learn_time_ms\": 4.485, \"total_train_time_s\": 1.420644760131836}", "{\"n\": 5824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.13, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.463562250137329}", "{\"n\": 5825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.13, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.40864896774292}", "{\"n\": 5826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.99, \"learn_time_ms\": 4.393, \"total_train_time_s\": 1.4173929691314697}", "{\"n\": 5827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.99, \"learn_time_ms\": 4.442, \"total_train_time_s\": 1.4115533828735352}", "{\"n\": 5828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4155869483947754}", "{\"n\": 5829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.4156219959259033}", "{\"n\": 5830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.82, \"learn_time_ms\": 4.322, \"total_train_time_s\": 1.4296975135803223}", "{\"n\": 5831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.49, \"learn_time_ms\": 4.547, \"total_train_time_s\": 1.4291932582855225}", "{\"n\": 5832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.36, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4243786334991455}", "{\"n\": 5833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.36, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.5155048370361328}", "{\"n\": 5834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.36, \"learn_time_ms\": 4.517, \"total_train_time_s\": 1.4141571521759033}", "{\"n\": 5835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.47, \"learn_time_ms\": 4.385, \"total_train_time_s\": 1.435781717300415}", "{\"n\": 5836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.449, \"total_train_time_s\": 1.452523946762085}", "{\"n\": 5837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.594, \"total_train_time_s\": 1.4378881454467773}", "{\"n\": 5838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.37, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4229316711425781}", "{\"n\": 5839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.28, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4259097576141357}", "{\"n\": 5840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.406, \"total_train_time_s\": 1.459580659866333}", "{\"n\": 5841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.532, \"total_train_time_s\": 1.4023990631103516}", "{\"n\": 5842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.9, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.449509859085083}", "{\"n\": 5843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.29, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4308927059173584}", "{\"n\": 5844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.4, \"learn_time_ms\": 4.491, \"total_train_time_s\": 1.4470314979553223}", "{\"n\": 5845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.4, \"learn_time_ms\": 4.38, \"total_train_time_s\": 1.4219844341278076}", "{\"n\": 5846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.4, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.393488883972168}", "{\"n\": 5847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.25, \"learn_time_ms\": 4.496, \"total_train_time_s\": 1.410149335861206}", "{\"n\": 5848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.18, \"learn_time_ms\": 4.435, \"total_train_time_s\": 1.4747436046600342}", "{\"n\": 5849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.18, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.4481253623962402}", "{\"n\": 5850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.18, \"learn_time_ms\": 4.53, \"total_train_time_s\": 1.4255506992340088}", "{\"n\": 5851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.27, \"learn_time_ms\": 4.264, \"total_train_time_s\": 1.4277942180633545}", "{\"n\": 5852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.85, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.452934980392456}", "{\"n\": 5853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.85, \"learn_time_ms\": 4.507, \"total_train_time_s\": 1.4205026626586914}", "{\"n\": 5854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.85, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4200952053070068}", "{\"n\": 5855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.78, \"learn_time_ms\": 4.546, \"total_train_time_s\": 1.4274837970733643}", "{\"n\": 5856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.69, \"learn_time_ms\": 4.313, \"total_train_time_s\": 1.4249918460845947}", "{\"n\": 5857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.69, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.4125549793243408}", "{\"n\": 5858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.69, \"learn_time_ms\": 4.557, \"total_train_time_s\": 1.3763620853424072}", "{\"n\": 5859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.72, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.3886799812316895}", "{\"n\": 5860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.96, \"learn_time_ms\": 4.424, \"total_train_time_s\": 1.4802584648132324}", "{\"n\": 5861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.96, \"learn_time_ms\": 4.397, \"total_train_time_s\": 1.4106321334838867}", "{\"n\": 5862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.96, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3963608741760254}", "{\"n\": 5863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.19, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4163811206817627}", "{\"n\": 5864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.66, \"learn_time_ms\": 4.299, \"total_train_time_s\": 1.4267561435699463}", "{\"n\": 5865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.66, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4254615306854248}", "{\"n\": 5866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.66, \"learn_time_ms\": 4.315, \"total_train_time_s\": 1.4066572189331055}", "{\"n\": 5867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.43, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.3910183906555176}", "{\"n\": 5868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.53, \"learn_time_ms\": 4.259, \"total_train_time_s\": 1.4511175155639648}", "{\"n\": 5869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.53, \"learn_time_ms\": 4.41, \"total_train_time_s\": 1.4515290260314941}", "{\"n\": 5870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.53, \"learn_time_ms\": 4.373, \"total_train_time_s\": 1.4106318950653076}", "{\"n\": 5871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.59, \"learn_time_ms\": 4.302, \"total_train_time_s\": 1.415832757949829}", "{\"n\": 5872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.246, \"total_train_time_s\": 1.4312031269073486}", "{\"n\": 5873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.51, \"total_train_time_s\": 1.4309427738189697}", "{\"n\": 5874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.51, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.406639814376831}", "{\"n\": 5875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.59, \"learn_time_ms\": 4.537, \"total_train_time_s\": 1.4080913066864014}", "{\"n\": 5876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.84, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4186723232269287}", "{\"n\": 5877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.84, \"learn_time_ms\": 4.306, \"total_train_time_s\": 1.4127752780914307}", "{\"n\": 5878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.84, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4038493633270264}", "{\"n\": 5879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.64, \"learn_time_ms\": 4.326, \"total_train_time_s\": 1.4039480686187744}", "{\"n\": 5880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.292, \"total_train_time_s\": 1.4294183254241943}", "{\"n\": 5881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.434, \"total_train_time_s\": 1.4310455322265625}", "{\"n\": 5882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.52, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.410064458847046}", "{\"n\": 5883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.67, \"learn_time_ms\": 4.29, \"total_train_time_s\": 1.4201931953430176}", "{\"n\": 5884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.294, \"total_train_time_s\": 1.3965263366699219}", "{\"n\": 5885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.519, \"total_train_time_s\": 1.4048337936401367}", "{\"n\": 5886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.64, \"learn_time_ms\": 4.531, \"total_train_time_s\": 1.4310894012451172}", "{\"n\": 5887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.65, \"learn_time_ms\": 4.49, \"total_train_time_s\": 1.4350743293762207}", "{\"n\": 5888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.53, \"learn_time_ms\": 4.321, \"total_train_time_s\": 1.459200382232666}", "{\"n\": 5889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.53, \"learn_time_ms\": 4.375, \"total_train_time_s\": 1.4090163707733154}", "{\"n\": 5890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.53, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4268238544464111}", "{\"n\": 5891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.88, \"learn_time_ms\": 4.399, \"total_train_time_s\": 1.412816047668457}", "{\"n\": 5892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.75, \"learn_time_ms\": 4.257, \"total_train_time_s\": 1.4107666015625}", "{\"n\": 5893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.75, \"learn_time_ms\": 4.43, \"total_train_time_s\": 1.41984224319458}", "{\"n\": 5894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.75, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.4003565311431885}", "{\"n\": 5895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.49, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.400266408920288}", "{\"n\": 5896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.43, \"learn_time_ms\": 4.343, \"total_train_time_s\": 1.4549205303192139}", "{\"n\": 5897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.43, \"learn_time_ms\": 4.275, \"total_train_time_s\": 1.4133694171905518}", "{\"n\": 5898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.43, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4031519889831543}", "{\"n\": 5899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.66, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.427480936050415}", "{\"n\": 5900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.35, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4309322834014893}", "{\"n\": 5901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.35, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4001662731170654}", "{\"n\": 5902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.35, \"learn_time_ms\": 4.452, \"total_train_time_s\": 1.3889057636260986}", "{\"n\": 5903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.64, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4360344409942627}", "{\"n\": 5904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.287, \"total_train_time_s\": 1.4268577098846436}", "{\"n\": 5905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4299261569976807}", "{\"n\": 5906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4167077541351318}", "{\"n\": 5907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.87, \"learn_time_ms\": 4.55, \"total_train_time_s\": 1.436997413635254}", "{\"n\": 5908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.356, \"total_train_time_s\": 1.4176995754241943}", "{\"n\": 5909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4079902172088623}", "{\"n\": 5910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.82, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.3876121044158936}", "{\"n\": 5911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.0, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.4434282779693604}", "{\"n\": 5912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.405336856842041}", "{\"n\": 5913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.506, \"total_train_time_s\": 1.4180307388305664}", "{\"n\": 5914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.87, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4119503498077393}", "{\"n\": 5915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.17, \"learn_time_ms\": 4.32, \"total_train_time_s\": 1.7464368343353271}", "{\"n\": 5916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.06, \"learn_time_ms\": 4.355, \"total_train_time_s\": 1.4383468627929688}", "{\"n\": 5917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.06, \"learn_time_ms\": 4.474, \"total_train_time_s\": 1.4122662544250488}", "{\"n\": 5918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.06, \"learn_time_ms\": 4.363, \"total_train_time_s\": 1.4027795791625977}", "{\"n\": 5919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.03, \"learn_time_ms\": 4.365, \"total_train_time_s\": 1.4164514541625977}", "{\"n\": 5920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.408, \"total_train_time_s\": 1.4327130317687988}", "{\"n\": 5921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.469, \"total_train_time_s\": 1.4339079856872559}", "{\"n\": 5922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.83, \"learn_time_ms\": 4.332, \"total_train_time_s\": 1.4255166053771973}", "{\"n\": 5923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.16, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.422813892364502}", "{\"n\": 5924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.86, \"learn_time_ms\": 4.428, \"total_train_time_s\": 1.40736722946167}", "{\"n\": 5925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.86, \"learn_time_ms\": 4.367, \"total_train_time_s\": 1.4206204414367676}", "{\"n\": 5926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.86, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.406479835510254}", "{\"n\": 5927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1028.17, \"learn_time_ms\": 4.472, \"total_train_time_s\": 1.4217190742492676}", "{\"n\": 5928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4080898761749268}", "{\"n\": 5929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.4117918014526367}", "{\"n\": 5930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 4.57, \"total_train_time_s\": 1.417196273803711}", "{\"n\": 5931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4231739044189453}", "{\"n\": 5932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.3, \"total_train_time_s\": 1.4276487827301025}", "{\"n\": 5933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.307, \"total_train_time_s\": 1.389793872833252}", "{\"n\": 5934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.47, \"total_train_time_s\": 1.4275388717651367}", "{\"n\": 5935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 4.387, \"total_train_time_s\": 1.3974533081054688}", "{\"n\": 5936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.12, \"learn_time_ms\": 4.328, \"total_train_time_s\": 1.4026541709899902}", "{\"n\": 5937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.357, \"total_train_time_s\": 1.442504644393921}", "{\"n\": 5938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.407, \"total_train_time_s\": 1.4105861186981201}", "{\"n\": 5939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.39, \"learn_time_ms\": 4.447, \"total_train_time_s\": 1.4123249053955078}", "{\"n\": 5940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.43, \"learn_time_ms\": 4.374, \"total_train_time_s\": 1.4410464763641357}", "{\"n\": 5941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.79, \"learn_time_ms\": 4.422, \"total_train_time_s\": 1.4299044609069824}", "{\"n\": 5942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.79, \"learn_time_ms\": 4.462, \"total_train_time_s\": 1.4221220016479492}", "{\"n\": 5943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.79, \"learn_time_ms\": 4.345, \"total_train_time_s\": 1.3959667682647705}", "{\"n\": 5944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.48, \"learn_time_ms\": 4.486, \"total_train_time_s\": 1.42262601852417}", "{\"n\": 5945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.409, \"total_train_time_s\": 1.4180915355682373}", "{\"n\": 5946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.305, \"total_train_time_s\": 1.3889527320861816}", "{\"n\": 5947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.43, \"learn_time_ms\": 4.34, \"total_train_time_s\": 1.3955943584442139}", "{\"n\": 5948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.22, \"learn_time_ms\": 4.349, \"total_train_time_s\": 1.4488122463226318}", "{\"n\": 5949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.253, \"total_train_time_s\": 1.437328815460205}", "{\"n\": 5950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.286, \"total_train_time_s\": 1.396836280822754}", "{\"n\": 5951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.12, \"learn_time_ms\": 4.351, \"total_train_time_s\": 1.4066927433013916}", "{\"n\": 5952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 4.378, \"total_train_time_s\": 1.4035727977752686}", "{\"n\": 5953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.314, \"total_train_time_s\": 1.4401118755340576}", "{\"n\": 5954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.295, \"total_train_time_s\": 1.4057741165161133}", "{\"n\": 5955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.24, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4105634689331055}", "{\"n\": 5956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.25, \"learn_time_ms\": 4.298, \"total_train_time_s\": 1.4155504703521729}", "{\"n\": 5957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.65, \"learn_time_ms\": 4.348, \"total_train_time_s\": 1.464914321899414}", "{\"n\": 5958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.65, \"learn_time_ms\": 4.241, \"total_train_time_s\": 1.3798470497131348}", "{\"n\": 5959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.65, \"learn_time_ms\": 4.382, \"total_train_time_s\": 1.412200689315796}", "{\"n\": 5960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.61, \"learn_time_ms\": 4.482, \"total_train_time_s\": 1.4256489276885986}", "{\"n\": 5961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.341, \"total_train_time_s\": 1.4401931762695312}", "{\"n\": 5962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.392, \"total_train_time_s\": 1.4085938930511475}", "{\"n\": 5963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.42, \"learn_time_ms\": 4.333, \"total_train_time_s\": 1.3913342952728271}", "{\"n\": 5964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.24, \"learn_time_ms\": 4.265, \"total_train_time_s\": 1.4236161708831787}", "{\"n\": 5965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.47, \"learn_time_ms\": 4.372, \"total_train_time_s\": 1.408639907836914}", "{\"n\": 5966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.47, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4133915901184082}", "{\"n\": 5967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.47, \"learn_time_ms\": 4.416, \"total_train_time_s\": 1.4017798900604248}", "{\"n\": 5968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.21, \"learn_time_ms\": 4.329, \"total_train_time_s\": 1.432424545288086}", "{\"n\": 5969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.24, \"learn_time_ms\": 4.389, \"total_train_time_s\": 1.4524776935577393}", "{\"n\": 5970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.24, \"learn_time_ms\": 4.334, \"total_train_time_s\": 1.4509165287017822}", "{\"n\": 5971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.24, \"learn_time_ms\": 4.216, \"total_train_time_s\": 1.3900842666625977}", "{\"n\": 5972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.08, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.4069786071777344}", "{\"n\": 5973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.267, \"total_train_time_s\": 1.4071087837219238}", "{\"n\": 5974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.297, \"total_train_time_s\": 1.4093801975250244}", "{\"n\": 5975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.89, \"learn_time_ms\": 4.395, \"total_train_time_s\": 1.4089930057525635}", "{\"n\": 5976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.78, \"learn_time_ms\": 4.401, \"total_train_time_s\": 1.4114463329315186}", "{\"n\": 5977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.65, \"learn_time_ms\": 4.359, \"total_train_time_s\": 1.4377703666687012}", "{\"n\": 5978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.65, \"learn_time_ms\": 4.337, \"total_train_time_s\": 1.397674560546875}", "{\"n\": 5979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.65, \"learn_time_ms\": 4.402, \"total_train_time_s\": 1.3859059810638428}", "{\"n\": 5980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.91, \"learn_time_ms\": 4.448, \"total_train_time_s\": 1.4163577556610107}", "{\"n\": 5981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.79, \"learn_time_ms\": 4.418, \"total_train_time_s\": 1.4239263534545898}", "{\"n\": 5982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.79, \"learn_time_ms\": 4.386, \"total_train_time_s\": 1.4117064476013184}", "{\"n\": 5983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.79, \"learn_time_ms\": 4.429, \"total_train_time_s\": 1.4177680015563965}", "{\"n\": 5984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.57, \"learn_time_ms\": 4.325, \"total_train_time_s\": 1.4386098384857178}", "{\"n\": 5985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.66, \"learn_time_ms\": 4.335, \"total_train_time_s\": 1.420863389968872}", "{\"n\": 5986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.66, \"learn_time_ms\": 4.417, \"total_train_time_s\": 1.4046430587768555}", "{\"n\": 5987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.66, \"learn_time_ms\": 4.361, \"total_train_time_s\": 1.3769850730895996}", "{\"n\": 5988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.283, \"total_train_time_s\": 1.4323360919952393}", "{\"n\": 5989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.51, \"learn_time_ms\": 4.432, \"total_train_time_s\": 1.4455654621124268}", "{\"n\": 5990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.51, \"learn_time_ms\": 4.404, \"total_train_time_s\": 1.4143402576446533}", "{\"n\": 5991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.51, \"learn_time_ms\": 4.303, \"total_train_time_s\": 1.4170324802398682}", "{\"n\": 5992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.39, \"learn_time_ms\": 4.457, \"total_train_time_s\": 1.4030036926269531}", "{\"n\": 5993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.352, \"total_train_time_s\": 1.447427749633789}", "{\"n\": 5994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.427, \"total_train_time_s\": 1.410377025604248}", "{\"n\": 5995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.23, \"learn_time_ms\": 4.288, \"total_train_time_s\": 1.4013257026672363}", "{\"n\": 5996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.34, \"learn_time_ms\": 4.279, \"total_train_time_s\": 1.406101942062378}", "{\"n\": 5997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.413, \"total_train_time_s\": 1.4279465675354004}", "{\"n\": 5998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.362, \"total_train_time_s\": 1.395982265472412}", "{\"n\": 5999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.55, \"learn_time_ms\": 4.216, \"total_train_time_s\": 1.4168672561645508}", "{\"n\": 6000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.49, \"learn_time_ms\": 4.488, \"total_train_time_s\": 1.4419326782226562}"]