["{\"n\": 5952, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 8928.016, \"total_train_time_s\": 10.504895448684692}", "{\"n\": 5953, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 8748.467, \"total_train_time_s\": 9.945694923400879}", "{\"n\": 5954, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9100.525, \"total_train_time_s\": 11.180353164672852}", "{\"n\": 5955, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 8987.193, \"total_train_time_s\": 10.082890272140503}", "{\"n\": 5956, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9048.36, \"total_train_time_s\": 10.635292053222656}", "{\"n\": 5957, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9114.659, \"total_train_time_s\": 10.85376501083374}", "{\"n\": 5958, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3250.75, \"learn_time_ms\": 9143.936, \"total_train_time_s\": 10.746971368789673}", "{\"n\": 5959, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3250.75, \"learn_time_ms\": 9004.486, \"total_train_time_s\": 9.446245431900024}", "{\"n\": 5960, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3250.75, \"learn_time_ms\": 8869.427, \"total_train_time_s\": 9.13160490989685}", "{\"n\": 5961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3241.0, \"learn_time_ms\": 8821.768, \"total_train_time_s\": 9.787610530853271}", "{\"n\": 5962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3293.625, \"learn_time_ms\": 8812.369, \"total_train_time_s\": 10.214459419250488}", "{\"n\": 5963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3293.625, \"learn_time_ms\": 8643.231, \"total_train_time_s\": 8.271868467330933}", "{\"n\": 5964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.1, \"learn_time_ms\": 8492.53, \"total_train_time_s\": 9.71626353263855}", "{\"n\": 5965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3339.0, \"learn_time_ms\": 8505.267, \"total_train_time_s\": 10.191651344299316}", "{\"n\": 5966, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3339.0, \"learn_time_ms\": 8421.091, \"total_train_time_s\": 9.86613392829895}", "{\"n\": 5967, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.846153846153846, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3324.6153846153848, \"learn_time_ms\": 8375.696, \"total_train_time_s\": 10.42099642753601}", "{\"n\": 5968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -7.133333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3293.3333333333335, \"learn_time_ms\": 8306.507, \"total_train_time_s\": 10.052415132522583}", "{\"n\": 5969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -7.0625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3302.8125, \"learn_time_ms\": 8404.162, \"total_train_time_s\": 10.405579805374146}", "{\"n\": 5970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.9411764705882355, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3304.1176470588234, \"learn_time_ms\": 8445.922, \"total_train_time_s\": 9.57702112197876}", "{\"n\": 5971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.947368421052632, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3295.8947368421054, \"learn_time_ms\": 8499.039, \"total_train_time_s\": 10.352166891098022}", "{\"n\": 5972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3292.45, \"learn_time_ms\": 8419.331, \"total_train_time_s\": 9.411193370819092}", "{\"n\": 5973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.142857142857143, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3276.190476190476, \"learn_time_ms\": 8633.832, \"total_train_time_s\": 10.43163013458252}", "{\"n\": 5974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.2272727272727275, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.7727272727275, \"learn_time_ms\": 8590.179, \"total_train_time_s\": 9.216304540634155}", "{\"n\": 5975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.291666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.2916666666665, \"learn_time_ms\": 8655.358, \"total_train_time_s\": 10.837176322937012}", "{\"n\": 5976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.291666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.2916666666665, \"learn_time_ms\": 8732.648, \"total_train_time_s\": 10.643605947494507}", "{\"n\": 5977, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3261.2, \"learn_time_ms\": 8765.33, \"total_train_time_s\": 10.73650050163269}", "{\"n\": 5978, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.285714285714286, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3267.035714285714, \"learn_time_ms\": 8657.004, \"total_train_time_s\": 8.95764970779419}", "{\"n\": 5979, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.241379310344827, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.4137931034484, \"learn_time_ms\": 8667.195, \"total_train_time_s\": 10.488628387451172}", "{\"n\": 5980, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.333333333333333, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.866666666667, \"learn_time_ms\": 8518.54, \"total_train_time_s\": 8.097595930099487}", "{\"n\": 5981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.375, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.5, \"learn_time_ms\": 8507.492, \"total_train_time_s\": 10.24076247215271}", "{\"n\": 5982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.484848484848484, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3250.5151515151515, \"learn_time_ms\": 8621.762, \"total_train_time_s\": 10.59973692893982}", "{\"n\": 5983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.647058823529412, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3231.8823529411766, \"learn_time_ms\": 8490.102, \"total_train_time_s\": 9.117877960205078}", "{\"n\": 5984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.833333333333333, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3214.277777777778, \"learn_time_ms\": 8667.048, \"total_train_time_s\": 11.011432886123657}", "{\"n\": 5985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.833333333333333, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3214.277777777778, \"learn_time_ms\": 8682.891, \"total_train_time_s\": 10.948842525482178}", "{\"n\": 5986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.894736842105263, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3205.0526315789475, \"learn_time_ms\": 8454.651, \"total_train_time_s\": 8.333821058273315}", "{\"n\": 5987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.775, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3212.5, \"learn_time_ms\": 8495.958, \"total_train_time_s\": 11.1435546875}", "{\"n\": 5988, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7073170731707314, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3215.829268292683, \"learn_time_ms\": 8552.631, \"total_train_time_s\": 9.549212455749512}", "{\"n\": 5989, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7073170731707314, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3215.829268292683, \"learn_time_ms\": 8515.896, \"total_train_time_s\": 10.153537034988403}", "{\"n\": 5990, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.761904761904762, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.5476190476193, \"learn_time_ms\": 8733.476, \"total_train_time_s\": 10.272797346115112}", "{\"n\": 5991, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7272727272727275, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3218.0, \"learn_time_ms\": 8738.219, \"total_train_time_s\": 10.224987030029297}", "{\"n\": 5992, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3207.6, \"learn_time_ms\": 8710.689, \"total_train_time_s\": 10.301516056060791}", "{\"n\": 5993, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.760869565217392, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3209.282608695652, \"learn_time_ms\": 8959.412, \"total_train_time_s\": 11.647898435592651}", "{\"n\": 5994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74468085106383, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3209.531914893617, \"learn_time_ms\": 8799.567, \"total_train_time_s\": 9.461453676223755}", "{\"n\": 5995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6938775510204085, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3221.612244897959, \"learn_time_ms\": 8734.25, \"total_train_time_s\": 10.361993789672852}", "{\"n\": 5996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3222.56, \"learn_time_ms\": 9009.71, \"total_train_time_s\": 11.123741626739502}", "{\"n\": 5997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.615384615384615, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.653846153846, \"learn_time_ms\": 8893.401, \"total_train_time_s\": 9.975608825683594}", "{\"n\": 5998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.660377358490566, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.566037735849, \"learn_time_ms\": 8731.989, \"total_train_time_s\": 7.911794662475586}", "{\"n\": 5999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.648148148148148, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.037037037037, \"learn_time_ms\": 8853.107, \"total_train_time_s\": 11.384019136428833}", "{\"n\": 6000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.636363636363637, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.6363636363635, \"learn_time_ms\": 8720.167, \"total_train_time_s\": 8.980588912963867}", "{\"n\": 6001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.719298245614035, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.035087719298, \"learn_time_ms\": 8863.89, \"total_train_time_s\": 11.681836605072021}", "{\"n\": 6002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.827586206896552, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.0689655172414, \"learn_time_ms\": 8970.505, \"total_train_time_s\": 11.3623788356781}", "{\"n\": 6003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.864406779661017, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.4406779661017, \"learn_time_ms\": 8748.892, \"total_train_time_s\": 9.358213901519775}", "{\"n\": 6004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.8166666666666, \"learn_time_ms\": 8801.123, \"total_train_time_s\": 9.916046142578125}", "{\"n\": 6005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.838709677419355, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.2258064516127, \"learn_time_ms\": 8715.256, \"total_train_time_s\": 9.463927745819092}", "{\"n\": 6006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.838709677419355, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.2258064516127, \"learn_time_ms\": 8707.575, \"total_train_time_s\": 11.021538257598877}", "{\"n\": 6007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.796875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.3125, \"learn_time_ms\": 8691.481, \"total_train_time_s\": 9.831984281539917}", "{\"n\": 6008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.753846153846154, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.7846153846153, \"learn_time_ms\": 8964.516, \"total_train_time_s\": 10.646419286727905}", "{\"n\": 6009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7727272727272725, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.969696969697, \"learn_time_ms\": 9019.025, \"total_train_time_s\": 11.924597263336182}", "{\"n\": 6010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.746268656716418, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.805970149254, \"learn_time_ms\": 8991.245, \"total_train_time_s\": 8.648885011672974}", "{\"n\": 6011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.739130434782608, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.985507246377, \"learn_time_ms\": 8860.277, \"total_train_time_s\": 10.39404821395874}", "{\"n\": 6012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6571428571428575, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.1714285714284, \"learn_time_ms\": 8747.507, \"total_train_time_s\": 10.248481512069702}", "{\"n\": 6013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6571428571428575, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.1714285714284, \"learn_time_ms\": 8930.195, \"total_train_time_s\": 11.18340539932251}", "{\"n\": 6014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.602739726027397, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.986301369863, \"learn_time_ms\": 8848.218, \"total_train_time_s\": 9.1466064453125}", "{\"n\": 6015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.581081081081081, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.5675675675675, \"learn_time_ms\": 8888.625, \"total_train_time_s\": 9.909024715423584}", "{\"n\": 6016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.581081081081081, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.5675675675675, \"learn_time_ms\": 8607.634, \"total_train_time_s\": 8.223344326019287}", "{\"n\": 6017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5394736842105265, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.7236842105262, \"learn_time_ms\": 8566.169, \"total_train_time_s\": 9.409219741821289}", "{\"n\": 6018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.545454545454546, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.220779220779, \"learn_time_ms\": 8547.845, \"total_train_time_s\": 10.429129600524902}", "{\"n\": 6019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5256410256410255, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.2179487179487, \"learn_time_ms\": 8258.082, \"total_train_time_s\": 9.000503778457642}", "{\"n\": 6020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.525, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.225, \"learn_time_ms\": 8523.157, \"total_train_time_s\": 11.353453397750854}", "{\"n\": 6021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.451219512195122, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.5731707317073, \"learn_time_ms\": 8432.749, \"total_train_time_s\": 9.546886205673218}", "{\"n\": 6022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.451219512195122, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.5731707317073, \"learn_time_ms\": 8296.13, \"total_train_time_s\": 8.897176742553711}", "{\"n\": 6023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.518072289156627, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.987951807229, \"learn_time_ms\": 8097.704, \"total_train_time_s\": 9.18591022491455}", "{\"n\": 6024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.564705882352941, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.164705882353, \"learn_time_ms\": 8275.206, \"total_train_time_s\": 10.928865671157837}", "{\"n\": 6025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6395348837209305, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.186046511628, \"learn_time_ms\": 8204.24, \"total_train_time_s\": 9.182288646697998}", "{\"n\": 6026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67816091954023, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.0344827586205, \"learn_time_ms\": 8468.03, \"total_train_time_s\": 10.816486358642578}", "{\"n\": 6027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.640449438202247, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.516853932584, \"learn_time_ms\": 8405.256, \"total_train_time_s\": 8.797608375549316}", "{\"n\": 6028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.644444444444445, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.5333333333333, \"learn_time_ms\": 8298.836, \"total_train_time_s\": 9.424865961074829}", "{\"n\": 6029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.648351648351649, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.3956043956046, \"learn_time_ms\": 8405.908, \"total_train_time_s\": 10.073976755142212}", "{\"n\": 6030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.602150537634409, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.6881720430106, \"learn_time_ms\": 8327.133, \"total_train_time_s\": 10.551234722137451}", "{\"n\": 6031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.585106382978723, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.872340425532, \"learn_time_ms\": 8324.499, \"total_train_time_s\": 9.487792015075684}", "{\"n\": 6032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.585106382978723, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.872340425532, \"learn_time_ms\": 8485.409, \"total_train_time_s\": 10.522488355636597}", "{\"n\": 6033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.649484536082475, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.092783505155, \"learn_time_ms\": 8553.692, \"total_train_time_s\": 9.928234100341797}", "{\"n\": 6034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.642857142857143, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.9489795918366, \"learn_time_ms\": 8566.95, \"total_train_time_s\": 11.089595794677734}", "{\"n\": 6035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.642857142857143, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.9489795918366, \"learn_time_ms\": 8669.01, \"total_train_time_s\": 10.170176267623901}", "{\"n\": 6036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.08, \"learn_time_ms\": 8638.334, \"total_train_time_s\": 10.568995237350464}", "{\"n\": 6037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.93, \"learn_time_ms\": 8764.529, \"total_train_time_s\": 10.039196014404297}", "{\"n\": 6038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.93, \"learn_time_ms\": 8779.444, \"total_train_time_s\": 9.526551246643066}", "{\"n\": 6039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.64, \"learn_time_ms\": 8834.584, \"total_train_time_s\": 10.654819011688232}", "{\"n\": 6040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.74, \"learn_time_ms\": 8799.11, \"total_train_time_s\": 10.179974794387817}", "{\"n\": 6041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.74, \"learn_time_ms\": 8930.431, \"total_train_time_s\": 10.823657512664795}", "{\"n\": 6042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.11, \"learn_time_ms\": 8859.524, \"total_train_time_s\": 9.843664169311523}", "{\"n\": 6043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.44, \"learn_time_ms\": 8885.804, \"total_train_time_s\": 10.21839690208435}", "{\"n\": 6044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.44, \"learn_time_ms\": 8753.855, \"total_train_time_s\": 9.714977264404297}", "{\"n\": 6045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.69, \"learn_time_ms\": 8728.325, \"total_train_time_s\": 9.923317432403564}", "{\"n\": 6046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.16, \"learn_time_ms\": 8528.755, \"total_train_time_s\": 8.5519380569458}", "{\"n\": 6047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.47, \"learn_time_ms\": 8516.324, \"total_train_time_s\": 9.882428169250488}", "{\"n\": 6048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.47, \"learn_time_ms\": 8725.192, \"total_train_time_s\": 11.659430503845215}", "{\"n\": 6049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.3, \"learn_time_ms\": 8734.858, \"total_train_time_s\": 10.748191356658936}", "{\"n\": 6050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.62, \"learn_time_ms\": 8685.729, \"total_train_time_s\": 9.724504232406616}", "{\"n\": 6051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.62, \"learn_time_ms\": 8595.193, \"total_train_time_s\": 9.844101428985596}", "{\"n\": 6052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.08, \"learn_time_ms\": 8432.315, \"total_train_time_s\": 8.168139219284058}", "{\"n\": 6053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.56, \"learn_time_ms\": 8492.788, \"total_train_time_s\": 10.793590545654297}", "{\"n\": 6054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.56, \"learn_time_ms\": 8619.046, \"total_train_time_s\": 10.985369682312012}", "{\"n\": 6055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.4, \"learn_time_ms\": 8717.647, \"total_train_time_s\": 10.927645444869995}", "{\"n\": 6056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.33, \"learn_time_ms\": 8875.215, \"total_train_time_s\": 10.1364164352417}", "{\"n\": 6057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.33, \"learn_time_ms\": 8895.038, \"total_train_time_s\": 10.112727165222168}", "{\"n\": 6058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.9, \"learn_time_ms\": 8651.78, \"total_train_time_s\": 9.186691522598267}", "{\"n\": 6059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.51, \"learn_time_ms\": 8603.733, \"total_train_time_s\": 10.287724018096924}", "{\"n\": 6060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.51, \"learn_time_ms\": 8783.72, \"total_train_time_s\": 11.499887228012085}", "{\"n\": 6061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.13, \"learn_time_ms\": 8657.1, \"total_train_time_s\": 8.626718282699585}", "{\"n\": 6062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.13, \"learn_time_ms\": 8915.148, \"total_train_time_s\": 10.69909954071045}", "{\"n\": 6063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.86, \"learn_time_ms\": 8859.463, \"total_train_time_s\": 10.180735349655151}", "{\"n\": 6064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.31, \"learn_time_ms\": 8668.168, \"total_train_time_s\": 9.051149368286133}", "{\"n\": 6065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.49, \"learn_time_ms\": 8558.972, \"total_train_time_s\": 9.845711708068848}", "{\"n\": 6066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.37, \"learn_time_ms\": 8567.436, \"total_train_time_s\": 10.241997003555298}", "{\"n\": 6067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.37, \"learn_time_ms\": 8593.818, \"total_train_time_s\": 10.395602941513062}", "{\"n\": 6068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.02, \"learn_time_ms\": 8751.85, \"total_train_time_s\": 10.796561241149902}", "{\"n\": 6069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.85, \"learn_time_ms\": 8633.843, \"total_train_time_s\": 9.099500179290771}", "{\"n\": 6070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.85, \"learn_time_ms\": 8480.699, \"total_train_time_s\": 9.99237060546875}", "{\"n\": 6071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.77, \"learn_time_ms\": 8694.321, \"total_train_time_s\": 10.718019962310791}", "{\"n\": 6072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.03, \"learn_time_ms\": 8562.272, \"total_train_time_s\": 9.372996807098389}", "{\"n\": 6073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.41, \"learn_time_ms\": 8370.387, \"total_train_time_s\": 8.308220863342285}", "{\"n\": 6074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.94, \"learn_time_ms\": 8469.022, \"total_train_time_s\": 10.101551532745361}", "{\"n\": 6075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.94, \"learn_time_ms\": 8529.956, \"total_train_time_s\": 10.461218118667603}", "{\"n\": 6076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.85, \"learn_time_ms\": 8511.448, \"total_train_time_s\": 10.022750854492188}", "{\"n\": 6077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.57, \"learn_time_ms\": 8443.748, \"total_train_time_s\": 9.650086402893066}", "{\"n\": 6078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.57, \"learn_time_ms\": 8430.699, \"total_train_time_s\": 10.65147852897644}", "{\"n\": 6079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.93, \"learn_time_ms\": 8468.101, \"total_train_time_s\": 9.456816673278809}", "{\"n\": 6080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.22, \"learn_time_ms\": 8417.521, \"total_train_time_s\": 9.484804630279541}", "{\"n\": 6081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.27, \"learn_time_ms\": 8192.467, \"total_train_time_s\": 8.477023124694824}", "{\"n\": 6082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.27, \"learn_time_ms\": 8246.792, \"total_train_time_s\": 9.940082788467407}", "{\"n\": 6083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.84, \"learn_time_ms\": 8481.527, \"total_train_time_s\": 10.727768182754517}", "{\"n\": 6084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.5, \"learn_time_ms\": 8537.723, \"total_train_time_s\": 10.611325025558472}", "{\"n\": 6085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.5, \"learn_time_ms\": 8575.301, \"total_train_time_s\": 10.855916500091553}", "{\"n\": 6086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.89, \"learn_time_ms\": 8430.42, \"total_train_time_s\": 8.544955492019653}", "{\"n\": 6087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.98, \"learn_time_ms\": 8589.2, \"total_train_time_s\": 11.28885006904602}", "{\"n\": 6088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.98, \"learn_time_ms\": 8521.181, \"total_train_time_s\": 9.92723822593689}", "{\"n\": 6089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.61, \"learn_time_ms\": 8607.251, \"total_train_time_s\": 10.307809114456177}", "{\"n\": 6090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8691.277, \"total_train_time_s\": 10.315960168838501}", "{\"n\": 6091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8783.279, \"total_train_time_s\": 9.414613008499146}", "{\"n\": 6092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.85, \"learn_time_ms\": 8690.093, \"total_train_time_s\": 9.014506340026855}", "{\"n\": 6093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.88, \"learn_time_ms\": 8641.471, \"total_train_time_s\": 10.187074184417725}", "{\"n\": 6094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.64, \"learn_time_ms\": 8475.31, \"total_train_time_s\": 8.948301076889038}", "{\"n\": 6095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.47, \"learn_time_ms\": 8357.214, \"total_train_time_s\": 9.646787643432617}", "{\"n\": 6096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.83, \"learn_time_ms\": 8646.544, \"total_train_time_s\": 11.473610401153564}", "{\"n\": 6097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.92, \"learn_time_ms\": 8587.008, \"total_train_time_s\": 10.716556310653687}", "{\"n\": 6098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.92, \"learn_time_ms\": 8632.07, \"total_train_time_s\": 10.418277263641357}", "{\"n\": 6099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.49, \"learn_time_ms\": 8556.913, \"total_train_time_s\": 9.536535024642944}", "{\"n\": 6100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.66, \"learn_time_ms\": 8507.763, \"total_train_time_s\": 9.876981496810913}", "{\"n\": 6101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.66, \"learn_time_ms\": 8454.816, \"total_train_time_s\": 8.911607265472412}", "{\"n\": 6102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.25, \"learn_time_ms\": 8545.567, \"total_train_time_s\": 9.955381155014038}", "{\"n\": 6103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.09, \"learn_time_ms\": 8521.126, \"total_train_time_s\": 9.916309118270874}", "{\"n\": 6104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.09, \"learn_time_ms\": 8592.711, \"total_train_time_s\": 9.652446031570435}", "{\"n\": 6105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.09, \"learn_time_ms\": 8646.258, \"total_train_time_s\": 10.189149141311646}", "{\"n\": 6106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.34, \"learn_time_ms\": 8590.896, \"total_train_time_s\": 10.92991018295288}", "{\"n\": 6107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.22, \"learn_time_ms\": 8492.304, \"total_train_time_s\": 9.745801210403442}", "{\"n\": 6108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.22, \"learn_time_ms\": 8362.987, \"total_train_time_s\": 9.112640142440796}", "{\"n\": 6109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.73, \"learn_time_ms\": 8524.79, \"total_train_time_s\": 11.167393445968628}", "{\"n\": 6110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.65, \"learn_time_ms\": 8435.288, \"total_train_time_s\": 8.893834352493286}", "{\"n\": 6111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.65, \"learn_time_ms\": 8616.689, \"total_train_time_s\": 10.685673713684082}", "{\"n\": 6112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.8, \"learn_time_ms\": 8532.325, \"total_train_time_s\": 9.084043502807617}", "{\"n\": 6113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.6, \"learn_time_ms\": 8537.235, \"total_train_time_s\": 10.023200511932373}", "{\"n\": 6114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.72, \"learn_time_ms\": 8620.871, \"total_train_time_s\": 10.561052322387695}", "{\"n\": 6115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.0, \"learn_time_ms\": 8626.204, \"total_train_time_s\": 10.221440315246582}", "{\"n\": 6116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.68, \"learn_time_ms\": 8417.326, \"total_train_time_s\": 8.8290114402771}", "{\"n\": 6117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.19, \"learn_time_ms\": 8436.936, \"total_train_time_s\": 9.935580492019653}", "{\"n\": 6118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.15, \"learn_time_ms\": 8606.733, \"total_train_time_s\": 10.83982515335083}", "{\"n\": 6119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.31, \"learn_time_ms\": 8426.303, \"total_train_time_s\": 9.359251260757446}", "{\"n\": 6120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.22, \"learn_time_ms\": 8451.264, \"total_train_time_s\": 9.16883659362793}", "{\"n\": 6121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.94, \"learn_time_ms\": 8359.455, \"total_train_time_s\": 9.791617393493652}", "{\"n\": 6122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.56, \"learn_time_ms\": 8337.801, \"total_train_time_s\": 8.845305919647217}", "{\"n\": 6123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.56, \"learn_time_ms\": 8274.193, \"total_train_time_s\": 9.334678173065186}", "{\"n\": 6124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.91, \"learn_time_ms\": 8277.6, \"total_train_time_s\": 10.563307762145996}", "{\"n\": 6125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.43, \"learn_time_ms\": 8243.955, \"total_train_time_s\": 9.890991687774658}", "{\"n\": 6126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.1, \"learn_time_ms\": 8303.116, \"total_train_time_s\": 9.440048217773438}", "{\"n\": 6127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.53, \"learn_time_ms\": 8287.555, \"total_train_time_s\": 9.74707555770874}", "{\"n\": 6128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.45, \"learn_time_ms\": 8209.331, \"total_train_time_s\": 10.035909652709961}", "{\"n\": 6129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.41, \"learn_time_ms\": 8249.237, \"total_train_time_s\": 9.739795923233032}", "{\"n\": 6130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.6, \"learn_time_ms\": 8436.29, \"total_train_time_s\": 11.091317653656006}", "{\"n\": 6131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.24, \"learn_time_ms\": 8377.945, \"total_train_time_s\": 9.159913301467896}", "{\"n\": 6132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.49, \"learn_time_ms\": 8495.279, \"total_train_time_s\": 10.078060626983643}", "{\"n\": 6133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.02, \"learn_time_ms\": 8564.954, \"total_train_time_s\": 9.994293689727783}", "{\"n\": 6134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.63, \"learn_time_ms\": 8507.025, \"total_train_time_s\": 9.957309007644653}", "{\"n\": 6135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.63, \"learn_time_ms\": 8421.596, \"total_train_time_s\": 8.985477209091187}", "{\"n\": 6136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.34, \"learn_time_ms\": 8509.749, \"total_train_time_s\": 10.301523923873901}", "{\"n\": 6137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.81, \"learn_time_ms\": 8464.808, \"total_train_time_s\": 9.264804601669312}", "{\"n\": 6138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.05, \"learn_time_ms\": 8490.19, \"total_train_time_s\": 10.300180673599243}", "{\"n\": 6139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.05, \"learn_time_ms\": 8390.751, \"total_train_time_s\": 8.762721538543701}", "{\"n\": 6140, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.26, \"learn_time_ms\": 8401.122, \"total_train_time_s\": 11.15504789352417}", "{\"n\": 6141, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.61, \"learn_time_ms\": 8595.972, \"total_train_time_s\": 11.183887720108032}", "{\"n\": 6142, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.61, \"learn_time_ms\": 8545.546, \"total_train_time_s\": 9.548757791519165}", "{\"n\": 6143, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.03, \"learn_time_ms\": 8606.146, \"total_train_time_s\": 10.59738039970398}", "{\"n\": 6144, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.2, \"learn_time_ms\": 8808.225, \"total_train_time_s\": 11.982476234436035}", "{\"n\": 6145, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.92, \"learn_time_ms\": 8858.499, \"total_train_time_s\": 9.549862146377563}", "{\"n\": 6146, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.02, \"learn_time_ms\": 8763.003, \"total_train_time_s\": 9.402187585830688}", "{\"n\": 6147, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.96, \"learn_time_ms\": 8783.931, \"total_train_time_s\": 9.48906135559082}", "{\"n\": 6148, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.96, \"learn_time_ms\": 8700.873, \"total_train_time_s\": 9.44868540763855}", "{\"n\": 6149, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.95, \"learn_time_ms\": 8791.786, \"total_train_time_s\": 9.659000158309937}", "{\"n\": 6150, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.95, \"learn_time_ms\": 8622.349, \"total_train_time_s\": 9.399112224578857}", "{\"n\": 6151, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.46, \"learn_time_ms\": 8641.821, \"total_train_time_s\": 11.350507736206055}", "{\"n\": 6152, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.4, \"learn_time_ms\": 8716.44, \"total_train_time_s\": 10.288559675216675}", "{\"n\": 6153, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.4, \"learn_time_ms\": 8677.358, \"total_train_time_s\": 10.25655746459961}", "{\"n\": 6154, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.41, \"learn_time_ms\": 8498.978, \"total_train_time_s\": 10.199510335922241}", "{\"n\": 6155, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.41, \"learn_time_ms\": 8549.962, \"total_train_time_s\": 9.99853229522705}", "{\"n\": 6156, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.87, \"learn_time_ms\": 8725.581, \"total_train_time_s\": 11.068497896194458}", "{\"n\": 6157, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.27, \"learn_time_ms\": 8683.47, \"total_train_time_s\": 9.090087413787842}", "{\"n\": 6158, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.66, \"learn_time_ms\": 8705.48, \"total_train_time_s\": 9.757799863815308}", "{\"n\": 6159, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.65, \"learn_time_ms\": 8755.066, \"total_train_time_s\": 10.185708045959473}", "{\"n\": 6160, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.65, \"learn_time_ms\": 8807.935, \"total_train_time_s\": 9.990971088409424}", "{\"n\": 6161, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.45, \"learn_time_ms\": 8524.475, \"total_train_time_s\": 8.49351716041565}", "{\"n\": 6162, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.37, \"learn_time_ms\": 8621.635, \"total_train_time_s\": 11.242343187332153}", "{\"n\": 6163, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.37, \"learn_time_ms\": 8626.778, \"total_train_time_s\": 10.28860878944397}", "{\"n\": 6164, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.69, \"learn_time_ms\": 8635.125, \"total_train_time_s\": 10.30003547668457}", "{\"n\": 6165, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.69, \"learn_time_ms\": 8700.764, \"total_train_time_s\": 10.729014158248901}", "{\"n\": 6166, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.95, \"learn_time_ms\": 8601.141, \"total_train_time_s\": 10.102454423904419}", "{\"n\": 6167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.64, \"learn_time_ms\": 8680.709, \"total_train_time_s\": 9.883117437362671}", "{\"n\": 6168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.13, \"learn_time_ms\": 8801.976, \"total_train_time_s\": 10.900419235229492}", "{\"n\": 6169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.77, \"learn_time_ms\": 8816.064, \"total_train_time_s\": 10.333888292312622}", "{\"n\": 6170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.78, \"learn_time_ms\": 8872.308, \"total_train_time_s\": 10.584187746047974}", "{\"n\": 6171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 8863.326, \"total_train_time_s\": 8.403179407119751}", "{\"n\": 6172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.29, \"learn_time_ms\": 8782.856, \"total_train_time_s\": 10.458069801330566}", "{\"n\": 6173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.03, \"learn_time_ms\": 8768.391, \"total_train_time_s\": 10.185369491577148}", "{\"n\": 6174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.66, \"learn_time_ms\": 8605.738, \"total_train_time_s\": 8.700489044189453}", "{\"n\": 6175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.59, \"learn_time_ms\": 8430.025, \"total_train_time_s\": 8.92760157585144}", "{\"n\": 6176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.68, \"learn_time_ms\": 8380.468, \"total_train_time_s\": 9.601661205291748}", "{\"n\": 6177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.91, \"learn_time_ms\": 8186.269, \"total_train_time_s\": 7.975170612335205}", "{\"n\": 6178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.2, \"learn_time_ms\": 8035.185, \"total_train_time_s\": 9.411102294921875}", "{\"n\": 6179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.2, \"learn_time_ms\": 7974.873, \"total_train_time_s\": 9.724715948104858}", "{\"n\": 6180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.02, \"learn_time_ms\": 7999.936, \"total_train_time_s\": 10.810375690460205}", "{\"n\": 6181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.56, \"learn_time_ms\": 8284.428, \"total_train_time_s\": 11.263582229614258}", "{\"n\": 6182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.48, \"learn_time_ms\": 8319.498, \"total_train_time_s\": 10.793367147445679}", "{\"n\": 6183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.35, \"learn_time_ms\": 8271.861, \"total_train_time_s\": 9.672449827194214}", "{\"n\": 6184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.59, \"learn_time_ms\": 8330.033, \"total_train_time_s\": 9.28302264213562}", "{\"n\": 6185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.1, \"learn_time_ms\": 8518.22, \"total_train_time_s\": 10.848773002624512}", "{\"n\": 6186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 8469.89, \"total_train_time_s\": 9.129793882369995}", "{\"n\": 6187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.08, \"learn_time_ms\": 8639.082, \"total_train_time_s\": 9.631433248519897}", "{\"n\": 6188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.5, \"learn_time_ms\": 8607.633, \"total_train_time_s\": 9.041287660598755}", "{\"n\": 6189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.23, \"learn_time_ms\": 8743.137, \"total_train_time_s\": 11.044514179229736}", "{\"n\": 6190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.25, \"learn_time_ms\": 8692.708, \"total_train_time_s\": 10.293978452682495}", "{\"n\": 6191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.48, \"learn_time_ms\": 8499.865, \"total_train_time_s\": 9.37562370300293}", "{\"n\": 6192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.48, \"learn_time_ms\": 8397.033, \"total_train_time_s\": 9.766404628753662}", "{\"n\": 6193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.52, \"learn_time_ms\": 8376.062, \"total_train_time_s\": 9.481411933898926}", "{\"n\": 6194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 8403.595, \"total_train_time_s\": 9.586405277252197}", "{\"n\": 6195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 8349.79, \"total_train_time_s\": 10.324989318847656}", "{\"n\": 6196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.17, \"learn_time_ms\": 8451.186, \"total_train_time_s\": 10.103382110595703}", "{\"n\": 6197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.35, \"learn_time_ms\": 8623.254, \"total_train_time_s\": 11.354918718338013}", "{\"n\": 6198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.35, \"learn_time_ms\": 8672.097, \"total_train_time_s\": 9.668839454650879}", "{\"n\": 6199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.31, \"learn_time_ms\": 8659.468, \"total_train_time_s\": 10.985555410385132}", "{\"n\": 6200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 8585.491, \"total_train_time_s\": 9.522716999053955}", "{\"n\": 6201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 8743.688, \"total_train_time_s\": 10.9229736328125}", "{\"n\": 6202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 8748.79, \"total_train_time_s\": 9.833224058151245}", "{\"n\": 6203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.0, \"learn_time_ms\": 8826.37, \"total_train_time_s\": 10.261116981506348}", "{\"n\": 6204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.09, \"learn_time_ms\": 8837.813, \"total_train_time_s\": 9.627366065979004}", "{\"n\": 6205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.09, \"learn_time_ms\": 8808.117, \"total_train_time_s\": 10.021316051483154}", "{\"n\": 6206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.72, \"learn_time_ms\": 8764.408, \"total_train_time_s\": 9.707836389541626}", "{\"n\": 6207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.29, \"learn_time_ms\": 8668.147, \"total_train_time_s\": 10.388234853744507}", "{\"n\": 6208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.29, \"learn_time_ms\": 8681.654, \"total_train_time_s\": 9.73278284072876}", "{\"n\": 6209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.28, \"learn_time_ms\": 8725.973, \"total_train_time_s\": 11.37414264678955}", "{\"n\": 6210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.64, \"learn_time_ms\": 8744.274, \"total_train_time_s\": 9.71454906463623}", "{\"n\": 6211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.64, \"learn_time_ms\": 8661.036, \"total_train_time_s\": 10.106409549713135}", "{\"n\": 6212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.64, \"learn_time_ms\": 8596.689, \"total_train_time_s\": 9.179489850997925}", "{\"n\": 6213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.81, \"learn_time_ms\": 8638.839, \"total_train_time_s\": 10.650355577468872}", "{\"n\": 6214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.82, \"learn_time_ms\": 8713.014, \"total_train_time_s\": 10.386704444885254}", "{\"n\": 6215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.82, \"learn_time_ms\": 8769.152, \"total_train_time_s\": 10.558322668075562}", "{\"n\": 6216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.15, \"learn_time_ms\": 8791.201, \"total_train_time_s\": 9.93343710899353}", "{\"n\": 6217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.45, \"learn_time_ms\": 8758.496, \"total_train_time_s\": 10.06008243560791}", "{\"n\": 6218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.2, \"learn_time_ms\": 8896.045, \"total_train_time_s\": 11.03871488571167}", "{\"n\": 6219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.2, \"learn_time_ms\": 8656.237, \"total_train_time_s\": 8.970529556274414}", "{\"n\": 6220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.08, \"learn_time_ms\": 8731.297, \"total_train_time_s\": 10.544138193130493}", "{\"n\": 6221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.08, \"learn_time_ms\": 8675.788, \"total_train_time_s\": 9.506773471832275}", "{\"n\": 6222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.02, \"learn_time_ms\": 8546.227, \"total_train_time_s\": 7.8994669914245605}", "{\"n\": 6223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.65, \"learn_time_ms\": 8405.311, \"total_train_time_s\": 9.242910623550415}", "{\"n\": 6224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.65, \"learn_time_ms\": 8389.736, \"total_train_time_s\": 10.233152151107788}", "{\"n\": 6225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.65, \"learn_time_ms\": 8298.073, \"total_train_time_s\": 9.616976737976074}", "{\"n\": 6226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.0, \"learn_time_ms\": 8099.075, \"total_train_time_s\": 7.940319299697876}", "{\"n\": 6227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.75, \"learn_time_ms\": 8069.689, \"total_train_time_s\": 9.763571977615356}", "{\"n\": 6228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.2, \"learn_time_ms\": 7875.324, \"total_train_time_s\": 9.136348485946655}", "{\"n\": 6229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.45, \"learn_time_ms\": 7909.534, \"total_train_time_s\": 9.360548257827759}", "{\"n\": 6230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 7845.393, \"total_train_time_s\": 9.843417406082153}", "{\"n\": 6231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 8078.975, \"total_train_time_s\": 11.827113151550293}", "{\"n\": 6232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.57, \"learn_time_ms\": 8261.444, \"total_train_time_s\": 9.701502323150635}", "{\"n\": 6233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.07, \"learn_time_ms\": 8360.657, \"total_train_time_s\": 10.258026123046875}", "{\"n\": 6234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.07, \"learn_time_ms\": 8341.463, \"total_train_time_s\": 10.065354347229004}", "{\"n\": 6235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.14, \"learn_time_ms\": 8363.309, \"total_train_time_s\": 9.868841886520386}", "{\"n\": 6236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.34, \"learn_time_ms\": 8544.715, \"total_train_time_s\": 9.76601767539978}", "{\"n\": 6237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.34, \"learn_time_ms\": 8676.482, \"total_train_time_s\": 11.108896732330322}", "{\"n\": 6238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.88, \"learn_time_ms\": 8778.208, \"total_train_time_s\": 10.12102460861206}", "{\"n\": 6239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.36, \"learn_time_ms\": 8834.09, \"total_train_time_s\": 9.860896825790405}", "{\"n\": 6240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.36, \"learn_time_ms\": 8975.283, \"total_train_time_s\": 11.244979858398438}", "{\"n\": 6241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.26, \"learn_time_ms\": 8913.293, \"total_train_time_s\": 11.234275102615356}", "{\"n\": 6242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.24, \"learn_time_ms\": 8896.915, \"total_train_time_s\": 9.556367635726929}", "{\"n\": 6243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.24, \"learn_time_ms\": 8909.033, \"total_train_time_s\": 10.36532998085022}", "{\"n\": 6244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.24, \"learn_time_ms\": 9007.737, \"total_train_time_s\": 11.033449649810791}", "{\"n\": 6245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.47, \"learn_time_ms\": 9047.755, \"total_train_time_s\": 10.268633604049683}", "{\"n\": 6246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.73, \"learn_time_ms\": 9013.759, \"total_train_time_s\": 9.361700296401978}", "{\"n\": 6247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.46, \"learn_time_ms\": 8844.855, \"total_train_time_s\": 9.347925424575806}", "{\"n\": 6248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.2, \"learn_time_ms\": 8693.227, \"total_train_time_s\": 8.593243598937988}", "{\"n\": 6249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.09, \"learn_time_ms\": 8688.773, \"total_train_time_s\": 9.823289632797241}", "{\"n\": 6250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.87, \"learn_time_ms\": 8508.912, \"total_train_time_s\": 9.490931272506714}", "{\"n\": 6251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.24, \"learn_time_ms\": 8272.801, \"total_train_time_s\": 8.911975622177124}", "{\"n\": 6252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.26, \"learn_time_ms\": 8363.445, \"total_train_time_s\": 10.451300382614136}", "{\"n\": 6253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.26, \"learn_time_ms\": 8254.85, \"total_train_time_s\": 9.247421979904175}", "{\"n\": 6254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.49, \"learn_time_ms\": 8081.049, \"total_train_time_s\": 9.28344440460205}", "{\"n\": 6255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.87, \"learn_time_ms\": 7940.53, \"total_train_time_s\": 8.882343053817749}", "{\"n\": 6256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.87, \"learn_time_ms\": 7971.82, \"total_train_time_s\": 9.720116376876831}", "{\"n\": 6257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.28, \"learn_time_ms\": 7965.697, \"total_train_time_s\": 9.358959674835205}", "{\"n\": 6258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.41, \"learn_time_ms\": 8080.541, \"total_train_time_s\": 9.827532052993774}", "{\"n\": 6259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.41, \"learn_time_ms\": 8027.321, \"total_train_time_s\": 9.34697437286377}", "{\"n\": 6260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.48, \"learn_time_ms\": 8062.031, \"total_train_time_s\": 9.798947095870972}", "{\"n\": 6261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.54, \"learn_time_ms\": 8126.945, \"total_train_time_s\": 9.527807235717773}", "{\"n\": 6262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.99, \"learn_time_ms\": 8093.93, \"total_train_time_s\": 10.16461181640625}", "{\"n\": 6263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.58, \"learn_time_ms\": 8157.501, \"total_train_time_s\": 9.91085696220398}", "{\"n\": 6264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.4, \"learn_time_ms\": 8344.839, \"total_train_time_s\": 11.151330471038818}", "{\"n\": 6265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.05, \"learn_time_ms\": 8518.704, \"total_train_time_s\": 10.620034217834473}", "{\"n\": 6266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.03, \"learn_time_ms\": 8761.689, \"total_train_time_s\": 12.167493104934692}", "{\"n\": 6267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.03, \"learn_time_ms\": 8823.669, \"total_train_time_s\": 9.96147871017456}", "{\"n\": 6268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.39, \"learn_time_ms\": 8938.358, \"total_train_time_s\": 10.96124267578125}", "{\"n\": 6269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.59, \"learn_time_ms\": 9028.802, \"total_train_time_s\": 10.22125792503357}", "{\"n\": 6270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.59, \"learn_time_ms\": 9117.331, \"total_train_time_s\": 10.686931133270264}", "{\"n\": 6271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.68, \"learn_time_ms\": 9168.161, \"total_train_time_s\": 10.065443754196167}", "{\"n\": 6272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.48, \"learn_time_ms\": 9276.554, \"total_train_time_s\": 11.22633171081543}", "{\"n\": 6273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.48, \"learn_time_ms\": 9317.575, \"total_train_time_s\": 10.339178800582886}", "{\"n\": 6274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.71, \"learn_time_ms\": 9264.434, \"total_train_time_s\": 10.613495349884033}", "{\"n\": 6275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.74, \"learn_time_ms\": 9095.761, \"total_train_time_s\": 8.918406009674072}", "{\"n\": 6276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.74, \"learn_time_ms\": 8876.818, \"total_train_time_s\": 9.964734554290771}", "{\"n\": 6277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.67, \"learn_time_ms\": 8851.276, \"total_train_time_s\": 9.71450138092041}", "{\"n\": 6278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.6, \"learn_time_ms\": 8855.51, \"total_train_time_s\": 10.91409945487976}", "{\"n\": 6279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.22, \"learn_time_ms\": 8896.211, \"total_train_time_s\": 10.598579406738281}", "{\"n\": 6280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.72, \"learn_time_ms\": 8787.36, \"total_train_time_s\": 9.625855922698975}", "{\"n\": 6281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.13, \"learn_time_ms\": 8795.844, \"total_train_time_s\": 10.125433206558228}", "{\"n\": 6282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.17, \"learn_time_ms\": 8631.874, \"total_train_time_s\": 9.571336030960083}", "{\"n\": 6283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.73, \"learn_time_ms\": 8614.428, \"total_train_time_s\": 10.17907977104187}", "{\"n\": 6284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.73, \"learn_time_ms\": 8474.804, \"total_train_time_s\": 9.200603246688843}", "{\"n\": 6285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.61, \"learn_time_ms\": 8677.96, \"total_train_time_s\": 10.991861581802368}", "{\"n\": 6286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.15, \"learn_time_ms\": 8633.967, \"total_train_time_s\": 9.535181045532227}", "{\"n\": 6287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.46, \"learn_time_ms\": 8625.748, \"total_train_time_s\": 9.6099693775177}", "{\"n\": 6288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.46, \"learn_time_ms\": 8524.623, \"total_train_time_s\": 9.927740335464478}", "{\"n\": 6289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.63, \"learn_time_ms\": 8332.554, \"total_train_time_s\": 8.702012538909912}", "{\"n\": 6290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.43, \"learn_time_ms\": 8275.424, \"total_train_time_s\": 9.00684142112732}", "{\"n\": 6291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.43, \"learn_time_ms\": 8316.723, \"total_train_time_s\": 10.53096055984497}", "{\"n\": 6292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.64, \"learn_time_ms\": 8310.41, \"total_train_time_s\": 9.524253129959106}", "{\"n\": 6293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.26, \"learn_time_ms\": 8146.611, \"total_train_time_s\": 8.487617492675781}", "{\"n\": 6294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.26, \"learn_time_ms\": 8301.062, \"total_train_time_s\": 10.738603591918945}", "{\"n\": 6295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.38, \"learn_time_ms\": 8143.639, \"total_train_time_s\": 9.374421119689941}", "{\"n\": 6296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.79, \"learn_time_ms\": 8220.88, \"total_train_time_s\": 10.293992042541504}", "{\"n\": 6297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.44, \"learn_time_ms\": 8225.413, \"total_train_time_s\": 9.672350406646729}", "{\"n\": 6298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.94, \"learn_time_ms\": 8107.082, \"total_train_time_s\": 8.751586437225342}", "{\"n\": 6299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.94, \"learn_time_ms\": 8201.727, \"total_train_time_s\": 9.637263059616089}", "{\"n\": 6300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 8330.941, \"total_train_time_s\": 10.33811354637146}", "{\"n\": 6301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.82, \"learn_time_ms\": 8335.19, \"total_train_time_s\": 10.604055166244507}", "{\"n\": 6302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.36, \"learn_time_ms\": 8323.357, \"total_train_time_s\": 9.43701720237732}", "{\"n\": 6303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.36, \"learn_time_ms\": 8396.258, \"total_train_time_s\": 9.22991132736206}", "{\"n\": 6304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.01, \"learn_time_ms\": 8389.535, \"total_train_time_s\": 10.74869704246521}", "{\"n\": 6305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.01, \"learn_time_ms\": 8407.852, \"total_train_time_s\": 9.545644998550415}", "{\"n\": 6306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.54, \"learn_time_ms\": 8363.141, \"total_train_time_s\": 9.83617639541626}", "{\"n\": 6307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.72, \"learn_time_ms\": 8366.813, \"total_train_time_s\": 9.699447393417358}", "{\"n\": 6308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.2, \"learn_time_ms\": 8581.029, \"total_train_time_s\": 10.89134669303894}", "{\"n\": 6309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.2, \"learn_time_ms\": 8546.487, \"total_train_time_s\": 9.293774843215942}", "{\"n\": 6310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.1, \"learn_time_ms\": 8613.111, \"total_train_time_s\": 11.018193483352661}", "{\"n\": 6311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.54, \"learn_time_ms\": 8460.953, \"total_train_time_s\": 9.084081172943115}", "{\"n\": 6312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.54, \"learn_time_ms\": 8599.044, \"total_train_time_s\": 10.714848756790161}", "{\"n\": 6313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3217.5, \"learn_time_ms\": 8702.548, \"total_train_time_s\": 10.28443956375122}", "{\"n\": 6314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.99, \"learn_time_ms\": 8559.638, \"total_train_time_s\": 9.311559438705444}", "{\"n\": 6315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.99, \"learn_time_ms\": 8644.189, \"total_train_time_s\": 10.368602514266968}", "{\"n\": 6316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.99, \"learn_time_ms\": 8665.214, \"total_train_time_s\": 10.029699087142944}", "{\"n\": 6317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3218.17, \"learn_time_ms\": 8670.999, \"total_train_time_s\": 9.792175769805908}", "{\"n\": 6318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.85, \"learn_time_ms\": 8553.835, \"total_train_time_s\": 9.765182495117188}", "{\"n\": 6319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.85, \"learn_time_ms\": 8725.853, \"total_train_time_s\": 10.987408876419067}", "{\"n\": 6320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3218.25, \"learn_time_ms\": 8569.391, \"total_train_time_s\": 9.44443392753601}", "{\"n\": 6321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3223.59, \"learn_time_ms\": 8679.827, \"total_train_time_s\": 10.15410327911377}", "{\"n\": 6322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3223.59, \"learn_time_ms\": 8645.026, \"total_train_time_s\": 10.410351276397705}", "{\"n\": 6323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3222.71, \"learn_time_ms\": 8531.048, \"total_train_time_s\": 9.103221654891968}", "{\"n\": 6324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3234.94, \"learn_time_ms\": 8491.174, \"total_train_time_s\": 8.873432874679565}", "{\"n\": 6325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3234.94, \"learn_time_ms\": 8464.548, \"total_train_time_s\": 10.10332703590393}", "{\"n\": 6326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3234.94, \"learn_time_ms\": 8304.255, \"total_train_time_s\": 8.431989908218384}", "{\"n\": 6327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8371.328, \"total_train_time_s\": 10.417060613632202}", "{\"n\": 6328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.48, \"learn_time_ms\": 8508.598, \"total_train_time_s\": 11.086678266525269}", "{\"n\": 6329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.48, \"learn_time_ms\": 8425.182, \"total_train_time_s\": 10.159343004226685}", "{\"n\": 6330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3235.78, \"learn_time_ms\": 8570.76, \"total_train_time_s\": 10.902404546737671}", "{\"n\": 6331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.74, \"learn_time_ms\": 8459.723, \"total_train_time_s\": 9.091846942901611}", "{\"n\": 6332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.74, \"learn_time_ms\": 8427.915, \"total_train_time_s\": 10.08378291130066}", "{\"n\": 6333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3243.31, \"learn_time_ms\": 8577.562, \"total_train_time_s\": 10.62912654876709}", "{\"n\": 6334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3246.32, \"learn_time_ms\": 8745.585, \"total_train_time_s\": 10.587715148925781}", "{\"n\": 6335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3246.32, \"learn_time_ms\": 8732.75, \"total_train_time_s\": 9.976632595062256}", "{\"n\": 6336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.55, \"learn_time_ms\": 9000.975, \"total_train_time_s\": 11.134298324584961}", "{\"n\": 6337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.55, \"learn_time_ms\": 8954.098, \"total_train_time_s\": 9.964731216430664}", "{\"n\": 6338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.18, \"learn_time_ms\": 8806.61, \"total_train_time_s\": 9.666276931762695}", "{\"n\": 6339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.18, \"learn_time_ms\": 8746.612, \"total_train_time_s\": 9.636016130447388}", "{\"n\": 6340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3245.41, \"learn_time_ms\": 8429.421, \"total_train_time_s\": 7.74020528793335}", "{\"n\": 6341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3253.21, \"learn_time_ms\": 8487.468, \"total_train_time_s\": 9.621297359466553}", "{\"n\": 6342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3253.21, \"learn_time_ms\": 8546.4, \"total_train_time_s\": 10.713338375091553}", "{\"n\": 6343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3254.37, \"learn_time_ms\": 8432.528, \"total_train_time_s\": 9.517639636993408}", "{\"n\": 6344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3257.93, \"learn_time_ms\": 8351.873, \"total_train_time_s\": 9.810546875}", "{\"n\": 6345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3257.93, \"learn_time_ms\": 8316.054, \"total_train_time_s\": 9.652714490890503}", "{\"n\": 6346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3252.89, \"learn_time_ms\": 8150.268, \"total_train_time_s\": 9.478856086730957}", "{\"n\": 6347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.78, \"learn_time_ms\": 8225.34, \"total_train_time_s\": 10.72490406036377}", "{\"n\": 6348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.78, \"learn_time_ms\": 8254.757, \"total_train_time_s\": 9.961962938308716}", "{\"n\": 6349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.94, \"learn_time_ms\": 8216.32, \"total_train_time_s\": 9.19657301902771}", "{\"n\": 6350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.68, \"learn_time_ms\": 8355.986, \"total_train_time_s\": 9.13257646560669}", "{\"n\": 6351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.68, \"learn_time_ms\": 8400.424, \"total_train_time_s\": 10.068416118621826}", "{\"n\": 6352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3243.08, \"learn_time_ms\": 8342.083, \"total_train_time_s\": 10.112074613571167}", "{\"n\": 6353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3244.23, \"learn_time_ms\": 8364.266, \"total_train_time_s\": 9.714682817459106}", "{\"n\": 6354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3249.38, \"learn_time_ms\": 8421.948, \"total_train_time_s\": 10.35523533821106}", "{\"n\": 6355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.59, \"learn_time_ms\": 8508.702, \"total_train_time_s\": 10.513029336929321}", "{\"n\": 6356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.14, \"learn_time_ms\": 8512.398, \"total_train_time_s\": 9.518481016159058}", "{\"n\": 6357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.1, \"learn_time_ms\": 8434.185, \"total_train_time_s\": 9.870744466781616}", "{\"n\": 6358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.1, \"learn_time_ms\": 8310.554, \"total_train_time_s\": 8.686877965927124}", "{\"n\": 6359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3242.39, \"learn_time_ms\": 8223.433, \"total_train_time_s\": 8.375767707824707}", "{\"n\": 6360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3242.16, \"learn_time_ms\": 8298.679, \"total_train_time_s\": 9.8706693649292}", "{\"n\": 6361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3242.16, \"learn_time_ms\": 8324.97, \"total_train_time_s\": 10.312809228897095}", "{\"n\": 6362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3246.04, \"learn_time_ms\": 8296.45, \"total_train_time_s\": 9.79640507698059}", "{\"n\": 6363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.73, \"learn_time_ms\": 8358.418, \"total_train_time_s\": 10.34477710723877}", "{\"n\": 6364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.73, \"learn_time_ms\": 8392.493, \"total_train_time_s\": 10.697309017181396}", "{\"n\": 6365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3249.58, \"learn_time_ms\": 8360.436, \"total_train_time_s\": 10.190681457519531}", "{\"n\": 6366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3252.28, \"learn_time_ms\": 8480.77, \"total_train_time_s\": 10.685625314712524}", "{\"n\": 6367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3258.7, \"learn_time_ms\": 8603.957, \"total_train_time_s\": 11.207667350769043}", "{\"n\": 6368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3262.85, \"learn_time_ms\": 8832.243, \"total_train_time_s\": 10.988400936126709}", "{\"n\": 6369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3266.1, \"learn_time_ms\": 8969.526, \"total_train_time_s\": 9.688499450683594}", "{\"n\": 6370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3260.77, \"learn_time_ms\": 8999.05, \"total_train_time_s\": 10.182998895645142}", "{\"n\": 6371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3260.61, \"learn_time_ms\": 8979.901, \"total_train_time_s\": 10.152766227722168}", "{\"n\": 6372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3256.76, \"learn_time_ms\": 8917.236, \"total_train_time_s\": 9.335295915603638}", "{\"n\": 6373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3258.3, \"learn_time_ms\": 8769.77, \"total_train_time_s\": 8.837668180465698}", "{\"n\": 6374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3254.5, \"learn_time_ms\": 8752.198, \"total_train_time_s\": 10.45982027053833}", "{\"n\": 6375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3253.37, \"learn_time_ms\": 8730.781, \"total_train_time_s\": 9.946031332015991}", "{\"n\": 6376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.59, \"learn_time_ms\": 8660.983, \"total_train_time_s\": 10.017884731292725}", "{\"n\": 6377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.02, \"learn_time_ms\": 8683.104, \"total_train_time_s\": 11.489280700683594}", "{\"n\": 6378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3249.12, \"learn_time_ms\": 8531.322, \"total_train_time_s\": 9.488961219787598}", "{\"n\": 6379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 8500.82, \"total_train_time_s\": 9.460049390792847}", "{\"n\": 6380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 8448.644, \"total_train_time_s\": 9.654707193374634}", "{\"n\": 6381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.43, \"learn_time_ms\": 8373.016, \"total_train_time_s\": 9.36658763885498}", "{\"n\": 6382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.78, \"learn_time_ms\": 8401.216, \"total_train_time_s\": 9.527554035186768}", "{\"n\": 6383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.78, \"learn_time_ms\": 8577.015, \"total_train_time_s\": 10.700667142868042}", "{\"n\": 6384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3225.35, \"learn_time_ms\": 8510.677, \"total_train_time_s\": 9.865801095962524}", "{\"n\": 6385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3231.94, \"learn_time_ms\": 8500.047, \"total_train_time_s\": 9.873973846435547}", "{\"n\": 6386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.61, \"learn_time_ms\": 8419.971, \"total_train_time_s\": 9.26945424079895}", "{\"n\": 6387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.82, \"learn_time_ms\": 8298.884, \"total_train_time_s\": 10.185508251190186}", "{\"n\": 6388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.71, \"learn_time_ms\": 8408.155, \"total_train_time_s\": 10.561248064041138}", "{\"n\": 6389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.71, \"learn_time_ms\": 8329.431, \"total_train_time_s\": 8.601423025131226}", "{\"n\": 6390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3234.62, \"learn_time_ms\": 8355.578, \"total_train_time_s\": 9.952731847763062}", "{\"n\": 6391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3231.85, \"learn_time_ms\": 8399.56, \"total_train_time_s\": 9.881868362426758}", "{\"n\": 6392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3231.85, \"learn_time_ms\": 8475.321, \"total_train_time_s\": 10.197519779205322}", "{\"n\": 6393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3240.46, \"learn_time_ms\": 8375.314, \"total_train_time_s\": 9.635801553726196}", "{\"n\": 6394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3230.57, \"learn_time_ms\": 8344.973, \"total_train_time_s\": 9.544895648956299}", "{\"n\": 6395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3230.57, \"learn_time_ms\": 8399.832, \"total_train_time_s\": 10.440687894821167}", "{\"n\": 6396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3232.26, \"learn_time_ms\": 8473.71, \"total_train_time_s\": 9.98581051826477}", "{\"n\": 6397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.02, \"learn_time_ms\": 8462.37, \"total_train_time_s\": 9.98196816444397}", "{\"n\": 6398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.1, \"learn_time_ms\": 8512.532, \"total_train_time_s\": 11.085846662521362}", "{\"n\": 6399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3241.7, \"learn_time_ms\": 8573.012, \"total_train_time_s\": 9.203868389129639}", "{\"n\": 6400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3241.7, \"learn_time_ms\": 8454.774, \"total_train_time_s\": 8.691882133483887}", "{\"n\": 6401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.84, \"learn_time_ms\": 8489.145, \"total_train_time_s\": 10.205758571624756}", "{\"n\": 6402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.84, \"learn_time_ms\": 8536.287, \"total_train_time_s\": 10.712078332901001}", "{\"n\": 6403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3242.86, \"learn_time_ms\": 8433.47, \"total_train_time_s\": 8.588947772979736}", "{\"n\": 6404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.57, \"learn_time_ms\": 8634.026, \"total_train_time_s\": 11.567817449569702}", "{\"n\": 6405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.57, \"learn_time_ms\": 8450.515, \"total_train_time_s\": 8.583155632019043}", "{\"n\": 6406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.07, \"learn_time_ms\": 8412.043, \"total_train_time_s\": 9.615020275115967}", "{\"n\": 6407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.02, \"learn_time_ms\": 8505.645, \"total_train_time_s\": 10.988158226013184}", "{\"n\": 6408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 8377.934, \"total_train_time_s\": 9.785783290863037}", "{\"n\": 6409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.24, \"learn_time_ms\": 8507.082, \"total_train_time_s\": 10.499592304229736}", "{\"n\": 6410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.42, \"learn_time_ms\": 8633.367, \"total_train_time_s\": 10.041099786758423}", "{\"n\": 6411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.42, \"learn_time_ms\": 8619.126, \"total_train_time_s\": 10.015354871749878}", "{\"n\": 6412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.68, \"learn_time_ms\": 8611.062, \"total_train_time_s\": 10.612135410308838}", "{\"n\": 6413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.91, \"learn_time_ms\": 8827.652, \"total_train_time_s\": 10.733087539672852}", "{\"n\": 6414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.91, \"learn_time_ms\": 8764.977, \"total_train_time_s\": 10.915552139282227}", "{\"n\": 6415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.91, \"learn_time_ms\": 8863.5, \"total_train_time_s\": 9.522569417953491}", "{\"n\": 6416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.21, \"learn_time_ms\": 8866.94, \"total_train_time_s\": 9.597746133804321}", "{\"n\": 6417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.21, \"learn_time_ms\": 8873.018, \"total_train_time_s\": 11.057791233062744}", "{\"n\": 6418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.21, \"learn_time_ms\": 8891.033, \"total_train_time_s\": 9.971770286560059}", "{\"n\": 6419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.04, \"learn_time_ms\": 8794.331, \"total_train_time_s\": 9.56920313835144}", "{\"n\": 6420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.48, \"learn_time_ms\": 8978.875, \"total_train_time_s\": 11.840805768966675}", "{\"n\": 6421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.48, \"learn_time_ms\": 8988.823, \"total_train_time_s\": 10.09958004951477}", "{\"n\": 6422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.96, \"learn_time_ms\": 8895.861, \"total_train_time_s\": 9.654433488845825}", "{\"n\": 6423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.76, \"learn_time_ms\": 8811.9, \"total_train_time_s\": 9.942211389541626}", "{\"n\": 6424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.76, \"learn_time_ms\": 8613.173, \"total_train_time_s\": 8.947940111160278}", "{\"n\": 6425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.76, \"learn_time_ms\": 8670.929, \"total_train_time_s\": 10.124414682388306}", "{\"n\": 6426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.46, \"learn_time_ms\": 8811.003, \"total_train_time_s\": 11.013852834701538}", "{\"n\": 6427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.46, \"learn_time_ms\": 8656.239, \"total_train_time_s\": 9.50069522857666}", "{\"n\": 6428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.46, \"learn_time_ms\": 8663.108, \"total_train_time_s\": 10.080966234207153}", "{\"n\": 6429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.47, \"learn_time_ms\": 8709.068, \"total_train_time_s\": 10.028794527053833}", "{\"n\": 6430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.26, \"learn_time_ms\": 8607.044, \"total_train_time_s\": 10.817102909088135}", "{\"n\": 6431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.26, \"learn_time_ms\": 8639.346, \"total_train_time_s\": 10.411280632019043}", "{\"n\": 6432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.02, \"learn_time_ms\": 8717.313, \"total_train_time_s\": 10.634456634521484}", "{\"n\": 6433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8702.96, \"total_train_time_s\": 9.782585382461548}", "{\"n\": 6434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8890.37, \"total_train_time_s\": 10.825647115707397}", "{\"n\": 6435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.96, \"learn_time_ms\": 8930.119, \"total_train_time_s\": 10.571398735046387}", "{\"n\": 6436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.93, \"learn_time_ms\": 8849.88, \"total_train_time_s\": 10.208523750305176}", "{\"n\": 6437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.8, \"learn_time_ms\": 8878.88, \"total_train_time_s\": 9.802073955535889}", "{\"n\": 6438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.8, \"learn_time_ms\": 8871.293, \"total_train_time_s\": 9.922553777694702}", "{\"n\": 6439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.29, \"learn_time_ms\": 8936.755, \"total_train_time_s\": 10.622801780700684}", "{\"n\": 6440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.64, \"learn_time_ms\": 8913.044, \"total_train_time_s\": 10.53689956665039}", "{\"n\": 6441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.64, \"learn_time_ms\": 8838.394, \"total_train_time_s\": 9.644949913024902}", "{\"n\": 6442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.53, \"learn_time_ms\": 8848.157, \"total_train_time_s\": 10.565235614776611}", "{\"n\": 6443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.82, \"learn_time_ms\": 8957.231, \"total_train_time_s\": 10.845292329788208}", "{\"n\": 6444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.92, \"learn_time_ms\": 9010.953, \"total_train_time_s\": 11.324323177337646}", "{\"n\": 6445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.46, \"learn_time_ms\": 8895.169, \"total_train_time_s\": 9.398987531661987}", "{\"n\": 6446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.8, \"learn_time_ms\": 8900.365, \"total_train_time_s\": 10.259217739105225}", "{\"n\": 6447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.5, \"learn_time_ms\": 8825.071, \"total_train_time_s\": 9.041688680648804}", "{\"n\": 6448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.56, \"learn_time_ms\": 8888.995, \"total_train_time_s\": 10.599371194839478}", "{\"n\": 6449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.22, \"learn_time_ms\": 8772.211, \"total_train_time_s\": 9.480918169021606}", "{\"n\": 6450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.72, \"learn_time_ms\": 8603.891, \"total_train_time_s\": 8.868685722351074}", "{\"n\": 6451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.72, \"learn_time_ms\": 8632.77, \"total_train_time_s\": 10.016835451126099}", "{\"n\": 6452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.28, \"learn_time_ms\": 8547.428, \"total_train_time_s\": 9.716485977172852}", "{\"n\": 6453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.62, \"learn_time_ms\": 8514.741, \"total_train_time_s\": 10.510853290557861}", "{\"n\": 6454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.62, \"learn_time_ms\": 8518.031, \"total_train_time_s\": 11.387715816497803}", "{\"n\": 6455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.22, \"learn_time_ms\": 8597.007, \"total_train_time_s\": 10.179580211639404}", "{\"n\": 6456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.13, \"learn_time_ms\": 8603.555, \"total_train_time_s\": 10.362555503845215}", "{\"n\": 6457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.13, \"learn_time_ms\": 8498.113, \"total_train_time_s\": 7.980743646621704}", "{\"n\": 6458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.43, \"learn_time_ms\": 8371.573, \"total_train_time_s\": 9.341142892837524}", "{\"n\": 6459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.56, \"learn_time_ms\": 8552.547, \"total_train_time_s\": 11.321011543273926}", "{\"n\": 6460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.56, \"learn_time_ms\": 8608.454, \"total_train_time_s\": 9.422495126724243}", "{\"n\": 6461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.99, \"learn_time_ms\": 8595.821, \"total_train_time_s\": 9.915623903274536}", "{\"n\": 6462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.4, \"learn_time_ms\": 8638.041, \"total_train_time_s\": 10.126063823699951}", "{\"n\": 6463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.99, \"learn_time_ms\": 8539.838, \"total_train_time_s\": 9.54501748085022}", "{\"n\": 6464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.99, \"learn_time_ms\": 8305.46, \"total_train_time_s\": 9.026326656341553}", "{\"n\": 6465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.04, \"learn_time_ms\": 8271.223, \"total_train_time_s\": 9.843035697937012}", "{\"n\": 6466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.55, \"learn_time_ms\": 8216.852, \"total_train_time_s\": 9.799957513809204}", "{\"n\": 6467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.55, \"learn_time_ms\": 8505.158, \"total_train_time_s\": 10.87826919555664}", "{\"n\": 6468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.94, \"learn_time_ms\": 8505.562, \"total_train_time_s\": 9.323654413223267}", "{\"n\": 6469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.65, \"learn_time_ms\": 8301.109, \"total_train_time_s\": 9.231682300567627}", "{\"n\": 6470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.65, \"learn_time_ms\": 8172.488, \"total_train_time_s\": 8.173553466796875}", "{\"n\": 6471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.48, \"learn_time_ms\": 8277.425, \"total_train_time_s\": 10.90840768814087}", "{\"n\": 6472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.77, \"learn_time_ms\": 8298.692, \"total_train_time_s\": 10.360130071640015}", "{\"n\": 6473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.77, \"learn_time_ms\": 8387.211, \"total_train_time_s\": 10.409552335739136}", "{\"n\": 6474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.03, \"learn_time_ms\": 8492.707, \"total_train_time_s\": 10.065107583999634}", "{\"n\": 6475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.83, \"learn_time_ms\": 8470.067, \"total_train_time_s\": 9.624647855758667}", "{\"n\": 6476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.52, \"learn_time_ms\": 8583.614, \"total_train_time_s\": 10.938140869140625}", "{\"n\": 6477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.47, \"learn_time_ms\": 8479.037, \"total_train_time_s\": 9.86484956741333}", "{\"n\": 6478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.19, \"learn_time_ms\": 8463.605, \"total_train_time_s\": 9.239234924316406}", "{\"n\": 6479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.24, \"learn_time_ms\": 8550.345, \"total_train_time_s\": 10.099845170974731}", "{\"n\": 6480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.4, \"learn_time_ms\": 8728.216, \"total_train_time_s\": 9.953913688659668}", "{\"n\": 6481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.4, \"learn_time_ms\": 8687.241, \"total_train_time_s\": 10.517681360244751}", "{\"n\": 6482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.66, \"learn_time_ms\": 8606.849, \"total_train_time_s\": 9.554633140563965}", "{\"n\": 6483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.66, \"learn_time_ms\": 8414.378, \"total_train_time_s\": 8.481074333190918}", "{\"n\": 6484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.16, \"learn_time_ms\": 8460.767, \"total_train_time_s\": 10.503042697906494}", "{\"n\": 6485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.05, \"learn_time_ms\": 8446.315, \"total_train_time_s\": 9.42175841331482}", "{\"n\": 6486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.05, \"learn_time_ms\": 8362.045, \"total_train_time_s\": 10.055823564529419}", "{\"n\": 6487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.56, \"learn_time_ms\": 8262.549, \"total_train_time_s\": 8.774184703826904}", "{\"n\": 6488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.11, \"learn_time_ms\": 8277.676, \"total_train_time_s\": 9.330485105514526}", "{\"n\": 6489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.66, \"learn_time_ms\": 8304.816, \"total_train_time_s\": 10.368109226226807}", "{\"n\": 6490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.66, \"learn_time_ms\": 8277.598, \"total_train_time_s\": 9.65088939666748}", "{\"n\": 6491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.67, \"learn_time_ms\": 8190.628, \"total_train_time_s\": 9.629272222518921}", "{\"n\": 6492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.76, \"learn_time_ms\": 8253.638, \"total_train_time_s\": 10.136854648590088}", "{\"n\": 6493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.76, \"learn_time_ms\": 8438.047, \"total_train_time_s\": 10.352049589157104}", "{\"n\": 6494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.31, \"learn_time_ms\": 8317.013, \"total_train_time_s\": 9.364840030670166}", "{\"n\": 6495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.74, \"learn_time_ms\": 8369.763, \"total_train_time_s\": 9.945225954055786}", "{\"n\": 6496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.74, \"learn_time_ms\": 8222.526, \"total_train_time_s\": 8.569697618484497}", "{\"n\": 6497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.81, \"learn_time_ms\": 8392.989, \"total_train_time_s\": 10.536924123764038}", "{\"n\": 6498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.87, \"learn_time_ms\": 8492.021, \"total_train_time_s\": 10.274410486221313}", "{\"n\": 6499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.87, \"learn_time_ms\": 8528.99, \"total_train_time_s\": 10.78683066368103}", "{\"n\": 6500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.94, \"learn_time_ms\": 8400.513, \"total_train_time_s\": 8.41618800163269}", "{\"n\": 6501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.57, \"learn_time_ms\": 8477.959, \"total_train_time_s\": 10.396876096725464}", "{\"n\": 6502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.57, \"learn_time_ms\": 8464.815, \"total_train_time_s\": 10.065101385116577}", "{\"n\": 6503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.7, \"learn_time_ms\": 8310.491, \"total_train_time_s\": 8.81691598892212}", "{\"n\": 6504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.23, \"learn_time_ms\": 8399.185, \"total_train_time_s\": 10.183624267578125}", "{\"n\": 6505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.29, \"learn_time_ms\": 8434.439, \"total_train_time_s\": 10.301804542541504}", "{\"n\": 6506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.36, \"learn_time_ms\": 8508.381, \"total_train_time_s\": 9.342325925827026}", "{\"n\": 6507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.98, \"learn_time_ms\": 8415.789, \"total_train_time_s\": 9.595090866088867}", "{\"n\": 6508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.29, \"learn_time_ms\": 8259.421, \"total_train_time_s\": 8.780180215835571}", "{\"n\": 6509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.29, \"learn_time_ms\": 8171.566, \"total_train_time_s\": 9.875114440917969}", "{\"n\": 6510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.11, \"learn_time_ms\": 8329.041, \"total_train_time_s\": 9.983440637588501}", "{\"n\": 6511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.28, \"learn_time_ms\": 8152.16, \"total_train_time_s\": 8.618886709213257}", "{\"n\": 6512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.28, \"learn_time_ms\": 8130.701, \"total_train_time_s\": 9.831001996994019}", "{\"n\": 6513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.41, \"learn_time_ms\": 8277.416, \"total_train_time_s\": 10.337430238723755}", "{\"n\": 6514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.41, \"learn_time_ms\": 8178.309, \"total_train_time_s\": 9.237196207046509}", "{\"n\": 6515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.93, \"learn_time_ms\": 8196.245, \"total_train_time_s\": 10.50644040107727}", "{\"n\": 6516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.2, \"learn_time_ms\": 8353.036, \"total_train_time_s\": 10.89267373085022}", "{\"n\": 6517, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.2, \"learn_time_ms\": 8317.426, \"total_train_time_s\": 9.251737117767334}", "{\"n\": 6518, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.15, \"learn_time_ms\": 8408.261, \"total_train_time_s\": 9.635077953338623}", "{\"n\": 6519, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.59, \"learn_time_ms\": 8516.3, \"total_train_time_s\": 10.968319416046143}", "{\"n\": 6520, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.59, \"learn_time_ms\": 8475.319, \"total_train_time_s\": 9.542821884155273}", "{\"n\": 6521, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.59, \"learn_time_ms\": 8468.696, \"total_train_time_s\": 8.55720567703247}", "{\"n\": 6522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 8340.793, \"total_train_time_s\": 8.518449783325195}", "{\"n\": 6523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 8254.197, \"total_train_time_s\": 9.37400197982788}", "{\"n\": 6524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 8453.204, \"total_train_time_s\": 11.19404935836792}", "{\"n\": 6525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.59, \"learn_time_ms\": 8466.467, \"total_train_time_s\": 10.653749942779541}", "{\"n\": 6526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.97, \"learn_time_ms\": 8241.118, \"total_train_time_s\": 8.650448083877563}", "{\"n\": 6527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.97, \"learn_time_ms\": 8400.573, \"total_train_time_s\": 10.79145097732544}", "{\"n\": 6528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.35, \"learn_time_ms\": 8426.508, \"total_train_time_s\": 9.931815147399902}", "{\"n\": 6529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.35, \"learn_time_ms\": 8384.12, \"total_train_time_s\": 10.51228141784668}", "{\"n\": 6530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.35, \"learn_time_ms\": 8271.601, \"total_train_time_s\": 8.360310554504395}", "{\"n\": 6531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.32, \"learn_time_ms\": 8476.305, \"total_train_time_s\": 10.617016553878784}", "{\"n\": 6532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.92, \"learn_time_ms\": 8711.144, \"total_train_time_s\": 10.916039943695068}", "{\"n\": 6533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.92, \"learn_time_ms\": 8725.55, \"total_train_time_s\": 9.558119297027588}", "{\"n\": 6534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.32, \"learn_time_ms\": 8682.466, \"total_train_time_s\": 10.754918813705444}", "{\"n\": 6535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.93, \"learn_time_ms\": 8532.704, \"total_train_time_s\": 9.10835576057434}", "{\"n\": 6536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.93, \"learn_time_ms\": 8826.727, \"total_train_time_s\": 11.59842300415039}", "{\"n\": 6537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.81, \"learn_time_ms\": 8708.425, \"total_train_time_s\": 9.70287537574768}", "{\"n\": 6538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.12, \"learn_time_ms\": 8730.419, \"total_train_time_s\": 10.203968048095703}", "{\"n\": 6539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.12, \"learn_time_ms\": 8649.358, \"total_train_time_s\": 9.743611812591553}", "{\"n\": 6540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.45, \"learn_time_ms\": 8800.47, \"total_train_time_s\": 9.996071338653564}", "{\"n\": 6541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.19, \"learn_time_ms\": 8834.633, \"total_train_time_s\": 11.002353429794312}", "{\"n\": 6542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.89, \"learn_time_ms\": 8671.629, \"total_train_time_s\": 9.36491060256958}", "{\"n\": 6543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.39, \"learn_time_ms\": 8561.672, \"total_train_time_s\": 8.457615375518799}", "{\"n\": 6544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.6, \"learn_time_ms\": 8349.598, \"total_train_time_s\": 8.640337705612183}", "{\"n\": 6545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.64, \"learn_time_ms\": 8615.807, \"total_train_time_s\": 11.821033477783203}", "{\"n\": 6546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.2, \"learn_time_ms\": 8684.756, \"total_train_time_s\": 12.269275903701782}", "{\"n\": 6547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.54, \"learn_time_ms\": 8753.48, \"total_train_time_s\": 10.375848531723022}", "{\"n\": 6548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.31, \"learn_time_ms\": 8493.47, \"total_train_time_s\": 7.509995460510254}", "{\"n\": 6549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.99, \"learn_time_ms\": 8491.563, \"total_train_time_s\": 9.719990730285645}", "{\"n\": 6550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.53, \"learn_time_ms\": 8585.825, \"total_train_time_s\": 10.855834722518921}", "{\"n\": 6551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.48, \"learn_time_ms\": 8608.716, \"total_train_time_s\": 11.205007314682007}", "{\"n\": 6552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.9, \"learn_time_ms\": 8537.291, \"total_train_time_s\": 8.573741674423218}", "{\"n\": 6553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.12, \"learn_time_ms\": 8552.904, \"total_train_time_s\": 8.724970579147339}", "{\"n\": 6554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.12, \"learn_time_ms\": 8683.897, \"total_train_time_s\": 9.96795654296875}", "{\"n\": 6555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.31, \"learn_time_ms\": 8655.921, \"total_train_time_s\": 11.569020748138428}", "{\"n\": 6556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.28, \"learn_time_ms\": 8443.599, \"total_train_time_s\": 10.179462909698486}", "{\"n\": 6557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.28, \"learn_time_ms\": 8493.776, \"total_train_time_s\": 10.802042484283447}", "{\"n\": 6558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.23, \"learn_time_ms\": 8892.332, \"total_train_time_s\": 11.534370422363281}", "{\"n\": 6559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.53, \"learn_time_ms\": 8976.007, \"total_train_time_s\": 10.553773403167725}", "{\"n\": 6560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.53, \"learn_time_ms\": 8788.392, \"total_train_time_s\": 8.989466667175293}", "{\"n\": 6561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.04, \"learn_time_ms\": 8685.509, \"total_train_time_s\": 10.19658613204956}", "{\"n\": 6562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.0, \"learn_time_ms\": 8710.569, \"total_train_time_s\": 8.829383850097656}", "{\"n\": 6563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.38, \"learn_time_ms\": 8908.447, \"total_train_time_s\": 10.582706928253174}", "{\"n\": 6564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.38, \"learn_time_ms\": 8970.24, \"total_train_time_s\": 10.58728814125061}", "{\"n\": 6565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.83, \"learn_time_ms\": 8785.261, \"total_train_time_s\": 9.6572585105896}", "{\"n\": 6566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.09, \"learn_time_ms\": 8763.138, \"total_train_time_s\": 9.964972019195557}", "{\"n\": 6567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.09, \"learn_time_ms\": 8625.859, \"total_train_time_s\": 9.479501247406006}", "{\"n\": 6568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.96, \"learn_time_ms\": 8470.154, \"total_train_time_s\": 9.963266372680664}", "{\"n\": 6569, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.18, \"learn_time_ms\": 8606.947, \"total_train_time_s\": 11.882976055145264}", "{\"n\": 6570, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.7, \"learn_time_ms\": 8830.608, \"total_train_time_s\": 11.195486783981323}", "{\"n\": 6571, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.83, \"learn_time_ms\": 8787.598, \"total_train_time_s\": 9.699350118637085}", "{\"n\": 6572, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.64, \"learn_time_ms\": 9027.326, \"total_train_time_s\": 11.201375246047974}", "{\"n\": 6573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.54, \"learn_time_ms\": 8866.409, \"total_train_time_s\": 9.00102686882019}", "{\"n\": 6574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.45, \"learn_time_ms\": 8820.91, \"total_train_time_s\": 10.1085844039917}", "{\"n\": 6575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.16, \"learn_time_ms\": 8853.094, \"total_train_time_s\": 9.957486629486084}", "{\"n\": 6576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.55, \"learn_time_ms\": 8755.184, \"total_train_time_s\": 8.982111930847168}", "{\"n\": 6577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.7, \"learn_time_ms\": 8960.235, \"total_train_time_s\": 11.57225775718689}", "{\"n\": 6578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.36, \"learn_time_ms\": 8976.435, \"total_train_time_s\": 10.141283750534058}", "{\"n\": 6579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.06, \"learn_time_ms\": 8789.42, \"total_train_time_s\": 10.071999311447144}", "{\"n\": 6580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.55, \"learn_time_ms\": 8608.299, \"total_train_time_s\": 9.421195268630981}", "{\"n\": 6581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.5, \"learn_time_ms\": 8550.326, \"total_train_time_s\": 9.149072885513306}", "{\"n\": 6582, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.27, \"learn_time_ms\": 8548.286, \"total_train_time_s\": 11.19752836227417}", "{\"n\": 6583, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.62, \"learn_time_ms\": 8609.159, \"total_train_time_s\": 9.616307020187378}", "{\"n\": 6584, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.46, \"learn_time_ms\": 8642.039, \"total_train_time_s\": 10.444005250930786}", "{\"n\": 6585, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.68, \"learn_time_ms\": 8674.25, \"total_train_time_s\": 10.319869756698608}", "{\"n\": 6586, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.68, \"learn_time_ms\": 8786.764, \"total_train_time_s\": 10.110926628112793}", "{\"n\": 6587, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.03, \"learn_time_ms\": 8759.07, \"total_train_time_s\": 11.271760940551758}", "{\"n\": 6588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.07, \"learn_time_ms\": 8658.104, \"total_train_time_s\": 9.115525960922241}", "{\"n\": 6589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.07, \"learn_time_ms\": 8649.58, \"total_train_time_s\": 9.950050115585327}", "{\"n\": 6590, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.59, \"learn_time_ms\": 8744.846, \"total_train_time_s\": 10.37618350982666}", "{\"n\": 6591, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.99, \"learn_time_ms\": 8858.859, \"total_train_time_s\": 10.303672790527344}", "{\"n\": 6592, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.04, \"learn_time_ms\": 8850.42, \"total_train_time_s\": 11.084641695022583}", "{\"n\": 6593, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.3, \"learn_time_ms\": 8902.933, \"total_train_time_s\": 10.109632730484009}", "{\"n\": 6594, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.5, \"learn_time_ms\": 8974.834, \"total_train_time_s\": 11.189631938934326}", "{\"n\": 6595, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.16, \"learn_time_ms\": 8941.622, \"total_train_time_s\": 10.01159143447876}", "{\"n\": 6596, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.59, \"learn_time_ms\": 8893.486, \"total_train_time_s\": 9.582155704498291}", "{\"n\": 6597, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.59, \"learn_time_ms\": 8810.858, \"total_train_time_s\": 10.427906036376953}", "{\"n\": 6598, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.69, \"learn_time_ms\": 9065.547, \"total_train_time_s\": 11.705411195755005}", "{\"n\": 6599, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.69, \"learn_time_ms\": 8989.632, \"total_train_time_s\": 9.210689544677734}", "{\"n\": 6600, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.91, \"learn_time_ms\": 8784.213, \"total_train_time_s\": 8.311407804489136}", "{\"n\": 6601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.96, \"learn_time_ms\": 8809.864, \"total_train_time_s\": 10.566413879394531}", "{\"n\": 6602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.96, \"learn_time_ms\": 8621.756, \"total_train_time_s\": 9.207309007644653}", "{\"n\": 6603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.37, \"learn_time_ms\": 8695.1, \"total_train_time_s\": 10.877913236618042}", "{\"n\": 6604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.37, \"learn_time_ms\": 8649.857, \"total_train_time_s\": 10.717512845993042}", "{\"n\": 6605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.6, \"learn_time_ms\": 8578.573, \"total_train_time_s\": 9.270621299743652}", "{\"n\": 6606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.62, \"learn_time_ms\": 8505.395, \"total_train_time_s\": 8.873234033584595}", "{\"n\": 6607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.62, \"learn_time_ms\": 8450.868, \"total_train_time_s\": 9.918227672576904}", "{\"n\": 6608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.3, \"learn_time_ms\": 8244.163, \"total_train_time_s\": 9.590158462524414}", "{\"n\": 6609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.24, \"learn_time_ms\": 8240.97, \"total_train_time_s\": 9.140424966812134}", "{\"n\": 6610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.24, \"learn_time_ms\": 8363.203, \"total_train_time_s\": 9.510053396224976}", "{\"n\": 6611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.75, \"learn_time_ms\": 8392.191, \"total_train_time_s\": 10.889461994171143}", "{\"n\": 6612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.32, \"learn_time_ms\": 8509.854, \"total_train_time_s\": 10.391814231872559}", "{\"n\": 6613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.21, \"learn_time_ms\": 8434.685, \"total_train_time_s\": 10.088205337524414}", "{\"n\": 6614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.21, \"learn_time_ms\": 8240.142, \"total_train_time_s\": 8.806457281112671}", "{\"n\": 6615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.0, \"learn_time_ms\": 8295.372, \"total_train_time_s\": 9.8778395652771}", "{\"n\": 6616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.39, \"learn_time_ms\": 8550.046, \"total_train_time_s\": 11.465535402297974}", "{\"n\": 6617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.39, \"learn_time_ms\": 8474.621, \"total_train_time_s\": 9.129833936691284}", "{\"n\": 6618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.61, \"learn_time_ms\": 8475.486, \"total_train_time_s\": 9.604698657989502}", "{\"n\": 6619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.42, \"learn_time_ms\": 8647.74, \"total_train_time_s\": 10.888298034667969}", "{\"n\": 6620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.42, \"learn_time_ms\": 8703.668, \"total_train_time_s\": 10.076940536499023}", "{\"n\": 6621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.03, \"learn_time_ms\": 8722.735, \"total_train_time_s\": 11.068434238433838}", "{\"n\": 6622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.25, \"learn_time_ms\": 8726.123, \"total_train_time_s\": 10.518924474716187}", "{\"n\": 6623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.25, \"learn_time_ms\": 8579.394, \"total_train_time_s\": 8.629395723342896}", "{\"n\": 6624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.25, \"learn_time_ms\": 8643.117, \"total_train_time_s\": 9.411069393157959}", "{\"n\": 6625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.03, \"learn_time_ms\": 8659.798, \"total_train_time_s\": 9.982978343963623}", "{\"n\": 6626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.44, \"learn_time_ms\": 8419.836, \"total_train_time_s\": 9.040629148483276}", "{\"n\": 6627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.44, \"learn_time_ms\": 8586.495, \"total_train_time_s\": 10.813621282577515}", "{\"n\": 6628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.08, \"learn_time_ms\": 8737.173, \"total_train_time_s\": 11.090948104858398}", "{\"n\": 6629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.29, \"learn_time_ms\": 8733.304, \"total_train_time_s\": 10.891156673431396}", "{\"n\": 6630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.29, \"learn_time_ms\": 8765.812, \"total_train_time_s\": 10.431658029556274}", "{\"n\": 6631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.48, \"learn_time_ms\": 8480.277, \"total_train_time_s\": 8.170607089996338}", "{\"n\": 6632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.31, \"learn_time_ms\": 8380.908, \"total_train_time_s\": 9.465465545654297}", "{\"n\": 6633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.31, \"learn_time_ms\": 8480.518, \"total_train_time_s\": 9.64368462562561}", "{\"n\": 6634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.61, \"learn_time_ms\": 8569.937, \"total_train_time_s\": 10.277759552001953}", "{\"n\": 6635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.43, \"learn_time_ms\": 8644.224, \"total_train_time_s\": 10.749171257019043}", "{\"n\": 6636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.91, \"learn_time_ms\": 8669.038, \"total_train_time_s\": 9.280029773712158}", "{\"n\": 6637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.09, \"learn_time_ms\": 8598.451, \"total_train_time_s\": 10.062231302261353}", "{\"n\": 6638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.68, \"learn_time_ms\": 8488.526, \"total_train_time_s\": 10.022623300552368}", "{\"n\": 6639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 8409.145, \"total_train_time_s\": 10.059130907058716}", "{\"n\": 6640, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 8243.6, \"total_train_time_s\": 8.772615432739258}", "{\"n\": 6641, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.79, \"learn_time_ms\": 8444.264, \"total_train_time_s\": 10.17135763168335}", "{\"n\": 6642, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.7, \"learn_time_ms\": 8540.003, \"total_train_time_s\": 10.363693475723267}", "{\"n\": 6643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.7, \"learn_time_ms\": 8547.977, \"total_train_time_s\": 9.695622205734253}", "{\"n\": 6644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.31, \"learn_time_ms\": 8463.892, \"total_train_time_s\": 9.51626968383789}", "{\"n\": 6645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.03, \"learn_time_ms\": 8313.492, \"total_train_time_s\": 9.195109605789185}", "{\"n\": 6646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.03, \"learn_time_ms\": 8436.283, \"total_train_time_s\": 10.498173236846924}", "{\"n\": 6647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.13, \"learn_time_ms\": 8408.737, \"total_train_time_s\": 9.815581798553467}", "{\"n\": 6648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.25, \"learn_time_ms\": 8432.919, \"total_train_time_s\": 10.274771451950073}", "{\"n\": 6649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.25, \"learn_time_ms\": 8461.83, \"total_train_time_s\": 10.310708045959473}", "{\"n\": 6650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.44, \"learn_time_ms\": 8584.092, \"total_train_time_s\": 9.950456142425537}", "{\"n\": 6651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 8700.83, \"total_train_time_s\": 11.36571717262268}", "{\"n\": 6652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.96, \"learn_time_ms\": 8633.966, \"total_train_time_s\": 9.761805295944214}", "{\"n\": 6653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.68, \"learn_time_ms\": 8629.785, \"total_train_time_s\": 9.638292789459229}", "{\"n\": 6654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.9, \"learn_time_ms\": 8656.414, \"total_train_time_s\": 9.753608226776123}", "{\"n\": 6655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.45, \"learn_time_ms\": 8852.246, \"total_train_time_s\": 11.218367576599121}", "{\"n\": 6656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.27, \"learn_time_ms\": 8791.523, \"total_train_time_s\": 9.839096784591675}", "{\"n\": 6657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.95, \"learn_time_ms\": 8682.677, \"total_train_time_s\": 8.720801830291748}", "{\"n\": 6658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.29, \"learn_time_ms\": 8715.502, \"total_train_time_s\": 10.585444688796997}", "{\"n\": 6659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.66, \"learn_time_ms\": 8739.694, \"total_train_time_s\": 10.560706615447998}", "{\"n\": 6660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.65, \"learn_time_ms\": 8760.901, \"total_train_time_s\": 10.217944383621216}", "{\"n\": 6661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.39, \"learn_time_ms\": 8512.336, \"total_train_time_s\": 8.84235954284668}", "{\"n\": 6662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.95, \"learn_time_ms\": 8687.472, \"total_train_time_s\": 11.483715772628784}", "{\"n\": 6663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.53, \"learn_time_ms\": 8787.496, \"total_train_time_s\": 10.67917537689209}", "{\"n\": 6664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.69, \"learn_time_ms\": 8852.875, \"total_train_time_s\": 10.43306851387024}", "{\"n\": 6665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.69, \"learn_time_ms\": 8757.353, \"total_train_time_s\": 10.224933862686157}", "{\"n\": 6666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.08, \"learn_time_ms\": 8657.365, \"total_train_time_s\": 8.879555702209473}", "{\"n\": 6667, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.81, \"learn_time_ms\": 8725.475, \"total_train_time_s\": 9.43705129623413}", "{\"n\": 6668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.81, \"learn_time_ms\": 8633.004, \"total_train_time_s\": 9.642068862915039}", "{\"n\": 6669, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.67, \"learn_time_ms\": 8510.615, \"total_train_time_s\": 9.341121435165405}", "{\"n\": 6670, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.35, \"learn_time_ms\": 8399.73, \"total_train_time_s\": 9.135119676589966}", "{\"n\": 6671, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.74, \"learn_time_ms\": 8442.415, \"total_train_time_s\": 9.318881750106812}", "{\"n\": 6672, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 8368.569, \"total_train_time_s\": 10.73538851737976}", "{\"n\": 6673, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.81, \"learn_time_ms\": 8491.636, \"total_train_time_s\": 11.900008201599121}", "{\"n\": 6674, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.15, \"learn_time_ms\": 8468.521, \"total_train_time_s\": 10.146440267562866}", "{\"n\": 6675, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.15, \"learn_time_ms\": 8427.292, \"total_train_time_s\": 9.81836748123169}", "{\"n\": 6676, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.09, \"learn_time_ms\": 8571.564, \"total_train_time_s\": 10.32583236694336}", "{\"n\": 6677, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.34, \"learn_time_ms\": 8502.798, \"total_train_time_s\": 8.709671974182129}", "{\"n\": 6678, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.34, \"learn_time_ms\": 8594.182, \"total_train_time_s\": 10.577768802642822}", "{\"n\": 6679, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.66, \"learn_time_ms\": 8760.693, \"total_train_time_s\": 11.027772188186646}", "{\"n\": 6680, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.26, \"learn_time_ms\": 8837.637, \"total_train_time_s\": 9.869723558425903}", "{\"n\": 6681, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.81, \"learn_time_ms\": 8765.854, \"total_train_time_s\": 8.593260288238525}", "{\"n\": 6682, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.9, \"learn_time_ms\": 8757.711, \"total_train_time_s\": 10.695254802703857}", "{\"n\": 6683, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.75, \"learn_time_ms\": 8636.062, \"total_train_time_s\": 10.705479860305786}", "{\"n\": 6684, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.42, \"learn_time_ms\": 8627.913, \"total_train_time_s\": 10.097855806350708}", "{\"n\": 6685, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.42, \"learn_time_ms\": 8759.887, \"total_train_time_s\": 11.136930227279663}", "{\"n\": 6686, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.87, \"learn_time_ms\": 8577.082, \"total_train_time_s\": 8.474833011627197}", "{\"n\": 6687, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.67, \"learn_time_ms\": 8571.25, \"total_train_time_s\": 8.649818897247314}", "{\"n\": 6688, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.06, \"learn_time_ms\": 8443.395, \"total_train_time_s\": 9.297289371490479}", "{\"n\": 6689, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.06, \"learn_time_ms\": 8070.324, \"total_train_time_s\": 7.2754082679748535}", "{\"n\": 6690, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.4, \"learn_time_ms\": 7965.29, \"total_train_time_s\": 8.806366920471191}", "{\"n\": 6691, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.65, \"learn_time_ms\": 8198.739, \"total_train_time_s\": 10.880083084106445}", "{\"n\": 6692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.26, \"learn_time_ms\": 8074.033, \"total_train_time_s\": 9.362202405929565}", "{\"n\": 6693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.9, \"learn_time_ms\": 7812.104, \"total_train_time_s\": 8.061771392822266}", "{\"n\": 6694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.18, \"learn_time_ms\": 7740.397, \"total_train_time_s\": 9.33344054222107}", "{\"n\": 6695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.02, \"learn_time_ms\": 7508.593, \"total_train_time_s\": 8.875152587890625}", "{\"n\": 6696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.1, \"learn_time_ms\": 7683.672, \"total_train_time_s\": 10.265625715255737}", "{\"n\": 6697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.95, \"learn_time_ms\": 7891.936, \"total_train_time_s\": 10.738382577896118}", "{\"n\": 6698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.09, \"learn_time_ms\": 7842.639, \"total_train_time_s\": 8.825193881988525}", "{\"n\": 6699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.16, \"learn_time_ms\": 8161.357, \"total_train_time_s\": 10.441402196884155}", "{\"n\": 6700, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.53, \"learn_time_ms\": 8186.558, \"total_train_time_s\": 9.066847085952759}", "{\"n\": 6701, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.28, \"learn_time_ms\": 7992.073, \"total_train_time_s\": 8.950554370880127}", "{\"n\": 6702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.22, \"learn_time_ms\": 8048.847, \"total_train_time_s\": 9.98720932006836}", "{\"n\": 6703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.22, \"learn_time_ms\": 8266.163, \"total_train_time_s\": 10.208831787109375}", "{\"n\": 6704, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.06, \"learn_time_ms\": 8274.769, \"total_train_time_s\": 9.454420566558838}", "{\"n\": 6705, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.9, \"learn_time_ms\": 8377.589, \"total_train_time_s\": 9.829530715942383}", "{\"n\": 6706, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.52, \"learn_time_ms\": 8371.241, \"total_train_time_s\": 10.200884342193604}", "{\"n\": 6707, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.74, \"learn_time_ms\": 8307.063, \"total_train_time_s\": 10.111791372299194}", "{\"n\": 6708, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.74, \"learn_time_ms\": 8362.943, \"total_train_time_s\": 9.333269357681274}", "{\"n\": 6709, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.29, \"learn_time_ms\": 8321.11, \"total_train_time_s\": 10.074271202087402}", "{\"n\": 6710, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.52, \"learn_time_ms\": 8397.913, \"total_train_time_s\": 9.840012550354004}", "{\"n\": 6711, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.52, \"learn_time_ms\": 8446.556, \"total_train_time_s\": 9.440283060073853}", "{\"n\": 6712, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.12, \"learn_time_ms\": 8403.198, \"total_train_time_s\": 9.515106201171875}", "{\"n\": 6713, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.83, \"learn_time_ms\": 8344.68, \"total_train_time_s\": 9.65295124053955}", "{\"n\": 6714, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.97, \"learn_time_ms\": 8283.396, \"total_train_time_s\": 8.873527526855469}", "{\"n\": 6715, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.1, \"learn_time_ms\": 8270.765, \"total_train_time_s\": 9.725207805633545}", "{\"n\": 6716, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.08, \"learn_time_ms\": 8438.491, \"total_train_time_s\": 11.899364948272705}", "{\"n\": 6717, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.76, \"learn_time_ms\": 8353.149, \"total_train_time_s\": 9.267744541168213}", "{\"n\": 6718, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.5, \"learn_time_ms\": 8388.153, \"total_train_time_s\": 9.682434797286987}", "{\"n\": 6719, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.82, \"learn_time_ms\": 8335.002, \"total_train_time_s\": 9.535151481628418}", "{\"n\": 6720, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.26, \"learn_time_ms\": 8250.116, \"total_train_time_s\": 9.015395164489746}", "{\"n\": 6721, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.65, \"learn_time_ms\": 8319.293, \"total_train_time_s\": 10.17562460899353}", "{\"n\": 6722, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.91, \"learn_time_ms\": 8383.173, \"total_train_time_s\": 10.220502376556396}", "{\"n\": 6723, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.31, \"learn_time_ms\": 8436.084, \"total_train_time_s\": 10.209629774093628}", "{\"n\": 6724, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.09, \"learn_time_ms\": 8691.386, \"total_train_time_s\": 11.413529634475708}", "{\"n\": 6725, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.75, \"learn_time_ms\": 8668.169, \"total_train_time_s\": 9.497718095779419}", "{\"n\": 6726, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.03, \"learn_time_ms\": 8630.841, \"total_train_time_s\": 11.49549674987793}", "{\"n\": 6727, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.72, \"learn_time_ms\": 8663.574, \"total_train_time_s\": 9.617303371429443}", "{\"n\": 6728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.06, \"learn_time_ms\": 8665.113, \"total_train_time_s\": 9.801476001739502}", "{\"n\": 6729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.28, \"learn_time_ms\": 8723.75, \"total_train_time_s\": 10.172306299209595}", "{\"n\": 6730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.28, \"learn_time_ms\": 8834.366, \"total_train_time_s\": 10.077457427978516}", "{\"n\": 6731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.03, \"learn_time_ms\": 8896.944, \"total_train_time_s\": 10.781449794769287}", "{\"n\": 6732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.01, \"learn_time_ms\": 8804.942, \"total_train_time_s\": 9.324125051498413}", "{\"n\": 6733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.35, \"learn_time_ms\": 8716.182, \"total_train_time_s\": 9.27102518081665}", "{\"n\": 6734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.35, \"learn_time_ms\": 8614.337, \"total_train_time_s\": 10.33075737953186}", "{\"n\": 6735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.14, \"learn_time_ms\": 8595.668, \"total_train_time_s\": 9.33591341972351}", "{\"n\": 6736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.17, \"learn_time_ms\": 8448.093, \"total_train_time_s\": 9.992779016494751}", "{\"n\": 6737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.25, \"learn_time_ms\": 8431.367, \"total_train_time_s\": 9.40682053565979}", "{\"n\": 6738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.29, \"learn_time_ms\": 8435.373, \"total_train_time_s\": 9.762796878814697}", "{\"n\": 6739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.4, \"learn_time_ms\": 8502.554, \"total_train_time_s\": 10.792900085449219}", "{\"n\": 6740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.16, \"learn_time_ms\": 8502.078, \"total_train_time_s\": 10.07270359992981}", "{\"n\": 6741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.05, \"learn_time_ms\": 8441.613, \"total_train_time_s\": 10.197372436523438}", "{\"n\": 6742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.05, \"learn_time_ms\": 8491.03, \"total_train_time_s\": 9.763742446899414}", "{\"n\": 6743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.14, \"learn_time_ms\": 8534.022, \"total_train_time_s\": 9.729204177856445}", "{\"n\": 6744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.53, \"learn_time_ms\": 8459.383, \"total_train_time_s\": 9.622594833374023}", "{\"n\": 6745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.53, \"learn_time_ms\": 8508.613, \"total_train_time_s\": 9.814335584640503}", "{\"n\": 6746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.87, \"learn_time_ms\": 8521.16, \"total_train_time_s\": 10.109492540359497}", "{\"n\": 6747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.18, \"learn_time_ms\": 8647.98, \"total_train_time_s\": 10.639324426651001}", "{\"n\": 6748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.18, \"learn_time_ms\": 8666.736, \"total_train_time_s\": 9.934815406799316}", "{\"n\": 6749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.17, \"learn_time_ms\": 8514.764, \"total_train_time_s\": 9.300210237503052}", "{\"n\": 6750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.91, \"learn_time_ms\": 8458.523, \"total_train_time_s\": 9.53413200378418}", "{\"n\": 6751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.2, \"learn_time_ms\": 8536.87, \"total_train_time_s\": 10.93746566772461}", "{\"n\": 6752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.2, \"learn_time_ms\": 8554.365, \"total_train_time_s\": 9.92245602607727}", "{\"n\": 6753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.6, \"learn_time_ms\": 8644.276, \"total_train_time_s\": 10.658826112747192}", "{\"n\": 6754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.93, \"learn_time_ms\": 8589.357, \"total_train_time_s\": 9.096789360046387}", "{\"n\": 6755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.93, \"learn_time_ms\": 8593.696, \"total_train_time_s\": 9.851161241531372}", "{\"n\": 6756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.96, \"learn_time_ms\": 8615.173, \"total_train_time_s\": 10.409648656845093}", "{\"n\": 6757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.72, \"learn_time_ms\": 8565.787, \"total_train_time_s\": 10.215391397476196}", "{\"n\": 6758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.72, \"learn_time_ms\": 8527.175, \"total_train_time_s\": 9.552533388137817}", "{\"n\": 6759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.49, \"learn_time_ms\": 8661.653, \"total_train_time_s\": 10.595347166061401}", "{\"n\": 6760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.76, \"learn_time_ms\": 8660.206, \"total_train_time_s\": 9.501456499099731}", "{\"n\": 6761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.76, \"learn_time_ms\": 8632.589, \"total_train_time_s\": 10.654688835144043}", "{\"n\": 6762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.63, \"learn_time_ms\": 8766.19, \"total_train_time_s\": 11.29784107208252}", "{\"n\": 6763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.51, \"learn_time_ms\": 8592.022, \"total_train_time_s\": 8.869654417037964}", "{\"n\": 6764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.51, \"learn_time_ms\": 8781.027, \"total_train_time_s\": 10.965097188949585}", "{\"n\": 6765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.08, \"learn_time_ms\": 8717.212, \"total_train_time_s\": 9.244804620742798}", "{\"n\": 6766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.63, \"learn_time_ms\": 8720.234, \"total_train_time_s\": 10.386482954025269}", "{\"n\": 6767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.25, \"learn_time_ms\": 8816.817, \"total_train_time_s\": 11.121711492538452}", "{\"n\": 6768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.03, \"learn_time_ms\": 8803.492, \"total_train_time_s\": 9.431191205978394}", "{\"n\": 6769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.75, \"learn_time_ms\": 8742.463, \"total_train_time_s\": 10.008960008621216}", "{\"n\": 6770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.16, \"learn_time_ms\": 8667.224, \"total_train_time_s\": 8.760653495788574}", "{\"n\": 6771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.73, \"learn_time_ms\": 8503.172, \"total_train_time_s\": 9.0004301071167}", "{\"n\": 6772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.76, \"learn_time_ms\": 8438.995, \"total_train_time_s\": 10.587327718734741}", "{\"n\": 6773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.84, \"learn_time_ms\": 8555.939, \"total_train_time_s\": 10.030151128768921}", "{\"n\": 6774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.04, \"learn_time_ms\": 8542.521, \"total_train_time_s\": 10.824392080307007}", "{\"n\": 6775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.36, \"learn_time_ms\": 8671.004, \"total_train_time_s\": 10.490003108978271}", "{\"n\": 6776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.94, \"learn_time_ms\": 8594.502, \"total_train_time_s\": 9.68333888053894}", "{\"n\": 6777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.46, \"learn_time_ms\": 8473.645, \"total_train_time_s\": 9.928762197494507}", "{\"n\": 6778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.91, \"learn_time_ms\": 8396.736, \"total_train_time_s\": 8.666428804397583}", "{\"n\": 6779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.91, \"learn_time_ms\": 8366.215, \"total_train_time_s\": 9.711695909500122}", "{\"n\": 6780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.51, \"learn_time_ms\": 8476.27, \"total_train_time_s\": 9.84162950515747}", "{\"n\": 6781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.13, \"learn_time_ms\": 8468.032, \"total_train_time_s\": 8.96227765083313}", "{\"n\": 6782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.13, \"learn_time_ms\": 8424.284, \"total_train_time_s\": 10.183960437774658}", "{\"n\": 6783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.76, \"learn_time_ms\": 8452.539, \"total_train_time_s\": 10.287878274917603}", "{\"n\": 6784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.43, \"learn_time_ms\": 8294.635, \"total_train_time_s\": 9.242716312408447}", "{\"n\": 6785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.97, \"learn_time_ms\": 8359.947, \"total_train_time_s\": 11.150660514831543}", "{\"n\": 6786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.97, \"learn_time_ms\": 8407.282, \"total_train_time_s\": 10.11781620979309}", "{\"n\": 6787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.17, \"learn_time_ms\": 8420.941, \"total_train_time_s\": 10.040087699890137}", "{\"n\": 6788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.4, \"learn_time_ms\": 8653.791, \"total_train_time_s\": 11.016825675964355}", "{\"n\": 6789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.4, \"learn_time_ms\": 8955.0, \"total_train_time_s\": 12.679609537124634}", "{\"n\": 6790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.69, \"learn_time_ms\": 8892.618, \"total_train_time_s\": 9.261165618896484}", "{\"n\": 6791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.15, \"learn_time_ms\": 8989.613, \"total_train_time_s\": 9.922898054122925}", "{\"n\": 6792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.15, \"learn_time_ms\": 8856.311, \"total_train_time_s\": 8.8565034866333}", "{\"n\": 6793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.11, \"learn_time_ms\": 8813.261, \"total_train_time_s\": 9.926676750183105}", "{\"n\": 6794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.11, \"learn_time_ms\": 8949.418, \"total_train_time_s\": 10.594594717025757}", "{\"n\": 6795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.02, \"learn_time_ms\": 8842.694, \"total_train_time_s\": 10.0946786403656}", "{\"n\": 6796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.66, \"learn_time_ms\": 8892.753, \"total_train_time_s\": 10.614876508712769}", "{\"n\": 6797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.58, \"learn_time_ms\": 8913.966, \"total_train_time_s\": 10.321110010147095}", "{\"n\": 6798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.36, \"learn_time_ms\": 8743.645, \"total_train_time_s\": 9.276512861251831}", "{\"n\": 6799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.69, \"learn_time_ms\": 8356.275, \"total_train_time_s\": 8.85089898109436}", "{\"n\": 6800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.26, \"learn_time_ms\": 8464.91, \"total_train_time_s\": 10.35261583328247}", "{\"n\": 6801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.27, \"learn_time_ms\": 8527.473, \"total_train_time_s\": 10.555981874465942}", "{\"n\": 6802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.27, \"learn_time_ms\": 8600.827, \"total_train_time_s\": 9.620487689971924}", "{\"n\": 6803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.41, \"learn_time_ms\": 8730.889, \"total_train_time_s\": 11.221794128417969}", "{\"n\": 6804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.41, \"learn_time_ms\": 8720.782, \"total_train_time_s\": 10.507984161376953}", "{\"n\": 6805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.4, \"learn_time_ms\": 8682.645, \"total_train_time_s\": 9.7186861038208}", "{\"n\": 6806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.65, \"learn_time_ms\": 8521.499, \"total_train_time_s\": 8.946979761123657}", "{\"n\": 6807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.32, \"learn_time_ms\": 8494.704, \"total_train_time_s\": 10.008654594421387}", "{\"n\": 6808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.38, \"learn_time_ms\": 8558.537, \"total_train_time_s\": 9.931570053100586}", "{\"n\": 6809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.38, \"learn_time_ms\": 8762.972, \"total_train_time_s\": 10.864903926849365}", "{\"n\": 6810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.95, \"learn_time_ms\": 8747.672, \"total_train_time_s\": 10.177015781402588}", "{\"n\": 6811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.95, \"learn_time_ms\": 8874.529, \"total_train_time_s\": 11.800129652023315}", "{\"n\": 6812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.42, \"learn_time_ms\": 8700.673, \"total_train_time_s\": 7.831198692321777}", "{\"n\": 6813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.24, \"learn_time_ms\": 8517.738, \"total_train_time_s\": 9.39911437034607}", "{\"n\": 6814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.24, \"learn_time_ms\": 8499.009, \"total_train_time_s\": 10.322545051574707}", "{\"n\": 6815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.2, \"learn_time_ms\": 8610.45, \"total_train_time_s\": 10.819687604904175}", "{\"n\": 6816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.2, \"learn_time_ms\": 8651.245, \"total_train_time_s\": 9.412270784378052}", "{\"n\": 6817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3263.11, \"learn_time_ms\": 8576.539, \"total_train_time_s\": 9.33405327796936}", "{\"n\": 6818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3263.11, \"learn_time_ms\": 8541.918, \"total_train_time_s\": 9.559961795806885}", "{\"n\": 6819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.2, \"learn_time_ms\": 8404.561, \"total_train_time_s\": 9.511821508407593}", "{\"n\": 6820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.98, \"learn_time_ms\": 8225.359, \"total_train_time_s\": 8.40225076675415}", "{\"n\": 6821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.98, \"learn_time_ms\": 7988.786, \"total_train_time_s\": 9.453986167907715}", "{\"n\": 6822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.9, \"learn_time_ms\": 8228.708, \"total_train_time_s\": 10.250986576080322}", "{\"n\": 6823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.27, \"learn_time_ms\": 8110.378, \"total_train_time_s\": 8.20642900466919}", "{\"n\": 6824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.99, \"learn_time_ms\": 8020.553, \"total_train_time_s\": 9.441140174865723}", "{\"n\": 6825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.92, \"learn_time_ms\": 7945.679, \"total_train_time_s\": 10.134245872497559}", "{\"n\": 6826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.63, \"learn_time_ms\": 8124.393, \"total_train_time_s\": 11.218765497207642}", "{\"n\": 6827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3289.34, \"learn_time_ms\": 8213.274, \"total_train_time_s\": 10.16262149810791}", "{\"n\": 6828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.82, \"learn_time_ms\": 8264.735, \"total_train_time_s\": 10.137946605682373}", "{\"n\": 6829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.82, \"learn_time_ms\": 8368.135, \"total_train_time_s\": 10.53789472579956}", "{\"n\": 6830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.6, \"learn_time_ms\": 8519.923, \"total_train_time_s\": 9.870701789855957}", "{\"n\": 6831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 8619.938, \"total_train_time_s\": 10.442205667495728}", "{\"n\": 6832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 8589.767, \"total_train_time_s\": 9.94945240020752}", "{\"n\": 6833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.16, \"learn_time_ms\": 8724.204, \"total_train_time_s\": 9.55296540260315}", "{\"n\": 6834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.65, \"learn_time_ms\": 8681.066, \"total_train_time_s\": 8.97721552848816}", "{\"n\": 6835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.77, \"learn_time_ms\": 8574.849, \"total_train_time_s\": 9.007137537002563}", "{\"n\": 6836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.47, \"learn_time_ms\": 8377.647, \"total_train_time_s\": 9.202584505081177}", "{\"n\": 6837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.23, \"learn_time_ms\": 8372.718, \"total_train_time_s\": 10.122130393981934}", "{\"n\": 6838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.23, \"learn_time_ms\": 8406.756, \"total_train_time_s\": 10.407875299453735}", "{\"n\": 6839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.74, \"learn_time_ms\": 8291.718, \"total_train_time_s\": 9.407726049423218}", "{\"n\": 6840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.01, \"learn_time_ms\": 8291.64, \"total_train_time_s\": 9.891513109207153}", "{\"n\": 6841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.42, \"learn_time_ms\": 8372.963, \"total_train_time_s\": 11.254517793655396}", "{\"n\": 6842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.14, \"learn_time_ms\": 8457.6, \"total_train_time_s\": 10.81362009048462}", "{\"n\": 6843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.3, \"learn_time_ms\": 8417.408, \"total_train_time_s\": 9.13568377494812}", "{\"n\": 6844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.65, \"learn_time_ms\": 8501.792, \"total_train_time_s\": 9.858939409255981}", "{\"n\": 6845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.02, \"learn_time_ms\": 8491.713, \"total_train_time_s\": 8.905166625976562}", "{\"n\": 6846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.64, \"learn_time_ms\": 8593.885, \"total_train_time_s\": 10.244009733200073}", "{\"n\": 6847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.83, \"learn_time_ms\": 8693.79, \"total_train_time_s\": 11.161264896392822}", "{\"n\": 6848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.05, \"learn_time_ms\": 8591.558, \"total_train_time_s\": 9.452744960784912}", "{\"n\": 6849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.47, \"learn_time_ms\": 8650.263, \"total_train_time_s\": 9.959993362426758}", "{\"n\": 6850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.86, \"learn_time_ms\": 8473.247, \"total_train_time_s\": 8.137399673461914}", "{\"n\": 6851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.8, \"learn_time_ms\": 8467.811, \"total_train_time_s\": 11.207891941070557}", "{\"n\": 6852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.41, \"learn_time_ms\": 8442.231, \"total_train_time_s\": 10.513593673706055}", "{\"n\": 6853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.74, \"learn_time_ms\": 8518.684, \"total_train_time_s\": 9.887197017669678}", "{\"n\": 6854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.44, \"learn_time_ms\": 8414.478, \"total_train_time_s\": 8.807201147079468}", "{\"n\": 6855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.73, \"learn_time_ms\": 8442.006, \"total_train_time_s\": 9.17762565612793}", "{\"n\": 6856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.88, \"learn_time_ms\": 8398.678, \"total_train_time_s\": 9.782618761062622}", "{\"n\": 6857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.51, \"learn_time_ms\": 8384.221, \"total_train_time_s\": 10.958120107650757}", "{\"n\": 6858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.26, \"learn_time_ms\": 8500.185, \"total_train_time_s\": 10.561519145965576}", "{\"n\": 6859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.61, \"learn_time_ms\": 8370.905, \"total_train_time_s\": 8.706958293914795}", "{\"n\": 6860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.77, \"learn_time_ms\": 8468.552, \"total_train_time_s\": 9.07006311416626}", "{\"n\": 6861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.41, \"learn_time_ms\": 8350.126, \"total_train_time_s\": 10.026952266693115}", "{\"n\": 6862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.59, \"learn_time_ms\": 8119.819, \"total_train_time_s\": 8.279037475585938}", "{\"n\": 6863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.42, \"learn_time_ms\": 8198.528, \"total_train_time_s\": 10.702857255935669}", "{\"n\": 6864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 8475.117, \"total_train_time_s\": 11.540043354034424}", "{\"n\": 6865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 8459.154, \"total_train_time_s\": 8.998280048370361}", "{\"n\": 6866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.88, \"learn_time_ms\": 8432.776, \"total_train_time_s\": 9.556448459625244}", "{\"n\": 6867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 8299.29, \"total_train_time_s\": 9.601970195770264}", "{\"n\": 6868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 8245.53, \"total_train_time_s\": 10.028725147247314}", "{\"n\": 6869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.16, \"learn_time_ms\": 8384.21, \"total_train_time_s\": 10.074406623840332}", "{\"n\": 6870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.88, \"learn_time_ms\": 8475.687, \"total_train_time_s\": 10.028702735900879}", "{\"n\": 6871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.53, \"learn_time_ms\": 8339.239, \"total_train_time_s\": 8.657836675643921}", "{\"n\": 6872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.2, \"learn_time_ms\": 8484.255, \"total_train_time_s\": 9.72249436378479}", "{\"n\": 6873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.89, \"learn_time_ms\": 8628.309, \"total_train_time_s\": 12.165612936019897}", "{\"n\": 6874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.59, \"learn_time_ms\": 8463.657, \"total_train_time_s\": 9.937188863754272}", "{\"n\": 6875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.14, \"learn_time_ms\": 8521.211, \"total_train_time_s\": 9.622544765472412}", "{\"n\": 6876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.64, \"learn_time_ms\": 8552.622, \"total_train_time_s\": 9.828932046890259}", "{\"n\": 6877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.26, \"learn_time_ms\": 8592.912, \"total_train_time_s\": 10.028574228286743}", "{\"n\": 6878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.56, \"learn_time_ms\": 8694.046, \"total_train_time_s\": 11.053733825683594}", "{\"n\": 6879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.13, \"learn_time_ms\": 8580.988, \"total_train_time_s\": 8.891783237457275}", "{\"n\": 6880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.57, \"learn_time_ms\": 8547.234, \"total_train_time_s\": 9.67681336402893}", "{\"n\": 6881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.03, \"learn_time_ms\": 8672.514, \"total_train_time_s\": 9.888277530670166}", "{\"n\": 6882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.51, \"learn_time_ms\": 8789.753, \"total_train_time_s\": 10.879784345626831}", "{\"n\": 6883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 8604.065, \"total_train_time_s\": 10.321164608001709}", "{\"n\": 6884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.69, \"learn_time_ms\": 8739.951, \"total_train_time_s\": 11.264516353607178}", "{\"n\": 6885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.69, \"learn_time_ms\": 8767.104, \"total_train_time_s\": 9.860047101974487}", "{\"n\": 6886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.37, \"learn_time_ms\": 8877.701, \"total_train_time_s\": 10.93681263923645}", "{\"n\": 6887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.15, \"learn_time_ms\": 8811.999, \"total_train_time_s\": 9.351948499679565}", "{\"n\": 6888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.15, \"learn_time_ms\": 8597.077, \"total_train_time_s\": 8.907222747802734}", "{\"n\": 6889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.82, \"learn_time_ms\": 8599.356, \"total_train_time_s\": 8.978821277618408}", "{\"n\": 6890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.82, \"learn_time_ms\": 8633.592, \"total_train_time_s\": 10.053941488265991}", "{\"n\": 6891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.08, \"learn_time_ms\": 8608.722, \"total_train_time_s\": 9.714246034622192}", "{\"n\": 6892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.9, \"learn_time_ms\": 8727.424, \"total_train_time_s\": 12.01557183265686}", "{\"n\": 6893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.76, \"learn_time_ms\": 8795.447, \"total_train_time_s\": 10.985828876495361}", "{\"n\": 6894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.31, \"learn_time_ms\": 8640.566, \"total_train_time_s\": 9.762034177780151}", "{\"n\": 6895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.31, \"learn_time_ms\": 8588.304, \"total_train_time_s\": 9.34675669670105}", "{\"n\": 6896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.96, \"learn_time_ms\": 8751.004, \"total_train_time_s\": 12.613386869430542}", "{\"n\": 6897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.96, \"learn_time_ms\": 8796.751, \"total_train_time_s\": 9.91526746749878}", "{\"n\": 6898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.72, \"learn_time_ms\": 8886.609, \"total_train_time_s\": 9.811773777008057}", "{\"n\": 6899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.86, \"learn_time_ms\": 9158.209, \"total_train_time_s\": 11.688640832901001}", "{\"n\": 6900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.86, \"learn_time_ms\": 9172.562, \"total_train_time_s\": 10.141234874725342}", "{\"n\": 6901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.84, \"learn_time_ms\": 9128.627, \"total_train_time_s\": 9.229681253433228}", "{\"n\": 6902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.65, \"learn_time_ms\": 8851.836, \"total_train_time_s\": 9.32323431968689}", "{\"n\": 6903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.65, \"learn_time_ms\": 8719.6, \"total_train_time_s\": 9.605610370635986}", "{\"n\": 6904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.43, \"learn_time_ms\": 8783.178, \"total_train_time_s\": 10.377380132675171}", "{\"n\": 6905, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 8834.181, \"total_train_time_s\": 9.855627298355103}", "{\"n\": 6906, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 8660.215, \"total_train_time_s\": 10.813844680786133}", "{\"n\": 6907, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.14, \"learn_time_ms\": 8852.422, \"total_train_time_s\": 11.759722232818604}", "{\"n\": 6908, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.42, \"learn_time_ms\": 9056.813, \"total_train_time_s\": 11.780132293701172}", "{\"n\": 6909, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.87, \"learn_time_ms\": 8818.652, \"total_train_time_s\": 9.32779836654663}", "{\"n\": 6910, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.72, \"learn_time_ms\": 8900.715, \"total_train_time_s\": 10.990596294403076}", "{\"n\": 6911, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.72, \"learn_time_ms\": 8843.434, \"total_train_time_s\": 8.658558130264282}", "{\"n\": 6912, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.78, \"learn_time_ms\": 8979.572, \"total_train_time_s\": 10.687670469284058}", "{\"n\": 6913, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.64, \"learn_time_ms\": 9124.648, \"total_train_time_s\": 11.082668542861938}", "{\"n\": 6914, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.22, \"learn_time_ms\": 9063.678, \"total_train_time_s\": 9.763255596160889}", "{\"n\": 6915, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.13, \"learn_time_ms\": 9025.062, \"total_train_time_s\": 9.476942539215088}", "{\"n\": 6916, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.54, \"learn_time_ms\": 8836.876, \"total_train_time_s\": 8.963035106658936}", "{\"n\": 6917, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.54, \"learn_time_ms\": 8696.153, \"total_train_time_s\": 10.334717750549316}", "{\"n\": 6918, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.21, \"learn_time_ms\": 8537.029, \"total_train_time_s\": 10.225070476531982}", "{\"n\": 6919, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.21, \"learn_time_ms\": 8766.285, \"total_train_time_s\": 11.577095746994019}", "{\"n\": 6920, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.32, \"learn_time_ms\": 8649.785, \"total_train_time_s\": 9.834312915802002}", "{\"n\": 6921, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.18, \"learn_time_ms\": 8790.519, \"total_train_time_s\": 10.04693341255188}", "{\"n\": 6922, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.18, \"learn_time_ms\": 8820.142, \"total_train_time_s\": 10.909647464752197}", "{\"n\": 6923, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.8, \"learn_time_ms\": 8725.786, \"total_train_time_s\": 10.142208337783813}", "{\"n\": 6924, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.71, \"learn_time_ms\": 8745.786, \"total_train_time_s\": 9.975713968276978}", "{\"n\": 6925, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.71, \"learn_time_ms\": 8869.312, \"total_train_time_s\": 10.676825761795044}", "{\"n\": 6926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.48, \"learn_time_ms\": 9044.292, \"total_train_time_s\": 10.697968006134033}", "{\"n\": 6927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.28, \"learn_time_ms\": 9063.202, \"total_train_time_s\": 10.530216932296753}", "{\"n\": 6928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.35, \"learn_time_ms\": 9107.875, \"total_train_time_s\": 10.658835172653198}", "{\"n\": 6929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.99, \"learn_time_ms\": 8948.131, \"total_train_time_s\": 9.987661361694336}", "{\"n\": 6930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.27, \"learn_time_ms\": 8813.823, \"total_train_time_s\": 8.451319932937622}", "{\"n\": 6931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.47, \"learn_time_ms\": 8804.7, \"total_train_time_s\": 9.985369205474854}", "{\"n\": 6932, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.47, \"learn_time_ms\": 8704.179, \"total_train_time_s\": 9.958791971206665}", "{\"n\": 6933, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.02, \"learn_time_ms\": 8664.66, \"total_train_time_s\": 9.745621681213379}", "{\"n\": 6934, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.29, \"learn_time_ms\": 8721.008, \"total_train_time_s\": 10.55664610862732}", "{\"n\": 6935, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.29, \"learn_time_ms\": 8604.008, \"total_train_time_s\": 9.47877049446106}", "{\"n\": 6936, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.26, \"learn_time_ms\": 8508.422, \"total_train_time_s\": 9.754105806350708}", "{\"n\": 6937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.53, \"learn_time_ms\": 8526.231, \"total_train_time_s\": 10.674927711486816}", "{\"n\": 6938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.53, \"learn_time_ms\": 8517.121, \"total_train_time_s\": 10.601080656051636}", "{\"n\": 6939, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.92, \"learn_time_ms\": 8458.359, \"total_train_time_s\": 9.410881519317627}", "{\"n\": 6940, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.02, \"learn_time_ms\": 8636.358, \"total_train_time_s\": 10.25545620918274}", "{\"n\": 6941, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.2, \"learn_time_ms\": 8630.194, \"total_train_time_s\": 9.958038806915283}", "{\"n\": 6942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.29, \"learn_time_ms\": 8666.063, \"total_train_time_s\": 10.259937524795532}", "{\"n\": 6943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.49, \"learn_time_ms\": 8657.267, \"total_train_time_s\": 9.673542499542236}", "{\"n\": 6944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.9, \"learn_time_ms\": 8571.042, \"total_train_time_s\": 9.668064594268799}", "{\"n\": 6945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.9, \"learn_time_ms\": 8695.043, \"total_train_time_s\": 10.761442422866821}", "{\"n\": 6946, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.25, \"learn_time_ms\": 8713.06, \"total_train_time_s\": 9.963021039962769}", "{\"n\": 6947, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.21, \"learn_time_ms\": 8717.466, \"total_train_time_s\": 10.788372039794922}", "{\"n\": 6948, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.14, \"learn_time_ms\": 8613.726, \"total_train_time_s\": 9.54584550857544}", "{\"n\": 6949, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.94, \"learn_time_ms\": 8590.007, \"total_train_time_s\": 9.197217464447021}", "{\"n\": 6950, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.06, \"learn_time_ms\": 8556.612, \"total_train_time_s\": 9.943099737167358}", "{\"n\": 6951, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.74, \"learn_time_ms\": 8597.084, \"total_train_time_s\": 10.32863974571228}", "{\"n\": 6952, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.74, \"learn_time_ms\": 8595.384, \"total_train_time_s\": 10.247741460800171}", "{\"n\": 6953, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.3, \"learn_time_ms\": 8468.684, \"total_train_time_s\": 8.335474967956543}", "{\"n\": 6954, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.37, \"learn_time_ms\": 8615.058, \"total_train_time_s\": 11.15575385093689}", "{\"n\": 6955, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.32, \"learn_time_ms\": 8566.755, \"total_train_time_s\": 10.316567659378052}", "{\"n\": 6956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.12, \"learn_time_ms\": 8561.793, \"total_train_time_s\": 9.883821249008179}", "{\"n\": 6957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.61, \"learn_time_ms\": 8520.551, \"total_train_time_s\": 10.392786979675293}", "{\"n\": 6958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.65, \"learn_time_ms\": 8490.214, \"total_train_time_s\": 9.25650429725647}", "{\"n\": 6959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.65, \"learn_time_ms\": 8394.155, \"total_train_time_s\": 8.206074714660645}", "{\"n\": 6960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.23, \"learn_time_ms\": 8172.656, \"total_train_time_s\": 7.737969636917114}", "{\"n\": 6961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.93, \"learn_time_ms\": 8161.569, \"total_train_time_s\": 10.187211751937866}", "{\"n\": 6962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.93, \"learn_time_ms\": 8073.123, \"total_train_time_s\": 9.383585453033447}", "{\"n\": 6963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.9, \"learn_time_ms\": 8133.44, \"total_train_time_s\": 8.987422943115234}", "{\"n\": 6964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.01, \"learn_time_ms\": 8013.707, \"total_train_time_s\": 9.949467897415161}", "{\"n\": 6965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.01, \"learn_time_ms\": 8087.144, \"total_train_time_s\": 11.016405582427979}", "{\"n\": 6966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.01, \"learn_time_ms\": 8285.373, \"total_train_time_s\": 11.879738330841064}", "{\"n\": 6967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.87, \"learn_time_ms\": 8284.376, \"total_train_time_s\": 10.343246936798096}", "{\"n\": 6968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.87, \"learn_time_ms\": 8349.805, \"total_train_time_s\": 9.873334884643555}", "{\"n\": 6969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.87, \"learn_time_ms\": 8561.024, \"total_train_time_s\": 10.340951919555664}", "{\"n\": 6970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.06, \"learn_time_ms\": 8866.405, \"total_train_time_s\": 10.796603441238403}", "{\"n\": 6971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.78, \"learn_time_ms\": 8761.189, \"total_train_time_s\": 9.182321548461914}", "{\"n\": 6972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.78, \"learn_time_ms\": 8704.683, \"total_train_time_s\": 8.848976850509644}", "{\"n\": 6973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.15, \"learn_time_ms\": 8754.809, \"total_train_time_s\": 9.487440586090088}", "{\"n\": 6974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.72, \"learn_time_ms\": 8841.493, \"total_train_time_s\": 10.780071020126343}", "{\"n\": 6975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.72, \"learn_time_ms\": 8598.785, \"total_train_time_s\": 8.548354148864746}", "{\"n\": 6976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.62, \"learn_time_ms\": 8380.575, \"total_train_time_s\": 9.708692789077759}", "{\"n\": 6977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.04, \"learn_time_ms\": 8370.783, \"total_train_time_s\": 10.203905820846558}", "{\"n\": 6978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.94, \"learn_time_ms\": 8340.731, \"total_train_time_s\": 9.596416711807251}", "{\"n\": 6979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.94, \"learn_time_ms\": 8441.408, \"total_train_time_s\": 11.35438847541809}", "{\"n\": 6980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.69, \"learn_time_ms\": 8409.967, \"total_train_time_s\": 10.507901191711426}", "{\"n\": 6981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.3, \"learn_time_ms\": 8542.04, \"total_train_time_s\": 10.46273946762085}", "{\"n\": 6982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.83, \"learn_time_ms\": 8694.358, \"total_train_time_s\": 10.363808393478394}", "{\"n\": 6983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.1, \"learn_time_ms\": 8665.261, \"total_train_time_s\": 9.251951456069946}", "{\"n\": 6984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.19, \"learn_time_ms\": 8527.865, \"total_train_time_s\": 9.386849880218506}", "{\"n\": 6985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.19, \"learn_time_ms\": 8665.704, \"total_train_time_s\": 9.99785041809082}", "{\"n\": 6986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.32, \"learn_time_ms\": 8719.597, \"total_train_time_s\": 10.217293977737427}", "{\"n\": 6987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.56, \"learn_time_ms\": 8727.238, \"total_train_time_s\": 10.300222396850586}", "{\"n\": 6988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.56, \"learn_time_ms\": 8752.943, \"total_train_time_s\": 9.873761892318726}", "{\"n\": 6989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.17, \"learn_time_ms\": 8528.212, \"total_train_time_s\": 9.061717510223389}", "{\"n\": 6990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.13, \"learn_time_ms\": 8467.552, \"total_train_time_s\": 9.812170505523682}", "{\"n\": 6991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.52, \"learn_time_ms\": 8461.782, \"total_train_time_s\": 10.377916097640991}", "{\"n\": 6992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.46, \"learn_time_ms\": 8478.547, \"total_train_time_s\": 10.50859522819519}", "{\"n\": 6993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.39, \"learn_time_ms\": 8617.777, \"total_train_time_s\": 10.624389410018921}", "{\"n\": 6994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.65, \"learn_time_ms\": 8824.849, \"total_train_time_s\": 11.480735778808594}", "{\"n\": 6995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.07, \"learn_time_ms\": 8733.309, \"total_train_time_s\": 9.025329113006592}", "{\"n\": 6996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.52, \"learn_time_ms\": 8717.268, \"total_train_time_s\": 10.082437992095947}", "{\"n\": 6997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.52, \"learn_time_ms\": 8825.544, \"total_train_time_s\": 11.39474606513977}", "{\"n\": 6998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.98, \"learn_time_ms\": 8813.954, \"total_train_time_s\": 9.76865530014038}", "{\"n\": 6999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.54, \"learn_time_ms\": 8962.556, \"total_train_time_s\": 10.560863256454468}", "{\"n\": 7000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.54, \"learn_time_ms\": 8944.178, \"total_train_time_s\": 9.619279623031616}", "{\"n\": 7001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.67, \"learn_time_ms\": 8879.333, \"total_train_time_s\": 9.777031421661377}", "{\"n\": 7002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.54, \"learn_time_ms\": 8759.234, \"total_train_time_s\": 9.320073127746582}", "{\"n\": 7003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.46, \"learn_time_ms\": 8672.7, \"total_train_time_s\": 9.752691745758057}", "{\"n\": 7004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.46, \"learn_time_ms\": 8589.886, \"total_train_time_s\": 10.719066381454468}", "{\"n\": 7005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.77, \"learn_time_ms\": 8553.186, \"total_train_time_s\": 8.720044612884521}", "{\"n\": 7006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.16, \"learn_time_ms\": 8658.221, \"total_train_time_s\": 11.128756999969482}", "{\"n\": 7007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.16, \"learn_time_ms\": 8573.972, \"total_train_time_s\": 10.49809718132019}", "{\"n\": 7008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.31, \"learn_time_ms\": 8646.071, \"total_train_time_s\": 10.48539662361145}", "{\"n\": 7009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.65, \"learn_time_ms\": 8516.715, \"total_train_time_s\": 9.293197393417358}", "{\"n\": 7010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.65, \"learn_time_ms\": 8685.463, \"total_train_time_s\": 11.323559522628784}", "{\"n\": 7011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.22, \"learn_time_ms\": 8744.042, \"total_train_time_s\": 10.34165644645691}", "{\"n\": 7012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.44, \"learn_time_ms\": 8732.149, \"total_train_time_s\": 9.183749675750732}", "{\"n\": 7013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.44, \"learn_time_ms\": 8872.648, \"total_train_time_s\": 11.153842449188232}", "{\"n\": 7014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.14, \"learn_time_ms\": 8674.234, \"total_train_time_s\": 8.650595664978027}", "{\"n\": 7015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.92, \"learn_time_ms\": 8822.313, \"total_train_time_s\": 10.20908784866333}", "{\"n\": 7016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.92, \"learn_time_ms\": 8727.201, \"total_train_time_s\": 10.174822568893433}", "{\"n\": 7017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.88, \"learn_time_ms\": 8629.574, \"total_train_time_s\": 9.596488952636719}", "{\"n\": 7018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.38, \"learn_time_ms\": 8638.478, \"total_train_time_s\": 10.546046018600464}", "{\"n\": 7019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.54, \"learn_time_ms\": 8667.145, \"total_train_time_s\": 9.532086372375488}", "{\"n\": 7020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.54, \"learn_time_ms\": 8515.366, \"total_train_time_s\": 9.771995544433594}", "{\"n\": 7021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.24, \"learn_time_ms\": 8529.32, \"total_train_time_s\": 10.453218936920166}", "{\"n\": 7022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.77, \"learn_time_ms\": 8567.68, \"total_train_time_s\": 9.620360136032104}", "{\"n\": 7023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.77, \"learn_time_ms\": 8666.489, \"total_train_time_s\": 12.134741067886353}", "{\"n\": 7024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.19, \"learn_time_ms\": 8719.102, \"total_train_time_s\": 9.171939611434937}", "{\"n\": 7025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.97, \"learn_time_ms\": 8882.421, \"total_train_time_s\": 11.827943325042725}", "{\"n\": 7026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.97, \"learn_time_ms\": 8917.164, \"total_train_time_s\": 10.484557867050171}", "{\"n\": 7027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.4, \"learn_time_ms\": 9081.879, \"total_train_time_s\": 11.23421025276184}", "{\"n\": 7028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.66, \"learn_time_ms\": 9164.665, \"total_train_time_s\": 11.400528907775879}", "{\"n\": 7029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.66, \"learn_time_ms\": 9321.663, \"total_train_time_s\": 11.106244325637817}", "{\"n\": 7030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.66, \"learn_time_ms\": 9417.768, \"total_train_time_s\": 10.758609533309937}", "{\"n\": 7031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.07, \"learn_time_ms\": 9272.948, \"total_train_time_s\": 9.071690082550049}", "{\"n\": 7032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.56, \"learn_time_ms\": 9215.627, \"total_train_time_s\": 9.000416278839111}", "{\"n\": 7033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.56, \"learn_time_ms\": 8950.42, \"total_train_time_s\": 9.487642049789429}", "{\"n\": 7034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.57, \"learn_time_ms\": 9054.066, \"total_train_time_s\": 10.261715412139893}", "{\"n\": 7035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.99, \"learn_time_ms\": 8846.956, \"total_train_time_s\": 9.789145469665527}", "{\"n\": 7036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.99, \"learn_time_ms\": 8570.664, \"total_train_time_s\": 7.718939542770386}", "{\"n\": 7037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.09, \"learn_time_ms\": 8384.082, \"total_train_time_s\": 9.359222173690796}", "{\"n\": 7038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.21, \"learn_time_ms\": 8187.657, \"total_train_time_s\": 9.42994499206543}", "{\"n\": 7039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.21, \"learn_time_ms\": 8189.004, \"total_train_time_s\": 11.10721755027771}", "{\"n\": 7040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.7, \"learn_time_ms\": 8135.025, \"total_train_time_s\": 10.218270778656006}", "{\"n\": 7041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.69, \"learn_time_ms\": 8276.751, \"total_train_time_s\": 10.4873046875}", "{\"n\": 7042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.16, \"learn_time_ms\": 8098.417, \"total_train_time_s\": 7.22906231880188}", "{\"n\": 7043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.62, \"learn_time_ms\": 8148.558, \"total_train_time_s\": 9.955366611480713}", "{\"n\": 7044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.64, \"learn_time_ms\": 8124.796, \"total_train_time_s\": 9.942949056625366}", "{\"n\": 7045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.64, \"learn_time_ms\": 8168.071, \"total_train_time_s\": 10.179283380508423}", "{\"n\": 7046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.44, \"learn_time_ms\": 8401.108, \"total_train_time_s\": 10.076705932617188}", "{\"n\": 7047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.92, \"learn_time_ms\": 8423.294, \"total_train_time_s\": 9.562341690063477}", "{\"n\": 7048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.92, \"learn_time_ms\": 8374.678, \"total_train_time_s\": 8.919150114059448}", "{\"n\": 7049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.61, \"learn_time_ms\": 8258.208, \"total_train_time_s\": 9.95454454421997}", "{\"n\": 7050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.41, \"learn_time_ms\": 8102.182, \"total_train_time_s\": 8.697709798812866}", "{\"n\": 7051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.31, \"learn_time_ms\": 8046.925, \"total_train_time_s\": 9.918880224227905}", "{\"n\": 7052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.31, \"learn_time_ms\": 8454.766, \"total_train_time_s\": 11.335191488265991}", "{\"n\": 7053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.5, \"learn_time_ms\": 8343.068, \"total_train_time_s\": 8.856430292129517}", "{\"n\": 7054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.07, \"learn_time_ms\": 8317.744, \"total_train_time_s\": 9.728442192077637}", "{\"n\": 7055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.12, \"learn_time_ms\": 8126.766, \"total_train_time_s\": 8.26505970954895}", "{\"n\": 7056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.45, \"learn_time_ms\": 8075.483, \"total_train_time_s\": 9.584169864654541}", "{\"n\": 7057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.1, \"learn_time_ms\": 8195.89, \"total_train_time_s\": 10.735550165176392}", "{\"n\": 7058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.74, \"learn_time_ms\": 8282.785, \"total_train_time_s\": 9.815563440322876}", "{\"n\": 7059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.98, \"learn_time_ms\": 8286.177, \"total_train_time_s\": 10.036349296569824}", "{\"n\": 7060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.57, \"learn_time_ms\": 8296.04, \"total_train_time_s\": 8.77285122871399}", "{\"n\": 7061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.68, \"learn_time_ms\": 8305.104, \"total_train_time_s\": 9.972194194793701}", "{\"n\": 7062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.57, \"learn_time_ms\": 8249.014, \"total_train_time_s\": 10.69813847541809}", "{\"n\": 7063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.14, \"learn_time_ms\": 8378.64, \"total_train_time_s\": 10.161327838897705}", "{\"n\": 7064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.5, \"learn_time_ms\": 8436.692, \"total_train_time_s\": 10.356817960739136}", "{\"n\": 7065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.35, \"learn_time_ms\": 8598.764, \"total_train_time_s\": 9.887557983398438}", "{\"n\": 7066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.8, \"learn_time_ms\": 8724.289, \"total_train_time_s\": 10.814648866653442}", "{\"n\": 7067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.29, \"learn_time_ms\": 8590.961, \"total_train_time_s\": 9.48173213005066}", "{\"n\": 7068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.42, \"learn_time_ms\": 8452.623, \"total_train_time_s\": 8.404345750808716}", "{\"n\": 7069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.64, \"learn_time_ms\": 8526.692, \"total_train_time_s\": 10.731918811798096}", "{\"n\": 7070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.73, \"learn_time_ms\": 8673.318, \"total_train_time_s\": 10.226447343826294}", "{\"n\": 7071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.26, \"learn_time_ms\": 8646.808, \"total_train_time_s\": 9.718996524810791}", "{\"n\": 7072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.2, \"learn_time_ms\": 8600.477, \"total_train_time_s\": 10.280662536621094}", "{\"n\": 7073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.8, \"learn_time_ms\": 8571.606, \"total_train_time_s\": 9.889374256134033}", "{\"n\": 7074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.83, \"learn_time_ms\": 8629.426, \"total_train_time_s\": 10.955458641052246}", "{\"n\": 7075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.84, \"learn_time_ms\": 8737.394, \"total_train_time_s\": 10.942458629608154}", "{\"n\": 7076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.19, \"learn_time_ms\": 8732.536, \"total_train_time_s\": 10.768255949020386}", "{\"n\": 7077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.02, \"learn_time_ms\": 8870.433, \"total_train_time_s\": 10.821491003036499}", "{\"n\": 7078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.25, \"learn_time_ms\": 8997.094, \"total_train_time_s\": 9.683889150619507}", "{\"n\": 7079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.79, \"learn_time_ms\": 8895.239, \"total_train_time_s\": 9.74970555305481}", "{\"n\": 7080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.02, \"learn_time_ms\": 8787.004, \"total_train_time_s\": 9.161585569381714}", "{\"n\": 7081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.05, \"learn_time_ms\": 8855.67, \"total_train_time_s\": 10.423418521881104}", "{\"n\": 7082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.05, \"learn_time_ms\": 8824.434, \"total_train_time_s\": 9.946539878845215}", "{\"n\": 7083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.5, \"learn_time_ms\": 8827.439, \"total_train_time_s\": 9.909676313400269}", "{\"n\": 7084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.82, \"learn_time_ms\": 8784.694, \"total_train_time_s\": 10.484327554702759}", "{\"n\": 7085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.04, \"learn_time_ms\": 8604.5, \"total_train_time_s\": 9.138347625732422}", "{\"n\": 7086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.92, \"learn_time_ms\": 8597.434, \"total_train_time_s\": 10.705994367599487}", "{\"n\": 7087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.3, \"learn_time_ms\": 8667.264, \"total_train_time_s\": 11.50573468208313}", "{\"n\": 7088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.88, \"learn_time_ms\": 8617.763, \"total_train_time_s\": 9.209118127822876}", "{\"n\": 7089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.88, \"learn_time_ms\": 8679.796, \"total_train_time_s\": 10.363699913024902}", "{\"n\": 7090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.06, \"learn_time_ms\": 8728.089, \"total_train_time_s\": 9.661821365356445}", "{\"n\": 7091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.32, \"learn_time_ms\": 8766.805, \"total_train_time_s\": 10.833343982696533}", "{\"n\": 7092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.32, \"learn_time_ms\": 8751.582, \"total_train_time_s\": 9.796090841293335}", "{\"n\": 7093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.16, \"learn_time_ms\": 8890.204, \"total_train_time_s\": 11.295774936676025}", "{\"n\": 7094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.16, \"learn_time_ms\": 8882.522, \"total_train_time_s\": 10.401137828826904}", "{\"n\": 7095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.2, \"learn_time_ms\": 9014.422, \"total_train_time_s\": 10.50503420829773}", "{\"n\": 7096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.22, \"learn_time_ms\": 9022.194, \"total_train_time_s\": 10.801403284072876}", "{\"n\": 7097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.95, \"learn_time_ms\": 8937.249, \"total_train_time_s\": 10.67144775390625}", "{\"n\": 7098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.62, \"learn_time_ms\": 9065.005, \"total_train_time_s\": 10.4780752658844}", "{\"n\": 7099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.06, \"learn_time_ms\": 9042.048, \"total_train_time_s\": 10.15636420249939}", "{\"n\": 7100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3260.31, \"learn_time_ms\": 9099.808, \"total_train_time_s\": 10.248244524002075}", "{\"n\": 7101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.45, \"learn_time_ms\": 9008.388, \"total_train_time_s\": 9.935765981674194}", "{\"n\": 7102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.45, \"learn_time_ms\": 8970.376, \"total_train_time_s\": 9.42039966583252}", "{\"n\": 7103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.58, \"learn_time_ms\": 8971.478, \"total_train_time_s\": 11.281398057937622}", "{\"n\": 7104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.63, \"learn_time_ms\": 8906.819, \"total_train_time_s\": 9.787683486938477}", "{\"n\": 7105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.17, \"learn_time_ms\": 8895.288, \"total_train_time_s\": 10.39353322982788}", "{\"n\": 7106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.39, \"learn_time_ms\": 8914.947, \"total_train_time_s\": 10.966155290603638}", "{\"n\": 7107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.49, \"learn_time_ms\": 8705.18, \"total_train_time_s\": 8.563927173614502}", "{\"n\": 7108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.36, \"learn_time_ms\": 8646.792, \"total_train_time_s\": 9.890679597854614}", "{\"n\": 7109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.36, \"learn_time_ms\": 8718.858, \"total_train_time_s\": 10.879945039749146}", "{\"n\": 7110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.75, \"learn_time_ms\": 8734.261, \"total_train_time_s\": 10.362926244735718}", "{\"n\": 7111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.37, \"learn_time_ms\": 8892.65, \"total_train_time_s\": 11.489999294281006}", "{\"n\": 7112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.9, \"learn_time_ms\": 8891.144, \"total_train_time_s\": 9.404018640518188}", "{\"n\": 7113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.46, \"learn_time_ms\": 8667.804, \"total_train_time_s\": 9.066611051559448}", "{\"n\": 7114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.18, \"learn_time_ms\": 8499.716, \"total_train_time_s\": 8.061513900756836}", "{\"n\": 7115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.04, \"learn_time_ms\": 8259.894, \"total_train_time_s\": 7.943854808807373}", "{\"n\": 7116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.88, \"learn_time_ms\": 8179.778, \"total_train_time_s\": 10.200331449508667}", "{\"n\": 7117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.94, \"learn_time_ms\": 8258.173, \"total_train_time_s\": 9.398395538330078}", "{\"n\": 7118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.23, \"learn_time_ms\": 8234.227, \"total_train_time_s\": 9.639197826385498}", "{\"n\": 7119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.54, \"learn_time_ms\": 8167.993, \"total_train_time_s\": 10.19585132598877}", "{\"n\": 7120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.99, \"learn_time_ms\": 8052.673, \"total_train_time_s\": 9.224687337875366}", "{\"n\": 7121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.27, \"learn_time_ms\": 7966.772, \"total_train_time_s\": 10.624934196472168}", "{\"n\": 7122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.27, \"learn_time_ms\": 8048.132, \"total_train_time_s\": 10.24081015586853}", "{\"n\": 7123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.2, \"learn_time_ms\": 8044.339, \"total_train_time_s\": 9.065313339233398}", "{\"n\": 7124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.13, \"learn_time_ms\": 8182.112, \"total_train_time_s\": 9.498075008392334}", "{\"n\": 7125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.13, \"learn_time_ms\": 8417.649, \"total_train_time_s\": 10.363744497299194}", "{\"n\": 7126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.69, \"learn_time_ms\": 8300.556, \"total_train_time_s\": 9.043263673782349}", "{\"n\": 7127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.6, \"learn_time_ms\": 8423.259, \"total_train_time_s\": 10.57809591293335}", "{\"n\": 7128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.6, \"learn_time_ms\": 8328.868, \"total_train_time_s\": 8.729766607284546}", "{\"n\": 7129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.75, \"learn_time_ms\": 8370.292, \"total_train_time_s\": 10.600720643997192}", "{\"n\": 7130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.56, \"learn_time_ms\": 8504.903, \"total_train_time_s\": 10.609687805175781}", "{\"n\": 7131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.56, \"learn_time_ms\": 8487.102, \"total_train_time_s\": 10.4466392993927}", "{\"n\": 7132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.56, \"learn_time_ms\": 8459.138, \"total_train_time_s\": 9.92902159690857}", "{\"n\": 7133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.5, \"learn_time_ms\": 8546.435, \"total_train_time_s\": 9.91158938407898}", "{\"n\": 7134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.18, \"learn_time_ms\": 8561.072, \"total_train_time_s\": 9.58109974861145}", "{\"n\": 7135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.24, \"learn_time_ms\": 8477.884, \"total_train_time_s\": 9.529480695724487}", "{\"n\": 7136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.11, \"learn_time_ms\": 8641.647, \"total_train_time_s\": 10.67098355293274}", "{\"n\": 7137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.67, \"learn_time_ms\": 8588.584, \"total_train_time_s\": 9.996129035949707}", "{\"n\": 7138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.9, \"learn_time_ms\": 8664.437, \"total_train_time_s\": 9.435854196548462}", "{\"n\": 7139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.9, \"learn_time_ms\": 8686.947, \"total_train_time_s\": 10.810046434402466}", "{\"n\": 7140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.69, \"learn_time_ms\": 8598.208, \"total_train_time_s\": 9.682041645050049}", "{\"n\": 7141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.79, \"learn_time_ms\": 8430.386, \"total_train_time_s\": 8.777951955795288}", "{\"n\": 7142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.79, \"learn_time_ms\": 8343.865, \"total_train_time_s\": 9.083819150924683}", "{\"n\": 7143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.61, \"learn_time_ms\": 8319.541, \"total_train_time_s\": 9.638649940490723}", "{\"n\": 7144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.6, \"learn_time_ms\": 8402.639, \"total_train_time_s\": 10.414378881454468}", "{\"n\": 7145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.6, \"learn_time_ms\": 8275.478, \"total_train_time_s\": 8.203097820281982}", "{\"n\": 7146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.2, \"learn_time_ms\": 8222.255, \"total_train_time_s\": 10.123792171478271}", "{\"n\": 7147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.09, \"learn_time_ms\": 8017.065, \"total_train_time_s\": 7.954580783843994}", "{\"n\": 7148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.7, \"learn_time_ms\": 8010.957, \"total_train_time_s\": 9.393960237503052}", "{\"n\": 7149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.5, \"learn_time_ms\": 7994.613, \"total_train_time_s\": 10.656222343444824}", "{\"n\": 7150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.5, \"learn_time_ms\": 7957.495, \"total_train_time_s\": 9.280783891677856}", "{\"n\": 7151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.5, \"learn_time_ms\": 8157.201, \"total_train_time_s\": 10.726616144180298}", "{\"n\": 7152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.01, \"learn_time_ms\": 8248.082, \"total_train_time_s\": 10.002655982971191}", "{\"n\": 7153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.06, \"learn_time_ms\": 8419.746, \"total_train_time_s\": 11.358881711959839}", "{\"n\": 7154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.06, \"learn_time_ms\": 8258.296, \"total_train_time_s\": 8.818331956863403}", "{\"n\": 7155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.88, \"learn_time_ms\": 8394.933, \"total_train_time_s\": 9.593505620956421}", "{\"n\": 7156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.61, \"learn_time_ms\": 8334.625, \"total_train_time_s\": 9.524409294128418}", "{\"n\": 7157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.61, \"learn_time_ms\": 8552.537, \"total_train_time_s\": 10.171767234802246}", "{\"n\": 7158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.61, \"learn_time_ms\": 8557.651, \"total_train_time_s\": 9.445280075073242}", "{\"n\": 7159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3209.35, \"learn_time_ms\": 8337.245, \"total_train_time_s\": 8.448015451431274}", "{\"n\": 7160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3209.35, \"learn_time_ms\": 8503.057, \"total_train_time_s\": 10.94426703453064}", "{\"n\": 7161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3209.35, \"learn_time_ms\": 8351.396, \"total_train_time_s\": 9.243552446365356}", "{\"n\": 7162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3214.17, \"learn_time_ms\": 8293.836, \"total_train_time_s\": 9.407533884048462}", "{\"n\": 7163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3215.87, \"learn_time_ms\": 8098.819, \"total_train_time_s\": 9.40578007698059}", "{\"n\": 7164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3215.87, \"learn_time_ms\": 8238.003, \"total_train_time_s\": 10.183347225189209}", "{\"n\": 7165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3214.66, \"learn_time_ms\": 8266.994, \"total_train_time_s\": 9.844884157180786}", "{\"n\": 7166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3223.13, \"learn_time_ms\": 8234.105, \"total_train_time_s\": 9.162481546401978}", "{\"n\": 7167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3215.6, \"learn_time_ms\": 8199.758, \"total_train_time_s\": 9.863524913787842}", "{\"n\": 7168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3207.57, \"learn_time_ms\": 8217.032, \"total_train_time_s\": 9.64987301826477}", "{\"n\": 7169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3210.48, \"learn_time_ms\": 8387.911, \"total_train_time_s\": 10.169036149978638}", "{\"n\": 7170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3207.35, \"learn_time_ms\": 8294.055, \"total_train_time_s\": 10.054737091064453}", "{\"n\": 7171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3204.9, \"learn_time_ms\": 8507.243, \"total_train_time_s\": 11.397806406021118}", "{\"n\": 7172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3203.47, \"learn_time_ms\": 8450.529, \"total_train_time_s\": 8.852160215377808}", "{\"n\": 7173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3197.78, \"learn_time_ms\": 8564.848, \"total_train_time_s\": 10.574687719345093}", "{\"n\": 7174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3194.25, \"learn_time_ms\": 8553.729, \"total_train_time_s\": 10.112668514251709}", "{\"n\": 7175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3195.19, \"learn_time_ms\": 8555.827, \"total_train_time_s\": 9.933735370635986}", "{\"n\": 7176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3193.32, \"learn_time_ms\": 8631.722, \"total_train_time_s\": 9.9541757106781}", "{\"n\": 7177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3190.62, \"learn_time_ms\": 8585.826, \"total_train_time_s\": 9.39165472984314}", "{\"n\": 7178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.58, \"learn_time_ms\": 8641.036, \"total_train_time_s\": 10.237643480300903}", "{\"n\": 7179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.58, \"learn_time_ms\": 8546.105, \"total_train_time_s\": 9.24077582359314}", "{\"n\": 7180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3181.73, \"learn_time_ms\": 8557.683, \"total_train_time_s\": 10.199870347976685}", "{\"n\": 7181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3177.79, \"learn_time_ms\": 8436.433, \"total_train_time_s\": 10.167907476425171}", "{\"n\": 7182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3181.91, \"learn_time_ms\": 8494.925, \"total_train_time_s\": 9.427298307418823}", "{\"n\": 7183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.28, \"learn_time_ms\": 8480.168, \"total_train_time_s\": 10.375368356704712}", "{\"n\": 7184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3175.29, \"learn_time_ms\": 8381.483, \"total_train_time_s\": 9.157993078231812}", "{\"n\": 7185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3173.31, \"learn_time_ms\": 8356.81, \"total_train_time_s\": 9.661846160888672}", "{\"n\": 7186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3165.98, \"learn_time_ms\": 8332.132, \"total_train_time_s\": 9.695157527923584}", "{\"n\": 7187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3164.62, \"learn_time_ms\": 8422.194, \"total_train_time_s\": 10.277276992797852}", "{\"n\": 7188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3174.17, \"learn_time_ms\": 8450.441, \"total_train_time_s\": 10.48167109489441}", "{\"n\": 7189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3173.71, \"learn_time_ms\": 8477.412, \"total_train_time_s\": 9.500454187393188}", "{\"n\": 7190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3179.09, \"learn_time_ms\": 8404.416, \"total_train_time_s\": 9.395228385925293}", "{\"n\": 7191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3179.09, \"learn_time_ms\": 8430.584, \"total_train_time_s\": 10.444091081619263}", "{\"n\": 7192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3181.73, \"learn_time_ms\": 8454.632, \"total_train_time_s\": 9.734222173690796}", "{\"n\": 7193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3178.66, \"learn_time_ms\": 8407.808, \"total_train_time_s\": 9.974787950515747}", "{\"n\": 7194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3178.66, \"learn_time_ms\": 8480.738, \"total_train_time_s\": 9.8387451171875}", "{\"n\": 7195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.08, \"learn_time_ms\": 8476.109, \"total_train_time_s\": 9.591943740844727}", "{\"n\": 7196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.31, \"learn_time_ms\": 8581.211, \"total_train_time_s\": 10.743897199630737}", "{\"n\": 7197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3184.31, \"learn_time_ms\": 8534.124, \"total_train_time_s\": 9.810960292816162}", "{\"n\": 7198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3180.39, \"learn_time_ms\": 8555.206, \"total_train_time_s\": 10.725053787231445}", "{\"n\": 7199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3171.77, \"learn_time_ms\": 8552.855, \"total_train_time_s\": 9.465050220489502}", "{\"n\": 7200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3171.77, \"learn_time_ms\": 8709.806, \"total_train_time_s\": 11.005185604095459}", "{\"n\": 7201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3171.77, \"learn_time_ms\": 8556.447, \"total_train_time_s\": 8.91358995437622}", "{\"n\": 7202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3177.21, \"learn_time_ms\": 8563.834, \"total_train_time_s\": 9.817475318908691}", "{\"n\": 7203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3179.19, \"learn_time_ms\": 8446.886, \"total_train_time_s\": 8.732439279556274}", "{\"n\": 7204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3180.89, \"learn_time_ms\": 8528.127, \"total_train_time_s\": 10.652654647827148}", "{\"n\": 7205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3186.12, \"learn_time_ms\": 8472.339, \"total_train_time_s\": 9.063647747039795}", "{\"n\": 7206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3188.17, \"learn_time_ms\": 8356.161, \"total_train_time_s\": 9.559550285339355}", "{\"n\": 7207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3188.17, \"learn_time_ms\": 8404.653, \"total_train_time_s\": 10.29136347770691}", "{\"n\": 7208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3189.78, \"learn_time_ms\": 8266.633, \"total_train_time_s\": 9.322874307632446}", "{\"n\": 7209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3195.21, \"learn_time_ms\": 8324.165, \"total_train_time_s\": 10.012985229492188}", "{\"n\": 7210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3195.21, \"learn_time_ms\": 8161.329, \"total_train_time_s\": 9.364196300506592}", "{\"n\": 7211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3199.88, \"learn_time_ms\": 8304.387, \"total_train_time_s\": 10.357123613357544}", "{\"n\": 7212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3199.58, \"learn_time_ms\": 8388.411, \"total_train_time_s\": 10.61127758026123}", "{\"n\": 7213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3201.04, \"learn_time_ms\": 8350.977, \"total_train_time_s\": 8.38373851776123}", "{\"n\": 7214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3207.7, \"learn_time_ms\": 8253.864, \"total_train_time_s\": 9.69812560081482}", "{\"n\": 7215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3205.17, \"learn_time_ms\": 8460.261, \"total_train_time_s\": 11.265283584594727}", "{\"n\": 7216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3211.27, \"learn_time_ms\": 8500.111, \"total_train_time_s\": 9.968905210494995}", "{\"n\": 7217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3205.97, \"learn_time_ms\": 8371.845, \"total_train_time_s\": 9.030665159225464}", "{\"n\": 7218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3208.89, \"learn_time_ms\": 8301.629, \"total_train_time_s\": 8.641014099121094}", "{\"n\": 7219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3206.46, \"learn_time_ms\": 8248.169, \"total_train_time_s\": 9.493068933486938}", "{\"n\": 7220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3206.46, \"learn_time_ms\": 8452.27, \"total_train_time_s\": 11.430061101913452}", "{\"n\": 7221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3209.87, \"learn_time_ms\": 8587.705, \"total_train_time_s\": 11.688857555389404}", "{\"n\": 7222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3209.15, \"learn_time_ms\": 8536.636, \"total_train_time_s\": 10.106224536895752}", "{\"n\": 7223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3204.74, \"learn_time_ms\": 8645.852, \"total_train_time_s\": 9.49983549118042}", "{\"n\": 7224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3207.41, \"learn_time_ms\": 8823.368, \"total_train_time_s\": 11.432884454727173}", "{\"n\": 7225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3212.18, \"learn_time_ms\": 8883.662, \"total_train_time_s\": 11.745923042297363}", "{\"n\": 7226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3213.98, \"learn_time_ms\": 8851.091, \"total_train_time_s\": 9.676567316055298}", "{\"n\": 7227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.64, \"learn_time_ms\": 8838.957, \"total_train_time_s\": 8.920361042022705}", "{\"n\": 7228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.77, \"learn_time_ms\": 9002.947, \"total_train_time_s\": 10.238598585128784}", "{\"n\": 7229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3221.14, \"learn_time_ms\": 8947.244, \"total_train_time_s\": 8.94893217086792}", "{\"n\": 7230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3221.14, \"learn_time_ms\": 8815.373, \"total_train_time_s\": 10.114762544631958}", "{\"n\": 7231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3238.03, \"learn_time_ms\": 8702.826, \"total_train_time_s\": 10.632947444915771}", "{\"n\": 7232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3239.78, \"learn_time_ms\": 8674.53, \"total_train_time_s\": 9.793706178665161}", "{\"n\": 7233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3244.76, \"learn_time_ms\": 8831.243, \"total_train_time_s\": 11.084879398345947}", "{\"n\": 7234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3239.06, \"learn_time_ms\": 8681.812, \"total_train_time_s\": 9.991892099380493}", "{\"n\": 7235, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.09, \"learn_time_ms\": 8457.962, \"total_train_time_s\": 9.512210369110107}", "{\"n\": 7236, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3231.53, \"learn_time_ms\": 8388.033, \"total_train_time_s\": 8.97132420539856}", "{\"n\": 7237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.92, \"learn_time_ms\": 8422.451, \"total_train_time_s\": 9.257895946502686}", "{\"n\": 7238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.1, \"learn_time_ms\": 8333.561, \"total_train_time_s\": 9.347559452056885}", "{\"n\": 7239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.13, \"learn_time_ms\": 8409.848, \"total_train_time_s\": 9.701138496398926}", "{\"n\": 7240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.0, \"learn_time_ms\": 8409.864, \"total_train_time_s\": 10.085368394851685}", "{\"n\": 7241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.43, \"learn_time_ms\": 8333.927, \"total_train_time_s\": 9.80691647529602}", "{\"n\": 7242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.49, \"learn_time_ms\": 8395.75, \"total_train_time_s\": 10.374583959579468}", "{\"n\": 7243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.71, \"learn_time_ms\": 8154.198, \"total_train_time_s\": 8.700104713439941}", "{\"n\": 7244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.1, \"learn_time_ms\": 7994.636, \"total_train_time_s\": 8.400487899780273}", "{\"n\": 7245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.59, \"learn_time_ms\": 8171.703, \"total_train_time_s\": 11.207873582839966}", "{\"n\": 7246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.35, \"learn_time_ms\": 8350.281, \"total_train_time_s\": 10.752054691314697}", "{\"n\": 7247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.28, \"learn_time_ms\": 8273.321, \"total_train_time_s\": 8.51794958114624}", "{\"n\": 7248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.39, \"learn_time_ms\": 8227.52, \"total_train_time_s\": 8.896480798721313}", "{\"n\": 7249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.38, \"learn_time_ms\": 8250.673, \"total_train_time_s\": 9.93859338760376}", "{\"n\": 7250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.79, \"learn_time_ms\": 8299.07, \"total_train_time_s\": 10.5447678565979}", "{\"n\": 7251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.87, \"learn_time_ms\": 8336.485, \"total_train_time_s\": 10.132895231246948}", "{\"n\": 7252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.67, \"learn_time_ms\": 8299.642, \"total_train_time_s\": 10.065900325775146}", "{\"n\": 7253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.67, \"learn_time_ms\": 8374.257, \"total_train_time_s\": 9.375317811965942}", "{\"n\": 7254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.63, \"learn_time_ms\": 8294.614, \"total_train_time_s\": 7.605173826217651}", "{\"n\": 7255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.7, \"learn_time_ms\": 8154.142, \"total_train_time_s\": 9.806734085083008}", "{\"n\": 7256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.7, \"learn_time_ms\": 8020.289, \"total_train_time_s\": 9.35286569595337}", "{\"n\": 7257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.32, \"learn_time_ms\": 8116.607, \"total_train_time_s\": 9.458478689193726}", "{\"n\": 7258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.74, \"learn_time_ms\": 8209.425, \"total_train_time_s\": 9.827208280563354}", "{\"n\": 7259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.74, \"learn_time_ms\": 8082.562, \"total_train_time_s\": 8.676727771759033}", "{\"n\": 7260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.86, \"learn_time_ms\": 7956.319, \"total_train_time_s\": 9.321978330612183}", "{\"n\": 7261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.23, \"learn_time_ms\": 7892.274, \"total_train_time_s\": 9.538613319396973}", "{\"n\": 7262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.43, \"learn_time_ms\": 7877.471, \"total_train_time_s\": 9.89760708808899}", "{\"n\": 7263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.29, \"learn_time_ms\": 7898.775, \"total_train_time_s\": 9.625195264816284}", "{\"n\": 7264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.29, \"learn_time_ms\": 8177.805, \"total_train_time_s\": 10.333251237869263}", "{\"n\": 7265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.41, \"learn_time_ms\": 8110.229, \"total_train_time_s\": 9.17217206954956}", "{\"n\": 7266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.33, \"learn_time_ms\": 8283.839, \"total_train_time_s\": 11.121261835098267}", "{\"n\": 7267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.51, \"learn_time_ms\": 8343.162, \"total_train_time_s\": 10.078272104263306}", "{\"n\": 7268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.96, \"learn_time_ms\": 8281.358, \"total_train_time_s\": 9.207791090011597}", "{\"n\": 7269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.21, \"learn_time_ms\": 8477.018, \"total_train_time_s\": 10.633441925048828}", "{\"n\": 7270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.87, \"learn_time_ms\": 8648.512, \"total_train_time_s\": 10.968982219696045}", "{\"n\": 7271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.87, \"learn_time_ms\": 8785.882, \"total_train_time_s\": 10.91043758392334}", "{\"n\": 7272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.3, \"learn_time_ms\": 8796.647, \"total_train_time_s\": 10.003138780593872}", "{\"n\": 7273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.24, \"learn_time_ms\": 8790.911, \"total_train_time_s\": 9.49831223487854}", "{\"n\": 7274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.24, \"learn_time_ms\": 8792.718, \"total_train_time_s\": 10.333255290985107}", "{\"n\": 7275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.91, \"learn_time_ms\": 8945.533, \"total_train_time_s\": 10.644521474838257}", "{\"n\": 7276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.97, \"learn_time_ms\": 8822.622, \"total_train_time_s\": 9.910110712051392}", "{\"n\": 7277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.97, \"learn_time_ms\": 8808.056, \"total_train_time_s\": 9.856103897094727}", "{\"n\": 7278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.57, \"learn_time_ms\": 8843.893, \"total_train_time_s\": 9.569386959075928}", "{\"n\": 7279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.74, \"learn_time_ms\": 8902.958, \"total_train_time_s\": 11.242702722549438}", "{\"n\": 7280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.74, \"learn_time_ms\": 8727.68, \"total_train_time_s\": 9.270884275436401}", "{\"n\": 7281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.98, \"learn_time_ms\": 8647.137, \"total_train_time_s\": 10.096758842468262}", "{\"n\": 7282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.21, \"learn_time_ms\": 8651.991, \"total_train_time_s\": 10.038394212722778}", "{\"n\": 7283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.21, \"learn_time_ms\": 8800.453, \"total_train_time_s\": 11.037416696548462}", "{\"n\": 7284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.68, \"learn_time_ms\": 8688.269, \"total_train_time_s\": 9.244788408279419}", "{\"n\": 7285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.36, \"learn_time_ms\": 8579.182, \"total_train_time_s\": 9.622133016586304}", "{\"n\": 7286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.14, \"learn_time_ms\": 8620.326, \"total_train_time_s\": 10.288751125335693}", "{\"n\": 7287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.52, \"learn_time_ms\": 8625.648, \"total_train_time_s\": 9.910869836807251}", "{\"n\": 7288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.2, \"learn_time_ms\": 8724.148, \"total_train_time_s\": 10.538246631622314}", "{\"n\": 7289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.26, \"learn_time_ms\": 8644.789, \"total_train_time_s\": 10.43989610671997}", "{\"n\": 7290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.26, \"learn_time_ms\": 8711.096, \"total_train_time_s\": 9.908478260040283}", "{\"n\": 7291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.72, \"learn_time_ms\": 8477.401, \"total_train_time_s\": 7.759289979934692}", "{\"n\": 7292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.51, \"learn_time_ms\": 8445.802, \"total_train_time_s\": 9.733955383300781}", "{\"n\": 7293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.03, \"learn_time_ms\": 8423.483, \"total_train_time_s\": 10.805032730102539}", "{\"n\": 7294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.03, \"learn_time_ms\": 8377.357, \"total_train_time_s\": 8.718309879302979}", "{\"n\": 7295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.31, \"learn_time_ms\": 8487.867, \"total_train_time_s\": 10.716253757476807}", "{\"n\": 7296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.78, \"learn_time_ms\": 8605.223, \"total_train_time_s\": 11.510806798934937}", "{\"n\": 7297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.57, \"learn_time_ms\": 8487.126, \"total_train_time_s\": 8.763620138168335}", "{\"n\": 7298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.27, \"learn_time_ms\": 8380.801, \"total_train_time_s\": 9.489372253417969}", "{\"n\": 7299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.55, \"learn_time_ms\": 8445.642, \"total_train_time_s\": 11.062684774398804}", "{\"n\": 7300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.51, \"learn_time_ms\": 8383.325, \"total_train_time_s\": 9.275273561477661}", "{\"n\": 7301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.52, \"learn_time_ms\": 8662.119, \"total_train_time_s\": 10.536062240600586}", "{\"n\": 7302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.38, \"learn_time_ms\": 8597.045, \"total_train_time_s\": 9.068099975585938}", "{\"n\": 7303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.98, \"learn_time_ms\": 8607.02, \"total_train_time_s\": 10.910767078399658}", "{\"n\": 7304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.98, \"learn_time_ms\": 8803.486, \"total_train_time_s\": 10.780909061431885}", "{\"n\": 7305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.49, \"learn_time_ms\": 8805.704, \"total_train_time_s\": 10.711851358413696}", "{\"n\": 7306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.3, \"learn_time_ms\": 8737.832, \"total_train_time_s\": 10.79219365119934}", "{\"n\": 7307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.3, \"learn_time_ms\": 8966.603, \"total_train_time_s\": 11.030764102935791}", "{\"n\": 7308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.94, \"learn_time_ms\": 9069.919, \"total_train_time_s\": 10.524853944778442}", "{\"n\": 7309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.94, \"learn_time_ms\": 8991.905, \"total_train_time_s\": 10.320735931396484}", "{\"n\": 7310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.22, \"learn_time_ms\": 8916.021, \"total_train_time_s\": 8.570152044296265}", "{\"n\": 7311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.27, \"learn_time_ms\": 8860.917, \"total_train_time_s\": 9.977718591690063}", "{\"n\": 7312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.75, \"learn_time_ms\": 8881.461, \"total_train_time_s\": 9.313042402267456}", "{\"n\": 7313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.75, \"learn_time_ms\": 8872.235, \"total_train_time_s\": 10.81072449684143}", "{\"n\": 7314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.67, \"learn_time_ms\": 8822.245, \"total_train_time_s\": 10.2776358127594}", "{\"n\": 7315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.68, \"learn_time_ms\": 8821.883, \"total_train_time_s\": 10.70058536529541}", "{\"n\": 7316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.05, \"learn_time_ms\": 8736.764, \"total_train_time_s\": 9.954311609268188}", "{\"n\": 7317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.05, \"learn_time_ms\": 8666.198, \"total_train_time_s\": 10.380923986434937}", "{\"n\": 7318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.33, \"learn_time_ms\": 8574.334, \"total_train_time_s\": 9.608649730682373}", "{\"n\": 7319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.29, \"learn_time_ms\": 8616.67, \"total_train_time_s\": 10.730633735656738}", "{\"n\": 7320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.29, \"learn_time_ms\": 8772.56, \"total_train_time_s\": 10.103407859802246}", "{\"n\": 7321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.5, \"learn_time_ms\": 8658.107, \"total_train_time_s\": 8.865651845932007}", "{\"n\": 7322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.38, \"learn_time_ms\": 8706.98, \"total_train_time_s\": 9.841954708099365}", "{\"n\": 7323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.38, \"learn_time_ms\": 8708.407, \"total_train_time_s\": 10.807850122451782}", "{\"n\": 7324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.33, \"learn_time_ms\": 8507.526, \"total_train_time_s\": 8.202573537826538}", "{\"n\": 7325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.61, \"learn_time_ms\": 8396.918, \"total_train_time_s\": 9.598520994186401}", "{\"n\": 7326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.93, \"learn_time_ms\": 8327.628, \"total_train_time_s\": 9.277148246765137}", "{\"n\": 7327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.93, \"learn_time_ms\": 8368.717, \"total_train_time_s\": 10.75680422782898}", "{\"n\": 7328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.62, \"learn_time_ms\": 8379.6, \"total_train_time_s\": 9.728957176208496}", "{\"n\": 7329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.15, \"learn_time_ms\": 8455.17, \"total_train_time_s\": 11.442308902740479}", "{\"n\": 7330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.15, \"learn_time_ms\": 8451.067, \"total_train_time_s\": 10.045163631439209}", "{\"n\": 7331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.68, \"learn_time_ms\": 8592.805, \"total_train_time_s\": 10.27311396598816}", "{\"n\": 7332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.06, \"learn_time_ms\": 8588.037, \"total_train_time_s\": 9.739844799041748}", "{\"n\": 7333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.06, \"learn_time_ms\": 8597.749, \"total_train_time_s\": 10.928112983703613}", "{\"n\": 7334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.03, \"learn_time_ms\": 8617.921, \"total_train_time_s\": 8.456473112106323}", "{\"n\": 7335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.32, \"learn_time_ms\": 8569.517, \"total_train_time_s\": 9.126834154129028}", "{\"n\": 7336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.32, \"learn_time_ms\": 8751.457, \"total_train_time_s\": 11.053080558776855}", "{\"n\": 7337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8597.912, \"total_train_time_s\": 9.245020151138306}", "{\"n\": 7338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.49, \"learn_time_ms\": 8484.116, \"total_train_time_s\": 8.604898452758789}", "{\"n\": 7339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.93, \"learn_time_ms\": 8397.861, \"total_train_time_s\": 10.59782099723816}", "{\"n\": 7340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.0, \"learn_time_ms\": 8464.715, \"total_train_time_s\": 10.69218397140503}", "{\"n\": 7341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.42, \"learn_time_ms\": 8331.853, \"total_train_time_s\": 8.891062259674072}", "{\"n\": 7342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.44, \"learn_time_ms\": 8257.287, \"total_train_time_s\": 8.94664478302002}", "{\"n\": 7343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.44, \"learn_time_ms\": 8125.725, \"total_train_time_s\": 9.650679111480713}", "{\"n\": 7344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.35, \"learn_time_ms\": 8206.545, \"total_train_time_s\": 9.272032260894775}", "{\"n\": 7345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.17, \"learn_time_ms\": 8172.164, \"total_train_time_s\": 8.791337490081787}", "{\"n\": 7346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.12, \"learn_time_ms\": 8150.867, \"total_train_time_s\": 10.877706050872803}", "{\"n\": 7347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.65, \"learn_time_ms\": 8241.595, \"total_train_time_s\": 10.126564264297485}", "{\"n\": 7348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.42, \"learn_time_ms\": 8432.037, \"total_train_time_s\": 10.449259757995605}", "{\"n\": 7349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.97, \"learn_time_ms\": 8252.081, \"total_train_time_s\": 8.840049743652344}", "{\"n\": 7350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.88, \"learn_time_ms\": 8319.501, \"total_train_time_s\": 11.448225975036621}", "{\"n\": 7351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.22, \"learn_time_ms\": 8312.215, \"total_train_time_s\": 8.833786010742188}", "{\"n\": 7352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.55, \"learn_time_ms\": 8489.768, \"total_train_time_s\": 10.771630048751831}", "{\"n\": 7353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.02, \"learn_time_ms\": 8386.039, \"total_train_time_s\": 8.55117154121399}", "{\"n\": 7354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.58, \"learn_time_ms\": 8462.872, \"total_train_time_s\": 10.009422063827515}", "{\"n\": 7355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.13, \"learn_time_ms\": 8576.863, \"total_train_time_s\": 9.922151565551758}", "{\"n\": 7356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.92, \"learn_time_ms\": 8460.767, \"total_train_time_s\": 9.679775714874268}", "{\"n\": 7357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.1, \"learn_time_ms\": 8441.846, \"total_train_time_s\": 9.90796971321106}", "{\"n\": 7358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.41, \"learn_time_ms\": 8301.891, \"total_train_time_s\": 9.048054933547974}", "{\"n\": 7359, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.41, \"learn_time_ms\": 8322.054, \"total_train_time_s\": 8.957332611083984}", "{\"n\": 7360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.36, \"learn_time_ms\": 8163.574, \"total_train_time_s\": 9.853822946548462}", "{\"n\": 7361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.56, \"learn_time_ms\": 8278.237, \"total_train_time_s\": 9.984440088272095}", "{\"n\": 7362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.56, \"learn_time_ms\": 8132.278, \"total_train_time_s\": 9.29853630065918}", "{\"n\": 7363, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.86, \"learn_time_ms\": 8227.669, \"total_train_time_s\": 9.542967081069946}", "{\"n\": 7364, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.41, \"learn_time_ms\": 8211.433, \"total_train_time_s\": 9.882271766662598}", "{\"n\": 7365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.43, \"learn_time_ms\": 8244.913, \"total_train_time_s\": 10.297867774963379}", "{\"n\": 7366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.24, \"learn_time_ms\": 8242.901, \"total_train_time_s\": 9.657682657241821}", "{\"n\": 7367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.43, \"learn_time_ms\": 8246.521, \"total_train_time_s\": 9.962791919708252}", "{\"n\": 7368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.19, \"learn_time_ms\": 8229.148, \"total_train_time_s\": 8.926992416381836}", "{\"n\": 7369, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.44, \"learn_time_ms\": 8270.017, \"total_train_time_s\": 9.443060636520386}", "{\"n\": 7370, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.05, \"learn_time_ms\": 8224.588, \"total_train_time_s\": 9.337003469467163}", "{\"n\": 7371, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.76, \"learn_time_ms\": 8283.495, \"total_train_time_s\": 10.561314105987549}", "{\"n\": 7372, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.91, \"learn_time_ms\": 8372.801, \"total_train_time_s\": 10.163335800170898}", "{\"n\": 7373, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.46, \"learn_time_ms\": 8563.642, \"total_train_time_s\": 11.396987199783325}", "{\"n\": 7374, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.54, \"learn_time_ms\": 8641.876, \"total_train_time_s\": 10.678944110870361}", "{\"n\": 7375, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.48, \"learn_time_ms\": 8497.677, \"total_train_time_s\": 8.770875692367554}", "{\"n\": 7376, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.48, \"learn_time_ms\": 8489.532, \"total_train_time_s\": 9.62592887878418}", "{\"n\": 7377, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.69, \"learn_time_ms\": 8418.165, \"total_train_time_s\": 9.247015237808228}", "{\"n\": 7378, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.27, \"learn_time_ms\": 8392.789, \"total_train_time_s\": 8.688360691070557}", "{\"n\": 7379, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.27, \"learn_time_ms\": 8396.537, \"total_train_time_s\": 9.44436264038086}", "{\"n\": 7380, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.66, \"learn_time_ms\": 8416.711, \"total_train_time_s\": 9.595002174377441}", "{\"n\": 7381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.18, \"learn_time_ms\": 8323.805, \"total_train_time_s\": 9.702415466308594}", "{\"n\": 7382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.18, \"learn_time_ms\": 8292.46, \"total_train_time_s\": 9.882083892822266}", "{\"n\": 7383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.18, \"learn_time_ms\": 8010.084, \"total_train_time_s\": 8.587361097335815}", "{\"n\": 7384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.44, \"learn_time_ms\": 7894.577, \"total_train_time_s\": 9.510056972503662}", "{\"n\": 7385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.44, \"learn_time_ms\": 8013.423, \"total_train_time_s\": 10.013271808624268}", "{\"n\": 7386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.44, \"learn_time_ms\": 8123.064, \"total_train_time_s\": 10.708157300949097}", "{\"n\": 7387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.86, \"learn_time_ms\": 8305.835, \"total_train_time_s\": 11.106694459915161}", "{\"n\": 7388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.44, \"learn_time_ms\": 8476.337, \"total_train_time_s\": 10.352707147598267}", "{\"n\": 7389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.44, \"learn_time_ms\": 8537.508, \"total_train_time_s\": 10.054256916046143}", "{\"n\": 7390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.82, \"learn_time_ms\": 8573.434, \"total_train_time_s\": 9.925110101699829}", "{\"n\": 7391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.07, \"learn_time_ms\": 8543.813, \"total_train_time_s\": 9.390631437301636}", "{\"n\": 7392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.07, \"learn_time_ms\": 8607.722, \"total_train_time_s\": 10.531681299209595}", "{\"n\": 7393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.61, \"learn_time_ms\": 8689.315, \"total_train_time_s\": 9.438807249069214}", "{\"n\": 7394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.76, \"learn_time_ms\": 8727.554, \"total_train_time_s\": 9.89957880973816}", "{\"n\": 7395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.76, \"learn_time_ms\": 8804.108, \"total_train_time_s\": 10.799299001693726}", "{\"n\": 7396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.76, \"learn_time_ms\": 8815.734, \"total_train_time_s\": 10.792918920516968}", "{\"n\": 7397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.92, \"learn_time_ms\": 8616.744, \"total_train_time_s\": 9.110480308532715}", "{\"n\": 7398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.92, \"learn_time_ms\": 8555.775, \"total_train_time_s\": 9.748313188552856}", "{\"n\": 7399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.92, \"learn_time_ms\": 8572.458, \"total_train_time_s\": 10.21683144569397}", "{\"n\": 7400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.62, \"learn_time_ms\": 8635.055, \"total_train_time_s\": 10.585092067718506}", "{\"n\": 7401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.62, \"learn_time_ms\": 8572.884, \"total_train_time_s\": 8.742952108383179}", "{\"n\": 7402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.62, \"learn_time_ms\": 8630.754, \"total_train_time_s\": 11.10033130645752}", "{\"n\": 7403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.11, \"learn_time_ms\": 8689.686, \"total_train_time_s\": 9.995646953582764}", "{\"n\": 7404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.96, \"learn_time_ms\": 8858.181, \"total_train_time_s\": 11.546967267990112}", "{\"n\": 7405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.96, \"learn_time_ms\": 8828.638, \"total_train_time_s\": 10.425922870635986}", "{\"n\": 7406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.4, \"learn_time_ms\": 8667.426, \"total_train_time_s\": 9.258395671844482}", "{\"n\": 7407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.38, \"learn_time_ms\": 8794.575, \"total_train_time_s\": 10.35751223564148}", "{\"n\": 7408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.38, \"learn_time_ms\": 8766.27, \"total_train_time_s\": 9.447471141815186}", "{\"n\": 7409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.67, \"learn_time_ms\": 8701.047, \"total_train_time_s\": 9.574985265731812}", "{\"n\": 7410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.75, \"learn_time_ms\": 8611.807, \"total_train_time_s\": 9.717225313186646}", "{\"n\": 7411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.75, \"learn_time_ms\": 8741.876, \"total_train_time_s\": 10.025953531265259}", "{\"n\": 7412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.85, \"learn_time_ms\": 8641.827, \"total_train_time_s\": 10.085782766342163}", "{\"n\": 7413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.86, \"learn_time_ms\": 8608.53, \"total_train_time_s\": 9.688185453414917}", "{\"n\": 7414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.86, \"learn_time_ms\": 8382.574, \"total_train_time_s\": 9.293889284133911}", "{\"n\": 7415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.12, \"learn_time_ms\": 8405.24, \"total_train_time_s\": 10.681926965713501}", "{\"n\": 7416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.11, \"learn_time_ms\": 8487.59, \"total_train_time_s\": 10.045626640319824}", "{\"n\": 7417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.11, \"learn_time_ms\": 8464.709, \"total_train_time_s\": 10.15333890914917}", "{\"n\": 7418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.86, \"learn_time_ms\": 8470.077, \"total_train_time_s\": 9.520077228546143}", "{\"n\": 7419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.09, \"learn_time_ms\": 8469.706, \"total_train_time_s\": 9.607816219329834}", "{\"n\": 7420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.44, \"learn_time_ms\": 8646.013, \"total_train_time_s\": 11.502042531967163}", "{\"n\": 7421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.37, \"learn_time_ms\": 8640.756, \"total_train_time_s\": 10.009194374084473}", "{\"n\": 7422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.28, \"learn_time_ms\": 8659.091, \"total_train_time_s\": 10.267767190933228}", "{\"n\": 7423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.08, \"learn_time_ms\": 8837.632, \"total_train_time_s\": 11.455398321151733}", "{\"n\": 7424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.42, \"learn_time_ms\": 8904.864, \"total_train_time_s\": 9.990938186645508}", "{\"n\": 7425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.39, \"learn_time_ms\": 8812.533, \"total_train_time_s\": 9.753675937652588}", "{\"n\": 7426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.6, \"learn_time_ms\": 8729.185, \"total_train_time_s\": 9.217325925827026}", "{\"n\": 7427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.07, \"learn_time_ms\": 8537.475, \"total_train_time_s\": 8.237955808639526}", "{\"n\": 7428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.84, \"learn_time_ms\": 8214.793, \"total_train_time_s\": 6.368220329284668}", "{\"n\": 7429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.26, \"learn_time_ms\": 7901.483, \"total_train_time_s\": 6.57784366607666}", "{\"n\": 7430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.44, \"learn_time_ms\": 7825.349, \"total_train_time_s\": 10.79948878288269}", "{\"n\": 7431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.76, \"learn_time_ms\": 7750.369, \"total_train_time_s\": 9.26110029220581}", "{\"n\": 7432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.41, \"learn_time_ms\": 7832.808, \"total_train_time_s\": 11.166158676147461}", "{\"n\": 7433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.67, \"learn_time_ms\": 7590.735, \"total_train_time_s\": 9.044382810592651}", "{\"n\": 7434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.71, \"learn_time_ms\": 7682.813, \"total_train_time_s\": 10.935933113098145}", "{\"n\": 7435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.37, \"learn_time_ms\": 7581.433, \"total_train_time_s\": 8.788644552230835}", "{\"n\": 7436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.18, \"learn_time_ms\": 7657.73, \"total_train_time_s\": 9.954347372055054}", "{\"n\": 7437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.51, \"learn_time_ms\": 7808.592, \"total_train_time_s\": 9.766955375671387}", "{\"n\": 7438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.35, \"learn_time_ms\": 8134.154, \"total_train_time_s\": 9.544701099395752}", "{\"n\": 7439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.05, \"learn_time_ms\": 8411.084, \"total_train_time_s\": 9.206321716308594}", "{\"n\": 7440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.16, \"learn_time_ms\": 8402.3, \"total_train_time_s\": 10.565803289413452}", "{\"n\": 7441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.16, \"learn_time_ms\": 8518.401, \"total_train_time_s\": 10.385401248931885}", "{\"n\": 7442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.94, \"learn_time_ms\": 8398.777, \"total_train_time_s\": 9.890518426895142}", "{\"n\": 7443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.78, \"learn_time_ms\": 8649.254, \"total_train_time_s\": 11.535712003707886}", "{\"n\": 7444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.78, \"learn_time_ms\": 8529.88, \"total_train_time_s\": 9.736373901367188}", "{\"n\": 7445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.06, \"learn_time_ms\": 8609.486, \"total_train_time_s\": 9.577097415924072}", "{\"n\": 7446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.06, \"learn_time_ms\": 8496.754, \"total_train_time_s\": 8.829076766967773}", "{\"n\": 7447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.18, \"learn_time_ms\": 8491.455, \"total_train_time_s\": 9.682856798171997}", "{\"n\": 7448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.62, \"learn_time_ms\": 8330.946, \"total_train_time_s\": 7.914529323577881}", "{\"n\": 7449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.34, \"learn_time_ms\": 8324.649, \"total_train_time_s\": 9.127554655075073}", "{\"n\": 7450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.02, \"learn_time_ms\": 8325.217, \"total_train_time_s\": 10.594367265701294}", "{\"n\": 7451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.02, \"learn_time_ms\": 8421.655, \"total_train_time_s\": 11.393343210220337}", "{\"n\": 7452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.24, \"learn_time_ms\": 8384.583, \"total_train_time_s\": 9.510329008102417}", "{\"n\": 7453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.71, \"learn_time_ms\": 8314.506, \"total_train_time_s\": 10.836733341217041}", "{\"n\": 7454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.71, \"learn_time_ms\": 8384.045, \"total_train_time_s\": 10.38261365890503}", "{\"n\": 7455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.3, \"learn_time_ms\": 8417.843, \"total_train_time_s\": 9.90068531036377}", "{\"n\": 7456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.56, \"learn_time_ms\": 8346.814, \"total_train_time_s\": 8.132665395736694}", "{\"n\": 7457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.41, \"learn_time_ms\": 8351.201, \"total_train_time_s\": 9.71618938446045}", "{\"n\": 7458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.65, \"learn_time_ms\": 8651.502, \"total_train_time_s\": 10.952187061309814}", "{\"n\": 7459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.78, \"learn_time_ms\": 8866.261, \"total_train_time_s\": 11.268411874771118}", "{\"n\": 7460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.16, \"learn_time_ms\": 8796.345, \"total_train_time_s\": 9.897088766098022}", "{\"n\": 7461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.53, \"learn_time_ms\": 8738.588, \"total_train_time_s\": 10.810879230499268}", "{\"n\": 7462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.66, \"learn_time_ms\": 8711.253, \"total_train_time_s\": 9.262724161148071}", "{\"n\": 7463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.66, \"learn_time_ms\": 8665.236, \"total_train_time_s\": 10.383797645568848}", "{\"n\": 7464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.66, \"learn_time_ms\": 8639.218, \"total_train_time_s\": 10.11943793296814}", "{\"n\": 7465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.76, \"learn_time_ms\": 8623.829, \"total_train_time_s\": 9.750593900680542}", "{\"n\": 7466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.36, \"learn_time_ms\": 8904.061, \"total_train_time_s\": 10.919495820999146}", "{\"n\": 7467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.36, \"learn_time_ms\": 8802.37, \"total_train_time_s\": 8.697795152664185}", "{\"n\": 7468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.78, \"learn_time_ms\": 8715.683, \"total_train_time_s\": 10.044272184371948}", "{\"n\": 7469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.76, \"learn_time_ms\": 8486.601, \"total_train_time_s\": 8.992324829101562}", "{\"n\": 7470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.0, \"learn_time_ms\": 8400.443, \"total_train_time_s\": 8.986513137817383}", "{\"n\": 7471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.82, \"learn_time_ms\": 8446.434, \"total_train_time_s\": 11.18577241897583}", "{\"n\": 7472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.99, \"learn_time_ms\": 8496.861, \"total_train_time_s\": 9.745515823364258}", "{\"n\": 7473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.7, \"learn_time_ms\": 8322.727, \"total_train_time_s\": 8.630613088607788}", "{\"n\": 7474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.59, \"learn_time_ms\": 8411.785, \"total_train_time_s\": 11.017508506774902}", "{\"n\": 7475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.85, \"learn_time_ms\": 8534.116, \"total_train_time_s\": 10.959191799163818}", "{\"n\": 7476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.13, \"learn_time_ms\": 8415.291, \"total_train_time_s\": 9.746009588241577}", "{\"n\": 7477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.07, \"learn_time_ms\": 8458.116, \"total_train_time_s\": 9.114264011383057}", "{\"n\": 7478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.72, \"learn_time_ms\": 8369.077, \"total_train_time_s\": 9.182129144668579}", "{\"n\": 7479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.72, \"learn_time_ms\": 8337.619, \"total_train_time_s\": 8.688074588775635}", "{\"n\": 7480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.68, \"learn_time_ms\": 8387.306, \"total_train_time_s\": 9.542410612106323}", "{\"n\": 7481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.57, \"learn_time_ms\": 8265.4, \"total_train_time_s\": 10.060642957687378}", "{\"n\": 7482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.57, \"learn_time_ms\": 8358.89, \"total_train_time_s\": 10.718512296676636}", "{\"n\": 7483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.73, \"learn_time_ms\": 8353.656, \"total_train_time_s\": 8.559237241744995}", "{\"n\": 7484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.86, \"learn_time_ms\": 8299.309, \"total_train_time_s\": 10.471853494644165}", "{\"n\": 7485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.86, \"learn_time_ms\": 8179.319, \"total_train_time_s\": 9.763403177261353}", "{\"n\": 7486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.75, \"learn_time_ms\": 8297.762, \"total_train_time_s\": 10.93584156036377}", "{\"n\": 7487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.25, \"learn_time_ms\": 8436.157, \"total_train_time_s\": 10.519148349761963}", "{\"n\": 7488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.9, \"learn_time_ms\": 8416.135, \"total_train_time_s\": 8.988724946975708}", "{\"n\": 7489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.24, \"learn_time_ms\": 8459.192, \"total_train_time_s\": 9.122562646865845}", "{\"n\": 7490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.24, \"learn_time_ms\": 8490.809, \"total_train_time_s\": 9.871118307113647}", "{\"n\": 7491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.1, \"learn_time_ms\": 8476.332, \"total_train_time_s\": 9.898657083511353}", "{\"n\": 7492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.14, \"learn_time_ms\": 8439.837, \"total_train_time_s\": 10.310519456863403}", "{\"n\": 7493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.14, \"learn_time_ms\": 8448.932, \"total_train_time_s\": 8.655395030975342}", "{\"n\": 7494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.53, \"learn_time_ms\": 8467.784, \"total_train_time_s\": 10.660544633865356}", "{\"n\": 7495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.78, \"learn_time_ms\": 8517.905, \"total_train_time_s\": 10.286930084228516}", "{\"n\": 7496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.78, \"learn_time_ms\": 8402.79, \"total_train_time_s\": 9.802827596664429}", "{\"n\": 7497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.33, \"learn_time_ms\": 8288.279, \"total_train_time_s\": 9.387635707855225}", "{\"n\": 7498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.13, \"learn_time_ms\": 8419.838, \"total_train_time_s\": 10.31716275215149}", "{\"n\": 7499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.68, \"learn_time_ms\": 8424.726, \"total_train_time_s\": 9.144056797027588}", "{\"n\": 7500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.42, \"learn_time_ms\": 8475.753, \"total_train_time_s\": 10.362469911575317}", "{\"n\": 7501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.54, \"learn_time_ms\": 8477.052, \"total_train_time_s\": 9.87914490699768}", "{\"n\": 7502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.46, \"learn_time_ms\": 8344.282, \"total_train_time_s\": 9.019951343536377}", "{\"n\": 7503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.34, \"learn_time_ms\": 8463.259, \"total_train_time_s\": 9.88616132736206}", "{\"n\": 7504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.3, \"learn_time_ms\": 8333.99, \"total_train_time_s\": 9.375158786773682}", "{\"n\": 7505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.24, \"learn_time_ms\": 8428.921, \"total_train_time_s\": 11.201117515563965}", "{\"n\": 7506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.68, \"learn_time_ms\": 8636.889, \"total_train_time_s\": 11.856091737747192}", "{\"n\": 7507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.99, \"learn_time_ms\": 8446.298, \"total_train_time_s\": 7.459672212600708}", "{\"n\": 7508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.25, \"learn_time_ms\": 8455.053, \"total_train_time_s\": 10.396691083908081}", "{\"n\": 7509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.35, \"learn_time_ms\": 8556.792, \"total_train_time_s\": 10.281353950500488}", "{\"n\": 7510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.95, \"learn_time_ms\": 8505.408, \"total_train_time_s\": 9.849401473999023}", "{\"n\": 7511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.14, \"learn_time_ms\": 8489.332, \"total_train_time_s\": 9.690659046173096}", "{\"n\": 7512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.35, \"learn_time_ms\": 8579.147, \"total_train_time_s\": 9.89988899230957}", "{\"n\": 7513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.31, \"learn_time_ms\": 8663.878, \"total_train_time_s\": 10.72804570198059}", "{\"n\": 7514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.31, \"learn_time_ms\": 8789.481, \"total_train_time_s\": 10.610490083694458}", "{\"n\": 7515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.83, \"learn_time_ms\": 8619.229, \"total_train_time_s\": 9.513055562973022}", "{\"n\": 7516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.83, \"learn_time_ms\": 8649.185, \"total_train_time_s\": 12.167675733566284}", "{\"n\": 7517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.86, \"learn_time_ms\": 8997.975, \"total_train_time_s\": 10.925956726074219}", "{\"n\": 7518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.65, \"learn_time_ms\": 9038.698, \"total_train_time_s\": 10.75318455696106}", "{\"n\": 7519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.74, \"learn_time_ms\": 9098.195, \"total_train_time_s\": 10.79826545715332}", "{\"n\": 7520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.33, \"learn_time_ms\": 9160.08, \"total_train_time_s\": 10.412509202957153}", "{\"n\": 7521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.47, \"learn_time_ms\": 9166.578, \"total_train_time_s\": 9.766603708267212}", "{\"n\": 7522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.88, \"learn_time_ms\": 8996.216, \"total_train_time_s\": 8.198846340179443}", "{\"n\": 7523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.24, \"learn_time_ms\": 8901.71, \"total_train_time_s\": 9.776078939437866}", "{\"n\": 7524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.75, \"learn_time_ms\": 8837.645, \"total_train_time_s\": 9.991122961044312}", "{\"n\": 7525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.78, \"learn_time_ms\": 8853.033, \"total_train_time_s\": 9.640233755111694}", "{\"n\": 7526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.07, \"learn_time_ms\": 8685.821, \"total_train_time_s\": 10.497988224029541}", "{\"n\": 7527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.08, \"learn_time_ms\": 8623.444, \"total_train_time_s\": 10.347942352294922}", "{\"n\": 7528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.32, \"learn_time_ms\": 8544.968, \"total_train_time_s\": 10.03087329864502}", "{\"n\": 7529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.87, \"learn_time_ms\": 8471.611, \"total_train_time_s\": 10.10394287109375}", "{\"n\": 7530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.89, \"learn_time_ms\": 8405.18, \"total_train_time_s\": 9.822581052780151}", "{\"n\": 7531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.89, \"learn_time_ms\": 8468.682, \"total_train_time_s\": 10.4442880153656}", "{\"n\": 7532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.56, \"learn_time_ms\": 8704.608, \"total_train_time_s\": 10.572007179260254}", "{\"n\": 7533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.93, \"learn_time_ms\": 8622.811, \"total_train_time_s\": 8.994959354400635}", "{\"n\": 7534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.61, \"learn_time_ms\": 8531.644, \"total_train_time_s\": 9.106691122055054}", "{\"n\": 7535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.02, \"learn_time_ms\": 8651.734, \"total_train_time_s\": 10.853439092636108}", "{\"n\": 7536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.43, \"learn_time_ms\": 8523.373, \"total_train_time_s\": 9.211735248565674}", "{\"n\": 7537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.92, \"learn_time_ms\": 8446.48, \"total_train_time_s\": 9.515130519866943}", "{\"n\": 7538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.31, \"learn_time_ms\": 8450.842, \"total_train_time_s\": 10.051198959350586}", "{\"n\": 7539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.31, \"learn_time_ms\": 8506.382, \"total_train_time_s\": 10.630576372146606}", "{\"n\": 7540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.99, \"learn_time_ms\": 8685.872, \"total_train_time_s\": 11.607997417449951}", "{\"n\": 7541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.52, \"learn_time_ms\": 8559.489, \"total_train_time_s\": 9.20246171951294}", "{\"n\": 7542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.52, \"learn_time_ms\": 8682.851, \"total_train_time_s\": 11.811588287353516}", "{\"n\": 7543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.04, \"learn_time_ms\": 8682.839, \"total_train_time_s\": 8.983433723449707}", "{\"n\": 7544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.67, \"learn_time_ms\": 8757.62, \"total_train_time_s\": 9.817565679550171}", "{\"n\": 7545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.67, \"learn_time_ms\": 8580.836, \"total_train_time_s\": 9.144075155258179}", "{\"n\": 7546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.5, \"learn_time_ms\": 8667.126, \"total_train_time_s\": 10.089680194854736}", "{\"n\": 7547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8653.899, \"total_train_time_s\": 9.442883968353271}", "{\"n\": 7548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8542.537, \"total_train_time_s\": 8.944403409957886}", "{\"n\": 7549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8521.68, \"total_train_time_s\": 10.388155698776245}", "{\"n\": 7550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.02, \"learn_time_ms\": 8328.633, \"total_train_time_s\": 9.623189687728882}", "{\"n\": 7551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.54, \"learn_time_ms\": 8380.966, \"total_train_time_s\": 9.683918237686157}", "{\"n\": 7552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.54, \"learn_time_ms\": 8216.707, \"total_train_time_s\": 10.14022707939148}", "{\"n\": 7553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.3, \"learn_time_ms\": 8477.305, \"total_train_time_s\": 11.58595061302185}", "{\"n\": 7554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.56, \"learn_time_ms\": 8564.023, \"total_train_time_s\": 10.706607818603516}", "{\"n\": 7555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.56, \"learn_time_ms\": 8649.855, \"total_train_time_s\": 9.915047645568848}", "{\"n\": 7556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.88, \"learn_time_ms\": 8640.087, \"total_train_time_s\": 9.934326648712158}", "{\"n\": 7557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.55, \"learn_time_ms\": 8738.018, \"total_train_time_s\": 10.393480777740479}", "{\"n\": 7558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.55, \"learn_time_ms\": 8784.338, \"total_train_time_s\": 9.420042276382446}", "{\"n\": 7559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.13, \"learn_time_ms\": 8691.847, \"total_train_time_s\": 9.470000982284546}", "{\"n\": 7560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.3, \"learn_time_ms\": 8794.599, \"total_train_time_s\": 10.695707321166992}", "{\"n\": 7561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.3, \"learn_time_ms\": 8896.131, \"total_train_time_s\": 10.714701175689697}", "{\"n\": 7562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.77, \"learn_time_ms\": 8696.915, \"total_train_time_s\": 8.148788452148438}", "{\"n\": 7563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.8, \"learn_time_ms\": 8694.755, \"total_train_time_s\": 11.48871636390686}", "{\"n\": 7564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.93, \"learn_time_ms\": 8494.909, \"total_train_time_s\": 8.700243473052979}", "{\"n\": 7565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.31, \"learn_time_ms\": 8552.678, \"total_train_time_s\": 10.578073024749756}", "{\"n\": 7566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.14, \"learn_time_ms\": 8730.613, \"total_train_time_s\": 11.70909333229065}", "{\"n\": 7567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.35, \"learn_time_ms\": 8626.281, \"total_train_time_s\": 9.378925323486328}", "{\"n\": 7568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.13, \"learn_time_ms\": 8759.383, \"total_train_time_s\": 10.747588396072388}", "{\"n\": 7569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.06, \"learn_time_ms\": 8869.083, \"total_train_time_s\": 10.529174089431763}", "{\"n\": 7570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.86, \"learn_time_ms\": 8708.158, \"total_train_time_s\": 9.037878513336182}", "{\"n\": 7571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.29, \"learn_time_ms\": 8628.231, \"total_train_time_s\": 9.902985334396362}", "{\"n\": 7572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.29, \"learn_time_ms\": 8725.88, \"total_train_time_s\": 9.147783279418945}", "{\"n\": 7573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.69, \"learn_time_ms\": 8542.64, \"total_train_time_s\": 9.72261095046997}", "{\"n\": 7574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.6, \"learn_time_ms\": 8611.975, \"total_train_time_s\": 9.3902108669281}", "{\"n\": 7575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.35, \"learn_time_ms\": 8626.749, \"total_train_time_s\": 10.668434143066406}", "{\"n\": 7576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.82, \"learn_time_ms\": 8431.124, \"total_train_time_s\": 9.727426528930664}", "{\"n\": 7577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.91, \"learn_time_ms\": 8584.244, \"total_train_time_s\": 10.83981728553772}", "{\"n\": 7578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.45, \"learn_time_ms\": 8467.939, \"total_train_time_s\": 9.72210168838501}", "{\"n\": 7579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.34, \"learn_time_ms\": 8487.036, \"total_train_time_s\": 10.748127698898315}", "{\"n\": 7580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.65, \"learn_time_ms\": 8595.199, \"total_train_time_s\": 10.182732105255127}", "{\"n\": 7581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.18, \"learn_time_ms\": 8757.911, \"total_train_time_s\": 11.547734498977661}", "{\"n\": 7582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.67, \"learn_time_ms\": 8924.254, \"total_train_time_s\": 10.814079523086548}", "{\"n\": 7583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.67, \"learn_time_ms\": 8894.656, \"total_train_time_s\": 9.396028757095337}", "{\"n\": 7584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.9, \"learn_time_ms\": 8959.196, \"total_train_time_s\": 10.021987915039062}", "{\"n\": 7585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.56, \"learn_time_ms\": 8939.345, \"total_train_time_s\": 10.499736070632935}", "{\"n\": 7586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.56, \"learn_time_ms\": 8928.375, \"total_train_time_s\": 9.670591115951538}", "{\"n\": 7587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.64, \"learn_time_ms\": 8737.66, \"total_train_time_s\": 8.967931509017944}", "{\"n\": 7588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.08, \"learn_time_ms\": 8813.958, \"total_train_time_s\": 10.3595449924469}", "{\"n\": 7589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.08, \"learn_time_ms\": 8746.543, \"total_train_time_s\": 10.087981224060059}", "{\"n\": 7590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.15, \"learn_time_ms\": 8606.376, \"total_train_time_s\": 8.798288583755493}", "{\"n\": 7591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.99, \"learn_time_ms\": 8425.327, \"total_train_time_s\": 9.782455444335938}", "{\"n\": 7592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.99, \"learn_time_ms\": 8300.277, \"total_train_time_s\": 9.588593244552612}", "{\"n\": 7593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.99, \"learn_time_ms\": 8336.365, \"total_train_time_s\": 9.758400201797485}", "{\"n\": 7594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8227.47, \"total_train_time_s\": 8.95060420036316}", "{\"n\": 7595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8200.617, \"total_train_time_s\": 10.192126512527466}", "{\"n\": 7596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8327.059, \"total_train_time_s\": 10.935939311981201}", "{\"n\": 7597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.23, \"learn_time_ms\": 8297.982, \"total_train_time_s\": 8.694303035736084}", "{\"n\": 7598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.2, \"learn_time_ms\": 8332.682, \"total_train_time_s\": 10.647592067718506}", "{\"n\": 7599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.2, \"learn_time_ms\": 8217.249, \"total_train_time_s\": 8.946576595306396}", "{\"n\": 7600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.23, \"learn_time_ms\": 8299.663, \"total_train_time_s\": 9.570571899414062}", "{\"n\": 7601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.41, \"learn_time_ms\": 8374.095, \"total_train_time_s\": 10.471996068954468}", "{\"n\": 7602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.41, \"learn_time_ms\": 8350.543, \"total_train_time_s\": 9.31387448310852}", "{\"n\": 7603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.82, \"learn_time_ms\": 8461.0, \"total_train_time_s\": 10.875472068786621}", "{\"n\": 7604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.01, \"learn_time_ms\": 8552.231, \"total_train_time_s\": 9.832103967666626}", "{\"n\": 7605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.01, \"learn_time_ms\": 8487.876, \"total_train_time_s\": 9.53809642791748}", "{\"n\": 7606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.45, \"learn_time_ms\": 8280.364, \"total_train_time_s\": 8.861942768096924}", "{\"n\": 7607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.26, \"learn_time_ms\": 8216.03, \"total_train_time_s\": 8.031396389007568}", "{\"n\": 7608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.26, \"learn_time_ms\": 8264.676, \"total_train_time_s\": 11.132265567779541}", "{\"n\": 7609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.04, \"learn_time_ms\": 8365.513, \"total_train_time_s\": 9.964051961898804}", "{\"n\": 7610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.0, \"learn_time_ms\": 8413.868, \"total_train_time_s\": 10.055121183395386}", "{\"n\": 7611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.79, \"learn_time_ms\": 8314.369, \"total_train_time_s\": 9.511020421981812}", "{\"n\": 7612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.81, \"learn_time_ms\": 8559.356, \"total_train_time_s\": 11.798366785049438}", "{\"n\": 7613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.1, \"learn_time_ms\": 8293.892, \"total_train_time_s\": 8.314354181289673}", "{\"n\": 7614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.1, \"learn_time_ms\": 8277.597, \"total_train_time_s\": 9.726152896881104}", "{\"n\": 7615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.77, \"learn_time_ms\": 8260.815, \"total_train_time_s\": 9.40995740890503}", "{\"n\": 7616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.78, \"learn_time_ms\": 8330.144, \"total_train_time_s\": 9.581452369689941}", "{\"n\": 7617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.78, \"learn_time_ms\": 8507.828, \"total_train_time_s\": 9.822372674942017}", "{\"n\": 7618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.38, \"learn_time_ms\": 8303.111, \"total_train_time_s\": 9.0909903049469}", "{\"n\": 7619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.33, \"learn_time_ms\": 8344.098, \"total_train_time_s\": 10.320819616317749}", "{\"n\": 7620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.28, \"learn_time_ms\": 8300.206, \"total_train_time_s\": 9.635603427886963}", "{\"n\": 7621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.29, \"learn_time_ms\": 8328.696, \"total_train_time_s\": 9.758540868759155}", "{\"n\": 7622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.12, \"learn_time_ms\": 8049.426, \"total_train_time_s\": 9.010850429534912}", "{\"n\": 7623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.56, \"learn_time_ms\": 8169.344, \"total_train_time_s\": 9.397790431976318}", "{\"n\": 7624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.66, \"learn_time_ms\": 8281.881, \"total_train_time_s\": 10.867687225341797}", "{\"n\": 7625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.42, \"learn_time_ms\": 8333.847, \"total_train_time_s\": 9.93759536743164}", "{\"n\": 7626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.78, \"learn_time_ms\": 8319.192, \"total_train_time_s\": 9.396070957183838}", "{\"n\": 7627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.39, \"learn_time_ms\": 8276.738, \"total_train_time_s\": 9.441480159759521}", "{\"n\": 7628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.54, \"learn_time_ms\": 8449.472, \"total_train_time_s\": 10.84412693977356}", "{\"n\": 7629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.54, \"learn_time_ms\": 8425.91, \"total_train_time_s\": 10.132439613342285}", "{\"n\": 7630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.84, \"learn_time_ms\": 8357.583, \"total_train_time_s\": 8.942710161209106}", "{\"n\": 7631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.45, \"learn_time_ms\": 8499.648, \"total_train_time_s\": 11.193088293075562}", "{\"n\": 7632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.45, \"learn_time_ms\": 8500.778, \"total_train_time_s\": 9.000429630279541}", "{\"n\": 7633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.36, \"learn_time_ms\": 8641.007, \"total_train_time_s\": 10.804362297058105}", "{\"n\": 7634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.36, \"learn_time_ms\": 8562.309, \"total_train_time_s\": 10.062020301818848}", "{\"n\": 7635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.94, \"learn_time_ms\": 8501.585, \"total_train_time_s\": 9.335011959075928}", "{\"n\": 7636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.94, \"learn_time_ms\": 8567.684, \"total_train_time_s\": 10.059492588043213}", "{\"n\": 7637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.19, \"learn_time_ms\": 8644.663, \"total_train_time_s\": 10.158551216125488}", "{\"n\": 7638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.64, \"learn_time_ms\": 8612.784, \"total_train_time_s\": 10.509554386138916}", "{\"n\": 7639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.41, \"learn_time_ms\": 8474.886, \"total_train_time_s\": 8.737602949142456}", "{\"n\": 7640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.9, \"learn_time_ms\": 8544.411, \"total_train_time_s\": 9.665780067443848}", "{\"n\": 7641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.9, \"learn_time_ms\": 8461.408, \"total_train_time_s\": 10.383485555648804}", "{\"n\": 7642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.71, \"learn_time_ms\": 8634.424, \"total_train_time_s\": 10.711051225662231}", "{\"n\": 7643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.46, \"learn_time_ms\": 8560.726, \"total_train_time_s\": 10.119011640548706}", "{\"n\": 7644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.46, \"learn_time_ms\": 8621.292, \"total_train_time_s\": 10.601008653640747}", "{\"n\": 7645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.14, \"learn_time_ms\": 8705.183, \"total_train_time_s\": 10.126188039779663}", "{\"n\": 7646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.14, \"learn_time_ms\": 8666.14, \"total_train_time_s\": 9.644493579864502}", "{\"n\": 7647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.39, \"learn_time_ms\": 8695.329, \"total_train_time_s\": 10.435435771942139}", "{\"n\": 7648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.45, \"learn_time_ms\": 8563.637, \"total_train_time_s\": 9.203946113586426}", "{\"n\": 7649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.42, \"learn_time_ms\": 8664.628, \"total_train_time_s\": 9.731743812561035}", "{\"n\": 7650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.09, \"learn_time_ms\": 8728.688, \"total_train_time_s\": 10.274306297302246}", "{\"n\": 7651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.09, \"learn_time_ms\": 8720.726, \"total_train_time_s\": 10.276152849197388}", "{\"n\": 7652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.42, \"learn_time_ms\": 8652.166, \"total_train_time_s\": 10.049098014831543}", "{\"n\": 7653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.82, \"learn_time_ms\": 8628.939, \"total_train_time_s\": 9.83615756034851}", "{\"n\": 7654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8555.858, \"total_train_time_s\": 9.917149066925049}", "{\"n\": 7655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.77, \"learn_time_ms\": 8574.508, \"total_train_time_s\": 10.33754825592041}", "{\"n\": 7656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.11, \"learn_time_ms\": 8545.692, \"total_train_time_s\": 9.425005435943604}", "{\"n\": 7657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.84, \"learn_time_ms\": 8471.24, \"total_train_time_s\": 9.728039026260376}", "{\"n\": 7658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.77, \"learn_time_ms\": 8588.651, \"total_train_time_s\": 10.38176941871643}", "{\"n\": 7659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.25, \"learn_time_ms\": 8612.439, \"total_train_time_s\": 9.96606159210205}", "{\"n\": 7660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.33, \"learn_time_ms\": 8493.137, \"total_train_time_s\": 9.042760372161865}", "{\"n\": 7661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.31, \"learn_time_ms\": 8572.144, \"total_train_time_s\": 11.06148624420166}", "{\"n\": 7662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.31, \"learn_time_ms\": 8587.086, \"total_train_time_s\": 10.18912672996521}", "{\"n\": 7663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.43, \"learn_time_ms\": 8769.538, \"total_train_time_s\": 11.69444727897644}", "{\"n\": 7664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.43, \"learn_time_ms\": 8629.288, \"total_train_time_s\": 8.512400150299072}", "{\"n\": 7665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.43, \"learn_time_ms\": 8516.374, \"total_train_time_s\": 9.2073392868042}", "{\"n\": 7666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.09, \"learn_time_ms\": 8674.054, \"total_train_time_s\": 10.99099087715149}", "{\"n\": 7667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.85, \"learn_time_ms\": 8792.019, \"total_train_time_s\": 10.95049786567688}", "{\"n\": 7668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.14, \"learn_time_ms\": 8694.606, \"total_train_time_s\": 9.411527872085571}", "{\"n\": 7669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.41, \"learn_time_ms\": 8702.468, \"total_train_time_s\": 10.084097623825073}", "{\"n\": 7670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.86, \"learn_time_ms\": 8793.644, \"total_train_time_s\": 10.026630878448486}", "{\"n\": 7671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.86, \"learn_time_ms\": 8730.754, \"total_train_time_s\": 10.428521871566772}", "{\"n\": 7672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.35, \"learn_time_ms\": 8634.354, \"total_train_time_s\": 9.233713388442993}", "{\"n\": 7673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.72, \"learn_time_ms\": 8527.475, \"total_train_time_s\": 10.5896475315094}", "{\"n\": 7674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.89, \"learn_time_ms\": 8490.603, \"total_train_time_s\": 8.091550827026367}", "{\"n\": 7675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.53, \"learn_time_ms\": 8581.742, \"total_train_time_s\": 10.072932720184326}", "{\"n\": 7676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.24, \"learn_time_ms\": 8437.038, \"total_train_time_s\": 9.478405714035034}", "{\"n\": 7677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.04, \"learn_time_ms\": 8284.361, \"total_train_time_s\": 9.365718126296997}", "{\"n\": 7678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.04, \"learn_time_ms\": 8361.842, \"total_train_time_s\": 10.16235613822937}", "{\"n\": 7679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.7, \"learn_time_ms\": 8399.693, \"total_train_time_s\": 10.438243627548218}", "{\"n\": 7680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.81, \"learn_time_ms\": 8286.062, \"total_train_time_s\": 8.856725692749023}", "{\"n\": 7681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.94, \"learn_time_ms\": 8237.677, \"total_train_time_s\": 9.926616668701172}", "{\"n\": 7682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.28, \"learn_time_ms\": 8225.885, \"total_train_time_s\": 9.142889976501465}", "{\"n\": 7683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.09, \"learn_time_ms\": 8114.651, \"total_train_time_s\": 9.533557653427124}", "{\"n\": 7684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.09, \"learn_time_ms\": 8281.439, \"total_train_time_s\": 9.823390245437622}", "{\"n\": 7685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.33, \"learn_time_ms\": 8312.824, \"total_train_time_s\": 10.469098806381226}", "{\"n\": 7686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.88, \"learn_time_ms\": 8489.927, \"total_train_time_s\": 11.30591893196106}", "{\"n\": 7687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.6, \"learn_time_ms\": 8586.559, \"total_train_time_s\": 10.324182271957397}", "{\"n\": 7688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.91, \"learn_time_ms\": 8600.922, \"total_train_time_s\": 10.326627969741821}", "{\"n\": 7689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.88, \"learn_time_ms\": 8622.482, \"total_train_time_s\": 10.66595721244812}", "{\"n\": 7690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.07, \"learn_time_ms\": 8795.223, \"total_train_time_s\": 10.556297779083252}", "{\"n\": 7691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.16, \"learn_time_ms\": 8817.772, \"total_train_time_s\": 10.191981077194214}", "{\"n\": 7692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.16, \"learn_time_ms\": 8839.575, \"total_train_time_s\": 9.329589366912842}", "{\"n\": 7693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.89, \"learn_time_ms\": 8939.393, \"total_train_time_s\": 10.515765190124512}", "{\"n\": 7694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.41, \"learn_time_ms\": 8992.189, \"total_train_time_s\": 10.325515031814575}", "{\"n\": 7695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.58, \"learn_time_ms\": 8810.238, \"total_train_time_s\": 8.645441770553589}", "{\"n\": 7696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.56, \"learn_time_ms\": 8573.295, \"total_train_time_s\": 8.905914545059204}", "{\"n\": 7697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.88, \"learn_time_ms\": 8525.328, \"total_train_time_s\": 9.881892681121826}", "{\"n\": 7698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.65, \"learn_time_ms\": 8507.006, \"total_train_time_s\": 10.139378547668457}", "{\"n\": 7699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.96, \"learn_time_ms\": 8438.982, \"total_train_time_s\": 10.13708209991455}", "{\"n\": 7700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.73, \"learn_time_ms\": 8332.057, \"total_train_time_s\": 9.498313903808594}", "{\"n\": 7701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.49, \"learn_time_ms\": 8358.346, \"total_train_time_s\": 10.44545602798462}", "{\"n\": 7702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.56, \"learn_time_ms\": 8353.102, \"total_train_time_s\": 9.321936845779419}", "{\"n\": 7703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.54, \"learn_time_ms\": 8106.158, \"total_train_time_s\": 8.010990381240845}", "{\"n\": 7704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.04, \"learn_time_ms\": 8165.341, \"total_train_time_s\": 10.862282752990723}", "{\"n\": 7705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.04, \"learn_time_ms\": 8338.551, \"total_train_time_s\": 10.333825588226318}", "{\"n\": 7706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.57, \"learn_time_ms\": 8418.55, \"total_train_time_s\": 9.734955787658691}", "{\"n\": 7707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.1, \"learn_time_ms\": 8532.631, \"total_train_time_s\": 10.985046148300171}", "{\"n\": 7708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8420.352, \"total_train_time_s\": 8.985092163085938}", "{\"n\": 7709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.99, \"learn_time_ms\": 8563.923, \"total_train_time_s\": 11.399502515792847}", "{\"n\": 7710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.33, \"learn_time_ms\": 8735.504, \"total_train_time_s\": 11.234506607055664}", "{\"n\": 7711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.33, \"learn_time_ms\": 8849.575, \"total_train_time_s\": 11.587170600891113}", "{\"n\": 7712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.23, \"learn_time_ms\": 8954.068, \"total_train_time_s\": 10.35014271736145}", "{\"n\": 7713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.19, \"learn_time_ms\": 9084.577, \"total_train_time_s\": 9.341485023498535}", "{\"n\": 7714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.19, \"learn_time_ms\": 9081.11, \"total_train_time_s\": 10.906726360321045}", "{\"n\": 7715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.6, \"learn_time_ms\": 9155.126, \"total_train_time_s\": 11.079379320144653}", "{\"n\": 7716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.37, \"learn_time_ms\": 9240.741, \"total_train_time_s\": 10.58981442451477}", "{\"n\": 7717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.4, \"learn_time_ms\": 9134.192, \"total_train_time_s\": 9.944971561431885}", "{\"n\": 7718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.92, \"learn_time_ms\": 9265.974, \"total_train_time_s\": 10.324954748153687}", "{\"n\": 7719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.51, \"learn_time_ms\": 9190.339, \"total_train_time_s\": 10.651052236557007}", "{\"n\": 7720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.62, \"learn_time_ms\": 9018.63, \"total_train_time_s\": 9.523755311965942}", "{\"n\": 7721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.07, \"learn_time_ms\": 8781.513, \"total_train_time_s\": 9.180605411529541}", "{\"n\": 7722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.79, \"learn_time_ms\": 8574.217, \"total_train_time_s\": 8.22999906539917}", "{\"n\": 7723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.81, \"learn_time_ms\": 8605.634, \"total_train_time_s\": 9.638110160827637}", "{\"n\": 7724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.81, \"learn_time_ms\": 8603.304, \"total_train_time_s\": 10.865211009979248}", "{\"n\": 7725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.17, \"learn_time_ms\": 8448.824, \"total_train_time_s\": 9.609796524047852}", "{\"n\": 7726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.21, \"learn_time_ms\": 8318.198, \"total_train_time_s\": 9.304687738418579}", "{\"n\": 7727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.21, \"learn_time_ms\": 8524.626, \"total_train_time_s\": 11.991861820220947}", "{\"n\": 7728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.23, \"learn_time_ms\": 8450.617, \"total_train_time_s\": 9.638476133346558}", "{\"n\": 7729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.95, \"learn_time_ms\": 8283.007, \"total_train_time_s\": 8.99582552909851}", "{\"n\": 7730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.95, \"learn_time_ms\": 8335.48, \"total_train_time_s\": 10.003162145614624}", "{\"n\": 7731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.59, \"learn_time_ms\": 8614.055, \"total_train_time_s\": 12.02224063873291}", "{\"n\": 7732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.9, \"learn_time_ms\": 8805.964, \"total_train_time_s\": 10.201085805892944}", "{\"n\": 7733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.9, \"learn_time_ms\": 8868.105, \"total_train_time_s\": 10.276395320892334}", "{\"n\": 7734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.6, \"learn_time_ms\": 8787.767, \"total_train_time_s\": 10.090448379516602}", "{\"n\": 7735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.82, \"learn_time_ms\": 8837.612, \"total_train_time_s\": 10.05892825126648}", "{\"n\": 7736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.11, \"learn_time_ms\": 8997.278, \"total_train_time_s\": 10.920853853225708}", "{\"n\": 7737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.11, \"learn_time_ms\": 8804.049, \"total_train_time_s\": 10.093005895614624}", "{\"n\": 7738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.35, \"learn_time_ms\": 8856.899, \"total_train_time_s\": 10.17228651046753}", "{\"n\": 7739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.91, \"learn_time_ms\": 8838.965, \"total_train_time_s\": 8.80529260635376}", "{\"n\": 7740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.91, \"learn_time_ms\": 8902.123, \"total_train_time_s\": 10.67778205871582}", "{\"n\": 7741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.11, \"learn_time_ms\": 8492.919, \"total_train_time_s\": 7.912119388580322}", "{\"n\": 7742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.13, \"learn_time_ms\": 8387.224, \"total_train_time_s\": 9.106632471084595}", "{\"n\": 7743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.13, \"learn_time_ms\": 8301.448, \"total_train_time_s\": 9.405404567718506}", "{\"n\": 7744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.55, \"learn_time_ms\": 8284.93, \"total_train_time_s\": 9.928934097290039}", "{\"n\": 7745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.44, \"learn_time_ms\": 8224.919, \"total_train_time_s\": 9.443773031234741}", "{\"n\": 7746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.08, \"learn_time_ms\": 8230.004, \"total_train_time_s\": 10.910024642944336}", "{\"n\": 7747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.44, \"learn_time_ms\": 8306.188, \"total_train_time_s\": 10.817994594573975}", "{\"n\": 7748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.51, \"learn_time_ms\": 8281.351, \"total_train_time_s\": 9.855136394500732}", "{\"n\": 7749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.26, \"learn_time_ms\": 8261.267, \"total_train_time_s\": 8.598677635192871}", "{\"n\": 7750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.54, \"learn_time_ms\": 8164.812, \"total_train_time_s\": 9.719105005264282}", "{\"n\": 7751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.54, \"learn_time_ms\": 8295.387, \"total_train_time_s\": 9.205134630203247}", "{\"n\": 7752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.45, \"learn_time_ms\": 8294.542, \"total_train_time_s\": 9.141230583190918}", "{\"n\": 7753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.88, \"learn_time_ms\": 8514.422, \"total_train_time_s\": 11.622749328613281}", "{\"n\": 7754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.88, \"learn_time_ms\": 8467.721, \"total_train_time_s\": 9.392887115478516}", "{\"n\": 7755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.47, \"learn_time_ms\": 8456.392, \"total_train_time_s\": 9.372106552124023}", "{\"n\": 7756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.82, \"learn_time_ms\": 8406.231, \"total_train_time_s\": 10.413992166519165}", "{\"n\": 7757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.82, \"learn_time_ms\": 8335.546, \"total_train_time_s\": 10.128912925720215}", "{\"n\": 7758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.13, \"learn_time_ms\": 8295.365, \"total_train_time_s\": 9.472288131713867}", "{\"n\": 7759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.61, \"learn_time_ms\": 8482.091, \"total_train_time_s\": 10.572799921035767}", "{\"n\": 7760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.71, \"learn_time_ms\": 8495.388, \"total_train_time_s\": 9.813817262649536}", "{\"n\": 7761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.5, \"learn_time_ms\": 8502.424, \"total_train_time_s\": 9.289906740188599}", "{\"n\": 7762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.5, \"learn_time_ms\": 8614.298, \"total_train_time_s\": 10.223950624465942}", "{\"n\": 7763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.55, \"learn_time_ms\": 8561.755, \"total_train_time_s\": 11.096138954162598}", "{\"n\": 7764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.27, \"learn_time_ms\": 8476.825, \"total_train_time_s\": 8.579273462295532}", "{\"n\": 7765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.27, \"learn_time_ms\": 8540.875, \"total_train_time_s\": 9.96289324760437}", "{\"n\": 7766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.64, \"learn_time_ms\": 8499.831, \"total_train_time_s\": 10.011327028274536}", "{\"n\": 7767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.88, \"learn_time_ms\": 8459.34, \"total_train_time_s\": 9.732996463775635}", "{\"n\": 7768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.23, \"learn_time_ms\": 8603.306, \"total_train_time_s\": 10.924015283584595}", "{\"n\": 7769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.98, \"learn_time_ms\": 8553.445, \"total_train_time_s\": 9.938448905944824}", "{\"n\": 7770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.88, \"learn_time_ms\": 8632.162, \"total_train_time_s\": 10.587557077407837}", "{\"n\": 7771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.88, \"learn_time_ms\": 8699.004, \"total_train_time_s\": 9.956843137741089}", "{\"n\": 7772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.14, \"learn_time_ms\": 8575.049, \"total_train_time_s\": 8.965084075927734}", "{\"n\": 7773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.46, \"learn_time_ms\": 8522.042, \"total_train_time_s\": 10.54797649383545}", "{\"n\": 7774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.73, \"learn_time_ms\": 8513.63, \"total_train_time_s\": 8.466256618499756}", "{\"n\": 7775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.69, \"learn_time_ms\": 8589.346, \"total_train_time_s\": 10.762915134429932}", "{\"n\": 7776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.86, \"learn_time_ms\": 8706.823, \"total_train_time_s\": 11.193429708480835}", "{\"n\": 7777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.61, \"learn_time_ms\": 8841.442, \"total_train_time_s\": 11.049806356430054}", "{\"n\": 7778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.7, \"learn_time_ms\": 8726.375, \"total_train_time_s\": 9.775311946868896}", "{\"n\": 7779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.27, \"learn_time_ms\": 8873.044, \"total_train_time_s\": 11.44778060913086}", "{\"n\": 7780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.97, \"learn_time_ms\": 8943.873, \"total_train_time_s\": 11.38356614112854}", "{\"n\": 7781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.81, \"learn_time_ms\": 8966.009, \"total_train_time_s\": 10.1739821434021}", "{\"n\": 7782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.93, \"learn_time_ms\": 8886.998, \"total_train_time_s\": 8.185695171356201}", "{\"n\": 7783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.93, \"learn_time_ms\": 8958.078, \"total_train_time_s\": 11.257571935653687}", "{\"n\": 7784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.81, \"learn_time_ms\": 9173.411, \"total_train_time_s\": 10.701881647109985}", "{\"n\": 7785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.39, \"learn_time_ms\": 9172.332, \"total_train_time_s\": 10.712715148925781}", "{\"n\": 7786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.01, \"learn_time_ms\": 9132.833, \"total_train_time_s\": 10.796550273895264}", "{\"n\": 7787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.3, \"learn_time_ms\": 8991.61, \"total_train_time_s\": 9.693694353103638}", "{\"n\": 7788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.3, \"learn_time_ms\": 8876.076, \"total_train_time_s\": 8.595555305480957}", "{\"n\": 7789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.85, \"learn_time_ms\": 8827.489, \"total_train_time_s\": 10.987990856170654}", "{\"n\": 7790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.88, \"learn_time_ms\": 8634.272, \"total_train_time_s\": 9.43944239616394}", "{\"n\": 7791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.54, \"learn_time_ms\": 8502.764, \"total_train_time_s\": 8.854583501815796}", "{\"n\": 7792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.42, \"learn_time_ms\": 8735.91, \"total_train_time_s\": 10.513184309005737}", "{\"n\": 7793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.35, \"learn_time_ms\": 8605.415, \"total_train_time_s\": 9.949888706207275}", "{\"n\": 7794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.56, \"learn_time_ms\": 8528.243, \"total_train_time_s\": 9.872058391571045}", "{\"n\": 7795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.56, \"learn_time_ms\": 8571.281, \"total_train_time_s\": 11.141480445861816}", "{\"n\": 7796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.28, \"learn_time_ms\": 8598.691, \"total_train_time_s\": 11.08055853843689}", "{\"n\": 7797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.32, \"learn_time_ms\": 8636.508, \"total_train_time_s\": 9.959569931030273}", "{\"n\": 7798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.32, \"learn_time_ms\": 8790.344, \"total_train_time_s\": 10.145015716552734}", "{\"n\": 7799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.9, \"learn_time_ms\": 8705.16, \"total_train_time_s\": 10.153041362762451}", "{\"n\": 7800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.58, \"learn_time_ms\": 8895.708, \"total_train_time_s\": 11.319735288619995}", "{\"n\": 7801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.35, \"learn_time_ms\": 8938.188, \"total_train_time_s\": 9.267048358917236}", "{\"n\": 7802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.35, \"learn_time_ms\": 8843.158, \"total_train_time_s\": 9.579031705856323}", "{\"n\": 7803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.39, \"learn_time_ms\": 8780.226, \"total_train_time_s\": 9.357189893722534}", "{\"n\": 7804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.94, \"learn_time_ms\": 8824.929, \"total_train_time_s\": 10.313591718673706}", "{\"n\": 7805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.94, \"learn_time_ms\": 8719.121, \"total_train_time_s\": 10.115930795669556}", "{\"n\": 7806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.99, \"learn_time_ms\": 8541.169, \"total_train_time_s\": 9.305145502090454}", "{\"n\": 7807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.3, \"learn_time_ms\": 8599.948, \"total_train_time_s\": 10.67197299003601}", "{\"n\": 7808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.3, \"learn_time_ms\": 8562.649, \"total_train_time_s\": 9.789076566696167}", "{\"n\": 7809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.33, \"learn_time_ms\": 8517.27, \"total_train_time_s\": 9.630887746810913}", "{\"n\": 7810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.22, \"learn_time_ms\": 8312.891, \"total_train_time_s\": 9.245090246200562}", "{\"n\": 7811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.22, \"learn_time_ms\": 8379.054, \"total_train_time_s\": 9.915984392166138}", "{\"n\": 7812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.1, \"learn_time_ms\": 8421.201, \"total_train_time_s\": 10.002076148986816}", "{\"n\": 7813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3257.38, \"learn_time_ms\": 8449.515, \"total_train_time_s\": 9.564902782440186}", "{\"n\": 7814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.26, \"learn_time_ms\": 8385.651, \"total_train_time_s\": 9.709771394729614}", "{\"n\": 7815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.22, \"learn_time_ms\": 8357.344, \"total_train_time_s\": 9.786173820495605}", "{\"n\": 7816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.22, \"learn_time_ms\": 8440.351, \"total_train_time_s\": 10.155722856521606}", "{\"n\": 7817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.25, \"learn_time_ms\": 8368.075, \"total_train_time_s\": 9.907823085784912}", "{\"n\": 7818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.05, \"learn_time_ms\": 8477.712, \"total_train_time_s\": 10.871540546417236}", "{\"n\": 7819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.05, \"learn_time_ms\": 8663.153, \"total_train_time_s\": 11.489418029785156}", "{\"n\": 7820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.63, \"learn_time_ms\": 8776.392, \"total_train_time_s\": 10.408932447433472}", "{\"n\": 7821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.31, \"learn_time_ms\": 8809.73, \"total_train_time_s\": 10.303442478179932}", "{\"n\": 7822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.31, \"learn_time_ms\": 8742.386, \"total_train_time_s\": 9.307249307632446}", "{\"n\": 7823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.83, \"learn_time_ms\": 8720.651, \"total_train_time_s\": 9.39998745918274}", "{\"n\": 7824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.21, \"learn_time_ms\": 8781.862, \"total_train_time_s\": 10.307315111160278}", "{\"n\": 7825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.76, \"learn_time_ms\": 8647.168, \"total_train_time_s\": 8.441313982009888}", "{\"n\": 7826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.76, \"learn_time_ms\": 8637.347, \"total_train_time_s\": 10.028608083724976}", "{\"n\": 7827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.48, \"learn_time_ms\": 8569.364, \"total_train_time_s\": 9.178472995758057}", "{\"n\": 7828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.21, \"learn_time_ms\": 8382.855, \"total_train_time_s\": 9.001272678375244}", "{\"n\": 7829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.21, \"learn_time_ms\": 8294.238, \"total_train_time_s\": 10.626677751541138}", "{\"n\": 7830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.71, \"learn_time_ms\": 8390.39, \"total_train_time_s\": 11.349084854125977}", "{\"n\": 7831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.85, \"learn_time_ms\": 8414.747, \"total_train_time_s\": 10.53179121017456}", "{\"n\": 7832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.85, \"learn_time_ms\": 8354.329, \"total_train_time_s\": 8.722143650054932}", "{\"n\": 7833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.08, \"learn_time_ms\": 8354.262, \"total_train_time_s\": 9.43653130531311}", "{\"n\": 7834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.2, \"learn_time_ms\": 8482.886, \"total_train_time_s\": 11.604289531707764}", "{\"n\": 7835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3305.32, \"learn_time_ms\": 8701.95, \"total_train_time_s\": 10.679599523544312}", "{\"n\": 7836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.23, \"learn_time_ms\": 8629.539, \"total_train_time_s\": 9.318825721740723}", "{\"n\": 7837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.21, \"learn_time_ms\": 8603.382, \"total_train_time_s\": 8.92132568359375}", "{\"n\": 7838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.82, \"learn_time_ms\": 8558.132, \"total_train_time_s\": 8.539782524108887}", "{\"n\": 7839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3293.61, \"learn_time_ms\": 8446.727, \"total_train_time_s\": 9.47140645980835}", "{\"n\": 7840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3290.12, \"learn_time_ms\": 8175.601, \"total_train_time_s\": 8.604599237442017}", "{\"n\": 7841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.5, \"learn_time_ms\": 7990.222, \"total_train_time_s\": 8.62715482711792}", "{\"n\": 7842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.5, \"learn_time_ms\": 7925.406, \"total_train_time_s\": 8.07658576965332}", "{\"n\": 7843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.17, \"learn_time_ms\": 8083.831, \"total_train_time_s\": 11.04076862335205}", "{\"n\": 7844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.58, \"learn_time_ms\": 7926.627, \"total_train_time_s\": 10.004918336868286}", "{\"n\": 7845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.58, \"learn_time_ms\": 7782.231, \"total_train_time_s\": 9.202171087265015}", "{\"n\": 7846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3293.71, \"learn_time_ms\": 7867.002, \"total_train_time_s\": 10.177235841751099}", "{\"n\": 7847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.91, \"learn_time_ms\": 7784.291, \"total_train_time_s\": 8.136138439178467}", "{\"n\": 7848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.91, \"learn_time_ms\": 7816.83, \"total_train_time_s\": 8.85939335823059}", "{\"n\": 7849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.88, \"learn_time_ms\": 7936.959, \"total_train_time_s\": 10.687652111053467}", "{\"n\": 7850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.49, \"learn_time_ms\": 7991.353, \"total_train_time_s\": 9.21973204612732}", "{\"n\": 7851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.53, \"learn_time_ms\": 8179.552, \"total_train_time_s\": 10.558822393417358}", "{\"n\": 7852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.43, \"learn_time_ms\": 8338.369, \"total_train_time_s\": 9.66418719291687}", "{\"n\": 7853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.55, \"learn_time_ms\": 8090.077, \"total_train_time_s\": 8.490460634231567}", "{\"n\": 7854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.38, \"learn_time_ms\": 8006.496, \"total_train_time_s\": 9.177081108093262}", "{\"n\": 7855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.38, \"learn_time_ms\": 7980.692, \"total_train_time_s\": 8.967445135116577}", "{\"n\": 7856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.92, \"learn_time_ms\": 7803.323, \"total_train_time_s\": 8.354256868362427}", "{\"n\": 7857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.39, \"learn_time_ms\": 8017.638, \"total_train_time_s\": 10.26989459991455}", "{\"n\": 7858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.39, \"learn_time_ms\": 8109.988, \"total_train_time_s\": 9.863080263137817}", "{\"n\": 7859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.57, \"learn_time_ms\": 8074.611, \"total_train_time_s\": 10.380526781082153}", "{\"n\": 7860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.2, \"learn_time_ms\": 8215.862, \"total_train_time_s\": 10.588846206665039}", "{\"n\": 7861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.2, \"learn_time_ms\": 8131.006, \"total_train_time_s\": 9.663208484649658}", "{\"n\": 7862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.2, \"learn_time_ms\": 8156.685, \"total_train_time_s\": 9.893568515777588}", "{\"n\": 7863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3304.26, \"learn_time_ms\": 8324.758, \"total_train_time_s\": 10.194183588027954}", "{\"n\": 7864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.13, \"learn_time_ms\": 8392.287, \"total_train_time_s\": 9.894851922988892}", "{\"n\": 7865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.13, \"learn_time_ms\": 8495.186, \"total_train_time_s\": 9.980481624603271}", "{\"n\": 7866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3317.19, \"learn_time_ms\": 8548.963, \"total_train_time_s\": 8.922133684158325}", "{\"n\": 7867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.16, \"learn_time_ms\": 8490.233, \"total_train_time_s\": 9.711186170578003}", "{\"n\": 7868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.16, \"learn_time_ms\": 8519.525, \"total_train_time_s\": 10.076264381408691}", "{\"n\": 7869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 8504.231, \"total_train_time_s\": 10.23135232925415}", "{\"n\": 7870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.77, \"learn_time_ms\": 8537.63, \"total_train_time_s\": 10.93568730354309}", "{\"n\": 7871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.77, \"learn_time_ms\": 8583.785, \"total_train_time_s\": 10.108787775039673}", "{\"n\": 7872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.77, \"learn_time_ms\": 8655.844, \"total_train_time_s\": 10.652066946029663}", "{\"n\": 7873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.73, \"learn_time_ms\": 8538.004, \"total_train_time_s\": 8.980198383331299}", "{\"n\": 7874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.99, \"learn_time_ms\": 8565.638, \"total_train_time_s\": 10.15970492362976}", "{\"n\": 7875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.99, \"learn_time_ms\": 8619.023, \"total_train_time_s\": 10.54558777809143}", "{\"n\": 7876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.8, \"learn_time_ms\": 8768.147, \"total_train_time_s\": 10.38548731803894}", "{\"n\": 7877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.76, \"learn_time_ms\": 8742.808, \"total_train_time_s\": 9.455380916595459}", "{\"n\": 7878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.76, \"learn_time_ms\": 8742.18, \"total_train_time_s\": 10.099628448486328}", "{\"n\": 7879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3324.5, \"learn_time_ms\": 8666.697, \"total_train_time_s\": 9.433478832244873}", "{\"n\": 7880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3321.05, \"learn_time_ms\": 8690.108, \"total_train_time_s\": 11.342775583267212}", "{\"n\": 7881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3321.05, \"learn_time_ms\": 8599.312, \"total_train_time_s\": 9.315071821212769}", "{\"n\": 7882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.91, \"learn_time_ms\": 8472.29, \"total_train_time_s\": 9.380731344223022}", "{\"n\": 7883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.84, \"learn_time_ms\": 8622.75, \"total_train_time_s\": 10.497481107711792}", "{\"n\": 7884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.77, \"learn_time_ms\": 8696.785, \"total_train_time_s\": 10.880672931671143}", "{\"n\": 7885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.43, \"learn_time_ms\": 8798.395, \"total_train_time_s\": 11.538815259933472}", "{\"n\": 7886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.3, \"learn_time_ms\": 8660.057, \"total_train_time_s\": 9.060680389404297}", "{\"n\": 7887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.3, \"learn_time_ms\": 8927.25, \"total_train_time_s\": 12.130576372146606}", "{\"n\": 7888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.82, \"learn_time_ms\": 8889.757, \"total_train_time_s\": 9.72551155090332}", "{\"n\": 7889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.44, \"learn_time_ms\": 8994.31, \"total_train_time_s\": 10.506213188171387}", "{\"n\": 7890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.44, \"learn_time_ms\": 8947.993, \"total_train_time_s\": 10.690323114395142}", "{\"n\": 7891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.87, \"learn_time_ms\": 8842.485, \"total_train_time_s\": 8.18059778213501}", "{\"n\": 7892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.39, \"learn_time_ms\": 8852.205, \"total_train_time_s\": 9.448666095733643}", "{\"n\": 7893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.8, \"learn_time_ms\": 8857.165, \"total_train_time_s\": 10.603835344314575}", "{\"n\": 7894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.4, \"learn_time_ms\": 8818.289, \"total_train_time_s\": 10.471057891845703}", "{\"n\": 7895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.11, \"learn_time_ms\": 8625.932, \"total_train_time_s\": 9.593443393707275}", "{\"n\": 7896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.17, \"learn_time_ms\": 8742.64, \"total_train_time_s\": 10.159088611602783}", "{\"n\": 7897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.03, \"learn_time_ms\": 8601.71, \"total_train_time_s\": 10.639129638671875}", "{\"n\": 7898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3303.89, \"learn_time_ms\": 8650.931, \"total_train_time_s\": 10.173548698425293}", "{\"n\": 7899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.79, \"learn_time_ms\": 8615.014, \"total_train_time_s\": 10.092634677886963}", "{\"n\": 7900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.79, \"learn_time_ms\": 8533.63, \"total_train_time_s\": 9.890047311782837}", "{\"n\": 7901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.3, \"learn_time_ms\": 8638.136, \"total_train_time_s\": 9.272006511688232}", "{\"n\": 7902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.56, \"learn_time_ms\": 8721.717, \"total_train_time_s\": 10.339321613311768}", "{\"n\": 7903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3291.34, \"learn_time_ms\": 8618.577, \"total_train_time_s\": 9.53191614151001}", "{\"n\": 7904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.18, \"learn_time_ms\": 8604.584, \"total_train_time_s\": 10.333000421524048}", "{\"n\": 7905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.62, \"learn_time_ms\": 8587.238, \"total_train_time_s\": 9.439003705978394}", "{\"n\": 7906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3294.1, \"learn_time_ms\": 8637.661, \"total_train_time_s\": 10.664507389068604}", "{\"n\": 7907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.53, \"learn_time_ms\": 8455.163, \"total_train_time_s\": 8.811724424362183}", "{\"n\": 7908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.53, \"learn_time_ms\": 8368.392, \"total_train_time_s\": 9.319669008255005}", "{\"n\": 7909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3303.11, \"learn_time_ms\": 8319.416, \"total_train_time_s\": 9.66727328300476}", "{\"n\": 7910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3303.11, \"learn_time_ms\": 8476.908, \"total_train_time_s\": 11.490279197692871}", "{\"n\": 7911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3299.21, \"learn_time_ms\": 8594.465, \"total_train_time_s\": 10.421581506729126}", "{\"n\": 7912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.54, \"learn_time_ms\": 8705.762, \"total_train_time_s\": 11.408043146133423}", "{\"n\": 7913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.22, \"learn_time_ms\": 8792.25, \"total_train_time_s\": 10.389631986618042}", "{\"n\": 7914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.44, \"learn_time_ms\": 8792.363, \"total_train_time_s\": 10.392093658447266}", "{\"n\": 7915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.53, \"learn_time_ms\": 8893.406, \"total_train_time_s\": 10.480161428451538}", "{\"n\": 7916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3303.21, \"learn_time_ms\": 8971.806, \"total_train_time_s\": 11.453283309936523}", "{\"n\": 7917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.47, \"learn_time_ms\": 9149.438, \"total_train_time_s\": 10.629703044891357}", "{\"n\": 7918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.47, \"learn_time_ms\": 9195.323, \"total_train_time_s\": 9.805411577224731}", "{\"n\": 7919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.99, \"learn_time_ms\": 9197.708, \"total_train_time_s\": 9.67581295967102}", "{\"n\": 7920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.99, \"learn_time_ms\": 8939.947, \"total_train_time_s\": 8.91211748123169}", "{\"n\": 7921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 9039.521, \"total_train_time_s\": 11.452718496322632}", "{\"n\": 7922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3317.87, \"learn_time_ms\": 8841.264, \"total_train_time_s\": 9.407812118530273}", "{\"n\": 7923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.12, \"learn_time_ms\": 8743.4, \"total_train_time_s\": 9.388898372650146}", "{\"n\": 7924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3315.45, \"learn_time_ms\": 8651.403, \"total_train_time_s\": 9.42659068107605}", "{\"n\": 7925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3315.71, \"learn_time_ms\": 8698.151, \"total_train_time_s\": 10.961780548095703}", "{\"n\": 7926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.87, \"learn_time_ms\": 8392.284, \"total_train_time_s\": 8.404232501983643}", "{\"n\": 7927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.63, \"learn_time_ms\": 8182.35, \"total_train_time_s\": 8.594295978546143}", "{\"n\": 7928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.32, \"learn_time_ms\": 8235.417, \"total_train_time_s\": 10.360036849975586}", "{\"n\": 7929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.41, \"learn_time_ms\": 8270.353, \"total_train_time_s\": 9.994847774505615}", "{\"n\": 7930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.41, \"learn_time_ms\": 8369.326, \"total_train_time_s\": 9.88648772239685}", "{\"n\": 7931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3304.77, \"learn_time_ms\": 8285.979, \"total_train_time_s\": 10.62979531288147}", "{\"n\": 7932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.41, \"learn_time_ms\": 8353.431, \"total_train_time_s\": 10.144700050354004}", "{\"n\": 7933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.41, \"learn_time_ms\": 8347.434, \"total_train_time_s\": 9.303544998168945}", "{\"n\": 7934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3304.54, \"learn_time_ms\": 8390.467, \"total_train_time_s\": 9.838667869567871}", "{\"n\": 7935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.64, \"learn_time_ms\": 8398.959, \"total_train_time_s\": 10.99373984336853}", "{\"n\": 7936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.95, \"learn_time_ms\": 8706.144, \"total_train_time_s\": 11.465065479278564}", "{\"n\": 7937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.95, \"learn_time_ms\": 8825.222, \"total_train_time_s\": 9.711093664169312}", "{\"n\": 7938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.02, \"learn_time_ms\": 8823.115, \"total_train_time_s\": 10.307893991470337}", "{\"n\": 7939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.91, \"learn_time_ms\": 8750.462, \"total_train_time_s\": 9.299670934677124}", "{\"n\": 7940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.64, \"learn_time_ms\": 8815.967, \"total_train_time_s\": 10.567434310913086}", "{\"n\": 7941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.81, \"learn_time_ms\": 8835.318, \"total_train_time_s\": 10.822808980941772}", "{\"n\": 7942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.38, \"learn_time_ms\": 8914.688, \"total_train_time_s\": 10.878276824951172}", "{\"n\": 7943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.38, \"learn_time_ms\": 8996.905, \"total_train_time_s\": 10.17566466331482}", "{\"n\": 7944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.52, \"learn_time_ms\": 8941.461, \"total_train_time_s\": 9.274003028869629}", "{\"n\": 7945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.06, \"learn_time_ms\": 8742.846, \"total_train_time_s\": 8.991545915603638}", "{\"n\": 7946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.06, \"learn_time_ms\": 8590.261, \"total_train_time_s\": 10.02617621421814}", "{\"n\": 7947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.13, \"learn_time_ms\": 8623.407, \"total_train_time_s\": 10.103716611862183}", "{\"n\": 7948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.81, \"learn_time_ms\": 8454.786, \"total_train_time_s\": 8.663619756698608}", "{\"n\": 7949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.81, \"learn_time_ms\": 8544.789, \"total_train_time_s\": 10.158492803573608}", "{\"n\": 7950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.5, \"learn_time_ms\": 8582.891, \"total_train_time_s\": 10.964273929595947}", "{\"n\": 7951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.97, \"learn_time_ms\": 8493.8, \"total_train_time_s\": 9.901714324951172}", "{\"n\": 7952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.19, \"learn_time_ms\": 8485.486, \"total_train_time_s\": 10.787715435028076}", "{\"n\": 7953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.19, \"learn_time_ms\": 8493.206, \"total_train_time_s\": 10.267377376556396}", "{\"n\": 7954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.88, \"learn_time_ms\": 8706.173, \"total_train_time_s\": 11.437556505203247}", "{\"n\": 7955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.13, \"learn_time_ms\": 8847.647, \"total_train_time_s\": 10.45038628578186}", "{\"n\": 7956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.13, \"learn_time_ms\": 8825.573, \"total_train_time_s\": 9.776444911956787}", "{\"n\": 7957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.26, \"learn_time_ms\": 8635.495, \"total_train_time_s\": 8.16697883605957}", "{\"n\": 7958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.26, \"learn_time_ms\": 8407.895, \"total_train_time_s\": 6.474210977554321}", "{\"n\": 7959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.26, \"learn_time_ms\": 8023.799, \"total_train_time_s\": 6.476706504821777}", "{\"n\": 7960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.78, \"learn_time_ms\": 7590.831, \"total_train_time_s\": 6.718830347061157}", "{\"n\": 7961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.38, \"learn_time_ms\": 7239.151, \"total_train_time_s\": 6.532972812652588}", "{\"n\": 7962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.39, \"learn_time_ms\": 6963.374, \"total_train_time_s\": 8.16231632232666}", "{\"n\": 7963, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.22, \"learn_time_ms\": 7042.005, \"total_train_time_s\": 11.034367084503174}", "{\"n\": 7964, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.85, \"learn_time_ms\": 7050.52, \"total_train_time_s\": 11.544496774673462}", "{\"n\": 7965, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.85, \"learn_time_ms\": 6942.23, \"total_train_time_s\": 9.33577585220337}", "{\"n\": 7966, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.63, \"learn_time_ms\": 6892.504, \"total_train_time_s\": 9.22907280921936}", "{\"n\": 7967, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3291.07, \"learn_time_ms\": 7041.598, \"total_train_time_s\": 9.636762857437134}", "{\"n\": 7968, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.35, \"learn_time_ms\": 7435.943, \"total_train_time_s\": 10.267441034317017}", "{\"n\": 7969, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.35, \"learn_time_ms\": 7718.577, \"total_train_time_s\": 9.187040090560913}", "{\"n\": 7970, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.21, \"learn_time_ms\": 8109.53, \"total_train_time_s\": 10.553487300872803}", "{\"n\": 7971, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.61, \"learn_time_ms\": 8334.073, \"total_train_time_s\": 8.627031803131104}", "{\"n\": 7972, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.61, \"learn_time_ms\": 8378.634, \"total_train_time_s\": 8.510855197906494}", "{\"n\": 7973, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3277.46, \"learn_time_ms\": 8288.464, \"total_train_time_s\": 10.14138388633728}", "{\"n\": 7974, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3277.46, \"learn_time_ms\": 8119.014, \"total_train_time_s\": 9.861303091049194}", "{\"n\": 7975, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.44, \"learn_time_ms\": 8146.657, \"total_train_time_s\": 9.64249849319458}", "{\"n\": 7976, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.09, \"learn_time_ms\": 8199.325, \"total_train_time_s\": 9.84372591972351}", "{\"n\": 7977, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.09, \"learn_time_ms\": 8202.852, \"total_train_time_s\": 9.679332494735718}", "{\"n\": 7978, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.95, \"learn_time_ms\": 8214.087, \"total_train_time_s\": 10.438453674316406}", "{\"n\": 7979, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.69, \"learn_time_ms\": 8370.569, \"total_train_time_s\": 10.768866062164307}", "{\"n\": 7980, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.56, \"learn_time_ms\": 8252.874, \"total_train_time_s\": 9.318758249282837}", "{\"n\": 7981, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.56, \"learn_time_ms\": 8482.649, \"total_train_time_s\": 10.882266283035278}", "{\"n\": 7982, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3276.1, \"learn_time_ms\": 8695.737, \"total_train_time_s\": 10.62133264541626}", "{\"n\": 7983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.5, \"learn_time_ms\": 8651.02, \"total_train_time_s\": 9.67000675201416}", "{\"n\": 7984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.5, \"learn_time_ms\": 8716.35, \"total_train_time_s\": 10.483453750610352}", "{\"n\": 7985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.34, \"learn_time_ms\": 8773.554, \"total_train_time_s\": 10.205546617507935}", "{\"n\": 7986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.03, \"learn_time_ms\": 8958.029, \"total_train_time_s\": 11.657041072845459}", "{\"n\": 7987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3276.24, \"learn_time_ms\": 9064.667, \"total_train_time_s\": 10.751827478408813}", "{\"n\": 7988, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.77, \"learn_time_ms\": 8956.8, \"total_train_time_s\": 9.407541275024414}", "{\"n\": 7989, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.49, \"learn_time_ms\": 8938.186, \"total_train_time_s\": 10.543963432312012}", "{\"n\": 7990, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3268.74, \"learn_time_ms\": 9150.787, \"total_train_time_s\": 11.426039218902588}", "{\"n\": 7991, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3268.74, \"learn_time_ms\": 9140.788, \"total_train_time_s\": 10.79024887084961}", "{\"n\": 7992, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.32, \"learn_time_ms\": 9151.081, \"total_train_time_s\": 10.745167255401611}", "{\"n\": 7993, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.07, \"learn_time_ms\": 9154.64, \"total_train_time_s\": 9.75102972984314}", "{\"n\": 7994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.07, \"learn_time_ms\": 9029.054, \"total_train_time_s\": 9.22295594215393}", "{\"n\": 7995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3264.67, \"learn_time_ms\": 9000.531, \"total_train_time_s\": 9.954530239105225}", "{\"n\": 7996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.35, \"learn_time_ms\": 8878.258, \"total_train_time_s\": 10.370537996292114}", "{\"n\": 7997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.35, \"learn_time_ms\": 8910.631, \"total_train_time_s\": 11.095706701278687}", "{\"n\": 7998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3261.06, \"learn_time_ms\": 8858.627, \"total_train_time_s\": 8.831578016281128}", "{\"n\": 7999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.35, \"learn_time_ms\": 8710.608, \"total_train_time_s\": 9.082280158996582}", "{\"n\": 8000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.35, \"learn_time_ms\": 8558.547, \"total_train_time_s\": 9.88011884689331}", "{\"n\": 8001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.87, \"learn_time_ms\": 8425.903, \"total_train_time_s\": 9.49638319015503}", "{\"n\": 8002, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.02, \"learn_time_ms\": 8371.656, \"total_train_time_s\": 10.178377866744995}", "{\"n\": 8003, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.02, \"learn_time_ms\": 8304.739, \"total_train_time_s\": 9.062962055206299}", "{\"n\": 8004, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.21, \"learn_time_ms\": 8291.869, \"total_train_time_s\": 9.077284812927246}", "{\"n\": 8005, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.13, \"learn_time_ms\": 8230.038, \"total_train_time_s\": 9.307771921157837}", "{\"n\": 8006, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.7, \"learn_time_ms\": 8148.963, \"total_train_time_s\": 9.549024820327759}", "{\"n\": 8007, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.7, \"learn_time_ms\": 7893.608, \"total_train_time_s\": 8.523719549179077}", "{\"n\": 8008, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.62, \"learn_time_ms\": 7947.594, \"total_train_time_s\": 9.288966655731201}", "{\"n\": 8009, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.27, \"learn_time_ms\": 8112.037, \"total_train_time_s\": 10.69005537033081}", "{\"n\": 8010, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.27, \"learn_time_ms\": 8157.771, \"total_train_time_s\": 10.359369039535522}", "{\"n\": 8011, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.33, \"learn_time_ms\": 8254.748, \"total_train_time_s\": 10.473767757415771}", "{\"n\": 8012, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.95, \"learn_time_ms\": 8398.098, \"total_train_time_s\": 11.605087995529175}", "{\"n\": 8013, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.95, \"learn_time_ms\": 8583.041, \"total_train_time_s\": 10.923231840133667}", "{\"n\": 8014, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.97, \"learn_time_ms\": 8643.271, \"total_train_time_s\": 9.723827838897705}", "{\"n\": 8015, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.97, \"learn_time_ms\": 8659.99, \"total_train_time_s\": 9.48346996307373}", "{\"n\": 8016, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.29, \"learn_time_ms\": 8724.983, \"total_train_time_s\": 10.227949857711792}", "{\"n\": 8017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.45, \"learn_time_ms\": 8899.504, \"total_train_time_s\": 10.278757810592651}", "{\"n\": 8018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.45, \"learn_time_ms\": 8952.269, \"total_train_time_s\": 9.833678245544434}", "{\"n\": 8019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.97, \"learn_time_ms\": 8857.292, \"total_train_time_s\": 9.759035587310791}", "{\"n\": 8020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.27, \"learn_time_ms\": 8669.211, \"total_train_time_s\": 8.50167202949524}", "{\"n\": 8021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.27, \"learn_time_ms\": 8657.921, \"total_train_time_s\": 10.387803316116333}", "{\"n\": 8022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.49, \"learn_time_ms\": 8562.392, \"total_train_time_s\": 10.642583131790161}", "{\"n\": 8023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.38, \"learn_time_ms\": 8444.383, \"total_train_time_s\": 9.726338624954224}", "{\"n\": 8024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.48, \"learn_time_ms\": 8497.039, \"total_train_time_s\": 10.181459903717041}", "{\"n\": 8025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.48, \"learn_time_ms\": 8669.049, \"total_train_time_s\": 11.159527778625488}", "{\"n\": 8026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.83, \"learn_time_ms\": 8707.974, \"total_train_time_s\": 10.680545091629028}", "{\"n\": 8027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.1, \"learn_time_ms\": 8722.362, \"total_train_time_s\": 10.42816972732544}", "{\"n\": 8028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.1, \"learn_time_ms\": 8551.639, \"total_train_time_s\": 8.170708894729614}", "{\"n\": 8029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.96, \"learn_time_ms\": 8532.428, \"total_train_time_s\": 9.544045448303223}", "{\"n\": 8030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8613.098, \"total_train_time_s\": 9.35357141494751}", "{\"n\": 8031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.83, \"learn_time_ms\": 8499.975, \"total_train_time_s\": 9.18383526802063}", "{\"n\": 8032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.76, \"learn_time_ms\": 8336.908, \"total_train_time_s\": 9.008571863174438}", "{\"n\": 8033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.76, \"learn_time_ms\": 8446.303, \"total_train_time_s\": 10.793360710144043}", "{\"n\": 8034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.15, \"learn_time_ms\": 8374.85, \"total_train_time_s\": 9.50243616104126}", "{\"n\": 8035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.36, \"learn_time_ms\": 8294.854, \"total_train_time_s\": 10.390199661254883}", "{\"n\": 8036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.27, \"learn_time_ms\": 8255.604, \"total_train_time_s\": 10.277084589004517}", "{\"n\": 8037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.89, \"learn_time_ms\": 8163.147, \"total_train_time_s\": 9.475693464279175}", "{\"n\": 8038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.72, \"learn_time_ms\": 8476.842, \"total_train_time_s\": 11.242091655731201}", "{\"n\": 8039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.44, \"learn_time_ms\": 8486.358, \"total_train_time_s\": 9.648748397827148}", "{\"n\": 8040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.21, \"learn_time_ms\": 8572.716, \"total_train_time_s\": 10.173861980438232}", "{\"n\": 8041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.3, \"learn_time_ms\": 8678.981, \"total_train_time_s\": 10.288763046264648}", "{\"n\": 8042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.96, \"learn_time_ms\": 8836.772, \"total_train_time_s\": 10.611949920654297}", "{\"n\": 8043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.94, \"learn_time_ms\": 8829.722, \"total_train_time_s\": 10.719673871994019}", "{\"n\": 8044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.84, \"learn_time_ms\": 8845.499, \"total_train_time_s\": 9.675796508789062}", "{\"n\": 8045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.84, \"learn_time_ms\": 8880.312, \"total_train_time_s\": 10.752056360244751}", "{\"n\": 8046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.74, \"learn_time_ms\": 8792.82, \"total_train_time_s\": 9.336805820465088}", "{\"n\": 8047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.68, \"learn_time_ms\": 8942.664, \"total_train_time_s\": 11.008285522460938}", "{\"n\": 8048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.68, \"learn_time_ms\": 8832.35, \"total_train_time_s\": 10.207047939300537}", "{\"n\": 8049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.41, \"learn_time_ms\": 8776.736, \"total_train_time_s\": 9.09194302558899}", "{\"n\": 8050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.41, \"learn_time_ms\": 8762.739, \"total_train_time_s\": 10.047576427459717}", "{\"n\": 8051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.4, \"learn_time_ms\": 8809.662, \"total_train_time_s\": 10.723517179489136}", "{\"n\": 8052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.66, \"learn_time_ms\": 8638.428, \"total_train_time_s\": 8.900007724761963}", "{\"n\": 8053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.64, \"learn_time_ms\": 8680.294, \"total_train_time_s\": 11.165638446807861}", "{\"n\": 8054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.64, \"learn_time_ms\": 8615.973, \"total_train_time_s\": 8.954799890518188}", "{\"n\": 8055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.64, \"learn_time_ms\": 8551.828, \"total_train_time_s\": 10.087570905685425}", "{\"n\": 8056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.86, \"learn_time_ms\": 8654.216, \"total_train_time_s\": 10.377678632736206}", "{\"n\": 8057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.79, \"learn_time_ms\": 8555.253, \"total_train_time_s\": 10.010275602340698}", "{\"n\": 8058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.79, \"learn_time_ms\": 8602.493, \"total_train_time_s\": 10.662965297698975}", "{\"n\": 8059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.08, \"learn_time_ms\": 8720.232, \"total_train_time_s\": 10.322027683258057}", "{\"n\": 8060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.04, \"learn_time_ms\": 8829.832, \"total_train_time_s\": 11.148974657058716}", "{\"n\": 8061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.04, \"learn_time_ms\": 8628.375, \"total_train_time_s\": 8.723536968231201}", "{\"n\": 8062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.93, \"learn_time_ms\": 8630.079, \"total_train_time_s\": 8.905824661254883}", "{\"n\": 8063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.68, \"learn_time_ms\": 8408.498, \"total_train_time_s\": 8.970658540725708}", "{\"n\": 8064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.75, \"learn_time_ms\": 8445.752, \"total_train_time_s\": 9.39342975616455}", "{\"n\": 8065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.75, \"learn_time_ms\": 8324.945, \"total_train_time_s\": 8.892873764038086}", "{\"n\": 8066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.15, \"learn_time_ms\": 8157.585, \"total_train_time_s\": 8.689891576766968}", "{\"n\": 8067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.92, \"learn_time_ms\": 8082.41, \"total_train_time_s\": 9.285012483596802}", "{\"n\": 8068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.37, \"learn_time_ms\": 8087.379, \"total_train_time_s\": 10.683181524276733}", "{\"n\": 8069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.37, \"learn_time_ms\": 8075.751, \"total_train_time_s\": 10.150416135787964}", "{\"n\": 8070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.82, \"learn_time_ms\": 8037.721, \"total_train_time_s\": 10.755449056625366}", "{\"n\": 8071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.82, \"learn_time_ms\": 8125.2, \"total_train_time_s\": 9.546941995620728}", "{\"n\": 8072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.63, \"learn_time_ms\": 8129.528, \"total_train_time_s\": 8.95564889907837}", "{\"n\": 8073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.96, \"learn_time_ms\": 8261.451, \"total_train_time_s\": 10.266676187515259}", "{\"n\": 8074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.96, \"learn_time_ms\": 8276.373, \"total_train_time_s\": 9.561706304550171}", "{\"n\": 8075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.84, \"learn_time_ms\": 8420.002, \"total_train_time_s\": 10.35853123664856}", "{\"n\": 8076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.63, \"learn_time_ms\": 8687.54, \"total_train_time_s\": 11.414057493209839}", "{\"n\": 8077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.63, \"learn_time_ms\": 8803.44, \"total_train_time_s\": 10.406007289886475}", "{\"n\": 8078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.3, \"learn_time_ms\": 8574.096, \"total_train_time_s\": 8.438104391098022}", "{\"n\": 8079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.03, \"learn_time_ms\": 8419.236, \"total_train_time_s\": 8.671610116958618}", "{\"n\": 8080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.28, \"learn_time_ms\": 8230.806, \"total_train_time_s\": 8.841052293777466}", "{\"n\": 8081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.28, \"learn_time_ms\": 8260.892, \"total_train_time_s\": 9.87623143196106}", "{\"n\": 8082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.32, \"learn_time_ms\": 8346.844, \"total_train_time_s\": 9.8451247215271}", "{\"n\": 8083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.77, \"learn_time_ms\": 8351.217, \"total_train_time_s\": 10.363729000091553}", "{\"n\": 8084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.77, \"learn_time_ms\": 8438.144, \"total_train_time_s\": 10.451660871505737}", "{\"n\": 8085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.65, \"learn_time_ms\": 8395.872, \"total_train_time_s\": 9.942939519882202}", "{\"n\": 8086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.99, \"learn_time_ms\": 8272.411, \"total_train_time_s\": 10.161300897598267}", "{\"n\": 8087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.99, \"learn_time_ms\": 8145.643, \"total_train_time_s\": 9.176261901855469}", "{\"n\": 8088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.99, \"learn_time_ms\": 8216.185, \"total_train_time_s\": 9.12326431274414}", "{\"n\": 8089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.82, \"learn_time_ms\": 8359.536, \"total_train_time_s\": 10.040214538574219}", "{\"n\": 8090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.82, \"learn_time_ms\": 8563.035, \"total_train_time_s\": 10.875839233398438}", "{\"n\": 8091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.82, \"learn_time_ms\": 8462.926, \"total_train_time_s\": 8.900788307189941}", "{\"n\": 8092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.64, \"learn_time_ms\": 8579.557, \"total_train_time_s\": 11.037784814834595}", "{\"n\": 8093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.64, \"learn_time_ms\": 8606.613, \"total_train_time_s\": 10.60025405883789}", "{\"n\": 8094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.64, \"learn_time_ms\": 8550.702, \"total_train_time_s\": 9.887959480285645}", "{\"n\": 8095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.14, \"learn_time_ms\": 8521.86, \"total_train_time_s\": 9.580496549606323}", "{\"n\": 8096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.83, \"learn_time_ms\": 8626.656, \"total_train_time_s\": 11.222872734069824}", "{\"n\": 8097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.83, \"learn_time_ms\": 8628.446, \"total_train_time_s\": 9.166387796401978}", "{\"n\": 8098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.83, \"learn_time_ms\": 8670.52, \"total_train_time_s\": 9.531996250152588}", "{\"n\": 8099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8594.345, \"total_train_time_s\": 9.310543298721313}", "{\"n\": 8100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8444.093, \"total_train_time_s\": 9.374709367752075}", "{\"n\": 8101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8565.919, \"total_train_time_s\": 10.105439186096191}", "{\"n\": 8102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.57, \"learn_time_ms\": 8345.366, \"total_train_time_s\": 8.798611164093018}", "{\"n\": 8103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.68, \"learn_time_ms\": 8340.649, \"total_train_time_s\": 10.515838861465454}", "{\"n\": 8104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.68, \"learn_time_ms\": 8545.874, \"total_train_time_s\": 11.905669212341309}", "{\"n\": 8105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.62, \"learn_time_ms\": 8550.54, \"total_train_time_s\": 9.65004014968872}", "{\"n\": 8106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.61, \"learn_time_ms\": 8482.414, \"total_train_time_s\": 10.50496244430542}", "{\"n\": 8107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.61, \"learn_time_ms\": 8622.29, \"total_train_time_s\": 10.539416074752808}", "{\"n\": 8108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.13, \"learn_time_ms\": 8709.996, \"total_train_time_s\": 10.46553659439087}", "{\"n\": 8109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.96, \"learn_time_ms\": 8842.098, \"total_train_time_s\": 10.639817714691162}", "{\"n\": 8110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.96, \"learn_time_ms\": 8934.81, \"total_train_time_s\": 10.335102558135986}", "{\"n\": 8111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.88, \"learn_time_ms\": 8853.027, \"total_train_time_s\": 9.343015909194946}", "{\"n\": 8112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.3, \"learn_time_ms\": 8980.579, \"total_train_time_s\": 10.065573453903198}", "{\"n\": 8113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.2, \"learn_time_ms\": 8919.229, \"total_train_time_s\": 9.919954299926758}", "{\"n\": 8114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.76, \"learn_time_ms\": 8678.265, \"total_train_time_s\": 9.482241868972778}", "{\"n\": 8115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.44, \"learn_time_ms\": 8772.249, \"total_train_time_s\": 10.6033296585083}", "{\"n\": 8116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.87, \"learn_time_ms\": 8923.536, \"total_train_time_s\": 12.052277565002441}", "{\"n\": 8117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.87, \"learn_time_ms\": 8666.69, \"total_train_time_s\": 7.9758546352386475}", "{\"n\": 8118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.35, \"learn_time_ms\": 8506.133, \"total_train_time_s\": 8.783051252365112}", "{\"n\": 8119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.45, \"learn_time_ms\": 8439.307, \"total_train_time_s\": 9.960172891616821}", "{\"n\": 8120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.56, \"learn_time_ms\": 8489.201, \"total_train_time_s\": 10.826814651489258}", "{\"n\": 8121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.97, \"learn_time_ms\": 8433.176, \"total_train_time_s\": 8.771667718887329}", "{\"n\": 8122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.59, \"learn_time_ms\": 8387.388, \"total_train_time_s\": 9.647746801376343}", "{\"n\": 8123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.34, \"learn_time_ms\": 8285.694, \"total_train_time_s\": 8.927611827850342}", "{\"n\": 8124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.46, \"learn_time_ms\": 8348.761, \"total_train_time_s\": 10.130227088928223}", "{\"n\": 8125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.46, \"learn_time_ms\": 8200.097, \"total_train_time_s\": 9.124364852905273}", "{\"n\": 8126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 7903.246, \"total_train_time_s\": 9.101035356521606}", "{\"n\": 8127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 8192.895, \"total_train_time_s\": 10.912230253219604}", "{\"n\": 8128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.14, \"learn_time_ms\": 8272.176, \"total_train_time_s\": 9.6095871925354}", "{\"n\": 8129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.61, \"learn_time_ms\": 8116.759, \"total_train_time_s\": 8.415032625198364}", "{\"n\": 8130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.61, \"learn_time_ms\": 8105.285, \"total_train_time_s\": 10.73388385772705}", "{\"n\": 8131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.14, \"learn_time_ms\": 8397.893, \"total_train_time_s\": 11.658385515213013}", "{\"n\": 8132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.2, \"learn_time_ms\": 8481.497, \"total_train_time_s\": 10.400633573532104}", "{\"n\": 8133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.81, \"learn_time_ms\": 8517.57, \"total_train_time_s\": 9.23740267753601}", "{\"n\": 8134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.91, \"learn_time_ms\": 8564.26, \"total_train_time_s\": 10.59438157081604}", "{\"n\": 8135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.32, \"learn_time_ms\": 8632.813, \"total_train_time_s\": 9.80031681060791}", "{\"n\": 8136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.37, \"learn_time_ms\": 8801.026, \"total_train_time_s\": 10.754830598831177}", "{\"n\": 8137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.28, \"learn_time_ms\": 8570.937, \"total_train_time_s\": 8.60978889465332}", "{\"n\": 8138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.28, \"learn_time_ms\": 8559.301, \"total_train_time_s\": 9.497828006744385}", "{\"n\": 8139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.73, \"learn_time_ms\": 8723.805, \"total_train_time_s\": 10.04793119430542}", "{\"n\": 8140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.6, \"learn_time_ms\": 8646.498, \"total_train_time_s\": 9.947168350219727}", "{\"n\": 8141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.6, \"learn_time_ms\": 8426.854, \"total_train_time_s\": 9.48924446105957}", "{\"n\": 8142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.78, \"learn_time_ms\": 8428.055, \"total_train_time_s\": 10.455820322036743}", "{\"n\": 8143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.27, \"learn_time_ms\": 8552.968, \"total_train_time_s\": 10.559321641921997}", "{\"n\": 8144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.27, \"learn_time_ms\": 8423.926, \"total_train_time_s\": 9.282967805862427}", "{\"n\": 8145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.74, \"learn_time_ms\": 8417.147, \"total_train_time_s\": 9.732475757598877}", "{\"n\": 8146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.09, \"learn_time_ms\": 8315.466, \"total_train_time_s\": 9.75891923904419}", "{\"n\": 8147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.36, \"learn_time_ms\": 8407.718, \"total_train_time_s\": 9.473684787750244}", "{\"n\": 8148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.17, \"learn_time_ms\": 8564.104, \"total_train_time_s\": 11.102504968643188}", "{\"n\": 8149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.67, \"learn_time_ms\": 8407.675, \"total_train_time_s\": 8.511952877044678}", "{\"n\": 8150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.09, \"learn_time_ms\": 8417.851, \"total_train_time_s\": 10.032567501068115}", "{\"n\": 8151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.93, \"learn_time_ms\": 8376.352, \"total_train_time_s\": 9.066189289093018}", "{\"n\": 8152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.92, \"learn_time_ms\": 8404.828, \"total_train_time_s\": 10.751639127731323}", "{\"n\": 8153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.51, \"learn_time_ms\": 8359.6, \"total_train_time_s\": 10.026957035064697}", "{\"n\": 8154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.64, \"learn_time_ms\": 8363.419, \"total_train_time_s\": 9.359617233276367}", "{\"n\": 8155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.27, \"learn_time_ms\": 8347.857, \"total_train_time_s\": 9.589013576507568}", "{\"n\": 8156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.4, \"learn_time_ms\": 8454.929, \"total_train_time_s\": 10.816851615905762}", "{\"n\": 8157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.73, \"learn_time_ms\": 8590.233, \"total_train_time_s\": 10.864516258239746}", "{\"n\": 8158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.07, \"learn_time_ms\": 8511.55, \"total_train_time_s\": 10.242624998092651}", "{\"n\": 8159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.9, \"learn_time_ms\": 8646.233, \"total_train_time_s\": 9.889925003051758}", "{\"n\": 8160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.15, \"learn_time_ms\": 8530.513, \"total_train_time_s\": 8.882980585098267}", "{\"n\": 8161, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.41, \"learn_time_ms\": 8596.736, \"total_train_time_s\": 9.722672700881958}", "{\"n\": 8162, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.19, \"learn_time_ms\": 8320.721, \"total_train_time_s\": 7.978320598602295}", "{\"n\": 8163, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.19, \"learn_time_ms\": 8500.435, \"total_train_time_s\": 11.857816696166992}", "{\"n\": 8164, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.24, \"learn_time_ms\": 8384.873, \"total_train_time_s\": 8.200952768325806}", "{\"n\": 8165, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.52, \"learn_time_ms\": 8470.745, \"total_train_time_s\": 10.439194202423096}", "{\"n\": 8166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.02, \"learn_time_ms\": 8368.892, \"total_train_time_s\": 9.765871286392212}", "{\"n\": 8167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.15, \"learn_time_ms\": 8313.51, \"total_train_time_s\": 10.311424255371094}", "{\"n\": 8168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.15, \"learn_time_ms\": 8279.147, \"total_train_time_s\": 9.920281410217285}", "{\"n\": 8169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8342.584, \"total_train_time_s\": 10.424684762954712}", "{\"n\": 8170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.77, \"learn_time_ms\": 8348.158, \"total_train_time_s\": 8.925296306610107}", "{\"n\": 8171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.49, \"learn_time_ms\": 8395.645, \"total_train_time_s\": 10.229256391525269}", "{\"n\": 8172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.85, \"learn_time_ms\": 8680.9, \"total_train_time_s\": 10.830416202545166}", "{\"n\": 8173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.17, \"learn_time_ms\": 8475.237, \"total_train_time_s\": 9.80386233329773}", "{\"n\": 8174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.5, \"learn_time_ms\": 8712.255, \"total_train_time_s\": 10.609684705734253}", "{\"n\": 8175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.5, \"learn_time_ms\": 8620.317, \"total_train_time_s\": 9.48572850227356}", "{\"n\": 8176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.55, \"learn_time_ms\": 8636.235, \"total_train_time_s\": 9.903939723968506}", "{\"n\": 8177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.56, \"learn_time_ms\": 8562.003, \"total_train_time_s\": 9.558708667755127}", "{\"n\": 8178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.42, \"learn_time_ms\": 8647.982, \"total_train_time_s\": 10.832129001617432}", "{\"n\": 8179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.8, \"learn_time_ms\": 8504.291, \"total_train_time_s\": 9.00412368774414}", "{\"n\": 8180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.77, \"learn_time_ms\": 8666.717, \"total_train_time_s\": 10.542885303497314}", "{\"n\": 8181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.87, \"learn_time_ms\": 8679.29, \"total_train_time_s\": 10.295288562774658}", "{\"n\": 8182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.41, \"learn_time_ms\": 8620.263, \"total_train_time_s\": 10.362993240356445}", "{\"n\": 8183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.7, \"learn_time_ms\": 8615.745, \"total_train_time_s\": 9.776362180709839}", "{\"n\": 8184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.71, \"learn_time_ms\": 8573.927, \"total_train_time_s\": 10.108563423156738}", "{\"n\": 8185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.03, \"learn_time_ms\": 8709.967, \"total_train_time_s\": 10.867916584014893}", "{\"n\": 8186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.41, \"learn_time_ms\": 8558.436, \"total_train_time_s\": 8.397274017333984}", "{\"n\": 8187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.59, \"learn_time_ms\": 8620.741, \"total_train_time_s\": 10.22165298461914}", "{\"n\": 8188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.82, \"learn_time_ms\": 8538.137, \"total_train_time_s\": 10.020804405212402}", "{\"n\": 8189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.21, \"learn_time_ms\": 8665.169, \"total_train_time_s\": 10.316751718521118}", "{\"n\": 8190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.21, \"learn_time_ms\": 8634.597, \"total_train_time_s\": 10.237470388412476}", "{\"n\": 8191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.44, \"learn_time_ms\": 8702.08, \"total_train_time_s\": 10.991079092025757}", "{\"n\": 8192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.75, \"learn_time_ms\": 8869.146, \"total_train_time_s\": 11.924667119979858}", "{\"n\": 8193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.75, \"learn_time_ms\": 8809.103, \"total_train_time_s\": 9.156569242477417}", "{\"n\": 8194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.11, \"learn_time_ms\": 8844.46, \"total_train_time_s\": 10.518525838851929}", "{\"n\": 8195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.78, \"learn_time_ms\": 8840.898, \"total_train_time_s\": 10.842620134353638}", "{\"n\": 8196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.78, \"learn_time_ms\": 8960.05, \"total_train_time_s\": 9.59779667854309}", "{\"n\": 8197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.51, \"learn_time_ms\": 8926.008, \"total_train_time_s\": 9.813689947128296}", "{\"n\": 8198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.04, \"learn_time_ms\": 8923.541, \"total_train_time_s\": 9.967204570770264}", "{\"n\": 8199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.75, \"learn_time_ms\": 8951.942, \"total_train_time_s\": 10.584962844848633}", "{\"n\": 8200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.65, \"learn_time_ms\": 8891.284, \"total_train_time_s\": 9.645738124847412}", "{\"n\": 8201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.14, \"learn_time_ms\": 8841.42, \"total_train_time_s\": 10.482986211776733}", "{\"n\": 8202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.66, \"learn_time_ms\": 8590.983, \"total_train_time_s\": 9.387230157852173}", "{\"n\": 8203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.86, \"learn_time_ms\": 8814.986, \"total_train_time_s\": 11.389546871185303}", "{\"n\": 8204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.19, \"learn_time_ms\": 8819.546, \"total_train_time_s\": 10.493958234786987}", "{\"n\": 8205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.8, \"learn_time_ms\": 8619.202, \"total_train_time_s\": 8.798553943634033}", "{\"n\": 8206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.73, \"learn_time_ms\": 8600.494, \"total_train_time_s\": 9.42644190788269}", "{\"n\": 8207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.73, \"learn_time_ms\": 8591.064, \"total_train_time_s\": 9.733146667480469}", "{\"n\": 8208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.35, \"learn_time_ms\": 8404.96, \"total_train_time_s\": 8.108421564102173}", "{\"n\": 8209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.01, \"learn_time_ms\": 8356.409, \"total_train_time_s\": 10.092795848846436}", "{\"n\": 8210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 8390.456, \"total_train_time_s\": 10.030538558959961}", "{\"n\": 8211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 8338.77, \"total_train_time_s\": 9.9751136302948}", "{\"n\": 8212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.2, \"learn_time_ms\": 8340.127, \"total_train_time_s\": 9.450344562530518}", "{\"n\": 8213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.87, \"learn_time_ms\": 8204.968, \"total_train_time_s\": 10.024029970169067}", "{\"n\": 8214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.87, \"learn_time_ms\": 7983.564, \"total_train_time_s\": 8.286939144134521}", "{\"n\": 8215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.02, \"learn_time_ms\": 8184.731, \"total_train_time_s\": 10.82619333267212}", "{\"n\": 8216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.18, \"learn_time_ms\": 8273.738, \"total_train_time_s\": 10.29419994354248}", "{\"n\": 8217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.22, \"learn_time_ms\": 8244.452, \"total_train_time_s\": 9.442145347595215}", "{\"n\": 8218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.13, \"learn_time_ms\": 8393.611, \"total_train_time_s\": 9.534127950668335}", "{\"n\": 8219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8343.078, \"total_train_time_s\": 9.541946649551392}", "{\"n\": 8220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8347.578, \"total_train_time_s\": 10.01134705543518}", "{\"n\": 8221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.14, \"learn_time_ms\": 8345.664, \"total_train_time_s\": 9.947105884552002}", "{\"n\": 8222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.64, \"learn_time_ms\": 8381.835, \"total_train_time_s\": 9.76220417022705}", "{\"n\": 8223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.18, \"learn_time_ms\": 8495.96, \"total_train_time_s\": 11.176788091659546}", "{\"n\": 8224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.07, \"learn_time_ms\": 8644.357, \"total_train_time_s\": 9.817907810211182}", "{\"n\": 8225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.3, \"learn_time_ms\": 8527.844, \"total_train_time_s\": 9.68878722190857}", "{\"n\": 8226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.75, \"learn_time_ms\": 8498.153, \"total_train_time_s\": 9.976918458938599}", "{\"n\": 8227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.14, \"learn_time_ms\": 8569.649, \"total_train_time_s\": 10.17463755607605}", "{\"n\": 8228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.27, \"learn_time_ms\": 8700.184, \"total_train_time_s\": 10.885876893997192}", "{\"n\": 8229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.13, \"learn_time_ms\": 8740.423, \"total_train_time_s\": 10.02147388458252}", "{\"n\": 8230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.98, \"learn_time_ms\": 8602.891, \"total_train_time_s\": 8.661062002182007}", "{\"n\": 8231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.52, \"learn_time_ms\": 8592.287, \"total_train_time_s\": 9.81147813796997}", "{\"n\": 8232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.72, \"learn_time_ms\": 8672.375, \"total_train_time_s\": 10.617388486862183}", "{\"n\": 8233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.21, \"learn_time_ms\": 8481.396, \"total_train_time_s\": 9.292696475982666}", "{\"n\": 8234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.21, \"learn_time_ms\": 8472.144, \"total_train_time_s\": 9.726025581359863}", "{\"n\": 8235, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.91, \"learn_time_ms\": 8535.098, \"total_train_time_s\": 10.330533504486084}", "{\"n\": 8236, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.68, \"learn_time_ms\": 8503.133, \"total_train_time_s\": 9.683335304260254}", "{\"n\": 8237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.68, \"learn_time_ms\": 8431.501, \"total_train_time_s\": 9.391423225402832}", "{\"n\": 8238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.57, \"learn_time_ms\": 8271.175, \"total_train_time_s\": 9.236469030380249}", "{\"n\": 8239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.22, \"learn_time_ms\": 8298.402, \"total_train_time_s\": 10.23962950706482}", "{\"n\": 8240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.11, \"learn_time_ms\": 8328.733, \"total_train_time_s\": 8.961836814880371}", "{\"n\": 8241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.11, \"learn_time_ms\": 8430.927, \"total_train_time_s\": 10.892011404037476}", "{\"n\": 8242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.25, \"learn_time_ms\": 8510.02, \"total_train_time_s\": 11.398074626922607}", "{\"n\": 8243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.82, \"learn_time_ms\": 8473.545, \"total_train_time_s\": 8.949838876724243}", "{\"n\": 8244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.82, \"learn_time_ms\": 8531.141, \"total_train_time_s\": 10.297060489654541}", "{\"n\": 8245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.87, \"learn_time_ms\": 8558.006, \"total_train_time_s\": 10.532597303390503}", "{\"n\": 8246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.32, \"learn_time_ms\": 8523.864, \"total_train_time_s\": 9.339455366134644}", "{\"n\": 8247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.08, \"learn_time_ms\": 8504.434, \"total_train_time_s\": 9.256336688995361}", "{\"n\": 8248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.68, \"learn_time_ms\": 8543.158, \"total_train_time_s\": 9.641110181808472}", "{\"n\": 8249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.06, \"learn_time_ms\": 8593.671, \"total_train_time_s\": 10.776610851287842}", "{\"n\": 8250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.49, \"learn_time_ms\": 8676.077, \"total_train_time_s\": 9.753913640975952}", "{\"n\": 8251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.49, \"learn_time_ms\": 8537.658, \"total_train_time_s\": 9.535283088684082}", "{\"n\": 8252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.5, \"learn_time_ms\": 8486.979, \"total_train_time_s\": 10.8744797706604}", "{\"n\": 8253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.01, \"learn_time_ms\": 8643.565, \"total_train_time_s\": 10.451139450073242}", "{\"n\": 8254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.7, \"learn_time_ms\": 8675.502, \"total_train_time_s\": 10.577374935150146}", "{\"n\": 8255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.2, \"learn_time_ms\": 8669.315, \"total_train_time_s\": 10.522151708602905}", "{\"n\": 8256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.8, \"learn_time_ms\": 8693.538, \"total_train_time_s\": 9.629775285720825}", "{\"n\": 8257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.76, \"learn_time_ms\": 8745.918, \"total_train_time_s\": 9.812967300415039}", "{\"n\": 8258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.27, \"learn_time_ms\": 8765.392, \"total_train_time_s\": 9.851759672164917}", "{\"n\": 8259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.44, \"learn_time_ms\": 8642.246, \"total_train_time_s\": 9.552196741104126}", "{\"n\": 8260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.98, \"learn_time_ms\": 8642.71, \"total_train_time_s\": 9.788555383682251}", "{\"n\": 8261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.82, \"learn_time_ms\": 8687.01, \"total_train_time_s\": 9.951485633850098}", "{\"n\": 8262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.14, \"learn_time_ms\": 8627.538, \"total_train_time_s\": 10.242822408676147}", "{\"n\": 8263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.5, \"learn_time_ms\": 8728.944, \"total_train_time_s\": 11.51024317741394}", "{\"n\": 8264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.1, \"learn_time_ms\": 8680.289, \"total_train_time_s\": 10.119799375534058}", "{\"n\": 8265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.04, \"learn_time_ms\": 8692.418, \"total_train_time_s\": 10.624271631240845}", "{\"n\": 8266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.04, \"learn_time_ms\": 8750.239, \"total_train_time_s\": 10.176532745361328}", "{\"n\": 8267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.9, \"learn_time_ms\": 8821.526, \"total_train_time_s\": 10.50268030166626}", "{\"n\": 8268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.81, \"learn_time_ms\": 8902.961, \"total_train_time_s\": 10.698210000991821}", "{\"n\": 8269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.81, \"learn_time_ms\": 8853.963, \"total_train_time_s\": 9.053503274917603}", "{\"n\": 8270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.89, \"learn_time_ms\": 8810.161, \"total_train_time_s\": 9.32274079322815}", "{\"n\": 8271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.89, \"learn_time_ms\": 8858.498, \"total_train_time_s\": 10.431777000427246}", "{\"n\": 8272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.16, \"learn_time_ms\": 8876.643, \"total_train_time_s\": 10.427550077438354}", "{\"n\": 8273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.26, \"learn_time_ms\": 8788.514, \"total_train_time_s\": 10.623343467712402}", "{\"n\": 8274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.26, \"learn_time_ms\": 8846.827, \"total_train_time_s\": 10.724961042404175}", "{\"n\": 8275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.93, \"learn_time_ms\": 8773.364, \"total_train_time_s\": 9.919193744659424}", "{\"n\": 8276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.35, \"learn_time_ms\": 8794.546, \"total_train_time_s\": 10.452033281326294}", "{\"n\": 8277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.35, \"learn_time_ms\": 8712.358, \"total_train_time_s\": 9.691447019577026}", "{\"n\": 8278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.14, \"learn_time_ms\": 8616.779, \"total_train_time_s\": 9.706554889678955}", "{\"n\": 8279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.3, \"learn_time_ms\": 8658.495, \"total_train_time_s\": 9.449746370315552}", "{\"n\": 8280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.17, \"learn_time_ms\": 8613.599, \"total_train_time_s\": 8.881351709365845}", "{\"n\": 8281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.21, \"learn_time_ms\": 8533.261, \"total_train_time_s\": 9.616018772125244}", "{\"n\": 8282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.98, \"learn_time_ms\": 8496.045, \"total_train_time_s\": 10.063138484954834}", "{\"n\": 8283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.05, \"learn_time_ms\": 8361.27, \"total_train_time_s\": 9.250940799713135}", "{\"n\": 8284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.86, \"learn_time_ms\": 8258.092, \"total_train_time_s\": 9.675557374954224}", "{\"n\": 8285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.15, \"learn_time_ms\": 8273.175, \"total_train_time_s\": 10.056347608566284}", "{\"n\": 8286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.22, \"learn_time_ms\": 8245.716, \"total_train_time_s\": 10.118378639221191}", "{\"n\": 8287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.84, \"learn_time_ms\": 8274.881, \"total_train_time_s\": 10.016928434371948}", "{\"n\": 8288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.02, \"learn_time_ms\": 8245.98, \"total_train_time_s\": 9.391752243041992}", "{\"n\": 8289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.02, \"learn_time_ms\": 8389.207, \"total_train_time_s\": 10.867425203323364}", "{\"n\": 8290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.53, \"learn_time_ms\": 8570.658, \"total_train_time_s\": 10.729103326797485}", "{\"n\": 8291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.53, \"learn_time_ms\": 8626.589, \"total_train_time_s\": 10.193789005279541}", "{\"n\": 8292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.62, \"learn_time_ms\": 8531.933, \"total_train_time_s\": 9.143168926239014}", "{\"n\": 8293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.52, \"learn_time_ms\": 8494.59, \"total_train_time_s\": 8.892388820648193}", "{\"n\": 8294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.52, \"learn_time_ms\": 8432.553, \"total_train_time_s\": 9.061083555221558}", "{\"n\": 8295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.39, \"learn_time_ms\": 8341.744, \"total_train_time_s\": 9.127492189407349}", "{\"n\": 8296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.81, \"learn_time_ms\": 8205.007, \"total_train_time_s\": 8.747159957885742}", "{\"n\": 8297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.81, \"learn_time_ms\": 8361.646, \"total_train_time_s\": 11.521121263504028}", "{\"n\": 8298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.96, \"learn_time_ms\": 8415.189, \"total_train_time_s\": 9.983560800552368}", "{\"n\": 8299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.35, \"learn_time_ms\": 8289.622, \"total_train_time_s\": 9.60005235671997}", "{\"n\": 8300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.35, \"learn_time_ms\": 8277.34, \"total_train_time_s\": 10.598237037658691}", "{\"n\": 8301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.34, \"learn_time_ms\": 8284.978, \"total_train_time_s\": 10.288993835449219}", "{\"n\": 8302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.77, \"learn_time_ms\": 8336.948, \"total_train_time_s\": 9.670306921005249}", "{\"n\": 8303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.87, \"learn_time_ms\": 8447.474, \"total_train_time_s\": 9.97974157333374}", "{\"n\": 8304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.87, \"learn_time_ms\": 8438.189, \"total_train_time_s\": 8.933924913406372}", "{\"n\": 8305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.7, \"learn_time_ms\": 8473.656, \"total_train_time_s\": 9.505106449127197}", "{\"n\": 8306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.87, \"learn_time_ms\": 8712.89, \"total_train_time_s\": 11.14112901687622}", "{\"n\": 8307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.87, \"learn_time_ms\": 8614.207, \"total_train_time_s\": 10.537394523620605}", "{\"n\": 8308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.94, \"learn_time_ms\": 8498.454, \"total_train_time_s\": 8.797725439071655}", "{\"n\": 8309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.58, \"learn_time_ms\": 8445.32, \"total_train_time_s\": 9.116381168365479}", "{\"n\": 8310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.58, \"learn_time_ms\": 8449.761, \"total_train_time_s\": 10.648067474365234}", "{\"n\": 8311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.55, \"learn_time_ms\": 8459.988, \"total_train_time_s\": 10.344475984573364}", "{\"n\": 8312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.11, \"learn_time_ms\": 8495.285, \"total_train_time_s\": 10.026004314422607}", "{\"n\": 8313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.36, \"learn_time_ms\": 8356.462, \"total_train_time_s\": 8.594949722290039}", "{\"n\": 8314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.36, \"learn_time_ms\": 8434.319, \"total_train_time_s\": 9.743812799453735}", "{\"n\": 8315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3243.93, \"learn_time_ms\": 8567.153, \"total_train_time_s\": 10.828533411026001}", "{\"n\": 8316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3250.91, \"learn_time_ms\": 8505.268, \"total_train_time_s\": 10.510515928268433}", "{\"n\": 8317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3250.91, \"learn_time_ms\": 8432.399, \"total_train_time_s\": 9.766041040420532}", "{\"n\": 8318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3244.4, \"learn_time_ms\": 8461.42, \"total_train_time_s\": 9.128468036651611}", "{\"n\": 8319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.88, \"learn_time_ms\": 8569.958, \"total_train_time_s\": 10.229433059692383}", "{\"n\": 8320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.88, \"learn_time_ms\": 8463.455, \"total_train_time_s\": 9.565675973892212}", "{\"n\": 8321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3237.88, \"learn_time_ms\": 8424.904, \"total_train_time_s\": 9.952560663223267}", "{\"n\": 8322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.27, \"learn_time_ms\": 8423.124, \"total_train_time_s\": 9.971827030181885}", "{\"n\": 8323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.27, \"learn_time_ms\": 8559.288, \"total_train_time_s\": 9.986104488372803}", "{\"n\": 8324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.83, \"learn_time_ms\": 8456.499, \"total_train_time_s\": 8.709624767303467}", "{\"n\": 8325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3230.97, \"learn_time_ms\": 8306.253, \"total_train_time_s\": 9.321288347244263}", "{\"n\": 8326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3230.97, \"learn_time_ms\": 8209.253, \"total_train_time_s\": 9.523158550262451}", "{\"n\": 8327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3231.08, \"learn_time_ms\": 8195.902, \"total_train_time_s\": 9.686068296432495}", "{\"n\": 8328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3231.08, \"learn_time_ms\": 8204.709, \"total_train_time_s\": 9.188645839691162}", "{\"n\": 8329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.31, \"learn_time_ms\": 8269.094, \"total_train_time_s\": 10.876922130584717}", "{\"n\": 8330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.31, \"learn_time_ms\": 8371.777, \"total_train_time_s\": 10.595187425613403}", "{\"n\": 8331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.96, \"learn_time_ms\": 8528.913, \"total_train_time_s\": 11.519952774047852}", "{\"n\": 8332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.88, \"learn_time_ms\": 8580.941, \"total_train_time_s\": 10.473769664764404}", "{\"n\": 8333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.88, \"learn_time_ms\": 8619.351, \"total_train_time_s\": 10.325260400772095}", "{\"n\": 8334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3248.64, \"learn_time_ms\": 8753.196, \"total_train_time_s\": 10.081725358963013}", "{\"n\": 8335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.56, \"learn_time_ms\": 8846.519, \"total_train_time_s\": 10.277211904525757}", "{\"n\": 8336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.56, \"learn_time_ms\": 8865.908, \"total_train_time_s\": 9.710808515548706}", "{\"n\": 8337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.72, \"learn_time_ms\": 9014.98, \"total_train_time_s\": 11.155609846115112}", "{\"n\": 8338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.8, \"learn_time_ms\": 9211.349, \"total_train_time_s\": 11.122851848602295}", "{\"n\": 8339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.22, \"learn_time_ms\": 9026.849, \"total_train_time_s\": 9.038145542144775}", "{\"n\": 8340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.22, \"learn_time_ms\": 8958.661, \"total_train_time_s\": 9.92178750038147}", "{\"n\": 8341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3267.05, \"learn_time_ms\": 8748.698, \"total_train_time_s\": 9.420918941497803}", "{\"n\": 8342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 8747.136, \"total_train_time_s\": 10.492634773254395}", "{\"n\": 8343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 8794.462, \"total_train_time_s\": 10.8239426612854}", "{\"n\": 8344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 8736.977, \"total_train_time_s\": 9.403501749038696}", "{\"n\": 8345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.0, \"learn_time_ms\": 8670.08, \"total_train_time_s\": 9.599931955337524}", "{\"n\": 8346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.69, \"learn_time_ms\": 8736.74, \"total_train_time_s\": 10.39549446105957}", "{\"n\": 8347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.69, \"learn_time_ms\": 8590.004, \"total_train_time_s\": 9.714279890060425}", "{\"n\": 8348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.63, \"learn_time_ms\": 8529.042, \"total_train_time_s\": 10.544436693191528}", "{\"n\": 8349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.36, \"learn_time_ms\": 8658.22, \"total_train_time_s\": 10.291691780090332}", "{\"n\": 8350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.28, \"learn_time_ms\": 8755.235, \"total_train_time_s\": 10.920644521713257}", "{\"n\": 8351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 8930.16, \"total_train_time_s\": 11.199711084365845}", "{\"n\": 8352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.68, \"learn_time_ms\": 8879.052, \"total_train_time_s\": 9.980509281158447}", "{\"n\": 8353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.68, \"learn_time_ms\": 8653.184, \"total_train_time_s\": 8.536707639694214}", "{\"n\": 8354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.52, \"learn_time_ms\": 8740.9, \"total_train_time_s\": 10.399664402008057}", "{\"n\": 8355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.76, \"learn_time_ms\": 8756.364, \"total_train_time_s\": 9.720997095108032}", "{\"n\": 8356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.21, \"learn_time_ms\": 8646.786, \"total_train_time_s\": 9.325963258743286}", "{\"n\": 8357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.35, \"learn_time_ms\": 8710.049, \"total_train_time_s\": 10.344274044036865}", "{\"n\": 8358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.6, \"learn_time_ms\": 8743.179, \"total_train_time_s\": 10.86518669128418}", "{\"n\": 8359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3264.05, \"learn_time_ms\": 8691.124, \"total_train_time_s\": 9.768031120300293}", "{\"n\": 8360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3261.74, \"learn_time_ms\": 8665.284, \"total_train_time_s\": 10.643990278244019}", "{\"n\": 8361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3260.72, \"learn_time_ms\": 8580.759, \"total_train_time_s\": 10.334588050842285}", "{\"n\": 8362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.99, \"learn_time_ms\": 8459.127, \"total_train_time_s\": 8.764577627182007}", "{\"n\": 8363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3248.48, \"learn_time_ms\": 8649.954, \"total_train_time_s\": 10.451350450515747}", "{\"n\": 8364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3251.37, \"learn_time_ms\": 8681.953, \"total_train_time_s\": 10.668241262435913}", "{\"n\": 8365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.85, \"learn_time_ms\": 8588.133, \"total_train_time_s\": 8.826240539550781}", "{\"n\": 8366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8711.83, \"total_train_time_s\": 10.604197263717651}", "{\"n\": 8367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.06, \"learn_time_ms\": 8545.582, \"total_train_time_s\": 8.698159217834473}", "{\"n\": 8368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.06, \"learn_time_ms\": 8543.185, \"total_train_time_s\": 10.844475030899048}", "{\"n\": 8369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3258.15, \"learn_time_ms\": 8584.685, \"total_train_time_s\": 10.197039127349854}", "{\"n\": 8370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.72, \"learn_time_ms\": 8332.55, \"total_train_time_s\": 8.093284606933594}", "{\"n\": 8371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3260.9, \"learn_time_ms\": 7940.788, \"total_train_time_s\": 6.459161996841431}", "{\"n\": 8372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3255.05, \"learn_time_ms\": 7753.928, \"total_train_time_s\": 6.875058174133301}", "{\"n\": 8373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.92, \"learn_time_ms\": 7367.228, \"total_train_time_s\": 6.632620096206665}", "{\"n\": 8374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3261.52, \"learn_time_ms\": 7253.284, \"total_train_time_s\": 9.557576656341553}", "{\"n\": 8375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.59, \"learn_time_ms\": 7441.773, \"total_train_time_s\": 10.690708875656128}", "{\"n\": 8376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.9, \"learn_time_ms\": 7358.742, \"total_train_time_s\": 9.728137969970703}", "{\"n\": 8377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.05, \"learn_time_ms\": 7479.515, \"total_train_time_s\": 9.924490690231323}", "{\"n\": 8378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.05, \"learn_time_ms\": 7295.596, \"total_train_time_s\": 9.008443117141724}", "{\"n\": 8379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.18, \"learn_time_ms\": 7268.87, \"total_train_time_s\": 9.925198554992676}", "{\"n\": 8380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 7294.598, \"total_train_time_s\": 8.334107875823975}", "{\"n\": 8381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 7556.733, \"total_train_time_s\": 9.010676145553589}", "{\"n\": 8382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.72, \"learn_time_ms\": 7773.952, \"total_train_time_s\": 9.090431213378906}", "{\"n\": 8383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.97, \"learn_time_ms\": 8202.171, \"total_train_time_s\": 10.915563344955444}", "{\"n\": 8384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.97, \"learn_time_ms\": 8235.511, \"total_train_time_s\": 9.890633344650269}", "{\"n\": 8385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.97, \"learn_time_ms\": 8162.742, \"total_train_time_s\": 9.9533052444458}", "{\"n\": 8386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3273.55, \"learn_time_ms\": 8273.273, \"total_train_time_s\": 10.825263023376465}", "{\"n\": 8387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.55, \"learn_time_ms\": 8392.023, \"total_train_time_s\": 11.068427085876465}", "{\"n\": 8388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.55, \"learn_time_ms\": 8433.048, \"total_train_time_s\": 9.448461294174194}", "{\"n\": 8389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3267.52, \"learn_time_ms\": 8393.991, \"total_train_time_s\": 9.51545763015747}", "{\"n\": 8390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.22, \"learn_time_ms\": 8585.896, \"total_train_time_s\": 10.264146089553833}", "{\"n\": 8391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.22, \"learn_time_ms\": 8589.604, \"total_train_time_s\": 9.10470986366272}", "{\"n\": 8392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.96, \"learn_time_ms\": 8584.865, \"total_train_time_s\": 9.012816905975342}", "{\"n\": 8393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.26, \"learn_time_ms\": 8508.22, \"total_train_time_s\": 10.150071382522583}", "{\"n\": 8394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.26, \"learn_time_ms\": 8419.948, \"total_train_time_s\": 8.973457336425781}", "{\"n\": 8395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.26, \"learn_time_ms\": 8351.996, \"total_train_time_s\": 9.26306414604187}", "{\"n\": 8396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.63, \"learn_time_ms\": 8188.952, \"total_train_time_s\": 9.223005533218384}", "{\"n\": 8397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.63, \"learn_time_ms\": 8098.742, \"total_train_time_s\": 10.162734508514404}", "{\"n\": 8398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.63, \"learn_time_ms\": 8139.318, \"total_train_time_s\": 9.84020709991455}", "{\"n\": 8399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.27, \"learn_time_ms\": 8048.713, \"total_train_time_s\": 8.653934240341187}", "{\"n\": 8400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.18, \"learn_time_ms\": 7875.5, \"total_train_time_s\": 8.565139293670654}", "{\"n\": 8401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.18, \"learn_time_ms\": 7800.373, \"total_train_time_s\": 8.34720492362976}", "{\"n\": 8402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.88, \"learn_time_ms\": 7888.675, \"total_train_time_s\": 9.9064359664917}", "{\"n\": 8403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.25, \"learn_time_ms\": 7829.272, \"total_train_time_s\": 9.527904033660889}", "{\"n\": 8404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.25, \"learn_time_ms\": 7863.808, \"total_train_time_s\": 9.3124418258667}", "{\"n\": 8405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.36, \"learn_time_ms\": 7953.471, \"total_train_time_s\": 10.20139217376709}", "{\"n\": 8406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.8, \"learn_time_ms\": 7928.783, \"total_train_time_s\": 8.937166452407837}", "{\"n\": 8407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.65, \"learn_time_ms\": 7815.705, \"total_train_time_s\": 9.011533737182617}", "{\"n\": 8408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.12, \"learn_time_ms\": 7927.418, \"total_train_time_s\": 10.896075963973999}", "{\"n\": 8409, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.05, \"learn_time_ms\": 8039.08, \"total_train_time_s\": 9.701241254806519}", "{\"n\": 8410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.75, \"learn_time_ms\": 8131.655, \"total_train_time_s\": 9.440040826797485}", "{\"n\": 8411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.75, \"learn_time_ms\": 8227.754, \"total_train_time_s\": 9.288591146469116}", "{\"n\": 8412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.95, \"learn_time_ms\": 8054.251, \"total_train_time_s\": 8.189137697219849}", "{\"n\": 8413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.48, \"learn_time_ms\": 8175.279, \"total_train_time_s\": 10.792673110961914}", "{\"n\": 8414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.48, \"learn_time_ms\": 8340.812, \"total_train_time_s\": 10.977474927902222}", "{\"n\": 8415, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.17, \"learn_time_ms\": 8125.44, \"total_train_time_s\": 8.019195795059204}", "{\"n\": 8416, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.07, \"learn_time_ms\": 8344.708, \"total_train_time_s\": 11.157124519348145}", "{\"n\": 8417, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.07, \"learn_time_ms\": 8309.076, \"total_train_time_s\": 8.68182897567749}", "{\"n\": 8418, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.63, \"learn_time_ms\": 8251.723, \"total_train_time_s\": 10.364607334136963}", "{\"n\": 8419, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.55, \"learn_time_ms\": 8270.289, \"total_train_time_s\": 9.932050466537476}", "{\"n\": 8420, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.09, \"learn_time_ms\": 8267.74, \"total_train_time_s\": 9.428747653961182}", "{\"n\": 8421, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3272.37, \"learn_time_ms\": 8359.752, \"total_train_time_s\": 10.210699558258057}", "{\"n\": 8422, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3272.37, \"learn_time_ms\": 8549.692, \"total_train_time_s\": 10.040011882781982}", "{\"n\": 8423, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3268.32, \"learn_time_ms\": 8416.5, \"total_train_time_s\": 9.381473779678345}", "{\"n\": 8424, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.41, \"learn_time_ms\": 8276.134, \"total_train_time_s\": 9.63004732131958}", "{\"n\": 8425, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3258.41, \"learn_time_ms\": 8369.337, \"total_train_time_s\": 8.951027393341064}", "{\"n\": 8426, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.13, \"learn_time_ms\": 8321.11, \"total_train_time_s\": 10.666821241378784}", "{\"n\": 8427, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3256.16, \"learn_time_ms\": 8481.331, \"total_train_time_s\": 10.342600107192993}", "{\"n\": 8428, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.08, \"learn_time_ms\": 8363.712, \"total_train_time_s\": 9.186207294464111}", "{\"n\": 8429, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.08, \"learn_time_ms\": 8344.321, \"total_train_time_s\": 9.706726551055908}", "{\"n\": 8430, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.45, \"learn_time_ms\": 8469.525, \"total_train_time_s\": 10.741100549697876}", "{\"n\": 8431, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.19, \"learn_time_ms\": 8459.797, \"total_train_time_s\": 10.15714693069458}", "{\"n\": 8432, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.19, \"learn_time_ms\": 8636.429, \"total_train_time_s\": 11.839351415634155}", "{\"n\": 8433, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.47, \"learn_time_ms\": 8638.016, \"total_train_time_s\": 9.400864601135254}", "{\"n\": 8434, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.86, \"learn_time_ms\": 8705.737, \"total_train_time_s\": 10.26672649383545}", "{\"n\": 8435, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.86, \"learn_time_ms\": 8890.795, \"total_train_time_s\": 10.780163049697876}", "{\"n\": 8436, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.79, \"learn_time_ms\": 8801.549, \"total_train_time_s\": 9.770796775817871}", "{\"n\": 8437, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.72, \"learn_time_ms\": 8834.761, \"total_train_time_s\": 10.584151268005371}", "{\"n\": 8438, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.72, \"learn_time_ms\": 8860.958, \"total_train_time_s\": 9.446464538574219}", "{\"n\": 8439, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.54, \"learn_time_ms\": 8939.352, \"total_train_time_s\": 10.526859760284424}", "{\"n\": 8440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.06, \"learn_time_ms\": 8731.273, \"total_train_time_s\": 8.599572896957397}", "{\"n\": 8441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.0, \"learn_time_ms\": 8643.641, \"total_train_time_s\": 9.258420467376709}", "{\"n\": 8442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.0, \"learn_time_ms\": 8507.195, \"total_train_time_s\": 10.458598852157593}", "{\"n\": 8443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.63, \"learn_time_ms\": 8515.876, \"total_train_time_s\": 9.531582593917847}", "{\"n\": 8444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.22, \"learn_time_ms\": 8480.843, \"total_train_time_s\": 9.914525270462036}", "{\"n\": 8445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.22, \"learn_time_ms\": 8368.469, \"total_train_time_s\": 9.668500423431396}", "{\"n\": 8446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.89, \"learn_time_ms\": 8311.341, \"total_train_time_s\": 9.22829532623291}", "{\"n\": 8447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.06, \"learn_time_ms\": 8305.275, \"total_train_time_s\": 10.610242366790771}", "{\"n\": 8448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.06, \"learn_time_ms\": 8532.02, \"total_train_time_s\": 11.73241901397705}", "{\"n\": 8449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.53, \"learn_time_ms\": 8563.169, \"total_train_time_s\": 10.84169054031372}", "{\"n\": 8450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.04, \"learn_time_ms\": 8903.231, \"total_train_time_s\": 12.066170454025269}", "{\"n\": 8451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.04, \"learn_time_ms\": 8892.67, \"total_train_time_s\": 9.117748260498047}", "{\"n\": 8452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.73, \"learn_time_ms\": 8901.199, \"total_train_time_s\": 10.556968212127686}", "{\"n\": 8453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.74, \"learn_time_ms\": 8918.467, \"total_train_time_s\": 9.692776679992676}", "{\"n\": 8454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.74, \"learn_time_ms\": 8890.813, \"total_train_time_s\": 9.61086130142212}", "{\"n\": 8455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.74, \"learn_time_ms\": 8885.528, \"total_train_time_s\": 9.629394054412842}", "{\"n\": 8456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.65, \"learn_time_ms\": 8931.093, \"total_train_time_s\": 9.686068773269653}", "{\"n\": 8457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.65, \"learn_time_ms\": 8840.244, \"total_train_time_s\": 9.618249654769897}", "{\"n\": 8458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.65, \"learn_time_ms\": 8677.725, \"total_train_time_s\": 10.084274291992188}", "{\"n\": 8459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8630.754, \"total_train_time_s\": 10.333468914031982}", "{\"n\": 8460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8430.052, \"total_train_time_s\": 9.990125179290771}", "{\"n\": 8461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.81, \"learn_time_ms\": 8559.337, \"total_train_time_s\": 10.43420672416687}", "{\"n\": 8462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.09, \"learn_time_ms\": 8491.422, \"total_train_time_s\": 9.894190549850464}", "{\"n\": 8463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.35, \"learn_time_ms\": 8566.306, \"total_train_time_s\": 10.418648958206177}", "{\"n\": 8464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.35, \"learn_time_ms\": 8538.254, \"total_train_time_s\": 9.374617576599121}", "{\"n\": 8465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.24, \"learn_time_ms\": 8674.977, \"total_train_time_s\": 11.00475525856018}", "{\"n\": 8466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.71, \"learn_time_ms\": 8782.097, \"total_train_time_s\": 10.705088138580322}", "{\"n\": 8467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.71, \"learn_time_ms\": 8823.788, \"total_train_time_s\": 10.044427394866943}", "{\"n\": 8468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.71, \"learn_time_ms\": 8883.808, \"total_train_time_s\": 10.666233777999878}", "{\"n\": 8469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.15, \"learn_time_ms\": 8659.643, \"total_train_time_s\": 8.08232307434082}", "{\"n\": 8470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.48, \"learn_time_ms\": 8605.1, \"total_train_time_s\": 9.474306344985962}", "{\"n\": 8471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.48, \"learn_time_ms\": 8520.206, \"total_train_time_s\": 9.5766921043396}", "{\"n\": 8472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.34, \"learn_time_ms\": 8484.749, \"total_train_time_s\": 9.545333623886108}", "{\"n\": 8473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.68, \"learn_time_ms\": 8443.129, \"total_train_time_s\": 10.009807586669922}", "{\"n\": 8474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.68, \"learn_time_ms\": 8492.044, \"total_train_time_s\": 9.814715147018433}", "{\"n\": 8475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.23, \"learn_time_ms\": 8287.949, \"total_train_time_s\": 8.927109003067017}", "{\"n\": 8476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.11, \"learn_time_ms\": 8255.177, \"total_train_time_s\": 10.395721197128296}", "{\"n\": 8477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.11, \"learn_time_ms\": 8321.244, \"total_train_time_s\": 10.708249807357788}", "{\"n\": 8478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.41, \"learn_time_ms\": 8402.178, \"total_train_time_s\": 11.474405765533447}", "{\"n\": 8479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.02, \"learn_time_ms\": 8614.263, \"total_train_time_s\": 10.192058563232422}", "{\"n\": 8480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.95, \"learn_time_ms\": 8642.858, \"total_train_time_s\": 9.719261407852173}", "{\"n\": 8481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.95, \"learn_time_ms\": 8693.407, \"total_train_time_s\": 10.075568675994873}", "{\"n\": 8482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.88, \"learn_time_ms\": 8708.697, \"total_train_time_s\": 9.670606136322021}", "{\"n\": 8483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.91, \"learn_time_ms\": 8699.295, \"total_train_time_s\": 9.947519063949585}", "{\"n\": 8484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.91, \"learn_time_ms\": 8584.792, \"total_train_time_s\": 8.67806077003479}", "{\"n\": 8485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.55, \"learn_time_ms\": 8614.864, \"total_train_time_s\": 9.202522277832031}", "{\"n\": 8486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.79, \"learn_time_ms\": 8662.581, \"total_train_time_s\": 10.834235668182373}", "{\"n\": 8487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.79, \"learn_time_ms\": 8464.668, \"total_train_time_s\": 8.709827899932861}", "{\"n\": 8488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.1, \"learn_time_ms\": 8301.104, \"total_train_time_s\": 9.866012811660767}", "{\"n\": 8489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.02, \"learn_time_ms\": 8243.738, \"total_train_time_s\": 9.643521785736084}", "{\"n\": 8490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.02, \"learn_time_ms\": 8250.808, \"total_train_time_s\": 9.821089267730713}", "{\"n\": 8491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.32, \"learn_time_ms\": 8285.026, \"total_train_time_s\": 10.448726654052734}", "{\"n\": 8492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.89, \"learn_time_ms\": 8285.671, \"total_train_time_s\": 9.659194469451904}", "{\"n\": 8493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.39, \"learn_time_ms\": 8313.294, \"total_train_time_s\": 10.154890775680542}", "{\"n\": 8494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.8, \"learn_time_ms\": 8485.625, \"total_train_time_s\": 10.38926362991333}", "{\"n\": 8495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.2, \"learn_time_ms\": 8610.582, \"total_train_time_s\": 10.539607763290405}", "{\"n\": 8496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.58, \"learn_time_ms\": 8606.511, \"total_train_time_s\": 10.846052646636963}", "{\"n\": 8497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.58, \"learn_time_ms\": 8583.914, \"total_train_time_s\": 8.517784833908081}", "{\"n\": 8498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.17, \"learn_time_ms\": 8599.172, \"total_train_time_s\": 10.023046731948853}", "{\"n\": 8499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.64, \"learn_time_ms\": 8732.712, \"total_train_time_s\": 10.96312427520752}", "{\"n\": 8500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.42, \"learn_time_ms\": 8691.911, \"total_train_time_s\": 9.446882247924805}", "{\"n\": 8501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.09, \"learn_time_ms\": 8606.82, \"total_train_time_s\": 9.588228702545166}", "{\"n\": 8502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.93, \"learn_time_ms\": 8594.77, \"total_train_time_s\": 9.583680629730225}", "{\"n\": 8503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.93, \"learn_time_ms\": 8642.668, \"total_train_time_s\": 10.637509107589722}", "{\"n\": 8504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3250.7, \"learn_time_ms\": 8590.901, \"total_train_time_s\": 9.908397912979126}", "{\"n\": 8505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.51, \"learn_time_ms\": 8627.542, \"total_train_time_s\": 10.915656805038452}", "{\"n\": 8506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3267.45, \"learn_time_ms\": 8609.428, \"total_train_time_s\": 10.634101867675781}", "{\"n\": 8507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.18, \"learn_time_ms\": 8787.785, \"total_train_time_s\": 10.281272172927856}", "{\"n\": 8508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.19, \"learn_time_ms\": 8633.393, \"total_train_time_s\": 8.429317235946655}", "{\"n\": 8509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.19, \"learn_time_ms\": 8608.992, \"total_train_time_s\": 10.784443616867065}", "{\"n\": 8510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.41, \"learn_time_ms\": 8694.111, \"total_train_time_s\": 10.31135630607605}", "{\"n\": 8511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.78, \"learn_time_ms\": 8543.163, \"total_train_time_s\": 8.078245639801025}", "{\"n\": 8512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.72, \"learn_time_ms\": 8607.061, \"total_train_time_s\": 10.205686807632446}", "{\"n\": 8513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.9, \"learn_time_ms\": 8615.365, \"total_train_time_s\": 10.758466482162476}", "{\"n\": 8514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.12, \"learn_time_ms\": 8675.644, \"total_train_time_s\": 10.480027198791504}", "{\"n\": 8515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.82, \"learn_time_ms\": 8535.232, \"total_train_time_s\": 9.438244104385376}", "{\"n\": 8516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.82, \"learn_time_ms\": 8256.758, \"total_train_time_s\": 7.895951271057129}", "{\"n\": 8517, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.16, \"learn_time_ms\": 8094.943, \"total_train_time_s\": 8.69347596168518}", "{\"n\": 8518, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.62, \"learn_time_ms\": 8050.613, \"total_train_time_s\": 8.024196863174438}", "{\"n\": 8519, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.62, \"learn_time_ms\": 8045.546, \"total_train_time_s\": 10.691655158996582}", "{\"n\": 8520, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.21, \"learn_time_ms\": 8070.255, \"total_train_time_s\": 10.495691299438477}", "{\"n\": 8521, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.74, \"learn_time_ms\": 8221.895, \"total_train_time_s\": 9.590729475021362}", "{\"n\": 8522, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.74, \"learn_time_ms\": 8229.206, \"total_train_time_s\": 10.243678569793701}", "{\"n\": 8523, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.88, \"learn_time_ms\": 8024.846, \"total_train_time_s\": 8.722782850265503}", "{\"n\": 8524, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.4, \"learn_time_ms\": 7906.718, \"total_train_time_s\": 9.293087720870972}", "{\"n\": 8525, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.03, \"learn_time_ms\": 7981.78, \"total_train_time_s\": 10.189807176589966}", "{\"n\": 8526, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.22, \"learn_time_ms\": 8204.341, \"total_train_time_s\": 10.081253290176392}", "{\"n\": 8527, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.93, \"learn_time_ms\": 8279.406, \"total_train_time_s\": 9.39249873161316}", "{\"n\": 8528, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.38, \"learn_time_ms\": 8472.026, \"total_train_time_s\": 9.955687999725342}", "{\"n\": 8529, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.38, \"learn_time_ms\": 8290.836, \"total_train_time_s\": 8.867064952850342}", "{\"n\": 8530, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.41, \"learn_time_ms\": 8309.6, \"total_train_time_s\": 10.72837781906128}", "{\"n\": 8531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.78, \"learn_time_ms\": 8444.783, \"total_train_time_s\": 10.899593114852905}", "{\"n\": 8532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.78, \"learn_time_ms\": 8438.382, \"total_train_time_s\": 10.21855354309082}", "{\"n\": 8533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.64, \"learn_time_ms\": 8572.764, \"total_train_time_s\": 10.063819646835327}", "{\"n\": 8534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.98, \"learn_time_ms\": 8685.617, \"total_train_time_s\": 10.437717199325562}", "{\"n\": 8535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.98, \"learn_time_ms\": 8671.257, \"total_train_time_s\": 10.08770751953125}", "{\"n\": 8536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.74, \"learn_time_ms\": 8641.35, \"total_train_time_s\": 9.723634719848633}", "{\"n\": 8537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.9, \"learn_time_ms\": 8673.251, \"total_train_time_s\": 9.798685789108276}", "{\"n\": 8538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.9, \"learn_time_ms\": 8595.716, \"total_train_time_s\": 9.196031093597412}", "{\"n\": 8539, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.01, \"learn_time_ms\": 8590.928, \"total_train_time_s\": 8.843127489089966}", "{\"n\": 8540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.49, \"learn_time_ms\": 8549.143, \"total_train_time_s\": 10.28415036201477}", "{\"n\": 8541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.73, \"learn_time_ms\": 8243.665, \"total_train_time_s\": 7.855614900588989}", "{\"n\": 8542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.56, \"learn_time_ms\": 8146.902, \"total_train_time_s\": 9.207625389099121}", "{\"n\": 8543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.32, \"learn_time_ms\": 8106.23, \"total_train_time_s\": 9.659320831298828}", "{\"n\": 8544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.13, \"learn_time_ms\": 8097.818, \"total_train_time_s\": 10.329698324203491}", "{\"n\": 8545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.13, \"learn_time_ms\": 7959.838, \"total_train_time_s\": 8.713491678237915}", "{\"n\": 8546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.0, \"learn_time_ms\": 8133.68, \"total_train_time_s\": 11.498112916946411}", "{\"n\": 8547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.39, \"learn_time_ms\": 8035.747, \"total_train_time_s\": 8.797179222106934}", "{\"n\": 8548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.39, \"learn_time_ms\": 8106.793, \"total_train_time_s\": 9.863375425338745}", "{\"n\": 8549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.58, \"learn_time_ms\": 8391.64, \"total_train_time_s\": 11.669528722763062}", "{\"n\": 8550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.21, \"learn_time_ms\": 8361.939, \"total_train_time_s\": 10.024670124053955}", "{\"n\": 8551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.21, \"learn_time_ms\": 8635.043, \"total_train_time_s\": 10.611788034439087}", "{\"n\": 8552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.36, \"learn_time_ms\": 8701.979, \"total_train_time_s\": 9.939043045043945}", "{\"n\": 8553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.49, \"learn_time_ms\": 8719.004, \"total_train_time_s\": 9.835845232009888}", "{\"n\": 8554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.28, \"learn_time_ms\": 8562.456, \"total_train_time_s\": 8.775549173355103}", "{\"n\": 8555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.98, \"learn_time_ms\": 8721.651, \"total_train_time_s\": 10.317241907119751}", "{\"n\": 8556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.01, \"learn_time_ms\": 8551.346, \"total_train_time_s\": 9.891006469726562}", "{\"n\": 8557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.7, \"learn_time_ms\": 8672.924, \"total_train_time_s\": 9.994871854782104}", "{\"n\": 8558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.21, \"learn_time_ms\": 8633.71, \"total_train_time_s\": 9.48562479019165}", "{\"n\": 8559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.2, \"learn_time_ms\": 8388.167, \"total_train_time_s\": 9.203275680541992}", "{\"n\": 8560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.97, \"learn_time_ms\": 8248.019, \"total_train_time_s\": 8.555264949798584}", "{\"n\": 8561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.63, \"learn_time_ms\": 8272.944, \"total_train_time_s\": 10.863327026367188}", "{\"n\": 8562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.63, \"learn_time_ms\": 8375.878, \"total_train_time_s\": 10.866260051727295}", "{\"n\": 8563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.13, \"learn_time_ms\": 8468.985, \"total_train_time_s\": 10.784074068069458}", "{\"n\": 8564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.0, \"learn_time_ms\": 8569.733, \"total_train_time_s\": 9.81250548362732}", "{\"n\": 8565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.0, \"learn_time_ms\": 8448.228, \"total_train_time_s\": 9.092088222503662}", "{\"n\": 8566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3289.52, \"learn_time_ms\": 8372.481, \"total_train_time_s\": 9.09358286857605}", "{\"n\": 8567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3289.52, \"learn_time_ms\": 8345.313, \"total_train_time_s\": 9.6860933303833}", "{\"n\": 8568, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.36, \"learn_time_ms\": 8424.987, \"total_train_time_s\": 10.294659614562988}", "{\"n\": 8569, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.36, \"learn_time_ms\": 8540.223, \"total_train_time_s\": 10.397252798080444}", "{\"n\": 8570, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.31, \"learn_time_ms\": 8662.6, \"total_train_time_s\": 9.797991514205933}", "{\"n\": 8571, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.44, \"learn_time_ms\": 8517.675, \"total_train_time_s\": 9.404197216033936}", "{\"n\": 8572, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.44, \"learn_time_ms\": 8326.453, \"total_train_time_s\": 9.02390718460083}", "{\"n\": 8573, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.88, \"learn_time_ms\": 8249.74, \"total_train_time_s\": 9.999170303344727}", "{\"n\": 8574, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.52, \"learn_time_ms\": 8282.789, \"total_train_time_s\": 10.130529403686523}", "{\"n\": 8575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.28, \"learn_time_ms\": 8494.722, \"total_train_time_s\": 11.21900749206543}", "{\"n\": 8576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.82, \"learn_time_ms\": 8496.916, \"total_train_time_s\": 9.137398481369019}", "{\"n\": 8577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.32, \"learn_time_ms\": 8590.932, \"total_train_time_s\": 10.68556022644043}", "{\"n\": 8578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.71, \"learn_time_ms\": 8605.175, \"total_train_time_s\": 10.450724601745605}", "{\"n\": 8579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.73, \"learn_time_ms\": 8501.787, \"total_train_time_s\": 9.34884238243103}", "{\"n\": 8580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.02, \"learn_time_ms\": 8645.92, \"total_train_time_s\": 11.223482608795166}", "{\"n\": 8581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.48, \"learn_time_ms\": 8773.19, \"total_train_time_s\": 10.72032880783081}", "{\"n\": 8582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3285.79, \"learn_time_ms\": 8908.437, \"total_train_time_s\": 10.39280390739441}", "{\"n\": 8583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.97, \"learn_time_ms\": 8973.068, \"total_train_time_s\": 10.626965761184692}", "{\"n\": 8584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.54, \"learn_time_ms\": 8943.264, \"total_train_time_s\": 9.871824979782104}", "{\"n\": 8585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.39, \"learn_time_ms\": 8864.692, \"total_train_time_s\": 10.418328523635864}", "{\"n\": 8586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.6, \"learn_time_ms\": 9057.595, \"total_train_time_s\": 11.00647521018982}", "{\"n\": 8587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.86, \"learn_time_ms\": 8996.011, \"total_train_time_s\": 10.02843427658081}", "{\"n\": 8588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.77, \"learn_time_ms\": 8861.344, \"total_train_time_s\": 9.067528486251831}", "{\"n\": 8589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.99, \"learn_time_ms\": 8988.229, \"total_train_time_s\": 10.584450721740723}", "{\"n\": 8590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.12, \"learn_time_ms\": 8877.955, \"total_train_time_s\": 10.142715692520142}", "{\"n\": 8591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.85, \"learn_time_ms\": 8895.43, \"total_train_time_s\": 10.857826948165894}", "{\"n\": 8592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.47, \"learn_time_ms\": 8789.566, \"total_train_time_s\": 9.356119155883789}", "{\"n\": 8593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.47, \"learn_time_ms\": 8672.589, \"total_train_time_s\": 9.45358920097351}", "{\"n\": 8594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.07, \"learn_time_ms\": 8699.12, \"total_train_time_s\": 10.109007835388184}", "{\"n\": 8595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.12, \"learn_time_ms\": 8652.177, \"total_train_time_s\": 10.01119589805603}", "{\"n\": 8596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.0, \"learn_time_ms\": 8524.714, \"total_train_time_s\": 9.767313241958618}", "{\"n\": 8597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.16, \"learn_time_ms\": 8482.43, \"total_train_time_s\": 9.622948408126831}", "{\"n\": 8598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.89, \"learn_time_ms\": 8483.075, \"total_train_time_s\": 9.09406852722168}", "{\"n\": 8599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.37, \"learn_time_ms\": 8269.711, \"total_train_time_s\": 8.468676567077637}", "{\"n\": 8600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.37, \"learn_time_ms\": 8231.826, \"total_train_time_s\": 9.792404651641846}", "{\"n\": 8601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.29, \"learn_time_ms\": 8082.05, \"total_train_time_s\": 9.34351372718811}", "{\"n\": 8602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.4, \"learn_time_ms\": 8243.277, \"total_train_time_s\": 10.92729663848877}", "{\"n\": 8603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.27, \"learn_time_ms\": 8198.03, \"total_train_time_s\": 8.986201763153076}", "{\"n\": 8604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.19, \"learn_time_ms\": 8178.974, \"total_train_time_s\": 9.922968864440918}", "{\"n\": 8605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.4, \"learn_time_ms\": 8188.035, \"total_train_time_s\": 10.10430359840393}", "{\"n\": 8606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.87, \"learn_time_ms\": 8229.051, \"total_train_time_s\": 10.138046503067017}", "{\"n\": 8607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.87, \"learn_time_ms\": 8399.996, \"total_train_time_s\": 11.300241708755493}", "{\"n\": 8608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.35, \"learn_time_ms\": 8443.809, \"total_train_time_s\": 9.546616554260254}", "{\"n\": 8609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.85, \"learn_time_ms\": 8471.879, \"total_train_time_s\": 8.742259740829468}", "{\"n\": 8610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.85, \"learn_time_ms\": 8600.595, \"total_train_time_s\": 11.041699647903442}", "{\"n\": 8611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.86, \"learn_time_ms\": 8628.64, \"total_train_time_s\": 9.628969430923462}", "{\"n\": 8612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.03, \"learn_time_ms\": 8677.369, \"total_train_time_s\": 11.401187658309937}", "{\"n\": 8613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.03, \"learn_time_ms\": 8745.16, \"total_train_time_s\": 9.699596166610718}", "{\"n\": 8614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.86, \"learn_time_ms\": 8815.455, \"total_train_time_s\": 10.594767808914185}", "{\"n\": 8615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.39, \"learn_time_ms\": 8676.489, \"total_train_time_s\": 8.608738899230957}", "{\"n\": 8616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.39, \"learn_time_ms\": 8550.197, \"total_train_time_s\": 8.881104230880737}", "{\"n\": 8617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.41, \"learn_time_ms\": 8408.351, \"total_train_time_s\": 9.916231155395508}", "{\"n\": 8618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.32, \"learn_time_ms\": 8516.555, \"total_train_time_s\": 10.634701251983643}", "{\"n\": 8619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.32, \"learn_time_ms\": 8620.243, \"total_train_time_s\": 9.772759914398193}", "{\"n\": 8620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.43, \"learn_time_ms\": 8623.316, \"total_train_time_s\": 11.11127781867981}", "{\"n\": 8621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.82, \"learn_time_ms\": 8657.761, \"total_train_time_s\": 9.950500726699829}", "{\"n\": 8622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.82, \"learn_time_ms\": 8452.029, \"total_train_time_s\": 9.381020069122314}", "{\"n\": 8623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.19, \"learn_time_ms\": 8447.609, \"total_train_time_s\": 9.607085943222046}", "{\"n\": 8624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.26, \"learn_time_ms\": 8121.682, \"total_train_time_s\": 7.337197303771973}", "{\"n\": 8625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.22, \"learn_time_ms\": 8409.003, \"total_train_time_s\": 11.514721632003784}", "{\"n\": 8626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.35, \"learn_time_ms\": 8659.432, \"total_train_time_s\": 11.406278133392334}", "{\"n\": 8627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.35, \"learn_time_ms\": 8702.582, \"total_train_time_s\": 10.311036109924316}", "{\"n\": 8628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.1, \"learn_time_ms\": 8665.922, \"total_train_time_s\": 10.244635105133057}", "{\"n\": 8629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.1, \"learn_time_ms\": 8631.339, \"total_train_time_s\": 9.416504859924316}", "{\"n\": 8630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.87, \"learn_time_ms\": 8556.192, \"total_train_time_s\": 10.32100248336792}", "{\"n\": 8631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 8544.181, \"total_train_time_s\": 9.85494065284729}", "{\"n\": 8632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 8708.795, \"total_train_time_s\": 10.96645998954773}", "{\"n\": 8633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.64, \"learn_time_ms\": 8713.491, \"total_train_time_s\": 9.681919574737549}", "{\"n\": 8634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.27, \"learn_time_ms\": 9127.837, \"total_train_time_s\": 11.481796741485596}", "{\"n\": 8635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.27, \"learn_time_ms\": 9110.364, \"total_train_time_s\": 11.302741527557373}", "{\"n\": 8636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.63, \"learn_time_ms\": 8779.515, \"total_train_time_s\": 8.068072080612183}", "{\"n\": 8637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.08, \"learn_time_ms\": 8666.507, \"total_train_time_s\": 9.185978889465332}", "{\"n\": 8638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.97, \"learn_time_ms\": 8770.714, \"total_train_time_s\": 11.29417371749878}", "{\"n\": 8639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.28, \"learn_time_ms\": 8921.338, \"total_train_time_s\": 10.903578281402588}", "{\"n\": 8640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.35, \"learn_time_ms\": 8999.704, \"total_train_time_s\": 11.144516229629517}", "{\"n\": 8641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.45, \"learn_time_ms\": 9063.671, \"total_train_time_s\": 10.491952896118164}", "{\"n\": 8642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.72, \"learn_time_ms\": 9009.983, \"total_train_time_s\": 10.439113140106201}", "{\"n\": 8643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.22, \"learn_time_ms\": 9171.217, \"total_train_time_s\": 11.30199146270752}", "{\"n\": 8644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.86, \"learn_time_ms\": 8893.659, \"total_train_time_s\": 8.746605157852173}", "{\"n\": 8645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.86, \"learn_time_ms\": 8933.096, \"total_train_time_s\": 11.71161937713623}", "{\"n\": 8646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.88, \"learn_time_ms\": 9079.607, \"total_train_time_s\": 9.553320169448853}", "{\"n\": 8647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.88, \"learn_time_ms\": 9190.88, \"total_train_time_s\": 10.359214544296265}", "{\"n\": 8648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.56, \"learn_time_ms\": 9059.676, \"total_train_time_s\": 9.985702991485596}", "{\"n\": 8649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.53, \"learn_time_ms\": 8937.926, \"total_train_time_s\": 9.725963115692139}", "{\"n\": 8650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.99, \"learn_time_ms\": 8822.716, \"total_train_time_s\": 9.975298643112183}", "{\"n\": 8651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.95, \"learn_time_ms\": 8947.338, \"total_train_time_s\": 11.759554862976074}", "{\"n\": 8652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.7, \"learn_time_ms\": 8772.015, \"total_train_time_s\": 8.70053482055664}", "{\"n\": 8653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.16, \"learn_time_ms\": 8719.636, \"total_train_time_s\": 10.801291227340698}", "{\"n\": 8654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.74, \"learn_time_ms\": 8800.063, \"total_train_time_s\": 9.533069372177124}", "{\"n\": 8655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.01, \"learn_time_ms\": 8702.557, \"total_train_time_s\": 10.796136379241943}", "{\"n\": 8656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.52, \"learn_time_ms\": 8854.956, \"total_train_time_s\": 11.092865705490112}", "{\"n\": 8657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.85, \"learn_time_ms\": 8687.621, \"total_train_time_s\": 8.660653114318848}", "{\"n\": 8658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.85, \"learn_time_ms\": 8760.658, \"total_train_time_s\": 10.697614192962646}", "{\"n\": 8659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.67, \"learn_time_ms\": 8735.496, \"total_train_time_s\": 9.508269786834717}", "{\"n\": 8660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.17, \"learn_time_ms\": 8765.353, \"total_train_time_s\": 10.240134954452515}", "{\"n\": 8661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.57, \"learn_time_ms\": 8610.599, \"total_train_time_s\": 10.21293044090271}", "{\"n\": 8662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.57, \"learn_time_ms\": 8706.124, \"total_train_time_s\": 9.71559190750122}", "{\"n\": 8663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.98, \"learn_time_ms\": 8552.948, \"total_train_time_s\": 9.251535177230835}", "{\"n\": 8664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.98, \"learn_time_ms\": 8585.898, \"total_train_time_s\": 9.822930574417114}", "{\"n\": 8665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.88, \"learn_time_ms\": 8516.915, \"total_train_time_s\": 10.048598051071167}", "{\"n\": 8666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.44, \"learn_time_ms\": 8340.143, \"total_train_time_s\": 9.323760509490967}", "{\"n\": 8667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.44, \"learn_time_ms\": 8543.741, \"total_train_time_s\": 10.738301038742065}", "{\"n\": 8668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 8318.952, \"total_train_time_s\": 8.424637794494629}", "{\"n\": 8669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.18, \"learn_time_ms\": 8250.569, \"total_train_time_s\": 8.787206411361694}", "{\"n\": 8670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.16, \"learn_time_ms\": 8121.259, \"total_train_time_s\": 8.91633653640747}", "{\"n\": 8671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.49, \"learn_time_ms\": 8090.49, \"total_train_time_s\": 9.889227867126465}", "{\"n\": 8672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.15, \"learn_time_ms\": 8179.785, \"total_train_time_s\": 10.529416799545288}", "{\"n\": 8673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.92, \"learn_time_ms\": 8204.617, \"total_train_time_s\": 9.463401556015015}", "{\"n\": 8674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.92, \"learn_time_ms\": 8303.776, \"total_train_time_s\": 10.852622032165527}", "{\"n\": 8675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.92, \"learn_time_ms\": 8189.586, \"total_train_time_s\": 8.917191505432129}", "{\"n\": 8676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.11, \"learn_time_ms\": 8242.219, \"total_train_time_s\": 9.806504011154175}", "{\"n\": 8677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.22, \"learn_time_ms\": 8173.631, \"total_train_time_s\": 10.01472783088684}", "{\"n\": 8678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.87, \"learn_time_ms\": 8239.869, \"total_train_time_s\": 9.098361492156982}", "{\"n\": 8679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.48, \"learn_time_ms\": 8367.009, \"total_train_time_s\": 10.0635986328125}", "{\"n\": 8680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.48, \"learn_time_ms\": 8386.409, \"total_train_time_s\": 9.190677404403687}", "{\"n\": 8681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.28, \"learn_time_ms\": 8201.41, \"total_train_time_s\": 8.06038784980774}", "{\"n\": 8682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.1, \"learn_time_ms\": 8118.346, \"total_train_time_s\": 9.739226818084717}", "{\"n\": 8683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.83, \"learn_time_ms\": 8206.308, \"total_train_time_s\": 10.390693664550781}", "{\"n\": 8684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.46, \"learn_time_ms\": 8268.285, \"total_train_time_s\": 11.458523988723755}", "{\"n\": 8685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.57, \"learn_time_ms\": 8427.683, \"total_train_time_s\": 10.509073495864868}", "{\"n\": 8686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.57, \"learn_time_ms\": 8398.162, \"total_train_time_s\": 9.517937421798706}", "{\"n\": 8687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.25, \"learn_time_ms\": 8439.977, \"total_train_time_s\": 10.420681476593018}", "{\"n\": 8688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.38, \"learn_time_ms\": 8634.335, \"total_train_time_s\": 11.071875095367432}", "{\"n\": 8689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.67, \"learn_time_ms\": 8693.287, \"total_train_time_s\": 10.645219564437866}", "{\"n\": 8690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.73, \"learn_time_ms\": 8750.477, \"total_train_time_s\": 9.727469682693481}", "{\"n\": 8691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.73, \"learn_time_ms\": 8978.226, \"total_train_time_s\": 10.306794881820679}", "{\"n\": 8692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.19, \"learn_time_ms\": 8957.474, \"total_train_time_s\": 9.539172887802124}", "{\"n\": 8693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.81, \"learn_time_ms\": 9192.387, \"total_train_time_s\": 12.69791054725647}", "{\"n\": 8694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.94, \"learn_time_ms\": 9031.435, \"total_train_time_s\": 9.869462013244629}", "{\"n\": 8695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.88, \"learn_time_ms\": 9095.628, \"total_train_time_s\": 11.163675785064697}", "{\"n\": 8696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.88, \"learn_time_ms\": 9175.119, \"total_train_time_s\": 10.301334619522095}", "{\"n\": 8697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.57, \"learn_time_ms\": 9072.885, \"total_train_time_s\": 9.393778085708618}", "{\"n\": 8698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.57, \"learn_time_ms\": 8894.962, \"total_train_time_s\": 9.257469177246094}", "{\"n\": 8699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.45, \"learn_time_ms\": 8869.64, \"total_train_time_s\": 10.387530326843262}", "{\"n\": 8700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.14, \"learn_time_ms\": 8819.468, \"total_train_time_s\": 9.198680639266968}", "{\"n\": 8701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.14, \"learn_time_ms\": 8712.633, \"total_train_time_s\": 9.203345537185669}", "{\"n\": 8702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.98, \"learn_time_ms\": 8594.315, \"total_train_time_s\": 8.316367149353027}", "{\"n\": 8703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.97, \"learn_time_ms\": 8110.23, \"total_train_time_s\": 7.8924291133880615}", "{\"n\": 8704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.97, \"learn_time_ms\": 8068.322, \"total_train_time_s\": 9.441449880599976}", "{\"n\": 8705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.73, \"learn_time_ms\": 7979.731, \"total_train_time_s\": 10.232041120529175}", "{\"n\": 8706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.08, \"learn_time_ms\": 8002.843, \"total_train_time_s\": 10.582628965377808}", "{\"n\": 8707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.08, \"learn_time_ms\": 8097.742, \"total_train_time_s\": 10.335575103759766}", "{\"n\": 8708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.08, \"learn_time_ms\": 8118.111, \"total_train_time_s\": 9.490838527679443}", "{\"n\": 8709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.72, \"learn_time_ms\": 8063.571, \"total_train_time_s\": 9.912837982177734}", "{\"n\": 8710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.72, \"learn_time_ms\": 8059.416, \"total_train_time_s\": 9.236387729644775}", "{\"n\": 8711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.72, \"learn_time_ms\": 8227.826, \"total_train_time_s\": 10.955371141433716}", "{\"n\": 8712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.92, \"learn_time_ms\": 8366.718, \"total_train_time_s\": 9.745311737060547}", "{\"n\": 8713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.77, \"learn_time_ms\": 8536.355, \"total_train_time_s\": 9.620269298553467}", "{\"n\": 8714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.77, \"learn_time_ms\": 8583.821, \"total_train_time_s\": 9.95146632194519}", "{\"n\": 8715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.07, \"learn_time_ms\": 8463.949, \"total_train_time_s\": 9.090542078018188}", "{\"n\": 8716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.94, \"learn_time_ms\": 8501.355, \"total_train_time_s\": 10.940892696380615}", "{\"n\": 8717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.94, \"learn_time_ms\": 8389.477, \"total_train_time_s\": 9.219385385513306}", "{\"n\": 8718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.94, \"learn_time_ms\": 8357.621, \"total_train_time_s\": 9.177907228469849}", "{\"n\": 8719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.61, \"learn_time_ms\": 8576.845, \"total_train_time_s\": 12.062091588973999}", "{\"n\": 8720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.0, \"learn_time_ms\": 8682.338, \"total_train_time_s\": 10.27395224571228}", "{\"n\": 8721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.08, \"learn_time_ms\": 8697.194, \"total_train_time_s\": 11.099735975265503}", "{\"n\": 8722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.08, \"learn_time_ms\": 8669.319, \"total_train_time_s\": 9.487223386764526}", "{\"n\": 8723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.43, \"learn_time_ms\": 8676.022, \"total_train_time_s\": 9.610556840896606}", "{\"n\": 8724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.43, \"learn_time_ms\": 8805.151, \"total_train_time_s\": 11.17650842666626}", "{\"n\": 8725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.14, \"learn_time_ms\": 9006.364, \"total_train_time_s\": 11.09838342666626}", "{\"n\": 8726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.93, \"learn_time_ms\": 9011.98, \"total_train_time_s\": 11.045844316482544}", "{\"n\": 8727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.93, \"learn_time_ms\": 9138.299, \"total_train_time_s\": 10.481333494186401}", "{\"n\": 8728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.93, \"learn_time_ms\": 9088.055, \"total_train_time_s\": 8.666287660598755}", "{\"n\": 8729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.48, \"learn_time_ms\": 8944.184, \"total_train_time_s\": 10.593007564544678}", "{\"n\": 8730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.48, \"learn_time_ms\": 8852.896, \"total_train_time_s\": 9.346250057220459}", "{\"n\": 8731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.48, \"learn_time_ms\": 8660.18, \"total_train_time_s\": 9.149896621704102}", "{\"n\": 8732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.68, \"learn_time_ms\": 8668.305, \"total_train_time_s\": 9.558916091918945}", "{\"n\": 8733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.84, \"learn_time_ms\": 8691.83, \"total_train_time_s\": 9.902831792831421}", "{\"n\": 8734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.84, \"learn_time_ms\": 8601.604, \"total_train_time_s\": 10.279735565185547}", "{\"n\": 8735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.42, \"learn_time_ms\": 8457.522, \"total_train_time_s\": 9.59673023223877}", "{\"n\": 8736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.38, \"learn_time_ms\": 8534.301, \"total_train_time_s\": 11.77530288696289}", "{\"n\": 8737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.38, \"learn_time_ms\": 8444.144, \"total_train_time_s\": 9.61163854598999}", "{\"n\": 8738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.38, \"learn_time_ms\": 8582.463, \"total_train_time_s\": 10.07637619972229}", "{\"n\": 8739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.62, \"learn_time_ms\": 8517.444, \"total_train_time_s\": 10.044967889785767}", "{\"n\": 8740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.62, \"learn_time_ms\": 8768.272, \"total_train_time_s\": 11.873058319091797}", "{\"n\": 8741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.62, \"learn_time_ms\": 8792.734, \"total_train_time_s\": 9.391425371170044}", "{\"n\": 8742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.11, \"learn_time_ms\": 8970.09, \"total_train_time_s\": 11.307732820510864}", "{\"n\": 8743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.11, \"learn_time_ms\": 8958.83, \"total_train_time_s\": 9.764504671096802}", "{\"n\": 8744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.11, \"learn_time_ms\": 9050.4, \"total_train_time_s\": 11.217145442962646}", "{\"n\": 8745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.55, \"learn_time_ms\": 9010.185, \"total_train_time_s\": 9.235549688339233}", "{\"n\": 8746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.28, \"learn_time_ms\": 8830.767, \"total_train_time_s\": 9.991058826446533}", "{\"n\": 8747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.28, \"learn_time_ms\": 8839.863, \"total_train_time_s\": 9.660483121871948}", "{\"n\": 8748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.12, \"learn_time_ms\": 8846.553, \"total_train_time_s\": 10.129648447036743}", "{\"n\": 8749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.44, \"learn_time_ms\": 8890.942, \"total_train_time_s\": 10.449180126190186}", "{\"n\": 8750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.44, \"learn_time_ms\": 8750.71, \"total_train_time_s\": 10.418559312820435}", "{\"n\": 8751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.5, \"learn_time_ms\": 8659.628, \"total_train_time_s\": 8.502895832061768}", "{\"n\": 8752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.38, \"learn_time_ms\": 8513.456, \"total_train_time_s\": 9.868119239807129}", "{\"n\": 8753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.38, \"learn_time_ms\": 8509.603, \"total_train_time_s\": 9.684554815292358}", "{\"n\": 8754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.67, \"learn_time_ms\": 8275.279, \"total_train_time_s\": 8.829068422317505}", "{\"n\": 8755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.11, \"learn_time_ms\": 8495.974, \"total_train_time_s\": 11.483402729034424}", "{\"n\": 8756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.11, \"learn_time_ms\": 8304.983, \"total_train_time_s\": 8.106811285018921}", "{\"n\": 8757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.7, \"learn_time_ms\": 8474.006, \"total_train_time_s\": 11.374280452728271}", "{\"n\": 8758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.01, \"learn_time_ms\": 8525.925, \"total_train_time_s\": 10.699337244033813}", "{\"n\": 8759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.01, \"learn_time_ms\": 8390.627, \"total_train_time_s\": 9.044410228729248}", "{\"n\": 8760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.01, \"learn_time_ms\": 8382.918, \"total_train_time_s\": 10.388874053955078}", "{\"n\": 8761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.28, \"learn_time_ms\": 8426.1, \"total_train_time_s\": 8.960315942764282}", "{\"n\": 8762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.28, \"learn_time_ms\": 8626.583, \"total_train_time_s\": 11.872477293014526}", "{\"n\": 8763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.28, \"learn_time_ms\": 8782.514, \"total_train_time_s\": 11.301940441131592}", "{\"n\": 8764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.68, \"learn_time_ms\": 8885.864, \"total_train_time_s\": 9.967883348464966}", "{\"n\": 8765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8745.019, \"total_train_time_s\": 10.09797477722168}", "{\"n\": 8766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8953.321, \"total_train_time_s\": 10.154022216796875}", "{\"n\": 8767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8889.467, \"total_train_time_s\": 10.718786239624023}", "{\"n\": 8768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.2, \"learn_time_ms\": 8736.96, \"total_train_time_s\": 9.153571367263794}", "{\"n\": 8769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.2, \"learn_time_ms\": 8737.899, \"total_train_time_s\": 9.091312170028687}", "{\"n\": 8770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.2, \"learn_time_ms\": 8758.76, \"total_train_time_s\": 10.602983236312866}", "{\"n\": 8771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.96, \"learn_time_ms\": 8815.538, \"total_train_time_s\": 9.460270404815674}", "{\"n\": 8772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.86, \"learn_time_ms\": 8562.54, \"total_train_time_s\": 9.283982038497925}", "{\"n\": 8773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.86, \"learn_time_ms\": 8385.058, \"total_train_time_s\": 9.470689296722412}", "{\"n\": 8774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.41, \"learn_time_ms\": 8410.341, \"total_train_time_s\": 10.187252044677734}", "{\"n\": 8775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.42, \"learn_time_ms\": 8486.105, \"total_train_time_s\": 10.813940048217773}", "{\"n\": 8776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.42, \"learn_time_ms\": 8487.703, \"total_train_time_s\": 10.168288946151733}", "{\"n\": 8777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.5, \"learn_time_ms\": 8607.902, \"total_train_time_s\": 11.953195333480835}", "{\"n\": 8778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.32, \"learn_time_ms\": 8721.912, \"total_train_time_s\": 10.23227047920227}", "{\"n\": 8779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.21, \"learn_time_ms\": 8700.215, \"total_train_time_s\": 8.889214754104614}", "{\"n\": 8780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.55, \"learn_time_ms\": 8605.344, \"total_train_time_s\": 9.640482187271118}", "{\"n\": 8781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.53, \"learn_time_ms\": 8722.835, \"total_train_time_s\": 10.65591549873352}", "{\"n\": 8782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.34, \"learn_time_ms\": 8764.662, \"total_train_time_s\": 9.690056324005127}", "{\"n\": 8783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.37, \"learn_time_ms\": 8703.563, \"total_train_time_s\": 8.881735563278198}", "{\"n\": 8784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.2, \"learn_time_ms\": 8802.098, \"total_train_time_s\": 11.153485536575317}", "{\"n\": 8785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.32, \"learn_time_ms\": 8731.725, \"total_train_time_s\": 10.116508722305298}", "{\"n\": 8786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.32, \"learn_time_ms\": 8738.836, \"total_train_time_s\": 10.222756624221802}", "{\"n\": 8787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.66, \"learn_time_ms\": 8612.472, \"total_train_time_s\": 10.660771131515503}", "{\"n\": 8788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.66, \"learn_time_ms\": 8535.454, \"total_train_time_s\": 9.472220182418823}", "{\"n\": 8789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.9, \"learn_time_ms\": 8569.834, \"total_train_time_s\": 9.210114002227783}", "{\"n\": 8790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.72, \"learn_time_ms\": 8706.891, \"total_train_time_s\": 11.002182006835938}", "{\"n\": 8791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.46, \"learn_time_ms\": 8599.278, \"total_train_time_s\": 9.597581386566162}", "{\"n\": 8792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.56, \"learn_time_ms\": 8656.966, \"total_train_time_s\": 10.288543224334717}", "{\"n\": 8793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.39, \"learn_time_ms\": 8806.139, \"total_train_time_s\": 10.414806842803955}", "{\"n\": 8794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.1, \"learn_time_ms\": 8859.233, \"total_train_time_s\": 11.709072351455688}", "{\"n\": 8795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.1, \"learn_time_ms\": 8909.938, \"total_train_time_s\": 10.57941198348999}", "{\"n\": 8796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.52, \"learn_time_ms\": 8814.583, \"total_train_time_s\": 9.301846504211426}", "{\"n\": 8797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.12, \"learn_time_ms\": 8745.304, \"total_train_time_s\": 9.941006898880005}", "{\"n\": 8798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.12, \"learn_time_ms\": 8815.29, \"total_train_time_s\": 10.16059160232544}", "{\"n\": 8799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.94, \"learn_time_ms\": 8810.843, \"total_train_time_s\": 9.167107105255127}", "{\"n\": 8800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.4, \"learn_time_ms\": 8557.759, \"total_train_time_s\": 8.454035520553589}", "{\"n\": 8801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.4, \"learn_time_ms\": 8758.896, \"total_train_time_s\": 11.64046835899353}", "{\"n\": 8802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.4, \"learn_time_ms\": 8755.581, \"total_train_time_s\": 10.33639645576477}", "{\"n\": 8803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.49, \"learn_time_ms\": 8696.033, \"total_train_time_s\": 9.838085174560547}", "{\"n\": 8804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.77, \"learn_time_ms\": 8471.854, \"total_train_time_s\": 9.434518814086914}", "{\"n\": 8805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.77, \"learn_time_ms\": 8427.122, \"total_train_time_s\": 10.15045690536499}", "{\"n\": 8806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.96, \"learn_time_ms\": 8591.594, \"total_train_time_s\": 10.926283597946167}", "{\"n\": 8807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.17, \"learn_time_ms\": 8585.8, \"total_train_time_s\": 9.922428369522095}", "{\"n\": 8808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.17, \"learn_time_ms\": 8622.439, \"total_train_time_s\": 10.55941367149353}", "{\"n\": 8809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.23, \"learn_time_ms\": 8715.528, \"total_train_time_s\": 10.128880262374878}", "{\"n\": 8810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.34, \"learn_time_ms\": 8973.833, \"total_train_time_s\": 11.047684669494629}", "{\"n\": 8811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.38, \"learn_time_ms\": 8801.832, \"total_train_time_s\": 9.896011352539062}", "{\"n\": 8812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.6, \"learn_time_ms\": 8701.363, \"total_train_time_s\": 9.260425567626953}", "{\"n\": 8813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.92, \"learn_time_ms\": 8672.129, \"total_train_time_s\": 9.527826309204102}", "{\"n\": 8814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.24, \"learn_time_ms\": 8745.364, \"total_train_time_s\": 10.223864078521729}", "{\"n\": 8815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.24, \"learn_time_ms\": 8692.979, \"total_train_time_s\": 9.605571746826172}", "{\"n\": 8816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.89, \"learn_time_ms\": 8645.167, \"total_train_time_s\": 10.451639890670776}", "{\"n\": 8817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8713.837, \"total_train_time_s\": 10.649219512939453}", "{\"n\": 8818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8686.085, \"total_train_time_s\": 10.268870115280151}", "{\"n\": 8819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.67, \"learn_time_ms\": 8687.892, \"total_train_time_s\": 10.072458982467651}", "{\"n\": 8820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.31, \"learn_time_ms\": 8694.926, \"total_train_time_s\": 11.088421106338501}", "{\"n\": 8821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.31, \"learn_time_ms\": 8548.455, \"total_train_time_s\": 8.368179082870483}", "{\"n\": 8822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.31, \"learn_time_ms\": 8702.999, \"total_train_time_s\": 10.795530319213867}", "{\"n\": 8823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 8847.707, \"total_train_time_s\": 10.964099884033203}", "{\"n\": 8824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 8761.171, \"total_train_time_s\": 9.251843452453613}", "{\"n\": 8825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.92, \"learn_time_ms\": 8701.393, \"total_train_time_s\": 8.999746799468994}", "{\"n\": 8826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.52, \"learn_time_ms\": 8612.936, \"total_train_time_s\": 9.520193576812744}", "{\"n\": 8827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 8607.029, \"total_train_time_s\": 10.57431674003601}", "{\"n\": 8828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 8480.566, \"total_train_time_s\": 9.012173891067505}", "{\"n\": 8829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.64, \"learn_time_ms\": 8565.662, \"total_train_time_s\": 10.936633348464966}", "{\"n\": 8830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.04, \"learn_time_ms\": 8502.765, \"total_train_time_s\": 10.474521160125732}", "{\"n\": 8831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.73, \"learn_time_ms\": 8672.662, \"total_train_time_s\": 10.101107835769653}", "{\"n\": 8832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.73, \"learn_time_ms\": 8566.607, \"total_train_time_s\": 9.776938915252686}", "{\"n\": 8833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.78, \"learn_time_ms\": 8512.576, \"total_train_time_s\": 10.393922328948975}", "{\"n\": 8834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.28, \"learn_time_ms\": 8528.156, \"total_train_time_s\": 9.500013589859009}", "{\"n\": 8835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.28, \"learn_time_ms\": 8725.016, \"total_train_time_s\": 10.980663061141968}", "{\"n\": 8836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.24, \"learn_time_ms\": 8687.8, \"total_train_time_s\": 9.179242849349976}", "{\"n\": 8837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.72, \"learn_time_ms\": 8674.645, \"total_train_time_s\": 10.407319068908691}", "{\"n\": 8838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.72, \"learn_time_ms\": 8788.613, \"total_train_time_s\": 10.144884586334229}", "{\"n\": 8839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.77, \"learn_time_ms\": 8774.012, \"total_train_time_s\": 10.836241006851196}", "{\"n\": 8840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.77, \"learn_time_ms\": 8687.679, \"total_train_time_s\": 9.648167610168457}", "{\"n\": 8841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.72, \"learn_time_ms\": 8607.967, \"total_train_time_s\": 9.333430051803589}", "{\"n\": 8842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.72, \"learn_time_ms\": 8580.672, \"total_train_time_s\": 9.480652570724487}", "{\"n\": 8843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.21, \"learn_time_ms\": 8488.308, \"total_train_time_s\": 9.515329837799072}", "{\"n\": 8844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.53, \"learn_time_ms\": 8483.484, \"total_train_time_s\": 9.425012350082397}", "{\"n\": 8845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.53, \"learn_time_ms\": 8355.148, \"total_train_time_s\": 9.684603691101074}", "{\"n\": 8846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.33, \"learn_time_ms\": 8466.447, \"total_train_time_s\": 10.37894058227539}", "{\"n\": 8847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.33, \"learn_time_ms\": 8395.277, \"total_train_time_s\": 9.673025846481323}", "{\"n\": 8848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.59, \"learn_time_ms\": 8398.602, \"total_train_time_s\": 10.158496618270874}", "{\"n\": 8849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.57, \"learn_time_ms\": 8349.96, \"total_train_time_s\": 10.294689416885376}", "{\"n\": 8850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.57, \"learn_time_ms\": 8461.825, \"total_train_time_s\": 10.774561882019043}", "{\"n\": 8851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.83, \"learn_time_ms\": 8400.183, \"total_train_time_s\": 8.687866449356079}", "{\"n\": 8852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.35, \"learn_time_ms\": 8441.357, \"total_train_time_s\": 9.926187753677368}", "{\"n\": 8853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.75, \"learn_time_ms\": 8476.294, \"total_train_time_s\": 9.827503442764282}", "{\"n\": 8854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.49, \"learn_time_ms\": 8527.318, \"total_train_time_s\": 9.938162088394165}", "{\"n\": 8855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.63, \"learn_time_ms\": 8643.305, \"total_train_time_s\": 10.890739440917969}", "{\"n\": 8856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.02, \"learn_time_ms\": 8710.296, \"total_train_time_s\": 10.963263273239136}", "{\"n\": 8857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.0, \"learn_time_ms\": 8802.317, \"total_train_time_s\": 10.631832599639893}", "{\"n\": 8858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.0, \"learn_time_ms\": 8893.704, \"total_train_time_s\": 11.099887609481812}", "{\"n\": 8859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.12, \"learn_time_ms\": 8699.301, \"total_train_time_s\": 8.399898290634155}", "{\"n\": 8860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.42, \"learn_time_ms\": 8640.062, \"total_train_time_s\": 10.163711786270142}", "{\"n\": 8861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.42, \"learn_time_ms\": 8780.511, \"total_train_time_s\": 10.111297845840454}", "{\"n\": 8862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.09, \"learn_time_ms\": 8610.427, \"total_train_time_s\": 8.2080397605896}", "{\"n\": 8863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.27, \"learn_time_ms\": 8690.91, \"total_train_time_s\": 10.6673903465271}", "{\"n\": 8864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.27, \"learn_time_ms\": 8744.247, \"total_train_time_s\": 10.441981077194214}", "{\"n\": 8865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.01, \"learn_time_ms\": 8627.832, \"total_train_time_s\": 9.714216947555542}", "{\"n\": 8866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.6, \"learn_time_ms\": 8536.897, \"total_train_time_s\": 10.043630123138428}", "{\"n\": 8867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.4, \"learn_time_ms\": 8433.546, \"total_train_time_s\": 9.582325458526611}", "{\"n\": 8868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.95, \"learn_time_ms\": 8278.925, \"total_train_time_s\": 9.525484323501587}", "{\"n\": 8869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.96, \"learn_time_ms\": 8394.387, \"total_train_time_s\": 9.498349666595459}", "{\"n\": 8870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.42, \"learn_time_ms\": 8357.96, \"total_train_time_s\": 9.765109777450562}", "{\"n\": 8871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.58, \"learn_time_ms\": 8356.193, \"total_train_time_s\": 10.070300340652466}", "{\"n\": 8872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.81, \"learn_time_ms\": 8555.649, \"total_train_time_s\": 10.186041116714478}", "{\"n\": 8873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.73, \"learn_time_ms\": 8390.434, \"total_train_time_s\": 8.959344863891602}", "{\"n\": 8874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.64, \"learn_time_ms\": 8494.028, \"total_train_time_s\": 11.456675052642822}", "{\"n\": 8875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.9, \"learn_time_ms\": 8616.364, \"total_train_time_s\": 10.92982530593872}", "{\"n\": 8876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.22, \"learn_time_ms\": 8608.555, \"total_train_time_s\": 9.933828353881836}", "{\"n\": 8877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.22, \"learn_time_ms\": 8683.913, \"total_train_time_s\": 10.324504137039185}", "{\"n\": 8878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.33, \"learn_time_ms\": 8699.457, \"total_train_time_s\": 9.717670202255249}", "{\"n\": 8879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.33, \"learn_time_ms\": 8762.353, \"total_train_time_s\": 10.159512758255005}", "{\"n\": 8880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.72, \"learn_time_ms\": 8828.956, \"total_train_time_s\": 10.477184772491455}", "{\"n\": 8881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.72, \"learn_time_ms\": 8814.363, \"total_train_time_s\": 9.962360620498657}", "{\"n\": 8882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.88, \"learn_time_ms\": 8894.537, \"total_train_time_s\": 10.993359088897705}", "{\"n\": 8883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.06, \"learn_time_ms\": 9137.862, \"total_train_time_s\": 11.42421555519104}", "{\"n\": 8884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.32, \"learn_time_ms\": 8894.6, \"total_train_time_s\": 9.071478843688965}", "{\"n\": 8885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.03, \"learn_time_ms\": 8757.543, \"total_train_time_s\": 9.5209059715271}", "{\"n\": 8886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.91, \"learn_time_ms\": 8812.409, \"total_train_time_s\": 10.47449541091919}", "{\"n\": 8887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.75, \"learn_time_ms\": 8777.129, \"total_train_time_s\": 9.994545936584473}", "{\"n\": 8888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.43, \"learn_time_ms\": 8954.172, \"total_train_time_s\": 11.479374170303345}", "{\"n\": 8889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.43, \"learn_time_ms\": 8980.678, \"total_train_time_s\": 10.42825436592102}", "{\"n\": 8890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.81, \"learn_time_ms\": 9054.898, \"total_train_time_s\": 11.2150399684906}", "{\"n\": 8891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.02, \"learn_time_ms\": 9067.538, \"total_train_time_s\": 10.066027879714966}", "{\"n\": 8892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.02, \"learn_time_ms\": 8900.444, \"total_train_time_s\": 9.277261972427368}", "{\"n\": 8893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.3, \"learn_time_ms\": 8753.686, \"total_train_time_s\": 9.974708795547485}", "{\"n\": 8894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.98, \"learn_time_ms\": 8814.435, \"total_train_time_s\": 9.6622953414917}", "{\"n\": 8895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.99, \"learn_time_ms\": 8719.961, \"total_train_time_s\": 8.638696432113647}", "{\"n\": 8896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.88, \"learn_time_ms\": 8528.836, \"total_train_time_s\": 8.602936744689941}", "{\"n\": 8897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.43, \"learn_time_ms\": 8598.611, \"total_train_time_s\": 10.69120979309082}", "{\"n\": 8898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.03, \"learn_time_ms\": 8492.95, \"total_train_time_s\": 10.430810928344727}", "{\"n\": 8899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.03, \"learn_time_ms\": 8351.882, \"total_train_time_s\": 8.990899801254272}", "{\"n\": 8900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.26, \"learn_time_ms\": 8358.781, \"total_train_time_s\": 11.282204866409302}", "{\"n\": 8901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.83, \"learn_time_ms\": 8411.446, \"total_train_time_s\": 10.596094369888306}", "{\"n\": 8902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.83, \"learn_time_ms\": 8528.165, \"total_train_time_s\": 10.491434097290039}", "{\"n\": 8903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.5, \"learn_time_ms\": 8570.131, \"total_train_time_s\": 10.414331197738647}", "{\"n\": 8904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.41, \"learn_time_ms\": 8553.019, \"total_train_time_s\": 9.51622986793518}", "{\"n\": 8905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.41, \"learn_time_ms\": 8832.229, \"total_train_time_s\": 11.39388632774353}", "{\"n\": 8906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.41, \"learn_time_ms\": 8928.943, \"total_train_time_s\": 9.593368530273438}", "{\"n\": 8907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.65, \"learn_time_ms\": 8797.444, \"total_train_time_s\": 9.349656343460083}", "{\"n\": 8908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.36, \"learn_time_ms\": 8794.256, \"total_train_time_s\": 10.349467515945435}", "{\"n\": 8909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.36, \"learn_time_ms\": 8901.59, \"total_train_time_s\": 10.080932140350342}", "{\"n\": 8910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.2, \"learn_time_ms\": 8701.327, \"total_train_time_s\": 9.250825643539429}", "{\"n\": 8911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.42, \"learn_time_ms\": 8613.542, \"total_train_time_s\": 9.7482430934906}", "{\"n\": 8912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.42, \"learn_time_ms\": 8589.6, \"total_train_time_s\": 10.228394269943237}", "{\"n\": 8913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.21, \"learn_time_ms\": 8582.104, \"total_train_time_s\": 10.322184324264526}", "{\"n\": 8914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.82, \"learn_time_ms\": 8549.618, \"total_train_time_s\": 9.193172931671143}", "{\"n\": 8915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.38, \"learn_time_ms\": 8449.305, \"total_train_time_s\": 10.38476276397705}", "{\"n\": 8916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.66, \"learn_time_ms\": 8443.125, \"total_train_time_s\": 9.486891508102417}", "{\"n\": 8917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.67, \"learn_time_ms\": 8616.428, \"total_train_time_s\": 11.080991744995117}", "{\"n\": 8918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.72, \"learn_time_ms\": 8471.554, \"total_train_time_s\": 8.945336818695068}", "{\"n\": 8919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.72, \"learn_time_ms\": 8416.086, \"total_train_time_s\": 9.477429628372192}", "{\"n\": 8920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.9, \"learn_time_ms\": 8483.656, \"total_train_time_s\": 9.94686245918274}", "{\"n\": 8921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.13, \"learn_time_ms\": 8451.612, \"total_train_time_s\": 9.396916151046753}", "{\"n\": 8922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.13, \"learn_time_ms\": 8404.753, \"total_train_time_s\": 9.761162757873535}", "{\"n\": 8923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.82, \"learn_time_ms\": 8339.481, \"total_train_time_s\": 9.635244131088257}", "{\"n\": 8924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.26, \"learn_time_ms\": 8127.312, \"total_train_time_s\": 7.033749103546143}", "{\"n\": 8925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.26, \"learn_time_ms\": 8076.401, \"total_train_time_s\": 9.902965784072876}", "{\"n\": 8926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.83, \"learn_time_ms\": 8224.332, \"total_train_time_s\": 11.058434963226318}", "{\"n\": 8927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.35, \"learn_time_ms\": 8082.061, \"total_train_time_s\": 9.7403883934021}", "{\"n\": 8928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.92, \"learn_time_ms\": 8133.78, \"total_train_time_s\": 9.42515516281128}", "{\"n\": 8929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.08, \"learn_time_ms\": 8292.446, \"total_train_time_s\": 11.12643814086914}", "{\"n\": 8930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.58, \"learn_time_ms\": 8196.886, \"total_train_time_s\": 9.01419472694397}", "{\"n\": 8931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.49, \"learn_time_ms\": 8181.681, \"total_train_time_s\": 9.25543737411499}", "{\"n\": 8932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.49, \"learn_time_ms\": 8039.502, \"total_train_time_s\": 8.381410360336304}", "{\"n\": 8933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.06, \"learn_time_ms\": 8150.124, \"total_train_time_s\": 10.733407258987427}", "{\"n\": 8934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.14, \"learn_time_ms\": 8557.944, \"total_train_time_s\": 11.171513319015503}", "{\"n\": 8935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.94, \"learn_time_ms\": 8588.365, \"total_train_time_s\": 10.219784021377563}", "{\"n\": 8936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.94, \"learn_time_ms\": 8422.38, \"total_train_time_s\": 9.342906713485718}", "{\"n\": 8937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.18, \"learn_time_ms\": 8258.581, \"total_train_time_s\": 8.035277128219604}", "{\"n\": 8938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.86, \"learn_time_ms\": 8213.965, \"total_train_time_s\": 9.010850429534912}", "{\"n\": 8939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.51, \"learn_time_ms\": 8082.478, \"total_train_time_s\": 9.786317348480225}", "{\"n\": 8940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.07, \"learn_time_ms\": 8147.689, \"total_train_time_s\": 9.595090627670288}", "{\"n\": 8941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.57, \"learn_time_ms\": 8068.858, \"total_train_time_s\": 8.390746831893921}", "{\"n\": 8942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.11, \"learn_time_ms\": 8200.164, \"total_train_time_s\": 9.650962352752686}", "{\"n\": 8943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.97, \"learn_time_ms\": 7932.556, \"total_train_time_s\": 8.082875967025757}", "{\"n\": 8944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.97, \"learn_time_ms\": 7679.908, \"total_train_time_s\": 8.564042568206787}", "{\"n\": 8945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.47, \"learn_time_ms\": 7761.639, \"total_train_time_s\": 11.010030746459961}", "{\"n\": 8946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.47, \"learn_time_ms\": 7913.694, \"total_train_time_s\": 10.85903286933899}", "{\"n\": 8947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.28, \"learn_time_ms\": 8179.709, \"total_train_time_s\": 10.721781969070435}", "{\"n\": 8948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.26, \"learn_time_ms\": 8277.401, \"total_train_time_s\": 9.977124691009521}", "{\"n\": 8949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.26, \"learn_time_ms\": 8419.755, \"total_train_time_s\": 11.197409868240356}", "{\"n\": 8950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.14, \"learn_time_ms\": 8521.965, \"total_train_time_s\": 10.638051986694336}", "{\"n\": 8951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.82, \"learn_time_ms\": 8646.569, \"total_train_time_s\": 9.6707284450531}", "{\"n\": 8952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.82, \"learn_time_ms\": 8775.2, \"total_train_time_s\": 10.972095727920532}", "{\"n\": 8953, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.82, \"learn_time_ms\": 9056.951, \"total_train_time_s\": 10.893243789672852}", "{\"n\": 8954, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.02, \"learn_time_ms\": 9287.376, \"total_train_time_s\": 10.890223503112793}", "{\"n\": 8955, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.56, \"learn_time_ms\": 9137.834, \"total_train_time_s\": 9.531701564788818}", "{\"n\": 8956, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.56, \"learn_time_ms\": 9048.332, \"total_train_time_s\": 9.968784809112549}", "{\"n\": 8957, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.73, \"learn_time_ms\": 9067.72, \"total_train_time_s\": 10.899818420410156}", "{\"n\": 8958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.82, \"learn_time_ms\": 9051.501, \"total_train_time_s\": 9.841136693954468}", "{\"n\": 8959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.82, \"learn_time_ms\": 8952.481, \"total_train_time_s\": 10.233398199081421}", "{\"n\": 8960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.53, \"learn_time_ms\": 8882.475, \"total_train_time_s\": 9.978717803955078}", "{\"n\": 8961, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.71, \"learn_time_ms\": 8914.751, \"total_train_time_s\": 10.074487924575806}", "{\"n\": 8962, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.71, \"learn_time_ms\": 8976.155, \"total_train_time_s\": 11.572125673294067}", "{\"n\": 8963, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.64, \"learn_time_ms\": 8873.12, \"total_train_time_s\": 9.869391202926636}", "{\"n\": 8964, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.71, \"learn_time_ms\": 8781.738, \"total_train_time_s\": 10.005796909332275}", "{\"n\": 8965, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.71, \"learn_time_ms\": 8801.999, \"total_train_time_s\": 9.718086242675781}", "{\"n\": 8966, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.85, \"learn_time_ms\": 8865.241, \"total_train_time_s\": 10.605420589447021}", "{\"n\": 8967, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.48, \"learn_time_ms\": 8724.122, \"total_train_time_s\": 9.485931396484375}", "{\"n\": 8968, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.97, \"learn_time_ms\": 8742.121, \"total_train_time_s\": 9.997873783111572}", "{\"n\": 8969, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.09, \"learn_time_ms\": 8695.687, \"total_train_time_s\": 9.738110780715942}", "{\"n\": 8970, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.67, \"learn_time_ms\": 8704.963, \"total_train_time_s\": 10.035517930984497}", "{\"n\": 8971, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.67, \"learn_time_ms\": 8694.959, \"total_train_time_s\": 9.878655910491943}", "{\"n\": 8972, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.2, \"learn_time_ms\": 8443.893, \"total_train_time_s\": 9.075403213500977}", "{\"n\": 8973, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.13, \"learn_time_ms\": 8520.62, \"total_train_time_s\": 10.641443252563477}", "{\"n\": 8974, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.13, \"learn_time_ms\": 8244.285, \"total_train_time_s\": 7.201905727386475}", "{\"n\": 8975, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.43, \"learn_time_ms\": 8291.977, \"total_train_time_s\": 10.217819929122925}", "{\"n\": 8976, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.18, \"learn_time_ms\": 8116.193, \"total_train_time_s\": 8.861407995223999}", "{\"n\": 8977, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.95, \"learn_time_ms\": 8392.664, \"total_train_time_s\": 12.248395919799805}", "{\"n\": 8978, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.16, \"learn_time_ms\": 8548.888, \"total_train_time_s\": 11.562654733657837}", "{\"n\": 8979, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.6, \"learn_time_ms\": 8648.391, \"total_train_time_s\": 10.761085748672485}", "{\"n\": 8980, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.6, \"learn_time_ms\": 8610.852, \"total_train_time_s\": 9.66826868057251}", "{\"n\": 8981, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.68, \"learn_time_ms\": 8702.749, \"total_train_time_s\": 10.874757289886475}", "{\"n\": 8982, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.46, \"learn_time_ms\": 8847.065, \"total_train_time_s\": 10.511560678482056}", "{\"n\": 8983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.52, \"learn_time_ms\": 8815.102, \"total_train_time_s\": 10.341543197631836}", "{\"n\": 8984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.32, \"learn_time_ms\": 9046.458, \"total_train_time_s\": 9.57625126838684}", "{\"n\": 8985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.14, \"learn_time_ms\": 8988.379, \"total_train_time_s\": 9.602130651473999}", "{\"n\": 8986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.97, \"learn_time_ms\": 9218.015, \"total_train_time_s\": 11.151583671569824}", "{\"n\": 8987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.97, \"learn_time_ms\": 8932.223, \"total_train_time_s\": 9.36308217048645}", "{\"n\": 8988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.69, \"learn_time_ms\": 8714.285, \"total_train_time_s\": 9.435766696929932}", "{\"n\": 8989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.96, \"learn_time_ms\": 8670.913, \"total_train_time_s\": 10.313111066818237}", "{\"n\": 8990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.96, \"learn_time_ms\": 8653.94, \"total_train_time_s\": 9.480082750320435}", "{\"n\": 8991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.81, \"learn_time_ms\": 8577.283, \"total_train_time_s\": 10.122638702392578}", "{\"n\": 8992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8608.699, \"total_train_time_s\": 10.827666282653809}", "{\"n\": 8993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.43, \"learn_time_ms\": 8513.554, \"total_train_time_s\": 9.400315999984741}", "{\"n\": 8994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.84, \"learn_time_ms\": 8630.822, \"total_train_time_s\": 10.688953876495361}", "{\"n\": 8995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.85, \"learn_time_ms\": 8808.931, \"total_train_time_s\": 11.418269395828247}", "{\"n\": 8996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.85, \"learn_time_ms\": 8645.511, \"total_train_time_s\": 9.48716950416565}", "{\"n\": 8997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.65, \"learn_time_ms\": 8582.849, \"total_train_time_s\": 8.830837726593018}", "{\"n\": 8998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.94, \"learn_time_ms\": 8682.677, \"total_train_time_s\": 10.406324863433838}", "{\"n\": 8999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.94, \"learn_time_ms\": 8797.463, \"total_train_time_s\": 11.453287839889526}", "{\"n\": 9000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.81, \"learn_time_ms\": 8699.03, \"total_train_time_s\": 8.56403636932373}", "{\"n\": 9001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.38, \"learn_time_ms\": 8806.02, \"total_train_time_s\": 11.179282903671265}", "{\"n\": 9002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.34, \"learn_time_ms\": 8717.782, \"total_train_time_s\": 9.978317260742188}", "{\"n\": 9003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.75, \"learn_time_ms\": 8583.633, \"total_train_time_s\": 8.015181064605713}", "{\"n\": 9004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.11, \"learn_time_ms\": 8542.517, \"total_train_time_s\": 10.273319721221924}", "{\"n\": 9005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.83, \"learn_time_ms\": 8384.024, \"total_train_time_s\": 9.787993669509888}", "{\"n\": 9006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.83, \"learn_time_ms\": 8423.038, \"total_train_time_s\": 9.879073143005371}", "{\"n\": 9007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.43, \"learn_time_ms\": 8431.19, \"total_train_time_s\": 8.876416444778442}", "{\"n\": 9008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.59, \"learn_time_ms\": 8587.215, \"total_train_time_s\": 11.952751874923706}", "{\"n\": 9009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.59, \"learn_time_ms\": 8498.203, \"total_train_time_s\": 10.58835220336914}", "{\"n\": 9010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.78, \"learn_time_ms\": 8749.564, \"total_train_time_s\": 11.020088195800781}", "{\"n\": 9011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.67, \"learn_time_ms\": 8644.37, \"total_train_time_s\": 10.122406005859375}", "{\"n\": 9012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.67, \"learn_time_ms\": 8488.821, \"total_train_time_s\": 8.416669845581055}", "{\"n\": 9013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.33, \"learn_time_ms\": 8665.099, \"total_train_time_s\": 9.771429538726807}", "{\"n\": 9014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.94, \"learn_time_ms\": 8757.557, \"total_train_time_s\": 11.202713251113892}", "{\"n\": 9015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.97, \"learn_time_ms\": 8777.889, \"total_train_time_s\": 10.018115520477295}", "{\"n\": 9016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.97, \"learn_time_ms\": 8796.326, \"total_train_time_s\": 10.09741997718811}", "{\"n\": 9017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.48, \"learn_time_ms\": 8966.291, \"total_train_time_s\": 10.5585777759552}", "{\"n\": 9018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.89, \"learn_time_ms\": 8661.728, \"total_train_time_s\": 8.927334070205688}", "{\"n\": 9019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.89, \"learn_time_ms\": 8626.913, \"total_train_time_s\": 10.222832679748535}", "{\"n\": 9020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.55, \"learn_time_ms\": 8445.83, \"total_train_time_s\": 9.24372673034668}", "{\"n\": 9021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.62, \"learn_time_ms\": 8418.135, \"total_train_time_s\": 9.811542987823486}", "{\"n\": 9022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.62, \"learn_time_ms\": 8545.097, \"total_train_time_s\": 9.641060590744019}", "{\"n\": 9023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.04, \"learn_time_ms\": 8598.12, \"total_train_time_s\": 10.30780291557312}", "{\"n\": 9024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.97, \"learn_time_ms\": 8463.258, \"total_train_time_s\": 9.858747243881226}", "{\"n\": 9025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.93, \"learn_time_ms\": 8317.362, \"total_train_time_s\": 8.534977912902832}", "{\"n\": 9026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.93, \"learn_time_ms\": 8281.414, \"total_train_time_s\": 9.702340841293335}", "{\"n\": 9027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.16, \"learn_time_ms\": 8164.289, \"total_train_time_s\": 9.362313032150269}", "{\"n\": 9028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.42, \"learn_time_ms\": 8253.377, \"total_train_time_s\": 9.758008480072021}", "{\"n\": 9029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.42, \"learn_time_ms\": 8175.439, \"total_train_time_s\": 9.477320194244385}", "{\"n\": 9030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.97, \"learn_time_ms\": 8340.295, \"total_train_time_s\": 10.877219438552856}", "{\"n\": 9031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.32, \"learn_time_ms\": 8363.766, \"total_train_time_s\": 10.051024198532104}", "{\"n\": 9032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.32, \"learn_time_ms\": 8394.896, \"total_train_time_s\": 9.960362672805786}", "{\"n\": 9033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.89, \"learn_time_ms\": 8286.095, \"total_train_time_s\": 9.256006240844727}", "{\"n\": 9034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.44, \"learn_time_ms\": 8275.849, \"total_train_time_s\": 9.767017364501953}", "{\"n\": 9035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.8, \"learn_time_ms\": 8494.183, \"total_train_time_s\": 10.812948942184448}", "{\"n\": 9036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.21, \"learn_time_ms\": 8450.9, \"total_train_time_s\": 9.314735651016235}", "{\"n\": 9037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.75, \"learn_time_ms\": 8587.894, \"total_train_time_s\": 10.71439814567566}", "{\"n\": 9038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.59, \"learn_time_ms\": 8677.877, \"total_train_time_s\": 10.702062845230103}", "{\"n\": 9039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.77, \"learn_time_ms\": 8584.154, \"total_train_time_s\": 8.535267353057861}", "{\"n\": 9040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.77, \"learn_time_ms\": 8377.713, \"total_train_time_s\": 8.800960063934326}", "{\"n\": 9041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.69, \"learn_time_ms\": 8316.822, \"total_train_time_s\": 9.456242322921753}", "{\"n\": 9042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.69, \"learn_time_ms\": 8236.837, \"total_train_time_s\": 9.166991472244263}", "{\"n\": 9043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.63, \"learn_time_ms\": 8219.31, \"total_train_time_s\": 9.091310024261475}", "{\"n\": 9044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.6, \"learn_time_ms\": 8395.77, \"total_train_time_s\": 11.511777400970459}", "{\"n\": 9045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.13, \"learn_time_ms\": 8270.0, \"total_train_time_s\": 9.510254144668579}", "{\"n\": 9046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.61, \"learn_time_ms\": 8436.038, \"total_train_time_s\": 10.952252626419067}", "{\"n\": 9047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.61, \"learn_time_ms\": 8390.409, \"total_train_time_s\": 10.301440000534058}", "{\"n\": 9048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.17, \"learn_time_ms\": 8205.484, \"total_train_time_s\": 8.840561866760254}", "{\"n\": 9049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.02, \"learn_time_ms\": 8258.506, \"total_train_time_s\": 9.051068544387817}", "{\"n\": 9050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.53, \"learn_time_ms\": 8294.514, \"total_train_time_s\": 9.160029172897339}", "{\"n\": 9051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.91, \"learn_time_ms\": 8346.686, \"total_train_time_s\": 9.954395294189453}", "{\"n\": 9052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.2, \"learn_time_ms\": 8337.02, \"total_train_time_s\": 9.042953729629517}", "{\"n\": 9053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.32, \"learn_time_ms\": 8397.179, \"total_train_time_s\": 9.64427638053894}", "{\"n\": 9054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.62, \"learn_time_ms\": 8217.713, \"total_train_time_s\": 9.702668905258179}", "{\"n\": 9055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.62, \"learn_time_ms\": 8299.885, \"total_train_time_s\": 10.2680025100708}", "{\"n\": 9056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.41, \"learn_time_ms\": 8345.733, \"total_train_time_s\": 11.400211811065674}", "{\"n\": 9057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.14, \"learn_time_ms\": 8388.475, \"total_train_time_s\": 10.745688676834106}", "{\"n\": 9058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.51, \"learn_time_ms\": 8535.372, \"total_train_time_s\": 10.311117172241211}", "{\"n\": 9059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.24, \"learn_time_ms\": 8698.16, \"total_train_time_s\": 10.657749652862549}", "{\"n\": 9060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.23, \"learn_time_ms\": 8771.522, \"total_train_time_s\": 9.92855429649353}", "{\"n\": 9061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.09, \"learn_time_ms\": 8743.923, \"total_train_time_s\": 9.660447359085083}", "{\"n\": 9062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.09, \"learn_time_ms\": 8914.944, \"total_train_time_s\": 10.778734922409058}", "{\"n\": 9063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.49, \"learn_time_ms\": 8833.671, \"total_train_time_s\": 8.866070032119751}", "{\"n\": 9064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.67, \"learn_time_ms\": 8754.804, \"total_train_time_s\": 8.951979637145996}", "{\"n\": 9065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.67, \"learn_time_ms\": 8847.027, \"total_train_time_s\": 11.294302463531494}", "{\"n\": 9066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.86, \"learn_time_ms\": 8732.471, \"total_train_time_s\": 10.31082558631897}", "{\"n\": 9067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.88, \"learn_time_ms\": 8617.915, \"total_train_time_s\": 9.585272789001465}", "{\"n\": 9068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.89, \"learn_time_ms\": 8597.532, \"total_train_time_s\": 10.151790142059326}", "{\"n\": 9069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.93, \"learn_time_ms\": 8485.151, \"total_train_time_s\": 9.564699649810791}", "{\"n\": 9070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.06, \"learn_time_ms\": 8583.189, \"total_train_time_s\": 10.906328439712524}", "{\"n\": 9071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.79, \"learn_time_ms\": 8605.902, \"total_train_time_s\": 9.918232440948486}", "{\"n\": 9072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.64, \"learn_time_ms\": 8677.146, \"total_train_time_s\": 11.47943925857544}", "{\"n\": 9073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.97, \"learn_time_ms\": 8767.856, \"total_train_time_s\": 9.731750726699829}", "{\"n\": 9074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.49, \"learn_time_ms\": 8842.928, \"total_train_time_s\": 9.721702575683594}", "{\"n\": 9075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.36, \"learn_time_ms\": 8796.047, \"total_train_time_s\": 10.807361841201782}", "{\"n\": 9076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.9, \"learn_time_ms\": 8853.045, \"total_train_time_s\": 10.863929748535156}", "{\"n\": 9077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.46, \"learn_time_ms\": 8896.5, \"total_train_time_s\": 10.01562786102295}", "{\"n\": 9078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.62, \"learn_time_ms\": 8953.28, \"total_train_time_s\": 10.687196493148804}", "{\"n\": 9079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.06, \"learn_time_ms\": 9058.406, \"total_train_time_s\": 10.556411981582642}", "{\"n\": 9080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.08, \"learn_time_ms\": 8964.792, \"total_train_time_s\": 9.985640525817871}", "{\"n\": 9081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.08, \"learn_time_ms\": 9099.512, \"total_train_time_s\": 11.264740943908691}", "{\"n\": 9082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.26, \"learn_time_ms\": 9010.634, \"total_train_time_s\": 10.597476482391357}", "{\"n\": 9083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.59, \"learn_time_ms\": 9022.091, \"total_train_time_s\": 9.824634075164795}", "{\"n\": 9084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.54, \"learn_time_ms\": 9014.17, \"total_train_time_s\": 9.648684740066528}", "{\"n\": 9085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.53, \"learn_time_ms\": 8954.633, \"total_train_time_s\": 10.169660806655884}", "{\"n\": 9086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.67, \"learn_time_ms\": 8913.306, \"total_train_time_s\": 10.416386127471924}", "{\"n\": 9087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.49, \"learn_time_ms\": 8889.163, \"total_train_time_s\": 9.759469270706177}", "{\"n\": 9088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.77, \"learn_time_ms\": 8783.146, \"total_train_time_s\": 9.569333553314209}", "{\"n\": 9089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.61, \"learn_time_ms\": 8713.732, \"total_train_time_s\": 9.886837244033813}", "{\"n\": 9090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.61, \"learn_time_ms\": 8704.454, \"total_train_time_s\": 9.830530405044556}", "{\"n\": 9091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.78, \"learn_time_ms\": 8532.549, \"total_train_time_s\": 9.564978122711182}", "{\"n\": 9092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.93, \"learn_time_ms\": 8494.145, \"total_train_time_s\": 10.173967599868774}", "{\"n\": 9093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.69, \"learn_time_ms\": 8590.831, \"total_train_time_s\": 10.833460330963135}", "{\"n\": 9094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.77, \"learn_time_ms\": 8523.496, \"total_train_time_s\": 8.92736554145813}", "{\"n\": 9095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.36, \"learn_time_ms\": 8495.791, \"total_train_time_s\": 9.932983636856079}", "{\"n\": 9096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.96, \"learn_time_ms\": 8369.078, \"total_train_time_s\": 9.130491733551025}", "{\"n\": 9097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.9, \"learn_time_ms\": 8343.868, \"total_train_time_s\": 9.547621250152588}", "{\"n\": 9098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.9, \"learn_time_ms\": 8382.316, \"total_train_time_s\": 9.992461919784546}", "{\"n\": 9099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.62, \"learn_time_ms\": 8358.761, \"total_train_time_s\": 9.695204973220825}", "{\"n\": 9100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.62, \"learn_time_ms\": 8431.577, \"total_train_time_s\": 10.524747371673584}", "{\"n\": 9101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.27, \"learn_time_ms\": 8512.533, \"total_train_time_s\": 10.326742172241211}", "{\"n\": 9102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.62, \"learn_time_ms\": 8450.385, \"total_train_time_s\": 9.574088335037231}", "{\"n\": 9103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.24, \"learn_time_ms\": 8382.213, \"total_train_time_s\": 10.096764326095581}", "{\"n\": 9104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.28, \"learn_time_ms\": 8454.859, \"total_train_time_s\": 9.666882038116455}", "{\"n\": 9105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.28, \"learn_time_ms\": 8550.17, \"total_train_time_s\": 10.85814619064331}", "{\"n\": 9106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.16, \"learn_time_ms\": 8598.99, \"total_train_time_s\": 9.602195739746094}", "{\"n\": 9107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.62, \"learn_time_ms\": 8594.738, \"total_train_time_s\": 9.47171926498413}", "{\"n\": 9108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.62, \"learn_time_ms\": 8614.856, \"total_train_time_s\": 10.164412498474121}", "{\"n\": 9109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.29, \"learn_time_ms\": 8503.153, \"total_train_time_s\": 8.558033466339111}", "{\"n\": 9110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.61, \"learn_time_ms\": 8475.882, \"total_train_time_s\": 10.323046922683716}", "{\"n\": 9111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.61, \"learn_time_ms\": 8516.125, \"total_train_time_s\": 10.815359592437744}", "{\"n\": 9112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.19, \"learn_time_ms\": 8546.632, \"total_train_time_s\": 9.887874841690063}", "{\"n\": 9113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.78, \"learn_time_ms\": 8430.138, \"total_train_time_s\": 9.024522066116333}", "{\"n\": 9114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.22, \"learn_time_ms\": 8546.441, \"total_train_time_s\": 10.86675763130188}", "{\"n\": 9115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.33, \"learn_time_ms\": 8328.137, \"total_train_time_s\": 8.69642949104309}", "{\"n\": 9116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.22, \"learn_time_ms\": 8387.801, \"total_train_time_s\": 10.238173484802246}", "{\"n\": 9117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.17, \"learn_time_ms\": 8532.052, \"total_train_time_s\": 10.950630903244019}", "{\"n\": 9118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 8387.646, \"total_train_time_s\": 8.787028312683105}", "{\"n\": 9119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.79, \"learn_time_ms\": 8527.826, \"total_train_time_s\": 9.938859939575195}", "{\"n\": 9120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.85, \"learn_time_ms\": 8411.588, \"total_train_time_s\": 9.185725212097168}", "{\"n\": 9121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 8393.603, \"total_train_time_s\": 10.60034704208374}", "{\"n\": 9122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 8291.04, \"total_train_time_s\": 8.883701086044312}", "{\"n\": 9123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.86, \"learn_time_ms\": 8398.584, \"total_train_time_s\": 10.026814699172974}", "{\"n\": 9124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.07, \"learn_time_ms\": 8379.44, \"total_train_time_s\": 10.65786600112915}", "{\"n\": 9125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.57, \"learn_time_ms\": 8522.518, \"total_train_time_s\": 10.107055902481079}", "{\"n\": 9126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.73, \"learn_time_ms\": 8503.084, \"total_train_time_s\": 10.012985944747925}", "{\"n\": 9127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.91, \"learn_time_ms\": 8431.033, \"total_train_time_s\": 10.265758514404297}", "{\"n\": 9128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.91, \"learn_time_ms\": 8439.824, \"total_train_time_s\": 8.869696617126465}", "{\"n\": 9129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.91, \"learn_time_ms\": 8484.077, \"total_train_time_s\": 10.390397071838379}", "{\"n\": 9130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.13, \"learn_time_ms\": 8631.558, \"total_train_time_s\": 10.643693685531616}", "{\"n\": 9131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.63, \"learn_time_ms\": 8562.664, \"total_train_time_s\": 9.883921146392822}", "{\"n\": 9132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.63, \"learn_time_ms\": 8596.635, \"total_train_time_s\": 9.20962381362915}", "{\"n\": 9133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.39, \"learn_time_ms\": 8751.329, \"total_train_time_s\": 11.660577535629272}", "{\"n\": 9134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.3, \"learn_time_ms\": 8690.484, \"total_train_time_s\": 10.101982593536377}", "{\"n\": 9135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.33, \"learn_time_ms\": 8569.288, \"total_train_time_s\": 8.863861799240112}", "{\"n\": 9136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.34, \"learn_time_ms\": 8432.162, \"total_train_time_s\": 8.67133641242981}", "{\"n\": 9137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.34, \"learn_time_ms\": 8384.539, \"total_train_time_s\": 9.697856903076172}", "{\"n\": 9138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.32, \"learn_time_ms\": 8360.411, \"total_train_time_s\": 8.56273865699768}", "{\"n\": 9139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.94, \"learn_time_ms\": 8247.003, \"total_train_time_s\": 9.24065113067627}", "{\"n\": 9140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.97, \"learn_time_ms\": 8248.985, \"total_train_time_s\": 10.629258155822754}", "{\"n\": 9141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.08, \"learn_time_ms\": 8342.946, \"total_train_time_s\": 10.799672603607178}", "{\"n\": 9142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.05, \"learn_time_ms\": 8290.46, \"total_train_time_s\": 8.672032356262207}", "{\"n\": 9143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.05, \"learn_time_ms\": 8031.42, \"total_train_time_s\": 9.00718092918396}", "{\"n\": 9144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.05, \"learn_time_ms\": 7957.043, \"total_train_time_s\": 9.280188083648682}", "{\"n\": 9145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 7997.79, \"total_train_time_s\": 9.329589605331421}", "{\"n\": 9146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.51, \"learn_time_ms\": 8204.952, \"total_train_time_s\": 10.797553062438965}", "{\"n\": 9147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.51, \"learn_time_ms\": 8248.609, \"total_train_time_s\": 10.12498927116394}", "{\"n\": 9148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.88, \"learn_time_ms\": 8432.199, \"total_train_time_s\": 10.436340093612671}", "{\"n\": 9149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 8523.006, \"total_train_time_s\": 10.190465927124023}", "{\"n\": 9150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.08, \"learn_time_ms\": 8437.873, \"total_train_time_s\": 9.807848930358887}", "{\"n\": 9151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.13, \"learn_time_ms\": 8463.256, \"total_train_time_s\": 11.146109104156494}", "{\"n\": 9152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.15, \"learn_time_ms\": 8694.551, \"total_train_time_s\": 11.044515132904053}", "{\"n\": 9153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.5, \"learn_time_ms\": 8663.51, \"total_train_time_s\": 8.688448190689087}", "{\"n\": 9154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.3, \"learn_time_ms\": 8693.121, \"total_train_time_s\": 9.622052192687988}", "{\"n\": 9155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.85, \"learn_time_ms\": 8801.729, \"total_train_time_s\": 10.40593147277832}", "{\"n\": 9156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.85, \"learn_time_ms\": 8699.65, \"total_train_time_s\": 9.711688756942749}", "{\"n\": 9157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.45, \"learn_time_ms\": 8720.091, \"total_train_time_s\": 10.386011362075806}", "{\"n\": 9158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.41, \"learn_time_ms\": 8714.854, \"total_train_time_s\": 10.367456197738647}", "{\"n\": 9159, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.02, \"learn_time_ms\": 8647.896, \"total_train_time_s\": 9.526940822601318}", "{\"n\": 9160, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.97, \"learn_time_ms\": 8729.641, \"total_train_time_s\": 10.605088472366333}", "{\"n\": 9161, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.97, \"learn_time_ms\": 8705.292, \"total_train_time_s\": 10.82703423500061}", "{\"n\": 9162, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.7, \"learn_time_ms\": 8560.497, \"total_train_time_s\": 9.5680091381073}", "{\"n\": 9163, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.13, \"learn_time_ms\": 8730.442, \"total_train_time_s\": 10.428725957870483}", "{\"n\": 9164, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.68, \"learn_time_ms\": 8854.995, \"total_train_time_s\": 10.853047609329224}", "{\"n\": 9165, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.68, \"learn_time_ms\": 8776.699, \"total_train_time_s\": 9.59327507019043}", "{\"n\": 9166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.38, \"learn_time_ms\": 8812.992, \"total_train_time_s\": 10.10010027885437}", "{\"n\": 9167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.94, \"learn_time_ms\": 8813.734, \"total_train_time_s\": 10.456718683242798}", "{\"n\": 9168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.94, \"learn_time_ms\": 8756.16, \"total_train_time_s\": 9.765009641647339}", "{\"n\": 9169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.15, \"learn_time_ms\": 8835.622, \"total_train_time_s\": 10.308268308639526}", "{\"n\": 9170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.3, \"learn_time_ms\": 8818.612, \"total_train_time_s\": 10.450869083404541}", "{\"n\": 9171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.3, \"learn_time_ms\": 8772.478, \"total_train_time_s\": 10.369749784469604}", "{\"n\": 9172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.3, \"learn_time_ms\": 8807.276, \"total_train_time_s\": 9.89613151550293}", "{\"n\": 9173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.98, \"learn_time_ms\": 8730.913, \"total_train_time_s\": 9.626367330551147}", "{\"n\": 9174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.71, \"learn_time_ms\": 8618.887, \"total_train_time_s\": 9.74307632446289}", "{\"n\": 9175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.71, \"learn_time_ms\": 8772.121, \"total_train_time_s\": 11.15294623374939}", "{\"n\": 9176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.28, \"learn_time_ms\": 8753.272, \"total_train_time_s\": 9.950284004211426}", "{\"n\": 9177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.72, \"learn_time_ms\": 8723.691, \"total_train_time_s\": 10.093668699264526}", "{\"n\": 9178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.72, \"learn_time_ms\": 8736.713, \"total_train_time_s\": 9.923370599746704}", "{\"n\": 9179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.41, \"learn_time_ms\": 8602.86, \"total_train_time_s\": 8.985049962997437}", "{\"n\": 9180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.77, \"learn_time_ms\": 8512.224, \"total_train_time_s\": 9.546806573867798}", "{\"n\": 9181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.77, \"learn_time_ms\": 8487.206, \"total_train_time_s\": 10.114859819412231}", "{\"n\": 9182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.77, \"learn_time_ms\": 8381.547, \"total_train_time_s\": 8.824878454208374}", "{\"n\": 9183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.99, \"learn_time_ms\": 8366.309, \"total_train_time_s\": 9.512081861495972}", "{\"n\": 9184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.86, \"learn_time_ms\": 8404.589, \"total_train_time_s\": 10.066466808319092}", "{\"n\": 9185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.86, \"learn_time_ms\": 8312.445, \"total_train_time_s\": 10.227818965911865}", "{\"n\": 9186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.82, \"learn_time_ms\": 8232.618, \"total_train_time_s\": 9.098466873168945}", "{\"n\": 9187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.38, \"learn_time_ms\": 8393.298, \"total_train_time_s\": 11.710217475891113}", "{\"n\": 9188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.38, \"learn_time_ms\": 8334.526, \"total_train_time_s\": 9.369919538497925}", "{\"n\": 9189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.48, \"learn_time_ms\": 8334.393, \"total_train_time_s\": 8.956237316131592}", "{\"n\": 9190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.14, \"learn_time_ms\": 8392.689, \"total_train_time_s\": 10.098401069641113}", "{\"n\": 9191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.14, \"learn_time_ms\": 8490.618, \"total_train_time_s\": 11.137319803237915}", "{\"n\": 9192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.64, \"learn_time_ms\": 8681.926, \"total_train_time_s\": 10.771184206008911}", "{\"n\": 9193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 8783.573, \"total_train_time_s\": 10.515605211257935}", "{\"n\": 9194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 8870.387, \"total_train_time_s\": 10.942423105239868}", "{\"n\": 9195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 8959.664, \"total_train_time_s\": 11.090731859207153}", "{\"n\": 9196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.66, \"learn_time_ms\": 9186.619, \"total_train_time_s\": 11.389472484588623}", "{\"n\": 9197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.49, \"learn_time_ms\": 9050.367, \"total_train_time_s\": 10.360149145126343}", "{\"n\": 9198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.49, \"learn_time_ms\": 9155.569, \"total_train_time_s\": 10.390142917633057}", "{\"n\": 9199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.98, \"learn_time_ms\": 9236.453, \"total_train_time_s\": 9.772702693939209}", "{\"n\": 9200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 9178.962, \"total_train_time_s\": 9.517855167388916}", "{\"n\": 9201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 9024.415, \"total_train_time_s\": 9.527224063873291}", "{\"n\": 9202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 9074.86, \"total_train_time_s\": 11.290126085281372}", "{\"n\": 9203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.43, \"learn_time_ms\": 8968.882, \"total_train_time_s\": 9.427694082260132}", "{\"n\": 9204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.43, \"learn_time_ms\": 8860.999, \"total_train_time_s\": 9.867741107940674}", "{\"n\": 9205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.43, \"learn_time_ms\": 8742.807, \"total_train_time_s\": 10.001418113708496}", "{\"n\": 9206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.0, \"learn_time_ms\": 8565.252, \"total_train_time_s\": 9.546624422073364}", "{\"n\": 9207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.18, \"learn_time_ms\": 8529.273, \"total_train_time_s\": 9.91794490814209}", "{\"n\": 9208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.18, \"learn_time_ms\": 8526.106, \"total_train_time_s\": 10.323498487472534}", "{\"n\": 9209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.21, \"learn_time_ms\": 8491.535, \"total_train_time_s\": 9.405393362045288}", "{\"n\": 9210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.34, \"learn_time_ms\": 8424.036, \"total_train_time_s\": 8.83338713645935}", "{\"n\": 9211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.34, \"learn_time_ms\": 8423.394, \"total_train_time_s\": 9.546303749084473}", "{\"n\": 9212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.08, \"learn_time_ms\": 8285.014, \"total_train_time_s\": 9.870011806488037}", "{\"n\": 9213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.52, \"learn_time_ms\": 8531.587, \"total_train_time_s\": 11.940935134887695}", "{\"n\": 9214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.14, \"learn_time_ms\": 8436.212, \"total_train_time_s\": 8.9895920753479}", "{\"n\": 9215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.14, \"learn_time_ms\": 8440.954, \"total_train_time_s\": 9.920470476150513}", "{\"n\": 9216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.37, \"learn_time_ms\": 8449.218, \"total_train_time_s\": 9.701412677764893}", "{\"n\": 9217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.88, \"learn_time_ms\": 8527.449, \"total_train_time_s\": 10.753045558929443}", "{\"n\": 9218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.88, \"learn_time_ms\": 8675.024, \"total_train_time_s\": 11.91861367225647}", "{\"n\": 9219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.13, \"learn_time_ms\": 8770.011, \"total_train_time_s\": 10.364435911178589}", "{\"n\": 9220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.88, \"learn_time_ms\": 8843.992, \"total_train_time_s\": 9.584274053573608}", "{\"n\": 9221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.32, \"learn_time_ms\": 8817.156, \"total_train_time_s\": 9.254443407058716}", "{\"n\": 9222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.75, \"learn_time_ms\": 8820.339, \"total_train_time_s\": 9.903604984283447}", "{\"n\": 9223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.14, \"learn_time_ms\": 8722.426, \"total_train_time_s\": 10.920910835266113}", "{\"n\": 9224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.47, \"learn_time_ms\": 8716.152, \"total_train_time_s\": 8.868293762207031}", "{\"n\": 9225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.63, \"learn_time_ms\": 8853.182, \"total_train_time_s\": 11.308408498764038}", "{\"n\": 9226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.63, \"learn_time_ms\": 8746.676, \"total_train_time_s\": 8.621205806732178}", "{\"n\": 9227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.64, \"learn_time_ms\": 8648.012, \"total_train_time_s\": 9.741206645965576}", "{\"n\": 9228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.48, \"learn_time_ms\": 8523.758, \"total_train_time_s\": 10.6017587184906}", "{\"n\": 9229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.93, \"learn_time_ms\": 8436.473, \"total_train_time_s\": 9.506732940673828}", "{\"n\": 9230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.32, \"learn_time_ms\": 8480.096, \"total_train_time_s\": 10.031162023544312}", "{\"n\": 9231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 8507.537, \"total_train_time_s\": 9.543018579483032}", "{\"n\": 9232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.73, \"learn_time_ms\": 8527.503, \"total_train_time_s\": 10.103840112686157}", "{\"n\": 9233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.05, \"learn_time_ms\": 8493.979, \"total_train_time_s\": 10.611368417739868}", "{\"n\": 9234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.67, \"learn_time_ms\": 8805.697, \"total_train_time_s\": 12.027283906936646}", "{\"n\": 9235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.07, \"learn_time_ms\": 8682.464, \"total_train_time_s\": 10.10963487625122}", "{\"n\": 9236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.63, \"learn_time_ms\": 8722.266, \"total_train_time_s\": 9.017162084579468}", "{\"n\": 9237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.97, \"learn_time_ms\": 8713.754, \"total_train_time_s\": 9.705381393432617}", "{\"n\": 9238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.12, \"learn_time_ms\": 8516.433, \"total_train_time_s\": 8.624657154083252}", "{\"n\": 9239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.03, \"learn_time_ms\": 8571.796, \"total_train_time_s\": 10.008715391159058}", "{\"n\": 9240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.21, \"learn_time_ms\": 8683.873, \"total_train_time_s\": 11.117977380752563}", "{\"n\": 9241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.46, \"learn_time_ms\": 8755.974, \"total_train_time_s\": 10.275718212127686}", "{\"n\": 9242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.25, \"learn_time_ms\": 8787.323, \"total_train_time_s\": 10.418007850646973}", "{\"n\": 9243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.56, \"learn_time_ms\": 8801.62, \"total_train_time_s\": 10.755383253097534}", "{\"n\": 9244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.61, \"learn_time_ms\": 8585.475, \"total_train_time_s\": 9.816130876541138}", "{\"n\": 9245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.16, \"learn_time_ms\": 8517.296, \"total_train_time_s\": 9.440654277801514}", "{\"n\": 9246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.16, \"learn_time_ms\": 8704.107, \"total_train_time_s\": 10.847083330154419}", "{\"n\": 9247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.8, \"learn_time_ms\": 8601.81, \"total_train_time_s\": 8.672391653060913}", "{\"n\": 9248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.6, \"learn_time_ms\": 8816.673, \"total_train_time_s\": 10.759968042373657}", "{\"n\": 9249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.6, \"learn_time_ms\": 8678.745, \"total_train_time_s\": 8.67217493057251}", "{\"n\": 9250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.6, \"learn_time_ms\": 8657.245, \"total_train_time_s\": 10.942322254180908}", "{\"n\": 9251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.83, \"learn_time_ms\": 8669.592, \"total_train_time_s\": 10.4404456615448}", "{\"n\": 9252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.92, \"learn_time_ms\": 8600.299, \"total_train_time_s\": 9.676532745361328}", "{\"n\": 9253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.79, \"learn_time_ms\": 8599.575, \"total_train_time_s\": 10.774507284164429}", "{\"n\": 9254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.64, \"learn_time_ms\": 8609.634, \"total_train_time_s\": 9.953086137771606}", "{\"n\": 9255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.92, \"learn_time_ms\": 8586.027, \"total_train_time_s\": 9.163248062133789}", "{\"n\": 9256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.46, \"learn_time_ms\": 8369.312, \"total_train_time_s\": 8.728863000869751}", "{\"n\": 9257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.46, \"learn_time_ms\": 8467.524, \"total_train_time_s\": 9.653195858001709}", "{\"n\": 9258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.66, \"learn_time_ms\": 8366.577, \"total_train_time_s\": 9.840795755386353}", "{\"n\": 9259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.66, \"learn_time_ms\": 8574.574, \"total_train_time_s\": 10.785664796829224}", "{\"n\": 9260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.16, \"learn_time_ms\": 8463.248, \"total_train_time_s\": 9.86448359489441}", "{\"n\": 9261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.12, \"learn_time_ms\": 8595.541, \"total_train_time_s\": 11.718996047973633}", "{\"n\": 9262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.44, \"learn_time_ms\": 8511.683, \"total_train_time_s\": 8.858810186386108}", "{\"n\": 9263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.84, \"learn_time_ms\": 8360.968, \"total_train_time_s\": 9.185609340667725}", "{\"n\": 9264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 8231.327, \"total_train_time_s\": 8.649609088897705}", "{\"n\": 9265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.38, \"learn_time_ms\": 8216.229, \"total_train_time_s\": 9.02228307723999}", "{\"n\": 9266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.05, \"learn_time_ms\": 8250.266, \"total_train_time_s\": 9.047204732894897}", "{\"n\": 9267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.37, \"learn_time_ms\": 8268.987, \"total_train_time_s\": 9.797617673873901}", "{\"n\": 9268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.56, \"learn_time_ms\": 8430.896, \"total_train_time_s\": 11.373565435409546}", "{\"n\": 9269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.76, \"learn_time_ms\": 8405.832, \"total_train_time_s\": 10.55431079864502}", "{\"n\": 9270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.12, \"learn_time_ms\": 8442.295, \"total_train_time_s\": 10.18989610671997}", "{\"n\": 9271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.02, \"learn_time_ms\": 8293.12, \"total_train_time_s\": 10.1958749294281}", "{\"n\": 9272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.24, \"learn_time_ms\": 8372.799, \"total_train_time_s\": 9.683504581451416}", "{\"n\": 9273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.18, \"learn_time_ms\": 8356.997, \"total_train_time_s\": 9.040929555892944}", "{\"n\": 9274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.87, \"learn_time_ms\": 8624.827, \"total_train_time_s\": 11.310112476348877}", "{\"n\": 9275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.82, \"learn_time_ms\": 8716.347, \"total_train_time_s\": 9.972654581069946}", "{\"n\": 9276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.82, \"learn_time_ms\": 8783.126, \"total_train_time_s\": 9.713572025299072}", "{\"n\": 9277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.26, \"learn_time_ms\": 8898.332, \"total_train_time_s\": 10.960646629333496}", "{\"n\": 9278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.09, \"learn_time_ms\": 8666.308, \"total_train_time_s\": 9.050241231918335}", "{\"n\": 9279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.09, \"learn_time_ms\": 8670.355, \"total_train_time_s\": 10.528667449951172}", "{\"n\": 9280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.01, \"learn_time_ms\": 8708.715, \"total_train_time_s\": 10.579309940338135}", "{\"n\": 9281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.87, \"learn_time_ms\": 8583.181, \"total_train_time_s\": 8.977129459381104}", "{\"n\": 9282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.87, \"learn_time_ms\": 8508.374, \"total_train_time_s\": 8.925462007522583}", "{\"n\": 9283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.77, \"learn_time_ms\": 8408.968, \"total_train_time_s\": 8.10605525970459}", "{\"n\": 9284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.28, \"learn_time_ms\": 8311.221, \"total_train_time_s\": 10.332018852233887}", "{\"n\": 9285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.2, \"learn_time_ms\": 8099.186, \"total_train_time_s\": 7.813933372497559}", "{\"n\": 9286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.2, \"learn_time_ms\": 8099.938, \"total_train_time_s\": 9.699067115783691}", "{\"n\": 9287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.16, \"learn_time_ms\": 7887.012, \"total_train_time_s\": 8.836506366729736}", "{\"n\": 9288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.07, \"learn_time_ms\": 8128.412, \"total_train_time_s\": 11.522744178771973}", "{\"n\": 9289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.07, \"learn_time_ms\": 8039.639, \"total_train_time_s\": 9.657143354415894}", "{\"n\": 9290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.6, \"learn_time_ms\": 8051.489, \"total_train_time_s\": 10.676157712936401}", "{\"n\": 9291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.99, \"learn_time_ms\": 8110.319, \"total_train_time_s\": 9.574500322341919}", "{\"n\": 9292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.37, \"learn_time_ms\": 8203.379, \"total_train_time_s\": 9.880734920501709}", "{\"n\": 9293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.13, \"learn_time_ms\": 8186.002, \"total_train_time_s\": 7.880498886108398}", "{\"n\": 9294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.0, \"learn_time_ms\": 8114.147, \"total_train_time_s\": 9.612420320510864}", "{\"n\": 9295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.47, \"learn_time_ms\": 8415.459, \"total_train_time_s\": 10.910982370376587}", "{\"n\": 9296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.05, \"learn_time_ms\": 8499.469, \"total_train_time_s\": 10.570679187774658}", "{\"n\": 9297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.17, \"learn_time_ms\": 8488.451, \"total_train_time_s\": 8.745898962020874}", "{\"n\": 9298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.63, \"learn_time_ms\": 8233.351, \"total_train_time_s\": 8.906587839126587}", "{\"n\": 9299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.63, \"learn_time_ms\": 8175.019, \"total_train_time_s\": 9.05349588394165}", "{\"n\": 9300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.33, \"learn_time_ms\": 7931.357, \"total_train_time_s\": 8.26416826248169}", "{\"n\": 9301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.33, \"learn_time_ms\": 7898.972, \"total_train_time_s\": 9.26393723487854}", "{\"n\": 9302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.23, \"learn_time_ms\": 7847.66, \"total_train_time_s\": 9.385555505752563}", "{\"n\": 9303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.03, \"learn_time_ms\": 8048.076, \"total_train_time_s\": 9.882807970046997}", "{\"n\": 9304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.18, \"learn_time_ms\": 7994.919, \"total_train_time_s\": 9.11265754699707}", "{\"n\": 9305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.54, \"learn_time_ms\": 7883.792, \"total_train_time_s\": 9.727054357528687}", "{\"n\": 9306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.0, \"learn_time_ms\": 7933.948, \"total_train_time_s\": 11.044081449508667}", "{\"n\": 9307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.46, \"learn_time_ms\": 8015.897, \"total_train_time_s\": 9.495446920394897}", "{\"n\": 9308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.04, \"learn_time_ms\": 8241.406, \"total_train_time_s\": 11.211753606796265}", "{\"n\": 9309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.71, \"learn_time_ms\": 8343.064, \"total_train_time_s\": 10.118151187896729}", "{\"n\": 9310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.54, \"learn_time_ms\": 8439.634, \"total_train_time_s\": 9.20635724067688}", "{\"n\": 9311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.54, \"learn_time_ms\": 8547.996, \"total_train_time_s\": 10.29676365852356}", "{\"n\": 9312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.62, \"learn_time_ms\": 8644.757, \"total_train_time_s\": 10.366865396499634}", "{\"n\": 9313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 8519.416, \"total_train_time_s\": 8.658741235733032}", "{\"n\": 9314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.51, \"learn_time_ms\": 8453.334, \"total_train_time_s\": 8.42672085762024}", "{\"n\": 9315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.2, \"learn_time_ms\": 8565.546, \"total_train_time_s\": 10.85789179801941}", "{\"n\": 9316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.04, \"learn_time_ms\": 8467.121, \"total_train_time_s\": 10.077404022216797}", "{\"n\": 9317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.71, \"learn_time_ms\": 8386.165, \"total_train_time_s\": 8.73508882522583}", "{\"n\": 9318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.64, \"learn_time_ms\": 8320.517, \"total_train_time_s\": 10.539029359817505}", "{\"n\": 9319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.64, \"learn_time_ms\": 8364.111, \"total_train_time_s\": 10.518668174743652}", "{\"n\": 9320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.34, \"learn_time_ms\": 8410.031, \"total_train_time_s\": 9.691854476928711}", "{\"n\": 9321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.69, \"learn_time_ms\": 8428.77, \"total_train_time_s\": 10.510944604873657}", "{\"n\": 9322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.08, \"learn_time_ms\": 8450.819, \"total_train_time_s\": 10.522045135498047}", "{\"n\": 9323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.46, \"learn_time_ms\": 8544.111, \"total_train_time_s\": 9.576852560043335}", "{\"n\": 9324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.08, \"learn_time_ms\": 8749.306, \"total_train_time_s\": 10.438202619552612}", "{\"n\": 9325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.08, \"learn_time_ms\": 8619.168, \"total_train_time_s\": 9.518046617507935}", "{\"n\": 9326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.07, \"learn_time_ms\": 8667.278, \"total_train_time_s\": 10.587759017944336}", "{\"n\": 9327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.87, \"learn_time_ms\": 8693.377, \"total_train_time_s\": 8.955165386199951}", "{\"n\": 9328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.87, \"learn_time_ms\": 8627.182, \"total_train_time_s\": 9.864413976669312}", "{\"n\": 9329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.04, \"learn_time_ms\": 8490.542, \"total_train_time_s\": 9.18900203704834}", "{\"n\": 9330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.69, \"learn_time_ms\": 8544.071, \"total_train_time_s\": 10.222825288772583}", "{\"n\": 9331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.69, \"learn_time_ms\": 8500.146, \"total_train_time_s\": 10.092533111572266}", "{\"n\": 9332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.8, \"learn_time_ms\": 8363.359, \"total_train_time_s\": 9.185875415802002}", "{\"n\": 9333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.67, \"learn_time_ms\": 8450.969, \"total_train_time_s\": 10.484203577041626}", "{\"n\": 9334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.67, \"learn_time_ms\": 8378.916, \"total_train_time_s\": 9.797559022903442}", "{\"n\": 9335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8485.711, \"total_train_time_s\": 10.651418685913086}", "{\"n\": 9336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8408.502, \"total_train_time_s\": 9.791558027267456}", "{\"n\": 9337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.2, \"learn_time_ms\": 8514.026, \"total_train_time_s\": 10.07313871383667}", "{\"n\": 9338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.05, \"learn_time_ms\": 8631.404, \"total_train_time_s\": 11.033010482788086}", "{\"n\": 9339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.05, \"learn_time_ms\": 8706.017, \"total_train_time_s\": 9.88884425163269}", "{\"n\": 9340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.62, \"learn_time_ms\": 8726.573, \"total_train_time_s\": 10.458752155303955}", "{\"n\": 9341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.99, \"learn_time_ms\": 8685.407, \"total_train_time_s\": 9.677387237548828}", "{\"n\": 9342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.56, \"learn_time_ms\": 8872.002, \"total_train_time_s\": 11.043845891952515}", "{\"n\": 9343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.56, \"learn_time_ms\": 8929.344, \"total_train_time_s\": 11.045451402664185}", "{\"n\": 9344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.8, \"learn_time_ms\": 8966.591, \"total_train_time_s\": 10.147860527038574}", "{\"n\": 9345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.72, \"learn_time_ms\": 8903.141, \"total_train_time_s\": 9.951247215270996}", "{\"n\": 9346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.72, \"learn_time_ms\": 8972.716, \"total_train_time_s\": 10.45107388496399}", "{\"n\": 9347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.96, \"learn_time_ms\": 8953.966, \"total_train_time_s\": 9.847640991210938}", "{\"n\": 9348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.73, \"learn_time_ms\": 8810.49, \"total_train_time_s\": 9.555712461471558}", "{\"n\": 9349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.73, \"learn_time_ms\": 8926.679, \"total_train_time_s\": 11.074690580368042}", "{\"n\": 9350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.84, \"learn_time_ms\": 8929.019, \"total_train_time_s\": 10.430691719055176}", "{\"n\": 9351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.46, \"learn_time_ms\": 8899.668, \"total_train_time_s\": 9.322161436080933}", "{\"n\": 9352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.34, \"learn_time_ms\": 8817.689, \"total_train_time_s\": 10.243899822235107}", "{\"n\": 9353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.34, \"learn_time_ms\": 8645.299, \"total_train_time_s\": 9.308502197265625}", "{\"n\": 9354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.79, \"learn_time_ms\": 8619.835, \"total_train_time_s\": 9.916895389556885}", "{\"n\": 9355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.95, \"learn_time_ms\": 8657.577, \"total_train_time_s\": 10.379871845245361}", "{\"n\": 9356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.95, \"learn_time_ms\": 8635.448, \"total_train_time_s\": 10.248097658157349}", "{\"n\": 9357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.26, \"learn_time_ms\": 8603.004, \"total_train_time_s\": 9.573449611663818}", "{\"n\": 9358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.11, \"learn_time_ms\": 8744.363, \"total_train_time_s\": 11.06940770149231}", "{\"n\": 9359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.11, \"learn_time_ms\": 8660.923, \"total_train_time_s\": 10.275858402252197}", "{\"n\": 9360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.04, \"learn_time_ms\": 8640.959, \"total_train_time_s\": 10.239705801010132}", "{\"n\": 9361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.39, \"learn_time_ms\": 8723.197, \"total_train_time_s\": 10.191011905670166}", "{\"n\": 9362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.01, \"learn_time_ms\": 8676.588, \"total_train_time_s\": 9.745306253433228}", "{\"n\": 9363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.64, \"learn_time_ms\": 8771.659, \"total_train_time_s\": 10.227615594863892}", "{\"n\": 9364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.24, \"learn_time_ms\": 8790.337, \"total_train_time_s\": 10.062108993530273}", "{\"n\": 9365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.24, \"learn_time_ms\": 8959.527, \"total_train_time_s\": 12.044034242630005}", "{\"n\": 9366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.03, \"learn_time_ms\": 8792.762, \"total_train_time_s\": 8.564973831176758}", "{\"n\": 9367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.69, \"learn_time_ms\": 8664.165, \"total_train_time_s\": 8.262887954711914}", "{\"n\": 9368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.69, \"learn_time_ms\": 8652.451, \"total_train_time_s\": 10.928544759750366}", "{\"n\": 9369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.52, \"learn_time_ms\": 8685.112, \"total_train_time_s\": 10.562222957611084}", "{\"n\": 9370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.28, \"learn_time_ms\": 8691.233, \"total_train_time_s\": 10.341386795043945}", "{\"n\": 9371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.28, \"learn_time_ms\": 8662.2, \"total_train_time_s\": 9.873961925506592}", "{\"n\": 9372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.06, \"learn_time_ms\": 8600.169, \"total_train_time_s\": 9.142816543579102}", "{\"n\": 9373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.93, \"learn_time_ms\": 8483.772, \"total_train_time_s\": 9.132581949234009}", "{\"n\": 9374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.18, \"learn_time_ms\": 8549.379, \"total_train_time_s\": 10.780489444732666}", "{\"n\": 9375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.18, \"learn_time_ms\": 8357.965, \"total_train_time_s\": 10.139100313186646}", "{\"n\": 9376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.53, \"learn_time_ms\": 8524.525, \"total_train_time_s\": 10.245015859603882}", "{\"n\": 9377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.99, \"learn_time_ms\": 8790.89, \"total_train_time_s\": 10.964111089706421}", "{\"n\": 9378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.99, \"learn_time_ms\": 8626.814, \"total_train_time_s\": 9.218135595321655}", "{\"n\": 9379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.88, \"learn_time_ms\": 8657.865, \"total_train_time_s\": 10.847822666168213}", "{\"n\": 9380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.4, \"learn_time_ms\": 8578.676, \"total_train_time_s\": 9.524568319320679}", "{\"n\": 9381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.4, \"learn_time_ms\": 8598.557, \"total_train_time_s\": 10.115761995315552}", "{\"n\": 9382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.16, \"learn_time_ms\": 8714.764, \"total_train_time_s\": 10.332831382751465}", "{\"n\": 9383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.29, \"learn_time_ms\": 8814.185, \"total_train_time_s\": 10.107566833496094}", "{\"n\": 9384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.29, \"learn_time_ms\": 8761.815, \"total_train_time_s\": 10.209016799926758}", "{\"n\": 9385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.18, \"learn_time_ms\": 8776.31, \"total_train_time_s\": 10.228042125701904}", "{\"n\": 9386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.23, \"learn_time_ms\": 8793.563, \"total_train_time_s\": 10.408382892608643}", "{\"n\": 9387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.64, \"learn_time_ms\": 8741.852, \"total_train_time_s\": 10.366060256958008}", "{\"n\": 9388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.64, \"learn_time_ms\": 8918.452, \"total_train_time_s\": 11.016669273376465}", "{\"n\": 9389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.69, \"learn_time_ms\": 8892.665, \"total_train_time_s\": 10.601674556732178}", "{\"n\": 9390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.56, \"learn_time_ms\": 9028.256, \"total_train_time_s\": 10.854197978973389}", "{\"n\": 9391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.76, \"learn_time_ms\": 9090.941, \"total_train_time_s\": 10.714495658874512}", "{\"n\": 9392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.54, \"learn_time_ms\": 9068.732, \"total_train_time_s\": 10.037758588790894}", "{\"n\": 9393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.93, \"learn_time_ms\": 8923.807, \"total_train_time_s\": 8.64382791519165}", "{\"n\": 9394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.93, \"learn_time_ms\": 9105.742, \"total_train_time_s\": 12.000451564788818}", "{\"n\": 9395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.91, \"learn_time_ms\": 8985.082, \"total_train_time_s\": 9.072280645370483}", "{\"n\": 9396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.05, \"learn_time_ms\": 8979.442, \"total_train_time_s\": 10.369088649749756}", "{\"n\": 9397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.05, \"learn_time_ms\": 8847.197, \"total_train_time_s\": 9.097993850708008}", "{\"n\": 9398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.66, \"learn_time_ms\": 8656.114, \"total_train_time_s\": 9.125945329666138}", "{\"n\": 9399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.61, \"learn_time_ms\": 8545.494, \"total_train_time_s\": 9.544694423675537}", "{\"n\": 9400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.68, \"learn_time_ms\": 8555.788, \"total_train_time_s\": 11.01131558418274}", "{\"n\": 9401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.5, \"learn_time_ms\": 8526.638, \"total_train_time_s\": 10.493035316467285}", "{\"n\": 9402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.69, \"learn_time_ms\": 8522.624, \"total_train_time_s\": 10.080923795700073}", "{\"n\": 9403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.65, \"learn_time_ms\": 8746.726, \"total_train_time_s\": 10.871067523956299}", "{\"n\": 9404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.52, \"learn_time_ms\": 8591.939, \"total_train_time_s\": 10.455366134643555}", "{\"n\": 9405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.13, \"learn_time_ms\": 8691.138, \"total_train_time_s\": 10.091568231582642}", "{\"n\": 9406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.49, \"learn_time_ms\": 8722.285, \"total_train_time_s\": 10.67753005027771}", "{\"n\": 9407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.49, \"learn_time_ms\": 8756.064, \"total_train_time_s\": 9.428321599960327}", "{\"n\": 9408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 8774.245, \"total_train_time_s\": 9.267560958862305}", "{\"n\": 9409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.03, \"learn_time_ms\": 8772.534, \"total_train_time_s\": 9.520440578460693}", "{\"n\": 9410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.28, \"learn_time_ms\": 8555.559, \"total_train_time_s\": 8.8280029296875}", "{\"n\": 9411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.98, \"learn_time_ms\": 8545.391, \"total_train_time_s\": 10.344236850738525}", "{\"n\": 9412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.63, \"learn_time_ms\": 8572.744, \"total_train_time_s\": 10.297568798065186}", "{\"n\": 9413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.82, \"learn_time_ms\": 8512.348, \"total_train_time_s\": 10.267344236373901}", "{\"n\": 9414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.83, \"learn_time_ms\": 8497.007, \"total_train_time_s\": 10.318021535873413}", "{\"n\": 9415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.35, \"learn_time_ms\": 8435.45, \"total_train_time_s\": 9.412331819534302}", "{\"n\": 9416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.74, \"learn_time_ms\": 8256.164, \"total_train_time_s\": 8.903971910476685}", "{\"n\": 9417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.74, \"learn_time_ms\": 8354.452, \"total_train_time_s\": 10.398062705993652}", "{\"n\": 9418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.29, \"learn_time_ms\": 8520.379, \"total_train_time_s\": 10.963949203491211}", "{\"n\": 9419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.73, \"learn_time_ms\": 8622.627, \"total_train_time_s\": 10.506622552871704}", "{\"n\": 9420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.2, \"learn_time_ms\": 8614.045, \"total_train_time_s\": 8.74508547782898}", "{\"n\": 9421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.98, \"learn_time_ms\": 8537.141, \"total_train_time_s\": 9.551528692245483}", "{\"n\": 9422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.98, \"learn_time_ms\": 8485.431, \"total_train_time_s\": 9.862222671508789}", "{\"n\": 9423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.21, \"learn_time_ms\": 8398.315, \"total_train_time_s\": 9.420318841934204}", "{\"n\": 9424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.72, \"learn_time_ms\": 8320.283, \"total_train_time_s\": 9.521631002426147}", "{\"n\": 9425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.72, \"learn_time_ms\": 8435.241, \"total_train_time_s\": 10.581752300262451}", "{\"n\": 9426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.41, \"learn_time_ms\": 8581.549, \"total_train_time_s\": 10.40424656867981}", "{\"n\": 9427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.07, \"learn_time_ms\": 8419.949, \"total_train_time_s\": 8.797412872314453}", "{\"n\": 9428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.32, \"learn_time_ms\": 8361.089, \"total_train_time_s\": 10.344414472579956}", "{\"n\": 9429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.73, \"learn_time_ms\": 8248.89, \"total_train_time_s\": 9.378555536270142}", "{\"n\": 9430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.73, \"learn_time_ms\": 8420.69, \"total_train_time_s\": 10.472499370574951}", "{\"n\": 9431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.53, \"learn_time_ms\": 8589.761, \"total_train_time_s\": 11.281940698623657}", "{\"n\": 9432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.93, \"learn_time_ms\": 8708.591, \"total_train_time_s\": 10.983871936798096}", "{\"n\": 9433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.81, \"learn_time_ms\": 8691.13, \"total_train_time_s\": 9.265137195587158}", "{\"n\": 9434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.16, \"learn_time_ms\": 8869.948, \"total_train_time_s\": 11.343590497970581}", "{\"n\": 9435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.16, \"learn_time_ms\": 8811.717, \"total_train_time_s\": 10.009121179580688}", "{\"n\": 9436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.28, \"learn_time_ms\": 8823.078, \"total_train_time_s\": 10.475942134857178}", "{\"n\": 9437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.98, \"learn_time_ms\": 8939.922, \"total_train_time_s\": 9.88521432876587}", "{\"n\": 9438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.83, \"learn_time_ms\": 8945.145, \"total_train_time_s\": 10.42177963256836}", "{\"n\": 9439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.67, \"learn_time_ms\": 9147.767, \"total_train_time_s\": 11.421200513839722}", "{\"n\": 9440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.67, \"learn_time_ms\": 9274.914, \"total_train_time_s\": 11.671635866165161}", "{\"n\": 9441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.28, \"learn_time_ms\": 9111.514, \"total_train_time_s\": 9.62789249420166}", "{\"n\": 9442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.21, \"learn_time_ms\": 9009.096, \"total_train_time_s\": 9.961302757263184}", "{\"n\": 9443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.5, \"learn_time_ms\": 9006.816, \"total_train_time_s\": 9.214026689529419}", "{\"n\": 9444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.5, \"learn_time_ms\": 8733.136, \"total_train_time_s\": 8.581671953201294}", "{\"n\": 9445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.87, \"learn_time_ms\": 8692.629, \"total_train_time_s\": 9.639070272445679}", "{\"n\": 9446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 8656.864, \"total_train_time_s\": 10.08963680267334}", "{\"n\": 9447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 8648.708, \"total_train_time_s\": 9.842663764953613}", "{\"n\": 9448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.36, \"learn_time_ms\": 8597.991, \"total_train_time_s\": 9.967050313949585}", "{\"n\": 9449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.9, \"learn_time_ms\": 8321.764, \"total_train_time_s\": 8.687041759490967}", "{\"n\": 9450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.9, \"learn_time_ms\": 8127.695, \"total_train_time_s\": 9.78261399269104}", "{\"n\": 9451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.28, \"learn_time_ms\": 8187.294, \"total_train_time_s\": 10.255856990814209}", "{\"n\": 9452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.7, \"learn_time_ms\": 8178.983, \"total_train_time_s\": 9.831058740615845}", "{\"n\": 9453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.66, \"learn_time_ms\": 8242.474, \"total_train_time_s\": 9.855057001113892}", "{\"n\": 9454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.49, \"learn_time_ms\": 8376.689, \"total_train_time_s\": 9.913695096969604}", "{\"n\": 9455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.49, \"learn_time_ms\": 8383.502, \"total_train_time_s\": 9.690723657608032}", "{\"n\": 9456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.35, \"learn_time_ms\": 8380.606, \"total_train_time_s\": 10.079635858535767}", "{\"n\": 9457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 8455.692, \"total_train_time_s\": 10.601539373397827}", "{\"n\": 9458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 8450.542, \"total_train_time_s\": 9.844958782196045}", "{\"n\": 9459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.66, \"learn_time_ms\": 8611.436, \"total_train_time_s\": 10.235175848007202}", "{\"n\": 9460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.67, \"learn_time_ms\": 8656.556, \"total_train_time_s\": 10.20525860786438}", "{\"n\": 9461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.67, \"learn_time_ms\": 8452.611, \"total_train_time_s\": 8.195317029953003}", "{\"n\": 9462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.07, \"learn_time_ms\": 8552.616, \"total_train_time_s\": 10.940463781356812}", "{\"n\": 9463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.07, \"learn_time_ms\": 8461.34, \"total_train_time_s\": 8.969960689544678}", "{\"n\": 9464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.45, \"learn_time_ms\": 8447.247, \"total_train_time_s\": 9.78820252418518}", "{\"n\": 9465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.43, \"learn_time_ms\": 8381.018, \"total_train_time_s\": 8.995740175247192}", "{\"n\": 9466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.07, \"learn_time_ms\": 8277.223, \"total_train_time_s\": 9.033581495285034}", "{\"n\": 9467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.41, \"learn_time_ms\": 8132.126, \"total_train_time_s\": 9.190898656845093}", "{\"n\": 9468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.41, \"learn_time_ms\": 8150.815, \"total_train_time_s\": 10.056509256362915}", "{\"n\": 9469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.21, \"learn_time_ms\": 8121.556, \"total_train_time_s\": 9.966421842575073}", "{\"n\": 9470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.14, \"learn_time_ms\": 8111.459, \"total_train_time_s\": 10.151646614074707}", "{\"n\": 9471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.14, \"learn_time_ms\": 8327.261, \"total_train_time_s\": 10.355748414993286}", "{\"n\": 9472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.26, \"learn_time_ms\": 8212.644, \"total_train_time_s\": 9.715590715408325}", "{\"n\": 9473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.44, \"learn_time_ms\": 8280.711, \"total_train_time_s\": 9.577394723892212}", "{\"n\": 9474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.44, \"learn_time_ms\": 8360.452, \"total_train_time_s\": 10.568928480148315}", "{\"n\": 9475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.72, \"learn_time_ms\": 8508.382, \"total_train_time_s\": 10.509411096572876}", "{\"n\": 9476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.8, \"learn_time_ms\": 8526.695, \"total_train_time_s\": 9.244874477386475}", "{\"n\": 9477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.8, \"learn_time_ms\": 8613.649, \"total_train_time_s\": 10.051018238067627}", "{\"n\": 9478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 8690.635, \"total_train_time_s\": 10.87315845489502}", "{\"n\": 9479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 8729.289, \"total_train_time_s\": 10.343025922775269}", "{\"n\": 9480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.95, \"learn_time_ms\": 8742.177, \"total_train_time_s\": 10.23915719985962}", "{\"n\": 9481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.66, \"learn_time_ms\": 8629.627, \"total_train_time_s\": 9.24008846282959}", "{\"n\": 9482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.66, \"learn_time_ms\": 8574.875, \"total_train_time_s\": 9.157668590545654}", "{\"n\": 9483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.35, \"learn_time_ms\": 8631.83, \"total_train_time_s\": 10.224925518035889}", "{\"n\": 9484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.35, \"learn_time_ms\": 8539.939, \"total_train_time_s\": 9.673253536224365}", "{\"n\": 9485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.32, \"learn_time_ms\": 8465.707, \"total_train_time_s\": 9.725943088531494}", "{\"n\": 9486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.42, \"learn_time_ms\": 8532.606, \"total_train_time_s\": 9.89145803451538}", "{\"n\": 9487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.34, \"learn_time_ms\": 8458.914, \"total_train_time_s\": 9.339309453964233}", "{\"n\": 9488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.31, \"learn_time_ms\": 8296.902, \"total_train_time_s\": 9.164690494537354}", "{\"n\": 9489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.4, \"learn_time_ms\": 8291.266, \"total_train_time_s\": 10.253430366516113}", "{\"n\": 9490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.4, \"learn_time_ms\": 8260.056, \"total_train_time_s\": 9.978237390518188}", "{\"n\": 9491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.01, \"learn_time_ms\": 8257.71, \"total_train_time_s\": 9.193949699401855}", "{\"n\": 9492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.41, \"learn_time_ms\": 8440.66, \"total_train_time_s\": 10.986490964889526}", "{\"n\": 9493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.41, \"learn_time_ms\": 8329.687, \"total_train_time_s\": 9.033235788345337}", "{\"n\": 9494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.49, \"learn_time_ms\": 8389.622, \"total_train_time_s\": 10.237957239151001}", "{\"n\": 9495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.49, \"learn_time_ms\": 8504.192, \"total_train_time_s\": 10.855395793914795}", "{\"n\": 9496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.8, \"learn_time_ms\": 8551.474, \"total_train_time_s\": 10.383203506469727}", "{\"n\": 9497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.42, \"learn_time_ms\": 8693.29, \"total_train_time_s\": 10.762419939041138}", "{\"n\": 9498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.42, \"learn_time_ms\": 8720.601, \"total_train_time_s\": 9.462766647338867}", "{\"n\": 9499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.0, \"learn_time_ms\": 8838.826, \"total_train_time_s\": 11.484554529190063}", "{\"n\": 9500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.26, \"learn_time_ms\": 8763.65, \"total_train_time_s\": 9.217695474624634}", "{\"n\": 9501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.26, \"learn_time_ms\": 8845.698, \"total_train_time_s\": 10.02593994140625}", "{\"n\": 9502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.03, \"learn_time_ms\": 8741.292, \"total_train_time_s\": 9.977404356002808}", "{\"n\": 9503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.08, \"learn_time_ms\": 8782.824, \"total_train_time_s\": 9.513519763946533}", "{\"n\": 9504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.89, \"learn_time_ms\": 8858.809, \"total_train_time_s\": 10.997019290924072}", "{\"n\": 9505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.34, \"learn_time_ms\": 8831.223, \"total_train_time_s\": 10.641183137893677}", "{\"n\": 9506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.13, \"learn_time_ms\": 8813.581, \"total_train_time_s\": 10.196500539779663}", "{\"n\": 9507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.64, \"learn_time_ms\": 8782.962, \"total_train_time_s\": 10.394195795059204}", "{\"n\": 9508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.64, \"learn_time_ms\": 8817.587, \"total_train_time_s\": 9.765039205551147}", "{\"n\": 9509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.72, \"learn_time_ms\": 8603.551, \"total_train_time_s\": 9.323676824569702}", "{\"n\": 9510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.23, \"learn_time_ms\": 8738.647, \"total_train_time_s\": 10.528346061706543}", "{\"n\": 9511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.23, \"learn_time_ms\": 8760.262, \"total_train_time_s\": 10.178633213043213}", "{\"n\": 9512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.91, \"learn_time_ms\": 8740.975, \"total_train_time_s\": 9.734454870223999}", "{\"n\": 9513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.71, \"learn_time_ms\": 8867.58, \"total_train_time_s\": 10.744368314743042}", "{\"n\": 9514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.65, \"learn_time_ms\": 8727.085, \"total_train_time_s\": 9.591262817382812}", "{\"n\": 9515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.65, \"learn_time_ms\": 8725.327, \"total_train_time_s\": 10.599110841751099}", "{\"n\": 9516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.54, \"learn_time_ms\": 8585.841, \"total_train_time_s\": 8.758556842803955}", "{\"n\": 9517, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.39, \"learn_time_ms\": 8755.415, \"total_train_time_s\": 12.135535717010498}", "{\"n\": 9518, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.39, \"learn_time_ms\": 8823.463, \"total_train_time_s\": 10.461725234985352}", "{\"n\": 9519, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.31, \"learn_time_ms\": 9038.207, \"total_train_time_s\": 11.508256673812866}", "{\"n\": 9520, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.68, \"learn_time_ms\": 9057.816, \"total_train_time_s\": 10.774210453033447}", "{\"n\": 9521, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.68, \"learn_time_ms\": 9060.617, \"total_train_time_s\": 10.240825414657593}", "{\"n\": 9522, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.94, \"learn_time_ms\": 9004.844, \"total_train_time_s\": 9.208598136901855}", "{\"n\": 9523, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.34, \"learn_time_ms\": 8845.936, \"total_train_time_s\": 9.141110897064209}", "{\"n\": 9524, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.11, \"learn_time_ms\": 8892.036, \"total_train_time_s\": 10.068467140197754}", "{\"n\": 9525, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.01, \"learn_time_ms\": 8723.374, \"total_train_time_s\": 8.952486276626587}", "{\"n\": 9526, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.64, \"learn_time_ms\": 8811.399, \"total_train_time_s\": 9.689685344696045}", "{\"n\": 9527, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.25, \"learn_time_ms\": 8567.711, \"total_train_time_s\": 9.707125902175903}", "{\"n\": 9528, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.25, \"learn_time_ms\": 8586.78, \"total_train_time_s\": 10.74894118309021}", "{\"n\": 9529, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.48, \"learn_time_ms\": 8377.464, \"total_train_time_s\": 9.449485063552856}", "{\"n\": 9530, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.63, \"learn_time_ms\": 8250.964, \"total_train_time_s\": 9.478543043136597}", "{\"n\": 9531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.63, \"learn_time_ms\": 8293.205, \"total_train_time_s\": 10.634750604629517}", "{\"n\": 9532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.69, \"learn_time_ms\": 8436.129, \"total_train_time_s\": 10.655838966369629}", "{\"n\": 9533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.78, \"learn_time_ms\": 8410.14, \"total_train_time_s\": 8.890659093856812}", "{\"n\": 9534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.78, \"learn_time_ms\": 8336.845, \"total_train_time_s\": 9.327070951461792}", "{\"n\": 9535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.78, \"learn_time_ms\": 8443.424, \"total_train_time_s\": 9.978144407272339}", "{\"n\": 9536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.33, \"learn_time_ms\": 8598.369, \"total_train_time_s\": 11.251737117767334}", "{\"n\": 9537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 8517.006, \"total_train_time_s\": 8.84769320487976}", "{\"n\": 9538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 8596.785, \"total_train_time_s\": 11.534751176834106}", "{\"n\": 9539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.05, \"learn_time_ms\": 8474.237, \"total_train_time_s\": 8.170078992843628}", "{\"n\": 9540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.74, \"learn_time_ms\": 8535.394, \"total_train_time_s\": 10.105539798736572}", "{\"n\": 9541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.74, \"learn_time_ms\": 8317.518, \"total_train_time_s\": 8.496664047241211}", "{\"n\": 9542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.77, \"learn_time_ms\": 8238.019, \"total_train_time_s\": 9.848021984100342}", "{\"n\": 9543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.56, \"learn_time_ms\": 8327.472, \"total_train_time_s\": 9.784246921539307}", "{\"n\": 9544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.56, \"learn_time_ms\": 8208.027, \"total_train_time_s\": 8.10132122039795}", "{\"n\": 9545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.56, \"learn_time_ms\": 8246.311, \"total_train_time_s\": 10.346546411514282}", "{\"n\": 9546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.56, \"learn_time_ms\": 8074.329, \"total_train_time_s\": 9.485144138336182}", "{\"n\": 9547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.0, \"learn_time_ms\": 8209.83, \"total_train_time_s\": 10.195168733596802}", "{\"n\": 9548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.0, \"learn_time_ms\": 8110.575, \"total_train_time_s\": 10.484496355056763}", "{\"n\": 9549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.04, \"learn_time_ms\": 8182.013, \"total_train_time_s\": 8.876346349716187}", "{\"n\": 9550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.04, \"learn_time_ms\": 8227.497, \"total_train_time_s\": 10.524439334869385}", "{\"n\": 9551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.04, \"learn_time_ms\": 8363.885, \"total_train_time_s\": 9.857423067092896}", "{\"n\": 9552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.11, \"learn_time_ms\": 8381.728, \"total_train_time_s\": 10.032721757888794}", "{\"n\": 9553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.98, \"learn_time_ms\": 8307.93, \"total_train_time_s\": 9.107892274856567}", "{\"n\": 9554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.98, \"learn_time_ms\": 8554.938, \"total_train_time_s\": 10.604991674423218}", "{\"n\": 9555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.59, \"learn_time_ms\": 8375.467, \"total_train_time_s\": 8.556328058242798}", "{\"n\": 9556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.32, \"learn_time_ms\": 8484.327, \"total_train_time_s\": 10.613749504089355}", "{\"n\": 9557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.32, \"learn_time_ms\": 8330.211, \"total_train_time_s\": 8.644612073898315}", "{\"n\": 9558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.32, \"learn_time_ms\": 8284.004, \"total_train_time_s\": 10.021378755569458}", "{\"n\": 9559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.92, \"learn_time_ms\": 8329.383, \"total_train_time_s\": 9.371196746826172}", "{\"n\": 9560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.23, \"learn_time_ms\": 8271.755, \"total_train_time_s\": 9.936595678329468}", "{\"n\": 9561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.23, \"learn_time_ms\": 8258.17, \"total_train_time_s\": 9.751294612884521}", "{\"n\": 9562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.36, \"learn_time_ms\": 8225.397, \"total_train_time_s\": 9.700540542602539}", "{\"n\": 9563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8402.877, \"total_train_time_s\": 10.865679740905762}", "{\"n\": 9564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8461.465, \"total_train_time_s\": 11.174472093582153}", "{\"n\": 9565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.43, \"learn_time_ms\": 8620.275, \"total_train_time_s\": 10.155999898910522}", "{\"n\": 9566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.85, \"learn_time_ms\": 8578.777, \"total_train_time_s\": 10.214697122573853}", "{\"n\": 9567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.78, \"learn_time_ms\": 8717.696, \"total_train_time_s\": 10.04592251777649}", "{\"n\": 9568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.32, \"learn_time_ms\": 8806.713, \"total_train_time_s\": 10.962861061096191}", "{\"n\": 9569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.47, \"learn_time_ms\": 8787.305, \"total_train_time_s\": 9.151442527770996}", "{\"n\": 9570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.66, \"learn_time_ms\": 8703.201, \"total_train_time_s\": 9.159975290298462}", "{\"n\": 9571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.78, \"learn_time_ms\": 8562.437, \"total_train_time_s\": 8.335290670394897}", "{\"n\": 9572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.78, \"learn_time_ms\": 8597.275, \"total_train_time_s\": 10.076513051986694}", "{\"n\": 9573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.87, \"learn_time_ms\": 8471.182, \"total_train_time_s\": 9.569182872772217}", "{\"n\": 9574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.41, \"learn_time_ms\": 8457.467, \"total_train_time_s\": 11.076208114624023}", "{\"n\": 9575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.46, \"learn_time_ms\": 8323.122, \"total_train_time_s\": 8.780076742172241}", "{\"n\": 9576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.47, \"learn_time_ms\": 8174.495, \"total_train_time_s\": 8.698336839675903}", "{\"n\": 9577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.71, \"learn_time_ms\": 8085.007, \"total_train_time_s\": 9.190862655639648}", "{\"n\": 9578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.76, \"learn_time_ms\": 7913.592, \"total_train_time_s\": 9.215962409973145}", "{\"n\": 9579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.76, \"learn_time_ms\": 8042.073, \"total_train_time_s\": 10.418016195297241}", "{\"n\": 9580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.38, \"learn_time_ms\": 8232.594, \"total_train_time_s\": 11.006528854370117}", "{\"n\": 9581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.42, \"learn_time_ms\": 8326.675, \"total_train_time_s\": 9.280951023101807}", "{\"n\": 9582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.36, \"learn_time_ms\": 8472.379, \"total_train_time_s\": 11.59131932258606}", "{\"n\": 9583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.7, \"learn_time_ms\": 8630.897, \"total_train_time_s\": 11.177669286727905}", "{\"n\": 9584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.7, \"learn_time_ms\": 8516.284, \"total_train_time_s\": 9.90321397781372}", "{\"n\": 9585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.03, \"learn_time_ms\": 8591.479, \"total_train_time_s\": 9.619523286819458}", "{\"n\": 9586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.05, \"learn_time_ms\": 8833.943, \"total_train_time_s\": 11.150303840637207}", "{\"n\": 9587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.29, \"learn_time_ms\": 9033.069, \"total_train_time_s\": 11.165149211883545}", "{\"n\": 9588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.01, \"learn_time_ms\": 9146.885, \"total_train_time_s\": 10.32460355758667}", "{\"n\": 9589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.63, \"learn_time_ms\": 9104.274, \"total_train_time_s\": 10.05158805847168}", "{\"n\": 9590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.96, \"learn_time_ms\": 9013.196, \"total_train_time_s\": 10.122596025466919}", "{\"n\": 9591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.95, \"learn_time_ms\": 9161.52, \"total_train_time_s\": 10.722144365310669}", "{\"n\": 9592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.15, \"learn_time_ms\": 8898.442, \"total_train_time_s\": 8.875655889511108}", "{\"n\": 9593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.28, \"learn_time_ms\": 8736.085, \"total_train_time_s\": 9.531298160552979}", "{\"n\": 9594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.34, \"learn_time_ms\": 8800.714, \"total_train_time_s\": 10.579717636108398}", "{\"n\": 9595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.34, \"learn_time_ms\": 8956.503, \"total_train_time_s\": 11.13979721069336}", "{\"n\": 9596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.71, \"learn_time_ms\": 8817.562, \"total_train_time_s\": 9.728191375732422}", "{\"n\": 9597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.06, \"learn_time_ms\": 8816.111, \"total_train_time_s\": 11.16356110572815}", "{\"n\": 9598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.06, \"learn_time_ms\": 8659.512, \"total_train_time_s\": 8.760363101959229}", "{\"n\": 9599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.63, \"learn_time_ms\": 8677.562, \"total_train_time_s\": 10.183951139450073}", "{\"n\": 9600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.45, \"learn_time_ms\": 8629.259, \"total_train_time_s\": 9.662949562072754}", "{\"n\": 9601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.45, \"learn_time_ms\": 8511.525, \"total_train_time_s\": 9.548136472702026}", "{\"n\": 9602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.14, \"learn_time_ms\": 8593.487, \"total_train_time_s\": 9.675387144088745}", "{\"n\": 9603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.54, \"learn_time_ms\": 8600.317, \"total_train_time_s\": 9.61590051651001}", "{\"n\": 9604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.74, \"learn_time_ms\": 8532.133, \"total_train_time_s\": 9.905024766921997}", "{\"n\": 9605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.3, \"learn_time_ms\": 8390.451, \"total_train_time_s\": 9.779282331466675}", "{\"n\": 9606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.99, \"learn_time_ms\": 8382.98, \"total_train_time_s\": 9.639261484146118}", "{\"n\": 9607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.47, \"learn_time_ms\": 8332.015, \"total_train_time_s\": 10.616297960281372}", "{\"n\": 9608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.47, \"learn_time_ms\": 8413.511, \"total_train_time_s\": 9.60896372795105}", "{\"n\": 9609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.61, \"learn_time_ms\": 8482.342, \"total_train_time_s\": 10.840730667114258}", "{\"n\": 9610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.95, \"learn_time_ms\": 8502.862, \"total_train_time_s\": 9.837139368057251}", "{\"n\": 9611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.51, \"learn_time_ms\": 8434.23, \"total_train_time_s\": 8.888770341873169}", "{\"n\": 9612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.01, \"learn_time_ms\": 8574.134, \"total_train_time_s\": 11.105282068252563}", "{\"n\": 9613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.84, \"learn_time_ms\": 8546.401, \"total_train_time_s\": 9.313853740692139}", "{\"n\": 9614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.83, \"learn_time_ms\": 8586.607, \"total_train_time_s\": 10.27593994140625}", "{\"n\": 9615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.83, \"learn_time_ms\": 8608.843, \"total_train_time_s\": 9.957361936569214}", "{\"n\": 9616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.41, \"learn_time_ms\": 8543.647, \"total_train_time_s\": 8.989291667938232}", "{\"n\": 9617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.13, \"learn_time_ms\": 8529.963, \"total_train_time_s\": 10.476508378982544}", "{\"n\": 9618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.04, \"learn_time_ms\": 8502.359, \"total_train_time_s\": 9.326237916946411}", "{\"n\": 9619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.36, \"learn_time_ms\": 8419.755, \"total_train_time_s\": 10.02041506767273}", "{\"n\": 9620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.9, \"learn_time_ms\": 8470.545, \"total_train_time_s\": 10.35460615158081}", "{\"n\": 9621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.81, \"learn_time_ms\": 8582.488, \"total_train_time_s\": 9.950699090957642}", "{\"n\": 9622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.53, \"learn_time_ms\": 8435.45, \"total_train_time_s\": 9.598331928253174}", "{\"n\": 9623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.01, \"learn_time_ms\": 8429.414, \"total_train_time_s\": 9.240975856781006}", "{\"n\": 9624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 8508.337, \"total_train_time_s\": 11.108260154724121}", "{\"n\": 9625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 8634.238, \"total_train_time_s\": 11.199629306793213}", "{\"n\": 9626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.77, \"learn_time_ms\": 8766.042, \"total_train_time_s\": 10.303983926773071}", "{\"n\": 9627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8667.442, \"total_train_time_s\": 9.522904634475708}", "{\"n\": 9628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8812.065, \"total_train_time_s\": 10.731314420700073}", "{\"n\": 9629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.29, \"learn_time_ms\": 8850.007, \"total_train_time_s\": 10.428140878677368}", "{\"n\": 9630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.76, \"learn_time_ms\": 8802.505, \"total_train_time_s\": 9.835238456726074}", "{\"n\": 9631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.04, \"learn_time_ms\": 8875.995, \"total_train_time_s\": 10.763222217559814}", "{\"n\": 9632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.38, \"learn_time_ms\": 8902.129, \"total_train_time_s\": 9.939622640609741}", "{\"n\": 9633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.46, \"learn_time_ms\": 8919.652, \"total_train_time_s\": 9.470327615737915}", "{\"n\": 9634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.23, \"learn_time_ms\": 8756.391, \"total_train_time_s\": 9.488672733306885}", "{\"n\": 9635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.85, \"learn_time_ms\": 8590.625, \"total_train_time_s\": 9.576584815979004}", "{\"n\": 9636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.44, \"learn_time_ms\": 8461.27, \"total_train_time_s\": 9.014787197113037}", "{\"n\": 9637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.96, \"learn_time_ms\": 8464.307, \"total_train_time_s\": 9.536633253097534}", "{\"n\": 9638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.09, \"learn_time_ms\": 8378.555, \"total_train_time_s\": 9.917641162872314}", "{\"n\": 9639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.09, \"learn_time_ms\": 8386.166, \"total_train_time_s\": 10.506805419921875}", "{\"n\": 9640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.01, \"learn_time_ms\": 8428.463, \"total_train_time_s\": 10.277689695358276}", "{\"n\": 9641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.77, \"learn_time_ms\": 8419.803, \"total_train_time_s\": 10.664294004440308}", "{\"n\": 9642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.77, \"learn_time_ms\": 8382.823, \"total_train_time_s\": 9.47318434715271}", "{\"n\": 9643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.65, \"learn_time_ms\": 8303.249, \"total_train_time_s\": 8.666898965835571}", "{\"n\": 9644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.65, \"learn_time_ms\": 8433.136, \"total_train_time_s\": 10.734654903411865}", "{\"n\": 9645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.66, \"learn_time_ms\": 8462.022, \"total_train_time_s\": 9.808933734893799}", "{\"n\": 9646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 8472.04, \"total_train_time_s\": 9.108408689498901}", "{\"n\": 9647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.49, \"learn_time_ms\": 8382.993, \"total_train_time_s\": 8.683257102966309}", "{\"n\": 9648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.22, \"learn_time_ms\": 8431.418, \"total_train_time_s\": 10.442457437515259}", "{\"n\": 9649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.13, \"learn_time_ms\": 8329.475, \"total_train_time_s\": 9.461288928985596}", "{\"n\": 9650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.78, \"learn_time_ms\": 8219.462, \"total_train_time_s\": 9.200764417648315}", "{\"n\": 9651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.78, \"learn_time_ms\": 8032.434, \"total_train_time_s\": 8.793790102005005}", "{\"n\": 9652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.53, \"learn_time_ms\": 8024.6, \"total_train_time_s\": 9.386653423309326}", "{\"n\": 9653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3313.97, \"learn_time_ms\": 8303.507, \"total_train_time_s\": 11.443855285644531}", "{\"n\": 9654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.56, \"learn_time_ms\": 8338.714, \"total_train_time_s\": 11.134651184082031}", "{\"n\": 9655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3322.03, \"learn_time_ms\": 8396.191, \"total_train_time_s\": 10.373455047607422}", "{\"n\": 9656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.26, \"learn_time_ms\": 8319.155, \"total_train_time_s\": 8.35662579536438}", "{\"n\": 9657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.36, \"learn_time_ms\": 8637.722, \"total_train_time_s\": 11.87594723701477}", "{\"n\": 9658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.64, \"learn_time_ms\": 8604.883, \"total_train_time_s\": 10.101398706436157}", "{\"n\": 9659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.38, \"learn_time_ms\": 8689.804, \"total_train_time_s\": 10.34365963935852}", "{\"n\": 9660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.16, \"learn_time_ms\": 8734.326, \"total_train_time_s\": 9.646345138549805}", "{\"n\": 9661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.09, \"learn_time_ms\": 8853.953, \"total_train_time_s\": 9.977665185928345}", "{\"n\": 9662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.09, \"learn_time_ms\": 9054.415, \"total_train_time_s\": 11.393556833267212}", "{\"n\": 9663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.71, \"learn_time_ms\": 8990.083, \"total_train_time_s\": 10.778486967086792}", "{\"n\": 9664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.71, \"learn_time_ms\": 9013.693, \"total_train_time_s\": 11.332866668701172}", "{\"n\": 9665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.73, \"learn_time_ms\": 8970.72, \"total_train_time_s\": 9.987316131591797}", "{\"n\": 9666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.86, \"learn_time_ms\": 9067.822, \"total_train_time_s\": 9.36302399635315}", "{\"n\": 9667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 8801.178, \"total_train_time_s\": 9.175282001495361}", "{\"n\": 9668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.89, \"learn_time_ms\": 8773.408, \"total_train_time_s\": 9.78242301940918}", "{\"n\": 9669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.89, \"learn_time_ms\": 8843.587, \"total_train_time_s\": 11.056033372879028}", "{\"n\": 9670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.53, \"learn_time_ms\": 8894.316, \"total_train_time_s\": 10.160332679748535}", "{\"n\": 9671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.8, \"learn_time_ms\": 8999.162, \"total_train_time_s\": 11.056893825531006}", "{\"n\": 9672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.8, \"learn_time_ms\": 8824.856, \"total_train_time_s\": 9.72552227973938}", "{\"n\": 9673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.57, \"learn_time_ms\": 8631.99, \"total_train_time_s\": 8.914107084274292}", "{\"n\": 9674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.64, \"learn_time_ms\": 8471.982, \"total_train_time_s\": 9.764420986175537}", "{\"n\": 9675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.64, \"learn_time_ms\": 8520.895, \"total_train_time_s\": 10.480817079544067}", "{\"n\": 9676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.24, \"learn_time_ms\": 8590.964, \"total_train_time_s\": 10.031463623046875}", "{\"n\": 9677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.58, \"learn_time_ms\": 8727.05, \"total_train_time_s\": 10.533555030822754}", "{\"n\": 9678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.58, \"learn_time_ms\": 8825.226, \"total_train_time_s\": 10.774085760116577}", "{\"n\": 9679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.36, \"learn_time_ms\": 8599.644, \"total_train_time_s\": 8.777264833450317}", "{\"n\": 9680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 8647.961, \"total_train_time_s\": 10.63115644454956}", "{\"n\": 9681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.52, \"learn_time_ms\": 8623.818, \"total_train_time_s\": 10.821556806564331}", "{\"n\": 9682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.52, \"learn_time_ms\": 8662.586, \"total_train_time_s\": 10.146191835403442}", "{\"n\": 9683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.12, \"learn_time_ms\": 8829.41, \"total_train_time_s\": 10.548619508743286}", "{\"n\": 9684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.86, \"learn_time_ms\": 8890.021, \"total_train_time_s\": 10.34065866470337}", "{\"n\": 9685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.86, \"learn_time_ms\": 8969.65, \"total_train_time_s\": 11.254353046417236}", "{\"n\": 9686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.95, \"learn_time_ms\": 8948.544, \"total_train_time_s\": 9.848948001861572}", "{\"n\": 9687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.52, \"learn_time_ms\": 8862.203, \"total_train_time_s\": 9.619094133377075}", "{\"n\": 9688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.07, \"learn_time_ms\": 8857.063, \"total_train_time_s\": 10.758168458938599}", "{\"n\": 9689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.09, \"learn_time_ms\": 9003.112, \"total_train_time_s\": 10.267527341842651}", "{\"n\": 9690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.64, \"learn_time_ms\": 8925.529, \"total_train_time_s\": 9.872779607772827}", "{\"n\": 9691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.19, \"learn_time_ms\": 8835.104, \"total_train_time_s\": 9.863007545471191}", "{\"n\": 9692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.26, \"learn_time_ms\": 8821.661, \"total_train_time_s\": 9.951905727386475}", "{\"n\": 9693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.98, \"learn_time_ms\": 8631.632, \"total_train_time_s\": 8.670567274093628}", "{\"n\": 9694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.56, \"learn_time_ms\": 8742.901, \"total_train_time_s\": 11.43024468421936}", "{\"n\": 9695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.56, \"learn_time_ms\": 8625.138, \"total_train_time_s\": 10.042522192001343}", "{\"n\": 9696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.1, \"learn_time_ms\": 8569.69, \"total_train_time_s\": 9.231431722640991}", "{\"n\": 9697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.22, \"learn_time_ms\": 8558.42, \"total_train_time_s\": 9.548553228378296}", "{\"n\": 9698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.97, \"learn_time_ms\": 8542.05, \"total_train_time_s\": 10.53858733177185}", "{\"n\": 9699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.53, \"learn_time_ms\": 8717.919, \"total_train_time_s\": 12.034611940383911}", "{\"n\": 9700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.21, \"learn_time_ms\": 8746.312, \"total_train_time_s\": 10.163579940795898}", "{\"n\": 9701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.84, \"learn_time_ms\": 8773.396, \"total_train_time_s\": 10.189462900161743}", "{\"n\": 9702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.84, \"learn_time_ms\": 8828.003, \"total_train_time_s\": 10.506550788879395}", "{\"n\": 9703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.3, \"learn_time_ms\": 9040.092, \"total_train_time_s\": 10.75917911529541}", "{\"n\": 9704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.19, \"learn_time_ms\": 8869.786, \"total_train_time_s\": 9.75731348991394}", "{\"n\": 9705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.19, \"learn_time_ms\": 8920.149, \"total_train_time_s\": 10.607505083084106}", "{\"n\": 9706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.47, \"learn_time_ms\": 9094.515, \"total_train_time_s\": 11.050274848937988}", "{\"n\": 9707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.21, \"learn_time_ms\": 9039.913, \"total_train_time_s\": 9.021598815917969}", "{\"n\": 9708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.49, \"learn_time_ms\": 8949.546, \"total_train_time_s\": 9.646885871887207}", "{\"n\": 9709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.66, \"learn_time_ms\": 8753.824, \"total_train_time_s\": 10.008667469024658}", "{\"n\": 9710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.18, \"learn_time_ms\": 8873.601, \"total_train_time_s\": 11.357431888580322}", "{\"n\": 9711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.3, \"learn_time_ms\": 8944.771, \"total_train_time_s\": 10.876078844070435}", "{\"n\": 9712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.66, \"learn_time_ms\": 8898.496, \"total_train_time_s\": 10.014678001403809}", "{\"n\": 9713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.38, \"learn_time_ms\": 8837.149, \"total_train_time_s\": 10.138427495956421}", "{\"n\": 9714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.28, \"learn_time_ms\": 8913.174, \"total_train_time_s\": 10.50007176399231}", "{\"n\": 9715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.92, \"learn_time_ms\": 8907.502, \"total_train_time_s\": 10.507937669754028}", "{\"n\": 9716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.14, \"learn_time_ms\": 8722.188, \"total_train_time_s\": 9.206323146820068}", "{\"n\": 9717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.35, \"learn_time_ms\": 8884.994, \"total_train_time_s\": 10.635146617889404}", "{\"n\": 9718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.29, \"learn_time_ms\": 8855.962, \"total_train_time_s\": 9.357813119888306}", "{\"n\": 9719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.85, \"learn_time_ms\": 8804.306, \"total_train_time_s\": 9.560150623321533}", "{\"n\": 9720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.85, \"learn_time_ms\": 8661.128, \"total_train_time_s\": 9.900152444839478}", "{\"n\": 9721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.68, \"learn_time_ms\": 8554.994, \"total_train_time_s\": 9.773406505584717}", "{\"n\": 9722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.27, \"learn_time_ms\": 8686.34, \"total_train_time_s\": 11.38622760772705}", "{\"n\": 9723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.27, \"learn_time_ms\": 8658.751, \"total_train_time_s\": 9.80902886390686}", "{\"n\": 9724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.29, \"learn_time_ms\": 8682.488, \"total_train_time_s\": 10.754352331161499}", "{\"n\": 9725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.58, \"learn_time_ms\": 8638.474, \"total_train_time_s\": 10.111842155456543}", "{\"n\": 9726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.05, \"learn_time_ms\": 8654.18, \"total_train_time_s\": 9.314661502838135}", "{\"n\": 9727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.05, \"learn_time_ms\": 8595.616, \"total_train_time_s\": 10.022438764572144}", "{\"n\": 9728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.51, \"learn_time_ms\": 8651.924, \"total_train_time_s\": 9.888885974884033}", "{\"n\": 9729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.19, \"learn_time_ms\": 8580.323, \"total_train_time_s\": 8.82237720489502}", "{\"n\": 9730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.19, \"learn_time_ms\": 8509.086, \"total_train_time_s\": 9.201140880584717}", "{\"n\": 9731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.37, \"learn_time_ms\": 8562.292, \"total_train_time_s\": 10.326269388198853}", "{\"n\": 9732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8460.657, \"total_train_time_s\": 10.365103244781494}", "{\"n\": 9733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8447.238, \"total_train_time_s\": 9.704282760620117}", "{\"n\": 9734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.86, \"learn_time_ms\": 8427.007, \"total_train_time_s\": 10.562718152999878}", "{\"n\": 9735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.36, \"learn_time_ms\": 8404.441, \"total_train_time_s\": 9.8739013671875}", "{\"n\": 9736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.36, \"learn_time_ms\": 8517.674, \"total_train_time_s\": 10.443994283676147}", "{\"n\": 9737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.36, \"learn_time_ms\": 8483.957, \"total_train_time_s\": 9.724353790283203}", "{\"n\": 9738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.1, \"learn_time_ms\": 8573.858, \"total_train_time_s\": 10.867361307144165}", "{\"n\": 9739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.62, \"learn_time_ms\": 8643.552, \"total_train_time_s\": 9.505621910095215}", "{\"n\": 9740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.62, \"learn_time_ms\": 8742.031, \"total_train_time_s\": 10.240288019180298}", "{\"n\": 9741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.5, \"learn_time_ms\": 8706.322, \"total_train_time_s\": 9.995323657989502}", "{\"n\": 9742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.27, \"learn_time_ms\": 8556.469, \"total_train_time_s\": 8.849795579910278}", "{\"n\": 9743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.68, \"learn_time_ms\": 8496.63, \"total_train_time_s\": 9.123331785202026}", "{\"n\": 9744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.18, \"learn_time_ms\": 8431.517, \"total_train_time_s\": 9.937947511672974}", "{\"n\": 9745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.19, \"learn_time_ms\": 8266.065, \"total_train_time_s\": 8.222452640533447}", "{\"n\": 9746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.97, \"learn_time_ms\": 8227.51, \"total_train_time_s\": 10.07022213935852}", "{\"n\": 9747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.69, \"learn_time_ms\": 8285.175, \"total_train_time_s\": 10.311184644699097}", "{\"n\": 9748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.69, \"learn_time_ms\": 8165.42, \"total_train_time_s\": 9.611039161682129}", "{\"n\": 9749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 8226.083, \"total_train_time_s\": 10.116089820861816}", "{\"n\": 9750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.41, \"learn_time_ms\": 8275.106, \"total_train_time_s\": 10.640170335769653}", "{\"n\": 9751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.41, \"learn_time_ms\": 8205.844, \"total_train_time_s\": 9.294917583465576}", "{\"n\": 9752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.43, \"learn_time_ms\": 8399.035, \"total_train_time_s\": 10.777227401733398}", "{\"n\": 9753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.41, \"learn_time_ms\": 8498.756, \"total_train_time_s\": 10.105687618255615}", "{\"n\": 9754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.06, \"learn_time_ms\": 8454.689, \"total_train_time_s\": 9.474659442901611}", "{\"n\": 9755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.64, \"learn_time_ms\": 8761.253, \"total_train_time_s\": 11.280866861343384}", "{\"n\": 9756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.18, \"learn_time_ms\": 8757.449, \"total_train_time_s\": 10.018385171890259}", "{\"n\": 9757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.17, \"learn_time_ms\": 8753.079, \"total_train_time_s\": 10.266549348831177}", "{\"n\": 9758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.17, \"learn_time_ms\": 8917.741, \"total_train_time_s\": 11.295584678649902}", "{\"n\": 9759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 8957.202, \"total_train_time_s\": 10.536039352416992}", "{\"n\": 9760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.87, \"learn_time_ms\": 8874.446, \"total_train_time_s\": 9.82028341293335}", "{\"n\": 9761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.87, \"learn_time_ms\": 9066.967, \"total_train_time_s\": 11.262006282806396}", "{\"n\": 9762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.61, \"learn_time_ms\": 9045.163, \"total_train_time_s\": 10.58592963218689}", "{\"n\": 9763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.39, \"learn_time_ms\": 9106.859, \"total_train_time_s\": 10.77528190612793}", "{\"n\": 9764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.78, \"learn_time_ms\": 9244.384, \"total_train_time_s\": 10.85526728630066}", "{\"n\": 9765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.78, \"learn_time_ms\": 9071.502, \"total_train_time_s\": 9.553015947341919}", "{\"n\": 9766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.26, \"learn_time_ms\": 9068.742, \"total_train_time_s\": 9.999541521072388}", "{\"n\": 9767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.72, \"learn_time_ms\": 9006.102, \"total_train_time_s\": 9.597168684005737}", "{\"n\": 9768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.72, \"learn_time_ms\": 8721.842, \"total_train_time_s\": 8.434064149856567}", "{\"n\": 9769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.12, \"learn_time_ms\": 8593.715, \"total_train_time_s\": 9.224726676940918}", "{\"n\": 9770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.12, \"learn_time_ms\": 8564.279, \"total_train_time_s\": 9.594700574874878}", "{\"n\": 9771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.13, \"learn_time_ms\": 8414.951, \"total_train_time_s\": 9.726792812347412}", "{\"n\": 9772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.77, \"learn_time_ms\": 8342.708, \"total_train_time_s\": 9.812582015991211}", "{\"n\": 9773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.38, \"learn_time_ms\": 8209.526, \"total_train_time_s\": 9.43306827545166}", "{\"n\": 9774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.97, \"learn_time_ms\": 8196.148, \"total_train_time_s\": 10.670310735702515}", "{\"n\": 9775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.97, \"learn_time_ms\": 8123.925, \"total_train_time_s\": 8.834867715835571}", "{\"n\": 9776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.63, \"learn_time_ms\": 8012.849, \"total_train_time_s\": 8.868460655212402}", "{\"n\": 9777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.01, \"learn_time_ms\": 8123.988, \"total_train_time_s\": 10.72156810760498}", "{\"n\": 9778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.01, \"learn_time_ms\": 8265.055, \"total_train_time_s\": 9.846177101135254}", "{\"n\": 9779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.81, \"learn_time_ms\": 8216.24, \"total_train_time_s\": 8.741053342819214}", "{\"n\": 9780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.81, \"learn_time_ms\": 8278.304, \"total_train_time_s\": 10.124264240264893}", "{\"n\": 9781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.64, \"learn_time_ms\": 8153.153, \"total_train_time_s\": 8.436274290084839}", "{\"n\": 9782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.04, \"learn_time_ms\": 8138.012, \"total_train_time_s\": 9.674826383590698}", "{\"n\": 9783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.41, \"learn_time_ms\": 8193.368, \"total_train_time_s\": 9.960906028747559}", "{\"n\": 9784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.06, \"learn_time_ms\": 8230.18, \"total_train_time_s\": 11.07174277305603}", "{\"n\": 9785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.67, \"learn_time_ms\": 8240.976, \"total_train_time_s\": 8.935405015945435}", "{\"n\": 9786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.67, \"learn_time_ms\": 8394.057, \"total_train_time_s\": 10.426876068115234}", "{\"n\": 9787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.7, \"learn_time_ms\": 8377.574, \"total_train_time_s\": 10.570836305618286}", "{\"n\": 9788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 8385.615, \"total_train_time_s\": 9.949167013168335}", "{\"n\": 9789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 8527.519, \"total_train_time_s\": 10.183748006820679}", "{\"n\": 9790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.96, \"learn_time_ms\": 8512.87, \"total_train_time_s\": 10.036697387695312}", "{\"n\": 9791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.39, \"learn_time_ms\": 8692.967, \"total_train_time_s\": 10.280638217926025}", "{\"n\": 9792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.39, \"learn_time_ms\": 8763.328, \"total_train_time_s\": 10.383845090866089}", "{\"n\": 9793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.91, \"learn_time_ms\": 8893.204, \"total_train_time_s\": 11.281381845474243}", "{\"n\": 9794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.48, \"learn_time_ms\": 8650.284, \"total_train_time_s\": 8.632271766662598}", "{\"n\": 9795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.34, \"learn_time_ms\": 8880.879, \"total_train_time_s\": 11.216162204742432}", "{\"n\": 9796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.92, \"learn_time_ms\": 8707.015, \"total_train_time_s\": 8.681888341903687}", "{\"n\": 9797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.92, \"learn_time_ms\": 8641.853, \"total_train_time_s\": 9.88818907737732}", "{\"n\": 9798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.34, \"learn_time_ms\": 8772.043, \"total_train_time_s\": 11.23827338218689}", "{\"n\": 9799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.21, \"learn_time_ms\": 8928.79, \"total_train_time_s\": 11.705214977264404}", "{\"n\": 9800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.95, \"learn_time_ms\": 8963.879, \"total_train_time_s\": 10.373871326446533}", "{\"n\": 9801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.13, \"learn_time_ms\": 8855.794, \"total_train_time_s\": 9.178285837173462}", "{\"n\": 9802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.97, \"learn_time_ms\": 8920.411, \"total_train_time_s\": 11.006855010986328}", "{\"n\": 9803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.29, \"learn_time_ms\": 8837.53, \"total_train_time_s\": 10.426860332489014}", "{\"n\": 9804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.16, \"learn_time_ms\": 9005.496, \"total_train_time_s\": 10.338799715042114}", "{\"n\": 9805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.35, \"learn_time_ms\": 8965.435, \"total_train_time_s\": 10.832891941070557}", "{\"n\": 9806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 9000.95, \"total_train_time_s\": 9.078000545501709}", "{\"n\": 9807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 9042.114, \"total_train_time_s\": 10.361027479171753}", "{\"n\": 9808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.17, \"learn_time_ms\": 8828.047, \"total_train_time_s\": 9.126781463623047}", "{\"n\": 9809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.17, \"learn_time_ms\": 8567.046, \"total_train_time_s\": 9.137807130813599}", "{\"n\": 9810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.13, \"learn_time_ms\": 8405.526, \"total_train_time_s\": 8.753900051116943}", "{\"n\": 9811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.89, \"learn_time_ms\": 8571.995, \"total_train_time_s\": 10.85995602607727}", "{\"n\": 9812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.87, \"learn_time_ms\": 8640.794, \"total_train_time_s\": 11.776923418045044}", "{\"n\": 9813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.44, \"learn_time_ms\": 8600.101, \"total_train_time_s\": 10.018521547317505}", "{\"n\": 9814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.08, \"learn_time_ms\": 8542.571, \"total_train_time_s\": 9.726250648498535}", "{\"n\": 9815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.4, \"learn_time_ms\": 8399.466, \"total_train_time_s\": 9.425621509552002}", "{\"n\": 9816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.35, \"learn_time_ms\": 8448.889, \"total_train_time_s\": 9.555925846099854}", "{\"n\": 9817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.55, \"learn_time_ms\": 8444.51, \"total_train_time_s\": 10.282533884048462}", "{\"n\": 9818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.55, \"learn_time_ms\": 8544.762, \"total_train_time_s\": 10.062666416168213}", "{\"n\": 9819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.86, \"learn_time_ms\": 8676.179, \"total_train_time_s\": 10.434887409210205}", "{\"n\": 9820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.0, \"learn_time_ms\": 8762.078, \"total_train_time_s\": 9.617357969284058}", "{\"n\": 9821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.0, \"learn_time_ms\": 8750.171, \"total_train_time_s\": 10.723022937774658}", "{\"n\": 9822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.1, \"learn_time_ms\": 8516.057, \"total_train_time_s\": 9.372798204421997}", "{\"n\": 9823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.53, \"learn_time_ms\": 8694.743, \"total_train_time_s\": 11.803253650665283}", "{\"n\": 9824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.92, \"learn_time_ms\": 8577.691, \"total_train_time_s\": 8.547895908355713}", "{\"n\": 9825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.92, \"learn_time_ms\": 8746.701, \"total_train_time_s\": 11.106260299682617}", "{\"n\": 9826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.92, \"learn_time_ms\": 8558.898, \"total_train_time_s\": 7.65566086769104}", "{\"n\": 9827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.1, \"learn_time_ms\": 8651.117, \"total_train_time_s\": 11.218831539154053}", "{\"n\": 9828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.1, \"learn_time_ms\": 8745.36, \"total_train_time_s\": 11.016216516494751}", "{\"n\": 9829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.13, \"learn_time_ms\": 8709.894, \"total_train_time_s\": 10.086544036865234}", "{\"n\": 9830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.82, \"learn_time_ms\": 8786.06, \"total_train_time_s\": 10.38355565071106}", "{\"n\": 9831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.82, \"learn_time_ms\": 8711.616, \"total_train_time_s\": 9.996828556060791}", "{\"n\": 9832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.35, \"learn_time_ms\": 8701.557, \"total_train_time_s\": 9.273183822631836}", "{\"n\": 9833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.02, \"learn_time_ms\": 8415.812, \"total_train_time_s\": 8.960078477859497}", "{\"n\": 9834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.95, \"learn_time_ms\": 8652.488, \"total_train_time_s\": 10.938005208969116}", "{\"n\": 9835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.95, \"learn_time_ms\": 8466.727, \"total_train_time_s\": 9.206683874130249}", "{\"n\": 9836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 8763.928, \"total_train_time_s\": 10.588634014129639}", "{\"n\": 9837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.52, \"learn_time_ms\": 8479.977, \"total_train_time_s\": 8.46143126487732}", "{\"n\": 9838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.52, \"learn_time_ms\": 8395.078, \"total_train_time_s\": 10.139713048934937}", "{\"n\": 9839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.02, \"learn_time_ms\": 8359.37, \"total_train_time_s\": 9.725146055221558}", "{\"n\": 9840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.02, \"learn_time_ms\": 8303.103, \"total_train_time_s\": 9.763800382614136}", "{\"n\": 9841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.0, \"learn_time_ms\": 8286.62, \"total_train_time_s\": 9.79934048652649}", "{\"n\": 9842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.13, \"learn_time_ms\": 8260.882, \"total_train_time_s\": 9.004583597183228}", "{\"n\": 9843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.27, \"learn_time_ms\": 8285.861, \"total_train_time_s\": 9.163127660751343}", "{\"n\": 9844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.32, \"learn_time_ms\": 8152.219, \"total_train_time_s\": 9.588735342025757}", "{\"n\": 9845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.32, \"learn_time_ms\": 8176.752, \"total_train_time_s\": 9.464674711227417}", "{\"n\": 9846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.77, \"learn_time_ms\": 8126.323, \"total_train_time_s\": 10.154229879379272}", "{\"n\": 9847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.77, \"learn_time_ms\": 8297.686, \"total_train_time_s\": 10.128998279571533}", "{\"n\": 9848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.64, \"learn_time_ms\": 8284.065, \"total_train_time_s\": 10.03476333618164}", "{\"n\": 9849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.39, \"learn_time_ms\": 8420.837, \"total_train_time_s\": 11.059945344924927}", "{\"n\": 9850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.51, \"learn_time_ms\": 8470.958, \"total_train_time_s\": 10.315919876098633}", "{\"n\": 9851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.85, \"learn_time_ms\": 8415.789, \"total_train_time_s\": 9.272286415100098}", "{\"n\": 9852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.68, \"learn_time_ms\": 8564.703, \"total_train_time_s\": 10.515958547592163}", "{\"n\": 9853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.44, \"learn_time_ms\": 8682.784, \"total_train_time_s\": 10.369646549224854}", "{\"n\": 9854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.41, \"learn_time_ms\": 8687.833, \"total_train_time_s\": 9.710917472839355}", "{\"n\": 9855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.29, \"learn_time_ms\": 8705.44, \"total_train_time_s\": 9.6624014377594}", "{\"n\": 9856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.54, \"learn_time_ms\": 8671.943, \"total_train_time_s\": 9.847632646560669}", "{\"n\": 9857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.54, \"learn_time_ms\": 8614.182, \"total_train_time_s\": 9.469804525375366}", "{\"n\": 9858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.38, \"learn_time_ms\": 8502.801, \"total_train_time_s\": 8.922852039337158}", "{\"n\": 9859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.55, \"learn_time_ms\": 8578.263, \"total_train_time_s\": 11.866488695144653}", "{\"n\": 9860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.43, \"learn_time_ms\": 8396.353, \"total_train_time_s\": 8.509736776351929}", "{\"n\": 9861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.3, \"learn_time_ms\": 8294.87, \"total_train_time_s\": 8.258564233779907}", "{\"n\": 9862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.3, \"learn_time_ms\": 8260.832, \"total_train_time_s\": 10.130235195159912}", "{\"n\": 9863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.42, \"learn_time_ms\": 8192.545, \"total_train_time_s\": 9.685256481170654}", "{\"n\": 9864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.42, \"learn_time_ms\": 8152.577, \"total_train_time_s\": 9.273805856704712}", "{\"n\": 9865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.98, \"learn_time_ms\": 8026.202, \"total_train_time_s\": 8.404841661453247}", "{\"n\": 9866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.65, \"learn_time_ms\": 8147.791, \"total_train_time_s\": 10.970629215240479}", "{\"n\": 9867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.94, \"learn_time_ms\": 8196.832, \"total_train_time_s\": 9.972348928451538}", "{\"n\": 9868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.17, \"learn_time_ms\": 8287.452, \"total_train_time_s\": 9.812424182891846}", "{\"n\": 9869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.17, \"learn_time_ms\": 8082.603, \"total_train_time_s\": 9.762564182281494}", "{\"n\": 9870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.9, \"learn_time_ms\": 8218.19, \"total_train_time_s\": 9.843791723251343}", "{\"n\": 9871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.62, \"learn_time_ms\": 8381.742, \"total_train_time_s\": 9.885753631591797}", "{\"n\": 9872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.27, \"learn_time_ms\": 8475.342, \"total_train_time_s\": 11.13270902633667}", "{\"n\": 9873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.43, \"learn_time_ms\": 8672.392, \"total_train_time_s\": 11.680022478103638}", "{\"n\": 9874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.43, \"learn_time_ms\": 8741.983, \"total_train_time_s\": 9.943272590637207}", "{\"n\": 9875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.78, \"learn_time_ms\": 9016.882, \"total_train_time_s\": 11.182848453521729}", "{\"n\": 9876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.27, \"learn_time_ms\": 8944.296, \"total_train_time_s\": 10.309865951538086}", "{\"n\": 9877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.27, \"learn_time_ms\": 8816.338, \"total_train_time_s\": 8.767353534698486}", "{\"n\": 9878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.21, \"learn_time_ms\": 8888.797, \"total_train_time_s\": 10.617524862289429}", "{\"n\": 9879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.07, \"learn_time_ms\": 8942.635, \"total_train_time_s\": 10.304702043533325}", "{\"n\": 9880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.3, \"learn_time_ms\": 9022.696, \"total_train_time_s\": 10.651918888092041}", "{\"n\": 9881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.67, \"learn_time_ms\": 9031.435, \"total_train_time_s\": 10.02405571937561}", "{\"n\": 9882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.22, \"learn_time_ms\": 8729.973, \"total_train_time_s\": 8.142577886581421}", "{\"n\": 9883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.1, \"learn_time_ms\": 8542.031, \"total_train_time_s\": 9.79303789138794}", "{\"n\": 9884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.55, \"learn_time_ms\": 8548.649, \"total_train_time_s\": 10.052003145217896}", "{\"n\": 9885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.71, \"learn_time_ms\": 8633.218, \"total_train_time_s\": 12.014617204666138}", "{\"n\": 9886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.19, \"learn_time_ms\": 8611.059, \"total_train_time_s\": 10.068140983581543}", "{\"n\": 9887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 8655.913, \"total_train_time_s\": 9.176135063171387}", "{\"n\": 9888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 8560.788, \"total_train_time_s\": 9.600958347320557}", "{\"n\": 9889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.13, \"learn_time_ms\": 8428.458, \"total_train_time_s\": 8.995452642440796}", "{\"n\": 9890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.8, \"learn_time_ms\": 8482.384, \"total_train_time_s\": 11.192304372787476}", "{\"n\": 9891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.39, \"learn_time_ms\": 8500.644, \"total_train_time_s\": 10.160489559173584}", "{\"n\": 9892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.65, \"learn_time_ms\": 8651.657, \"total_train_time_s\": 9.568157196044922}", "{\"n\": 9893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.25, \"learn_time_ms\": 8698.51, \"total_train_time_s\": 10.262073993682861}", "{\"n\": 9894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.74, \"learn_time_ms\": 8561.134, \"total_train_time_s\": 8.611509084701538}", "{\"n\": 9895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.32, \"learn_time_ms\": 8293.054, \"total_train_time_s\": 9.337930917739868}", "{\"n\": 9896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.54, \"learn_time_ms\": 8297.887, \"total_train_time_s\": 10.04910159111023}", "{\"n\": 9897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.52, \"learn_time_ms\": 8401.991, \"total_train_time_s\": 10.198488712310791}", "{\"n\": 9898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.52, \"learn_time_ms\": 8426.556, \"total_train_time_s\": 9.883348226547241}", "{\"n\": 9899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.78, \"learn_time_ms\": 8493.748, \"total_train_time_s\": 9.646548509597778}", "{\"n\": 9900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.56, \"learn_time_ms\": 8296.414, \"total_train_time_s\": 9.218555688858032}", "{\"n\": 9901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.56, \"learn_time_ms\": 8317.816, \"total_train_time_s\": 10.376980781555176}", "{\"n\": 9902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.0, \"learn_time_ms\": 8447.322, \"total_train_time_s\": 10.871077537536621}", "{\"n\": 9903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 8407.38, \"total_train_time_s\": 9.950231790542603}", "{\"n\": 9904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 8572.446, \"total_train_time_s\": 10.334063291549683}", "{\"n\": 9905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 8524.414, \"total_train_time_s\": 8.861381769180298}", "{\"n\": 9906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.3, \"learn_time_ms\": 8589.071, \"total_train_time_s\": 10.758448600769043}", "{\"n\": 9907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.12, \"learn_time_ms\": 8740.251, \"total_train_time_s\": 11.71295976638794}", "{\"n\": 9908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.12, \"learn_time_ms\": 8701.768, \"total_train_time_s\": 9.473111867904663}", "{\"n\": 9909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.9, \"learn_time_ms\": 8734.123, \"total_train_time_s\": 10.020776748657227}", "{\"n\": 9910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.74, \"learn_time_ms\": 8881.647, \"total_train_time_s\": 10.713079929351807}", "{\"n\": 9911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.74, \"learn_time_ms\": 8828.076, \"total_train_time_s\": 9.796371221542358}", "{\"n\": 9912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.3, \"learn_time_ms\": 8744.554, \"total_train_time_s\": 10.076913118362427}", "{\"n\": 9913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8743.156, \"total_train_time_s\": 9.877539873123169}", "{\"n\": 9914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8604.875, \"total_train_time_s\": 8.899133682250977}", "{\"n\": 9915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.16, \"learn_time_ms\": 8612.884, \"total_train_time_s\": 8.925184965133667}", "{\"n\": 9916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.17, \"learn_time_ms\": 8498.828, \"total_train_time_s\": 9.578453540802002}", "{\"n\": 9917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.26, \"learn_time_ms\": 8294.69, \"total_train_time_s\": 9.678961753845215}", "{\"n\": 9918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.26, \"learn_time_ms\": 8212.323, \"total_train_time_s\": 8.62454104423523}", "{\"n\": 9919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.08, \"learn_time_ms\": 8293.059, \"total_train_time_s\": 10.767278671264648}", "{\"n\": 9920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 8167.628, \"total_train_time_s\": 9.453863382339478}", "{\"n\": 9921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 8208.036, \"total_train_time_s\": 10.237257480621338}", "{\"n\": 9922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.78, \"learn_time_ms\": 8118.291, \"total_train_time_s\": 9.205942153930664}", "{\"n\": 9923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8023.088, \"total_train_time_s\": 8.953451156616211}", "{\"n\": 9924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8058.448, \"total_train_time_s\": 9.246747016906738}", "{\"n\": 9925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8145.657, \"total_train_time_s\": 9.800372123718262}", "{\"n\": 9926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.49, \"learn_time_ms\": 8126.628, \"total_train_time_s\": 9.466044425964355}", "{\"n\": 9927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.49, \"learn_time_ms\": 8179.661, \"total_train_time_s\": 10.207842350006104}", "{\"n\": 9928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.49, \"learn_time_ms\": 8341.777, \"total_train_time_s\": 10.26650595664978}", "{\"n\": 9929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.93, \"learn_time_ms\": 8230.4, \"total_train_time_s\": 9.740355968475342}", "{\"n\": 9930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.41, \"learn_time_ms\": 8420.323, \"total_train_time_s\": 11.290610074996948}", "{\"n\": 9931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.4, \"learn_time_ms\": 8455.897, \"total_train_time_s\": 10.564350605010986}", "{\"n\": 9932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.27, \"learn_time_ms\": 8521.739, \"total_train_time_s\": 9.814919233322144}", "{\"n\": 9933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.35, \"learn_time_ms\": 8634.687, \"total_train_time_s\": 10.054264545440674}", "{\"n\": 9934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.06, \"learn_time_ms\": 8673.528, \"total_train_time_s\": 9.727102518081665}", "{\"n\": 9935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.78, \"learn_time_ms\": 8693.218, \"total_train_time_s\": 10.008790731430054}", "{\"n\": 9936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.56, \"learn_time_ms\": 8649.757, \"total_train_time_s\": 9.0094895362854}", "{\"n\": 9937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.02, \"learn_time_ms\": 8510.145, \"total_train_time_s\": 8.815852403640747}", "{\"n\": 9938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.89, \"learn_time_ms\": 8385.413, \"total_train_time_s\": 9.056813478469849}", "{\"n\": 9939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.86, \"learn_time_ms\": 8140.331, \"total_train_time_s\": 7.195943593978882}", "{\"n\": 9940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.57, \"learn_time_ms\": 7948.286, \"total_train_time_s\": 9.413587808609009}", "{\"n\": 9941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.57, \"learn_time_ms\": 7770.517, \"total_train_time_s\": 8.80424427986145}", "{\"n\": 9942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.32, \"learn_time_ms\": 7958.025, \"total_train_time_s\": 11.708775043487549}", "{\"n\": 9943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.32, \"learn_time_ms\": 8019.16, \"total_train_time_s\": 10.639300346374512}", "{\"n\": 9944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.69, \"learn_time_ms\": 8062.856, \"total_train_time_s\": 10.120874404907227}", "{\"n\": 9945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.76, \"learn_time_ms\": 8113.918, \"total_train_time_s\": 10.466889381408691}", "{\"n\": 9946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.82, \"learn_time_ms\": 8089.774, \"total_train_time_s\": 8.673523187637329}", "{\"n\": 9947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.71, \"learn_time_ms\": 8043.909, \"total_train_time_s\": 8.335950136184692}", "{\"n\": 9948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.63, \"learn_time_ms\": 8112.878, \"total_train_time_s\": 9.735042095184326}", "{\"n\": 9949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.18, \"learn_time_ms\": 8343.607, \"total_train_time_s\": 9.631656646728516}", "{\"n\": 9950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.35, \"learn_time_ms\": 8392.178, \"total_train_time_s\": 9.898538827896118}", "{\"n\": 9951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.35, \"learn_time_ms\": 8501.23, \"total_train_time_s\": 9.92500376701355}", "{\"n\": 9952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.84, \"learn_time_ms\": 8144.776, \"total_train_time_s\": 8.106739044189453}", "{\"n\": 9953, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.86, \"learn_time_ms\": 8175.642, \"total_train_time_s\": 10.948878288269043}", "{\"n\": 9954, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.38, \"learn_time_ms\": 8078.624, \"total_train_time_s\": 9.111717939376831}", "{\"n\": 9955, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.15, \"learn_time_ms\": 8159.895, \"total_train_time_s\": 11.363024950027466}", "{\"n\": 9956, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.41, \"learn_time_ms\": 8221.374, \"total_train_time_s\": 9.341577768325806}", "{\"n\": 9957, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.92, \"learn_time_ms\": 8463.79, \"total_train_time_s\": 10.769592761993408}", "{\"n\": 9958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.0, \"learn_time_ms\": 8575.951, \"total_train_time_s\": 10.814132690429688}", "{\"n\": 9959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.16, \"learn_time_ms\": 8554.906, \"total_train_time_s\": 9.3468599319458}", "{\"n\": 9960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.89, \"learn_time_ms\": 8474.003, \"total_train_time_s\": 9.149353742599487}", "{\"n\": 9961, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.89, \"learn_time_ms\": 8425.888, \"total_train_time_s\": 9.42374563217163}", "{\"n\": 9962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.17, \"learn_time_ms\": 8641.298, \"total_train_time_s\": 10.296308755874634}", "{\"n\": 9963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.9, \"learn_time_ms\": 8541.63, \"total_train_time_s\": 9.913918733596802}", "{\"n\": 9964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.49, \"learn_time_ms\": 8724.633, \"total_train_time_s\": 10.93901777267456}", "{\"n\": 9965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.1, \"learn_time_ms\": 8575.28, \"total_train_time_s\": 9.82217264175415}", "{\"n\": 9966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.58, \"learn_time_ms\": 8626.48, \"total_train_time_s\": 9.85933518409729}", "{\"n\": 9967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.49, \"learn_time_ms\": 8361.118, \"total_train_time_s\": 8.12989330291748}", "{\"n\": 9968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.07, \"learn_time_ms\": 8340.807, \"total_train_time_s\": 10.661918878555298}", "{\"n\": 9969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.53, \"learn_time_ms\": 8386.284, \"total_train_time_s\": 9.835079908370972}", "{\"n\": 9970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.63, \"learn_time_ms\": 8563.985, \"total_train_time_s\": 10.819860935211182}", "{\"n\": 9971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.35, \"learn_time_ms\": 8578.519, \"total_train_time_s\": 9.54133915901184}", "{\"n\": 9972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.69, \"learn_time_ms\": 8531.168, \"total_train_time_s\": 9.82063627243042}", "{\"n\": 9973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.13, \"learn_time_ms\": 8486.06, \"total_train_time_s\": 9.477126836776733}", "{\"n\": 9974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.96, \"learn_time_ms\": 8630.227, \"total_train_time_s\": 12.37431788444519}", "{\"n\": 9975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.56, \"learn_time_ms\": 8655.738, \"total_train_time_s\": 10.045285701751709}", "{\"n\": 9976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.94, \"learn_time_ms\": 8637.885, \"total_train_time_s\": 9.726701021194458}", "{\"n\": 9977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.94, \"learn_time_ms\": 8810.832, \"total_train_time_s\": 9.847645282745361}", "{\"n\": 9978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.71, \"learn_time_ms\": 8643.7, \"total_train_time_s\": 8.949191808700562}", "{\"n\": 9979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.35, \"learn_time_ms\": 8593.187, \"total_train_time_s\": 9.294603824615479}", "{\"n\": 9980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.72, \"learn_time_ms\": 8550.102, \"total_train_time_s\": 10.414542436599731}", "{\"n\": 9981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.15, \"learn_time_ms\": 8522.098, \"total_train_time_s\": 9.289114952087402}", "{\"n\": 9982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.05, \"learn_time_ms\": 8642.607, \"total_train_time_s\": 10.97550106048584}", "{\"n\": 9983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.35, \"learn_time_ms\": 8643.873, \"total_train_time_s\": 9.486429929733276}", "{\"n\": 9984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.43, \"learn_time_ms\": 8365.368, \"total_train_time_s\": 9.614134788513184}", "{\"n\": 9985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.02, \"learn_time_ms\": 8377.338, \"total_train_time_s\": 10.16482663154602}", "{\"n\": 9986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.73, \"learn_time_ms\": 8507.954, \"total_train_time_s\": 11.024235248565674}", "{\"n\": 9987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.01, \"learn_time_ms\": 8471.212, \"total_train_time_s\": 9.518800735473633}", "{\"n\": 9988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.34, \"learn_time_ms\": 8461.055, \"total_train_time_s\": 8.843629121780396}", "{\"n\": 9989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.49, \"learn_time_ms\": 8540.207, \"total_train_time_s\": 10.063254117965698}", "{\"n\": 9990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 8407.461, \"total_train_time_s\": 9.126930952072144}", "{\"n\": 9991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.99, \"learn_time_ms\": 8499.483, \"total_train_time_s\": 10.251264095306396}", "{\"n\": 9992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.6, \"learn_time_ms\": 8568.53, \"total_train_time_s\": 11.709284782409668}", "{\"n\": 9993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.49, \"learn_time_ms\": 8583.29, \"total_train_time_s\": 9.695906639099121}", "{\"n\": 9994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.43, \"learn_time_ms\": 8667.051, \"total_train_time_s\": 10.407515287399292}", "{\"n\": 9995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.43, \"learn_time_ms\": 8676.53, \"total_train_time_s\": 10.273754358291626}", "{\"n\": 9996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.09, \"learn_time_ms\": 8611.532, \"total_train_time_s\": 10.384250164031982}", "{\"n\": 9997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.09, \"learn_time_ms\": 8605.359, \"total_train_time_s\": 9.412844181060791}", "{\"n\": 9998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.27, \"learn_time_ms\": 8746.881, \"total_train_time_s\": 10.27429747581482}", "{\"n\": 9999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.35, \"learn_time_ms\": 8884.497, \"total_train_time_s\": 11.447647333145142}", "{\"n\": 10000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.45, \"learn_time_ms\": 9060.219, \"total_train_time_s\": 10.865132808685303}", "{\"n\": 10001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.97, \"learn_time_ms\": 8990.115, \"total_train_time_s\": 9.503426313400269}", "{\"n\": 10002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.78, \"learn_time_ms\": 8846.061, \"total_train_time_s\": 10.306806325912476}", "{\"n\": 10003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.22, \"learn_time_ms\": 8837.212, \"total_train_time_s\": 9.577868700027466}", "{\"n\": 10004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.22, \"learn_time_ms\": 8908.542, \"total_train_time_s\": 11.182997465133667}", "{\"n\": 10005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.22, \"learn_time_ms\": 8788.03, \"total_train_time_s\": 9.054986715316772}", "{\"n\": 10006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.63, \"learn_time_ms\": 8834.662, \"total_train_time_s\": 10.817687511444092}", "{\"n\": 10007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.63, \"learn_time_ms\": 9005.775, \"total_train_time_s\": 11.107687950134277}", "{\"n\": 10008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.02, \"learn_time_ms\": 8947.144, \"total_train_time_s\": 9.64893627166748}", "{\"n\": 10009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.66, \"learn_time_ms\": 8797.807, \"total_train_time_s\": 9.936999320983887}", "{\"n\": 10010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.01, \"learn_time_ms\": 8715.672, \"total_train_time_s\": 10.089627027511597}", "{\"n\": 10011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.01, \"learn_time_ms\": 8825.382, \"total_train_time_s\": 10.568499565124512}", "{\"n\": 10012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.65, \"learn_time_ms\": 8819.743, \"total_train_time_s\": 10.177533626556396}", "{\"n\": 10013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.16, \"learn_time_ms\": 8962.145, \"total_train_time_s\": 11.028296947479248}", "{\"n\": 10014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.16, \"learn_time_ms\": 8817.375, \"total_train_time_s\": 9.683127641677856}", "{\"n\": 10015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.95, \"learn_time_ms\": 8977.344, \"total_train_time_s\": 10.64502215385437}", "{\"n\": 10016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.06, \"learn_time_ms\": 8997.163, \"total_train_time_s\": 10.982008695602417}", "{\"n\": 10017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.08, \"learn_time_ms\": 8793.385, \"total_train_time_s\": 9.058614492416382}", "{\"n\": 10018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 8915.646, \"total_train_time_s\": 10.91841173171997}", "{\"n\": 10019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.53, \"learn_time_ms\": 8962.418, \"total_train_time_s\": 10.389989376068115}", "{\"n\": 10020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.85, \"learn_time_ms\": 8875.538, \"total_train_time_s\": 9.235061407089233}", "{\"n\": 10021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.85, \"learn_time_ms\": 8879.245, \"total_train_time_s\": 10.658043384552002}", "{\"n\": 10022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.56, \"learn_time_ms\": 9029.734, \"total_train_time_s\": 11.687652349472046}", "{\"n\": 10023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.41, \"learn_time_ms\": 8885.68, \"total_train_time_s\": 9.570152997970581}", "{\"n\": 10024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.41, \"learn_time_ms\": 8955.69, \"total_train_time_s\": 10.359163045883179}", "{\"n\": 10025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.64, \"learn_time_ms\": 8843.984, \"total_train_time_s\": 9.54623007774353}", "{\"n\": 10026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.56, \"learn_time_ms\": 8768.624, \"total_train_time_s\": 10.223567485809326}", "{\"n\": 10027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.6, \"learn_time_ms\": 8966.871, \"total_train_time_s\": 11.096017599105835}", "{\"n\": 10028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.6, \"learn_time_ms\": 8861.922, \"total_train_time_s\": 9.889104843139648}", "{\"n\": 10029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.01, \"learn_time_ms\": 8765.065, \"total_train_time_s\": 9.499668836593628}", "{\"n\": 10030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.09, \"learn_time_ms\": 8943.351, \"total_train_time_s\": 10.964200019836426}", "{\"n\": 10031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.09, \"learn_time_ms\": 8920.676, \"total_train_time_s\": 10.418730974197388}", "{\"n\": 10032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 8739.225, \"total_train_time_s\": 9.891468286514282}", "{\"n\": 10033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.31, \"learn_time_ms\": 8804.001, \"total_train_time_s\": 10.214044094085693}", "{\"n\": 10034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.31, \"learn_time_ms\": 8769.427, \"total_train_time_s\": 10.053718090057373}", "{\"n\": 10035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.28, \"learn_time_ms\": 8847.325, \"total_train_time_s\": 10.361725330352783}", "{\"n\": 10036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.77, \"learn_time_ms\": 8799.896, \"total_train_time_s\": 9.711398124694824}", "{\"n\": 10037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.02, \"learn_time_ms\": 8658.522, \"total_train_time_s\": 9.640525817871094}", "{\"n\": 10038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 8604.923, \"total_train_time_s\": 9.281296968460083}", "{\"n\": 10039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.11, \"learn_time_ms\": 8756.424, \"total_train_time_s\": 10.979677438735962}", "{\"n\": 10040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.48, \"learn_time_ms\": 8700.631, \"total_train_time_s\": 10.421279668807983}", "{\"n\": 10041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.48, \"learn_time_ms\": 8656.542, \"total_train_time_s\": 9.994763135910034}", "{\"n\": 10042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.4, \"learn_time_ms\": 8771.583, \"total_train_time_s\": 11.012383699417114}", "{\"n\": 10043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.12, \"learn_time_ms\": 8785.567, \"total_train_time_s\": 10.344048500061035}", "{\"n\": 10044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.12, \"learn_time_ms\": 8796.645, \"total_train_time_s\": 10.10582709312439}", "{\"n\": 10045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.77, \"learn_time_ms\": 8844.362, \"total_train_time_s\": 10.855648279190063}", "{\"n\": 10046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.54, \"learn_time_ms\": 8889.937, \"total_train_time_s\": 10.24813199043274}", "{\"n\": 10047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.53, \"learn_time_ms\": 8938.672, \"total_train_time_s\": 10.178385019302368}", "{\"n\": 10048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.82, \"learn_time_ms\": 9009.632, \"total_train_time_s\": 10.02366852760315}", "{\"n\": 10049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.32, \"learn_time_ms\": 8952.478, \"total_train_time_s\": 10.422111749649048}", "{\"n\": 10050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.38, \"learn_time_ms\": 9034.313, \"total_train_time_s\": 11.199645757675171}", "{\"n\": 10051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.19, \"learn_time_ms\": 9053.716, \"total_train_time_s\": 10.184882640838623}", "{\"n\": 10052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.53, \"learn_time_ms\": 8946.974, \"total_train_time_s\": 9.920032262802124}", "{\"n\": 10053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.53, \"learn_time_ms\": 8882.262, \"total_train_time_s\": 9.692577600479126}", "{\"n\": 10054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.77, \"learn_time_ms\": 8848.029, \"total_train_time_s\": 9.8141508102417}", "{\"n\": 10055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.59, \"learn_time_ms\": 8762.41, \"total_train_time_s\": 9.954241275787354}", "{\"n\": 10056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.59, \"learn_time_ms\": 8684.314, \"total_train_time_s\": 9.451456785202026}", "{\"n\": 10057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.25, \"learn_time_ms\": 8726.595, \"total_train_time_s\": 10.571782350540161}", "{\"n\": 10058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.79, \"learn_time_ms\": 8567.732, \"total_train_time_s\": 8.422677040100098}", "{\"n\": 10059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.79, \"learn_time_ms\": 8510.207, \"total_train_time_s\": 9.84608507156372}", "{\"n\": 10060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.79, \"learn_time_ms\": 8433.19, \"total_train_time_s\": 10.471248388290405}", "{\"n\": 10061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.63, \"learn_time_ms\": 8399.691, \"total_train_time_s\": 9.86843490600586}", "{\"n\": 10062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.81, \"learn_time_ms\": 8396.503, \"total_train_time_s\": 9.935961246490479}", "{\"n\": 10063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.81, \"learn_time_ms\": 8463.362, \"total_train_time_s\": 10.358240127563477}", "{\"n\": 10064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.94, \"learn_time_ms\": 8443.234, \"total_train_time_s\": 9.636962175369263}", "{\"n\": 10065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 8266.283, \"total_train_time_s\": 8.19214391708374}", "{\"n\": 10066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 8298.344, \"total_train_time_s\": 9.79433560371399}", "{\"n\": 10067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 8161.857, \"total_train_time_s\": 9.187140464782715}", "{\"n\": 10068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.3, \"learn_time_ms\": 8288.082, \"total_train_time_s\": 9.69599986076355}", "{\"n\": 10069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.3, \"learn_time_ms\": 8311.898, \"total_train_time_s\": 10.073436975479126}", "{\"n\": 10070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.3, \"learn_time_ms\": 8220.548, \"total_train_time_s\": 9.583914995193481}", "{\"n\": 10071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.13, \"learn_time_ms\": 8228.806, \"total_train_time_s\": 9.930124998092651}", "{\"n\": 10072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.09, \"learn_time_ms\": 8457.372, \"total_train_time_s\": 12.245748281478882}", "{\"n\": 10073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.09, \"learn_time_ms\": 8466.438, \"total_train_time_s\": 10.449772357940674}", "{\"n\": 10074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.09, \"learn_time_ms\": 8451.307, \"total_train_time_s\": 9.483302593231201}", "{\"n\": 10075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.8, \"learn_time_ms\": 8705.54, \"total_train_time_s\": 10.758439064025879}", "{\"n\": 10076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 8742.687, \"total_train_time_s\": 10.13926386833191}", "{\"n\": 10077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 8972.039, \"total_train_time_s\": 11.480407476425171}", "{\"n\": 10078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 8878.548, \"total_train_time_s\": 8.745133638381958}", "{\"n\": 10079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.27, \"learn_time_ms\": 8899.353, \"total_train_time_s\": 10.298726320266724}", "{\"n\": 10080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.27, \"learn_time_ms\": 8936.299, \"total_train_time_s\": 9.901949644088745}", "{\"n\": 10081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.92, \"learn_time_ms\": 8966.574, \"total_train_time_s\": 10.238768815994263}", "{\"n\": 10082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.26, \"learn_time_ms\": 8681.824, \"total_train_time_s\": 9.371649742126465}", "{\"n\": 10083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.26, \"learn_time_ms\": 8696.348, \"total_train_time_s\": 10.586582899093628}", "{\"n\": 10084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.26, \"learn_time_ms\": 8666.959, \"total_train_time_s\": 9.17314338684082}", "{\"n\": 10085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.94, \"learn_time_ms\": 8654.099, \"total_train_time_s\": 10.678495407104492}", "{\"n\": 10086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.93, \"learn_time_ms\": 8504.111, \"total_train_time_s\": 8.638043403625488}", "{\"n\": 10087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.93, \"learn_time_ms\": 8288.612, \"total_train_time_s\": 9.341750621795654}", "{\"n\": 10088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.46, \"learn_time_ms\": 8545.896, \"total_train_time_s\": 11.360610723495483}", "{\"n\": 10089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.18, \"learn_time_ms\": 8518.431, \"total_train_time_s\": 10.040075778961182}", "{\"n\": 10090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.18, \"learn_time_ms\": 8481.647, \"total_train_time_s\": 9.550092697143555}", "{\"n\": 10091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.45, \"learn_time_ms\": 8418.685, \"total_train_time_s\": 9.612657070159912}", "{\"n\": 10092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.0, \"learn_time_ms\": 8486.238, \"total_train_time_s\": 10.029603004455566}", "{\"n\": 10093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.0, \"learn_time_ms\": 8457.041, \"total_train_time_s\": 10.255772590637207}", "{\"n\": 10094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.84, \"learn_time_ms\": 8608.201, \"total_train_time_s\": 10.697236061096191}", "{\"n\": 10095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.37, \"learn_time_ms\": 8504.486, \"total_train_time_s\": 9.583588361740112}", "{\"n\": 10096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.37, \"learn_time_ms\": 8804.161, \"total_train_time_s\": 11.652491569519043}", "{\"n\": 10097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.37, \"learn_time_ms\": 8870.138, \"total_train_time_s\": 10.00722622871399}", "{\"n\": 10098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.84, \"learn_time_ms\": 8676.996, \"total_train_time_s\": 9.431273221969604}", "{\"n\": 10099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.47, \"learn_time_ms\": 8559.182, \"total_train_time_s\": 8.898181676864624}", "{\"n\": 10100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.47, \"learn_time_ms\": 8681.981, \"total_train_time_s\": 10.744393825531006}", "{\"n\": 10101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.07, \"learn_time_ms\": 8661.375, \"total_train_time_s\": 9.393446207046509}", "{\"n\": 10102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 8723.199, \"total_train_time_s\": 10.72670602798462}", "{\"n\": 10103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 8748.551, \"total_train_time_s\": 10.534764766693115}", "{\"n\": 10104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 8597.671, \"total_train_time_s\": 9.157971382141113}", "{\"n\": 10105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.51, \"learn_time_ms\": 8596.891, \"total_train_time_s\": 9.536670446395874}", "{\"n\": 10106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.24, \"learn_time_ms\": 8429.385, \"total_train_time_s\": 9.948936462402344}", "{\"n\": 10107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.24, \"learn_time_ms\": 8400.207, \"total_train_time_s\": 9.726989269256592}", "{\"n\": 10108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.89, \"learn_time_ms\": 8459.827, \"total_train_time_s\": 10.001293659210205}", "{\"n\": 10109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.24, \"learn_time_ms\": 8636.164, \"total_train_time_s\": 10.579226732254028}", "{\"n\": 10110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.69, \"learn_time_ms\": 8562.997, \"total_train_time_s\": 10.050484895706177}", "{\"n\": 10111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.26, \"learn_time_ms\": 8711.571, \"total_train_time_s\": 10.91542911529541}", "{\"n\": 10112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.66, \"learn_time_ms\": 8489.845, \"total_train_time_s\": 8.454150199890137}", "{\"n\": 10113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.56, \"learn_time_ms\": 8371.097, \"total_train_time_s\": 9.398742914199829}", "{\"n\": 10114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.88, \"learn_time_ms\": 8505.12, \"total_train_time_s\": 10.529223442077637}", "{\"n\": 10115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.92, \"learn_time_ms\": 8582.297, \"total_train_time_s\": 10.300204992294312}", "{\"n\": 10116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.54, \"learn_time_ms\": 8548.688, \"total_train_time_s\": 9.640897035598755}", "{\"n\": 10117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.43, \"learn_time_ms\": 8508.319, \"total_train_time_s\": 9.29084300994873}", "{\"n\": 10118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.43, \"learn_time_ms\": 8537.327, \"total_train_time_s\": 10.310793161392212}", "{\"n\": 10119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.55, \"learn_time_ms\": 8544.357, \"total_train_time_s\": 10.674592971801758}", "{\"n\": 10120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 8520.737, \"total_train_time_s\": 9.866659164428711}", "{\"n\": 10121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.74, \"learn_time_ms\": 8453.248, \"total_train_time_s\": 10.218518495559692}", "{\"n\": 10122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.6, \"learn_time_ms\": 8713.243, \"total_train_time_s\": 11.057785987854004}", "{\"n\": 10123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.11, \"learn_time_ms\": 8803.455, \"total_train_time_s\": 10.257160663604736}", "{\"n\": 10124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.01, \"learn_time_ms\": 8591.467, \"total_train_time_s\": 8.40626311302185}", "{\"n\": 10125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.9, \"learn_time_ms\": 8654.511, \"total_train_time_s\": 10.96999454498291}", "{\"n\": 10126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.19, \"learn_time_ms\": 8674.633, \"total_train_time_s\": 9.83952784538269}", "{\"n\": 10127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.58, \"learn_time_ms\": 8703.514, \"total_train_time_s\": 9.657238006591797}", "{\"n\": 10128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.58, \"learn_time_ms\": 8619.403, \"total_train_time_s\": 9.416781187057495}", "{\"n\": 10129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.76, \"learn_time_ms\": 8501.691, \"total_train_time_s\": 9.494596242904663}", "{\"n\": 10130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.52, \"learn_time_ms\": 8458.783, \"total_train_time_s\": 9.407570362091064}", "{\"n\": 10131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.52, \"learn_time_ms\": 8406.629, \"total_train_time_s\": 9.660068273544312}", "{\"n\": 10132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.26, \"learn_time_ms\": 8269.966, \"total_train_time_s\": 9.658244132995605}", "{\"n\": 10133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.26, \"learn_time_ms\": 8316.864, \"total_train_time_s\": 10.733485460281372}", "{\"n\": 10134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8471.738, \"total_train_time_s\": 9.954822778701782}", "{\"n\": 10135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.91, \"learn_time_ms\": 8441.526, \"total_train_time_s\": 10.625603675842285}", "{\"n\": 10136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.33, \"learn_time_ms\": 8427.354, \"total_train_time_s\": 9.647227764129639}", "{\"n\": 10137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.27, \"learn_time_ms\": 8371.985, \"total_train_time_s\": 9.011728763580322}", "{\"n\": 10138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.27, \"learn_time_ms\": 8563.715, \"total_train_time_s\": 11.341540336608887}", "{\"n\": 10139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.22, \"learn_time_ms\": 8696.32, \"total_train_time_s\": 10.814884662628174}", "{\"n\": 10140, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.22, \"learn_time_ms\": 8871.223, \"total_train_time_s\": 11.077222108840942}", "{\"n\": 10141, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.3, \"learn_time_ms\": 8918.036, \"total_train_time_s\": 10.131895065307617}", "{\"n\": 10142, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8871.221, \"total_train_time_s\": 9.217851161956787}", "{\"n\": 10143, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8903.856, \"total_train_time_s\": 11.040303230285645}", "{\"n\": 10144, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.49, \"learn_time_ms\": 8806.205, \"total_train_time_s\": 8.961053609848022}", "{\"n\": 10145, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.47, \"learn_time_ms\": 8595.774, \"total_train_time_s\": 8.51590347290039}", "{\"n\": 10146, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.18, \"learn_time_ms\": 8638.75, \"total_train_time_s\": 10.117516994476318}", "{\"n\": 10147, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 8650.346, \"total_train_time_s\": 9.186949253082275}", "{\"n\": 10148, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 8472.448, \"total_train_time_s\": 9.587639331817627}", "{\"n\": 10149, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.61, \"learn_time_ms\": 8397.795, \"total_train_time_s\": 10.066912651062012}", "{\"n\": 10150, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.73, \"learn_time_ms\": 8443.789, \"total_train_time_s\": 11.569226741790771}", "{\"n\": 10151, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.69, \"learn_time_ms\": 8513.796, \"total_train_time_s\": 10.837593078613281}", "{\"n\": 10152, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.83, \"learn_time_ms\": 8517.074, \"total_train_time_s\": 9.23946499824524}", "{\"n\": 10153, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.83, \"learn_time_ms\": 8439.646, \"total_train_time_s\": 10.292511940002441}", "{\"n\": 10154, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.18, \"learn_time_ms\": 8603.37, \"total_train_time_s\": 10.573887586593628}", "{\"n\": 10155, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.94, \"learn_time_ms\": 8827.011, \"total_train_time_s\": 10.759680032730103}", "{\"n\": 10156, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.74, \"learn_time_ms\": 8774.803, \"total_train_time_s\": 9.604968309402466}", "{\"n\": 10157, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.74, \"learn_time_ms\": 8910.792, \"total_train_time_s\": 10.518434286117554}", "{\"n\": 10158, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.96, \"learn_time_ms\": 8942.766, \"total_train_time_s\": 9.925106763839722}", "{\"n\": 10159, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.14, \"learn_time_ms\": 8995.457, \"total_train_time_s\": 10.577443838119507}", "{\"n\": 10160, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.65, \"learn_time_ms\": 8779.11, \"total_train_time_s\": 9.379344940185547}", "{\"n\": 10161, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.8, \"learn_time_ms\": 8738.717, \"total_train_time_s\": 10.455858707427979}", "{\"n\": 10162, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.8, \"learn_time_ms\": 8823.708, \"total_train_time_s\": 10.097667217254639}", "{\"n\": 10163, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.74, \"learn_time_ms\": 8907.673, \"total_train_time_s\": 11.130156755447388}", "{\"n\": 10164, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.93, \"learn_time_ms\": 8826.065, \"total_train_time_s\": 9.825967073440552}", "{\"n\": 10165, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.98, \"learn_time_ms\": 8661.518, \"total_train_time_s\": 9.13117790222168}", "{\"n\": 10166, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.59, \"learn_time_ms\": 8689.243, \"total_train_time_s\": 9.853626489639282}", "{\"n\": 10167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.25, \"learn_time_ms\": 8711.424, \"total_train_time_s\": 10.773650884628296}", "{\"n\": 10168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.76, \"learn_time_ms\": 8711.917, \"total_train_time_s\": 9.933903455734253}", "{\"n\": 10169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.35, \"learn_time_ms\": 8512.654, \"total_train_time_s\": 8.597058773040771}", "{\"n\": 10170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.9, \"learn_time_ms\": 8604.397, \"total_train_time_s\": 10.361539602279663}", "{\"n\": 10171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.01, \"learn_time_ms\": 8623.248, \"total_train_time_s\": 10.674803972244263}", "{\"n\": 10172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.11, \"learn_time_ms\": 8678.577, \"total_train_time_s\": 10.663366794586182}", "{\"n\": 10173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.14, \"learn_time_ms\": 8352.04, \"total_train_time_s\": 7.889173984527588}", "{\"n\": 10174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.47, \"learn_time_ms\": 8303.684, \"total_train_time_s\": 9.294680833816528}", "{\"n\": 10175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.28, \"learn_time_ms\": 8400.066, \"total_train_time_s\": 10.150927305221558}", "{\"n\": 10176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.95, \"learn_time_ms\": 8512.434, \"total_train_time_s\": 11.053499221801758}", "{\"n\": 10177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.19, \"learn_time_ms\": 8379.657, \"total_train_time_s\": 9.420701742172241}", "{\"n\": 10178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.34, \"learn_time_ms\": 8305.568, \"total_train_time_s\": 9.185250043869019}", "{\"n\": 10179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.82, \"learn_time_ms\": 8250.555, \"total_train_time_s\": 7.98041033744812}", "{\"n\": 10180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.77, \"learn_time_ms\": 8083.757, \"total_train_time_s\": 8.64435863494873}", "{\"n\": 10181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.25, \"learn_time_ms\": 8059.764, \"total_train_time_s\": 10.343796253204346}", "{\"n\": 10182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.5, \"learn_time_ms\": 7986.945, \"total_train_time_s\": 9.953465461730957}", "{\"n\": 10183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.98, \"learn_time_ms\": 8231.473, \"total_train_time_s\": 10.30256724357605}", "{\"n\": 10184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.7, \"learn_time_ms\": 8370.735, \"total_train_time_s\": 10.739166498184204}", "{\"n\": 10185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.35, \"learn_time_ms\": 8408.518, \"total_train_time_s\": 10.485741138458252}", "{\"n\": 10186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.05, \"learn_time_ms\": 8277.498, \"total_train_time_s\": 9.7115957736969}", "{\"n\": 10187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.05, \"learn_time_ms\": 8499.814, \"total_train_time_s\": 11.59753966331482}", "{\"n\": 10188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.47, \"learn_time_ms\": 8624.613, \"total_train_time_s\": 10.462661743164062}", "{\"n\": 10189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.37, \"learn_time_ms\": 8803.319, \"total_train_time_s\": 9.84524655342102}", "{\"n\": 10190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.26, \"learn_time_ms\": 8842.727, \"total_train_time_s\": 9.051426410675049}", "{\"n\": 10191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.69, \"learn_time_ms\": 8715.63, \"total_train_time_s\": 9.101984739303589}", "{\"n\": 10192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.28, \"learn_time_ms\": 8633.153, \"total_train_time_s\": 9.079023361206055}", "{\"n\": 10193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.58, \"learn_time_ms\": 8482.843, \"total_train_time_s\": 8.812458276748657}", "{\"n\": 10194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.73, \"learn_time_ms\": 8355.785, \"total_train_time_s\": 9.450709104537964}", "{\"n\": 10195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.73, \"learn_time_ms\": 8349.727, \"total_train_time_s\": 10.402908325195312}", "{\"n\": 10196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.51, \"learn_time_ms\": 8222.765, \"total_train_time_s\": 8.431029558181763}", "{\"n\": 10197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.85, \"learn_time_ms\": 8148.115, \"total_train_time_s\": 10.869220495223999}", "{\"n\": 10198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.23, \"learn_time_ms\": 8087.718, \"total_train_time_s\": 9.806790351867676}", "{\"n\": 10199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.23, \"learn_time_ms\": 8024.543, \"total_train_time_s\": 9.180679321289062}", "{\"n\": 10200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.69, \"learn_time_ms\": 8108.204, \"total_train_time_s\": 9.91754412651062}", "{\"n\": 10201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.88, \"learn_time_ms\": 8107.913, \"total_train_time_s\": 9.194330215454102}", "{\"n\": 10202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.88, \"learn_time_ms\": 8145.249, \"total_train_time_s\": 9.469805240631104}", "{\"n\": 10203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.88, \"learn_time_ms\": 8308.45, \"total_train_time_s\": 10.445972681045532}", "{\"n\": 10204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.66, \"learn_time_ms\": 8476.87, \"total_train_time_s\": 11.117116689682007}", "{\"n\": 10205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.35, \"learn_time_ms\": 8433.038, \"total_train_time_s\": 10.01061224937439}", "{\"n\": 10206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.35, \"learn_time_ms\": 8604.587, \"total_train_time_s\": 10.12509799003601}", "{\"n\": 10207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.04, \"learn_time_ms\": 8450.634, \"total_train_time_s\": 9.376609802246094}", "{\"n\": 10208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.05, \"learn_time_ms\": 8564.83, \"total_train_time_s\": 10.967030763626099}", "{\"n\": 10209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.33, \"learn_time_ms\": 8601.369, \"total_train_time_s\": 9.5619637966156}", "{\"n\": 10210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.97, \"learn_time_ms\": 8518.356, \"total_train_time_s\": 9.044699430465698}", "{\"n\": 10211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.97, \"learn_time_ms\": 8733.02, \"total_train_time_s\": 11.258400678634644}", "{\"n\": 10212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.78, \"learn_time_ms\": 8730.351, \"total_train_time_s\": 9.529587745666504}", "{\"n\": 10213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.67, \"learn_time_ms\": 8607.299, \"total_train_time_s\": 9.217656135559082}", "{\"n\": 10214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.67, \"learn_time_ms\": 8570.598, \"total_train_time_s\": 10.749806880950928}", "{\"n\": 10215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.45, \"learn_time_ms\": 8541.256, \"total_train_time_s\": 9.690916299819946}", "{\"n\": 10216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.22, \"learn_time_ms\": 8480.413, \"total_train_time_s\": 9.545690298080444}", "{\"n\": 10217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.22, \"learn_time_ms\": 8602.835, \"total_train_time_s\": 10.591107368469238}", "{\"n\": 10218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.57, \"learn_time_ms\": 8448.4, \"total_train_time_s\": 9.473510503768921}", "{\"n\": 10219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.81, \"learn_time_ms\": 8441.835, \"total_train_time_s\": 9.494069337844849}", "{\"n\": 10220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.39, \"learn_time_ms\": 8308.609, \"total_train_time_s\": 7.703387498855591}", "{\"n\": 10221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.39, \"learn_time_ms\": 8204.248, \"total_train_time_s\": 10.22330641746521}", "{\"n\": 10222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.52, \"learn_time_ms\": 8227.656, \"total_train_time_s\": 9.70557188987732}", "{\"n\": 10223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.79, \"learn_time_ms\": 8311.575, \"total_train_time_s\": 10.093384742736816}", "{\"n\": 10224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.53, \"learn_time_ms\": 8154.75, \"total_train_time_s\": 9.191619396209717}", "{\"n\": 10225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.53, \"learn_time_ms\": 8150.96, \"total_train_time_s\": 9.668176412582397}", "{\"n\": 10226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.88, \"learn_time_ms\": 8183.566, \"total_train_time_s\": 9.871035814285278}", "{\"n\": 10227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.86, \"learn_time_ms\": 8094.833, \"total_train_time_s\": 9.66551661491394}", "{\"n\": 10228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.86, \"learn_time_ms\": 8251.724, \"total_train_time_s\": 10.967443466186523}", "{\"n\": 10229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.23, \"learn_time_ms\": 8511.703, \"total_train_time_s\": 12.077645301818848}", "{\"n\": 10230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.99, \"learn_time_ms\": 8773.777, \"total_train_time_s\": 10.36159086227417}", "{\"n\": 10231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.61, \"learn_time_ms\": 8816.946, \"total_train_time_s\": 10.673413038253784}", "{\"n\": 10232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.13, \"learn_time_ms\": 8771.293, \"total_train_time_s\": 9.233185768127441}", "{\"n\": 10233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.07, \"learn_time_ms\": 8811.417, \"total_train_time_s\": 10.438949584960938}", "{\"n\": 10234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.0, \"learn_time_ms\": 8924.935, \"total_train_time_s\": 10.32461953163147}", "{\"n\": 10235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.92, \"learn_time_ms\": 8943.21, \"total_train_time_s\": 9.820215463638306}", "{\"n\": 10236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.92, \"learn_time_ms\": 8910.321, \"total_train_time_s\": 9.515957593917847}", "{\"n\": 10237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.44, \"learn_time_ms\": 8900.829, \"total_train_time_s\": 9.59648060798645}", "{\"n\": 10238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.28, \"learn_time_ms\": 8778.739, \"total_train_time_s\": 9.774177074432373}", "{\"n\": 10239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.28, \"learn_time_ms\": 8557.932, \"total_train_time_s\": 9.90457558631897}", "{\"n\": 10240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.09, \"learn_time_ms\": 8499.911, \"total_train_time_s\": 9.779572486877441}", "{\"n\": 10241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.23, \"learn_time_ms\": 8366.374, \"total_train_time_s\": 9.250575542449951}", "{\"n\": 10242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.42, \"learn_time_ms\": 8485.606, \"total_train_time_s\": 10.388031721115112}", "{\"n\": 10243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.46, \"learn_time_ms\": 8478.036, \"total_train_time_s\": 10.39440655708313}", "{\"n\": 10244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.88, \"learn_time_ms\": 8526.117, \"total_train_time_s\": 10.79245376586914}", "{\"n\": 10245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.62, \"learn_time_ms\": 8521.976, \"total_train_time_s\": 9.765292167663574}", "{\"n\": 10246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.5, \"learn_time_ms\": 8519.055, \"total_train_time_s\": 9.51746940612793}", "{\"n\": 10247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.03, \"learn_time_ms\": 8510.987, \"total_train_time_s\": 9.517207622528076}", "{\"n\": 10248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.73, \"learn_time_ms\": 8396.492, \"total_train_time_s\": 8.623820066452026}", "{\"n\": 10249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.73, \"learn_time_ms\": 8463.073, \"total_train_time_s\": 10.59293818473816}", "{\"n\": 10250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.13, \"learn_time_ms\": 8474.502, \"total_train_time_s\": 9.872153759002686}", "{\"n\": 10251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.13, \"learn_time_ms\": 8521.929, \"total_train_time_s\": 9.776009321212769}", "{\"n\": 10252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.12, \"learn_time_ms\": 8447.251, \"total_train_time_s\": 9.669780254364014}", "{\"n\": 10253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.04, \"learn_time_ms\": 8497.426, \"total_train_time_s\": 10.874215364456177}", "{\"n\": 10254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.41, \"learn_time_ms\": 8383.457, \"total_train_time_s\": 9.628148555755615}", "{\"n\": 10255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.25, \"learn_time_ms\": 8415.304, \"total_train_time_s\": 10.13307499885559}", "{\"n\": 10256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.26, \"learn_time_ms\": 8539.619, \"total_train_time_s\": 10.789637327194214}", "{\"n\": 10257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.97, \"learn_time_ms\": 8772.844, \"total_train_time_s\": 11.828758001327515}", "{\"n\": 10258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.69, \"learn_time_ms\": 8912.604, \"total_train_time_s\": 10.040619134902954}", "{\"n\": 10259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.69, \"learn_time_ms\": 8950.916, \"total_train_time_s\": 10.93826150894165}", "{\"n\": 10260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.59, \"learn_time_ms\": 8880.568, \"total_train_time_s\": 9.209819555282593}", "{\"n\": 10261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.73, \"learn_time_ms\": 8995.317, \"total_train_time_s\": 10.905893802642822}", "{\"n\": 10262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.73, \"learn_time_ms\": 8940.892, \"total_train_time_s\": 9.151606798171997}", "{\"n\": 10263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.87, \"learn_time_ms\": 8897.727, \"total_train_time_s\": 10.486271858215332}", "{\"n\": 10264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.76, \"learn_time_ms\": 8767.747, \"total_train_time_s\": 8.357788324356079}", "{\"n\": 10265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.76, \"learn_time_ms\": 8709.808, \"total_train_time_s\": 9.518823146820068}", "{\"n\": 10266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.85, \"learn_time_ms\": 8687.954, \"total_train_time_s\": 10.529492139816284}", "{\"n\": 10267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.93, \"learn_time_ms\": 8439.726, \"total_train_time_s\": 9.384534120559692}", "{\"n\": 10268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.93, \"learn_time_ms\": 8392.864, \"total_train_time_s\": 9.52373480796814}", "{\"n\": 10269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.34, \"learn_time_ms\": 8252.617, \"total_train_time_s\": 9.527867555618286}", "{\"n\": 10270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.92, \"learn_time_ms\": 8362.129, \"total_train_time_s\": 10.306561946868896}", "{\"n\": 10271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.14, \"learn_time_ms\": 8288.795, \"total_train_time_s\": 10.19770359992981}", "{\"n\": 10272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.74, \"learn_time_ms\": 8290.972, \"total_train_time_s\": 9.118216753005981}", "{\"n\": 10273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.19, \"learn_time_ms\": 8305.968, \"total_train_time_s\": 10.640223741531372}", "{\"n\": 10274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.28, \"learn_time_ms\": 8361.716, \"total_train_time_s\": 8.937481880187988}", "{\"n\": 10275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.48, \"learn_time_ms\": 8379.944, \"total_train_time_s\": 9.678689956665039}", "{\"n\": 10276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.56, \"learn_time_ms\": 8245.222, \"total_train_time_s\": 9.158413648605347}", "{\"n\": 10277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.49, \"learn_time_ms\": 8172.673, \"total_train_time_s\": 8.629621505737305}", "{\"n\": 10278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.49, \"learn_time_ms\": 8245.796, \"total_train_time_s\": 10.298495054244995}", "{\"n\": 10279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.03, \"learn_time_ms\": 8230.91, \"total_train_time_s\": 9.416446685791016}", "{\"n\": 10280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.44, \"learn_time_ms\": 8134.724, \"total_train_time_s\": 9.290409326553345}", "{\"n\": 10281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.44, \"learn_time_ms\": 8105.7, \"total_train_time_s\": 9.94809889793396}", "{\"n\": 10282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.86, \"learn_time_ms\": 8123.191, \"total_train_time_s\": 9.344948053359985}", "{\"n\": 10283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.51, \"learn_time_ms\": 8061.727, \"total_train_time_s\": 9.958279609680176}", "{\"n\": 10284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.47, \"learn_time_ms\": 8052.077, \"total_train_time_s\": 8.83613896369934}", "{\"n\": 10285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.47, \"learn_time_ms\": 7981.073, \"total_train_time_s\": 8.979084730148315}", "{\"n\": 10286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.41, \"learn_time_ms\": 8135.865, \"total_train_time_s\": 10.722793817520142}", "{\"n\": 10287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.57, \"learn_time_ms\": 8406.497, \"total_train_time_s\": 11.37592077255249}", "{\"n\": 10288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.57, \"learn_time_ms\": 8407.961, \"total_train_time_s\": 10.306534767150879}", "{\"n\": 10289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.21, \"learn_time_ms\": 8541.07, \"total_train_time_s\": 10.694031476974487}", "{\"n\": 10290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.99, \"learn_time_ms\": 8591.619, \"total_train_time_s\": 9.847263097763062}", "{\"n\": 10291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.32, \"learn_time_ms\": 8627.024, \"total_train_time_s\": 10.263187170028687}", "{\"n\": 10292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.51, \"learn_time_ms\": 8775.236, \"total_train_time_s\": 10.837245464324951}", "{\"n\": 10293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.18, \"learn_time_ms\": 8859.352, \"total_train_time_s\": 10.837799072265625}", "{\"n\": 10294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.82, \"learn_time_ms\": 9031.258, \"total_train_time_s\": 10.555017232894897}", "{\"n\": 10295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.82, \"learn_time_ms\": 9238.163, \"total_train_time_s\": 11.060822248458862}", "{\"n\": 10296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.53, \"learn_time_ms\": 9236.829, \"total_train_time_s\": 10.714547395706177}", "{\"n\": 10297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.32, \"learn_time_ms\": 9086.099, \"total_train_time_s\": 9.863949060440063}", "{\"n\": 10298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.32, \"learn_time_ms\": 9029.653, \"total_train_time_s\": 9.690978288650513}", "{\"n\": 10299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.58, \"learn_time_ms\": 8997.409, \"total_train_time_s\": 10.373981475830078}", "{\"n\": 10300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.7, \"learn_time_ms\": 8997.642, \"total_train_time_s\": 9.834851264953613}", "{\"n\": 10301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.7, \"learn_time_ms\": 8996.189, \"total_train_time_s\": 10.299705028533936}", "{\"n\": 10302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.7, \"learn_time_ms\": 8858.744, \"total_train_time_s\": 9.430977582931519}", "{\"n\": 10303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.59, \"learn_time_ms\": 8765.235, \"total_train_time_s\": 9.872595310211182}", "{\"n\": 10304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.53, \"learn_time_ms\": 8844.916, \"total_train_time_s\": 11.37998080253601}", "{\"n\": 10305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.53, \"learn_time_ms\": 8723.606, \"total_train_time_s\": 9.855449914932251}", "{\"n\": 10306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.78, \"learn_time_ms\": 8743.974, \"total_train_time_s\": 10.897980451583862}", "{\"n\": 10307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.83, \"learn_time_ms\": 8709.256, \"total_train_time_s\": 9.482311725616455}", "{\"n\": 10308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.33, \"learn_time_ms\": 8861.438, \"total_train_time_s\": 11.246179342269897}", "{\"n\": 10309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.3, \"learn_time_ms\": 8698.773, \"total_train_time_s\": 8.776206016540527}", "{\"n\": 10310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.7, \"learn_time_ms\": 8640.351, \"total_train_time_s\": 9.266783237457275}", "{\"n\": 10311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.71, \"learn_time_ms\": 8677.276, \"total_train_time_s\": 10.615140676498413}", "{\"n\": 10312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.32, \"learn_time_ms\": 8841.555, \"total_train_time_s\": 11.096508741378784}", "{\"n\": 10313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.32, \"learn_time_ms\": 8812.731, \"total_train_time_s\": 9.606424331665039}", "{\"n\": 10314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.41, \"learn_time_ms\": 8809.862, \"total_train_time_s\": 11.266605854034424}", "{\"n\": 10315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.78, \"learn_time_ms\": 8876.362, \"total_train_time_s\": 10.52240514755249}", "{\"n\": 10316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.24, \"learn_time_ms\": 8880.865, \"total_train_time_s\": 10.936872243881226}", "{\"n\": 10317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.49, \"learn_time_ms\": 8987.347, \"total_train_time_s\": 10.587491273880005}", "{\"n\": 10318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.49, \"learn_time_ms\": 8698.205, \"total_train_time_s\": 8.342997550964355}", "{\"n\": 10319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.51, \"learn_time_ms\": 8683.713, \"total_train_time_s\": 8.595614194869995}", "{\"n\": 10320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.88, \"learn_time_ms\": 8862.523, \"total_train_time_s\": 11.054243564605713}", "{\"n\": 10321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.54, \"learn_time_ms\": 8762.742, \"total_train_time_s\": 9.658957481384277}", "{\"n\": 10322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.54, \"learn_time_ms\": 8714.232, \"total_train_time_s\": 10.61320161819458}", "{\"n\": 10323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.04, \"learn_time_ms\": 8920.383, \"total_train_time_s\": 11.66430115699768}", "{\"n\": 10324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.5, \"learn_time_ms\": 8948.836, \"total_train_time_s\": 11.612120151519775}", "{\"n\": 10325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.35, \"learn_time_ms\": 8923.124, \"total_train_time_s\": 10.296459197998047}", "{\"n\": 10326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.35, \"learn_time_ms\": 8805.054, \"total_train_time_s\": 9.799325227737427}", "{\"n\": 10327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.67, \"learn_time_ms\": 8655.752, \"total_train_time_s\": 9.049586534500122}", "{\"n\": 10328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8693.547, \"total_train_time_s\": 8.712640047073364}", "{\"n\": 10329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.25, \"learn_time_ms\": 8862.384, \"total_train_time_s\": 10.322070360183716}", "{\"n\": 10330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.63, \"learn_time_ms\": 8712.189, \"total_train_time_s\": 9.502551555633545}", "{\"n\": 10331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.97, \"learn_time_ms\": 8756.539, \"total_train_time_s\": 10.07657527923584}", "{\"n\": 10332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.88, \"learn_time_ms\": 8682.038, \"total_train_time_s\": 9.82482385635376}", "{\"n\": 10333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.88, \"learn_time_ms\": 8449.576, \"total_train_time_s\": 9.320680856704712}", "{\"n\": 10334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.72, \"learn_time_ms\": 8360.391, \"total_train_time_s\": 10.750898361206055}", "{\"n\": 10335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.9, \"learn_time_ms\": 8380.234, \"total_train_time_s\": 10.464316606521606}", "{\"n\": 10336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.9, \"learn_time_ms\": 8259.249, \"total_train_time_s\": 8.594407081604004}", "{\"n\": 10337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.52, \"learn_time_ms\": 8357.478, \"total_train_time_s\": 10.042707204818726}", "{\"n\": 10338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 8298.063, \"total_train_time_s\": 8.166640043258667}", "{\"n\": 10339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 8477.658, \"total_train_time_s\": 12.10646390914917}", "{\"n\": 10340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 8644.146, \"total_train_time_s\": 11.171388626098633}", "{\"n\": 10341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.3, \"learn_time_ms\": 8719.511, \"total_train_time_s\": 10.839357852935791}", "{\"n\": 10342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.59, \"learn_time_ms\": 8681.327, \"total_train_time_s\": 9.51796555519104}", "{\"n\": 10343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.59, \"learn_time_ms\": 8755.282, \"total_train_time_s\": 10.081329584121704}", "{\"n\": 10344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.78, \"learn_time_ms\": 8749.868, \"total_train_time_s\": 10.662452459335327}", "{\"n\": 10345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.43, \"learn_time_ms\": 8808.633, \"total_train_time_s\": 11.09198784828186}", "{\"n\": 10346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.43, \"learn_time_ms\": 9075.306, \"total_train_time_s\": 11.231376647949219}", "{\"n\": 10347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.5, \"learn_time_ms\": 9021.038, \"total_train_time_s\": 9.501946210861206}", "{\"n\": 10348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.13, \"learn_time_ms\": 9163.246, \"total_train_time_s\": 9.575446844100952}", "{\"n\": 10349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.77, \"learn_time_ms\": 8990.395, \"total_train_time_s\": 10.429577112197876}", "{\"n\": 10350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.77, \"learn_time_ms\": 8944.861, \"total_train_time_s\": 10.767753839492798}", "{\"n\": 10351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.27, \"learn_time_ms\": 8846.08, \"total_train_time_s\": 9.867101430892944}", "{\"n\": 10352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.28, \"learn_time_ms\": 8820.073, \"total_train_time_s\": 9.22757339477539}", "{\"n\": 10353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.28, \"learn_time_ms\": 8828.292, \"total_train_time_s\": 10.170365333557129}", "{\"n\": 10354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.32, \"learn_time_ms\": 8894.355, \"total_train_time_s\": 11.305171728134155}", "{\"n\": 10355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.86, \"learn_time_ms\": 8724.746, \"total_train_time_s\": 9.349088430404663}", "{\"n\": 10356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.86, \"learn_time_ms\": 8586.484, \"total_train_time_s\": 9.839327573776245}", "{\"n\": 10357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.87, \"learn_time_ms\": 8565.179, \"total_train_time_s\": 9.325380563735962}", "{\"n\": 10358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.5, \"learn_time_ms\": 8611.294, \"total_train_time_s\": 10.067141056060791}", "{\"n\": 10359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.5, \"learn_time_ms\": 8503.908, \"total_train_time_s\": 9.271459817886353}", "{\"n\": 10360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.46, \"learn_time_ms\": 8301.906, \"total_train_time_s\": 8.696043252944946}", "{\"n\": 10361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.65, \"learn_time_ms\": 8410.355, \"total_train_time_s\": 10.92370080947876}", "{\"n\": 10362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.87, \"learn_time_ms\": 8490.497, \"total_train_time_s\": 9.995205163955688}", "{\"n\": 10363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.37, \"learn_time_ms\": 8435.204, \"total_train_time_s\": 9.645871639251709}", "{\"n\": 10364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.43, \"learn_time_ms\": 8282.877, \"total_train_time_s\": 9.802163124084473}", "{\"n\": 10365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.85, \"learn_time_ms\": 8278.798, \"total_train_time_s\": 9.32395076751709}", "{\"n\": 10366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.85, \"learn_time_ms\": 8238.502, \"total_train_time_s\": 9.45327091217041}", "{\"n\": 10367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.5, \"learn_time_ms\": 8294.446, \"total_train_time_s\": 9.82552433013916}", "{\"n\": 10368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.26, \"learn_time_ms\": 8200.363, \"total_train_time_s\": 9.064582586288452}", "{\"n\": 10369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.26, \"learn_time_ms\": 8214.007, \"total_train_time_s\": 9.440603733062744}", "{\"n\": 10370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.21, \"learn_time_ms\": 8362.045, \"total_train_time_s\": 10.168675184249878}", "{\"n\": 10371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.17, \"learn_time_ms\": 8270.052, \"total_train_time_s\": 10.02199411392212}", "{\"n\": 10372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.17, \"learn_time_ms\": 8333.174, \"total_train_time_s\": 10.633631706237793}", "{\"n\": 10373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.17, \"learn_time_ms\": 8288.277, \"total_train_time_s\": 9.153710126876831}", "{\"n\": 10374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.1, \"learn_time_ms\": 8342.129, \"total_train_time_s\": 10.327728509902954}", "{\"n\": 10375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.36, \"learn_time_ms\": 8407.396, \"total_train_time_s\": 9.973233461380005}", "{\"n\": 10376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.36, \"learn_time_ms\": 8434.496, \"total_train_time_s\": 9.695703983306885}", "{\"n\": 10377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.36, \"learn_time_ms\": 8730.141, \"total_train_time_s\": 12.82328724861145}", "{\"n\": 10378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8722.123, \"total_train_time_s\": 9.032445907592773}", "{\"n\": 10379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8639.963, \"total_train_time_s\": 8.631125926971436}", "{\"n\": 10380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8665.057, \"total_train_time_s\": 10.461863279342651}", "{\"n\": 10381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 8676.954, \"total_train_time_s\": 10.120216846466064}", "{\"n\": 10382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 8792.539, \"total_train_time_s\": 11.802432775497437}", "{\"n\": 10383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 8828.405, \"total_train_time_s\": 9.5028817653656}", "{\"n\": 10384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.76, \"learn_time_ms\": 8927.608, \"total_train_time_s\": 11.361491441726685}", "{\"n\": 10385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.76, \"learn_time_ms\": 9064.822, \"total_train_time_s\": 11.315329551696777}", "{\"n\": 10386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.89, \"learn_time_ms\": 9048.453, \"total_train_time_s\": 9.523380994796753}", "{\"n\": 10387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.62, \"learn_time_ms\": 8902.29, \"total_train_time_s\": 11.34036898612976}", "{\"n\": 10388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.83, \"learn_time_ms\": 9041.386, \"total_train_time_s\": 10.360562086105347}", "{\"n\": 10389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.4, \"learn_time_ms\": 9233.533, \"total_train_time_s\": 10.590911626815796}", "{\"n\": 10390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.51, \"learn_time_ms\": 9083.47, \"total_train_time_s\": 8.99148178100586}", "{\"n\": 10391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.39, \"learn_time_ms\": 9084.957, \"total_train_time_s\": 10.154419660568237}", "{\"n\": 10392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.82, \"learn_time_ms\": 8925.449, \"total_train_time_s\": 10.17521595954895}", "{\"n\": 10393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.42, \"learn_time_ms\": 8977.882, \"total_train_time_s\": 10.067447900772095}", "{\"n\": 10394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.88, \"learn_time_ms\": 8872.66, \"total_train_time_s\": 10.255897998809814}", "{\"n\": 10395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.88, \"learn_time_ms\": 8645.483, \"total_train_time_s\": 9.093460321426392}", "{\"n\": 10396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.93, \"learn_time_ms\": 8864.128, \"total_train_time_s\": 11.752886533737183}", "{\"n\": 10397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.92, \"learn_time_ms\": 8621.987, \"total_train_time_s\": 8.927409172058105}", "{\"n\": 10398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.92, \"learn_time_ms\": 8584.398, \"total_train_time_s\": 10.038434743881226}", "{\"n\": 10399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.59, \"learn_time_ms\": 8562.455, \"total_train_time_s\": 10.37018084526062}", "{\"n\": 10400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.73, \"learn_time_ms\": 8571.499, \"total_train_time_s\": 9.004619359970093}", "{\"n\": 10401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.87, \"learn_time_ms\": 8546.687, \"total_train_time_s\": 9.868388175964355}", "{\"n\": 10402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.28, \"learn_time_ms\": 8383.727, \"total_train_time_s\": 8.595037937164307}", "{\"n\": 10403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.28, \"learn_time_ms\": 8384.957, \"total_train_time_s\": 10.032616138458252}", "{\"n\": 10404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.87, \"learn_time_ms\": 8310.074, \"total_train_time_s\": 9.550222873687744}", "{\"n\": 10405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.49, \"learn_time_ms\": 8427.159, \"total_train_time_s\": 10.217982053756714}", "{\"n\": 10406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.28, \"learn_time_ms\": 8266.014, \"total_train_time_s\": 10.144734621047974}", "{\"n\": 10407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.38, \"learn_time_ms\": 8334.315, \"total_train_time_s\": 9.615430355072021}", "{\"n\": 10408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.62, \"learn_time_ms\": 8314.992, \"total_train_time_s\": 9.85898756980896}", "{\"n\": 10409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.56, \"learn_time_ms\": 8209.604, \"total_train_time_s\": 9.321966409683228}", "{\"n\": 10410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.3, \"learn_time_ms\": 8309.177, \"total_train_time_s\": 10.037861347198486}", "{\"n\": 10411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.5, \"learn_time_ms\": 8426.781, \"total_train_time_s\": 11.029335975646973}", "{\"n\": 10412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.98, \"learn_time_ms\": 8697.673, \"total_train_time_s\": 11.271419286727905}", "{\"n\": 10413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.69, \"learn_time_ms\": 8650.677, \"total_train_time_s\": 9.593069076538086}", "{\"n\": 10414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.78, \"learn_time_ms\": 8751.811, \"total_train_time_s\": 10.555721759796143}", "{\"n\": 10415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.78, \"learn_time_ms\": 8782.343, \"total_train_time_s\": 10.559768438339233}", "{\"n\": 10416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.4, \"learn_time_ms\": 8843.269, \"total_train_time_s\": 10.766990423202515}", "{\"n\": 10417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.77, \"learn_time_ms\": 8788.941, \"total_train_time_s\": 9.090889692306519}", "{\"n\": 10418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.94, \"learn_time_ms\": 8614.378, \"total_train_time_s\": 8.093734979629517}", "{\"n\": 10419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.94, \"learn_time_ms\": 8835.324, \"total_train_time_s\": 11.473616123199463}", "{\"n\": 10420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.61, \"learn_time_ms\": 8760.665, \"total_train_time_s\": 9.306559085845947}", "{\"n\": 10421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 8651.503, \"total_train_time_s\": 9.94308853149414}", "{\"n\": 10422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 8588.787, \"total_train_time_s\": 10.657480001449585}", "{\"n\": 10423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.84, \"learn_time_ms\": 8798.867, \"total_train_time_s\": 11.68744421005249}", "{\"n\": 10424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.52, \"learn_time_ms\": 8833.385, \"total_train_time_s\": 10.902014970779419}", "{\"n\": 10425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.52, \"learn_time_ms\": 8878.933, \"total_train_time_s\": 10.987025022506714}", "{\"n\": 10426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.08, \"learn_time_ms\": 8927.082, \"total_train_time_s\": 11.224003314971924}", "{\"n\": 10427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 9044.64, \"total_train_time_s\": 10.222763299942017}", "{\"n\": 10428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.23, \"learn_time_ms\": 9236.896, \"total_train_time_s\": 9.977835655212402}", "{\"n\": 10429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.23, \"learn_time_ms\": 9015.923, \"total_train_time_s\": 9.26811933517456}", "{\"n\": 10430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.08, \"learn_time_ms\": 9055.115, \"total_train_time_s\": 9.644513607025146}", "{\"n\": 10431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 9051.196, \"total_train_time_s\": 9.940443754196167}", "{\"n\": 10432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 8984.184, \"total_train_time_s\": 9.992115497589111}", "{\"n\": 10433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.6, \"learn_time_ms\": 8918.017, \"total_train_time_s\": 11.05697774887085}", "{\"n\": 10434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.88, \"learn_time_ms\": 8907.362, \"total_train_time_s\": 10.803831577301025}", "{\"n\": 10435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.88, \"learn_time_ms\": 8784.837, \"total_train_time_s\": 9.751189231872559}", "{\"n\": 10436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.33, \"learn_time_ms\": 8632.804, \"total_train_time_s\": 9.701783657073975}", "{\"n\": 10437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.33, \"learn_time_ms\": 8468.626, \"total_train_time_s\": 8.608359813690186}", "{\"n\": 10438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.6, \"learn_time_ms\": 8355.494, \"total_train_time_s\": 8.885672807693481}", "{\"n\": 10439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.6, \"learn_time_ms\": 8334.123, \"total_train_time_s\": 9.02763295173645}", "{\"n\": 10440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.04, \"learn_time_ms\": 8434.07, \"total_train_time_s\": 10.701390266418457}", "{\"n\": 10441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.07, \"learn_time_ms\": 8476.422, \"total_train_time_s\": 10.36367154121399}", "{\"n\": 10442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.07, \"learn_time_ms\": 8436.169, \"total_train_time_s\": 9.648319721221924}", "{\"n\": 10443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.75, \"learn_time_ms\": 8409.923, \"total_train_time_s\": 10.786192178726196}", "{\"n\": 10444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.39, \"learn_time_ms\": 8395.606, \"total_train_time_s\": 10.618513584136963}", "{\"n\": 10445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.39, \"learn_time_ms\": 8523.903, \"total_train_time_s\": 11.065685033798218}", "{\"n\": 10446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.56, \"learn_time_ms\": 8475.515, \"total_train_time_s\": 9.212656497955322}", "{\"n\": 10447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.98, \"learn_time_ms\": 8695.858, \"total_train_time_s\": 10.807490110397339}", "{\"n\": 10448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.64, \"learn_time_ms\": 8903.282, \"total_train_time_s\": 10.977177619934082}", "{\"n\": 10449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.69, \"learn_time_ms\": 9010.343, \"total_train_time_s\": 10.114123582839966}", "{\"n\": 10450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.17, \"learn_time_ms\": 8970.353, \"total_train_time_s\": 10.282293796539307}", "{\"n\": 10451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.14, \"learn_time_ms\": 8901.29, \"total_train_time_s\": 9.65790343284607}", "{\"n\": 10452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.23, \"learn_time_ms\": 8851.649, \"total_train_time_s\": 9.09885859489441}", "{\"n\": 10453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.56, \"learn_time_ms\": 8662.637, \"total_train_time_s\": 8.842089176177979}", "{\"n\": 10454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.76, \"learn_time_ms\": 8567.099, \"total_train_time_s\": 9.68613076210022}", "{\"n\": 10455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.76, \"learn_time_ms\": 8338.879, \"total_train_time_s\": 8.774083614349365}", "{\"n\": 10456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.71, \"learn_time_ms\": 8625.479, \"total_train_time_s\": 12.096169471740723}", "{\"n\": 10457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.26, \"learn_time_ms\": 8565.905, \"total_train_time_s\": 10.1978440284729}", "{\"n\": 10458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.51, \"learn_time_ms\": 8621.394, \"total_train_time_s\": 11.528125524520874}", "{\"n\": 10459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.99, \"learn_time_ms\": 8587.627, \"total_train_time_s\": 9.763188123703003}", "{\"n\": 10460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.59, \"learn_time_ms\": 8521.573, \"total_train_time_s\": 9.606993913650513}", "{\"n\": 10461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.24, \"learn_time_ms\": 8522.325, \"total_train_time_s\": 9.662168502807617}", "{\"n\": 10462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.24, \"learn_time_ms\": 8789.955, \"total_train_time_s\": 11.730879783630371}", "{\"n\": 10463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.27, \"learn_time_ms\": 8880.324, \"total_train_time_s\": 9.789417266845703}", "{\"n\": 10464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.27, \"learn_time_ms\": 9061.868, \"total_train_time_s\": 11.491498947143555}", "{\"n\": 10465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.7, \"learn_time_ms\": 9313.795, \"total_train_time_s\": 11.361711263656616}", "{\"n\": 10466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.6, \"learn_time_ms\": 9225.411, \"total_train_time_s\": 11.178792715072632}", "{\"n\": 10467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.8, \"learn_time_ms\": 9133.757, \"total_train_time_s\": 9.290428638458252}", "{\"n\": 10468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.36, \"learn_time_ms\": 9026.882, \"total_train_time_s\": 10.4542076587677}", "{\"n\": 10469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.25, \"learn_time_ms\": 9148.722, \"total_train_time_s\": 11.019697904586792}", "{\"n\": 10470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 9078.521, \"total_train_time_s\": 8.891431093215942}", "{\"n\": 10471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.15, \"learn_time_ms\": 9075.213, \"total_train_time_s\": 9.592650651931763}", "{\"n\": 10472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.15, \"learn_time_ms\": 9015.23, \"total_train_time_s\": 11.135261297225952}", "{\"n\": 10473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.27, \"learn_time_ms\": 9081.766, \"total_train_time_s\": 10.41805362701416}", "{\"n\": 10474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.49, \"learn_time_ms\": 8984.255, \"total_train_time_s\": 10.518735647201538}", "{\"n\": 10475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.49, \"learn_time_ms\": 8963.237, \"total_train_time_s\": 11.083638906478882}", "{\"n\": 10476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 8964.952, \"total_train_time_s\": 11.191118717193604}", "{\"n\": 10477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.37, \"learn_time_ms\": 9070.217, \"total_train_time_s\": 10.299506425857544}", "{\"n\": 10478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.85, \"learn_time_ms\": 8976.302, \"total_train_time_s\": 9.502405405044556}", "{\"n\": 10479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.85, \"learn_time_ms\": 8699.38, \"total_train_time_s\": 8.222827196121216}", "{\"n\": 10480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.76, \"learn_time_ms\": 8883.272, \"total_train_time_s\": 10.746055841445923}", "{\"n\": 10481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.51, \"learn_time_ms\": 9081.376, \"total_train_time_s\": 11.624187231063843}", "{\"n\": 10482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.51, \"learn_time_ms\": 8925.134, \"total_train_time_s\": 9.610971689224243}", "{\"n\": 10483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.79, \"learn_time_ms\": 8838.181, \"total_train_time_s\": 9.557032585144043}", "{\"n\": 10484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.04, \"learn_time_ms\": 8892.433, \"total_train_time_s\": 11.029382467269897}", "{\"n\": 10485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.04, \"learn_time_ms\": 8669.727, \"total_train_time_s\": 8.862721681594849}", "{\"n\": 10486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.51, \"learn_time_ms\": 8727.945, \"total_train_time_s\": 11.811683177947998}", "{\"n\": 10487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.87, \"learn_time_ms\": 8652.468, \"total_train_time_s\": 9.594722747802734}", "{\"n\": 10488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.02, \"learn_time_ms\": 8793.573, \"total_train_time_s\": 10.903372049331665}", "{\"n\": 10489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.64, \"learn_time_ms\": 9042.374, \"total_train_time_s\": 10.733625411987305}", "{\"n\": 10490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.41, \"learn_time_ms\": 8817.705, \"total_train_time_s\": 8.513335227966309}", "{\"n\": 10491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.77, \"learn_time_ms\": 8676.384, \"total_train_time_s\": 10.158481121063232}", "{\"n\": 10492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.01, \"learn_time_ms\": 8714.255, \"total_train_time_s\": 9.96592402458191}", "{\"n\": 10493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.97, \"learn_time_ms\": 8749.318, \"total_train_time_s\": 9.934361457824707}", "{\"n\": 10494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.51, \"learn_time_ms\": 8593.914, \"total_train_time_s\": 9.471681356430054}", "{\"n\": 10495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.35, \"learn_time_ms\": 8764.727, \"total_train_time_s\": 10.50945258140564}", "{\"n\": 10496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.35, \"learn_time_ms\": 8509.844, \"total_train_time_s\": 9.259555101394653}", "{\"n\": 10497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.22, \"learn_time_ms\": 8430.326, \"total_train_time_s\": 8.815634727478027}", "{\"n\": 10498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.22, \"learn_time_ms\": 8448.561, \"total_train_time_s\": 11.120110511779785}", "{\"n\": 10499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.61, \"learn_time_ms\": 8219.723, \"total_train_time_s\": 8.491888284683228}", "{\"n\": 10500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.61, \"learn_time_ms\": 8381.466, \"total_train_time_s\": 10.138142347335815}", "{\"n\": 10501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.41, \"learn_time_ms\": 8463.788, \"total_train_time_s\": 11.067540884017944}", "{\"n\": 10502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.2, \"learn_time_ms\": 8411.725, \"total_train_time_s\": 9.44690728187561}", "{\"n\": 10503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.07, \"learn_time_ms\": 8331.512, \"total_train_time_s\": 9.110279321670532}", "{\"n\": 10504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.09, \"learn_time_ms\": 8465.07, \"total_train_time_s\": 10.810391664505005}", "{\"n\": 10505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.47, \"learn_time_ms\": 8521.219, \"total_train_time_s\": 11.119274616241455}", "{\"n\": 10506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.47, \"learn_time_ms\": 8537.217, \"total_train_time_s\": 9.386055707931519}", "{\"n\": 10507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.41, \"learn_time_ms\": 8595.631, \"total_train_time_s\": 9.385343790054321}", "{\"n\": 10508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.41, \"learn_time_ms\": 8551.984, \"total_train_time_s\": 10.66041374206543}", "{\"n\": 10509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.38, \"learn_time_ms\": 8808.801, \"total_train_time_s\": 11.071645021438599}", "{\"n\": 10510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.77, \"learn_time_ms\": 8852.443, \"total_train_time_s\": 10.642473697662354}", "{\"n\": 10511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.62, \"learn_time_ms\": 8776.44, \"total_train_time_s\": 10.239983081817627}", "{\"n\": 10512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.09, \"learn_time_ms\": 8994.01, \"total_train_time_s\": 11.619859457015991}", "{\"n\": 10513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.58, \"learn_time_ms\": 9084.385, \"total_train_time_s\": 10.004612922668457}", "{\"n\": 10514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.31, \"learn_time_ms\": 9070.291, \"total_train_time_s\": 10.742212772369385}", "{\"n\": 10515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.31, \"learn_time_ms\": 8868.286, \"total_train_time_s\": 9.083265542984009}", "{\"n\": 10516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.24, \"learn_time_ms\": 8993.808, \"total_train_time_s\": 10.629880905151367}", "{\"n\": 10517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.91, \"learn_time_ms\": 9173.508, \"total_train_time_s\": 11.194832563400269}", "{\"n\": 10518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.41, \"learn_time_ms\": 9120.056, \"total_train_time_s\": 10.11498475074768}", "{\"n\": 10519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.93, \"learn_time_ms\": 8843.863, \"total_train_time_s\": 8.220791816711426}", "{\"n\": 10520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.2, \"learn_time_ms\": 8979.751, \"total_train_time_s\": 11.927197456359863}", "{\"n\": 10521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.62, \"learn_time_ms\": 8918.681, \"total_train_time_s\": 9.62227463722229}", "{\"n\": 10522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.62, \"learn_time_ms\": 8719.021, \"total_train_time_s\": 9.672035932540894}", "{\"n\": 10523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.91, \"learn_time_ms\": 8692.756, \"total_train_time_s\": 9.74845838546753}", "{\"n\": 10524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.26, \"learn_time_ms\": 8641.894, \"total_train_time_s\": 10.205277681350708}", "{\"n\": 10525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.26, \"learn_time_ms\": 8691.979, \"total_train_time_s\": 9.597226858139038}", "{\"n\": 10526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.05, \"learn_time_ms\": 8630.332, \"total_train_time_s\": 10.036789894104004}", "{\"n\": 10527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 8487.54, \"total_train_time_s\": 9.734319686889648}", "{\"n\": 10528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 8442.861, \"total_train_time_s\": 9.668100357055664}", "{\"n\": 10529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.85, \"learn_time_ms\": 8543.492, \"total_train_time_s\": 9.263100862503052}", "{\"n\": 10530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.02, \"learn_time_ms\": 8264.429, \"total_train_time_s\": 9.183685064315796}", "{\"n\": 10531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.52, \"learn_time_ms\": 8327.649, \"total_train_time_s\": 10.249658823013306}", "{\"n\": 10532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.57, \"learn_time_ms\": 8347.247, \"total_train_time_s\": 9.826646089553833}", "{\"n\": 10533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.57, \"learn_time_ms\": 8279.516, \"total_train_time_s\": 9.07838773727417}", "{\"n\": 10534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.7, \"learn_time_ms\": 8361.382, \"total_train_time_s\": 10.980613946914673}", "{\"n\": 10535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.76, \"learn_time_ms\": 8388.917, \"total_train_time_s\": 9.889501571655273}", "{\"n\": 10536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.25, \"learn_time_ms\": 8279.44, \"total_train_time_s\": 8.9827401638031}", "{\"n\": 10537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.08, \"learn_time_ms\": 8277.682, \"total_train_time_s\": 9.698254108428955}", "{\"n\": 10538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.08, \"learn_time_ms\": 8155.004, \"total_train_time_s\": 8.429074048995972}", "{\"n\": 10539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.61, \"learn_time_ms\": 8175.913, \"total_train_time_s\": 9.478580951690674}", "{\"n\": 10540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.61, \"learn_time_ms\": 8146.145, \"total_train_time_s\": 8.816660404205322}", "{\"n\": 10541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.1, \"learn_time_ms\": 8001.336, \"total_train_time_s\": 8.810113668441772}", "{\"n\": 10542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.85, \"learn_time_ms\": 8070.587, \"total_train_time_s\": 10.570412158966064}", "{\"n\": 10543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.36, \"learn_time_ms\": 8052.347, \"total_train_time_s\": 8.900084495544434}", "{\"n\": 10544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.09, \"learn_time_ms\": 7912.631, \"total_train_time_s\": 9.603444576263428}", "{\"n\": 10545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.56, \"learn_time_ms\": 8008.083, \"total_train_time_s\": 10.839670419692993}", "{\"n\": 10546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.36, \"learn_time_ms\": 8247.736, \"total_train_time_s\": 11.341195583343506}", "{\"n\": 10547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.27, \"learn_time_ms\": 8179.962, \"total_train_time_s\": 9.011228561401367}", "{\"n\": 10548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.41, \"learn_time_ms\": 8397.918, \"total_train_time_s\": 10.634647607803345}", "{\"n\": 10549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.94, \"learn_time_ms\": 8634.247, \"total_train_time_s\": 11.820863246917725}", "{\"n\": 10550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.94, \"learn_time_ms\": 8773.029, \"total_train_time_s\": 10.175313234329224}", "{\"n\": 10551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.01, \"learn_time_ms\": 8868.076, \"total_train_time_s\": 9.799567461013794}", "{\"n\": 10552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.4, \"learn_time_ms\": 8814.157, \"total_train_time_s\": 9.997500658035278}", "{\"n\": 10553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 8917.614, \"total_train_time_s\": 9.96230173110962}", "{\"n\": 10554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.6, \"learn_time_ms\": 8809.666, \"total_train_time_s\": 8.534410238265991}", "{\"n\": 10555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.6, \"learn_time_ms\": 8955.087, \"total_train_time_s\": 12.286683559417725}", "{\"n\": 10556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.9, \"learn_time_ms\": 8717.897, \"total_train_time_s\": 8.968599319458008}", "{\"n\": 10557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.17, \"learn_time_ms\": 8805.918, \"total_train_time_s\": 9.911725044250488}", "{\"n\": 10558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.48, \"learn_time_ms\": 8597.934, \"total_train_time_s\": 8.598026037216187}", "{\"n\": 10559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.66, \"learn_time_ms\": 8283.042, \"total_train_time_s\": 8.689701795578003}", "{\"n\": 10560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.66, \"learn_time_ms\": 8247.443, \"total_train_time_s\": 9.859354019165039}", "{\"n\": 10561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.09, \"learn_time_ms\": 8250.347, \"total_train_time_s\": 9.802010297775269}", "{\"n\": 10562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.44, \"learn_time_ms\": 8134.841, \"total_train_time_s\": 8.818953514099121}", "{\"n\": 10563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 8179.255, \"total_train_time_s\": 10.362670660018921}", "{\"n\": 10564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.03, \"learn_time_ms\": 8325.267, \"total_train_time_s\": 9.946834802627563}", "{\"n\": 10565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.03, \"learn_time_ms\": 8187.165, \"total_train_time_s\": 10.868123531341553}", "{\"n\": 10566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.04, \"learn_time_ms\": 8285.073, \"total_train_time_s\": 9.91157054901123}", "{\"n\": 10567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.51, \"learn_time_ms\": 8147.633, \"total_train_time_s\": 8.516393184661865}", "{\"n\": 10568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.86, \"learn_time_ms\": 8222.612, \"total_train_time_s\": 9.315521717071533}", "{\"n\": 10569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.69, \"learn_time_ms\": 8209.664, \"total_train_time_s\": 8.56507158279419}", "{\"n\": 10570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.99, \"learn_time_ms\": 8243.582, \"total_train_time_s\": 10.205511331558228}", "{\"n\": 10571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.71, \"learn_time_ms\": 8252.98, \"total_train_time_s\": 9.913589000701904}", "{\"n\": 10572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.08, \"learn_time_ms\": 8353.062, \"total_train_time_s\": 9.825408458709717}", "{\"n\": 10573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.69, \"learn_time_ms\": 8489.197, \"total_train_time_s\": 11.732027292251587}", "{\"n\": 10574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.38, \"learn_time_ms\": 8680.25, \"total_train_time_s\": 11.876909017562866}", "{\"n\": 10575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.74, \"learn_time_ms\": 8684.939, \"total_train_time_s\": 10.964946269989014}", "{\"n\": 10576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.74, \"learn_time_ms\": 8643.608, \"total_train_time_s\": 9.536121129989624}", "{\"n\": 10577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.36, \"learn_time_ms\": 8667.945, \"total_train_time_s\": 8.78516674041748}", "{\"n\": 10578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.54, \"learn_time_ms\": 8830.089, \"total_train_time_s\": 10.973448514938354}", "{\"n\": 10579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.54, \"learn_time_ms\": 8969.372, \"total_train_time_s\": 9.968989610671997}", "{\"n\": 10580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.78, \"learn_time_ms\": 8949.93, \"total_train_time_s\": 10.080492496490479}", "{\"n\": 10581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.24, \"learn_time_ms\": 9122.522, \"total_train_time_s\": 11.641723394393921}", "{\"n\": 10582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.24, \"learn_time_ms\": 9072.308, \"total_train_time_s\": 9.368553400039673}", "{\"n\": 10583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.82, \"learn_time_ms\": 8911.077, \"total_train_time_s\": 10.120596170425415}", "{\"n\": 10584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.84, \"learn_time_ms\": 8598.027, \"total_train_time_s\": 8.733265399932861}", "{\"n\": 10585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.53, \"learn_time_ms\": 8315.498, \"total_train_time_s\": 8.125524520874023}", "{\"n\": 10586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.71, \"learn_time_ms\": 8389.69, \"total_train_time_s\": 10.274095296859741}", "{\"n\": 10587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.07, \"learn_time_ms\": 8486.74, \"total_train_time_s\": 9.777800559997559}", "{\"n\": 10588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.01, \"learn_time_ms\": 8254.248, \"total_train_time_s\": 8.618672132492065}", "{\"n\": 10589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.01, \"learn_time_ms\": 8159.544, \"total_train_time_s\": 8.964368343353271}", "{\"n\": 10590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.36, \"learn_time_ms\": 8086.86, \"total_train_time_s\": 9.281420469284058}", "{\"n\": 10591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 7843.92, \"total_train_time_s\": 9.248657941818237}", "{\"n\": 10592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8020.582, \"total_train_time_s\": 11.097311735153198}", "{\"n\": 10593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.47, \"learn_time_ms\": 8057.663, \"total_train_time_s\": 10.520772933959961}", "{\"n\": 10594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.85, \"learn_time_ms\": 8034.454, \"total_train_time_s\": 8.564964771270752}", "{\"n\": 10595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.85, \"learn_time_ms\": 8121.658, \"total_train_time_s\": 9.01674199104309}", "{\"n\": 10596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.38, \"learn_time_ms\": 8012.176, \"total_train_time_s\": 9.199657678604126}", "{\"n\": 10597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.26, \"learn_time_ms\": 8027.403, \"total_train_time_s\": 9.902061223983765}", "{\"n\": 10598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 8196.119, \"total_train_time_s\": 10.332420587539673}", "{\"n\": 10599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 8221.215, \"total_train_time_s\": 9.268735408782959}", "{\"n\": 10600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.91, \"learn_time_ms\": 8337.44, \"total_train_time_s\": 10.423728704452515}", "{\"n\": 10601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 8485.359, \"total_train_time_s\": 10.706854581832886}", "{\"n\": 10602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 8358.593, \"total_train_time_s\": 9.828221321105957}", "{\"n\": 10603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 8308.91, \"total_train_time_s\": 10.001996040344238}", "{\"n\": 10604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8344.055, \"total_train_time_s\": 8.925961971282959}", "{\"n\": 10605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8518.905, \"total_train_time_s\": 10.772347688674927}", "{\"n\": 10606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.15, \"learn_time_ms\": 8622.581, \"total_train_time_s\": 10.198926448822021}", "{\"n\": 10607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.15, \"learn_time_ms\": 8641.784, \"total_train_time_s\": 10.156490325927734}", "{\"n\": 10608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.86, \"learn_time_ms\": 8647.414, \"total_train_time_s\": 10.348814964294434}", "{\"n\": 10609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.07, \"learn_time_ms\": 8665.705, \"total_train_time_s\": 9.430206060409546}", "{\"n\": 10610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.07, \"learn_time_ms\": 8465.053, \"total_train_time_s\": 8.452214241027832}", "{\"n\": 10611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.32, \"learn_time_ms\": 8395.236, \"total_train_time_s\": 9.9766526222229}", "{\"n\": 10612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.32, \"learn_time_ms\": 8505.948, \"total_train_time_s\": 10.935293912887573}", "{\"n\": 10613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.84, \"learn_time_ms\": 8389.705, \"total_train_time_s\": 8.811383962631226}", "{\"n\": 10614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.43, \"learn_time_ms\": 8427.688, \"total_train_time_s\": 9.283040761947632}", "{\"n\": 10615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 8260.882, \"total_train_time_s\": 9.060077428817749}", "{\"n\": 10616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.42, \"learn_time_ms\": 8140.502, \"total_train_time_s\": 9.00455117225647}", "{\"n\": 10617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.47, \"learn_time_ms\": 8117.653, \"total_train_time_s\": 9.861911535263062}", "{\"n\": 10618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.5, \"learn_time_ms\": 8108.256, \"total_train_time_s\": 10.271799087524414}", "{\"n\": 10619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.82, \"learn_time_ms\": 8246.382, \"total_train_time_s\": 10.842864513397217}", "{\"n\": 10620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.82, \"learn_time_ms\": 8449.748, \"total_train_time_s\": 10.4253830909729}", "{\"n\": 10621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.09, \"learn_time_ms\": 8349.938, \"total_train_time_s\": 8.991831064224243}", "{\"n\": 10622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.51, \"learn_time_ms\": 8200.065, \"total_train_time_s\": 9.482210159301758}", "{\"n\": 10623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.51, \"learn_time_ms\": 8325.021, \"total_train_time_s\": 10.101149320602417}", "{\"n\": 10624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.47, \"learn_time_ms\": 8396.943, \"total_train_time_s\": 9.936410903930664}", "{\"n\": 10625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.39, \"learn_time_ms\": 8515.104, \"total_train_time_s\": 10.311473608016968}", "{\"n\": 10626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.39, \"learn_time_ms\": 8703.327, \"total_train_time_s\": 10.916346073150635}", "{\"n\": 10627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.39, \"learn_time_ms\": 8536.383, \"total_train_time_s\": 8.212790250778198}", "{\"n\": 10628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.86, \"learn_time_ms\": 8514.046, \"total_train_time_s\": 10.02219557762146}", "{\"n\": 10629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.89, \"learn_time_ms\": 8455.852, \"total_train_time_s\": 10.185324907302856}", "{\"n\": 10630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.89, \"learn_time_ms\": 8340.091, \"total_train_time_s\": 9.34277868270874}", "{\"n\": 10631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.89, \"learn_time_ms\": 8392.92, \"total_train_time_s\": 9.491143941879272}", "{\"n\": 10632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.88, \"learn_time_ms\": 8396.827, \"total_train_time_s\": 9.481103897094727}", "{\"n\": 10633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.88, \"learn_time_ms\": 8398.358, \"total_train_time_s\": 10.101169109344482}", "{\"n\": 10634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.88, \"learn_time_ms\": 8430.644, \"total_train_time_s\": 10.301209926605225}", "{\"n\": 10635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.88, \"learn_time_ms\": 8503.411, \"total_train_time_s\": 11.032776832580566}", "{\"n\": 10636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.88, \"learn_time_ms\": 8365.863, \"total_train_time_s\": 9.531872749328613}", "{\"n\": 10637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.88, \"learn_time_ms\": 8574.964, \"total_train_time_s\": 10.260586738586426}", "{\"n\": 10638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.63, \"learn_time_ms\": 8577.031, \"total_train_time_s\": 10.052311658859253}", "{\"n\": 10639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.87, \"learn_time_ms\": 8539.703, \"total_train_time_s\": 9.8519127368927}", "{\"n\": 10640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.87, \"learn_time_ms\": 8765.061, \"total_train_time_s\": 11.577940225601196}", "{\"n\": 10641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.06, \"learn_time_ms\": 8792.507, \"total_train_time_s\": 9.764968872070312}", "{\"n\": 10642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.06, \"learn_time_ms\": 8802.895, \"total_train_time_s\": 9.587246656417847}", "{\"n\": 10643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.06, \"learn_time_ms\": 8828.741, \"total_train_time_s\": 10.32373332977295}", "{\"n\": 10644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.18, \"learn_time_ms\": 8694.064, \"total_train_time_s\": 8.937268495559692}", "{\"n\": 10645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8524.887, \"total_train_time_s\": 9.344584941864014}", "{\"n\": 10646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8530.121, \"total_train_time_s\": 9.54229211807251}", "{\"n\": 10647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8497.069, \"total_train_time_s\": 9.966052770614624}", "{\"n\": 10648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.31, \"learn_time_ms\": 8473.313, \"total_train_time_s\": 9.813257455825806}", "{\"n\": 10649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8465.041, \"total_train_time_s\": 9.76134991645813}", "{\"n\": 10650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8323.169, \"total_train_time_s\": 10.099096775054932}", "{\"n\": 10651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.85, \"learn_time_ms\": 8438.695, \"total_train_time_s\": 10.968474388122559}", "{\"n\": 10652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.35, \"learn_time_ms\": 8376.279, \"total_train_time_s\": 8.992224931716919}", "{\"n\": 10653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.35, \"learn_time_ms\": 8442.072, \"total_train_time_s\": 11.046545267105103}", "{\"n\": 10654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.83, \"learn_time_ms\": 8579.815, \"total_train_time_s\": 10.354838848114014}", "{\"n\": 10655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.22, \"learn_time_ms\": 8712.169, \"total_train_time_s\": 10.63503384590149}", "{\"n\": 10656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.22, \"learn_time_ms\": 8678.006, \"total_train_time_s\": 9.187723159790039}", "{\"n\": 10657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.8, \"learn_time_ms\": 8608.576, \"total_train_time_s\": 9.292092561721802}", "{\"n\": 10658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.93, \"learn_time_ms\": 8547.099, \"total_train_time_s\": 9.18865704536438}", "{\"n\": 10659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.93, \"learn_time_ms\": 8429.423, \"total_train_time_s\": 8.594571352005005}", "{\"n\": 10660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.51, \"learn_time_ms\": 8559.561, \"total_train_time_s\": 11.42084527015686}", "{\"n\": 10661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.48, \"learn_time_ms\": 8470.88, \"total_train_time_s\": 10.102768898010254}", "{\"n\": 10662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.74, \"learn_time_ms\": 8604.172, \"total_train_time_s\": 10.304250001907349}", "{\"n\": 10663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.74, \"learn_time_ms\": 8538.898, \"total_train_time_s\": 10.328634977340698}", "{\"n\": 10664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.13, \"learn_time_ms\": 8584.546, \"total_train_time_s\": 10.792602062225342}", "{\"n\": 10665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.32, \"learn_time_ms\": 8588.79, \"total_train_time_s\": 10.674265623092651}", "{\"n\": 10666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.32, \"learn_time_ms\": 8763.118, \"total_train_time_s\": 10.996455907821655}", "{\"n\": 10667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.73, \"learn_time_ms\": 8998.994, \"total_train_time_s\": 11.627272605895996}", "{\"n\": 10668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.62, \"learn_time_ms\": 9087.172, \"total_train_time_s\": 10.093413352966309}", "{\"n\": 10669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.94, \"learn_time_ms\": 9344.489, \"total_train_time_s\": 11.178349494934082}", "{\"n\": 10670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.94, \"learn_time_ms\": 9195.246, \"total_train_time_s\": 10.000096321105957}", "{\"n\": 10671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.42, \"learn_time_ms\": 9308.282, \"total_train_time_s\": 11.23036527633667}", "{\"n\": 10672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.54, \"learn_time_ms\": 9207.742, \"total_train_time_s\": 9.288828372955322}", "{\"n\": 10673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.54, \"learn_time_ms\": 9299.734, \"total_train_time_s\": 11.290765047073364}", "{\"n\": 10674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.67, \"learn_time_ms\": 9264.957, \"total_train_time_s\": 10.460158824920654}", "{\"n\": 10675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.35, \"learn_time_ms\": 9318.16, \"total_train_time_s\": 11.198168754577637}", "{\"n\": 10676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.35, \"learn_time_ms\": 9284.399, \"total_train_time_s\": 10.635632276535034}", "{\"n\": 10677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.61, \"learn_time_ms\": 9105.5, \"total_train_time_s\": 9.871953964233398}", "{\"n\": 10678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.69, \"learn_time_ms\": 9068.131, \"total_train_time_s\": 9.714684009552002}", "{\"n\": 10679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.75, \"learn_time_ms\": 8973.487, \"total_train_time_s\": 10.208534955978394}", "{\"n\": 10680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.75, \"learn_time_ms\": 8974.751, \"total_train_time_s\": 10.004318475723267}", "{\"n\": 10681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.74, \"learn_time_ms\": 8763.617, \"total_train_time_s\": 9.154991388320923}", "{\"n\": 10682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.87, \"learn_time_ms\": 8825.146, \"total_train_time_s\": 9.907984495162964}", "{\"n\": 10683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.87, \"learn_time_ms\": 8802.984, \"total_train_time_s\": 11.08667778968811}", "{\"n\": 10684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.1, \"learn_time_ms\": 8621.145, \"total_train_time_s\": 8.697810173034668}", "{\"n\": 10685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.33, \"learn_time_ms\": 8327.793, \"total_train_time_s\": 8.321158647537231}", "{\"n\": 10686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.33, \"learn_time_ms\": 8348.561, \"total_train_time_s\": 10.868812084197998}", "{\"n\": 10687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.36, \"learn_time_ms\": 8366.861, \"total_train_time_s\": 10.031723499298096}", "{\"n\": 10688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8363.195, \"total_train_time_s\": 9.686866998672485}", "{\"n\": 10689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8330.385, \"total_train_time_s\": 9.934309720993042}", "{\"n\": 10690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8363.007, \"total_train_time_s\": 10.309383630752563}", "{\"n\": 10691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.29, \"learn_time_ms\": 8512.857, \"total_train_time_s\": 10.595052242279053}", "{\"n\": 10692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.29, \"learn_time_ms\": 8641.815, \"total_train_time_s\": 11.178705930709839}", "{\"n\": 10693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.29, \"learn_time_ms\": 8447.657, \"total_train_time_s\": 9.122038841247559}", "{\"n\": 10694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.29, \"learn_time_ms\": 8661.057, \"total_train_time_s\": 10.767536401748657}", "{\"n\": 10695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.29, \"learn_time_ms\": 8777.715, \"total_train_time_s\": 9.401536703109741}", "{\"n\": 10696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.29, \"learn_time_ms\": 8686.124, \"total_train_time_s\": 9.913450479507446}", "{\"n\": 10697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.48, \"learn_time_ms\": 8779.141, \"total_train_time_s\": 10.99342393875122}", "{\"n\": 10698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.69, \"learn_time_ms\": 8720.867, \"total_train_time_s\": 9.10590124130249}", "{\"n\": 10699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.69, \"learn_time_ms\": 8807.669, \"total_train_time_s\": 10.737429141998291}", "{\"n\": 10700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.17, \"learn_time_ms\": 8846.092, \"total_train_time_s\": 10.661069869995117}", "{\"n\": 10701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.32, \"learn_time_ms\": 8852.934, \"total_train_time_s\": 10.64822006225586}", "{\"n\": 10702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.88, \"learn_time_ms\": 8848.553, \"total_train_time_s\": 11.108271360397339}", "{\"n\": 10703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.09, \"learn_time_ms\": 8942.859, \"total_train_time_s\": 10.032625913619995}", "{\"n\": 10704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.05, \"learn_time_ms\": 8815.081, \"total_train_time_s\": 9.504488468170166}", "{\"n\": 10705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.33, \"learn_time_ms\": 9041.598, \"total_train_time_s\": 11.731625080108643}", "{\"n\": 10706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.31, \"learn_time_ms\": 9026.603, \"total_train_time_s\": 9.746152400970459}", "{\"n\": 10707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.74, \"learn_time_ms\": 8916.847, \"total_train_time_s\": 9.900543928146362}", "{\"n\": 10708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.73, \"learn_time_ms\": 9172.662, \"total_train_time_s\": 11.634657621383667}", "{\"n\": 10709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.81, \"learn_time_ms\": 9097.483, \"total_train_time_s\": 10.02769923210144}", "{\"n\": 10710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.81, \"learn_time_ms\": 9026.889, \"total_train_time_s\": 9.923295021057129}", "{\"n\": 10711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.49, \"learn_time_ms\": 9056.455, \"total_train_time_s\": 10.915719270706177}", "{\"n\": 10712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.19, \"learn_time_ms\": 8802.74, \"total_train_time_s\": 8.61389946937561}", "{\"n\": 10713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.19, \"learn_time_ms\": 8677.255, \"total_train_time_s\": 8.79420804977417}", "{\"n\": 10714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.66, \"learn_time_ms\": 8632.803, \"total_train_time_s\": 9.039758682250977}", "{\"n\": 10715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.51, \"learn_time_ms\": 8412.934, \"total_train_time_s\": 9.449651956558228}", "{\"n\": 10716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.58, \"learn_time_ms\": 8362.058, \"total_train_time_s\": 9.236580610275269}", "{\"n\": 10717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.05, \"learn_time_ms\": 8465.994, \"total_train_time_s\": 10.866639375686646}", "{\"n\": 10718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.85, \"learn_time_ms\": 8320.893, \"total_train_time_s\": 10.163897037506104}", "{\"n\": 10719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.12, \"learn_time_ms\": 8355.824, \"total_train_time_s\": 10.373551607131958}", "{\"n\": 10720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.12, \"learn_time_ms\": 8337.835, \"total_train_time_s\": 9.79273533821106}", "{\"n\": 10721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.37, \"learn_time_ms\": 8267.084, \"total_train_time_s\": 10.296732187271118}", "{\"n\": 10722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.71, \"learn_time_ms\": 8426.645, \"total_train_time_s\": 10.244718074798584}", "{\"n\": 10723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.71, \"learn_time_ms\": 8696.418, \"total_train_time_s\": 11.497972965240479}", "{\"n\": 10724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.64, \"learn_time_ms\": 8686.787, \"total_train_time_s\": 8.915249586105347}", "{\"n\": 10725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.42, \"learn_time_ms\": 8715.683, \"total_train_time_s\": 9.786781549453735}", "{\"n\": 10726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.42, \"learn_time_ms\": 8760.58, \"total_train_time_s\": 9.67633056640625}", "{\"n\": 10727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.22, \"learn_time_ms\": 8572.536, \"total_train_time_s\": 9.010765790939331}", "{\"n\": 10728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.2, \"learn_time_ms\": 8483.572, \"total_train_time_s\": 9.272946119308472}", "{\"n\": 10729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.02, \"learn_time_ms\": 8464.126, \"total_train_time_s\": 10.158276796340942}", "{\"n\": 10730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.56, \"learn_time_ms\": 8501.688, \"total_train_time_s\": 10.1561861038208}", "{\"n\": 10731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.31, \"learn_time_ms\": 8466.537, \"total_train_time_s\": 9.885993480682373}", "{\"n\": 10732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.9, \"learn_time_ms\": 8455.134, \"total_train_time_s\": 10.095040321350098}", "{\"n\": 10733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.67, \"learn_time_ms\": 8467.706, \"total_train_time_s\": 11.64423418045044}", "{\"n\": 10734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.67, \"learn_time_ms\": 8625.819, \"total_train_time_s\": 10.52463674545288}", "{\"n\": 10735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.01, \"learn_time_ms\": 8612.996, \"total_train_time_s\": 9.685201406478882}", "{\"n\": 10736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.69, \"learn_time_ms\": 8639.54, \"total_train_time_s\": 9.921367883682251}", "{\"n\": 10737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.69, \"learn_time_ms\": 8667.329, \"total_train_time_s\": 9.318125009536743}", "{\"n\": 10738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.52, \"learn_time_ms\": 8854.529, \"total_train_time_s\": 11.157642126083374}", "{\"n\": 10739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.85, \"learn_time_ms\": 8872.583, \"total_train_time_s\": 10.327908039093018}", "{\"n\": 10740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.32, \"learn_time_ms\": 8889.725, \"total_train_time_s\": 10.286343097686768}", "{\"n\": 10741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.51, \"learn_time_ms\": 8905.601, \"total_train_time_s\": 10.0208420753479}", "{\"n\": 10742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.53, \"learn_time_ms\": 8978.089, \"total_train_time_s\": 10.835566997528076}", "{\"n\": 10743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.7, \"learn_time_ms\": 8911.072, \"total_train_time_s\": 10.969854354858398}", "{\"n\": 10744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.7, \"learn_time_ms\": 8924.801, \"total_train_time_s\": 10.638975858688354}", "{\"n\": 10745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.37, \"learn_time_ms\": 8926.874, \"total_train_time_s\": 9.699233293533325}", "{\"n\": 10746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.04, \"learn_time_ms\": 8862.669, \"total_train_time_s\": 9.362396955490112}", "{\"n\": 10747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.04, \"learn_time_ms\": 9003.99, \"total_train_time_s\": 10.686511516571045}", "{\"n\": 10748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.32, \"learn_time_ms\": 8825.44, \"total_train_time_s\": 9.351563692092896}", "{\"n\": 10749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.26, \"learn_time_ms\": 8769.026, \"total_train_time_s\": 9.76789927482605}", "{\"n\": 10750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.26, \"learn_time_ms\": 8800.943, \"total_train_time_s\": 10.657305479049683}", "{\"n\": 10751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.31, \"learn_time_ms\": 8794.119, \"total_train_time_s\": 10.022430181503296}", "{\"n\": 10752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.76, \"learn_time_ms\": 8704.712, \"total_train_time_s\": 9.928719997406006}", "{\"n\": 10753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.65, \"learn_time_ms\": 8415.203, \"total_train_time_s\": 8.021299600601196}", "{\"n\": 10754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.65, \"learn_time_ms\": 8402.891, \"total_train_time_s\": 10.493390560150146}", "{\"n\": 10755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.99, \"learn_time_ms\": 8312.136, \"total_train_time_s\": 8.808058261871338}", "{\"n\": 10756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.49, \"learn_time_ms\": 8309.025, \"total_train_time_s\": 9.263738870620728}", "{\"n\": 10757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.49, \"learn_time_ms\": 8204.055, \"total_train_time_s\": 9.638407945632935}", "{\"n\": 10758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.46, \"learn_time_ms\": 8271.066, \"total_train_time_s\": 10.055957078933716}", "{\"n\": 10759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.78, \"learn_time_ms\": 8288.193, \"total_train_time_s\": 9.977137088775635}", "{\"n\": 10760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.78, \"learn_time_ms\": 8252.042, \"total_train_time_s\": 10.330377101898193}", "{\"n\": 10761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.62, \"learn_time_ms\": 8118.184, \"total_train_time_s\": 8.605235576629639}", "{\"n\": 10762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.64, \"learn_time_ms\": 8211.053, \"total_train_time_s\": 10.81583046913147}", "{\"n\": 10763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.23, \"learn_time_ms\": 8384.48, \"total_train_time_s\": 9.819560766220093}", "{\"n\": 10764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.23, \"learn_time_ms\": 8398.79, \"total_train_time_s\": 10.683278322219849}", "{\"n\": 10765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.07, \"learn_time_ms\": 8380.736, \"total_train_time_s\": 8.579715490341187}", "{\"n\": 10766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.79, \"learn_time_ms\": 8274.648, \"total_train_time_s\": 8.244944095611572}", "{\"n\": 10767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.97, \"learn_time_ms\": 8228.119, \"total_train_time_s\": 9.353458404541016}", "{\"n\": 10768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.8, \"learn_time_ms\": 8119.949, \"total_train_time_s\": 8.973843574523926}", "{\"n\": 10769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.71, \"learn_time_ms\": 8234.201, \"total_train_time_s\": 11.057771682739258}", "{\"n\": 10770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.35, \"learn_time_ms\": 8286.944, \"total_train_time_s\": 10.828092813491821}", "{\"n\": 10771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.35, \"learn_time_ms\": 8450.225, \"total_train_time_s\": 10.237208366394043}", "{\"n\": 10772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.79, \"learn_time_ms\": 8585.907, \"total_train_time_s\": 12.213993072509766}", "{\"n\": 10773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.79, \"learn_time_ms\": 8515.082, \"total_train_time_s\": 9.109365940093994}", "{\"n\": 10774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.13, \"learn_time_ms\": 8465.034, \"total_train_time_s\": 10.198134422302246}", "{\"n\": 10775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.89, \"learn_time_ms\": 8609.127, \"total_train_time_s\": 10.00765323638916}", "{\"n\": 10776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.01, \"learn_time_ms\": 8960.935, \"total_train_time_s\": 11.780112743377686}", "{\"n\": 10777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.46, \"learn_time_ms\": 9044.029, \"total_train_time_s\": 9.99942684173584}", "{\"n\": 10778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.66, \"learn_time_ms\": 9087.17, \"total_train_time_s\": 9.41677212715149}", "{\"n\": 10779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.05, \"learn_time_ms\": 9052.488, \"total_train_time_s\": 10.724351406097412}", "{\"n\": 10780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.05, \"learn_time_ms\": 8884.624, \"total_train_time_s\": 9.115583181381226}", "{\"n\": 10781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.15, \"learn_time_ms\": 8865.407, \"total_train_time_s\": 10.07822322845459}", "{\"n\": 10782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.66, \"learn_time_ms\": 8433.435, \"total_train_time_s\": 7.872730493545532}", "{\"n\": 10783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.25, \"learn_time_ms\": 8392.213, \"total_train_time_s\": 8.666448831558228}", "{\"n\": 10784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.43, \"learn_time_ms\": 8333.956, \"total_train_time_s\": 9.601490497589111}", "{\"n\": 10785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.35, \"learn_time_ms\": 8357.244, \"total_train_time_s\": 10.232090711593628}", "{\"n\": 10786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.77, \"learn_time_ms\": 8406.939, \"total_train_time_s\": 12.246228218078613}", "{\"n\": 10787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.77, \"learn_time_ms\": 8496.329, \"total_train_time_s\": 10.932119369506836}", "{\"n\": 10788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.8, \"learn_time_ms\": 8605.743, \"total_train_time_s\": 10.489545345306396}", "{\"n\": 10789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.04, \"learn_time_ms\": 8497.178, \"total_train_time_s\": 9.657373666763306}", "{\"n\": 10790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.04, \"learn_time_ms\": 8584.042, \"total_train_time_s\": 10.019284725189209}", "{\"n\": 10791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.13, \"learn_time_ms\": 8596.917, \"total_train_time_s\": 10.251721858978271}", "{\"n\": 10792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.66, \"learn_time_ms\": 8772.599, \"total_train_time_s\": 9.613168478012085}", "{\"n\": 10793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.48, \"learn_time_ms\": 8959.708, \"total_train_time_s\": 10.559172630310059}", "{\"n\": 10794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.43, \"learn_time_ms\": 9093.749, \"total_train_time_s\": 10.933876752853394}", "{\"n\": 10795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.81, \"learn_time_ms\": 9044.172, \"total_train_time_s\": 9.735200643539429}", "{\"n\": 10796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.96, \"learn_time_ms\": 8784.875, \"total_train_time_s\": 9.64655065536499}", "{\"n\": 10797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.21, \"learn_time_ms\": 8746.23, \"total_train_time_s\": 10.618507862091064}", "{\"n\": 10798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.39, \"learn_time_ms\": 8576.877, \"total_train_time_s\": 8.792262077331543}", "{\"n\": 10799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.37, \"learn_time_ms\": 8724.998, \"total_train_time_s\": 11.141152381896973}", "{\"n\": 10800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.33, \"learn_time_ms\": 8794.462, \"total_train_time_s\": 10.687788009643555}", "{\"n\": 10801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.02, \"learn_time_ms\": 8863.366, \"total_train_time_s\": 10.93691110610962}", "{\"n\": 10802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.94, \"learn_time_ms\": 8993.846, \"total_train_time_s\": 10.957150936126709}", "{\"n\": 10803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.53, \"learn_time_ms\": 8903.474, \"total_train_time_s\": 9.6451416015625}", "{\"n\": 10804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.6, \"learn_time_ms\": 8749.294, \"total_train_time_s\": 9.408015966415405}", "{\"n\": 10805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.41, \"learn_time_ms\": 8743.534, \"total_train_time_s\": 9.698889970779419}", "{\"n\": 10806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.37, \"learn_time_ms\": 8802.718, \"total_train_time_s\": 10.277623176574707}", "{\"n\": 10807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.41, \"learn_time_ms\": 8863.199, \"total_train_time_s\": 11.140384435653687}", "{\"n\": 10808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 8988.629, \"total_train_time_s\": 10.02348804473877}", "{\"n\": 10809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 8827.575, \"total_train_time_s\": 9.528448104858398}", "{\"n\": 10810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.21, \"learn_time_ms\": 8738.736, \"total_train_time_s\": 9.820581197738647}", "{\"n\": 10811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.38, \"learn_time_ms\": 8492.824, \"total_train_time_s\": 8.448546409606934}", "{\"n\": 10812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.66, \"learn_time_ms\": 8326.962, \"total_train_time_s\": 9.272611141204834}", "{\"n\": 10813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.27, \"learn_time_ms\": 8387.434, \"total_train_time_s\": 10.26866626739502}", "{\"n\": 10814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.73, \"learn_time_ms\": 8333.018, \"total_train_time_s\": 8.851885795593262}", "{\"n\": 10815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.82, \"learn_time_ms\": 8290.931, \"total_train_time_s\": 9.296305656433105}", "{\"n\": 10816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.74, \"learn_time_ms\": 8399.744, \"total_train_time_s\": 11.352340936660767}", "{\"n\": 10817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.74, \"learn_time_ms\": 8288.323, \"total_train_time_s\": 10.034020185470581}", "{\"n\": 10818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.45, \"learn_time_ms\": 8272.947, \"total_train_time_s\": 9.934729099273682}", "{\"n\": 10819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.72, \"learn_time_ms\": 8326.857, \"total_train_time_s\": 10.054372787475586}", "{\"n\": 10820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.44, \"learn_time_ms\": 8301.906, \"total_train_time_s\": 9.562967300415039}", "{\"n\": 10821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.17, \"learn_time_ms\": 8420.751, \"total_train_time_s\": 9.63446855545044}", "{\"n\": 10822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.91, \"learn_time_ms\": 8642.466, \"total_train_time_s\": 11.520249843597412}", "{\"n\": 10823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.27, \"learn_time_ms\": 8733.959, \"total_train_time_s\": 11.168132543563843}", "{\"n\": 10824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.28, \"learn_time_ms\": 8830.969, \"total_train_time_s\": 9.82081413269043}", "{\"n\": 10825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.07, \"learn_time_ms\": 8948.659, \"total_train_time_s\": 10.458711624145508}", "{\"n\": 10826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.07, \"learn_time_ms\": 8776.098, \"total_train_time_s\": 9.615080833435059}", "{\"n\": 10827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.55, \"learn_time_ms\": 8858.995, \"total_train_time_s\": 10.888349533081055}", "{\"n\": 10828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.3, \"learn_time_ms\": 8814.662, \"total_train_time_s\": 9.469282865524292}", "{\"n\": 10829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.46, \"learn_time_ms\": 8943.186, \"total_train_time_s\": 11.353883743286133}", "{\"n\": 10830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.34, \"learn_time_ms\": 9044.505, \"total_train_time_s\": 10.594289302825928}", "{\"n\": 10831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.44, \"learn_time_ms\": 9078.85, \"total_train_time_s\": 9.971028566360474}", "{\"n\": 10832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.73, \"learn_time_ms\": 8964.109, \"total_train_time_s\": 10.394791603088379}", "{\"n\": 10833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.73, \"learn_time_ms\": 8876.447, \"total_train_time_s\": 10.26726484298706}", "{\"n\": 10834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 8903.354, \"total_train_time_s\": 10.059444427490234}", "{\"n\": 10835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.87, \"learn_time_ms\": 8701.705, \"total_train_time_s\": 8.435235023498535}", "{\"n\": 10836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.2, \"learn_time_ms\": 8748.045, \"total_train_time_s\": 10.089693307876587}", "{\"n\": 10837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.2, \"learn_time_ms\": 8767.64, \"total_train_time_s\": 11.033437490463257}", "{\"n\": 10838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.83, \"learn_time_ms\": 8799.694, \"total_train_time_s\": 9.813075304031372}", "{\"n\": 10839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.47, \"learn_time_ms\": 8660.687, \"total_train_time_s\": 9.989506959915161}", "{\"n\": 10840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.47, \"learn_time_ms\": 8505.014, \"total_train_time_s\": 8.978599786758423}", "{\"n\": 10841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.69, \"learn_time_ms\": 8572.604, \"total_train_time_s\": 10.67298436164856}", "{\"n\": 10842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.69, \"learn_time_ms\": 8353.852, \"total_train_time_s\": 8.17049527168274}", "{\"n\": 10843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.0, \"learn_time_ms\": 8289.488, \"total_train_time_s\": 9.6764657497406}", "{\"n\": 10844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.09, \"learn_time_ms\": 8114.631, \"total_train_time_s\": 8.345612287521362}", "{\"n\": 10845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.09, \"learn_time_ms\": 8194.736, \"total_train_time_s\": 9.276284217834473}", "{\"n\": 10846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.85, \"learn_time_ms\": 8120.454, \"total_train_time_s\": 9.340847492218018}", "{\"n\": 10847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.32, \"learn_time_ms\": 8074.278, \"total_train_time_s\": 10.616937637329102}", "{\"n\": 10848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.76, \"learn_time_ms\": 8216.15, \"total_train_time_s\": 11.187465906143188}", "{\"n\": 10849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.69, \"learn_time_ms\": 8111.548, \"total_train_time_s\": 8.907793760299683}", "{\"n\": 10850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.35, \"learn_time_ms\": 8123.006, \"total_train_time_s\": 9.168474435806274}", "{\"n\": 10851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.91, \"learn_time_ms\": 7983.309, \"total_train_time_s\": 9.28237247467041}", "{\"n\": 10852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.83, \"learn_time_ms\": 8141.854, \"total_train_time_s\": 9.760019063949585}", "{\"n\": 10853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.09, \"learn_time_ms\": 8260.895, \"total_train_time_s\": 10.808606624603271}", "{\"n\": 10854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.77, \"learn_time_ms\": 8403.529, \"total_train_time_s\": 9.753636121749878}", "{\"n\": 10855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.39, \"learn_time_ms\": 8362.163, \"total_train_time_s\": 8.833858728408813}", "{\"n\": 10856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.67, \"learn_time_ms\": 8427.94, \"total_train_time_s\": 10.00997257232666}", "{\"n\": 10857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.36, \"learn_time_ms\": 8344.332, \"total_train_time_s\": 9.760099411010742}", "{\"n\": 10858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.62, \"learn_time_ms\": 8093.465, \"total_train_time_s\": 8.724884271621704}", "{\"n\": 10859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.61, \"learn_time_ms\": 8310.025, \"total_train_time_s\": 11.075562238693237}", "{\"n\": 10860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.16, \"learn_time_ms\": 8427.935, \"total_train_time_s\": 10.32601284980774}", "{\"n\": 10861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 8643.189, \"total_train_time_s\": 11.401057958602905}", "{\"n\": 10862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 8529.45, \"total_train_time_s\": 8.595673322677612}", "{\"n\": 10863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.93, \"learn_time_ms\": 8363.492, \"total_train_time_s\": 9.15161657333374}", "{\"n\": 10864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.22, \"learn_time_ms\": 8288.248, \"total_train_time_s\": 9.018673658370972}", "{\"n\": 10865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.22, \"learn_time_ms\": 8416.168, \"total_train_time_s\": 10.097755670547485}", "{\"n\": 10866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.49, \"learn_time_ms\": 8393.086, \"total_train_time_s\": 9.769750595092773}", "{\"n\": 10867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.81, \"learn_time_ms\": 8378.627, \"total_train_time_s\": 9.573264360427856}", "{\"n\": 10868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.95, \"learn_time_ms\": 8704.374, \"total_train_time_s\": 11.939329624176025}", "{\"n\": 10869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.95, \"learn_time_ms\": 8579.483, \"total_train_time_s\": 9.834587574005127}", "{\"n\": 10870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.88, \"learn_time_ms\": 8444.312, \"total_train_time_s\": 8.974260807037354}", "{\"n\": 10871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.88, \"learn_time_ms\": 8385.917, \"total_train_time_s\": 10.830136060714722}", "{\"n\": 10872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.88, \"learn_time_ms\": 8371.306, \"total_train_time_s\": 8.464731454849243}", "{\"n\": 10873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.28, \"learn_time_ms\": 8366.029, \"total_train_time_s\": 9.136806011199951}", "{\"n\": 10874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 8337.119, \"total_train_time_s\": 8.744407415390015}", "{\"n\": 10875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 8416.702, \"total_train_time_s\": 10.90540885925293}", "{\"n\": 10876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.87, \"learn_time_ms\": 8460.671, \"total_train_time_s\": 10.193073987960815}", "{\"n\": 10877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.12, \"learn_time_ms\": 8343.73, \"total_train_time_s\": 8.460496187210083}", "{\"n\": 10878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.76, \"learn_time_ms\": 8181.908, \"total_train_time_s\": 10.339177370071411}", "{\"n\": 10879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.06, \"learn_time_ms\": 8141.549, \"total_train_time_s\": 9.418745756149292}", "{\"n\": 10880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.27, \"learn_time_ms\": 8249.897, \"total_train_time_s\": 10.01654863357544}", "{\"n\": 10881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.42, \"learn_time_ms\": 8200.086, \"total_train_time_s\": 10.330525636672974}", "{\"n\": 10882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.78, \"learn_time_ms\": 8224.084, \"total_train_time_s\": 8.714543581008911}", "{\"n\": 10883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.78, \"learn_time_ms\": 8226.896, \"total_train_time_s\": 9.159971952438354}", "{\"n\": 10884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 8414.934, \"total_train_time_s\": 10.656577587127686}", "{\"n\": 10885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 8237.244, \"total_train_time_s\": 9.145729541778564}", "{\"n\": 10886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 8100.337, \"total_train_time_s\": 8.868980646133423}", "{\"n\": 10887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.06, \"learn_time_ms\": 8158.677, \"total_train_time_s\": 9.025616884231567}", "{\"n\": 10888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.82, \"learn_time_ms\": 8091.937, \"total_train_time_s\": 9.738715887069702}", "{\"n\": 10889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.68, \"learn_time_ms\": 8110.235, \"total_train_time_s\": 9.652024030685425}", "{\"n\": 10890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.68, \"learn_time_ms\": 8015.843, \"total_train_time_s\": 9.145792245864868}", "{\"n\": 10891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.83, \"learn_time_ms\": 7984.974, \"total_train_time_s\": 9.995491981506348}", "{\"n\": 10892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.81, \"learn_time_ms\": 8012.312, \"total_train_time_s\": 9.00937032699585}", "{\"n\": 10893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.81, \"learn_time_ms\": 8164.996, \"total_train_time_s\": 10.712591171264648}", "{\"n\": 10894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.55, \"learn_time_ms\": 8318.872, \"total_train_time_s\": 12.176621437072754}", "{\"n\": 10895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.55, \"learn_time_ms\": 8412.942, \"total_train_time_s\": 10.04194164276123}", "{\"n\": 10896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.88, \"learn_time_ms\": 8535.269, \"total_train_time_s\": 10.110156774520874}", "{\"n\": 10897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.53, \"learn_time_ms\": 8542.067, \"total_train_time_s\": 9.099033832550049}", "{\"n\": 10898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.54, \"learn_time_ms\": 8414.493, \"total_train_time_s\": 8.35242486000061}", "{\"n\": 10899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.57, \"learn_time_ms\": 8424.944, \"total_train_time_s\": 9.73705792427063}", "{\"n\": 10900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.16, \"learn_time_ms\": 8472.883, \"total_train_time_s\": 9.581485033035278}", "{\"n\": 10901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.93, \"learn_time_ms\": 8351.392, \"total_train_time_s\": 8.783931493759155}", "{\"n\": 10902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.04, \"learn_time_ms\": 8432.689, \"total_train_time_s\": 9.810518264770508}", "{\"n\": 10903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.04, \"learn_time_ms\": 8395.028, \"total_train_time_s\": 10.273722410202026}", "{\"n\": 10904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.6, \"learn_time_ms\": 8154.991, \"total_train_time_s\": 9.749839305877686}", "{\"n\": 10905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.7, \"learn_time_ms\": 8141.081, \"total_train_time_s\": 9.925933599472046}", "{\"n\": 10906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.04, \"learn_time_ms\": 8375.591, \"total_train_time_s\": 12.409930229187012}", "{\"n\": 10907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.35, \"learn_time_ms\": 8384.384, \"total_train_time_s\": 9.177841186523438}", "{\"n\": 10908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.13, \"learn_time_ms\": 8445.815, \"total_train_time_s\": 9.024360418319702}", "{\"n\": 10909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.63, \"learn_time_ms\": 8612.77, \"total_train_time_s\": 11.41890025138855}", "{\"n\": 10910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.63, \"learn_time_ms\": 8772.757, \"total_train_time_s\": 11.197116613388062}", "{\"n\": 10911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.29, \"learn_time_ms\": 8896.818, \"total_train_time_s\": 10.01478624343872}", "{\"n\": 10912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.61, \"learn_time_ms\": 9030.015, \"total_train_time_s\": 11.129544734954834}", "{\"n\": 10913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.61, \"learn_time_ms\": 9025.412, \"total_train_time_s\": 10.304075002670288}", "{\"n\": 10914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.39, \"learn_time_ms\": 9085.028, \"total_train_time_s\": 10.347198486328125}", "{\"n\": 10915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.1, \"learn_time_ms\": 9153.947, \"total_train_time_s\": 10.634129285812378}", "{\"n\": 10916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.1, \"learn_time_ms\": 8869.752, \"total_train_time_s\": 9.587888956069946}", "{\"n\": 10917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.24, \"learn_time_ms\": 8946.261, \"total_train_time_s\": 9.917399406433105}", "{\"n\": 10918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.8, \"learn_time_ms\": 9017.426, \"total_train_time_s\": 9.71661376953125}", "{\"n\": 10919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.23, \"learn_time_ms\": 8747.733, \"total_train_time_s\": 8.71086835861206}", "{\"n\": 10920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.23, \"learn_time_ms\": 8644.032, \"total_train_time_s\": 10.18072772026062}", "{\"n\": 10921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.2, \"learn_time_ms\": 8734.485, \"total_train_time_s\": 10.94576096534729}", "{\"n\": 10922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.9, \"learn_time_ms\": 8546.807, \"total_train_time_s\": 9.25654935836792}", "{\"n\": 10923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.9, \"learn_time_ms\": 8332.774, \"total_train_time_s\": 8.170434474945068}", "{\"n\": 10924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.02, \"learn_time_ms\": 8342.382, \"total_train_time_s\": 10.40686321258545}", "{\"n\": 10925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.65, \"learn_time_ms\": 8199.042, \"total_train_time_s\": 9.216177225112915}", "{\"n\": 10926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.65, \"learn_time_ms\": 8302.837, \"total_train_time_s\": 10.591061115264893}", "{\"n\": 10927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.72, \"learn_time_ms\": 8392.096, \"total_train_time_s\": 10.856369495391846}", "{\"n\": 10928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.16, \"learn_time_ms\": 8571.478, \"total_train_time_s\": 11.481709241867065}", "{\"n\": 10929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 8661.01, \"total_train_time_s\": 9.583153247833252}", "{\"n\": 10930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.42, \"learn_time_ms\": 8711.941, \"total_train_time_s\": 10.68898606300354}", "{\"n\": 10931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.35, \"learn_time_ms\": 8670.045, \"total_train_time_s\": 10.52786111831665}", "{\"n\": 10932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.48, \"learn_time_ms\": 8904.121, \"total_train_time_s\": 11.6243896484375}", "{\"n\": 10933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.26, \"learn_time_ms\": 9152.223, \"total_train_time_s\": 10.591131448745728}", "{\"n\": 10934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.63, \"learn_time_ms\": 9076.585, \"total_train_time_s\": 9.667603015899658}", "{\"n\": 10935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.63, \"learn_time_ms\": 9076.346, \"total_train_time_s\": 9.173409700393677}", "{\"n\": 10936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.81, \"learn_time_ms\": 8960.037, \"total_train_time_s\": 9.46240758895874}", "{\"n\": 10937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 8927.083, \"total_train_time_s\": 10.551420211791992}", "{\"n\": 10938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.62, \"learn_time_ms\": 8861.063, \"total_train_time_s\": 10.914858102798462}", "{\"n\": 10939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 9012.195, \"total_train_time_s\": 11.123143672943115}", "{\"n\": 10940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.56, \"learn_time_ms\": 8984.937, \"total_train_time_s\": 10.416611909866333}", "{\"n\": 10941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.41, \"learn_time_ms\": 8916.537, \"total_train_time_s\": 9.79861044883728}", "{\"n\": 10942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.78, \"learn_time_ms\": 8744.625, \"total_train_time_s\": 9.891395330429077}", "{\"n\": 10943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.89, \"learn_time_ms\": 8610.534, \"total_train_time_s\": 9.26397442817688}", "{\"n\": 10944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 8640.166, \"total_train_time_s\": 9.936980962753296}", "{\"n\": 10945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 8789.808, \"total_train_time_s\": 10.702907800674438}", "{\"n\": 10946, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.02, \"learn_time_ms\": 8884.567, \"total_train_time_s\": 10.437324523925781}", "{\"n\": 10947, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.67, \"learn_time_ms\": 8961.095, \"total_train_time_s\": 11.26821255683899}", "{\"n\": 10948, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.67, \"learn_time_ms\": 8863.766, \"total_train_time_s\": 9.86354374885559}", "{\"n\": 10949, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.38, \"learn_time_ms\": 8804.682, \"total_train_time_s\": 10.50963568687439}", "{\"n\": 10950, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.48, \"learn_time_ms\": 8801.67, \"total_train_time_s\": 10.386618375778198}", "{\"n\": 10951, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.81, \"learn_time_ms\": 8889.876, \"total_train_time_s\": 10.740233659744263}", "{\"n\": 10952, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.69, \"learn_time_ms\": 8929.334, \"total_train_time_s\": 10.291443586349487}", "{\"n\": 10953, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.84, \"learn_time_ms\": 9090.954, \"total_train_time_s\": 10.866736650466919}", "{\"n\": 10954, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.32, \"learn_time_ms\": 9101.675, \"total_train_time_s\": 10.083943605422974}", "{\"n\": 10955, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.32, \"learn_time_ms\": 9095.986, \"total_train_time_s\": 10.679797172546387}", "{\"n\": 10956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.78, \"learn_time_ms\": 9053.988, \"total_train_time_s\": 9.97738242149353}", "{\"n\": 10957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.14, \"learn_time_ms\": 8856.989, \"total_train_time_s\": 9.339118719100952}", "{\"n\": 10958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.14, \"learn_time_ms\": 8883.102, \"total_train_time_s\": 10.147907495498657}", "{\"n\": 10959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.99, \"learn_time_ms\": 8908.76, \"total_train_time_s\": 10.73082947731018}", "{\"n\": 10960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.24, \"learn_time_ms\": 8839.583, \"total_train_time_s\": 9.638150215148926}", "{\"n\": 10961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.9, \"learn_time_ms\": 8787.1, \"total_train_time_s\": 10.222150325775146}", "{\"n\": 10962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 8590.206, \"total_train_time_s\": 8.316183805465698}", "{\"n\": 10963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.67, \"learn_time_ms\": 8685.064, \"total_train_time_s\": 11.835734605789185}", "{\"n\": 10964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.79, \"learn_time_ms\": 8690.239, \"total_train_time_s\": 10.115255355834961}", "{\"n\": 10965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.79, \"learn_time_ms\": 8303.326, \"total_train_time_s\": 6.775010347366333}", "{\"n\": 10966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.95, \"learn_time_ms\": 7986.488, \"total_train_time_s\": 6.94597864151001}", "{\"n\": 10967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.21, \"learn_time_ms\": 8140.792, \"total_train_time_s\": 10.816673994064331}", "{\"n\": 10968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.22, \"learn_time_ms\": 8055.498, \"total_train_time_s\": 9.29303789138794}", "{\"n\": 10969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.55, \"learn_time_ms\": 7994.309, \"total_train_time_s\": 10.178104162216187}", "{\"n\": 10970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.55, \"learn_time_ms\": 8114.828, \"total_train_time_s\": 10.833778858184814}", "{\"n\": 10971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.09, \"learn_time_ms\": 8146.22, \"total_train_time_s\": 10.476609706878662}", "{\"n\": 10972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.98, \"learn_time_ms\": 8240.281, \"total_train_time_s\": 9.263788938522339}", "{\"n\": 10973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.44, \"learn_time_ms\": 8059.257, \"total_train_time_s\": 10.04513931274414}", "{\"n\": 10974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.95, \"learn_time_ms\": 8040.363, \"total_train_time_s\": 9.950507640838623}", "{\"n\": 10975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.65, \"learn_time_ms\": 8409.549, \"total_train_time_s\": 10.461331129074097}", "{\"n\": 10976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.66, \"learn_time_ms\": 8711.037, \"total_train_time_s\": 9.840556859970093}", "{\"n\": 10977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.4, \"learn_time_ms\": 8674.155, \"total_train_time_s\": 10.473158597946167}", "{\"n\": 10978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.36, \"learn_time_ms\": 8878.053, \"total_train_time_s\": 11.344952821731567}", "{\"n\": 10979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.36, \"learn_time_ms\": 8878.318, \"total_train_time_s\": 10.143316268920898}", "{\"n\": 10980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.42, \"learn_time_ms\": 8694.336, \"total_train_time_s\": 8.997925043106079}", "{\"n\": 10981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.47, \"learn_time_ms\": 8460.126, \"total_train_time_s\": 8.170087575912476}", "{\"n\": 10982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.05, \"learn_time_ms\": 8746.359, \"total_train_time_s\": 12.092240810394287}", "{\"n\": 10983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.95, \"learn_time_ms\": 8689.248, \"total_train_time_s\": 9.463355302810669}", "{\"n\": 10984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.82, \"learn_time_ms\": 8657.679, \"total_train_time_s\": 9.598904848098755}", "{\"n\": 10985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.39, \"learn_time_ms\": 8584.315, \"total_train_time_s\": 9.732157945632935}", "{\"n\": 10986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.58, \"learn_time_ms\": 8559.356, \"total_train_time_s\": 9.577329874038696}", "{\"n\": 10987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.61, \"learn_time_ms\": 8475.556, \"total_train_time_s\": 9.668308734893799}", "{\"n\": 10988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.04, \"learn_time_ms\": 8269.715, \"total_train_time_s\": 9.262109994888306}", "{\"n\": 10989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.29, \"learn_time_ms\": 8166.728, \"total_train_time_s\": 9.112506628036499}", "{\"n\": 10990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.73, \"learn_time_ms\": 8268.569, \"total_train_time_s\": 10.08571481704712}", "{\"n\": 10991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.73, \"learn_time_ms\": 8339.793, \"total_train_time_s\": 8.865686893463135}", "{\"n\": 10992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.53, \"learn_time_ms\": 8173.386, \"total_train_time_s\": 10.439504861831665}", "{\"n\": 10993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.29, \"learn_time_ms\": 8247.524, \"total_train_time_s\": 10.249344110488892}", "{\"n\": 10994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.29, \"learn_time_ms\": 8227.066, \"total_train_time_s\": 9.44143295288086}", "{\"n\": 10995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.58, \"learn_time_ms\": 8320.077, \"total_train_time_s\": 10.62704849243164}", "{\"n\": 10996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.68, \"learn_time_ms\": 8471.51, \"total_train_time_s\": 11.066614627838135}", "{\"n\": 10997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.42, \"learn_time_ms\": 8488.124, \"total_train_time_s\": 9.805363893508911}", "{\"n\": 10998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.42, \"learn_time_ms\": 8711.246, \"total_train_time_s\": 11.52394437789917}", "{\"n\": 10999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.27, \"learn_time_ms\": 8750.784, \"total_train_time_s\": 9.534867525100708}", "{\"n\": 11000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 8682.373, \"total_train_time_s\": 9.333570718765259}", "{\"n\": 11001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.73, \"learn_time_ms\": 8862.692, \"total_train_time_s\": 10.70907187461853}", "{\"n\": 11002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.27, \"learn_time_ms\": 8812.103, \"total_train_time_s\": 9.929141998291016}", "{\"n\": 11003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.92, \"learn_time_ms\": 8849.009, \"total_train_time_s\": 10.537904262542725}", "{\"n\": 11004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.88, \"learn_time_ms\": 8851.32, \"total_train_time_s\": 9.431068420410156}", "{\"n\": 11005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.46, \"learn_time_ms\": 8855.614, \"total_train_time_s\": 10.647885084152222}", "{\"n\": 11006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.27, \"learn_time_ms\": 8694.535, \"total_train_time_s\": 9.473904848098755}", "{\"n\": 11007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.19, \"learn_time_ms\": 8743.937, \"total_train_time_s\": 10.306262969970703}", "{\"n\": 11008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.19, \"learn_time_ms\": 8499.448, \"total_train_time_s\": 9.059744596481323}", "{\"n\": 11009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.28, \"learn_time_ms\": 8443.751, \"total_train_time_s\": 8.984745502471924}", "{\"n\": 11010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.13, \"learn_time_ms\": 8685.832, \"total_train_time_s\": 11.792912483215332}", "{\"n\": 11011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.76, \"learn_time_ms\": 8476.537, \"total_train_time_s\": 8.619161367416382}", "{\"n\": 11012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.42, \"learn_time_ms\": 8578.836, \"total_train_time_s\": 10.949449062347412}", "{\"n\": 11013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.44, \"learn_time_ms\": 8340.837, \"total_train_time_s\": 8.186828374862671}", "{\"n\": 11014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.34, \"learn_time_ms\": 8360.476, \"total_train_time_s\": 9.661788940429688}", "{\"n\": 11015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.34, \"learn_time_ms\": 8313.917, \"total_train_time_s\": 10.230166912078857}", "{\"n\": 11016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.81, \"learn_time_ms\": 8368.961, \"total_train_time_s\": 10.009756803512573}", "{\"n\": 11017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.67, \"learn_time_ms\": 8564.711, \"total_train_time_s\": 12.300262212753296}", "{\"n\": 11018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.77, \"learn_time_ms\": 8613.613, \"total_train_time_s\": 9.552393198013306}", "{\"n\": 11019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.45, \"learn_time_ms\": 8658.489, \"total_train_time_s\": 9.417664766311646}", "{\"n\": 11020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.28, \"learn_time_ms\": 8495.186, \"total_train_time_s\": 10.170112371444702}", "{\"n\": 11021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.74, \"learn_time_ms\": 8520.533, \"total_train_time_s\": 8.864968061447144}", "{\"n\": 11022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.72, \"learn_time_ms\": 8496.252, \"total_train_time_s\": 10.726499319076538}", "{\"n\": 11023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.72, \"learn_time_ms\": 8728.323, \"total_train_time_s\": 10.52393388748169}", "{\"n\": 11024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.8, \"learn_time_ms\": 8713.348, \"total_train_time_s\": 9.530441045761108}", "{\"n\": 11025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.44, \"learn_time_ms\": 8601.764, \"total_train_time_s\": 9.143269300460815}", "{\"n\": 11026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.05, \"learn_time_ms\": 8568.202, \"total_train_time_s\": 9.733904361724854}", "{\"n\": 11027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.35, \"learn_time_ms\": 8288.12, \"total_train_time_s\": 9.434267282485962}", "{\"n\": 11028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 8367.81, \"total_train_time_s\": 10.364391326904297}", "{\"n\": 11029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.36, \"learn_time_ms\": 8474.451, \"total_train_time_s\": 10.51780080795288}", "{\"n\": 11030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.19, \"learn_time_ms\": 8469.733, \"total_train_time_s\": 10.125882625579834}", "{\"n\": 11031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.15, \"learn_time_ms\": 8658.808, \"total_train_time_s\": 10.782358884811401}", "{\"n\": 11032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.93, \"learn_time_ms\": 8685.207, \"total_train_time_s\": 10.971569061279297}", "{\"n\": 11033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.93, \"learn_time_ms\": 8712.768, \"total_train_time_s\": 10.773394584655762}", "{\"n\": 11034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.96, \"learn_time_ms\": 8866.464, \"total_train_time_s\": 11.032028198242188}", "{\"n\": 11035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.15, \"learn_time_ms\": 9070.07, \"total_train_time_s\": 11.195485353469849}", "{\"n\": 11036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.15, \"learn_time_ms\": 9219.982, \"total_train_time_s\": 11.211180686950684}", "{\"n\": 11037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.0, \"learn_time_ms\": 9395.915, \"total_train_time_s\": 11.23383378982544}", "{\"n\": 11038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.79, \"learn_time_ms\": 9347.679, \"total_train_time_s\": 9.839191675186157}", "{\"n\": 11039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.79, \"learn_time_ms\": 9318.746, \"total_train_time_s\": 10.132546424865723}", "{\"n\": 11040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.79, \"learn_time_ms\": 9220.805, \"total_train_time_s\": 9.16559886932373}", "{\"n\": 11041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.69, \"learn_time_ms\": 9126.985, \"total_train_time_s\": 9.813110113143921}", "{\"n\": 11042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.17, \"learn_time_ms\": 8938.463, \"total_train_time_s\": 9.135350465774536}", "{\"n\": 11043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.17, \"learn_time_ms\": 9017.803, \"total_train_time_s\": 11.58513879776001}", "{\"n\": 11044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.87, \"learn_time_ms\": 8843.944, \"total_train_time_s\": 9.286939144134521}", "{\"n\": 11045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.6, \"learn_time_ms\": 8582.792, \"total_train_time_s\": 8.48939323425293}", "{\"n\": 11046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.16, \"learn_time_ms\": 8480.688, \"total_train_time_s\": 10.136896133422852}", "{\"n\": 11047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.07, \"learn_time_ms\": 8389.681, \"total_train_time_s\": 10.296440601348877}", "{\"n\": 11048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.01, \"learn_time_ms\": 8504.096, \"total_train_time_s\": 11.031545162200928}", "{\"n\": 11049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.15, \"learn_time_ms\": 8456.715, \"total_train_time_s\": 9.72805404663086}", "{\"n\": 11050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.15, \"learn_time_ms\": 8633.719, \"total_train_time_s\": 10.921117305755615}", "{\"n\": 11051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.21, \"learn_time_ms\": 8655.043, \"total_train_time_s\": 10.06722617149353}", "{\"n\": 11052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.11, \"learn_time_ms\": 8775.547, \"total_train_time_s\": 10.287151336669922}", "{\"n\": 11053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.54, \"learn_time_ms\": 8587.108, \"total_train_time_s\": 9.682669162750244}", "{\"n\": 11054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.08, \"learn_time_ms\": 8630.027, \"total_train_time_s\": 9.779480457305908}", "{\"n\": 11055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.81, \"learn_time_ms\": 8823.01, \"total_train_time_s\": 10.436986207962036}", "{\"n\": 11056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.81, \"learn_time_ms\": 8656.566, \"total_train_time_s\": 8.48160696029663}", "{\"n\": 11057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.51, \"learn_time_ms\": 8616.066, \"total_train_time_s\": 9.924890041351318}", "{\"n\": 11058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.43, \"learn_time_ms\": 8635.289, \"total_train_time_s\": 11.22668743133545}", "{\"n\": 11059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.43, \"learn_time_ms\": 8746.411, \"total_train_time_s\": 10.791701078414917}", "{\"n\": 11060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.92, \"learn_time_ms\": 8570.824, \"total_train_time_s\": 9.153956651687622}", "{\"n\": 11061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.55, \"learn_time_ms\": 8566.25, \"total_train_time_s\": 9.934240818023682}", "{\"n\": 11062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.59, \"learn_time_ms\": 8627.14, \"total_train_time_s\": 10.947115898132324}", "{\"n\": 11063, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.33, \"learn_time_ms\": 8613.607, \"total_train_time_s\": 9.509066581726074}", "{\"n\": 11064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.33, \"learn_time_ms\": 8629.73, \"total_train_time_s\": 9.846323728561401}", "{\"n\": 11065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.39, \"learn_time_ms\": 8440.563, \"total_train_time_s\": 8.593349933624268}", "{\"n\": 11066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.83, \"learn_time_ms\": 8706.13, \"total_train_time_s\": 11.196183681488037}", "{\"n\": 11067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.77, \"learn_time_ms\": 8615.781, \"total_train_time_s\": 9.112600088119507}", "{\"n\": 11068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.77, \"learn_time_ms\": 8540.055, \"total_train_time_s\": 10.396663904190063}", "{\"n\": 11069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.51, \"learn_time_ms\": 8455.28, \"total_train_time_s\": 9.975462913513184}", "{\"n\": 11070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.37, \"learn_time_ms\": 8371.513, \"total_train_time_s\": 8.284041404724121}", "{\"n\": 11071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.37, \"learn_time_ms\": 8483.404, \"total_train_time_s\": 11.126208305358887}", "{\"n\": 11072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.7, \"learn_time_ms\": 8393.318, \"total_train_time_s\": 10.00284719467163}", "{\"n\": 11073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.89, \"learn_time_ms\": 8414.493, \"total_train_time_s\": 9.724984884262085}", "{\"n\": 11074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.89, \"learn_time_ms\": 8495.446, \"total_train_time_s\": 10.693692445755005}", "{\"n\": 11075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.17, \"learn_time_ms\": 8703.82, \"total_train_time_s\": 10.639941453933716}", "{\"n\": 11076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.77, \"learn_time_ms\": 8525.42, \"total_train_time_s\": 9.373027324676514}", "{\"n\": 11077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.91, \"learn_time_ms\": 8703.864, \"total_train_time_s\": 10.790855169296265}", "{\"n\": 11078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3431.76, \"learn_time_ms\": 8648.998, \"total_train_time_s\": 9.863869428634644}", "{\"n\": 11079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3431.95, \"learn_time_ms\": 8723.457, \"total_train_time_s\": 10.732492208480835}", "{\"n\": 11080, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.7, \"learn_time_ms\": 8799.286, \"total_train_time_s\": 9.052293539047241}", "{\"n\": 11081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.7, \"learn_time_ms\": 8651.279, \"total_train_time_s\": 9.583495616912842}", "{\"n\": 11082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3439.08, \"learn_time_ms\": 8558.638, \"total_train_time_s\": 9.064271926879883}", "{\"n\": 11083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.23, \"learn_time_ms\": 8457.512, \"total_train_time_s\": 8.690515995025635}", "{\"n\": 11084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.23, \"learn_time_ms\": 8334.716, \"total_train_time_s\": 9.469138145446777}", "{\"n\": 11085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.42, \"learn_time_ms\": 8350.275, \"total_train_time_s\": 10.80302906036377}", "{\"n\": 11086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.86, \"learn_time_ms\": 8353.501, \"total_train_time_s\": 9.409347772598267}", "{\"n\": 11087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.83, \"learn_time_ms\": 8193.378, \"total_train_time_s\": 9.184469938278198}", "{\"n\": 11088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.94, \"learn_time_ms\": 8179.968, \"total_train_time_s\": 9.744244813919067}", "{\"n\": 11089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.23, \"learn_time_ms\": 8088.698, \"total_train_time_s\": 9.804497003555298}", "{\"n\": 11090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.93, \"learn_time_ms\": 8292.213, \"total_train_time_s\": 11.080261707305908}", "{\"n\": 11091, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.73, \"learn_time_ms\": 8277.253, \"total_train_time_s\": 9.486124038696289}", "{\"n\": 11092, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.78, \"learn_time_ms\": 8307.159, \"total_train_time_s\": 9.394665002822876}", "{\"n\": 11093, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.01, \"learn_time_ms\": 8394.436, \"total_train_time_s\": 9.62499737739563}", "{\"n\": 11094, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3439.03, \"learn_time_ms\": 8529.502, \"total_train_time_s\": 10.805884838104248}", "{\"n\": 11095, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3442.1, \"learn_time_ms\": 8320.713, \"total_train_time_s\": 8.747360467910767}", "{\"n\": 11096, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3446.65, \"learn_time_ms\": 8369.621, \"total_train_time_s\": 9.894603490829468}", "{\"n\": 11097, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.18, \"learn_time_ms\": 8363.121, \"total_train_time_s\": 9.119314432144165}", "{\"n\": 11098, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.78, \"learn_time_ms\": 8403.197, \"total_train_time_s\": 10.184885740280151}", "{\"n\": 11099, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.99, \"learn_time_ms\": 8446.053, \"total_train_time_s\": 10.21385145187378}", "{\"n\": 11100, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.89, \"learn_time_ms\": 8393.973, \"total_train_time_s\": 10.550040483474731}", "{\"n\": 11101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.75, \"learn_time_ms\": 8411.924, \"total_train_time_s\": 9.666684627532959}", "{\"n\": 11102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.75, \"learn_time_ms\": 8539.075, \"total_train_time_s\": 10.715690612792969}", "{\"n\": 11103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3439.83, \"learn_time_ms\": 8504.285, \"total_train_time_s\": 9.254379749298096}", "{\"n\": 11104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.05, \"learn_time_ms\": 8389.164, \"total_train_time_s\": 9.72333312034607}", "{\"n\": 11105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.22, \"learn_time_ms\": 8559.822, \"total_train_time_s\": 10.488214492797852}", "{\"n\": 11106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.22, \"learn_time_ms\": 8609.858, \"total_train_time_s\": 10.437204599380493}", "{\"n\": 11107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.14, \"learn_time_ms\": 8660.799, \"total_train_time_s\": 9.625850677490234}", "{\"n\": 11108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.14, \"learn_time_ms\": 8730.186, \"total_train_time_s\": 10.805100440979004}", "{\"n\": 11109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.13, \"learn_time_ms\": 8622.593, \"total_train_time_s\": 9.15644359588623}", "{\"n\": 11110, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.4, \"learn_time_ms\": 8548.616, \"total_train_time_s\": 9.897587776184082}", "{\"n\": 11111, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3442.86, \"learn_time_ms\": 8570.766, \"total_train_time_s\": 9.850536823272705}", "{\"n\": 11112, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.46, \"learn_time_ms\": 8485.586, \"total_train_time_s\": 9.822552680969238}", "{\"n\": 11113, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.06, \"learn_time_ms\": 8641.671, \"total_train_time_s\": 10.858954668045044}", "{\"n\": 11114, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.06, \"learn_time_ms\": 8611.941, \"total_train_time_s\": 9.393275737762451}", "{\"n\": 11115, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.1, \"learn_time_ms\": 8627.894, \"total_train_time_s\": 10.599554300308228}", "{\"n\": 11116, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.4, \"learn_time_ms\": 8433.356, \"total_train_time_s\": 8.444597244262695}", "{\"n\": 11117, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.4, \"learn_time_ms\": 8517.227, \"total_train_time_s\": 10.440369129180908}", "{\"n\": 11118, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.72, \"learn_time_ms\": 8469.726, \"total_train_time_s\": 10.457757711410522}", "{\"n\": 11119, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.43, \"learn_time_ms\": 8668.109, \"total_train_time_s\": 11.16253113746643}", "{\"n\": 11120, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.29, \"learn_time_ms\": 8615.838, \"total_train_time_s\": 9.347570896148682}", "{\"n\": 11121, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.0, \"learn_time_ms\": 8690.063, \"total_train_time_s\": 10.629358530044556}", "{\"n\": 11122, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.05, \"learn_time_ms\": 8690.394, \"total_train_time_s\": 9.795088291168213}", "{\"n\": 11123, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.05, \"learn_time_ms\": 8710.794, \"total_train_time_s\": 11.015656471252441}", "{\"n\": 11124, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.03, \"learn_time_ms\": 8803.708, \"total_train_time_s\": 10.280898809432983}", "{\"n\": 11125, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.99, \"learn_time_ms\": 8892.426, \"total_train_time_s\": 11.51778268814087}", "{\"n\": 11126, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.59, \"learn_time_ms\": 8950.677, \"total_train_time_s\": 9.05225396156311}", "{\"n\": 11127, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.84, \"learn_time_ms\": 9016.647, \"total_train_time_s\": 11.128398895263672}", "{\"n\": 11128, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.76, \"learn_time_ms\": 9044.742, \"total_train_time_s\": 10.62169599533081}", "{\"n\": 11129, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.32, \"learn_time_ms\": 9052.224, \"total_train_time_s\": 11.194965362548828}", "{\"n\": 11130, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.5, \"learn_time_ms\": 9128.475, \"total_train_time_s\": 10.047728776931763}", "{\"n\": 11131, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.66, \"learn_time_ms\": 9118.661, \"total_train_time_s\": 10.51554536819458}", "{\"n\": 11132, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.99, \"learn_time_ms\": 9073.176, \"total_train_time_s\": 9.396390676498413}", "{\"n\": 11133, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.15, \"learn_time_ms\": 8979.639, \"total_train_time_s\": 10.144948720932007}", "{\"n\": 11134, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.57, \"learn_time_ms\": 8856.967, \"total_train_time_s\": 9.064356088638306}", "{\"n\": 11135, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.5, \"learn_time_ms\": 8717.59, \"total_train_time_s\": 10.088652610778809}", "{\"n\": 11136, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.35, \"learn_time_ms\": 8726.832, \"total_train_time_s\": 9.184348106384277}", "{\"n\": 11137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.35, \"learn_time_ms\": 8497.041, \"total_train_time_s\": 8.804017066955566}", "{\"n\": 11138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.83, \"learn_time_ms\": 8485.267, \"total_train_time_s\": 10.52597427368164}", "{\"n\": 11139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.16, \"learn_time_ms\": 8286.391, \"total_train_time_s\": 9.27165174484253}", "{\"n\": 11140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.16, \"learn_time_ms\": 8355.105, \"total_train_time_s\": 10.78153681755066}", "{\"n\": 11141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.93, \"learn_time_ms\": 8176.542, \"total_train_time_s\": 8.700902462005615}", "{\"n\": 11142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.11, \"learn_time_ms\": 8218.749, \"total_train_time_s\": 9.765655040740967}", "{\"n\": 11143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.17, \"learn_time_ms\": 7993.651, \"total_train_time_s\": 7.879392385482788}", "{\"n\": 11144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.76, \"learn_time_ms\": 8131.424, \"total_train_time_s\": 10.421560287475586}", "{\"n\": 11145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.27, \"learn_time_ms\": 8114.748, \"total_train_time_s\": 9.927372694015503}", "{\"n\": 11146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.62, \"learn_time_ms\": 8195.731, \"total_train_time_s\": 9.973719358444214}", "{\"n\": 11147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.51, \"learn_time_ms\": 8455.285, \"total_train_time_s\": 11.432062864303589}", "{\"n\": 11148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.53, \"learn_time_ms\": 8297.441, \"total_train_time_s\": 8.936330556869507}", "{\"n\": 11149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.53, \"learn_time_ms\": 8352.667, \"total_train_time_s\": 9.782676219940186}", "{\"n\": 11150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.86, \"learn_time_ms\": 8264.531, \"total_train_time_s\": 9.882843971252441}", "{\"n\": 11151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.86, \"learn_time_ms\": 8259.175, \"total_train_time_s\": 8.627717971801758}", "{\"n\": 11152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.32, \"learn_time_ms\": 8232.202, \"total_train_time_s\": 9.484241247177124}", "{\"n\": 11153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.74, \"learn_time_ms\": 8360.832, \"total_train_time_s\": 9.140490531921387}", "{\"n\": 11154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.74, \"learn_time_ms\": 8366.192, \"total_train_time_s\": 10.53775691986084}", "{\"n\": 11155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 8354.154, \"total_train_time_s\": 9.801450967788696}", "{\"n\": 11156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 8430.403, \"total_train_time_s\": 10.699674606323242}", "{\"n\": 11157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.31, \"learn_time_ms\": 8212.247, \"total_train_time_s\": 9.242122173309326}", "{\"n\": 11158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.29, \"learn_time_ms\": 8226.289, \"total_train_time_s\": 9.122663021087646}", "{\"n\": 11159, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.29, \"learn_time_ms\": 8197.786, \"total_train_time_s\": 9.50620722770691}", "{\"n\": 11160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.7, \"learn_time_ms\": 8122.53, \"total_train_time_s\": 9.136026859283447}", "{\"n\": 11161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.7, \"learn_time_ms\": 8244.068, \"total_train_time_s\": 9.858253717422485}", "{\"n\": 11162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.59, \"learn_time_ms\": 8229.119, \"total_train_time_s\": 9.310701847076416}", "{\"n\": 11163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.07, \"learn_time_ms\": 8250.836, \"total_train_time_s\": 9.381264925003052}", "{\"n\": 11164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.13, \"learn_time_ms\": 8252.294, \"total_train_time_s\": 10.545584440231323}", "{\"n\": 11165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.61, \"learn_time_ms\": 8299.235, \"total_train_time_s\": 10.246971607208252}", "{\"n\": 11166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.43, \"learn_time_ms\": 8332.404, \"total_train_time_s\": 11.051940202713013}", "{\"n\": 11167, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.41, \"learn_time_ms\": 8498.944, \"total_train_time_s\": 10.940692663192749}", "{\"n\": 11168, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.41, \"learn_time_ms\": 8615.154, \"total_train_time_s\": 10.228857040405273}", "{\"n\": 11169, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.06, \"learn_time_ms\": 8647.404, \"total_train_time_s\": 9.820374727249146}", "{\"n\": 11170, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.69, \"learn_time_ms\": 8801.213, \"total_train_time_s\": 10.67884874343872}", "{\"n\": 11171, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.69, \"learn_time_ms\": 8842.614, \"total_train_time_s\": 10.303246259689331}", "{\"n\": 11172, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.6, \"learn_time_ms\": 8920.121, \"total_train_time_s\": 10.087653398513794}", "{\"n\": 11173, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.71, \"learn_time_ms\": 8780.766, \"total_train_time_s\": 7.981843709945679}", "{\"n\": 11174, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.73, \"learn_time_ms\": 8716.313, \"total_train_time_s\": 9.870793342590332}", "{\"n\": 11175, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.73, \"learn_time_ms\": 8685.445, \"total_train_time_s\": 9.928144454956055}", "{\"n\": 11176, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.62, \"learn_time_ms\": 8601.379, \"total_train_time_s\": 10.225625991821289}", "{\"n\": 11177, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.5, \"learn_time_ms\": 8530.528, \"total_train_time_s\": 10.225566864013672}", "{\"n\": 11178, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.5, \"learn_time_ms\": 8496.282, \"total_train_time_s\": 9.930189371109009}", "{\"n\": 11179, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.6, \"learn_time_ms\": 8495.041, \"total_train_time_s\": 9.83708906173706}", "{\"n\": 11180, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.18, \"learn_time_ms\": 8371.1, \"total_train_time_s\": 9.465943098068237}", "{\"n\": 11181, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.18, \"learn_time_ms\": 8376.046, \"total_train_time_s\": 10.353691816329956}", "{\"n\": 11182, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.87, \"learn_time_ms\": 8658.137, \"total_train_time_s\": 12.95709490776062}", "{\"n\": 11183, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.84, \"learn_time_ms\": 8853.034, \"total_train_time_s\": 9.86519742012024}", "{\"n\": 11184, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.86, \"learn_time_ms\": 8747.89, \"total_train_time_s\": 8.801268100738525}", "{\"n\": 11185, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.2, \"learn_time_ms\": 8747.834, \"total_train_time_s\": 10.025061845779419}", "{\"n\": 11186, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.69, \"learn_time_ms\": 8702.216, \"total_train_time_s\": 9.733262777328491}", "{\"n\": 11187, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.91, \"learn_time_ms\": 8617.293, \"total_train_time_s\": 9.324744701385498}", "{\"n\": 11188, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.91, \"learn_time_ms\": 8736.079, \"total_train_time_s\": 11.101780652999878}", "{\"n\": 11189, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.75, \"learn_time_ms\": 8769.726, \"total_train_time_s\": 10.146399974822998}", "{\"n\": 11190, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.29, \"learn_time_ms\": 8747.446, \"total_train_time_s\": 9.227423191070557}", "{\"n\": 11191, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.29, \"learn_time_ms\": 8683.392, \"total_train_time_s\": 9.69429898262024}", "{\"n\": 11192, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.86, \"learn_time_ms\": 8394.887, \"total_train_time_s\": 10.045934677124023}", "{\"n\": 11193, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.96, \"learn_time_ms\": 8468.272, \"total_train_time_s\": 10.690577030181885}", "{\"n\": 11194, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.96, \"learn_time_ms\": 8624.453, \"total_train_time_s\": 10.371055126190186}", "{\"n\": 11195, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.34, \"learn_time_ms\": 8660.105, \"total_train_time_s\": 10.301802635192871}", "{\"n\": 11196, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.99, \"learn_time_ms\": 8746.111, \"total_train_time_s\": 10.572759866714478}", "{\"n\": 11197, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.35, \"learn_time_ms\": 8854.437, \"total_train_time_s\": 10.422946214675903}", "{\"n\": 11198, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.12, \"learn_time_ms\": 8592.557, \"total_train_time_s\": 8.515998840332031}", "{\"n\": 11199, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.86, \"learn_time_ms\": 8622.912, \"total_train_time_s\": 10.453919887542725}", "{\"n\": 11200, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.2, \"learn_time_ms\": 8709.077, \"total_train_time_s\": 10.05811357498169}", "{\"n\": 11201, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.35, \"learn_time_ms\": 8725.059, \"total_train_time_s\": 9.87660002708435}", "{\"n\": 11202, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.91, \"learn_time_ms\": 8611.839, \"total_train_time_s\": 8.960860013961792}", "{\"n\": 11203, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.52, \"learn_time_ms\": 8596.531, \"total_train_time_s\": 10.471916675567627}", "{\"n\": 11204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.99, \"learn_time_ms\": 8622.769, \"total_train_time_s\": 10.658654928207397}", "{\"n\": 11205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.53, \"learn_time_ms\": 8591.02, \"total_train_time_s\": 9.991651773452759}", "{\"n\": 11206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.82, \"learn_time_ms\": 8488.635, \"total_train_time_s\": 9.575739622116089}", "{\"n\": 11207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.94, \"learn_time_ms\": 8644.379, \"total_train_time_s\": 11.960267066955566}", "{\"n\": 11208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.94, \"learn_time_ms\": 8606.734, \"total_train_time_s\": 8.117954969406128}", "{\"n\": 11209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.12, \"learn_time_ms\": 8410.41, \"total_train_time_s\": 8.504715204238892}", "{\"n\": 11210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.03, \"learn_time_ms\": 8476.407, \"total_train_time_s\": 10.685169696807861}", "{\"n\": 11211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.28, \"learn_time_ms\": 8549.231, \"total_train_time_s\": 10.58644151687622}", "{\"n\": 11212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.28, \"learn_time_ms\": 8790.83, \"total_train_time_s\": 11.336504697799683}", "{\"n\": 11213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.58, \"learn_time_ms\": 8679.665, \"total_train_time_s\": 9.441012620925903}", "{\"n\": 11214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.14, \"learn_time_ms\": 8537.811, \"total_train_time_s\": 9.228588104248047}", "{\"n\": 11215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.14, \"learn_time_ms\": 8403.153, \"total_train_time_s\": 8.617132186889648}", "{\"n\": 11216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.11, \"learn_time_ms\": 8434.587, \"total_train_time_s\": 9.876697063446045}", "{\"n\": 11217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.26, \"learn_time_ms\": 8191.523, \"total_train_time_s\": 9.5551917552948}", "{\"n\": 11218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.26, \"learn_time_ms\": 8389.584, \"total_train_time_s\": 10.05984902381897}", "{\"n\": 11219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.37, \"learn_time_ms\": 8772.009, \"total_train_time_s\": 12.334200620651245}", "{\"n\": 11220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.28, \"learn_time_ms\": 8724.712, \"total_train_time_s\": 10.29148530960083}", "{\"n\": 11221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.28, \"learn_time_ms\": 8698.301, \"total_train_time_s\": 10.353938341140747}", "{\"n\": 11222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.28, \"learn_time_ms\": 8465.291, \"total_train_time_s\": 9.040957689285278}", "{\"n\": 11223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.06, \"learn_time_ms\": 8456.559, \"total_train_time_s\": 9.339478015899658}", "{\"n\": 11224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.79, \"learn_time_ms\": 8496.439, \"total_train_time_s\": 9.62795877456665}", "{\"n\": 11225, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.79, \"learn_time_ms\": 8615.137, \"total_train_time_s\": 9.864569902420044}", "{\"n\": 11226, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.42, \"learn_time_ms\": 8741.707, \"total_train_time_s\": 11.146239757537842}", "{\"n\": 11227, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.99, \"learn_time_ms\": 8857.022, \"total_train_time_s\": 10.677218437194824}", "{\"n\": 11228, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.99, \"learn_time_ms\": 8891.195, \"total_train_time_s\": 10.369132041931152}", "{\"n\": 11229, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.79, \"learn_time_ms\": 8590.672, \"total_train_time_s\": 9.315845251083374}", "{\"n\": 11230, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.79, \"learn_time_ms\": 8522.636, \"total_train_time_s\": 9.555528163909912}", "{\"n\": 11231, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.89, \"learn_time_ms\": 8569.116, \"total_train_time_s\": 10.833023071289062}", "{\"n\": 11232, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.62, \"learn_time_ms\": 8625.99, \"total_train_time_s\": 9.609599590301514}", "{\"n\": 11233, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8594.564, \"total_train_time_s\": 9.037237644195557}", "{\"n\": 11234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8639.936, \"total_train_time_s\": 10.062381744384766}", "{\"n\": 11235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.05, \"learn_time_ms\": 8752.078, \"total_train_time_s\": 10.967523336410522}", "{\"n\": 11236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.37, \"learn_time_ms\": 8578.594, \"total_train_time_s\": 9.397866249084473}", "{\"n\": 11237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.27, \"learn_time_ms\": 8544.167, \"total_train_time_s\": 10.409321546554565}", "{\"n\": 11238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.35, \"learn_time_ms\": 8627.157, \"total_train_time_s\": 11.274832487106323}", "{\"n\": 11239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.76, \"learn_time_ms\": 8682.66, \"total_train_time_s\": 9.878690719604492}", "{\"n\": 11240, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.82, \"learn_time_ms\": 8677.114, \"total_train_time_s\": 9.549315929412842}", "{\"n\": 11241, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.82, \"learn_time_ms\": 8619.667, \"total_train_time_s\": 10.208272218704224}", "{\"n\": 11242, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.38, \"learn_time_ms\": 8740.903, \"total_train_time_s\": 10.785051822662354}", "{\"n\": 11243, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.14, \"learn_time_ms\": 8837.705, \"total_train_time_s\": 9.941963911056519}", "{\"n\": 11244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.02, \"learn_time_ms\": 8847.768, \"total_train_time_s\": 10.197142362594604}", "{\"n\": 11245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.98, \"learn_time_ms\": 8759.299, \"total_train_time_s\": 10.054327487945557}", "{\"n\": 11246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.69, \"learn_time_ms\": 8739.809, \"total_train_time_s\": 9.211504697799683}", "{\"n\": 11247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.4, \"learn_time_ms\": 8679.775, \"total_train_time_s\": 9.778307437896729}", "{\"n\": 11248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 8638.362, \"total_train_time_s\": 10.890383958816528}", "{\"n\": 11249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 8644.473, \"total_train_time_s\": 9.926013231277466}", "{\"n\": 11250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.66, \"learn_time_ms\": 8661.397, \"total_train_time_s\": 9.73746371269226}", "{\"n\": 11251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.66, \"learn_time_ms\": 8547.324, \"total_train_time_s\": 9.053590774536133}", "{\"n\": 11252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.73, \"learn_time_ms\": 8335.574, \"total_train_time_s\": 8.681559801101685}", "{\"n\": 11253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.98, \"learn_time_ms\": 8341.33, \"total_train_time_s\": 9.995885133743286}", "{\"n\": 11254, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.3, \"learn_time_ms\": 8317.664, \"total_train_time_s\": 9.917643070220947}", "{\"n\": 11255, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.06, \"learn_time_ms\": 8314.854, \"total_train_time_s\": 10.02169680595398}", "{\"n\": 11256, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.51, \"learn_time_ms\": 8358.256, \"total_train_time_s\": 9.650500535964966}", "{\"n\": 11257, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.32, \"learn_time_ms\": 8364.748, \"total_train_time_s\": 9.816437244415283}", "{\"n\": 11258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.38, \"learn_time_ms\": 8293.319, \"total_train_time_s\": 10.054165124893188}", "{\"n\": 11259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.76, \"learn_time_ms\": 8308.698, \"total_train_time_s\": 10.07868218421936}", "{\"n\": 11260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.42, \"learn_time_ms\": 8381.018, \"total_train_time_s\": 10.415433645248413}", "{\"n\": 11261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.42, \"learn_time_ms\": 8416.462, \"total_train_time_s\": 9.378431558609009}", "{\"n\": 11262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.46, \"learn_time_ms\": 8581.887, \"total_train_time_s\": 10.310720920562744}", "{\"n\": 11263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.66, \"learn_time_ms\": 8704.632, \"total_train_time_s\": 11.277561664581299}", "{\"n\": 11264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 8646.225, \"total_train_time_s\": 9.373137950897217}", "{\"n\": 11265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.83, \"learn_time_ms\": 8711.313, \"total_train_time_s\": 10.728008031845093}", "{\"n\": 11266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.27, \"learn_time_ms\": 8675.932, \"total_train_time_s\": 9.257999420166016}", "{\"n\": 11267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.16, \"learn_time_ms\": 8791.474, \"total_train_time_s\": 11.026611804962158}", "{\"n\": 11268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.16, \"learn_time_ms\": 8753.218, \"total_train_time_s\": 9.7250657081604}", "{\"n\": 11269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.26, \"learn_time_ms\": 8816.688, \"total_train_time_s\": 10.71820855140686}", "{\"n\": 11270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.24, \"learn_time_ms\": 8858.413, \"total_train_time_s\": 10.796950101852417}", "{\"n\": 11271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.24, \"learn_time_ms\": 9000.441, \"total_train_time_s\": 10.830589056015015}", "{\"n\": 11272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.15, \"learn_time_ms\": 9086.832, \"total_train_time_s\": 11.23330044746399}", "{\"n\": 11273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.15, \"learn_time_ms\": 9043.391, \"total_train_time_s\": 10.77090311050415}", "{\"n\": 11274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.55, \"learn_time_ms\": 9180.967, \"total_train_time_s\": 10.726551055908203}", "{\"n\": 11275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.55, \"learn_time_ms\": 9136.378, \"total_train_time_s\": 10.233659982681274}", "{\"n\": 11276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.4, \"learn_time_ms\": 9154.103, \"total_train_time_s\": 9.478063821792603}", "{\"n\": 11277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.02, \"learn_time_ms\": 8993.455, \"total_train_time_s\": 9.350016355514526}", "{\"n\": 11278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.02, \"learn_time_ms\": 9059.192, \"total_train_time_s\": 10.458961963653564}", "{\"n\": 11279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.29, \"learn_time_ms\": 8964.025, \"total_train_time_s\": 9.799726247787476}", "{\"n\": 11280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.54, \"learn_time_ms\": 8841.236, \"total_train_time_s\": 9.622222900390625}", "{\"n\": 11281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.54, \"learn_time_ms\": 8655.581, \"total_train_time_s\": 8.991517066955566}", "{\"n\": 11282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.54, \"learn_time_ms\": 8549.378, \"total_train_time_s\": 10.122100830078125}", "{\"n\": 11283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.59, \"learn_time_ms\": 8457.231, \"total_train_time_s\": 9.879222869873047}", "{\"n\": 11284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 8385.938, \"total_train_time_s\": 10.027655839920044}", "{\"n\": 11285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 8381.341, \"total_train_time_s\": 10.201305150985718}", "{\"n\": 11286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.14, \"learn_time_ms\": 8315.515, \"total_train_time_s\": 8.841421842575073}", "{\"n\": 11287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.59, \"learn_time_ms\": 8379.61, \"total_train_time_s\": 9.979602098464966}", "{\"n\": 11288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.59, \"learn_time_ms\": 8354.257, \"total_train_time_s\": 10.134446620941162}", "{\"n\": 11289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.59, \"learn_time_ms\": 8579.779, \"total_train_time_s\": 12.008405685424805}", "{\"n\": 11290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.86, \"learn_time_ms\": 8706.994, \"total_train_time_s\": 10.879993915557861}", "{\"n\": 11291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 8915.041, \"total_train_time_s\": 11.070222854614258}", "{\"n\": 11292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 9041.105, \"total_train_time_s\": 11.361829042434692}", "{\"n\": 11293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.77, \"learn_time_ms\": 9188.133, \"total_train_time_s\": 11.355961084365845}", "{\"n\": 11294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.49, \"learn_time_ms\": 9178.348, \"total_train_time_s\": 9.882376670837402}", "{\"n\": 11295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.49, \"learn_time_ms\": 9325.881, \"total_train_time_s\": 11.720259666442871}", "{\"n\": 11296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 9413.086, \"total_train_time_s\": 9.705924272537231}", "{\"n\": 11297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.54, \"learn_time_ms\": 9354.478, \"total_train_time_s\": 9.479126214981079}", "{\"n\": 11298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.54, \"learn_time_ms\": 9191.383, \"total_train_time_s\": 8.518932580947876}", "{\"n\": 11299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.54, \"learn_time_ms\": 8962.777, \"total_train_time_s\": 9.798760175704956}", "{\"n\": 11300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.69, \"learn_time_ms\": 8884.499, \"total_train_time_s\": 10.117709159851074}", "{\"n\": 11301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.7, \"learn_time_ms\": 8721.512, \"total_train_time_s\": 9.450650215148926}", "{\"n\": 11302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.7, \"learn_time_ms\": 8521.119, \"total_train_time_s\": 9.318951845169067}", "{\"n\": 11303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.74, \"learn_time_ms\": 8276.845, \"total_train_time_s\": 8.896093845367432}", "{\"n\": 11304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.31, \"learn_time_ms\": 8326.525, \"total_train_time_s\": 10.453045845031738}", "{\"n\": 11305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.31, \"learn_time_ms\": 8207.888, \"total_train_time_s\": 10.505262851715088}", "{\"n\": 11306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.36, \"learn_time_ms\": 8123.019, \"total_train_time_s\": 8.876246452331543}", "{\"n\": 11307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.49, \"learn_time_ms\": 8075.482, \"total_train_time_s\": 8.965276002883911}", "{\"n\": 11308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.62, \"learn_time_ms\": 8174.76, \"total_train_time_s\": 9.493163585662842}", "{\"n\": 11309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.62, \"learn_time_ms\": 8188.784, \"total_train_time_s\": 9.863971471786499}", "{\"n\": 11310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.99, \"learn_time_ms\": 8132.786, \"total_train_time_s\": 9.471940994262695}", "{\"n\": 11311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.14, \"learn_time_ms\": 8131.893, \"total_train_time_s\": 9.376221418380737}", "{\"n\": 11312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.7, \"learn_time_ms\": 8118.599, \"total_train_time_s\": 9.26137375831604}", "{\"n\": 11313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.84, \"learn_time_ms\": 8232.378, \"total_train_time_s\": 9.990159273147583}", "{\"n\": 11314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.85, \"learn_time_ms\": 8177.564, \"total_train_time_s\": 9.874874114990234}", "{\"n\": 11315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.47, \"learn_time_ms\": 8215.087, \"total_train_time_s\": 10.85946011543274}", "{\"n\": 11316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.57, \"learn_time_ms\": 8240.209, \"total_train_time_s\": 9.073618650436401}", "{\"n\": 11317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.59, \"learn_time_ms\": 8396.532, \"total_train_time_s\": 10.548576831817627}", "{\"n\": 11318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.26, \"learn_time_ms\": 8475.334, \"total_train_time_s\": 10.360431432723999}", "{\"n\": 11319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.26, \"learn_time_ms\": 8595.046, \"total_train_time_s\": 11.067119359970093}", "{\"n\": 11320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.46, \"learn_time_ms\": 8651.48, \"total_train_time_s\": 10.102548837661743}", "{\"n\": 11321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.9, \"learn_time_ms\": 8639.003, \"total_train_time_s\": 9.366013526916504}", "{\"n\": 11322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.08, \"learn_time_ms\": 8892.574, \"total_train_time_s\": 11.85420036315918}", "{\"n\": 11323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.6, \"learn_time_ms\": 8805.237, \"total_train_time_s\": 9.18974757194519}", "{\"n\": 11324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.6, \"learn_time_ms\": 8787.859, \"total_train_time_s\": 9.65355896949768}", "{\"n\": 11325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.21, \"learn_time_ms\": 8773.164, \"total_train_time_s\": 10.738211631774902}", "{\"n\": 11326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.8, \"learn_time_ms\": 8949.612, \"total_train_time_s\": 10.882110595703125}", "{\"n\": 11327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.8, \"learn_time_ms\": 8848.373, \"total_train_time_s\": 9.537265300750732}", "{\"n\": 11328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.74, \"learn_time_ms\": 8756.835, \"total_train_time_s\": 9.374905347824097}", "{\"n\": 11329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.17, \"learn_time_ms\": 8789.989, \"total_train_time_s\": 11.396889686584473}", "{\"n\": 11330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.42, \"learn_time_ms\": 8684.532, \"total_train_time_s\": 9.022675037384033}", "{\"n\": 11331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.83, \"learn_time_ms\": 8848.158, \"total_train_time_s\": 10.967682600021362}", "{\"n\": 11332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.37, \"learn_time_ms\": 8746.558, \"total_train_time_s\": 10.81082034111023}", "{\"n\": 11333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.41, \"learn_time_ms\": 8788.319, \"total_train_time_s\": 9.549034595489502}", "{\"n\": 11334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.88, \"learn_time_ms\": 8787.21, \"total_train_time_s\": 9.692081451416016}", "{\"n\": 11335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.88, \"learn_time_ms\": 8743.799, \"total_train_time_s\": 10.288406610488892}", "{\"n\": 11336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.37, \"learn_time_ms\": 8714.666, \"total_train_time_s\": 10.576150894165039}", "{\"n\": 11337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.81, \"learn_time_ms\": 8803.823, \"total_train_time_s\": 10.398759603500366}", "{\"n\": 11338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.17, \"learn_time_ms\": 8708.954, \"total_train_time_s\": 8.443368434906006}", "{\"n\": 11339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.38, \"learn_time_ms\": 8583.468, \"total_train_time_s\": 10.127552270889282}", "{\"n\": 11340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.89, \"learn_time_ms\": 8720.094, \"total_train_time_s\": 10.391002178192139}", "{\"n\": 11341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.25, \"learn_time_ms\": 8668.69, \"total_train_time_s\": 10.44811749458313}", "{\"n\": 11342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.25, \"learn_time_ms\": 8617.667, \"total_train_time_s\": 10.217225313186646}", "{\"n\": 11343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.48, \"learn_time_ms\": 8500.394, \"total_train_time_s\": 8.376118183135986}", "{\"n\": 11344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.81, \"learn_time_ms\": 8458.826, \"total_train_time_s\": 9.261162519454956}", "{\"n\": 11345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.41, \"learn_time_ms\": 8349.235, \"total_train_time_s\": 9.169744968414307}", "{\"n\": 11346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.39, \"learn_time_ms\": 8326.605, \"total_train_time_s\": 10.334587574005127}", "{\"n\": 11347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.39, \"learn_time_ms\": 8355.658, \"total_train_time_s\": 10.698851823806763}", "{\"n\": 11348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.58, \"learn_time_ms\": 8575.055, \"total_train_time_s\": 10.631603479385376}", "{\"n\": 11349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.51, \"learn_time_ms\": 8705.09, \"total_train_time_s\": 11.424605131149292}", "{\"n\": 11350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.45, \"learn_time_ms\": 8512.059, \"total_train_time_s\": 8.457720518112183}", "{\"n\": 11351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.71, \"learn_time_ms\": 8509.553, \"total_train_time_s\": 10.422903299331665}", "{\"n\": 11352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.71, \"learn_time_ms\": 8649.589, \"total_train_time_s\": 11.632410526275635}", "{\"n\": 11353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3399.51, \"learn_time_ms\": 8713.479, \"total_train_time_s\": 9.044663190841675}", "{\"n\": 11354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.02, \"learn_time_ms\": 8863.936, \"total_train_time_s\": 10.787862539291382}", "{\"n\": 11355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.34, \"learn_time_ms\": 8922.92, \"total_train_time_s\": 9.79225492477417}", "{\"n\": 11356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.83, \"learn_time_ms\": 8859.756, \"total_train_time_s\": 9.753468990325928}", "{\"n\": 11357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.83, \"learn_time_ms\": 8843.05, \"total_train_time_s\": 10.503598690032959}", "{\"n\": 11358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.76, \"learn_time_ms\": 8775.625, \"total_train_time_s\": 9.935630321502686}", "{\"n\": 11359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.48, \"learn_time_ms\": 8567.606, \"total_train_time_s\": 9.338719606399536}", "{\"n\": 11360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.48, \"learn_time_ms\": 8732.423, \"total_train_time_s\": 10.089699506759644}", "{\"n\": 11361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.5, \"learn_time_ms\": 8553.134, \"total_train_time_s\": 8.594985485076904}", "{\"n\": 11362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.32, \"learn_time_ms\": 8372.56, \"total_train_time_s\": 9.866157293319702}", "{\"n\": 11363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.97, \"learn_time_ms\": 8529.252, \"total_train_time_s\": 10.629938125610352}", "{\"n\": 11364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.16, \"learn_time_ms\": 8420.011, \"total_train_time_s\": 9.645244121551514}", "{\"n\": 11365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.18, \"learn_time_ms\": 8339.488, \"total_train_time_s\": 8.994421243667603}", "{\"n\": 11366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.18, \"learn_time_ms\": 8465.469, \"total_train_time_s\": 10.959050178527832}", "{\"n\": 11367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.95, \"learn_time_ms\": 8363.268, \"total_train_time_s\": 9.538374662399292}", "{\"n\": 11368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.77, \"learn_time_ms\": 8323.751, \"total_train_time_s\": 9.587080240249634}", "{\"n\": 11369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.77, \"learn_time_ms\": 8430.111, \"total_train_time_s\": 10.410154342651367}", "{\"n\": 11370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.04, \"learn_time_ms\": 8393.52, \"total_train_time_s\": 9.739047527313232}", "{\"n\": 11371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.44, \"learn_time_ms\": 8637.215, \"total_train_time_s\": 11.030074119567871}", "{\"n\": 11372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.89, \"learn_time_ms\": 8782.21, \"total_train_time_s\": 11.284168004989624}", "{\"n\": 11373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.78, \"learn_time_ms\": 8630.234, \"total_train_time_s\": 9.071937084197998}", "{\"n\": 11374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.9, \"learn_time_ms\": 8638.85, \"total_train_time_s\": 9.789123296737671}", "{\"n\": 11375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.14, \"learn_time_ms\": 8759.688, \"total_train_time_s\": 10.175192832946777}", "{\"n\": 11376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 8658.646, \"total_train_time_s\": 9.958340406417847}", "{\"n\": 11377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 8868.1, \"total_train_time_s\": 11.564259767532349}", "{\"n\": 11378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.3, \"learn_time_ms\": 8987.408, \"total_train_time_s\": 10.725131034851074}", "{\"n\": 11379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.3, \"learn_time_ms\": 8924.841, \"total_train_time_s\": 9.742167949676514}", "{\"n\": 11380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.51, \"learn_time_ms\": 8941.565, \"total_train_time_s\": 9.953872919082642}", "{\"n\": 11381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.38, \"learn_time_ms\": 8854.84, \"total_train_time_s\": 10.196532964706421}", "{\"n\": 11382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.38, \"learn_time_ms\": 8809.03, \"total_train_time_s\": 10.849179744720459}", "{\"n\": 11383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.74, \"learn_time_ms\": 8816.847, \"total_train_time_s\": 9.224850177764893}", "{\"n\": 11384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.05, \"learn_time_ms\": 8797.865, \"total_train_time_s\": 9.566261768341064}", "{\"n\": 11385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.6, \"learn_time_ms\": 8782.299, \"total_train_time_s\": 10.018064737319946}", "{\"n\": 11386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.87, \"learn_time_ms\": 8648.826, \"total_train_time_s\": 8.635266304016113}", "{\"n\": 11387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.1, \"learn_time_ms\": 8558.003, \"total_train_time_s\": 10.720247745513916}", "{\"n\": 11388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.87, \"learn_time_ms\": 8421.604, \"total_train_time_s\": 9.419737577438354}", "{\"n\": 11389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.88, \"learn_time_ms\": 8418.604, \"total_train_time_s\": 9.788583993911743}", "{\"n\": 11390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.24, \"learn_time_ms\": 8437.635, \"total_train_time_s\": 10.102601289749146}", "{\"n\": 11391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.03, \"learn_time_ms\": 8442.85, \"total_train_time_s\": 10.21872329711914}", "{\"n\": 11392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.39, \"learn_time_ms\": 8488.013, \"total_train_time_s\": 11.315171241760254}", "{\"n\": 11393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.84, \"learn_time_ms\": 8603.973, \"total_train_time_s\": 10.347642183303833}", "{\"n\": 11394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.42, \"learn_time_ms\": 8762.76, \"total_train_time_s\": 11.16903567314148}", "{\"n\": 11395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.22, \"learn_time_ms\": 8807.373, \"total_train_time_s\": 10.454724550247192}", "{\"n\": 11396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.68, \"learn_time_ms\": 9086.551, \"total_train_time_s\": 11.412447929382324}", "{\"n\": 11397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.31, \"learn_time_ms\": 9047.756, \"total_train_time_s\": 10.320680618286133}", "{\"n\": 11398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.46, \"learn_time_ms\": 9069.915, \"total_train_time_s\": 9.582556962966919}", "{\"n\": 11399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.03, \"learn_time_ms\": 9052.979, \"total_train_time_s\": 9.599727153778076}", "{\"n\": 11400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.03, \"learn_time_ms\": 9021.159, \"total_train_time_s\": 9.819145441055298}", "{\"n\": 11401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.56, \"learn_time_ms\": 8984.835, \"total_train_time_s\": 9.871879816055298}", "{\"n\": 11402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.46, \"learn_time_ms\": 8876.764, \"total_train_time_s\": 10.26123332977295}", "{\"n\": 11403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.46, \"learn_time_ms\": 8988.66, \"total_train_time_s\": 11.496076583862305}", "{\"n\": 11404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.37, \"learn_time_ms\": 8826.285, \"total_train_time_s\": 9.568889379501343}", "{\"n\": 11405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.34, \"learn_time_ms\": 8858.065, \"total_train_time_s\": 10.815431833267212}", "{\"n\": 11406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.34, \"learn_time_ms\": 8805.978, \"total_train_time_s\": 10.827231645584106}", "{\"n\": 11407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.86, \"learn_time_ms\": 8877.753, \"total_train_time_s\": 11.017099857330322}", "{\"n\": 11408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.34, \"learn_time_ms\": 8950.313, \"total_train_time_s\": 10.337312936782837}", "{\"n\": 11409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.4, \"learn_time_ms\": 9015.33, \"total_train_time_s\": 10.2379891872406}", "{\"n\": 11410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.68, \"learn_time_ms\": 9106.277, \"total_train_time_s\": 10.747103214263916}", "{\"n\": 11411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.77, \"learn_time_ms\": 9164.33, \"total_train_time_s\": 10.461880207061768}", "{\"n\": 11412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3293.42, \"learn_time_ms\": 9110.139, \"total_train_time_s\": 9.688626527786255}", "{\"n\": 11413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.9, \"learn_time_ms\": 8919.628, \"total_train_time_s\": 9.540226221084595}", "{\"n\": 11414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3286.9, \"learn_time_ms\": 8972.459, \"total_train_time_s\": 10.037131547927856}", "{\"n\": 11415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 8857.558, \"total_train_time_s\": 9.690260648727417}", "{\"n\": 11416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 8781.702, \"total_train_time_s\": 10.124328374862671}", "{\"n\": 11417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.64, \"learn_time_ms\": 8630.058, \"total_train_time_s\": 9.482185363769531}", "{\"n\": 11418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.54, \"learn_time_ms\": 8661.999, \"total_train_time_s\": 10.649495124816895}", "{\"n\": 11419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.3, \"learn_time_ms\": 8709.173, \"total_train_time_s\": 10.7630136013031}", "{\"n\": 11420, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.16, \"learn_time_ms\": 8771.953, \"total_train_time_s\": 11.285791158676147}", "{\"n\": 11421, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.92, \"learn_time_ms\": 8753.995, \"total_train_time_s\": 10.226728439331055}", "{\"n\": 11422, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.11, \"learn_time_ms\": 8815.744, \"total_train_time_s\": 10.289718627929688}", "{\"n\": 11423, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.07, \"learn_time_ms\": 8842.187, \"total_train_time_s\": 9.819329023361206}", "{\"n\": 11424, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.07, \"learn_time_ms\": 8823.604, \"total_train_time_s\": 9.86744737625122}", "{\"n\": 11425, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.25, \"learn_time_ms\": 8792.018, \"total_train_time_s\": 9.322630167007446}", "{\"n\": 11426, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.34, \"learn_time_ms\": 8758.06, \"total_train_time_s\": 9.940863609313965}", "{\"n\": 11427, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.57, \"learn_time_ms\": 8830.092, \"total_train_time_s\": 10.234260082244873}", "{\"n\": 11428, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.0, \"learn_time_ms\": 8691.06, \"total_train_time_s\": 9.287522315979004}", "{\"n\": 11429, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.26, \"learn_time_ms\": 8352.012, \"total_train_time_s\": 7.3234028816223145}", "{\"n\": 11430, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3306.39, \"learn_time_ms\": 8278.62, \"total_train_time_s\": 10.586008071899414}", "{\"n\": 11431, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.79, \"learn_time_ms\": 8337.964, \"total_train_time_s\": 10.840227127075195}", "{\"n\": 11432, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3303.85, \"learn_time_ms\": 8231.354, \"total_train_time_s\": 9.224085092544556}", "{\"n\": 11433, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.17, \"learn_time_ms\": 8278.886, \"total_train_time_s\": 10.32424545288086}", "{\"n\": 11434, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.17, \"learn_time_ms\": 8216.34, \"total_train_time_s\": 9.26981520652771}", "{\"n\": 11435, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.64, \"learn_time_ms\": 8271.677, \"total_train_time_s\": 9.88355541229248}", "{\"n\": 11436, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.75, \"learn_time_ms\": 8264.915, \"total_train_time_s\": 9.731450080871582}", "{\"n\": 11437, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.75, \"learn_time_ms\": 8314.668, \"total_train_time_s\": 10.715758085250854}", "{\"n\": 11438, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.38, \"learn_time_ms\": 8376.954, \"total_train_time_s\": 9.897605419158936}", "{\"n\": 11439, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.36, \"learn_time_ms\": 8520.516, \"total_train_time_s\": 8.818273067474365}", "{\"n\": 11440, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.36, \"learn_time_ms\": 8479.946, \"total_train_time_s\": 10.205328464508057}", "{\"n\": 11441, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.05, \"learn_time_ms\": 8380.075, \"total_train_time_s\": 9.883381128311157}", "{\"n\": 11442, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.39, \"learn_time_ms\": 8391.213, \"total_train_time_s\": 9.385477066040039}", "{\"n\": 11443, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.39, \"learn_time_ms\": 8378.32, \"total_train_time_s\": 10.224609613418579}", "{\"n\": 11444, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.39, \"learn_time_ms\": 8383.073, \"total_train_time_s\": 9.303574323654175}", "{\"n\": 11445, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.07, \"learn_time_ms\": 8314.907, \"total_train_time_s\": 9.186368703842163}", "{\"n\": 11446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8219.267, \"total_train_time_s\": 8.743725299835205}", "{\"n\": 11447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8126.711, \"total_train_time_s\": 9.809091329574585}", "{\"n\": 11448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3279.0, \"learn_time_ms\": 8219.092, \"total_train_time_s\": 10.838388204574585}", "{\"n\": 11449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.12, \"learn_time_ms\": 8398.942, \"total_train_time_s\": 10.60538363456726}", "{\"n\": 11450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.12, \"learn_time_ms\": 8458.818, \"total_train_time_s\": 10.790095329284668}", "{\"n\": 11451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.62, \"learn_time_ms\": 8585.809, \"total_train_time_s\": 11.191367387771606}", "{\"n\": 11452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.62, \"learn_time_ms\": 8602.927, \"total_train_time_s\": 9.482166767120361}", "{\"n\": 11453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.95, \"learn_time_ms\": 8671.122, \"total_train_time_s\": 10.877765893936157}", "{\"n\": 11454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.21, \"learn_time_ms\": 8631.133, \"total_train_time_s\": 8.912913799285889}", "{\"n\": 11455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.03, \"learn_time_ms\": 8633.192, \"total_train_time_s\": 9.222713947296143}", "{\"n\": 11456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3279.79, \"learn_time_ms\": 8692.222, \"total_train_time_s\": 9.35296630859375}", "{\"n\": 11457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3279.79, \"learn_time_ms\": 8759.243, \"total_train_time_s\": 10.473259925842285}", "{\"n\": 11458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.82, \"learn_time_ms\": 8638.083, \"total_train_time_s\": 9.611631393432617}", "{\"n\": 11459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.76, \"learn_time_ms\": 8701.452, \"total_train_time_s\": 11.24537992477417}", "{\"n\": 11460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.76, \"learn_time_ms\": 8620.135, \"total_train_time_s\": 9.98449969291687}", "{\"n\": 11461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.18, \"learn_time_ms\": 8673.173, \"total_train_time_s\": 11.706512689590454}", "{\"n\": 11462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.18, \"learn_time_ms\": 8687.156, \"total_train_time_s\": 9.666885614395142}", "{\"n\": 11463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3292.8, \"learn_time_ms\": 8555.294, \"total_train_time_s\": 9.508662700653076}", "{\"n\": 11464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.2, \"learn_time_ms\": 8679.97, \"total_train_time_s\": 10.173208713531494}", "{\"n\": 11465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.4, \"learn_time_ms\": 8849.965, \"total_train_time_s\": 10.990553855895996}", "{\"n\": 11466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.78, \"learn_time_ms\": 8899.947, \"total_train_time_s\": 9.881632089614868}", "{\"n\": 11467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3289.19, \"learn_time_ms\": 8856.736, \"total_train_time_s\": 10.006706714630127}", "{\"n\": 11468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.94, \"learn_time_ms\": 8887.597, \"total_train_time_s\": 9.912476062774658}", "{\"n\": 11469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.65, \"learn_time_ms\": 8795.488, \"total_train_time_s\": 10.29181170463562}", "{\"n\": 11470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.15, \"learn_time_ms\": 8785.888, \"total_train_time_s\": 9.88844609260559}", "{\"n\": 11471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.15, \"learn_time_ms\": 8654.077, \"total_train_time_s\": 10.320499420166016}", "{\"n\": 11472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.26, \"learn_time_ms\": 8654.673, \"total_train_time_s\": 9.708187103271484}", "{\"n\": 11473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 8605.578, \"total_train_time_s\": 9.05835747718811}", "{\"n\": 11474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.5, \"learn_time_ms\": 8596.543, \"total_train_time_s\": 10.04460597038269}", "{\"n\": 11475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.04, \"learn_time_ms\": 8372.792, \"total_train_time_s\": 8.722854852676392}", "{\"n\": 11476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.04, \"learn_time_ms\": 8385.632, \"total_train_time_s\": 10.028728008270264}", "{\"n\": 11477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.37, \"learn_time_ms\": 8473.449, \"total_train_time_s\": 10.921765804290771}", "{\"n\": 11478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.38, \"learn_time_ms\": 8529.186, \"total_train_time_s\": 10.447058916091919}", "{\"n\": 11479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.63, \"learn_time_ms\": 8464.628, \"total_train_time_s\": 9.648500442504883}", "{\"n\": 11480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.63, \"learn_time_ms\": 8405.495, \"total_train_time_s\": 9.256710290908813}", "{\"n\": 11481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.67, \"learn_time_ms\": 8386.104, \"total_train_time_s\": 10.246526002883911}", "{\"n\": 11482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.74, \"learn_time_ms\": 8527.459, \"total_train_time_s\": 11.127821445465088}", "{\"n\": 11483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.93, \"learn_time_ms\": 8762.312, \"total_train_time_s\": 11.409187078475952}", "{\"n\": 11484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.93, \"learn_time_ms\": 8850.412, \"total_train_time_s\": 10.958842277526855}", "{\"n\": 11485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3291.53, \"learn_time_ms\": 8880.377, \"total_train_time_s\": 8.987765789031982}", "{\"n\": 11486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.3, \"learn_time_ms\": 9021.733, \"total_train_time_s\": 11.391193151473999}", "{\"n\": 11487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.3, \"learn_time_ms\": 8910.218, \"total_train_time_s\": 9.800284385681152}", "{\"n\": 11488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.06, \"learn_time_ms\": 9043.779, \"total_train_time_s\": 11.786489248275757}", "{\"n\": 11489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.53, \"learn_time_ms\": 9044.562, \"total_train_time_s\": 9.633851051330566}", "{\"n\": 11490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.52, \"learn_time_ms\": 9138.513, \"total_train_time_s\": 10.24407434463501}", "{\"n\": 11491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.32, \"learn_time_ms\": 9031.581, \"total_train_time_s\": 9.077672004699707}", "{\"n\": 11492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.13, \"learn_time_ms\": 8993.565, \"total_train_time_s\": 10.697559118270874}", "{\"n\": 11493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.95, \"learn_time_ms\": 8786.458, \"total_train_time_s\": 9.309858322143555}", "{\"n\": 11494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.95, \"learn_time_ms\": 8680.008, \"total_train_time_s\": 9.8883216381073}", "{\"n\": 11495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.0, \"learn_time_ms\": 8701.727, \"total_train_time_s\": 9.230674743652344}", "{\"n\": 11496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.99, \"learn_time_ms\": 8519.088, \"total_train_time_s\": 9.616182565689087}", "{\"n\": 11497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.99, \"learn_time_ms\": 8586.634, \"total_train_time_s\": 10.475453853607178}", "{\"n\": 11498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.2, \"learn_time_ms\": 8455.722, \"total_train_time_s\": 10.48884105682373}", "{\"n\": 11499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.2, \"learn_time_ms\": 8462.176, \"total_train_time_s\": 9.706573247909546}", "{\"n\": 11500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.47, \"learn_time_ms\": 8474.136, \"total_train_time_s\": 10.349004030227661}", "{\"n\": 11501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.28, \"learn_time_ms\": 8560.768, \"total_train_time_s\": 9.995270729064941}", "{\"n\": 11502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.94, \"learn_time_ms\": 8407.022, \"total_train_time_s\": 9.157897472381592}", "{\"n\": 11503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.62, \"learn_time_ms\": 8328.495, \"total_train_time_s\": 8.537393808364868}", "{\"n\": 11504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.54, \"learn_time_ms\": 8292.7, \"total_train_time_s\": 9.523086309432983}", "{\"n\": 11505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.79, \"learn_time_ms\": 8286.794, \"total_train_time_s\": 9.12807583808899}", "{\"n\": 11506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.79, \"learn_time_ms\": 8246.521, \"total_train_time_s\": 9.135562181472778}", "{\"n\": 11507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.51, \"learn_time_ms\": 8185.42, \"total_train_time_s\": 9.872736692428589}", "{\"n\": 11508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.27, \"learn_time_ms\": 8078.049, \"total_train_time_s\": 9.435045957565308}", "{\"n\": 11509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.27, \"learn_time_ms\": 8143.426, \"total_train_time_s\": 10.386436462402344}", "{\"n\": 11510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.27, \"learn_time_ms\": 8345.176, \"total_train_time_s\": 12.349567651748657}", "{\"n\": 11511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.94, \"learn_time_ms\": 8355.578, \"total_train_time_s\": 10.05286955833435}", "{\"n\": 11512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.51, \"learn_time_ms\": 8446.012, \"total_train_time_s\": 10.071608781814575}", "{\"n\": 11513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.51, \"learn_time_ms\": 8465.525, \"total_train_time_s\": 8.74630856513977}", "{\"n\": 11514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.46, \"learn_time_ms\": 8592.111, \"total_train_time_s\": 10.800552368164062}", "{\"n\": 11515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.02, \"learn_time_ms\": 8769.806, \"total_train_time_s\": 10.904403448104858}", "{\"n\": 11516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.02, \"learn_time_ms\": 8871.317, \"total_train_time_s\": 10.172581195831299}", "{\"n\": 11517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.47, \"learn_time_ms\": 8847.872, \"total_train_time_s\": 9.650351285934448}", "{\"n\": 11518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.41, \"learn_time_ms\": 8962.598, \"total_train_time_s\": 10.57057523727417}", "{\"n\": 11519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.78, \"learn_time_ms\": 8969.676, \"total_train_time_s\": 10.440525770187378}", "{\"n\": 11520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.71, \"learn_time_ms\": 8898.799, \"total_train_time_s\": 11.69495415687561}", "{\"n\": 11521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 8936.341, \"total_train_time_s\": 10.404123783111572}", "{\"n\": 11522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.01, \"learn_time_ms\": 8977.413, \"total_train_time_s\": 10.456671237945557}", "{\"n\": 11523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.01, \"learn_time_ms\": 9014.104, \"total_train_time_s\": 9.05235505104065}", "{\"n\": 11524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.27, \"learn_time_ms\": 8974.201, \"total_train_time_s\": 10.382250785827637}", "{\"n\": 11525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.62, \"learn_time_ms\": 9000.767, \"total_train_time_s\": 11.171737909317017}", "{\"n\": 11526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.93, \"learn_time_ms\": 9040.192, \"total_train_time_s\": 10.599562406539917}", "{\"n\": 11527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.84, \"learn_time_ms\": 9112.722, \"total_train_time_s\": 10.33701467514038}", "{\"n\": 11528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.41, \"learn_time_ms\": 8981.643, \"total_train_time_s\": 9.30022406578064}", "{\"n\": 11529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.55, \"learn_time_ms\": 8828.025, \"total_train_time_s\": 8.910155296325684}", "{\"n\": 11530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.55, \"learn_time_ms\": 8731.061, \"total_train_time_s\": 10.660784721374512}", "{\"n\": 11531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.5, \"learn_time_ms\": 8682.929, \"total_train_time_s\": 9.950205087661743}", "{\"n\": 11532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.05, \"learn_time_ms\": 8628.871, \"total_train_time_s\": 9.944860219955444}", "{\"n\": 11533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.05, \"learn_time_ms\": 8662.781, \"total_train_time_s\": 9.436182022094727}", "{\"n\": 11534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.51, \"learn_time_ms\": 8585.836, \"total_train_time_s\": 9.651197671890259}", "{\"n\": 11535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.86, \"learn_time_ms\": 8517.77, \"total_train_time_s\": 10.535223245620728}", "{\"n\": 11536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.86, \"learn_time_ms\": 8341.342, \"total_train_time_s\": 8.831099271774292}", "{\"n\": 11537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.57, \"learn_time_ms\": 8325.162, \"total_train_time_s\": 10.204438209533691}", "{\"n\": 11538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8464.036, \"total_train_time_s\": 10.650466918945312}", "{\"n\": 11539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8476.759, \"total_train_time_s\": 9.031826972961426}", "{\"n\": 11540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.4, \"learn_time_ms\": 8306.992, \"total_train_time_s\": 8.995398998260498}", "{\"n\": 11541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3332.26, \"learn_time_ms\": 8339.881, \"total_train_time_s\": 10.263526439666748}", "{\"n\": 11542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3333.85, \"learn_time_ms\": 8305.283, \"total_train_time_s\": 9.582140922546387}", "{\"n\": 11543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3333.85, \"learn_time_ms\": 8416.04, \"total_train_time_s\": 10.522966146469116}", "{\"n\": 11544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3329.21, \"learn_time_ms\": 8508.811, \"total_train_time_s\": 10.58363676071167}", "{\"n\": 11545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3326.74, \"learn_time_ms\": 8403.907, \"total_train_time_s\": 9.4671790599823}", "{\"n\": 11546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3326.74, \"learn_time_ms\": 8392.488, \"total_train_time_s\": 8.682076215744019}", "{\"n\": 11547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3327.44, \"learn_time_ms\": 8280.795, \"total_train_time_s\": 9.095303297042847}", "{\"n\": 11548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3330.01, \"learn_time_ms\": 8199.14, \"total_train_time_s\": 9.776254177093506}", "{\"n\": 11549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3330.01, \"learn_time_ms\": 8096.296, \"total_train_time_s\": 7.976884365081787}", "{\"n\": 11550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3328.58, \"learn_time_ms\": 8128.162, \"total_train_time_s\": 9.307801961898804}", "{\"n\": 11551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3324.4, \"learn_time_ms\": 8001.416, \"total_train_time_s\": 9.067978620529175}", "{\"n\": 11552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3324.4, \"learn_time_ms\": 8125.802, \"total_train_time_s\": 10.83285665512085}", "{\"n\": 11553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3319.74, \"learn_time_ms\": 8069.794, \"total_train_time_s\": 9.987500667572021}", "{\"n\": 11554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3325.98, \"learn_time_ms\": 8095.364, \"total_train_time_s\": 10.844304084777832}", "{\"n\": 11555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3325.98, \"learn_time_ms\": 8062.713, \"total_train_time_s\": 9.151525735855103}", "{\"n\": 11556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3327.78, \"learn_time_ms\": 8153.11, \"total_train_time_s\": 9.600973844528198}", "{\"n\": 11557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3317.95, \"learn_time_ms\": 8197.204, \"total_train_time_s\": 9.551937103271484}", "{\"n\": 11558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3316.45, \"learn_time_ms\": 8130.322, \"total_train_time_s\": 9.13809871673584}", "{\"n\": 11559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3316.45, \"learn_time_ms\": 8253.798, \"total_train_time_s\": 9.178457498550415}", "{\"n\": 11560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.24, \"learn_time_ms\": 8393.44, \"total_train_time_s\": 10.73818564414978}", "{\"n\": 11561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.0, \"learn_time_ms\": 8477.966, \"total_train_time_s\": 9.904954671859741}", "{\"n\": 11562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.0, \"learn_time_ms\": 8523.835, \"total_train_time_s\": 11.277819633483887}", "{\"n\": 11563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3312.26, \"learn_time_ms\": 8462.306, \"total_train_time_s\": 9.35346508026123}", "{\"n\": 11564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3320.22, \"learn_time_ms\": 8431.164, \"total_train_time_s\": 10.498935461044312}", "{\"n\": 11565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3320.22, \"learn_time_ms\": 8543.714, \"total_train_time_s\": 10.201783895492554}", "{\"n\": 11566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3320.22, \"learn_time_ms\": 8664.675, \"total_train_time_s\": 10.804073810577393}", "{\"n\": 11567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3326.05, \"learn_time_ms\": 8726.157, \"total_train_time_s\": 10.164666414260864}", "{\"n\": 11568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3330.68, \"learn_time_ms\": 8833.463, \"total_train_time_s\": 10.271571397781372}", "{\"n\": 11569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3330.68, \"learn_time_ms\": 8868.846, \"total_train_time_s\": 9.557535409927368}", "{\"n\": 11570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3334.46, \"learn_time_ms\": 8854.408, \"total_train_time_s\": 10.57837986946106}", "{\"n\": 11571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3345.14, \"learn_time_ms\": 8731.499, \"total_train_time_s\": 8.627280473709106}", "{\"n\": 11572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3345.14, \"learn_time_ms\": 8620.875, \"total_train_time_s\": 10.204642295837402}", "{\"n\": 11573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3338.79, \"learn_time_ms\": 8718.488, \"total_train_time_s\": 10.358741044998169}", "{\"n\": 11574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3339.34, \"learn_time_ms\": 8525.919, \"total_train_time_s\": 8.546040296554565}", "{\"n\": 11575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3339.47, \"learn_time_ms\": 8509.769, \"total_train_time_s\": 10.08223032951355}", "{\"n\": 11576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3334.21, \"learn_time_ms\": 8452.028, \"total_train_time_s\": 10.269579648971558}", "{\"n\": 11577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3336.64, \"learn_time_ms\": 8401.671, \"total_train_time_s\": 9.62092661857605}", "{\"n\": 11578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3338.22, \"learn_time_ms\": 8355.998, \"total_train_time_s\": 9.763553142547607}", "{\"n\": 11579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3330.56, \"learn_time_ms\": 8362.363, \"total_train_time_s\": 9.64083194732666}", "{\"n\": 11580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3332.91, \"learn_time_ms\": 8291.087, \"total_train_time_s\": 9.865270853042603}", "{\"n\": 11581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3328.82, \"learn_time_ms\": 8414.348, \"total_train_time_s\": 9.85125184059143}", "{\"n\": 11582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3328.82, \"learn_time_ms\": 8560.148, \"total_train_time_s\": 11.641851425170898}", "{\"n\": 11583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3327.55, \"learn_time_ms\": 8484.244, \"total_train_time_s\": 9.61260175704956}", "{\"n\": 11584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3333.59, \"learn_time_ms\": 8691.454, \"total_train_time_s\": 10.630342721939087}", "{\"n\": 11585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3328.73, \"learn_time_ms\": 8557.846, \"total_train_time_s\": 8.744196653366089}", "{\"n\": 11586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3328.73, \"learn_time_ms\": 8551.27, \"total_train_time_s\": 10.163944482803345}", "{\"n\": 11587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 8652.438, \"total_train_time_s\": 10.665276288986206}", "{\"n\": 11588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 8681.802, \"total_train_time_s\": 10.108222961425781}", "{\"n\": 11589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 8649.851, \"total_train_time_s\": 9.410077095031738}", "{\"n\": 11590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3325.38, \"learn_time_ms\": 8739.987, \"total_train_time_s\": 10.768950462341309}", "{\"n\": 11591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3316.83, \"learn_time_ms\": 8777.886, \"total_train_time_s\": 10.251461029052734}", "{\"n\": 11592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3316.83, \"learn_time_ms\": 8578.957, \"total_train_time_s\": 9.67422890663147}", "{\"n\": 11593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3318.29, \"learn_time_ms\": 8684.79, \"total_train_time_s\": 10.645920515060425}", "{\"n\": 11594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3317.01, \"learn_time_ms\": 8660.431, \"total_train_time_s\": 10.38924503326416}", "{\"n\": 11595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3317.01, \"learn_time_ms\": 8815.298, \"total_train_time_s\": 10.307679176330566}", "{\"n\": 11596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3314.81, \"learn_time_ms\": 8831.438, \"total_train_time_s\": 10.334194421768188}", "{\"n\": 11597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.15, \"learn_time_ms\": 8754.143, \"total_train_time_s\": 9.905154705047607}", "{\"n\": 11598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.15, \"learn_time_ms\": 8628.214, \"total_train_time_s\": 8.764256000518799}", "{\"n\": 11599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3307.49, \"learn_time_ms\": 8687.697, \"total_train_time_s\": 9.969632625579834}", "{\"n\": 11600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3308.11, \"learn_time_ms\": 8635.106, \"total_train_time_s\": 10.270307064056396}", "{\"n\": 11601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3306.02, \"learn_time_ms\": 8524.11, \"total_train_time_s\": 9.089736461639404}", "{\"n\": 11602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3306.02, \"learn_time_ms\": 8674.963, \"total_train_time_s\": 11.17798376083374}", "{\"n\": 11603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3302.17, \"learn_time_ms\": 8592.645, \"total_train_time_s\": 9.818043231964111}", "{\"n\": 11604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 8504.524, \"total_train_time_s\": 9.47166109085083}", "{\"n\": 11605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 8357.613, \"total_train_time_s\": 8.811215877532959}", "{\"n\": 11606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3310.22, \"learn_time_ms\": 8313.755, \"total_train_time_s\": 9.904730319976807}", "{\"n\": 11607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3310.2, \"learn_time_ms\": 8447.766, \"total_train_time_s\": 11.194211483001709}", "{\"n\": 11608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3310.14, \"learn_time_ms\": 8582.563, \"total_train_time_s\": 10.140446662902832}", "{\"n\": 11609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3310.14, \"learn_time_ms\": 8626.175, \"total_train_time_s\": 10.380507946014404}", "{\"n\": 11610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3311.3, \"learn_time_ms\": 8519.041, \"total_train_time_s\": 9.14861249923706}", "{\"n\": 11611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3313.48, \"learn_time_ms\": 8505.683, \"total_train_time_s\": 8.96847915649414}", "{\"n\": 11612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3313.03, \"learn_time_ms\": 8424.539, \"total_train_time_s\": 10.32430386543274}", "{\"n\": 11613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3316.05, \"learn_time_ms\": 8475.369, \"total_train_time_s\": 10.334356784820557}", "{\"n\": 11614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3324.53, \"learn_time_ms\": 8538.954, \"total_train_time_s\": 10.144261360168457}", "{\"n\": 11615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3324.53, \"learn_time_ms\": 8662.62, \"total_train_time_s\": 10.084529638290405}", "{\"n\": 11616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3329.95, \"learn_time_ms\": 8618.9, \"total_train_time_s\": 9.489393711090088}", "{\"n\": 11617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3333.71, \"learn_time_ms\": 8424.159, \"total_train_time_s\": 9.252524375915527}", "{\"n\": 11618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3334.79, \"learn_time_ms\": 8489.69, \"total_train_time_s\": 10.79412293434143}", "{\"n\": 11619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3342.96, \"learn_time_ms\": 8372.985, \"total_train_time_s\": 9.192582130432129}", "{\"n\": 11620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3342.96, \"learn_time_ms\": 8547.232, \"total_train_time_s\": 10.892906188964844}", "{\"n\": 11621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3343.94, \"learn_time_ms\": 8494.71, \"total_train_time_s\": 8.471041440963745}", "{\"n\": 11622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8319.066, \"total_train_time_s\": 8.572997093200684}", "{\"n\": 11623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8250.401, \"total_train_time_s\": 9.636672735214233}", "{\"n\": 11624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.59, \"learn_time_ms\": 8301.184, \"total_train_time_s\": 10.648791551589966}", "{\"n\": 11625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.28, \"learn_time_ms\": 8327.779, \"total_train_time_s\": 10.293228387832642}", "{\"n\": 11626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.63, \"learn_time_ms\": 8309.6, \"total_train_time_s\": 9.270735263824463}", "{\"n\": 11627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.22, \"learn_time_ms\": 8455.528, \"total_train_time_s\": 10.684644222259521}", "{\"n\": 11628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.93, \"learn_time_ms\": 8434.272, \"total_train_time_s\": 10.588115692138672}", "{\"n\": 11629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.93, \"learn_time_ms\": 8509.462, \"total_train_time_s\": 9.953885793685913}", "{\"n\": 11630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.29, \"learn_time_ms\": 8428.121, \"total_train_time_s\": 10.158811092376709}", "{\"n\": 11631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.17, \"learn_time_ms\": 8649.038, \"total_train_time_s\": 10.699274778366089}", "{\"n\": 11632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.62, \"learn_time_ms\": 8838.767, \"total_train_time_s\": 10.514074325561523}", "{\"n\": 11633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.53, \"learn_time_ms\": 8953.584, \"total_train_time_s\": 10.728397130966187}", "{\"n\": 11634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.62, \"learn_time_ms\": 8959.353, \"total_train_time_s\": 10.711568117141724}", "{\"n\": 11635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.61, \"learn_time_ms\": 8996.273, \"total_train_time_s\": 10.725020170211792}", "{\"n\": 11636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.61, \"learn_time_ms\": 8912.168, \"total_train_time_s\": 8.409493684768677}", "{\"n\": 11637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.38, \"learn_time_ms\": 8770.739, \"total_train_time_s\": 9.274578332901001}", "{\"n\": 11638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.85, \"learn_time_ms\": 8671.706, \"total_train_time_s\": 9.603739976882935}", "{\"n\": 11639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.76, \"learn_time_ms\": 8811.59, \"total_train_time_s\": 11.33390736579895}", "{\"n\": 11640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.51, \"learn_time_ms\": 8882.1, \"total_train_time_s\": 10.7732253074646}", "{\"n\": 11641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.66, \"learn_time_ms\": 8719.04, \"total_train_time_s\": 9.02205491065979}", "{\"n\": 11642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.55, \"learn_time_ms\": 8568.259, \"total_train_time_s\": 8.987888097763062}", "{\"n\": 11643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.55, \"learn_time_ms\": 8414.96, \"total_train_time_s\": 9.206584930419922}", "{\"n\": 11644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.95, \"learn_time_ms\": 8177.254, \"total_train_time_s\": 8.338674306869507}", "{\"n\": 11645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.58, \"learn_time_ms\": 8211.666, \"total_train_time_s\": 11.091073751449585}", "{\"n\": 11646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.11, \"learn_time_ms\": 8379.043, \"total_train_time_s\": 10.116618156433105}", "{\"n\": 11647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.68, \"learn_time_ms\": 8463.23, \"total_train_time_s\": 10.139633417129517}", "{\"n\": 11648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.6, \"learn_time_ms\": 8663.245, \"total_train_time_s\": 11.605150699615479}", "{\"n\": 11649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.26, \"learn_time_ms\": 8448.488, \"total_train_time_s\": 9.130457878112793}", "{\"n\": 11650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.8, \"learn_time_ms\": 8494.026, \"total_train_time_s\": 11.276553392410278}", "{\"n\": 11651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.92, \"learn_time_ms\": 8618.988, \"total_train_time_s\": 10.349854946136475}", "{\"n\": 11652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.58, \"learn_time_ms\": 8827.086, \"total_train_time_s\": 11.026694536209106}", "{\"n\": 11653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.33, \"learn_time_ms\": 9061.051, \"total_train_time_s\": 11.608521699905396}", "{\"n\": 11654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.24, \"learn_time_ms\": 9178.599, \"total_train_time_s\": 9.51179313659668}", "{\"n\": 11655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.5, \"learn_time_ms\": 9055.591, \"total_train_time_s\": 9.799983501434326}", "{\"n\": 11656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.29, \"learn_time_ms\": 9055.287, \"total_train_time_s\": 10.156134366989136}", "{\"n\": 11657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.51, \"learn_time_ms\": 9082.05, \"total_train_time_s\": 10.417526960372925}", "{\"n\": 11658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.51, \"learn_time_ms\": 8986.978, \"total_train_time_s\": 10.661177158355713}", "{\"n\": 11659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.15, \"learn_time_ms\": 9035.996, \"total_train_time_s\": 9.732842683792114}", "{\"n\": 11660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.88, \"learn_time_ms\": 8866.976, \"total_train_time_s\": 9.573227167129517}", "{\"n\": 11661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.17, \"learn_time_ms\": 8871.045, \"total_train_time_s\": 10.282731533050537}", "{\"n\": 11662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.17, \"learn_time_ms\": 8771.107, \"total_train_time_s\": 10.027548551559448}", "{\"n\": 11663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.35, \"learn_time_ms\": 8646.864, \"total_train_time_s\": 10.31162142753601}", "{\"n\": 11664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.59, \"learn_time_ms\": 8666.092, \"total_train_time_s\": 9.71126914024353}", "{\"n\": 11665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.27, \"learn_time_ms\": 8737.757, \"total_train_time_s\": 10.564225673675537}", "{\"n\": 11666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.97, \"learn_time_ms\": 8765.43, \"total_train_time_s\": 10.3788583278656}", "{\"n\": 11667, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.7, \"learn_time_ms\": 8690.012, \"total_train_time_s\": 9.676858901977539}", "{\"n\": 11668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 8702.824, \"total_train_time_s\": 10.789726734161377}", "{\"n\": 11669, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 8661.261, \"total_train_time_s\": 9.260097742080688}", "{\"n\": 11670, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.0, \"learn_time_ms\": 8720.984, \"total_train_time_s\": 10.148529529571533}", "{\"n\": 11671, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.0, \"learn_time_ms\": 8658.718, \"total_train_time_s\": 9.678696393966675}", "{\"n\": 11672, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.09, \"learn_time_ms\": 8765.797, \"total_train_time_s\": 11.135525941848755}", "{\"n\": 11673, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.82, \"learn_time_ms\": 8777.492, \"total_train_time_s\": 10.46297311782837}", "{\"n\": 11674, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.04, \"learn_time_ms\": 8866.494, \"total_train_time_s\": 10.592535257339478}", "{\"n\": 11675, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.04, \"learn_time_ms\": 8711.87, \"total_train_time_s\": 8.987909078598022}", "{\"n\": 11676, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.69, \"learn_time_ms\": 8622.398, \"total_train_time_s\": 9.484441995620728}", "{\"n\": 11677, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.24, \"learn_time_ms\": 8766.461, \"total_train_time_s\": 11.069215297698975}", "{\"n\": 11678, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.24, \"learn_time_ms\": 8686.458, \"total_train_time_s\": 9.954508066177368}", "{\"n\": 11679, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.83, \"learn_time_ms\": 8772.063, \"total_train_time_s\": 10.122543334960938}", "{\"n\": 11680, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.49, \"learn_time_ms\": 8822.76, \"total_train_time_s\": 10.622945547103882}", "{\"n\": 11681, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.68, \"learn_time_ms\": 8780.864, \"total_train_time_s\": 9.263222455978394}", "{\"n\": 11682, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.9, \"learn_time_ms\": 8534.865, \"total_train_time_s\": 8.69139313697815}", "{\"n\": 11683, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.51, \"learn_time_ms\": 8426.956, \"total_train_time_s\": 9.405524730682373}", "{\"n\": 11684, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.51, \"learn_time_ms\": 8424.641, \"total_train_time_s\": 10.58347487449646}", "{\"n\": 11685, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.64, \"learn_time_ms\": 8556.432, \"total_train_time_s\": 10.308358192443848}", "{\"n\": 11686, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.95, \"learn_time_ms\": 8498.696, \"total_train_time_s\": 8.956616401672363}", "{\"n\": 11687, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.78, \"learn_time_ms\": 8295.656, \"total_train_time_s\": 9.069634675979614}", "{\"n\": 11688, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.63, \"learn_time_ms\": 8368.37, \"total_train_time_s\": 10.732651472091675}", "{\"n\": 11689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.74, \"learn_time_ms\": 8514.596, \"total_train_time_s\": 11.596474885940552}", "{\"n\": 11690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.31, \"learn_time_ms\": 8432.866, \"total_train_time_s\": 9.875428438186646}", "{\"n\": 11691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.4, \"learn_time_ms\": 8465.42, \"total_train_time_s\": 9.660031795501709}", "{\"n\": 11692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.38, \"learn_time_ms\": 8650.426, \"total_train_time_s\": 10.532358169555664}", "{\"n\": 11693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.07, \"learn_time_ms\": 8771.938, \"total_train_time_s\": 10.604115724563599}", "{\"n\": 11694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.66, \"learn_time_ms\": 8733.855, \"total_train_time_s\": 10.183980226516724}", "{\"n\": 11695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.75, \"learn_time_ms\": 8632.106, \"total_train_time_s\": 9.32874321937561}", "{\"n\": 11696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.9, \"learn_time_ms\": 8788.135, \"total_train_time_s\": 10.463987588882446}", "{\"n\": 11697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.9, \"learn_time_ms\": 8820.961, \"total_train_time_s\": 9.425466537475586}", "{\"n\": 11698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.54, \"learn_time_ms\": 8804.426, \"total_train_time_s\": 10.59163212776184}", "{\"n\": 11699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.64, \"learn_time_ms\": 8753.322, \"total_train_time_s\": 11.079600811004639}", "{\"n\": 11700, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.64, \"learn_time_ms\": 8963.472, \"total_train_time_s\": 11.994404792785645}", "{\"n\": 11701, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.07, \"learn_time_ms\": 9149.177, \"total_train_time_s\": 11.495716571807861}", "{\"n\": 11702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.66, \"learn_time_ms\": 9220.908, \"total_train_time_s\": 11.223673582077026}", "{\"n\": 11703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.66, \"learn_time_ms\": 9021.271, \"total_train_time_s\": 8.558188438415527}", "{\"n\": 11704, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.31, \"learn_time_ms\": 9070.925, \"total_train_time_s\": 10.675800085067749}", "{\"n\": 11705, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.61, \"learn_time_ms\": 9248.216, \"total_train_time_s\": 11.084080934524536}", "{\"n\": 11706, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 9224.266, \"total_train_time_s\": 10.221180438995361}", "{\"n\": 11707, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.24, \"learn_time_ms\": 9262.784, \"total_train_time_s\": 9.78637146949768}", "{\"n\": 11708, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.82, \"learn_time_ms\": 9277.584, \"total_train_time_s\": 10.680238246917725}", "{\"n\": 11709, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.56, \"learn_time_ms\": 9270.174, \"total_train_time_s\": 10.992267370223999}", "{\"n\": 11710, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.33, \"learn_time_ms\": 9063.214, \"total_train_time_s\": 9.854600429534912}", "{\"n\": 11711, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.73, \"learn_time_ms\": 8912.393, \"total_train_time_s\": 9.97588062286377}", "{\"n\": 11712, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 8923.797, \"total_train_time_s\": 11.382850646972656}", "{\"n\": 11713, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.85, \"learn_time_ms\": 8997.307, \"total_train_time_s\": 9.351016521453857}", "{\"n\": 11714, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.55, \"learn_time_ms\": 8924.241, \"total_train_time_s\": 9.962672233581543}", "{\"n\": 11715, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.55, \"learn_time_ms\": 8915.576, \"total_train_time_s\": 10.990315437316895}", "{\"n\": 11716, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.93, \"learn_time_ms\": 8892.821, \"total_train_time_s\": 10.046180248260498}", "{\"n\": 11717, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.62, \"learn_time_ms\": 8900.38, \"total_train_time_s\": 9.886945962905884}", "{\"n\": 11718, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.62, \"learn_time_ms\": 8762.187, \"total_train_time_s\": 9.298119068145752}", "{\"n\": 11719, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.11, \"learn_time_ms\": 8645.677, \"total_train_time_s\": 9.83286714553833}", "{\"n\": 11720, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.49, \"learn_time_ms\": 8598.789, \"total_train_time_s\": 9.404806852340698}", "{\"n\": 11721, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.49, \"learn_time_ms\": 8653.652, \"total_train_time_s\": 10.553560256958008}", "{\"n\": 11722, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.34, \"learn_time_ms\": 8530.181, \"total_train_time_s\": 10.14395809173584}", "{\"n\": 11723, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.79, \"learn_time_ms\": 8719.756, \"total_train_time_s\": 11.211808443069458}", "{\"n\": 11724, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.79, \"learn_time_ms\": 8764.921, \"total_train_time_s\": 10.361928224563599}", "{\"n\": 11725, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.82, \"learn_time_ms\": 8504.711, \"total_train_time_s\": 8.390464782714844}", "{\"n\": 11726, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.3, \"learn_time_ms\": 8581.169, \"total_train_time_s\": 10.752671957015991}", "{\"n\": 11727, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.73, \"learn_time_ms\": 8548.276, \"total_train_time_s\": 9.537219524383545}", "{\"n\": 11728, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.73, \"learn_time_ms\": 8540.103, \"total_train_time_s\": 9.249498128890991}", "{\"n\": 11729, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.25, \"learn_time_ms\": 8471.486, \"total_train_time_s\": 9.166314125061035}", "{\"n\": 11730, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.11, \"learn_time_ms\": 8515.997, \"total_train_time_s\": 9.846100330352783}", "{\"n\": 11731, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.11, \"learn_time_ms\": 8578.12, \"total_train_time_s\": 11.116977214813232}", "{\"n\": 11732, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.08, \"learn_time_ms\": 8643.748, \"total_train_time_s\": 10.834147930145264}", "{\"n\": 11733, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.09, \"learn_time_ms\": 8608.532, \"total_train_time_s\": 10.891392946243286}", "{\"n\": 11734, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.09, \"learn_time_ms\": 8583.278, \"total_train_time_s\": 10.168230533599854}", "{\"n\": 11735, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.72, \"learn_time_ms\": 8755.619, \"total_train_time_s\": 10.0896635055542}", "{\"n\": 11736, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.31, \"learn_time_ms\": 8664.058, \"total_train_time_s\": 9.89776611328125}", "{\"n\": 11737, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.21, \"learn_time_ms\": 8674.189, \"total_train_time_s\": 9.6558837890625}", "{\"n\": 11738, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.89, \"learn_time_ms\": 8839.685, \"total_train_time_s\": 10.84552550315857}", "{\"n\": 11739, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.89, \"learn_time_ms\": 8925.532, \"total_train_time_s\": 9.997382879257202}", "{\"n\": 11740, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.62, \"learn_time_ms\": 9011.797, \"total_train_time_s\": 10.763669490814209}", "{\"n\": 11741, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.62, \"learn_time_ms\": 9099.441, \"total_train_time_s\": 12.004805564880371}", "{\"n\": 11742, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.38, \"learn_time_ms\": 8966.537, \"total_train_time_s\": 9.438232660293579}", "{\"n\": 11743, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.37, \"learn_time_ms\": 8900.251, \"total_train_time_s\": 10.213239192962646}", "{\"n\": 11744, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.37, \"learn_time_ms\": 8885.338, \"total_train_time_s\": 9.967496633529663}", "{\"n\": 11745, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.55, \"learn_time_ms\": 8951.28, \"total_train_time_s\": 10.766175746917725}", "{\"n\": 11746, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.06, \"learn_time_ms\": 8976.842, \"total_train_time_s\": 10.157468557357788}", "{\"n\": 11747, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3304.19, \"learn_time_ms\": 8905.232, \"total_train_time_s\": 8.899103164672852}", "{\"n\": 11748, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.83, \"learn_time_ms\": 8625.402, \"total_train_time_s\": 8.094850540161133}", "{\"n\": 11749, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8595.373, \"total_train_time_s\": 9.734166860580444}", "{\"n\": 11750, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.84, \"learn_time_ms\": 8501.219, \"total_train_time_s\": 9.792596817016602}", "{\"n\": 11751, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.84, \"learn_time_ms\": 8158.041, \"total_train_time_s\": 8.612715005874634}", "{\"n\": 11752, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.65, \"learn_time_ms\": 8086.752, \"total_train_time_s\": 8.767282247543335}", "{\"n\": 11753, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.76, \"learn_time_ms\": 8100.684, \"total_train_time_s\": 10.37067461013794}", "{\"n\": 11754, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.76, \"learn_time_ms\": 8127.374, \"total_train_time_s\": 10.30742883682251}", "{\"n\": 11755, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3291.48, \"learn_time_ms\": 8124.438, \"total_train_time_s\": 10.738252401351929}", "{\"n\": 11756, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.2, \"learn_time_ms\": 8010.104, \"total_train_time_s\": 8.987028360366821}", "{\"n\": 11757, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.2, \"learn_time_ms\": 8265.639, \"total_train_time_s\": 11.465189218521118}", "{\"n\": 11758, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.2, \"learn_time_ms\": 8494.153, \"total_train_time_s\": 10.381303071975708}", "{\"n\": 11759, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3294.96, \"learn_time_ms\": 8607.365, \"total_train_time_s\": 10.867115259170532}", "{\"n\": 11760, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.99, \"learn_time_ms\": 8531.023, \"total_train_time_s\": 9.029886960983276}", "{\"n\": 11761, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.99, \"learn_time_ms\": 8861.502, \"total_train_time_s\": 11.894896745681763}", "{\"n\": 11762, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.05, \"learn_time_ms\": 9064.945, \"total_train_time_s\": 10.790157794952393}", "{\"n\": 11763, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 9044.293, \"total_train_time_s\": 10.165875673294067}", "{\"n\": 11764, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.39, \"learn_time_ms\": 9001.199, \"total_train_time_s\": 9.845444917678833}", "{\"n\": 11765, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.91, \"learn_time_ms\": 8873.876, \"total_train_time_s\": 9.485516786575317}", "{\"n\": 11766, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.05, \"learn_time_ms\": 8956.223, \"total_train_time_s\": 9.80724549293518}", "{\"n\": 11767, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.05, \"learn_time_ms\": 8728.664, \"total_train_time_s\": 9.1957266330719}", "{\"n\": 11768, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.05, \"learn_time_ms\": 8653.835, \"total_train_time_s\": 9.606894254684448}", "{\"n\": 11769, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.97, \"learn_time_ms\": 8481.735, \"total_train_time_s\": 9.148726463317871}", "{\"n\": 11770, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.97, \"learn_time_ms\": 8528.936, \"total_train_time_s\": 9.437566757202148}", "{\"n\": 11771, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.74, \"learn_time_ms\": 8456.901, \"total_train_time_s\": 11.129281282424927}", "{\"n\": 11772, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.32, \"learn_time_ms\": 8329.524, \"total_train_time_s\": 9.50374460220337}", "{\"n\": 11773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.32, \"learn_time_ms\": 8404.929, \"total_train_time_s\": 10.8922278881073}", "{\"n\": 11774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.9, \"learn_time_ms\": 8417.913, \"total_train_time_s\": 9.967909812927246}", "{\"n\": 11775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3295.24, \"learn_time_ms\": 8461.403, \"total_train_time_s\": 9.903294801712036}", "{\"n\": 11776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3291.72, \"learn_time_ms\": 8455.121, \"total_train_time_s\": 9.736008405685425}", "{\"n\": 11777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.66, \"learn_time_ms\": 8532.999, \"total_train_time_s\": 9.984750032424927}", "{\"n\": 11778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.15, \"learn_time_ms\": 8652.018, \"total_train_time_s\": 10.815309286117554}", "{\"n\": 11779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.42, \"learn_time_ms\": 8708.416, \"total_train_time_s\": 9.722350835800171}", "{\"n\": 11780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.32, \"learn_time_ms\": 8745.512, \"total_train_time_s\": 9.880932807922363}", "{\"n\": 11781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.79, \"learn_time_ms\": 8651.66, \"total_train_time_s\": 10.249695539474487}", "{\"n\": 11782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3302.42, \"learn_time_ms\": 8591.909, \"total_train_time_s\": 8.902700901031494}", "{\"n\": 11783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3302.53, \"learn_time_ms\": 8471.235, \"total_train_time_s\": 9.704704999923706}", "{\"n\": 11784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.71, \"learn_time_ms\": 8571.219, \"total_train_time_s\": 10.940601587295532}", "{\"n\": 11785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.74, \"learn_time_ms\": 8607.933, \"total_train_time_s\": 10.284801959991455}", "{\"n\": 11786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.25, \"learn_time_ms\": 8600.887, \"total_train_time_s\": 9.64953088760376}", "{\"n\": 11787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.25, \"learn_time_ms\": 8524.286, \"total_train_time_s\": 9.235373497009277}", "{\"n\": 11788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 8305.984, \"total_train_time_s\": 8.611860990524292}", "{\"n\": 11789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 8552.238, \"total_train_time_s\": 12.140348196029663}", "{\"n\": 11790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3295.73, \"learn_time_ms\": 8536.375, \"total_train_time_s\": 9.77131986618042}", "{\"n\": 11791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.49, \"learn_time_ms\": 8398.015, \"total_train_time_s\": 8.843989610671997}", "{\"n\": 11792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.43, \"learn_time_ms\": 8403.427, \"total_train_time_s\": 8.965869665145874}", "{\"n\": 11793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3294.56, \"learn_time_ms\": 8437.327, \"total_train_time_s\": 10.056040525436401}", "{\"n\": 11794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3295.53, \"learn_time_ms\": 8281.097, \"total_train_time_s\": 9.386776685714722}", "{\"n\": 11795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3295.87, \"learn_time_ms\": 8330.393, \"total_train_time_s\": 10.762737035751343}", "{\"n\": 11796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.08, \"learn_time_ms\": 8219.631, \"total_train_time_s\": 8.522478342056274}", "{\"n\": 11797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.08, \"learn_time_ms\": 8315.667, \"total_train_time_s\": 10.183036088943481}", "{\"n\": 11798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.47, \"learn_time_ms\": 8533.859, \"total_train_time_s\": 10.815064430236816}", "{\"n\": 11799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.12, \"learn_time_ms\": 8393.095, \"total_train_time_s\": 10.725972890853882}", "{\"n\": 11800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.12, \"learn_time_ms\": 8514.365, \"total_train_time_s\": 10.907531261444092}", "{\"n\": 11801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.2, \"learn_time_ms\": 8465.177, \"total_train_time_s\": 8.430737018585205}", "{\"n\": 11802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.43, \"learn_time_ms\": 8595.707, \"total_train_time_s\": 10.254220247268677}", "{\"n\": 11803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.43, \"learn_time_ms\": 8542.63, \"total_train_time_s\": 9.486396312713623}", "{\"n\": 11804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.08, \"learn_time_ms\": 8590.962, \"total_train_time_s\": 9.889622211456299}", "{\"n\": 11805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.07, \"learn_time_ms\": 8440.461, \"total_train_time_s\": 9.251685619354248}", "{\"n\": 11806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.75, \"learn_time_ms\": 8563.359, \"total_train_time_s\": 9.763624906539917}", "{\"n\": 11807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.75, \"learn_time_ms\": 8575.229, \"total_train_time_s\": 10.249493837356567}", "{\"n\": 11808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.11, \"learn_time_ms\": 8536.828, \"total_train_time_s\": 10.398675203323364}", "{\"n\": 11809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.03, \"learn_time_ms\": 8702.042, \"total_train_time_s\": 12.365131616592407}", "{\"n\": 11810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.03, \"learn_time_ms\": 8569.834, \"total_train_time_s\": 9.534418106079102}", "{\"n\": 11811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.53, \"learn_time_ms\": 8675.523, \"total_train_time_s\": 9.419973134994507}", "{\"n\": 11812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.08, \"learn_time_ms\": 8624.994, \"total_train_time_s\": 9.803903341293335}", "{\"n\": 11813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.08, \"learn_time_ms\": 8559.74, \"total_train_time_s\": 8.85794186592102}", "{\"n\": 11814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.81, \"learn_time_ms\": 8556.938, \"total_train_time_s\": 9.945502042770386}", "{\"n\": 11815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.82, \"learn_time_ms\": 8668.05, \"total_train_time_s\": 10.4027099609375}", "{\"n\": 11816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.82, \"learn_time_ms\": 8567.577, \"total_train_time_s\": 8.85155177116394}", "{\"n\": 11817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3294.74, \"learn_time_ms\": 8491.333, \"total_train_time_s\": 9.536798238754272}", "{\"n\": 11818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.29, \"learn_time_ms\": 8406.915, \"total_train_time_s\": 9.630181074142456}", "{\"n\": 11819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.29, \"learn_time_ms\": 8069.665, \"total_train_time_s\": 9.012950420379639}", "{\"n\": 11820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.29, \"learn_time_ms\": 8048.55, \"total_train_time_s\": 9.319978713989258}", "{\"n\": 11821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.34, \"learn_time_ms\": 8114.348, \"total_train_time_s\": 10.045730829238892}", "{\"n\": 11822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.58, \"learn_time_ms\": 7983.154, \"total_train_time_s\": 8.414446592330933}", "{\"n\": 11823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.58, \"learn_time_ms\": 8175.216, \"total_train_time_s\": 10.753954887390137}", "{\"n\": 11824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.93, \"learn_time_ms\": 8276.228, \"total_train_time_s\": 10.863194942474365}", "{\"n\": 11825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.2, \"learn_time_ms\": 8180.379, \"total_train_time_s\": 9.417561292648315}", "{\"n\": 11826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.2, \"learn_time_ms\": 8209.636, \"total_train_time_s\": 9.061958312988281}", "{\"n\": 11827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.04, \"learn_time_ms\": 8320.402, \"total_train_time_s\": 10.59290862083435}", "{\"n\": 11828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.33, \"learn_time_ms\": 8414.329, \"total_train_time_s\": 10.4900643825531}", "{\"n\": 11829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.33, \"learn_time_ms\": 8377.354, \"total_train_time_s\": 8.625599384307861}", "{\"n\": 11830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.77, \"learn_time_ms\": 8533.862, \"total_train_time_s\": 10.972837924957275}", "{\"n\": 11831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.6, \"learn_time_ms\": 8605.574, \"total_train_time_s\": 10.788914680480957}", "{\"n\": 11832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.6, \"learn_time_ms\": 8676.546, \"total_train_time_s\": 9.15935492515564}", "{\"n\": 11833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.05, \"learn_time_ms\": 8472.881, \"total_train_time_s\": 8.729710578918457}", "{\"n\": 11834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.38, \"learn_time_ms\": 8545.168, \"total_train_time_s\": 11.553561449050903}", "{\"n\": 11835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.38, \"learn_time_ms\": 8541.829, \"total_train_time_s\": 9.336885452270508}", "{\"n\": 11836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.96, \"learn_time_ms\": 8665.148, \"total_train_time_s\": 10.281918048858643}", "{\"n\": 11837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.87, \"learn_time_ms\": 8711.506, \"total_train_time_s\": 11.102088212966919}", "{\"n\": 11838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.69, \"learn_time_ms\": 8639.518, \"total_train_time_s\": 9.800350427627563}", "{\"n\": 11839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.81, \"learn_time_ms\": 8858.588, \"total_train_time_s\": 10.84801197052002}", "{\"n\": 11840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.09, \"learn_time_ms\": 8677.601, \"total_train_time_s\": 9.076880931854248}", "{\"n\": 11841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.82, \"learn_time_ms\": 8815.348, \"total_train_time_s\": 12.151980876922607}", "{\"n\": 11842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.82, \"learn_time_ms\": 8814.276, \"total_train_time_s\": 9.139889478683472}", "{\"n\": 11843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.69, \"learn_time_ms\": 8786.089, \"total_train_time_s\": 8.463414192199707}", "{\"n\": 11844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.05, \"learn_time_ms\": 8661.205, \"total_train_time_s\": 10.347636461257935}", "{\"n\": 11845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.05, \"learn_time_ms\": 8833.706, \"total_train_time_s\": 11.08383297920227}", "{\"n\": 11846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.93, \"learn_time_ms\": 8889.929, \"total_train_time_s\": 10.905982255935669}", "{\"n\": 11847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.06, \"learn_time_ms\": 8833.995, \"total_train_time_s\": 10.565987586975098}", "{\"n\": 11848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.75, \"learn_time_ms\": 8866.175, \"total_train_time_s\": 10.106693744659424}", "{\"n\": 11849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.4, \"learn_time_ms\": 8714.582, \"total_train_time_s\": 9.316208600997925}", "{\"n\": 11850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.06, \"learn_time_ms\": 8730.479, \"total_train_time_s\": 9.326733350753784}", "{\"n\": 11851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.59, \"learn_time_ms\": 8469.633, \"total_train_time_s\": 9.585441827774048}", "{\"n\": 11852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.12, \"learn_time_ms\": 8452.941, \"total_train_time_s\": 8.988024234771729}", "{\"n\": 11853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.58, \"learn_time_ms\": 8515.014, \"total_train_time_s\": 9.075825929641724}", "{\"n\": 11854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.84, \"learn_time_ms\": 8505.467, \"total_train_time_s\": 10.26863980293274}", "{\"n\": 11855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.84, \"learn_time_ms\": 8367.963, \"total_train_time_s\": 9.745031118392944}", "{\"n\": 11856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.43, \"learn_time_ms\": 8314.246, \"total_train_time_s\": 10.386866807937622}", "{\"n\": 11857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.13, \"learn_time_ms\": 8238.008, \"total_train_time_s\": 9.83922266960144}", "{\"n\": 11858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.72, \"learn_time_ms\": 8301.993, \"total_train_time_s\": 10.81258511543274}", "{\"n\": 11859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.7, \"learn_time_ms\": 8486.205, \"total_train_time_s\": 11.190322875976562}", "{\"n\": 11860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.87, \"learn_time_ms\": 8431.232, \"total_train_time_s\": 8.740391254425049}", "{\"n\": 11861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.23, \"learn_time_ms\": 8445.087, \"total_train_time_s\": 9.66301441192627}", "{\"n\": 11862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.11, \"learn_time_ms\": 8437.492, \"total_train_time_s\": 8.913142681121826}", "{\"n\": 11863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.83, \"learn_time_ms\": 8606.493, \"total_train_time_s\": 10.754522562026978}", "{\"n\": 11864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.69, \"learn_time_ms\": 8635.92, \"total_train_time_s\": 10.591577529907227}", "{\"n\": 11865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.6, \"learn_time_ms\": 8573.751, \"total_train_time_s\": 9.1079261302948}", "{\"n\": 11866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.6, \"learn_time_ms\": 8544.384, \"total_train_time_s\": 10.00185489654541}", "{\"n\": 11867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.06, \"learn_time_ms\": 8647.638, \"total_train_time_s\": 10.808706998825073}", "{\"n\": 11868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.98, \"learn_time_ms\": 8618.107, \"total_train_time_s\": 10.466002464294434}", "{\"n\": 11869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.73, \"learn_time_ms\": 8527.105, \"total_train_time_s\": 10.236867189407349}", "{\"n\": 11870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.96, \"learn_time_ms\": 8647.998, \"total_train_time_s\": 9.966597080230713}", "{\"n\": 11871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.28, \"learn_time_ms\": 8773.844, \"total_train_time_s\": 10.923489332199097}", "{\"n\": 11872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.95, \"learn_time_ms\": 8869.319, \"total_train_time_s\": 9.796483039855957}", "{\"n\": 11873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.21, \"learn_time_ms\": 8846.961, \"total_train_time_s\": 10.5417160987854}", "{\"n\": 11874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.87, \"learn_time_ms\": 8764.059, \"total_train_time_s\": 9.778981685638428}", "{\"n\": 11875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.52, \"learn_time_ms\": 8957.79, \"total_train_time_s\": 11.03069019317627}", "{\"n\": 11876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.52, \"learn_time_ms\": 8951.581, \"total_train_time_s\": 9.964561939239502}", "{\"n\": 11877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.86, \"learn_time_ms\": 8820.701, \"total_train_time_s\": 9.521029472351074}", "{\"n\": 11878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.19, \"learn_time_ms\": 8761.212, \"total_train_time_s\": 9.945181369781494}", "{\"n\": 11879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.19, \"learn_time_ms\": 8796.945, \"total_train_time_s\": 10.616279602050781}", "{\"n\": 11880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.49, \"learn_time_ms\": 8922.426, \"total_train_time_s\": 11.232342004776001}", "{\"n\": 11881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.13, \"learn_time_ms\": 8720.887, \"total_train_time_s\": 8.973819255828857}", "{\"n\": 11882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.13, \"learn_time_ms\": 8732.651, \"total_train_time_s\": 9.923523664474487}", "{\"n\": 11883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.43, \"learn_time_ms\": 8814.308, \"total_train_time_s\": 11.322511196136475}", "{\"n\": 11884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.85, \"learn_time_ms\": 8815.195, \"total_train_time_s\": 9.723856449127197}", "{\"n\": 11885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.85, \"learn_time_ms\": 8683.165, \"total_train_time_s\": 9.731491804122925}", "{\"n\": 11886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.42, \"learn_time_ms\": 8682.42, \"total_train_time_s\": 9.96390151977539}", "{\"n\": 11887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.88, \"learn_time_ms\": 8661.637, \"total_train_time_s\": 9.271734476089478}", "{\"n\": 11888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3262.04, \"learn_time_ms\": 8627.128, \"total_train_time_s\": 9.513518333435059}", "{\"n\": 11889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3262.04, \"learn_time_ms\": 8727.199, \"total_train_time_s\": 11.573062419891357}", "{\"n\": 11890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3266.64, \"learn_time_ms\": 8555.739, \"total_train_time_s\": 9.484214067459106}", "{\"n\": 11891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.89, \"learn_time_ms\": 8640.506, \"total_train_time_s\": 9.810457468032837}", "{\"n\": 11892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.89, \"learn_time_ms\": 8600.025, \"total_train_time_s\": 9.585407495498657}", "{\"n\": 11893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.47, \"learn_time_ms\": 8586.645, \"total_train_time_s\": 11.265886068344116}", "{\"n\": 11894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.76, \"learn_time_ms\": 8603.799, \"total_train_time_s\": 9.907161235809326}", "{\"n\": 11895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.76, \"learn_time_ms\": 8684.704, \"total_train_time_s\": 10.525097608566284}", "{\"n\": 11896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.76, \"learn_time_ms\": 8663.37, \"total_train_time_s\": 9.734493017196655}", "{\"n\": 11897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.94, \"learn_time_ms\": 8683.364, \"total_train_time_s\": 9.50217318534851}", "{\"n\": 11898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.94, \"learn_time_ms\": 8752.713, \"total_train_time_s\": 10.216178894042969}", "{\"n\": 11899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.94, \"learn_time_ms\": 8661.63, \"total_train_time_s\": 10.701146602630615}", "{\"n\": 11900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.07, \"learn_time_ms\": 8689.806, \"total_train_time_s\": 9.753471612930298}", "{\"n\": 11901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.72, \"learn_time_ms\": 8610.195, \"total_train_time_s\": 8.937727451324463}", "{\"n\": 11902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.72, \"learn_time_ms\": 8640.843, \"total_train_time_s\": 9.89126443862915}", "{\"n\": 11903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.1, \"learn_time_ms\": 8514.355, \"total_train_time_s\": 9.987116813659668}", "{\"n\": 11904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.1, \"learn_time_ms\": 8569.5, \"total_train_time_s\": 10.465407848358154}", "{\"n\": 11905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.1, \"learn_time_ms\": 8533.212, \"total_train_time_s\": 10.161283731460571}", "{\"n\": 11906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.85, \"learn_time_ms\": 8490.272, \"total_train_time_s\": 9.354994773864746}", "{\"n\": 11907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.96, \"learn_time_ms\": 8512.462, \"total_train_time_s\": 9.660584211349487}", "{\"n\": 11908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.96, \"learn_time_ms\": 8366.855, \"total_train_time_s\": 8.737622022628784}", "{\"n\": 11909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.38, \"learn_time_ms\": 8367.166, \"total_train_time_s\": 10.732854127883911}", "{\"n\": 11910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.82, \"learn_time_ms\": 8473.023, \"total_train_time_s\": 10.878502607345581}", "{\"n\": 11911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.82, \"learn_time_ms\": 8556.874, \"total_train_time_s\": 9.802564144134521}", "{\"n\": 11912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.77, \"learn_time_ms\": 8493.239, \"total_train_time_s\": 9.239931583404541}", "{\"n\": 11913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.09, \"learn_time_ms\": 8388.21, \"total_train_time_s\": 8.943771839141846}", "{\"n\": 11914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.09, \"learn_time_ms\": 8279.868, \"total_train_time_s\": 9.331768274307251}", "{\"n\": 11915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.65, \"learn_time_ms\": 8230.809, \"total_train_time_s\": 9.608771800994873}", "{\"n\": 11916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.39, \"learn_time_ms\": 8267.541, \"total_train_time_s\": 9.707594871520996}", "{\"n\": 11917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.56, \"learn_time_ms\": 8024.087, \"total_train_time_s\": 7.292307376861572}", "{\"n\": 11918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.56, \"learn_time_ms\": 8132.924, \"total_train_time_s\": 9.812936067581177}", "{\"n\": 11919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.93, \"learn_time_ms\": 8002.302, \"total_train_time_s\": 9.392511367797852}", "{\"n\": 11920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.48, \"learn_time_ms\": 8046.95, \"total_train_time_s\": 11.285104990005493}", "{\"n\": 11921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.52, \"learn_time_ms\": 7975.345, \"total_train_time_s\": 9.146318435668945}", "{\"n\": 11922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.93, \"learn_time_ms\": 8153.43, \"total_train_time_s\": 11.023019552230835}", "{\"n\": 11923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.72, \"learn_time_ms\": 8168.235, \"total_train_time_s\": 9.079056024551392}", "{\"n\": 11924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.66, \"learn_time_ms\": 8290.141, \"total_train_time_s\": 10.574053525924683}", "{\"n\": 11925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.89, \"learn_time_ms\": 8349.258, \"total_train_time_s\": 10.25571346282959}", "{\"n\": 11926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.9, \"learn_time_ms\": 8366.356, \"total_train_time_s\": 9.853027105331421}", "{\"n\": 11927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.54, \"learn_time_ms\": 8625.537, \"total_train_time_s\": 9.833320617675781}", "{\"n\": 11928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.54, \"learn_time_ms\": 8604.527, \"total_train_time_s\": 9.642157793045044}", "{\"n\": 11929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.61, \"learn_time_ms\": 8606.608, \"total_train_time_s\": 9.475436687469482}", "{\"n\": 11930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.97, \"learn_time_ms\": 8455.742, \"total_train_time_s\": 9.804892778396606}", "{\"n\": 11931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.97, \"learn_time_ms\": 8519.566, \"total_train_time_s\": 9.718581199645996}", "{\"n\": 11932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.94, \"learn_time_ms\": 8419.839, \"total_train_time_s\": 10.028608083724976}", "{\"n\": 11933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.22, \"learn_time_ms\": 8364.535, \"total_train_time_s\": 8.552939891815186}", "{\"n\": 11934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.79, \"learn_time_ms\": 8235.254, \"total_train_time_s\": 9.277565479278564}", "{\"n\": 11935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.96, \"learn_time_ms\": 8119.163, \"total_train_time_s\": 9.096534013748169}", "{\"n\": 11936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.16, \"learn_time_ms\": 8275.039, \"total_train_time_s\": 11.424701929092407}", "{\"n\": 11937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.28, \"learn_time_ms\": 8370.387, \"total_train_time_s\": 10.829254865646362}", "{\"n\": 11938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.28, \"learn_time_ms\": 8457.766, \"total_train_time_s\": 10.45675802230835}", "{\"n\": 11939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.59, \"learn_time_ms\": 8530.461, \"total_train_time_s\": 10.118939638137817}", "{\"n\": 11940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.92, \"learn_time_ms\": 8628.819, \"total_train_time_s\": 10.753242015838623}", "{\"n\": 11941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.46, \"learn_time_ms\": 8713.041, \"total_train_time_s\": 10.582270860671997}", "{\"n\": 11942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.2, \"learn_time_ms\": 8637.538, \"total_train_time_s\": 9.25956392288208}", "{\"n\": 11943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.02, \"learn_time_ms\": 8742.142, \"total_train_time_s\": 9.487244606018066}", "{\"n\": 11944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.02, \"learn_time_ms\": 8830.969, \"total_train_time_s\": 10.138882160186768}", "{\"n\": 11945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.12, \"learn_time_ms\": 8963.906, \"total_train_time_s\": 10.386972904205322}", "{\"n\": 11946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.12, \"learn_time_ms\": 8910.231, \"total_train_time_s\": 10.875925064086914}", "{\"n\": 11947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.58, \"learn_time_ms\": 8837.296, \"total_train_time_s\": 10.10969877243042}", "{\"n\": 11948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.77, \"learn_time_ms\": 8895.263, \"total_train_time_s\": 11.100390195846558}", "{\"n\": 11949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.77, \"learn_time_ms\": 9057.994, \"total_train_time_s\": 11.750779628753662}", "{\"n\": 11950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.78, \"learn_time_ms\": 8908.205, \"total_train_time_s\": 9.233812808990479}", "{\"n\": 11951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.78, \"learn_time_ms\": 8808.178, \"total_train_time_s\": 9.538292169570923}", "{\"n\": 11952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.35, \"learn_time_ms\": 8780.419, \"total_train_time_s\": 9.04981255531311}", "{\"n\": 11953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.7, \"learn_time_ms\": 8869.3, \"total_train_time_s\": 10.417412519454956}", "{\"n\": 11954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.66, \"learn_time_ms\": 8694.532, \"total_train_time_s\": 8.421098470687866}", "{\"n\": 11955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.49, \"learn_time_ms\": 8565.059, \"total_train_time_s\": 9.080715417861938}", "{\"n\": 11956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.49, \"learn_time_ms\": 8457.98, \"total_train_time_s\": 9.783750295639038}", "{\"n\": 11957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.34, \"learn_time_ms\": 8484.732, \"total_train_time_s\": 10.354726791381836}", "{\"n\": 11958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.34, \"learn_time_ms\": 8270.099, \"total_train_time_s\": 8.957955360412598}", "{\"n\": 11959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.21, \"learn_time_ms\": 7915.725, \"total_train_time_s\": 8.245699882507324}", "{\"n\": 11960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.14, \"learn_time_ms\": 7900.316, \"total_train_time_s\": 9.113583087921143}", "{\"n\": 11961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.14, \"learn_time_ms\": 7884.185, \"total_train_time_s\": 9.432640552520752}", "{\"n\": 11962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.02, \"learn_time_ms\": 8054.078, \"total_train_time_s\": 10.689923286437988}", "{\"n\": 11963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.32, \"learn_time_ms\": 7863.071, \"total_train_time_s\": 8.523450374603271}", "{\"n\": 11964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.11, \"learn_time_ms\": 8002.376, \"total_train_time_s\": 9.820841789245605}", "{\"n\": 11965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.92, \"learn_time_ms\": 8190.889, \"total_train_time_s\": 11.010496377944946}", "{\"n\": 11966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.07, \"learn_time_ms\": 8345.377, \"total_train_time_s\": 11.397201776504517}", "{\"n\": 11967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.13, \"learn_time_ms\": 8240.936, \"total_train_time_s\": 9.352970838546753}", "{\"n\": 11968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.13, \"learn_time_ms\": 8317.688, \"total_train_time_s\": 9.660040855407715}", "{\"n\": 11969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.39, \"learn_time_ms\": 8480.534, \"total_train_time_s\": 9.9159574508667}", "{\"n\": 11970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.77, \"learn_time_ms\": 8489.262, \"total_train_time_s\": 9.176214933395386}", "{\"n\": 11971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.77, \"learn_time_ms\": 8471.829, \"total_train_time_s\": 9.249982357025146}", "{\"n\": 11972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.17, \"learn_time_ms\": 8302.662, \"total_train_time_s\": 9.028472185134888}", "{\"n\": 11973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.26, \"learn_time_ms\": 8471.454, \"total_train_time_s\": 10.2215735912323}", "{\"n\": 11974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.26, \"learn_time_ms\": 8570.241, \"total_train_time_s\": 10.828988313674927}", "{\"n\": 11975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.83, \"learn_time_ms\": 8459.3, \"total_train_time_s\": 9.908122777938843}", "{\"n\": 11976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.3, \"learn_time_ms\": 8249.115, \"total_train_time_s\": 9.282016515731812}", "{\"n\": 11977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.32, \"learn_time_ms\": 8313.383, \"total_train_time_s\": 9.94653606414795}", "{\"n\": 11978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.34, \"learn_time_ms\": 8344.91, \"total_train_time_s\": 10.056737661361694}", "{\"n\": 11979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.03, \"learn_time_ms\": 8277.313, \"total_train_time_s\": 9.165458917617798}", "{\"n\": 11980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.1, \"learn_time_ms\": 8291.868, \"total_train_time_s\": 9.316728115081787}", "{\"n\": 11981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.21, \"learn_time_ms\": 8436.531, \"total_train_time_s\": 10.745757102966309}", "{\"n\": 11982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.01, \"learn_time_ms\": 8464.191, \"total_train_time_s\": 9.299365997314453}", "{\"n\": 11983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.94, \"learn_time_ms\": 8523.399, \"total_train_time_s\": 10.800154209136963}", "{\"n\": 11984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.4, \"learn_time_ms\": 8572.073, \"total_train_time_s\": 11.293447732925415}", "{\"n\": 11985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.4, \"learn_time_ms\": 8697.098, \"total_train_time_s\": 11.125272989273071}", "{\"n\": 11986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.23, \"learn_time_ms\": 8692.439, \"total_train_time_s\": 9.17314600944519}", "{\"n\": 11987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.59, \"learn_time_ms\": 8829.99, \"total_train_time_s\": 11.341614961624146}", "{\"n\": 11988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.59, \"learn_time_ms\": 8972.401, \"total_train_time_s\": 11.456654787063599}", "{\"n\": 11989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.94, \"learn_time_ms\": 8923.378, \"total_train_time_s\": 8.675010204315186}", "{\"n\": 11990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.34, \"learn_time_ms\": 8896.667, \"total_train_time_s\": 9.063450574874878}", "{\"n\": 11991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.23, \"learn_time_ms\": 8947.769, \"total_train_time_s\": 11.161490678787231}", "{\"n\": 11992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.23, \"learn_time_ms\": 9060.488, \"total_train_time_s\": 10.383872985839844}", "{\"n\": 11993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.88, \"learn_time_ms\": 8967.906, \"total_train_time_s\": 9.955135345458984}", "{\"n\": 11994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.79, \"learn_time_ms\": 8782.052, \"total_train_time_s\": 9.395081043243408}", "{\"n\": 11995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.79, \"learn_time_ms\": 8685.537, \"total_train_time_s\": 10.179750442504883}", "{\"n\": 11996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 8765.389, \"total_train_time_s\": 9.946840763092041}", "{\"n\": 11997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.85, \"learn_time_ms\": 8704.815, \"total_train_time_s\": 10.706832885742188}", "{\"n\": 11998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.85, \"learn_time_ms\": 8594.575, \"total_train_time_s\": 10.355717182159424}", "{\"n\": 11999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.04, \"learn_time_ms\": 8723.25, \"total_train_time_s\": 9.924136638641357}", "{\"n\": 12000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.83, \"learn_time_ms\": 8756.374, \"total_train_time_s\": 9.385648727416992}", "{\"n\": 12001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.49, \"learn_time_ms\": 8684.128, \"total_train_time_s\": 10.472486972808838}", "{\"n\": 12002, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.88, \"learn_time_ms\": 8649.094, \"total_train_time_s\": 10.033116340637207}", "{\"n\": 12003, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.88, \"learn_time_ms\": 8628.396, \"total_train_time_s\": 9.661262512207031}", "{\"n\": 12004, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 8721.349, \"total_train_time_s\": 10.386980056762695}", "{\"n\": 12005, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.5, \"learn_time_ms\": 8734.608, \"total_train_time_s\": 10.327023029327393}", "{\"n\": 12006, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.5, \"learn_time_ms\": 8629.726, \"total_train_time_s\": 8.955044269561768}", "{\"n\": 12007, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.31, \"learn_time_ms\": 8731.627, \"total_train_time_s\": 11.718446254730225}", "{\"n\": 12008, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.97, \"learn_time_ms\": 8658.167, \"total_train_time_s\": 9.65095591545105}", "{\"n\": 12009, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.97, \"learn_time_ms\": 8610.271, \"total_train_time_s\": 9.528266191482544}", "{\"n\": 12010, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.37, \"learn_time_ms\": 8596.859, \"total_train_time_s\": 9.220545291900635}", "{\"n\": 12011, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.74, \"learn_time_ms\": 8423.54, \"total_train_time_s\": 8.774550437927246}", "{\"n\": 12012, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.74, \"learn_time_ms\": 8430.773, \"total_train_time_s\": 10.115523338317871}", "{\"n\": 12013, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.74, \"learn_time_ms\": 8473.462, \"total_train_time_s\": 10.07746958732605}", "{\"n\": 12014, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.64, \"learn_time_ms\": 8395.963, \"total_train_time_s\": 9.621855020523071}", "{\"n\": 12015, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.02, \"learn_time_ms\": 8351.754, \"total_train_time_s\": 9.923686742782593}", "{\"n\": 12016, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.02, \"learn_time_ms\": 8526.329, \"total_train_time_s\": 10.69291353225708}", "{\"n\": 12017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.74, \"learn_time_ms\": 8470.571, \"total_train_time_s\": 11.19356656074524}", "{\"n\": 12018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.02, \"learn_time_ms\": 8409.441, \"total_train_time_s\": 9.016213417053223}", "{\"n\": 12019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.02, \"learn_time_ms\": 8534.824, \"total_train_time_s\": 10.726961135864258}", "{\"n\": 12020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.02, \"learn_time_ms\": 8615.947, \"total_train_time_s\": 10.065174341201782}", "{\"n\": 12021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.07, \"learn_time_ms\": 8664.646, \"total_train_time_s\": 9.217257261276245}", "{\"n\": 12022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.07, \"learn_time_ms\": 8607.302, \"total_train_time_s\": 9.536164999008179}", "{\"n\": 12023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.07, \"learn_time_ms\": 8609.969, \"total_train_time_s\": 10.166046857833862}", "{\"n\": 12024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.57, \"learn_time_ms\": 8821.281, \"total_train_time_s\": 11.740193843841553}", "{\"n\": 12025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.93, \"learn_time_ms\": 8877.512, \"total_train_time_s\": 10.401145458221436}", "{\"n\": 12026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.93, \"learn_time_ms\": 8840.852, \"total_train_time_s\": 10.351362466812134}", "{\"n\": 12027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.88, \"learn_time_ms\": 8715.25, \"total_train_time_s\": 9.956637144088745}", "{\"n\": 12028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.29, \"learn_time_ms\": 8765.755, \"total_train_time_s\": 9.543265581130981}", "{\"n\": 12029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.29, \"learn_time_ms\": 8685.754, \"total_train_time_s\": 9.924091815948486}", "{\"n\": 12030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.57, \"learn_time_ms\": 8550.727, \"total_train_time_s\": 8.738574743270874}", "{\"n\": 12031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.85, \"learn_time_ms\": 8635.511, \"total_train_time_s\": 10.071598768234253}", "{\"n\": 12032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.85, \"learn_time_ms\": 8706.96, \"total_train_time_s\": 10.250257730484009}", "{\"n\": 12033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.85, \"learn_time_ms\": 8603.76, \"total_train_time_s\": 9.105220556259155}", "{\"n\": 12034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.22, \"learn_time_ms\": 8373.1, \"total_train_time_s\": 9.42387843132019}", "{\"n\": 12035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.29, \"learn_time_ms\": 8467.334, \"total_train_time_s\": 11.367622375488281}", "{\"n\": 12036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.29, \"learn_time_ms\": 8472.989, \"total_train_time_s\": 10.363871812820435}", "{\"n\": 12037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.57, \"learn_time_ms\": 8418.82, \"total_train_time_s\": 9.36476993560791}", "{\"n\": 12038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.82, \"learn_time_ms\": 8469.951, \"total_train_time_s\": 9.996045112609863}", "{\"n\": 12039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.82, \"learn_time_ms\": 8449.853, \"total_train_time_s\": 9.70384168624878}", "{\"n\": 12040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.82, \"learn_time_ms\": 8541.792, \"total_train_time_s\": 9.632444620132446}", "{\"n\": 12041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.77, \"learn_time_ms\": 8435.227, \"total_train_time_s\": 9.051819086074829}", "{\"n\": 12042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.77, \"learn_time_ms\": 8398.44, \"total_train_time_s\": 9.89323616027832}", "{\"n\": 12043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.77, \"learn_time_ms\": 8583.601, \"total_train_time_s\": 10.89917540550232}", "{\"n\": 12044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.13, \"learn_time_ms\": 8763.484, \"total_train_time_s\": 11.18515944480896}", "{\"n\": 12045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.73, \"learn_time_ms\": 8582.92, \"total_train_time_s\": 9.615772247314453}", "{\"n\": 12046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.73, \"learn_time_ms\": 8529.972, \"total_train_time_s\": 9.8614342212677}", "{\"n\": 12047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.47, \"learn_time_ms\": 8602.1, \"total_train_time_s\": 10.067659139633179}", "{\"n\": 12048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.61, \"learn_time_ms\": 8722.898, \"total_train_time_s\": 11.237168788909912}", "{\"n\": 12049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.61, \"learn_time_ms\": 8726.77, \"total_train_time_s\": 9.754469156265259}", "{\"n\": 12050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.61, \"learn_time_ms\": 8752.076, \"total_train_time_s\": 9.894336700439453}", "{\"n\": 12051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.52, \"learn_time_ms\": 8904.844, \"total_train_time_s\": 10.539309024810791}", "{\"n\": 12052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.52, \"learn_time_ms\": 8961.095, \"total_train_time_s\": 10.435704469680786}", "{\"n\": 12053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.52, \"learn_time_ms\": 8998.727, \"total_train_time_s\": 11.337746620178223}", "{\"n\": 12054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.75, \"learn_time_ms\": 8874.309, \"total_train_time_s\": 9.998560428619385}", "{\"n\": 12055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.51, \"learn_time_ms\": 8831.014, \"total_train_time_s\": 9.189138174057007}", "{\"n\": 12056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.89, \"learn_time_ms\": 8913.621, \"total_train_time_s\": 10.678071022033691}", "{\"n\": 12057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.89, \"learn_time_ms\": 8783.668, \"total_train_time_s\": 8.813271522521973}", "{\"n\": 12058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.3, \"learn_time_ms\": 8599.746, \"total_train_time_s\": 9.36683201789856}", "{\"n\": 12059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.04, \"learn_time_ms\": 8597.381, \"total_train_time_s\": 9.781486988067627}", "{\"n\": 12060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.19, \"learn_time_ms\": 8658.016, \"total_train_time_s\": 10.48016095161438}", "{\"n\": 12061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.83, \"learn_time_ms\": 8519.678, \"total_train_time_s\": 9.172869205474854}", "{\"n\": 12062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 8543.772, \"total_train_time_s\": 10.71477484703064}", "{\"n\": 12063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.9, \"learn_time_ms\": 8359.949, \"total_train_time_s\": 9.512340068817139}", "{\"n\": 12064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.9, \"learn_time_ms\": 8360.81, \"total_train_time_s\": 9.987339496612549}", "{\"n\": 12065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.81, \"learn_time_ms\": 8493.551, \"total_train_time_s\": 10.446077823638916}", "{\"n\": 12066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.21, \"learn_time_ms\": 8357.064, \"total_train_time_s\": 9.30712604522705}", "{\"n\": 12067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.71, \"learn_time_ms\": 8334.692, \"total_train_time_s\": 8.582627534866333}", "{\"n\": 12068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.61, \"learn_time_ms\": 8335.292, \"total_train_time_s\": 9.42221212387085}", "{\"n\": 12069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.44, \"learn_time_ms\": 8350.881, \"total_train_time_s\": 9.946334838867188}", "{\"n\": 12070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.9, \"learn_time_ms\": 8270.594, \"total_train_time_s\": 9.724682092666626}", "{\"n\": 12071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.49, \"learn_time_ms\": 8440.884, \"total_train_time_s\": 10.894084692001343}", "{\"n\": 12072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.16, \"learn_time_ms\": 8341.748, \"total_train_time_s\": 9.6639564037323}", "{\"n\": 12073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.17, \"learn_time_ms\": 8418.54, \"total_train_time_s\": 10.248485088348389}", "{\"n\": 12074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.49, \"learn_time_ms\": 8461.85, \"total_train_time_s\": 10.356356620788574}", "{\"n\": 12075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.62, \"learn_time_ms\": 8441.125, \"total_train_time_s\": 10.278965950012207}", "{\"n\": 12076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.06, \"learn_time_ms\": 8565.802, \"total_train_time_s\": 10.589011430740356}", "{\"n\": 12077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.06, \"learn_time_ms\": 8739.904, \"total_train_time_s\": 10.334490299224854}", "{\"n\": 12078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 8700.65, \"total_train_time_s\": 9.00645899772644}", "{\"n\": 12079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.9, \"learn_time_ms\": 8664.77, \"total_train_time_s\": 9.56175446510315}", "{\"n\": 12080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.9, \"learn_time_ms\": 8648.217, \"total_train_time_s\": 9.535220861434937}", "{\"n\": 12081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.59, \"learn_time_ms\": 8586.174, \"total_train_time_s\": 10.291378736495972}", "{\"n\": 12082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.63, \"learn_time_ms\": 8503.099, \"total_train_time_s\": 8.905438423156738}", "{\"n\": 12083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.3, \"learn_time_ms\": 8594.664, \"total_train_time_s\": 11.20313024520874}", "{\"n\": 12084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.75, \"learn_time_ms\": 8695.517, \"total_train_time_s\": 11.458786725997925}", "{\"n\": 12085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.33, \"learn_time_ms\": 8712.123, \"total_train_time_s\": 10.435734987258911}", "{\"n\": 12086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.18, \"learn_time_ms\": 8841.232, \"total_train_time_s\": 11.83354115486145}", "{\"n\": 12087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.18, \"learn_time_ms\": 8910.022, \"total_train_time_s\": 11.058590650558472}", "{\"n\": 12088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.01, \"learn_time_ms\": 9005.06, \"total_train_time_s\": 10.018559694290161}", "{\"n\": 12089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.17, \"learn_time_ms\": 9201.855, \"total_train_time_s\": 11.541789531707764}", "{\"n\": 12090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.17, \"learn_time_ms\": 9466.507, \"total_train_time_s\": 12.187296390533447}", "{\"n\": 12091, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.97, \"learn_time_ms\": 9576.368, \"total_train_time_s\": 11.330630540847778}", "{\"n\": 12092, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.67, \"learn_time_ms\": 9758.843, \"total_train_time_s\": 10.685313701629639}", "{\"n\": 12093, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.67, \"learn_time_ms\": 9541.464, \"total_train_time_s\": 9.00080394744873}", "{\"n\": 12094, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.63, \"learn_time_ms\": 9301.897, \"total_train_time_s\": 8.996466875076294}", "{\"n\": 12095, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.56, \"learn_time_ms\": 9318.022, \"total_train_time_s\": 10.581141233444214}", "{\"n\": 12096, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.81, \"learn_time_ms\": 9085.875, \"total_train_time_s\": 9.551265239715576}", "{\"n\": 12097, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.81, \"learn_time_ms\": 8999.616, \"total_train_time_s\": 10.149600505828857}", "{\"n\": 12098, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.3, \"learn_time_ms\": 8961.306, \"total_train_time_s\": 9.550768375396729}", "{\"n\": 12099, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.64, \"learn_time_ms\": 8780.292, \"total_train_time_s\": 9.716768741607666}", "{\"n\": 12100, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.64, \"learn_time_ms\": 8495.544, \"total_train_time_s\": 9.33200192451477}", "{\"n\": 12101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.7, \"learn_time_ms\": 8466.928, \"total_train_time_s\": 11.084068775177002}", "{\"n\": 12102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8366.656, \"total_train_time_s\": 9.714922189712524}", "{\"n\": 12103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8580.517, \"total_train_time_s\": 11.12617564201355}", "{\"n\": 12104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8818.484, \"total_train_time_s\": 11.378700971603394}", "{\"n\": 12105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.53, \"learn_time_ms\": 8824.539, \"total_train_time_s\": 10.662075281143188}", "{\"n\": 12106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.53, \"learn_time_ms\": 8881.986, \"total_train_time_s\": 10.102479934692383}", "{\"n\": 12107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.34, \"learn_time_ms\": 9009.159, \"total_train_time_s\": 11.448298454284668}", "{\"n\": 12108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.97, \"learn_time_ms\": 9005.367, \"total_train_time_s\": 9.587201833724976}", "{\"n\": 12109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.53, \"learn_time_ms\": 9065.608, \"total_train_time_s\": 10.285391569137573}", "{\"n\": 12110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.46, \"learn_time_ms\": 9144.137, \"total_train_time_s\": 10.122592687606812}", "{\"n\": 12111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.46, \"learn_time_ms\": 9001.943, \"total_train_time_s\": 9.627199649810791}", "{\"n\": 12112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.97, \"learn_time_ms\": 8966.294, \"total_train_time_s\": 9.310592651367188}", "{\"n\": 12113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.97, \"learn_time_ms\": 8858.857, \"total_train_time_s\": 10.065353631973267}", "{\"n\": 12114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.38, \"learn_time_ms\": 8631.82, \"total_train_time_s\": 9.153589248657227}", "{\"n\": 12115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.96, \"learn_time_ms\": 8436.687, \"total_train_time_s\": 8.703547716140747}", "{\"n\": 12116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.96, \"learn_time_ms\": 8504.526, \"total_train_time_s\": 10.792200326919556}", "{\"n\": 12117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.52, \"learn_time_ms\": 8381.816, \"total_train_time_s\": 10.187279462814331}", "{\"n\": 12118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.16, \"learn_time_ms\": 8470.802, \"total_train_time_s\": 10.435442209243774}", "{\"n\": 12119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.73, \"learn_time_ms\": 8332.606, \"total_train_time_s\": 8.918699026107788}", "{\"n\": 12120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.73, \"learn_time_ms\": 8351.656, \"total_train_time_s\": 10.298192024230957}", "{\"n\": 12121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.07, \"learn_time_ms\": 8469.063, \"total_train_time_s\": 10.815985202789307}", "{\"n\": 12122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 8575.919, \"total_train_time_s\": 10.425409078598022}", "{\"n\": 12123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 8658.792, \"total_train_time_s\": 10.891721487045288}", "{\"n\": 12124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.83, \"learn_time_ms\": 8720.948, \"total_train_time_s\": 9.76053762435913}", "{\"n\": 12125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.99, \"learn_time_ms\": 8781.807, \"total_train_time_s\": 9.322349309921265}", "{\"n\": 12126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 8764.403, \"total_train_time_s\": 10.58901047706604}", "{\"n\": 12127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.08, \"learn_time_ms\": 8832.875, \"total_train_time_s\": 10.884071111679077}", "{\"n\": 12128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.42, \"learn_time_ms\": 8747.018, \"total_train_time_s\": 9.556879997253418}", "{\"n\": 12129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.06, \"learn_time_ms\": 8819.387, \"total_train_time_s\": 9.648061275482178}", "{\"n\": 12130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.36, \"learn_time_ms\": 8763.159, \"total_train_time_s\": 9.738521814346313}", "{\"n\": 12131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.15, \"learn_time_ms\": 8548.102, \"total_train_time_s\": 8.685922384262085}", "{\"n\": 12132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.95, \"learn_time_ms\": 8443.948, \"total_train_time_s\": 9.372674703598022}", "{\"n\": 12133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.2, \"learn_time_ms\": 8343.537, \"total_train_time_s\": 9.880475997924805}", "{\"n\": 12134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.2, \"learn_time_ms\": 8371.188, \"total_train_time_s\": 10.003533124923706}", "{\"n\": 12135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.35, \"learn_time_ms\": 8368.419, \"total_train_time_s\": 9.30860424041748}", "{\"n\": 12136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8250.747, \"total_train_time_s\": 9.467564582824707}", "{\"n\": 12137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.2, \"learn_time_ms\": 8026.405, \"total_train_time_s\": 8.665999174118042}", "{\"n\": 12138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.92, \"learn_time_ms\": 7920.622, \"total_train_time_s\": 8.534631729125977}", "{\"n\": 12139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.52, \"learn_time_ms\": 7906.311, \"total_train_time_s\": 9.54506230354309}", "{\"n\": 12140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.52, \"learn_time_ms\": 7991.005, \"total_train_time_s\": 10.598954677581787}", "{\"n\": 12141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.68, \"learn_time_ms\": 8254.589, \"total_train_time_s\": 11.309000253677368}", "{\"n\": 12142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.61, \"learn_time_ms\": 8401.654, \"total_train_time_s\": 10.883816480636597}", "{\"n\": 12143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.81, \"learn_time_ms\": 8348.554, \"total_train_time_s\": 9.366372346878052}", "{\"n\": 12144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.81, \"learn_time_ms\": 8365.826, \"total_train_time_s\": 10.209232807159424}", "{\"n\": 12145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.91, \"learn_time_ms\": 8488.28, \"total_train_time_s\": 10.493816375732422}", "{\"n\": 12146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.68, \"learn_time_ms\": 8438.271, \"total_train_time_s\": 8.983099222183228}", "{\"n\": 12147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.68, \"learn_time_ms\": 8534.147, \"total_train_time_s\": 9.601974725723267}", "{\"n\": 12148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.79, \"learn_time_ms\": 8713.376, \"total_train_time_s\": 10.340687036514282}", "{\"n\": 12149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.34, \"learn_time_ms\": 8879.84, \"total_train_time_s\": 11.235596418380737}", "{\"n\": 12150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.41, \"learn_time_ms\": 8824.444, \"total_train_time_s\": 10.03404951095581}", "{\"n\": 12151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.2, \"learn_time_ms\": 8679.607, \"total_train_time_s\": 9.868529796600342}", "{\"n\": 12152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.98, \"learn_time_ms\": 8447.742, \"total_train_time_s\": 8.512880325317383}", "{\"n\": 12153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.73, \"learn_time_ms\": 8471.261, \"total_train_time_s\": 9.584583044052124}", "{\"n\": 12154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.32, \"learn_time_ms\": 8405.109, \"total_train_time_s\": 9.513737678527832}", "{\"n\": 12155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.06, \"learn_time_ms\": 8308.907, \"total_train_time_s\": 9.620137453079224}", "{\"n\": 12156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.13, \"learn_time_ms\": 8400.014, \"total_train_time_s\": 9.915000438690186}", "{\"n\": 12157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.14, \"learn_time_ms\": 8460.376, \"total_train_time_s\": 10.272289991378784}", "{\"n\": 12158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.75, \"learn_time_ms\": 8300.994, \"total_train_time_s\": 8.709028005599976}", "{\"n\": 12159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.84, \"learn_time_ms\": 8113.452, \"total_train_time_s\": 9.329576253890991}", "{\"n\": 12160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.77, \"learn_time_ms\": 8046.898, \"total_train_time_s\": 9.404430627822876}", "{\"n\": 12161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.44, \"learn_time_ms\": 8065.052, \"total_train_time_s\": 10.060163497924805}", "{\"n\": 12162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.6, \"learn_time_ms\": 8323.058, \"total_train_time_s\": 11.098323822021484}", "{\"n\": 12163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.05, \"learn_time_ms\": 8353.67, \"total_train_time_s\": 9.89147424697876}", "{\"n\": 12164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.06, \"learn_time_ms\": 8398.675, \"total_train_time_s\": 9.963496685028076}", "{\"n\": 12165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.86, \"learn_time_ms\": 8563.741, \"total_train_time_s\": 11.223881244659424}", "{\"n\": 12166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.99, \"learn_time_ms\": 8580.167, \"total_train_time_s\": 9.974426746368408}", "{\"n\": 12167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.26, \"learn_time_ms\": 8594.642, \"total_train_time_s\": 10.336364030838013}", "{\"n\": 12168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.7, \"learn_time_ms\": 8730.4, \"total_train_time_s\": 10.072739362716675}", "{\"n\": 12169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.36, \"learn_time_ms\": 8957.605, \"total_train_time_s\": 11.550101518630981}", "{\"n\": 12170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.8, \"learn_time_ms\": 9039.595, \"total_train_time_s\": 10.161752462387085}", "{\"n\": 12171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.62, \"learn_time_ms\": 9015.648, \"total_train_time_s\": 9.807280540466309}", "{\"n\": 12172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.62, \"learn_time_ms\": 8883.198, \"total_train_time_s\": 9.749401092529297}", "{\"n\": 12173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.58, \"learn_time_ms\": 8939.304, \"total_train_time_s\": 10.498241186141968}", "{\"n\": 12174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.24, \"learn_time_ms\": 8859.745, \"total_train_time_s\": 9.180604457855225}", "{\"n\": 12175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.53, \"learn_time_ms\": 8791.876, \"total_train_time_s\": 10.509359359741211}", "{\"n\": 12176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.0, \"learn_time_ms\": 8683.542, \"total_train_time_s\": 8.948374509811401}", "{\"n\": 12177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.0, \"learn_time_ms\": 8568.656, \"total_train_time_s\": 9.19976258277893}", "{\"n\": 12178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.56, \"learn_time_ms\": 8547.006, \"total_train_time_s\": 9.893381357192993}", "{\"n\": 12179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.01, \"learn_time_ms\": 8481.296, \"total_train_time_s\": 10.972040176391602}", "{\"n\": 12180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.12, \"learn_time_ms\": 8455.915, \"total_train_time_s\": 9.916375160217285}", "{\"n\": 12181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.89, \"learn_time_ms\": 8319.18, \"total_train_time_s\": 8.423518180847168}", "{\"n\": 12182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.89, \"learn_time_ms\": 8299.153, \"total_train_time_s\": 9.593657493591309}", "{\"n\": 12183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.77, \"learn_time_ms\": 8205.564, \"total_train_time_s\": 9.5075204372406}", "{\"n\": 12184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.01, \"learn_time_ms\": 8349.552, \"total_train_time_s\": 10.614891529083252}", "{\"n\": 12185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.11, \"learn_time_ms\": 8259.413, \"total_train_time_s\": 9.64134955406189}", "{\"n\": 12186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.04, \"learn_time_ms\": 8342.306, \"total_train_time_s\": 9.765566349029541}", "{\"n\": 12187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.04, \"learn_time_ms\": 8433.555, \"total_train_time_s\": 10.090388536453247}", "{\"n\": 12188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.02, \"learn_time_ms\": 8474.853, \"total_train_time_s\": 10.305970191955566}", "{\"n\": 12189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.02, \"learn_time_ms\": 8303.588, \"total_train_time_s\": 9.240682601928711}", "{\"n\": 12190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.93, \"learn_time_ms\": 8400.138, \"total_train_time_s\": 10.894747972488403}", "{\"n\": 12191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.57, \"learn_time_ms\": 8460.4, \"total_train_time_s\": 9.015422582626343}", "{\"n\": 12192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.59, \"learn_time_ms\": 8495.931, \"total_train_time_s\": 9.960209608078003}", "{\"n\": 12193, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.07, \"learn_time_ms\": 8457.495, \"total_train_time_s\": 9.139036893844604}", "{\"n\": 12194, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.83, \"learn_time_ms\": 8563.033, \"total_train_time_s\": 11.658363103866577}", "{\"n\": 12195, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.79, \"learn_time_ms\": 8441.253, \"total_train_time_s\": 8.438560485839844}", "{\"n\": 12196, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.79, \"learn_time_ms\": 8499.032, \"total_train_time_s\": 10.359881401062012}", "{\"n\": 12197, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.58, \"learn_time_ms\": 8471.771, \"total_train_time_s\": 9.798622608184814}", "{\"n\": 12198, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.97, \"learn_time_ms\": 8452.232, \"total_train_time_s\": 10.082790851593018}", "{\"n\": 12199, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.97, \"learn_time_ms\": 8587.763, \"total_train_time_s\": 10.596767663955688}", "{\"n\": 12200, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.39, \"learn_time_ms\": 8505.241, \"total_train_time_s\": 10.075091123580933}", "{\"n\": 12201, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.78, \"learn_time_ms\": 8634.918, \"total_train_time_s\": 10.30510687828064}", "{\"n\": 12202, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.12, \"learn_time_ms\": 8593.325, \"total_train_time_s\": 9.464041233062744}", "{\"n\": 12203, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.66, \"learn_time_ms\": 8705.126, \"total_train_time_s\": 10.2094566822052}", "{\"n\": 12204, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.09, \"learn_time_ms\": 8558.766, \"total_train_time_s\": 10.252240896224976}", "{\"n\": 12205, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.4, \"learn_time_ms\": 8858.591, \"total_train_time_s\": 11.41500210762024}", "{\"n\": 12206, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.47, \"learn_time_ms\": 8844.687, \"total_train_time_s\": 10.226012945175171}", "{\"n\": 12207, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 8850.021, \"total_train_time_s\": 9.919371128082275}", "{\"n\": 12208, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.96, \"learn_time_ms\": 8871.652, \"total_train_time_s\": 10.33295750617981}", "{\"n\": 12209, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 8823.908, \"total_train_time_s\": 10.076759815216064}", "{\"n\": 12210, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.76, \"learn_time_ms\": 8904.086, \"total_train_time_s\": 10.832306861877441}", "{\"n\": 12211, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.28, \"learn_time_ms\": 8707.441, \"total_train_time_s\": 8.327222347259521}", "{\"n\": 12212, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.78, \"learn_time_ms\": 8716.772, \"total_train_time_s\": 9.584474802017212}", "{\"n\": 12213, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.08, \"learn_time_ms\": 8613.659, \"total_train_time_s\": 9.259588479995728}", "{\"n\": 12214, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.08, \"learn_time_ms\": 8422.123, \"total_train_time_s\": 8.312504291534424}", "{\"n\": 12215, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.92, \"learn_time_ms\": 8266.537, \"total_train_time_s\": 9.89250922203064}", "{\"n\": 12216, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.4, \"learn_time_ms\": 8232.364, \"total_train_time_s\": 9.858935356140137}", "{\"n\": 12217, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.59, \"learn_time_ms\": 8307.696, \"total_train_time_s\": 10.654362678527832}", "{\"n\": 12218, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.59, \"learn_time_ms\": 8257.229, \"total_train_time_s\": 9.792560577392578}", "{\"n\": 12219, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.68, \"learn_time_ms\": 8261.798, \"total_train_time_s\": 10.127108573913574}", "{\"n\": 12220, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.36, \"learn_time_ms\": 8147.999, \"total_train_time_s\": 9.74542236328125}", "{\"n\": 12221, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.36, \"learn_time_ms\": 8315.255, \"total_train_time_s\": 10.042517900466919}", "{\"n\": 12222, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.94, \"learn_time_ms\": 8493.031, \"total_train_time_s\": 11.408854961395264}", "{\"n\": 12223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.01, \"learn_time_ms\": 8526.996, \"total_train_time_s\": 9.604482889175415}", "{\"n\": 12224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.01, \"learn_time_ms\": 8754.672, \"total_train_time_s\": 10.557671546936035}", "{\"n\": 12225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.41, \"learn_time_ms\": 8830.098, \"total_train_time_s\": 10.621898651123047}", "{\"n\": 12226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.87, \"learn_time_ms\": 8800.917, \"total_train_time_s\": 9.564347982406616}", "{\"n\": 12227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.04, \"learn_time_ms\": 8650.049, \"total_train_time_s\": 9.172800064086914}", "{\"n\": 12228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.04, \"learn_time_ms\": 8673.437, \"total_train_time_s\": 10.014711141586304}", "{\"n\": 12229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.89, \"learn_time_ms\": 8629.389, \"total_train_time_s\": 9.751944780349731}", "{\"n\": 12230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.67, \"learn_time_ms\": 8633.088, \"total_train_time_s\": 9.79606318473816}", "{\"n\": 12231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.67, \"learn_time_ms\": 8621.296, \"total_train_time_s\": 9.89639687538147}", "{\"n\": 12232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.04, \"learn_time_ms\": 8504.017, \"total_train_time_s\": 10.163113594055176}", "{\"n\": 12233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.68, \"learn_time_ms\": 8613.808, \"total_train_time_s\": 10.748026847839355}", "{\"n\": 12234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.68, \"learn_time_ms\": 8618.541, \"total_train_time_s\": 10.61813735961914}", "{\"n\": 12235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.19, \"learn_time_ms\": 8522.134, \"total_train_time_s\": 9.623055458068848}", "{\"n\": 12236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.9, \"learn_time_ms\": 8534.49, \"total_train_time_s\": 9.701784133911133}", "{\"n\": 12237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.9, \"learn_time_ms\": 8576.361, \"total_train_time_s\": 9.544337511062622}", "{\"n\": 12238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.35, \"learn_time_ms\": 8568.696, \"total_train_time_s\": 9.931088924407959}", "{\"n\": 12239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.94, \"learn_time_ms\": 8623.924, \"total_train_time_s\": 10.241198539733887}", "{\"n\": 12240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.72, \"learn_time_ms\": 8664.154, \"total_train_time_s\": 10.160860300064087}", "{\"n\": 12241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.11, \"learn_time_ms\": 8562.761, \"total_train_time_s\": 8.881195783615112}", "{\"n\": 12242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.2, \"learn_time_ms\": 8450.421, \"total_train_time_s\": 9.136911869049072}", "{\"n\": 12243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.91, \"learn_time_ms\": 8266.021, \"total_train_time_s\": 8.802926063537598}", "{\"n\": 12244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 8262.152, \"total_train_time_s\": 10.57056474685669}", "{\"n\": 12245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.64, \"learn_time_ms\": 8329.476, \"total_train_time_s\": 10.325712442398071}", "{\"n\": 12246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.4, \"learn_time_ms\": 8360.368, \"total_train_time_s\": 9.977050304412842}", "{\"n\": 12247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.63, \"learn_time_ms\": 8391.547, \"total_train_time_s\": 9.840274572372437}", "{\"n\": 12248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.01, \"learn_time_ms\": 8266.191, \"total_train_time_s\": 8.730324506759644}", "{\"n\": 12249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.71, \"learn_time_ms\": 8239.826, \"total_train_time_s\": 10.028176069259644}", "{\"n\": 12250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.66, \"learn_time_ms\": 8295.757, \"total_train_time_s\": 10.766330480575562}", "{\"n\": 12251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.12, \"learn_time_ms\": 8317.48, \"total_train_time_s\": 9.089000940322876}", "{\"n\": 12252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.42, \"learn_time_ms\": 8425.879, \"total_train_time_s\": 10.176991939544678}", "{\"n\": 12253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.45, \"learn_time_ms\": 8662.04, \"total_train_time_s\": 11.167068481445312}", "{\"n\": 12254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.65, \"learn_time_ms\": 8542.045, \"total_train_time_s\": 9.46681833267212}", "{\"n\": 12255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.23, \"learn_time_ms\": 8525.863, \"total_train_time_s\": 10.195197343826294}", "{\"n\": 12256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.48, \"learn_time_ms\": 8583.589, \"total_train_time_s\": 10.535109996795654}", "{\"n\": 12257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.67, \"learn_time_ms\": 8644.626, \"total_train_time_s\": 10.452231407165527}", "{\"n\": 12258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.33, \"learn_time_ms\": 8794.472, \"total_train_time_s\": 10.181591749191284}", "{\"n\": 12259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.77, \"learn_time_ms\": 8849.532, \"total_train_time_s\": 10.557699203491211}", "{\"n\": 12260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.77, \"learn_time_ms\": 8750.023, \"total_train_time_s\": 9.708541631698608}", "{\"n\": 12261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.42, \"learn_time_ms\": 8953.354, \"total_train_time_s\": 11.161443710327148}", "{\"n\": 12262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.96, \"learn_time_ms\": 9029.133, \"total_train_time_s\": 10.945689678192139}", "{\"n\": 12263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.39, \"learn_time_ms\": 8935.792, \"total_train_time_s\": 10.235719680786133}", "{\"n\": 12264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.39, \"learn_time_ms\": 8983.346, \"total_train_time_s\": 9.856652736663818}", "{\"n\": 12265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.53, \"learn_time_ms\": 9150.579, \"total_train_time_s\": 11.79869294166565}", "{\"n\": 12266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 9115.179, \"total_train_time_s\": 10.221676349639893}", "{\"n\": 12267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 9143.036, \"total_train_time_s\": 10.79885220527649}", "{\"n\": 12268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.11, \"learn_time_ms\": 8986.51, \"total_train_time_s\": 8.590080738067627}", "{\"n\": 12269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.06, \"learn_time_ms\": 8956.876, \"total_train_time_s\": 10.19858455657959}", "{\"n\": 12270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.06, \"learn_time_ms\": 9196.719, \"total_train_time_s\": 12.123748779296875}", "{\"n\": 12271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.42, \"learn_time_ms\": 9168.921, \"total_train_time_s\": 10.849600791931152}", "{\"n\": 12272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.95, \"learn_time_ms\": 9139.625, \"total_train_time_s\": 10.62613558769226}", "{\"n\": 12273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.95, \"learn_time_ms\": 9064.896, \"total_train_time_s\": 9.500972032546997}", "{\"n\": 12274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.15, \"learn_time_ms\": 9140.332, \"total_train_time_s\": 10.618646621704102}", "{\"n\": 12275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.21, \"learn_time_ms\": 8905.906, \"total_train_time_s\": 9.512355089187622}", "{\"n\": 12276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.21, \"learn_time_ms\": 8800.446, \"total_train_time_s\": 9.208523035049438}", "{\"n\": 12277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.32, \"learn_time_ms\": 8634.417, \"total_train_time_s\": 9.07961654663086}", "{\"n\": 12278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.75, \"learn_time_ms\": 8690.124, \"total_train_time_s\": 9.156199216842651}", "{\"n\": 12279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.44, \"learn_time_ms\": 8685.705, \"total_train_time_s\": 10.17393946647644}", "{\"n\": 12280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.62, \"learn_time_ms\": 8353.164, \"total_train_time_s\": 8.831764936447144}", "{\"n\": 12281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.79, \"learn_time_ms\": 8391.757, \"total_train_time_s\": 11.291480541229248}", "{\"n\": 12282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.99, \"learn_time_ms\": 8274.262, \"total_train_time_s\": 9.446538209915161}", "{\"n\": 12283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.03, \"learn_time_ms\": 8290.889, \"total_train_time_s\": 9.696425437927246}", "{\"n\": 12284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.03, \"learn_time_ms\": 8117.398, \"total_train_time_s\": 8.861933469772339}", "{\"n\": 12285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.23, \"learn_time_ms\": 8126.652, \"total_train_time_s\": 9.596864700317383}", "{\"n\": 12286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.38, \"learn_time_ms\": 8093.409, \"total_train_time_s\": 8.843557119369507}", "{\"n\": 12287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.38, \"learn_time_ms\": 8127.416, \"total_train_time_s\": 9.418171644210815}", "{\"n\": 12288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.23, \"learn_time_ms\": 7999.304, \"total_train_time_s\": 7.915428638458252}", "{\"n\": 12289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.61, \"learn_time_ms\": 7897.684, \"total_train_time_s\": 9.190622568130493}", "{\"n\": 12290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.61, \"learn_time_ms\": 7926.966, \"total_train_time_s\": 9.081796646118164}", "{\"n\": 12291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.3, \"learn_time_ms\": 7738.969, \"total_train_time_s\": 9.378971099853516}", "{\"n\": 12292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.3, \"learn_time_ms\": 7727.703, \"total_train_time_s\": 9.399976253509521}", "{\"n\": 12293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.08, \"learn_time_ms\": 7701.258, \"total_train_time_s\": 9.360370397567749}", "{\"n\": 12294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.15, \"learn_time_ms\": 7957.72, \"total_train_time_s\": 11.434914827346802}", "{\"n\": 12295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.28, \"learn_time_ms\": 7907.929, \"total_train_time_s\": 9.069068193435669}", "{\"n\": 12296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.14, \"learn_time_ms\": 7842.01, \"total_train_time_s\": 8.222773313522339}", "{\"n\": 12297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.14, \"learn_time_ms\": 7819.604, \"total_train_time_s\": 9.185915470123291}", "{\"n\": 12298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.42, \"learn_time_ms\": 8017.968, \"total_train_time_s\": 9.89736557006836}", "{\"n\": 12299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.57, \"learn_time_ms\": 8056.257, \"total_train_time_s\": 9.573158740997314}", "{\"n\": 12300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.57, \"learn_time_ms\": 8238.343, \"total_train_time_s\": 10.941409826278687}", "{\"n\": 12301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.93, \"learn_time_ms\": 8296.586, \"total_train_time_s\": 9.952207326889038}", "{\"n\": 12302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.65, \"learn_time_ms\": 8327.558, \"total_train_time_s\": 9.67216944694519}", "{\"n\": 12303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.65, \"learn_time_ms\": 8402.616, \"total_train_time_s\": 10.091641664505005}", "{\"n\": 12304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.9, \"learn_time_ms\": 8100.152, \"total_train_time_s\": 8.435804605484009}", "{\"n\": 12305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.9, \"learn_time_ms\": 8164.128, \"total_train_time_s\": 9.704779863357544}", "{\"n\": 12306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.9, \"learn_time_ms\": 8307.597, \"total_train_time_s\": 9.610260486602783}", "{\"n\": 12307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.35, \"learn_time_ms\": 8392.554, \"total_train_time_s\": 10.075042247772217}", "{\"n\": 12308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.21, \"learn_time_ms\": 8424.864, \"total_train_time_s\": 10.219138622283936}", "{\"n\": 12309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.21, \"learn_time_ms\": 8628.551, \"total_train_time_s\": 11.644267559051514}", "{\"n\": 12310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.26, \"learn_time_ms\": 8455.57, \"total_train_time_s\": 9.216064214706421}", "{\"n\": 12311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.31, \"learn_time_ms\": 8574.929, \"total_train_time_s\": 11.204057931900024}", "{\"n\": 12312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.31, \"learn_time_ms\": 8669.825, \"total_train_time_s\": 10.57209062576294}", "{\"n\": 12313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8754.345, \"total_train_time_s\": 10.981221437454224}", "{\"n\": 12314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.18, \"learn_time_ms\": 8845.034, \"total_train_time_s\": 9.335863590240479}", "{\"n\": 12315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.08, \"learn_time_ms\": 9091.726, \"total_train_time_s\": 12.187201499938965}", "{\"n\": 12316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.08, \"learn_time_ms\": 9099.906, \"total_train_time_s\": 9.686779737472534}", "{\"n\": 12317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.65, \"learn_time_ms\": 9065.646, \"total_train_time_s\": 9.732042074203491}", "{\"n\": 12318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.17, \"learn_time_ms\": 9172.762, \"total_train_time_s\": 11.348623752593994}", "{\"n\": 12319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.17, \"learn_time_ms\": 9028.018, \"total_train_time_s\": 10.226724863052368}", "{\"n\": 12320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.49, \"learn_time_ms\": 9070.545, \"total_train_time_s\": 9.629416227340698}", "{\"n\": 12321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 9078.45, \"total_train_time_s\": 11.235499143600464}", "{\"n\": 12322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.97, \"learn_time_ms\": 8918.331, \"total_train_time_s\": 9.02058482170105}", "{\"n\": 12323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.42, \"learn_time_ms\": 9039.766, \"total_train_time_s\": 12.197441339492798}", "{\"n\": 12324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.06, \"learn_time_ms\": 9087.43, \"total_train_time_s\": 9.774210929870605}", "{\"n\": 12325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.06, \"learn_time_ms\": 8780.086, \"total_train_time_s\": 9.149175882339478}", "{\"n\": 12326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.06, \"learn_time_ms\": 8712.431, \"total_train_time_s\": 9.004323959350586}", "{\"n\": 12327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8812.465, \"total_train_time_s\": 10.741899967193604}", "{\"n\": 12328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8723.091, \"total_train_time_s\": 10.401854276657104}", "{\"n\": 12329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.56, \"learn_time_ms\": 8700.678, \"total_train_time_s\": 9.890952110290527}", "{\"n\": 12330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.07, \"learn_time_ms\": 8684.933, \"total_train_time_s\": 9.462744235992432}", "{\"n\": 12331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.07, \"learn_time_ms\": 8604.781, \"total_train_time_s\": 10.452204465866089}", "{\"n\": 12332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.19, \"learn_time_ms\": 8750.893, \"total_train_time_s\": 10.482240200042725}", "{\"n\": 12333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.19, \"learn_time_ms\": 8524.683, \"total_train_time_s\": 9.948337316513062}", "{\"n\": 12334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.33, \"learn_time_ms\": 8528.084, \"total_train_time_s\": 9.796390056610107}", "{\"n\": 12335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.33, \"learn_time_ms\": 8678.877, \"total_train_time_s\": 10.58868145942688}", "{\"n\": 12336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.06, \"learn_time_ms\": 8746.965, \"total_train_time_s\": 9.6857008934021}", "{\"n\": 12337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.55, \"learn_time_ms\": 8701.58, \"total_train_time_s\": 10.210917711257935}", "{\"n\": 12338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.72, \"learn_time_ms\": 8651.098, \"total_train_time_s\": 9.892492771148682}", "{\"n\": 12339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.72, \"learn_time_ms\": 8507.154, \"total_train_time_s\": 8.496955871582031}", "{\"n\": 12340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.41, \"learn_time_ms\": 8506.291, \"total_train_time_s\": 9.466676712036133}", "{\"n\": 12341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.74, \"learn_time_ms\": 8482.105, \"total_train_time_s\": 10.213712215423584}", "{\"n\": 12342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.74, \"learn_time_ms\": 8378.943, \"total_train_time_s\": 9.415522575378418}", "{\"n\": 12343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.61, \"learn_time_ms\": 8366.719, \"total_train_time_s\": 9.802724838256836}", "{\"n\": 12344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.03, \"learn_time_ms\": 8536.434, \"total_train_time_s\": 11.529172897338867}", "{\"n\": 12345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.03, \"learn_time_ms\": 8410.183, \"total_train_time_s\": 9.349836826324463}", "{\"n\": 12346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.03, \"learn_time_ms\": 8310.438, \"total_train_time_s\": 8.693914651870728}", "{\"n\": 12347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.3, \"learn_time_ms\": 8189.756, \"total_train_time_s\": 9.042067527770996}", "{\"n\": 12348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.3, \"learn_time_ms\": 8144.258, \"total_train_time_s\": 9.420466661453247}", "{\"n\": 12349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.3, \"learn_time_ms\": 8301.104, \"total_train_time_s\": 10.023767471313477}", "{\"n\": 12350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.32, \"learn_time_ms\": 8406.788, \"total_train_time_s\": 10.49512529373169}", "{\"n\": 12351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.14, \"learn_time_ms\": 8343.135, \"total_train_time_s\": 9.597233533859253}", "{\"n\": 12352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.14, \"learn_time_ms\": 8336.221, \"total_train_time_s\": 9.372853755950928}", "{\"n\": 12353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.77, \"learn_time_ms\": 8338.317, \"total_train_time_s\": 9.841859817504883}", "{\"n\": 12354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.07, \"learn_time_ms\": 8090.257, \"total_train_time_s\": 9.070327997207642}", "{\"n\": 12355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.07, \"learn_time_ms\": 8157.626, \"total_train_time_s\": 9.989624977111816}", "{\"n\": 12356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.78, \"learn_time_ms\": 8266.308, \"total_train_time_s\": 9.78378701210022}", "{\"n\": 12357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.31, \"learn_time_ms\": 8366.74, \"total_train_time_s\": 10.043110132217407}", "{\"n\": 12358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.31, \"learn_time_ms\": 8455.291, \"total_train_time_s\": 10.344652652740479}", "{\"n\": 12359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.14, \"learn_time_ms\": 8495.914, \"total_train_time_s\": 10.448251724243164}", "{\"n\": 12360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.25, \"learn_time_ms\": 8478.232, \"total_train_time_s\": 10.380642652511597}", "{\"n\": 12361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.34, \"learn_time_ms\": 8597.534, \"total_train_time_s\": 10.754952430725098}", "{\"n\": 12362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.34, \"learn_time_ms\": 8678.944, \"total_train_time_s\": 10.157980680465698}", "{\"n\": 12363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.36, \"learn_time_ms\": 8667.196, \"total_train_time_s\": 9.753982782363892}", "{\"n\": 12364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.92, \"learn_time_ms\": 8805.685, \"total_train_time_s\": 10.405409812927246}", "{\"n\": 12365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.92, \"learn_time_ms\": 8868.726, \"total_train_time_s\": 10.600606918334961}", "{\"n\": 12366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.09, \"learn_time_ms\": 8889.303, \"total_train_time_s\": 9.98714828491211}", "{\"n\": 12367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.61, \"learn_time_ms\": 8894.807, \"total_train_time_s\": 10.070662021636963}", "{\"n\": 12368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.66, \"learn_time_ms\": 8818.283, \"total_train_time_s\": 9.546607255935669}", "{\"n\": 12369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.21, \"learn_time_ms\": 8697.645, \"total_train_time_s\": 9.258861780166626}", "{\"n\": 12370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.04, \"learn_time_ms\": 8616.558, \"total_train_time_s\": 9.545087337493896}", "{\"n\": 12371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.59, \"learn_time_ms\": 8598.04, \"total_train_time_s\": 10.564319610595703}", "{\"n\": 12372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.59, \"learn_time_ms\": 8596.098, \"total_train_time_s\": 10.15217924118042}", "{\"n\": 12373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.12, \"learn_time_ms\": 8646.095, \"total_train_time_s\": 10.257673501968384}", "{\"n\": 12374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.02, \"learn_time_ms\": 8558.911, \"total_train_time_s\": 9.615280389785767}", "{\"n\": 12375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.85, \"learn_time_ms\": 8542.568, \"total_train_time_s\": 10.484782218933105}", "{\"n\": 12376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.03, \"learn_time_ms\": 8487.047, \"total_train_time_s\": 9.42686152458191}", "{\"n\": 12377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.2, \"learn_time_ms\": 8550.52, \"total_train_time_s\": 10.736422300338745}", "{\"n\": 12378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.63, \"learn_time_ms\": 8582.501, \"total_train_time_s\": 9.907242774963379}", "{\"n\": 12379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.35, \"learn_time_ms\": 8659.25, \"total_train_time_s\": 10.009469032287598}", "{\"n\": 12380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.57, \"learn_time_ms\": 8627.527, \"total_train_time_s\": 9.173497438430786}", "{\"n\": 12381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.72, \"learn_time_ms\": 8621.184, \"total_train_time_s\": 10.483794927597046}", "{\"n\": 12382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.72, \"learn_time_ms\": 8621.06, \"total_train_time_s\": 10.139031171798706}", "{\"n\": 12383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.28, \"learn_time_ms\": 8559.849, \"total_train_time_s\": 9.649960994720459}", "{\"n\": 12384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.55, \"learn_time_ms\": 8604.474, \"total_train_time_s\": 10.045144319534302}", "{\"n\": 12385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.38, \"learn_time_ms\": 8635.857, \"total_train_time_s\": 10.87986445426941}", "{\"n\": 12386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.93, \"learn_time_ms\": 8676.527, \"total_train_time_s\": 9.849971294403076}", "{\"n\": 12387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.87, \"learn_time_ms\": 8689.451, \"total_train_time_s\": 10.987098455429077}", "{\"n\": 12388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.24, \"learn_time_ms\": 8753.966, \"total_train_time_s\": 10.46810245513916}", "{\"n\": 12389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.66, \"learn_time_ms\": 8781.117, \"total_train_time_s\": 10.282597780227661}", "{\"n\": 12390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.16, \"learn_time_ms\": 8927.287, \"total_train_time_s\": 10.714788913726807}", "{\"n\": 12391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.79, \"learn_time_ms\": 8911.663, \"total_train_time_s\": 10.322227478027344}", "{\"n\": 12392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.79, \"learn_time_ms\": 8850.039, \"total_train_time_s\": 9.564029693603516}", "{\"n\": 12393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.33, \"learn_time_ms\": 8918.994, \"total_train_time_s\": 10.306425333023071}", "{\"n\": 12394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.77, \"learn_time_ms\": 8945.053, \"total_train_time_s\": 10.282465934753418}", "{\"n\": 12395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.88, \"learn_time_ms\": 8747.363, \"total_train_time_s\": 8.813730239868164}", "{\"n\": 12396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.73, \"learn_time_ms\": 8766.288, \"total_train_time_s\": 10.037098169326782}", "{\"n\": 12397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.79, \"learn_time_ms\": 8728.945, \"total_train_time_s\": 10.54695749282837}", "{\"n\": 12398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.12, \"learn_time_ms\": 8808.373, \"total_train_time_s\": 11.278942346572876}", "{\"n\": 12399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.09, \"learn_time_ms\": 8794.693, \"total_train_time_s\": 10.135452508926392}", "{\"n\": 12400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.02, \"learn_time_ms\": 8562.881, \"total_train_time_s\": 8.317535400390625}", "{\"n\": 12401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.32, \"learn_time_ms\": 8443.558, \"total_train_time_s\": 9.147518634796143}", "{\"n\": 12402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.77, \"learn_time_ms\": 8416.196, \"total_train_time_s\": 9.25443148612976}", "{\"n\": 12403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.77, \"learn_time_ms\": 8409.675, \"total_train_time_s\": 10.302067518234253}", "{\"n\": 12404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.74, \"learn_time_ms\": 8322.472, \"total_train_time_s\": 9.46826171875}", "{\"n\": 12405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.79, \"learn_time_ms\": 8398.752, \"total_train_time_s\": 9.602151870727539}", "{\"n\": 12406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.79, \"learn_time_ms\": 8334.084, \"total_train_time_s\": 9.38260817527771}", "{\"n\": 12407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.58, \"learn_time_ms\": 8269.826, \"total_train_time_s\": 9.875703573226929}", "{\"n\": 12408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.58, \"learn_time_ms\": 8070.872, \"total_train_time_s\": 9.30317211151123}", "{\"n\": 12409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.73, \"learn_time_ms\": 7991.158, \"total_train_time_s\": 9.377043724060059}", "{\"n\": 12410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.11, \"learn_time_ms\": 8208.425, \"total_train_time_s\": 10.528290748596191}", "{\"n\": 12411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.13, \"learn_time_ms\": 8306.532, \"total_train_time_s\": 10.116844177246094}", "{\"n\": 12412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.09, \"learn_time_ms\": 8381.254, \"total_train_time_s\": 10.014653444290161}", "{\"n\": 12413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.04, \"learn_time_ms\": 8404.654, \"total_train_time_s\": 10.508906126022339}", "{\"n\": 12414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.48, \"learn_time_ms\": 8388.729, \"total_train_time_s\": 9.199848175048828}", "{\"n\": 12415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.48, \"learn_time_ms\": 8482.694, \"total_train_time_s\": 10.531705141067505}", "{\"n\": 12416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 8576.914, \"total_train_time_s\": 10.309621572494507}", "{\"n\": 12417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.41, \"learn_time_ms\": 8693.757, \"total_train_time_s\": 11.01081895828247}", "{\"n\": 12418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.41, \"learn_time_ms\": 8754.452, \"total_train_time_s\": 9.902557373046875}", "{\"n\": 12419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.58, \"learn_time_ms\": 8724.415, \"total_train_time_s\": 9.00310492515564}", "{\"n\": 12420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.19, \"learn_time_ms\": 8700.597, \"total_train_time_s\": 10.303539276123047}", "{\"n\": 12421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.19, \"learn_time_ms\": 8668.904, \"total_train_time_s\": 9.820995330810547}", "{\"n\": 12422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.36, \"learn_time_ms\": 8593.258, \"total_train_time_s\": 9.262467622756958}", "{\"n\": 12423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.66, \"learn_time_ms\": 8648.843, \"total_train_time_s\": 11.064675569534302}", "{\"n\": 12424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.41, \"learn_time_ms\": 8597.91, \"total_train_time_s\": 8.706923484802246}", "{\"n\": 12425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.0, \"learn_time_ms\": 8513.099, \"total_train_time_s\": 9.655123472213745}", "{\"n\": 12426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.32, \"learn_time_ms\": 8467.951, \"total_train_time_s\": 9.910874843597412}", "{\"n\": 12427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.98, \"learn_time_ms\": 8379.667, \"total_train_time_s\": 10.15154767036438}", "{\"n\": 12428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.98, \"learn_time_ms\": 8323.605, \"total_train_time_s\": 9.366575717926025}", "{\"n\": 12429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.3, \"learn_time_ms\": 8418.811, \"total_train_time_s\": 10.038992643356323}", "{\"n\": 12430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.71, \"learn_time_ms\": 8342.538, \"total_train_time_s\": 9.526491403579712}", "{\"n\": 12431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.71, \"learn_time_ms\": 8454.465, \"total_train_time_s\": 10.93053150177002}", "{\"n\": 12432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.95, \"learn_time_ms\": 8496.556, \"total_train_time_s\": 9.712056875228882}", "{\"n\": 12433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.62, \"learn_time_ms\": 8483.908, \"total_train_time_s\": 10.908041715621948}", "{\"n\": 12434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.73, \"learn_time_ms\": 8502.059, \"total_train_time_s\": 8.92867922782898}", "{\"n\": 12435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.73, \"learn_time_ms\": 8544.699, \"total_train_time_s\": 10.08370327949524}", "{\"n\": 12436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.58, \"learn_time_ms\": 8535.992, \"total_train_time_s\": 9.795350313186646}", "{\"n\": 12437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.64, \"learn_time_ms\": 8568.268, \"total_train_time_s\": 10.46356725692749}", "{\"n\": 12438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.29, \"learn_time_ms\": 8667.811, \"total_train_time_s\": 10.360023260116577}", "{\"n\": 12439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.96, \"learn_time_ms\": 8605.751, \"total_train_time_s\": 9.429173231124878}", "{\"n\": 12440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.93, \"learn_time_ms\": 8664.64, \"total_train_time_s\": 10.169376850128174}", "{\"n\": 12441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.93, \"learn_time_ms\": 8489.262, \"total_train_time_s\": 9.18938159942627}", "{\"n\": 12442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.39, \"learn_time_ms\": 8643.555, \"total_train_time_s\": 11.230587244033813}", "{\"n\": 12443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.58, \"learn_time_ms\": 8709.005, \"total_train_time_s\": 11.563557624816895}", "{\"n\": 12444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.5, \"learn_time_ms\": 8818.303, \"total_train_time_s\": 9.99573826789856}", "{\"n\": 12445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.5, \"learn_time_ms\": 8768.624, \"total_train_time_s\": 9.611727237701416}", "{\"n\": 12446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.36, \"learn_time_ms\": 8822.815, \"total_train_time_s\": 10.390565156936646}", "{\"n\": 12447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.36, \"learn_time_ms\": 8656.846, \"total_train_time_s\": 8.794264793395996}", "{\"n\": 12448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.57, \"learn_time_ms\": 8497.771, \"total_train_time_s\": 8.744307041168213}", "{\"n\": 12449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.03, \"learn_time_ms\": 8544.372, \"total_train_time_s\": 9.848130702972412}", "{\"n\": 12450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.46, \"learn_time_ms\": 8413.069, \"total_train_time_s\": 8.757417917251587}", "{\"n\": 12451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3293.63, \"learn_time_ms\": 8453.249, \"total_train_time_s\": 9.563910961151123}", "{\"n\": 12452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.55, \"learn_time_ms\": 8355.313, \"total_train_time_s\": 10.201990365982056}", "{\"n\": 12453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.37, \"learn_time_ms\": 8197.707, \"total_train_time_s\": 10.0462965965271}", "{\"n\": 12454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.37, \"learn_time_ms\": 8165.891, \"total_train_time_s\": 9.722302198410034}", "{\"n\": 12455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.78, \"learn_time_ms\": 8238.37, \"total_train_time_s\": 10.348743200302124}", "{\"n\": 12456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.1, \"learn_time_ms\": 8250.662, \"total_train_time_s\": 10.42966079711914}", "{\"n\": 12457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.1, \"learn_time_ms\": 8422.6, \"total_train_time_s\": 10.52634072303772}", "{\"n\": 12458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.92, \"learn_time_ms\": 8474.889, \"total_train_time_s\": 9.250303745269775}", "{\"n\": 12459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.01, \"learn_time_ms\": 8409.557, \"total_train_time_s\": 9.205188035964966}", "{\"n\": 12460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.26, \"learn_time_ms\": 8585.467, \"total_train_time_s\": 10.563654899597168}", "{\"n\": 12461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.09, \"learn_time_ms\": 8572.052, \"total_train_time_s\": 9.417388439178467}", "{\"n\": 12462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.74, \"learn_time_ms\": 8371.445, \"total_train_time_s\": 8.204711675643921}", "{\"n\": 12463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.34, \"learn_time_ms\": 8370.29, \"total_train_time_s\": 9.998034954071045}", "{\"n\": 12464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.34, \"learn_time_ms\": 8358.476, \"total_train_time_s\": 9.572051525115967}", "{\"n\": 12465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.24, \"learn_time_ms\": 8297.63, \"total_train_time_s\": 9.780696868896484}", "{\"n\": 12466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.02, \"learn_time_ms\": 8100.369, \"total_train_time_s\": 8.489737749099731}", "{\"n\": 12467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.02, \"learn_time_ms\": 8031.963, \"total_train_time_s\": 9.816041707992554}", "{\"n\": 12468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.29, \"learn_time_ms\": 8131.0, \"total_train_time_s\": 10.281242370605469}", "{\"n\": 12469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.29, \"learn_time_ms\": 8228.188, \"total_train_time_s\": 10.163881063461304}", "{\"n\": 12470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.35, \"learn_time_ms\": 8058.603, \"total_train_time_s\": 8.904345750808716}", "{\"n\": 12471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.68, \"learn_time_ms\": 8066.063, \"total_train_time_s\": 9.549001455307007}", "{\"n\": 12472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.68, \"learn_time_ms\": 8179.736, \"total_train_time_s\": 9.35253381729126}", "{\"n\": 12473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.27, \"learn_time_ms\": 8233.362, \"total_train_time_s\": 10.463521480560303}", "{\"n\": 12474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.05, \"learn_time_ms\": 8241.924, \"total_train_time_s\": 9.680625438690186}", "{\"n\": 12475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.16, \"learn_time_ms\": 8323.341, \"total_train_time_s\": 10.544328212738037}", "{\"n\": 12476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.3, \"learn_time_ms\": 8364.773, \"total_train_time_s\": 8.881441593170166}", "{\"n\": 12477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.58, \"learn_time_ms\": 8329.311, \"total_train_time_s\": 9.523698091506958}", "{\"n\": 12478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.58, \"learn_time_ms\": 8369.784, \"total_train_time_s\": 10.701279401779175}", "{\"n\": 12479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.53, \"learn_time_ms\": 8433.392, \"total_train_time_s\": 10.804640054702759}", "{\"n\": 12480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.44, \"learn_time_ms\": 8640.888, \"total_train_time_s\": 10.935473203659058}", "{\"n\": 12481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.45, \"learn_time_ms\": 8711.296, \"total_train_time_s\": 10.228110790252686}", "{\"n\": 12482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.48, \"learn_time_ms\": 8583.317, \"total_train_time_s\": 8.069790124893188}", "{\"n\": 12483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.48, \"learn_time_ms\": 8565.474, \"total_train_time_s\": 10.319130182266235}", "{\"n\": 12484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.56, \"learn_time_ms\": 8477.688, \"total_train_time_s\": 8.799132108688354}", "{\"n\": 12485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.18, \"learn_time_ms\": 8402.621, \"total_train_time_s\": 9.802188873291016}", "{\"n\": 12486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.18, \"learn_time_ms\": 8546.999, \"total_train_time_s\": 10.377731323242188}", "{\"n\": 12487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.09, \"learn_time_ms\": 8507.61, \"total_train_time_s\": 9.085392951965332}", "{\"n\": 12488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.09, \"learn_time_ms\": 8574.433, \"total_train_time_s\": 11.336323738098145}", "{\"n\": 12489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.21, \"learn_time_ms\": 8557.617, \"total_train_time_s\": 10.636899948120117}", "{\"n\": 12490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.67, \"learn_time_ms\": 8569.365, \"total_train_time_s\": 11.005988597869873}", "{\"n\": 12491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.1, \"learn_time_ms\": 8687.541, \"total_train_time_s\": 11.409995317459106}", "{\"n\": 12492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.84, \"learn_time_ms\": 8888.231, \"total_train_time_s\": 10.040812492370605}", "{\"n\": 12493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.17, \"learn_time_ms\": 8850.801, \"total_train_time_s\": 10.002151489257812}", "{\"n\": 12494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.38, \"learn_time_ms\": 8907.528, \"total_train_time_s\": 9.350194692611694}", "{\"n\": 12495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.12, \"learn_time_ms\": 8896.283, \"total_train_time_s\": 9.661779642105103}", "{\"n\": 12496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.12, \"learn_time_ms\": 8854.308, \"total_train_time_s\": 9.964104175567627}", "{\"n\": 12497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.75, \"learn_time_ms\": 8892.604, \"total_train_time_s\": 9.511513471603394}", "{\"n\": 12498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.75, \"learn_time_ms\": 8755.957, \"total_train_time_s\": 9.932433366775513}", "{\"n\": 12499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.36, \"learn_time_ms\": 8595.984, \"total_train_time_s\": 9.019992351531982}", "{\"n\": 12500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.46, \"learn_time_ms\": 8424.744, \"total_train_time_s\": 9.327873706817627}", "{\"n\": 12501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.23, \"learn_time_ms\": 8265.72, \"total_train_time_s\": 9.81996488571167}", "{\"n\": 12502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.63, \"learn_time_ms\": 8237.563, \"total_train_time_s\": 9.81234097480774}", "{\"n\": 12503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.98, \"learn_time_ms\": 8216.215, \"total_train_time_s\": 9.750229835510254}", "{\"n\": 12504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.26, \"learn_time_ms\": 8248.594, \"total_train_time_s\": 9.620790004730225}", "{\"n\": 12505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.45, \"learn_time_ms\": 8274.863, \"total_train_time_s\": 9.902667999267578}", "{\"n\": 12506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.94, \"learn_time_ms\": 8200.048, \"total_train_time_s\": 9.188449382781982}", "{\"n\": 12507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.99, \"learn_time_ms\": 8281.313, \"total_train_time_s\": 10.310343265533447}", "{\"n\": 12508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.99, \"learn_time_ms\": 8390.536, \"total_train_time_s\": 11.118491888046265}", "{\"n\": 12509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.97, \"learn_time_ms\": 8437.697, \"total_train_time_s\": 9.512208461761475}", "{\"n\": 12510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.6, \"learn_time_ms\": 8370.395, \"total_train_time_s\": 8.634871482849121}", "{\"n\": 12511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.6, \"learn_time_ms\": 8313.598, \"total_train_time_s\": 9.195572137832642}", "{\"n\": 12512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.4, \"learn_time_ms\": 8414.302, \"total_train_time_s\": 10.909639835357666}", "{\"n\": 12513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.57, \"learn_time_ms\": 8427.049, \"total_train_time_s\": 9.891692638397217}", "{\"n\": 12514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.57, \"learn_time_ms\": 8461.933, \"total_train_time_s\": 9.977981567382812}", "{\"n\": 12515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.33, \"learn_time_ms\": 8494.785, \"total_train_time_s\": 10.209242105484009}", "{\"n\": 12516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.84, \"learn_time_ms\": 8581.129, \"total_train_time_s\": 10.026505947113037}", "{\"n\": 12517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.28, \"learn_time_ms\": 8517.387, \"total_train_time_s\": 9.67151403427124}", "{\"n\": 12518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.48, \"learn_time_ms\": 8286.54, \"total_train_time_s\": 8.768635034561157}", "{\"n\": 12519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.79, \"learn_time_ms\": 8321.118, \"total_train_time_s\": 9.827036142349243}", "{\"n\": 12520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.24, \"learn_time_ms\": 8341.356, \"total_train_time_s\": 8.874351024627686}", "{\"n\": 12521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.29, \"learn_time_ms\": 8365.273, \"total_train_time_s\": 9.466297626495361}", "{\"n\": 12522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.82, \"learn_time_ms\": 8340.435, \"total_train_time_s\": 10.585049629211426}", "{\"n\": 12523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.84, \"learn_time_ms\": 8387.156, \"total_train_time_s\": 10.378344297409058}", "{\"n\": 12524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.84, \"learn_time_ms\": 8526.211, \"total_train_time_s\": 11.373938083648682}", "{\"n\": 12525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.48, \"learn_time_ms\": 8411.49, \"total_train_time_s\": 9.143601894378662}", "{\"n\": 12526, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.8, \"learn_time_ms\": 8459.66, \"total_train_time_s\": 10.551305294036865}", "{\"n\": 12527, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.39, \"learn_time_ms\": 8498.965, \"total_train_time_s\": 10.049596786499023}", "{\"n\": 12528, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.39, \"learn_time_ms\": 8596.774, \"total_train_time_s\": 9.729378938674927}", "{\"n\": 12529, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.96, \"learn_time_ms\": 8557.948, \"total_train_time_s\": 9.445880889892578}", "{\"n\": 12530, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.53, \"learn_time_ms\": 8734.213, \"total_train_time_s\": 10.662469863891602}", "{\"n\": 12531, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.53, \"learn_time_ms\": 8822.914, \"total_train_time_s\": 10.385146379470825}", "{\"n\": 12532, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.38, \"learn_time_ms\": 8780.829, \"total_train_time_s\": 10.185850620269775}", "{\"n\": 12533, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.17, \"learn_time_ms\": 8748.326, \"total_train_time_s\": 10.049285411834717}", "{\"n\": 12534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.58, \"learn_time_ms\": 8559.3, \"total_train_time_s\": 9.52451229095459}", "{\"n\": 12535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.58, \"learn_time_ms\": 8537.88, \"total_train_time_s\": 8.883339643478394}", "{\"n\": 12536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.92, \"learn_time_ms\": 8497.452, \"total_train_time_s\": 10.15271782875061}", "{\"n\": 12537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.1, \"learn_time_ms\": 8607.715, \"total_train_time_s\": 11.152265071868896}", "{\"n\": 12538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.1, \"learn_time_ms\": 8604.302, \"total_train_time_s\": 9.721172094345093}", "{\"n\": 12539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.1, \"learn_time_ms\": 8670.493, \"total_train_time_s\": 10.099616050720215}", "{\"n\": 12540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.6, \"learn_time_ms\": 8659.435, \"total_train_time_s\": 10.532808303833008}", "{\"n\": 12541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.77, \"learn_time_ms\": 8703.164, \"total_train_time_s\": 10.765188694000244}", "{\"n\": 12542, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.77, \"learn_time_ms\": 8692.778, \"total_train_time_s\": 10.061132907867432}", "{\"n\": 12543, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.42, \"learn_time_ms\": 8869.734, \"total_train_time_s\": 11.847189664840698}", "{\"n\": 12544, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.85, \"learn_time_ms\": 8875.154, \"total_train_time_s\": 9.632132053375244}", "{\"n\": 12545, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.5, \"learn_time_ms\": 8995.379, \"total_train_time_s\": 10.158001899719238}", "{\"n\": 12546, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.5, \"learn_time_ms\": 8933.666, \"total_train_time_s\": 9.500079154968262}", "{\"n\": 12547, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.29, \"learn_time_ms\": 8817.528, \"total_train_time_s\": 9.99407148361206}", "{\"n\": 12548, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3336.21, \"learn_time_ms\": 8756.792, \"total_train_time_s\": 9.139697790145874}", "{\"n\": 12549, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3329.97, \"learn_time_ms\": 8627.678, \"total_train_time_s\": 8.831573247909546}", "{\"n\": 12550, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3329.97, \"learn_time_ms\": 8542.595, \"total_train_time_s\": 9.65273118019104}", "{\"n\": 12551, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3335.93, \"learn_time_ms\": 8396.479, \"total_train_time_s\": 9.36360764503479}", "{\"n\": 12552, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3333.47, \"learn_time_ms\": 8339.055, \"total_train_time_s\": 9.528709650039673}", "{\"n\": 12553, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3333.47, \"learn_time_ms\": 8242.669, \"total_train_time_s\": 10.854201316833496}", "{\"n\": 12554, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3329.8, \"learn_time_ms\": 8223.346, \"total_train_time_s\": 9.42920446395874}", "{\"n\": 12555, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.41, \"learn_time_ms\": 8217.009, \"total_train_time_s\": 10.110247373580933}", "{\"n\": 12556, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3315.36, \"learn_time_ms\": 8219.405, \"total_train_time_s\": 9.56804084777832}", "{\"n\": 12557, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3319.54, \"learn_time_ms\": 8140.265, \"total_train_time_s\": 9.205626726150513}", "{\"n\": 12558, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3322.51, \"learn_time_ms\": 8114.173, \"total_train_time_s\": 8.816126346588135}", "{\"n\": 12559, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3323.55, \"learn_time_ms\": 8166.387, \"total_train_time_s\": 9.352385997772217}", "{\"n\": 12560, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3314.8, \"learn_time_ms\": 8093.934, \"total_train_time_s\": 8.909866333007812}", "{\"n\": 12561, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3318.03, \"learn_time_ms\": 8168.571, \"total_train_time_s\": 10.11285400390625}", "{\"n\": 12562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3318.03, \"learn_time_ms\": 8161.496, \"total_train_time_s\": 9.405132055282593}", "{\"n\": 12563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3314.42, \"learn_time_ms\": 8140.368, \"total_train_time_s\": 10.622990608215332}", "{\"n\": 12564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.22, \"learn_time_ms\": 8180.572, \"total_train_time_s\": 9.815523862838745}", "{\"n\": 12565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.22, \"learn_time_ms\": 8175.982, \"total_train_time_s\": 10.000390768051147}", "{\"n\": 12566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.8, \"learn_time_ms\": 8222.852, \"total_train_time_s\": 9.985222339630127}", "{\"n\": 12567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3315.35, \"learn_time_ms\": 8482.876, \"total_train_time_s\": 11.824866771697998}", "{\"n\": 12568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3324.34, \"learn_time_ms\": 8614.754, \"total_train_time_s\": 10.201072931289673}", "{\"n\": 12569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3324.34, \"learn_time_ms\": 8704.205, \"total_train_time_s\": 10.220560073852539}", "{\"n\": 12570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3328.35, \"learn_time_ms\": 8874.328, \"total_train_time_s\": 10.650922536849976}", "{\"n\": 12571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.8, \"learn_time_ms\": 8972.45, \"total_train_time_s\": 11.075718402862549}", "{\"n\": 12572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3341.14, \"learn_time_ms\": 8959.431, \"total_train_time_s\": 9.31796669960022}", "{\"n\": 12573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3347.27, \"learn_time_ms\": 8799.18, \"total_train_time_s\": 9.01395034790039}", "{\"n\": 12574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3344.85, \"learn_time_ms\": 8871.918, \"total_train_time_s\": 10.47818374633789}", "{\"n\": 12575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.9, \"learn_time_ms\": 8872.04, \"total_train_time_s\": 10.015998601913452}", "{\"n\": 12576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.42, \"learn_time_ms\": 8769.921, \"total_train_time_s\": 8.983749628067017}", "{\"n\": 12577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.72, \"learn_time_ms\": 8477.775, \"total_train_time_s\": 8.900142669677734}", "{\"n\": 12578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.6, \"learn_time_ms\": 8392.046, \"total_train_time_s\": 9.352920532226562}", "{\"n\": 12579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3345.68, \"learn_time_ms\": 8236.451, \"total_train_time_s\": 8.742464780807495}", "{\"n\": 12580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3343.41, \"learn_time_ms\": 8225.62, \"total_train_time_s\": 10.508852243423462}", "{\"n\": 12581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3343.41, \"learn_time_ms\": 8064.943, \"total_train_time_s\": 9.465400457382202}", "{\"n\": 12582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.77, \"learn_time_ms\": 8084.086, \"total_train_time_s\": 9.498576164245605}", "{\"n\": 12583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.77, \"learn_time_ms\": 8197.063, \"total_train_time_s\": 10.118785619735718}", "{\"n\": 12584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.2, \"learn_time_ms\": 8173.049, \"total_train_time_s\": 10.298102855682373}", "{\"n\": 12585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.59, \"learn_time_ms\": 8344.74, \"total_train_time_s\": 11.725919008255005}", "{\"n\": 12586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.39, \"learn_time_ms\": 8459.708, \"total_train_time_s\": 10.121846914291382}", "{\"n\": 12587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3372.97, \"learn_time_ms\": 8662.124, \"total_train_time_s\": 10.937491655349731}", "{\"n\": 12588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 8624.376, \"total_train_time_s\": 8.911037921905518}", "{\"n\": 12589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.39, \"learn_time_ms\": 8761.345, \"total_train_time_s\": 10.064048528671265}", "{\"n\": 12590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.48, \"learn_time_ms\": 8543.698, \"total_train_time_s\": 8.366261720657349}", "{\"n\": 12591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3396.03, \"learn_time_ms\": 8520.999, \"total_train_time_s\": 9.273674488067627}", "{\"n\": 12592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3395.1, \"learn_time_ms\": 8510.944, \"total_train_time_s\": 9.350986003875732}", "{\"n\": 12593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3406.0, \"learn_time_ms\": 8556.958, \"total_train_time_s\": 10.61203908920288}", "{\"n\": 12594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3404.58, \"learn_time_ms\": 8536.075, \"total_train_time_s\": 10.070832014083862}", "{\"n\": 12595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3404.58, \"learn_time_ms\": 8278.883, \"total_train_time_s\": 9.172544002532959}", "{\"n\": 12596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3409.15, \"learn_time_ms\": 8270.326, \"total_train_time_s\": 10.070389747619629}", "{\"n\": 12597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.19, \"learn_time_ms\": 8053.354, \"total_train_time_s\": 8.74695110321045}", "{\"n\": 12598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.19, \"learn_time_ms\": 8294.906, \"total_train_time_s\": 11.354302167892456}", "{\"n\": 12599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.32, \"learn_time_ms\": 8298.749, \"total_train_time_s\": 10.15091323852539}", "{\"n\": 12600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3407.63, \"learn_time_ms\": 8413.004, \"total_train_time_s\": 9.503719091415405}", "{\"n\": 12601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3408.77, \"learn_time_ms\": 8399.741, \"total_train_time_s\": 9.136358499526978}", "{\"n\": 12602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3402.62, \"learn_time_ms\": 8413.036, \"total_train_time_s\": 9.495882749557495}", "{\"n\": 12603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3403.65, \"learn_time_ms\": 8292.589, \"total_train_time_s\": 9.35038137435913}", "{\"n\": 12604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3404.25, \"learn_time_ms\": 8212.727, \"total_train_time_s\": 9.271300554275513}", "{\"n\": 12605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3399.0, \"learn_time_ms\": 8395.701, \"total_train_time_s\": 10.948882818222046}", "{\"n\": 12606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3409.19, \"learn_time_ms\": 8273.666, \"total_train_time_s\": 8.870630502700806}", "{\"n\": 12607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3406.35, \"learn_time_ms\": 8467.635, \"total_train_time_s\": 10.700500726699829}", "{\"n\": 12608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3406.35, \"learn_time_ms\": 8283.407, \"total_train_time_s\": 9.552093744277954}", "{\"n\": 12609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3405.76, \"learn_time_ms\": 8315.634, \"total_train_time_s\": 10.432015657424927}", "{\"n\": 12610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3418.2, \"learn_time_ms\": 8331.086, \"total_train_time_s\": 9.716940879821777}", "{\"n\": 12611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3414.23, \"learn_time_ms\": 8425.521, \"total_train_time_s\": 10.10055947303772}", "{\"n\": 12612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.84, \"learn_time_ms\": 8415.535, \"total_train_time_s\": 9.431445360183716}", "{\"n\": 12613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.18, \"learn_time_ms\": 8462.935, \"total_train_time_s\": 9.86415433883667}", "{\"n\": 12614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3408.28, \"learn_time_ms\": 8584.619, \"total_train_time_s\": 10.48185396194458}", "{\"n\": 12615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3408.28, \"learn_time_ms\": 8379.386, \"total_train_time_s\": 8.89647102355957}", "{\"n\": 12616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3413.7, \"learn_time_ms\": 8536.44, \"total_train_time_s\": 10.396095514297485}", "{\"n\": 12617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3414.64, \"learn_time_ms\": 8414.106, \"total_train_time_s\": 9.477004766464233}", "{\"n\": 12618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3414.64, \"learn_time_ms\": 8424.003, \"total_train_time_s\": 9.623499393463135}", "{\"n\": 12619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3419.17, \"learn_time_ms\": 8426.802, \"total_train_time_s\": 10.48476505279541}", "{\"n\": 12620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3416.87, \"learn_time_ms\": 8590.451, \"total_train_time_s\": 11.314175844192505}", "{\"n\": 12621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.37, \"learn_time_ms\": 8541.95, \"total_train_time_s\": 9.52231478691101}", "{\"n\": 12622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.37, \"learn_time_ms\": 8534.839, \"total_train_time_s\": 9.323102474212646}", "{\"n\": 12623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3418.96, \"learn_time_ms\": 8342.425, \"total_train_time_s\": 7.944467544555664}", "{\"n\": 12624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3419.01, \"learn_time_ms\": 8265.568, \"total_train_time_s\": 9.748966932296753}", "{\"n\": 12625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3419.01, \"learn_time_ms\": 8409.629, \"total_train_time_s\": 10.325663089752197}", "{\"n\": 12626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3419.46, \"learn_time_ms\": 8407.865, \"total_train_time_s\": 10.351452112197876}", "{\"n\": 12627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3415.89, \"learn_time_ms\": 8486.999, \"total_train_time_s\": 10.263742446899414}", "{\"n\": 12628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3415.89, \"learn_time_ms\": 8546.558, \"total_train_time_s\": 10.175617456436157}", "{\"n\": 12629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3414.68, \"learn_time_ms\": 8506.716, \"total_train_time_s\": 10.039509534835815}", "{\"n\": 12630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.66, \"learn_time_ms\": 8423.282, \"total_train_time_s\": 10.471988916397095}", "{\"n\": 12631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.66, \"learn_time_ms\": 8599.373, \"total_train_time_s\": 11.378575563430786}", "{\"n\": 12632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.66, \"learn_time_ms\": 8704.331, \"total_train_time_s\": 10.37331485748291}", "{\"n\": 12633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.45, \"learn_time_ms\": 9032.171, \"total_train_time_s\": 11.206419229507446}", "{\"n\": 12634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.77, \"learn_time_ms\": 9037.234, \"total_train_time_s\": 9.792153120040894}", "{\"n\": 12635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.77, \"learn_time_ms\": 8910.781, \"total_train_time_s\": 9.07335638999939}", "{\"n\": 12636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.09, \"learn_time_ms\": 8999.958, \"total_train_time_s\": 11.24651026725769}", "{\"n\": 12637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.24, \"learn_time_ms\": 8950.484, \"total_train_time_s\": 9.724851131439209}", "{\"n\": 12638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.42, \"learn_time_ms\": 8954.254, \"total_train_time_s\": 10.250407934188843}", "{\"n\": 12639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.42, \"learn_time_ms\": 8777.761, \"total_train_time_s\": 8.268628358840942}", "{\"n\": 12640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.58, \"learn_time_ms\": 8648.641, \"total_train_time_s\": 9.250408172607422}", "{\"n\": 12641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.58, \"learn_time_ms\": 8474.079, \"total_train_time_s\": 9.598584413528442}", "{\"n\": 12642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.58, \"learn_time_ms\": 8470.445, \"total_train_time_s\": 10.362140655517578}", "{\"n\": 12643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.17, \"learn_time_ms\": 8328.476, \"total_train_time_s\": 9.763821601867676}", "{\"n\": 12644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.17, \"learn_time_ms\": 8336.524, \"total_train_time_s\": 9.85402250289917}", "{\"n\": 12645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.17, \"learn_time_ms\": 8475.073, \"total_train_time_s\": 10.503021717071533}", "{\"n\": 12646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.04, \"learn_time_ms\": 8379.202, \"total_train_time_s\": 10.313390970230103}", "{\"n\": 12647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.45, \"learn_time_ms\": 8236.089, \"total_train_time_s\": 8.290806531906128}", "{\"n\": 12648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.45, \"learn_time_ms\": 8244.718, \"total_train_time_s\": 10.32593059539795}", "{\"n\": 12649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.98, \"learn_time_ms\": 8471.798, \"total_train_time_s\": 10.558336973190308}", "{\"n\": 12650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.08, \"learn_time_ms\": 8557.469, \"total_train_time_s\": 10.016576290130615}", "{\"n\": 12651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.94, \"learn_time_ms\": 8578.687, \"total_train_time_s\": 9.818161964416504}", "{\"n\": 12652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.02, \"learn_time_ms\": 8589.363, \"total_train_time_s\": 10.450728416442871}", "{\"n\": 12653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.73, \"learn_time_ms\": 8582.735, \"total_train_time_s\": 9.668515920639038}", "{\"n\": 12654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.7, \"learn_time_ms\": 8768.406, \"total_train_time_s\": 11.66794228553772}", "{\"n\": 12655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.7, \"learn_time_ms\": 8703.11, \"total_train_time_s\": 9.820624589920044}", "{\"n\": 12656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.07, \"learn_time_ms\": 8642.01, \"total_train_time_s\": 9.699190855026245}", "{\"n\": 12657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.56, \"learn_time_ms\": 8957.73, \"total_train_time_s\": 11.491536855697632}", "{\"n\": 12658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.72, \"learn_time_ms\": 8864.109, \"total_train_time_s\": 9.382126569747925}", "{\"n\": 12659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.59, \"learn_time_ms\": 8793.401, \"total_train_time_s\": 9.877691984176636}", "{\"n\": 12660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.74, \"learn_time_ms\": 8685.235, \"total_train_time_s\": 8.925889015197754}", "{\"n\": 12661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.1, \"learn_time_ms\": 8736.189, \"total_train_time_s\": 10.286443710327148}", "{\"n\": 12662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.1, \"learn_time_ms\": 8898.216, \"total_train_time_s\": 12.086292743682861}", "{\"n\": 12663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.76, \"learn_time_ms\": 9007.879, \"total_train_time_s\": 10.831065654754639}", "{\"n\": 12664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.76, \"learn_time_ms\": 8709.205, \"total_train_time_s\": 8.710936307907104}", "{\"n\": 12665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.93, \"learn_time_ms\": 8827.972, \"total_train_time_s\": 11.066181659698486}", "{\"n\": 12666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.12, \"learn_time_ms\": 8952.191, \"total_train_time_s\": 10.985151529312134}", "{\"n\": 12667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.12, \"learn_time_ms\": 8782.942, \"total_train_time_s\": 9.744943857192993}", "{\"n\": 12668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.78, \"learn_time_ms\": 8868.362, \"total_train_time_s\": 10.21468997001648}", "{\"n\": 12669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.76, \"learn_time_ms\": 8841.044, \"total_train_time_s\": 9.565864324569702}", "{\"n\": 12670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.76, \"learn_time_ms\": 8929.874, \"total_train_time_s\": 9.825265407562256}", "{\"n\": 12671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.59, \"learn_time_ms\": 8887.072, \"total_train_time_s\": 9.86694860458374}", "{\"n\": 12672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.48, \"learn_time_ms\": 8575.198, \"total_train_time_s\": 8.959863662719727}", "{\"n\": 12673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.0, \"learn_time_ms\": 8519.758, \"total_train_time_s\": 10.282729625701904}", "{\"n\": 12674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.03, \"learn_time_ms\": 8571.018, \"total_train_time_s\": 9.25758171081543}", "{\"n\": 12675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.64, \"learn_time_ms\": 8380.857, \"total_train_time_s\": 9.12519359588623}", "{\"n\": 12676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 8229.505, \"total_train_time_s\": 9.44782042503357}", "{\"n\": 12677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 8222.929, \"total_train_time_s\": 9.69685697555542}", "{\"n\": 12678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.16, \"learn_time_ms\": 8242.101, \"total_train_time_s\": 10.443686962127686}", "{\"n\": 12679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.78, \"learn_time_ms\": 8246.753, \"total_train_time_s\": 9.60599422454834}", "{\"n\": 12680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.46, \"learn_time_ms\": 8340.388, \"total_train_time_s\": 10.790303707122803}", "{\"n\": 12681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.49, \"learn_time_ms\": 8250.836, \"total_train_time_s\": 9.014411687850952}", "{\"n\": 12682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.67, \"learn_time_ms\": 8328.272, \"total_train_time_s\": 9.720128059387207}", "{\"n\": 12683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.94, \"learn_time_ms\": 8426.961, \"total_train_time_s\": 11.259519100189209}", "{\"n\": 12684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.94, \"learn_time_ms\": 8472.417, \"total_train_time_s\": 9.62355351448059}", "{\"n\": 12685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.85, \"learn_time_ms\": 8523.227, \"total_train_time_s\": 9.658146858215332}", "{\"n\": 12686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 8522.993, \"total_train_time_s\": 9.408852577209473}", "{\"n\": 12687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.72, \"learn_time_ms\": 8481.07, \"total_train_time_s\": 9.280730724334717}", "{\"n\": 12688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.44, \"learn_time_ms\": 8347.749, \"total_train_time_s\": 9.079143047332764}", "{\"n\": 12689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.5, \"learn_time_ms\": 8283.504, \"total_train_time_s\": 9.004505634307861}", "{\"n\": 12690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.5, \"learn_time_ms\": 8376.59, \"total_train_time_s\": 11.859369039535522}", "{\"n\": 12691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.17, \"learn_time_ms\": 8422.041, \"total_train_time_s\": 9.468819856643677}", "{\"n\": 12692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.44, \"learn_time_ms\": 8288.832, \"total_train_time_s\": 8.372490167617798}", "{\"n\": 12693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.03, \"learn_time_ms\": 8030.604, \"total_train_time_s\": 8.682389974594116}", "{\"n\": 12694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.49, \"learn_time_ms\": 8194.808, \"total_train_time_s\": 11.358793497085571}", "{\"n\": 12695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.49, \"learn_time_ms\": 8219.295, \"total_train_time_s\": 9.841617584228516}", "{\"n\": 12696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 8303.488, \"total_train_time_s\": 10.292745113372803}", "{\"n\": 12697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 8284.175, \"total_train_time_s\": 9.082194566726685}", "{\"n\": 12698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.71, \"learn_time_ms\": 8378.978, \"total_train_time_s\": 10.053164005279541}", "{\"n\": 12699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.6, \"learn_time_ms\": 8416.203, \"total_train_time_s\": 9.38497805595398}", "{\"n\": 12700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.6, \"learn_time_ms\": 8272.407, \"total_train_time_s\": 10.271785974502563}", "{\"n\": 12701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.47, \"learn_time_ms\": 8363.107, \"total_train_time_s\": 10.326020002365112}", "{\"n\": 12702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 8668.417, \"total_train_time_s\": 11.442164897918701}", "{\"n\": 12703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.0, \"learn_time_ms\": 8863.821, \"total_train_time_s\": 10.637799501419067}", "{\"n\": 12704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.0, \"learn_time_ms\": 8743.868, \"total_train_time_s\": 10.067259788513184}", "{\"n\": 12705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.0, \"learn_time_ms\": 8893.197, \"total_train_time_s\": 11.362008810043335}", "{\"n\": 12706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.5, \"learn_time_ms\": 8790.672, \"total_train_time_s\": 9.224712371826172}", "{\"n\": 12707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.5, \"learn_time_ms\": 8911.073, \"total_train_time_s\": 10.320996046066284}", "{\"n\": 12708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.21, \"learn_time_ms\": 8920.2, \"total_train_time_s\": 10.128744840621948}", "{\"n\": 12709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.06, \"learn_time_ms\": 8923.932, \"total_train_time_s\": 9.434916496276855}", "{\"n\": 12710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.06, \"learn_time_ms\": 8838.998, \"total_train_time_s\": 9.441640853881836}", "{\"n\": 12711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.9, \"learn_time_ms\": 8799.924, \"total_train_time_s\": 9.950199604034424}", "{\"n\": 12712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.45, \"learn_time_ms\": 8923.528, \"total_train_time_s\": 12.625808000564575}", "{\"n\": 12713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.31, \"learn_time_ms\": 8803.819, \"total_train_time_s\": 9.401298761367798}", "{\"n\": 12714, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.93, \"learn_time_ms\": 8881.859, \"total_train_time_s\": 10.905218601226807}", "{\"n\": 12715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.82, \"learn_time_ms\": 8689.868, \"total_train_time_s\": 9.403642177581787}", "{\"n\": 12716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.47, \"learn_time_ms\": 8590.249, \"total_train_time_s\": 8.25573182106018}", "{\"n\": 12717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.01, \"learn_time_ms\": 8541.273, \"total_train_time_s\": 9.843517065048218}", "{\"n\": 12718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.01, \"learn_time_ms\": 8617.481, \"total_train_time_s\": 10.885521173477173}", "{\"n\": 12719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.44, \"learn_time_ms\": 8746.107, \"total_train_time_s\": 10.719664812088013}", "{\"n\": 12720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.91, \"learn_time_ms\": 8842.438, \"total_train_time_s\": 10.382937669754028}", "{\"n\": 12721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.91, \"learn_time_ms\": 8765.237, \"total_train_time_s\": 9.147382020950317}", "{\"n\": 12722, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.95, \"learn_time_ms\": 8442.261, \"total_train_time_s\": 9.477223634719849}", "{\"n\": 12723, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.41, \"learn_time_ms\": 8507.068, \"total_train_time_s\": 10.118148565292358}", "{\"n\": 12724, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.54, \"learn_time_ms\": 8457.604, \"total_train_time_s\": 10.461804151535034}", "{\"n\": 12725, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.54, \"learn_time_ms\": 8576.208, \"total_train_time_s\": 10.664698123931885}", "{\"n\": 12726, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.15, \"learn_time_ms\": 8652.071, \"total_train_time_s\": 8.990314960479736}", "{\"n\": 12727, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.83, \"learn_time_ms\": 8651.155, \"total_train_time_s\": 9.819095134735107}", "{\"n\": 12728, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.83, \"learn_time_ms\": 8477.136, \"total_train_time_s\": 9.167156219482422}", "{\"n\": 12729, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 8324.633, \"total_train_time_s\": 9.161102771759033}", "{\"n\": 12730, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.32, \"learn_time_ms\": 8338.914, \"total_train_time_s\": 10.499456882476807}", "{\"n\": 12731, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.32, \"learn_time_ms\": 8519.776, \"total_train_time_s\": 11.01712441444397}", "{\"n\": 12732, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.16, \"learn_time_ms\": 8619.845, \"total_train_time_s\": 10.544680833816528}", "{\"n\": 12733, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.31, \"learn_time_ms\": 8537.259, \"total_train_time_s\": 9.25567364692688}", "{\"n\": 12734, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.31, \"learn_time_ms\": 8494.011, \"total_train_time_s\": 10.013444423675537}", "{\"n\": 12735, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.22, \"learn_time_ms\": 8461.831, \"total_train_time_s\": 10.313832759857178}", "{\"n\": 12736, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.39, \"learn_time_ms\": 8666.347, \"total_train_time_s\": 11.087225437164307}", "{\"n\": 12737, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.3, \"learn_time_ms\": 8616.704, \"total_train_time_s\": 9.333835124969482}", "{\"n\": 12738, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.97, \"learn_time_ms\": 8804.529, \"total_train_time_s\": 11.082179546356201}", "{\"n\": 12739, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.35, \"learn_time_ms\": 8847.068, \"total_train_time_s\": 9.610548973083496}", "{\"n\": 12740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.76, \"learn_time_ms\": 8764.709, \"total_train_time_s\": 9.687121391296387}", "{\"n\": 12741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.76, \"learn_time_ms\": 8630.833, \"total_train_time_s\": 9.686087369918823}", "{\"n\": 12742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.32, \"learn_time_ms\": 8637.308, \"total_train_time_s\": 10.5214204788208}", "{\"n\": 12743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.33, \"learn_time_ms\": 8843.798, \"total_train_time_s\": 11.297341108322144}", "{\"n\": 12744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.33, \"learn_time_ms\": 8741.628, \"total_train_time_s\": 8.945070505142212}", "{\"n\": 12745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.36, \"learn_time_ms\": 8641.716, \"total_train_time_s\": 9.324005842208862}", "{\"n\": 12746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.48, \"learn_time_ms\": 8444.411, \"total_train_time_s\": 9.084025859832764}", "{\"n\": 12747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.48, \"learn_time_ms\": 8534.919, \"total_train_time_s\": 10.245068311691284}", "{\"n\": 12748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.48, \"learn_time_ms\": 8349.592, \"total_train_time_s\": 9.173430919647217}", "{\"n\": 12749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.72, \"learn_time_ms\": 8495.795, \"total_train_time_s\": 11.068033695220947}", "{\"n\": 12750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.76, \"learn_time_ms\": 8579.349, \"total_train_time_s\": 10.531768798828125}", "{\"n\": 12751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.76, \"learn_time_ms\": 8479.715, \"total_train_time_s\": 8.63632583618164}", "{\"n\": 12752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.0, \"learn_time_ms\": 8316.254, \"total_train_time_s\": 8.913147449493408}", "{\"n\": 12753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.15, \"learn_time_ms\": 8204.72, \"total_train_time_s\": 10.20211148262024}", "{\"n\": 12754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.98, \"learn_time_ms\": 8259.039, \"total_train_time_s\": 9.498910903930664}", "{\"n\": 12755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.06, \"learn_time_ms\": 8338.288, \"total_train_time_s\": 10.076931238174438}", "{\"n\": 12756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.84, \"learn_time_ms\": 8550.415, \"total_train_time_s\": 11.212390184402466}", "{\"n\": 12757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.56, \"learn_time_ms\": 8429.755, \"total_train_time_s\": 9.014507055282593}", "{\"n\": 12758, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.36, \"learn_time_ms\": 8523.685, \"total_train_time_s\": 10.149310111999512}", "{\"n\": 12759, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.26, \"learn_time_ms\": 8477.322, \"total_train_time_s\": 10.641024589538574}", "{\"n\": 12760, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.81, \"learn_time_ms\": 8474.665, \"total_train_time_s\": 10.48071837425232}", "{\"n\": 12761, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.81, \"learn_time_ms\": 8607.859, \"total_train_time_s\": 9.968471050262451}", "{\"n\": 12762, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.43, \"learn_time_ms\": 8635.019, \"total_train_time_s\": 9.10338306427002}", "{\"n\": 12763, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.49, \"learn_time_ms\": 8634.519, \"total_train_time_s\": 10.206948280334473}", "{\"n\": 12764, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.77, \"learn_time_ms\": 8649.483, \"total_train_time_s\": 9.654409170150757}", "{\"n\": 12765, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.9, \"learn_time_ms\": 8699.139, \"total_train_time_s\": 10.54931116104126}", "{\"n\": 12766, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.92, \"learn_time_ms\": 8533.764, \"total_train_time_s\": 9.509396076202393}", "{\"n\": 12767, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.56, \"learn_time_ms\": 8861.031, \"total_train_time_s\": 12.317603588104248}", "{\"n\": 12768, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.56, \"learn_time_ms\": 8931.119, \"total_train_time_s\": 10.784002780914307}", "{\"n\": 12769, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.95, \"learn_time_ms\": 8874.644, \"total_train_time_s\": 10.031859159469604}", "{\"n\": 12770, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.06, \"learn_time_ms\": 8804.471, \"total_train_time_s\": 9.84128212928772}", "{\"n\": 12771, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.06, \"learn_time_ms\": 8717.414, \"total_train_time_s\": 9.114570140838623}", "{\"n\": 12772, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.34, \"learn_time_ms\": 8739.007, \"total_train_time_s\": 9.428821802139282}", "{\"n\": 12773, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.07, \"learn_time_ms\": 8729.958, \"total_train_time_s\": 10.110704898834229}", "{\"n\": 12774, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.34, \"learn_time_ms\": 8678.343, \"total_train_time_s\": 9.091631174087524}", "{\"n\": 12775, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.75, \"learn_time_ms\": 8574.345, \"total_train_time_s\": 9.538259267807007}", "{\"n\": 12776, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.19, \"learn_time_ms\": 8575.053, \"total_train_time_s\": 9.519232034683228}", "{\"n\": 12777, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.86, \"learn_time_ms\": 8387.357, \"total_train_time_s\": 10.425952196121216}", "{\"n\": 12778, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.84, \"learn_time_ms\": 8267.509, \"total_train_time_s\": 9.650771856307983}", "{\"n\": 12779, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.4, \"learn_time_ms\": 8224.638, \"total_train_time_s\": 9.63842487335205}", "{\"n\": 12780, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.81, \"learn_time_ms\": 8447.944, \"total_train_time_s\": 12.081504583358765}", "{\"n\": 12781, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.92, \"learn_time_ms\": 8483.37, \"total_train_time_s\": 9.469953060150146}", "{\"n\": 12782, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.55, \"learn_time_ms\": 8547.115, \"total_train_time_s\": 10.0211341381073}", "{\"n\": 12783, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.81, \"learn_time_ms\": 8324.326, \"total_train_time_s\": 7.889022350311279}", "{\"n\": 12784, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.94, \"learn_time_ms\": 8307.562, \"total_train_time_s\": 8.97655200958252}", "{\"n\": 12785, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.94, \"learn_time_ms\": 8488.592, \"total_train_time_s\": 11.394037008285522}", "{\"n\": 12786, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.44, \"learn_time_ms\": 8291.823, \"total_train_time_s\": 7.5798375606536865}", "{\"n\": 12787, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.04, \"learn_time_ms\": 8044.167, \"total_train_time_s\": 7.8978190422058105}", "{\"n\": 12788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.7, \"learn_time_ms\": 8060.093, \"total_train_time_s\": 9.752749681472778}", "{\"n\": 12789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.7, \"learn_time_ms\": 8163.108, \"total_train_time_s\": 10.611566305160522}", "{\"n\": 12790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.5, \"learn_time_ms\": 7945.451, \"total_train_time_s\": 9.888522148132324}", "{\"n\": 12791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.96, \"learn_time_ms\": 7891.85, \"total_train_time_s\": 8.945586204528809}", "{\"n\": 12792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.44, \"learn_time_ms\": 7894.662, \"total_train_time_s\": 10.099543571472168}", "{\"n\": 12793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.65, \"learn_time_ms\": 8115.014, \"total_train_time_s\": 10.074649333953857}", "{\"n\": 12794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.48, \"learn_time_ms\": 8247.099, \"total_train_time_s\": 10.281799554824829}", "{\"n\": 12795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.48, \"learn_time_ms\": 8113.86, \"total_train_time_s\": 10.024794101715088}", "{\"n\": 12796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.5, \"learn_time_ms\": 8388.743, \"total_train_time_s\": 10.31260871887207}", "{\"n\": 12797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.87, \"learn_time_ms\": 8588.838, \"total_train_time_s\": 9.91222858428955}", "{\"n\": 12798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.77, \"learn_time_ms\": 8532.877, \"total_train_time_s\": 9.231096029281616}", "{\"n\": 12799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 8369.03, \"total_train_time_s\": 9.033199787139893}", "{\"n\": 12800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.64, \"learn_time_ms\": 8417.484, \"total_train_time_s\": 10.351952075958252}", "{\"n\": 12801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3344.61, \"learn_time_ms\": 8501.651, \"total_train_time_s\": 9.736783266067505}", "{\"n\": 12802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3344.8, \"learn_time_ms\": 8485.488, \"total_train_time_s\": 9.9096999168396}", "{\"n\": 12803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3345.11, \"learn_time_ms\": 8502.285, \"total_train_time_s\": 10.218289136886597}", "{\"n\": 12804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.79, \"learn_time_ms\": 8337.615, \"total_train_time_s\": 8.64700436592102}", "{\"n\": 12805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3336.98, \"learn_time_ms\": 8268.685, \"total_train_time_s\": 9.37501049041748}", "{\"n\": 12806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3336.98, \"learn_time_ms\": 8198.616, \"total_train_time_s\": 9.61102819442749}", "{\"n\": 12807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3333.95, \"learn_time_ms\": 8199.388, \"total_train_time_s\": 9.99338412284851}", "{\"n\": 12808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.76, \"learn_time_ms\": 8354.164, \"total_train_time_s\": 10.823227643966675}", "{\"n\": 12809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.76, \"learn_time_ms\": 8519.832, \"total_train_time_s\": 10.594305992126465}", "{\"n\": 12810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3329.68, \"learn_time_ms\": 8508.606, \"total_train_time_s\": 10.20854640007019}", "{\"n\": 12811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3329.36, \"learn_time_ms\": 8564.834, \"total_train_time_s\": 10.318513631820679}", "{\"n\": 12812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.78, \"learn_time_ms\": 8726.055, \"total_train_time_s\": 11.514013290405273}", "{\"n\": 12813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3335.32, \"learn_time_ms\": 8761.732, \"total_train_time_s\": 10.571727275848389}", "{\"n\": 12814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3335.32, \"learn_time_ms\": 9019.91, \"total_train_time_s\": 11.184435844421387}", "{\"n\": 12815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3351.4, \"learn_time_ms\": 9026.518, \"total_train_time_s\": 9.440695762634277}", "{\"n\": 12816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3352.4, \"learn_time_ms\": 9007.446, \"total_train_time_s\": 9.491533517837524}", "{\"n\": 12817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3352.4, \"learn_time_ms\": 9074.309, \"total_train_time_s\": 10.66118335723877}", "{\"n\": 12818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3352.28, \"learn_time_ms\": 9080.757, \"total_train_time_s\": 10.849926948547363}", "{\"n\": 12819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3352.28, \"learn_time_ms\": 8961.432, \"total_train_time_s\": 9.458950757980347}", "{\"n\": 12820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.68, \"learn_time_ms\": 8916.901, \"total_train_time_s\": 9.778003215789795}", "{\"n\": 12821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.8, \"learn_time_ms\": 8908.37, \"total_train_time_s\": 10.223322629928589}", "{\"n\": 12822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3350.24, \"learn_time_ms\": 8573.914, \"total_train_time_s\": 8.153943538665771}", "{\"n\": 12823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3347.18, \"learn_time_ms\": 8433.027, \"total_train_time_s\": 9.255998373031616}", "{\"n\": 12824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3346.67, \"learn_time_ms\": 8260.356, \"total_train_time_s\": 9.51921033859253}", "{\"n\": 12825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.85, \"learn_time_ms\": 8358.168, \"total_train_time_s\": 10.400451898574829}", "{\"n\": 12826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.25, \"learn_time_ms\": 8378.097, \"total_train_time_s\": 9.679432153701782}", "{\"n\": 12827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.25, \"learn_time_ms\": 8235.966, \"total_train_time_s\": 9.16303563117981}", "{\"n\": 12828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.73, \"learn_time_ms\": 8151.722, \"total_train_time_s\": 10.009808778762817}", "{\"n\": 12829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3334.73, \"learn_time_ms\": 8183.128, \"total_train_time_s\": 9.7862229347229}", "{\"n\": 12830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3334.73, \"learn_time_ms\": 8201.861, \"total_train_time_s\": 10.005657434463501}", "{\"n\": 12831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.22, \"learn_time_ms\": 8161.678, \"total_train_time_s\": 9.887386083602905}", "{\"n\": 12832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 8434.32, \"total_train_time_s\": 10.852798461914062}", "{\"n\": 12833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 8601.452, \"total_train_time_s\": 10.871825456619263}", "{\"n\": 12834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3324.2, \"learn_time_ms\": 8625.513, \"total_train_time_s\": 9.746580123901367}", "{\"n\": 12835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3328.23, \"learn_time_ms\": 8652.812, \"total_train_time_s\": 10.66945767402649}", "{\"n\": 12836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.14, \"learn_time_ms\": 8754.581, \"total_train_time_s\": 10.67249345779419}", "{\"n\": 12837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.14, \"learn_time_ms\": 8667.057, \"total_train_time_s\": 8.309499025344849}", "{\"n\": 12838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.46, \"learn_time_ms\": 8629.094, \"total_train_time_s\": 9.608088970184326}", "{\"n\": 12839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.65, \"learn_time_ms\": 8640.407, \"total_train_time_s\": 9.853610277175903}", "{\"n\": 12840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 8632.285, \"total_train_time_s\": 9.850642204284668}", "{\"n\": 12841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3345.12, \"learn_time_ms\": 8758.25, \"total_train_time_s\": 11.156519412994385}", "{\"n\": 12842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 8612.459, \"total_train_time_s\": 9.486174583435059}", "{\"n\": 12843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3347.1, \"learn_time_ms\": 8547.673, \"total_train_time_s\": 10.212697267532349}", "{\"n\": 12844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3343.66, \"learn_time_ms\": 8525.773, \"total_train_time_s\": 9.474773168563843}", "{\"n\": 12845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.16, \"learn_time_ms\": 8529.084, \"total_train_time_s\": 10.673660516738892}", "{\"n\": 12846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3351.7, \"learn_time_ms\": 8474.273, \"total_train_time_s\": 10.130868196487427}", "{\"n\": 12847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3351.7, \"learn_time_ms\": 8669.67, \"total_train_time_s\": 10.27031660079956}", "{\"n\": 12848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.69, \"learn_time_ms\": 8715.408, \"total_train_time_s\": 10.08407735824585}", "{\"n\": 12849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.18, \"learn_time_ms\": 8744.697, \"total_train_time_s\": 10.165526390075684}", "{\"n\": 12850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.7, \"learn_time_ms\": 8827.936, \"total_train_time_s\": 10.724501371383667}", "{\"n\": 12851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.04, \"learn_time_ms\": 8668.239, \"total_train_time_s\": 9.536648035049438}", "{\"n\": 12852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3355.38, \"learn_time_ms\": 8812.522, \"total_train_time_s\": 10.891978740692139}", "{\"n\": 12853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 8692.626, \"total_train_time_s\": 9.055676698684692}", "{\"n\": 12854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 8737.077, \"total_train_time_s\": 9.933621883392334}", "{\"n\": 12855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.89, \"learn_time_ms\": 8679.044, \"total_train_time_s\": 10.138112545013428}", "{\"n\": 12856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.77, \"learn_time_ms\": 8622.829, \"total_train_time_s\": 9.547245979309082}", "{\"n\": 12857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.82, \"learn_time_ms\": 8630.02, \"total_train_time_s\": 10.383261442184448}", "{\"n\": 12858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.17, \"learn_time_ms\": 8508.381, \"total_train_time_s\": 8.871858596801758}", "{\"n\": 12859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.5, \"learn_time_ms\": 8557.354, \"total_train_time_s\": 10.710401058197021}", "{\"n\": 12860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.28, \"learn_time_ms\": 8561.275, \"total_train_time_s\": 10.806833744049072}", "{\"n\": 12861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.81, \"learn_time_ms\": 8617.889, \"total_train_time_s\": 10.068817615509033}", "{\"n\": 12862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.96, \"learn_time_ms\": 8546.498, \"total_train_time_s\": 10.153451204299927}", "{\"n\": 12863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.14, \"learn_time_ms\": 8726.514, \"total_train_time_s\": 10.84917950630188}", "{\"n\": 12864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.43, \"learn_time_ms\": 8682.802, \"total_train_time_s\": 9.546261072158813}", "{\"n\": 12865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.07, \"learn_time_ms\": 8818.497, \"total_train_time_s\": 11.48186707496643}", "{\"n\": 12866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.91, \"learn_time_ms\": 8819.182, \"total_train_time_s\": 9.534836053848267}", "{\"n\": 12867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.33, \"learn_time_ms\": 8762.676, \"total_train_time_s\": 9.758985996246338}", "{\"n\": 12868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.33, \"learn_time_ms\": 8825.163, \"total_train_time_s\": 9.497010707855225}", "{\"n\": 12869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.12, \"learn_time_ms\": 8747.256, \"total_train_time_s\": 9.932056903839111}", "{\"n\": 12870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.06, \"learn_time_ms\": 8741.323, \"total_train_time_s\": 10.6779625415802}", "{\"n\": 12871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.61, \"learn_time_ms\": 8593.873, \"total_train_time_s\": 8.577468633651733}", "{\"n\": 12872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.61, \"learn_time_ms\": 8455.168, \"total_train_time_s\": 8.76633334159851}", "{\"n\": 12873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.78, \"learn_time_ms\": 8344.009, \"total_train_time_s\": 9.76784634590149}", "{\"n\": 12874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.78, \"learn_time_ms\": 8550.325, \"total_train_time_s\": 11.624095678329468}", "{\"n\": 12875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.72, \"learn_time_ms\": 8533.196, \"total_train_time_s\": 11.274474859237671}", "{\"n\": 12876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3391.95, \"learn_time_ms\": 8515.455, \"total_train_time_s\": 9.310956239700317}", "{\"n\": 12877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.3, \"learn_time_ms\": 8437.504, \"total_train_time_s\": 8.988651037216187}", "{\"n\": 12878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3399.21, \"learn_time_ms\": 8526.295, \"total_train_time_s\": 10.383171558380127}", "{\"n\": 12879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3399.21, \"learn_time_ms\": 8494.898, \"total_train_time_s\": 9.557724475860596}", "{\"n\": 12880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3403.57, \"learn_time_ms\": 8413.342, \"total_train_time_s\": 9.855475664138794}", "{\"n\": 12881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3403.34, \"learn_time_ms\": 8641.058, \"total_train_time_s\": 10.909708499908447}", "{\"n\": 12882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3403.34, \"learn_time_ms\": 8890.754, \"total_train_time_s\": 11.25762391090393}", "{\"n\": 12883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3409.25, \"learn_time_ms\": 9065.035, \"total_train_time_s\": 11.474449157714844}", "{\"n\": 12884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.29, \"learn_time_ms\": 9082.269, \"total_train_time_s\": 11.806660175323486}", "{\"n\": 12885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.58, \"learn_time_ms\": 9060.282, \"total_train_time_s\": 11.10411524772644}", "{\"n\": 12886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.91, \"learn_time_ms\": 9097.393, \"total_train_time_s\": 9.732832193374634}", "{\"n\": 12887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.75, \"learn_time_ms\": 9074.143, \"total_train_time_s\": 8.83802342414856}", "{\"n\": 12888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.04, \"learn_time_ms\": 8949.261, \"total_train_time_s\": 9.122739791870117}", "{\"n\": 12889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.33, \"learn_time_ms\": 8864.08, \"total_train_time_s\": 8.685241937637329}", "{\"n\": 12890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.1, \"learn_time_ms\": 8934.776, \"total_train_time_s\": 10.605450868606567}", "{\"n\": 12891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.22, \"learn_time_ms\": 8890.121, \"total_train_time_s\": 10.515592336654663}", "{\"n\": 12892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.22, \"learn_time_ms\": 8783.728, \"total_train_time_s\": 10.211217403411865}", "{\"n\": 12893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.58, \"learn_time_ms\": 8578.327, \"total_train_time_s\": 9.382554769515991}", "{\"n\": 12894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.8, \"learn_time_ms\": 8379.157, \"total_train_time_s\": 9.76559567451477}", "{\"n\": 12895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.8, \"learn_time_ms\": 8237.826, \"total_train_time_s\": 9.658322095870972}", "{\"n\": 12896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.44, \"learn_time_ms\": 8324.398, \"total_train_time_s\": 10.593322515487671}", "{\"n\": 12897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.13, \"learn_time_ms\": 8469.321, \"total_train_time_s\": 10.248816728591919}", "{\"n\": 12898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.02, \"learn_time_ms\": 8633.126, \"total_train_time_s\": 10.764721155166626}", "{\"n\": 12899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.95, \"learn_time_ms\": 8801.205, \"total_train_time_s\": 10.450807809829712}", "{\"n\": 12900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.75, \"learn_time_ms\": 8776.537, \"total_train_time_s\": 10.366480112075806}", "{\"n\": 12901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.45, \"learn_time_ms\": 8723.145, \"total_train_time_s\": 9.899794340133667}", "{\"n\": 12902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.45, \"learn_time_ms\": 8573.052, \"total_train_time_s\": 8.669655084609985}", "{\"n\": 12903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.42, \"learn_time_ms\": 8505.607, \"total_train_time_s\": 8.734415769577026}", "{\"n\": 12904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.53, \"learn_time_ms\": 8521.375, \"total_train_time_s\": 9.917806148529053}", "{\"n\": 12905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.53, \"learn_time_ms\": 8529.858, \"total_train_time_s\": 9.77703046798706}", "{\"n\": 12906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.91, \"learn_time_ms\": 8462.731, \"total_train_time_s\": 9.974016427993774}", "{\"n\": 12907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.96, \"learn_time_ms\": 8391.705, \"total_train_time_s\": 9.486863613128662}", "{\"n\": 12908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.83, \"learn_time_ms\": 8260.179, \"total_train_time_s\": 9.448189973831177}", "{\"n\": 12909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.83, \"learn_time_ms\": 8258.249, \"total_train_time_s\": 10.373099327087402}", "{\"n\": 12910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.65, \"learn_time_ms\": 8227.744, \"total_train_time_s\": 10.039731502532959}", "{\"n\": 12911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 8431.111, \"total_train_time_s\": 11.920210123062134}", "{\"n\": 12912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 8555.156, \"total_train_time_s\": 9.911704778671265}", "{\"n\": 12913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.32, \"learn_time_ms\": 8686.397, \"total_train_time_s\": 10.043291330337524}", "{\"n\": 12914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.69, \"learn_time_ms\": 8712.865, \"total_train_time_s\": 10.150189399719238}", "{\"n\": 12915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.1, \"learn_time_ms\": 8791.039, \"total_train_time_s\": 10.537366390228271}", "{\"n\": 12916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.1, \"learn_time_ms\": 8713.452, \"total_train_time_s\": 9.1620192527771}", "{\"n\": 12917, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.1, \"learn_time_ms\": 8790.402, \"total_train_time_s\": 10.265784978866577}", "{\"n\": 12918, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.18, \"learn_time_ms\": 8825.984, \"total_train_time_s\": 9.785737752914429}", "{\"n\": 12919, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.18, \"learn_time_ms\": 8732.41, \"total_train_time_s\": 9.453071117401123}", "{\"n\": 12920, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.11, \"learn_time_ms\": 8589.375, \"total_train_time_s\": 8.630003452301025}", "{\"n\": 12921, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.49, \"learn_time_ms\": 8443.569, \"total_train_time_s\": 10.486230373382568}", "{\"n\": 12922, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.49, \"learn_time_ms\": 8453.869, \"total_train_time_s\": 10.053137063980103}", "{\"n\": 12923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.65, \"learn_time_ms\": 8442.543, \"total_train_time_s\": 9.925264596939087}", "{\"n\": 12924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.49, \"learn_time_ms\": 8367.068, \"total_train_time_s\": 9.430985689163208}", "{\"n\": 12925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.47, \"learn_time_ms\": 8316.802, \"total_train_time_s\": 10.103509426116943}", "{\"n\": 12926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.59, \"learn_time_ms\": 8444.744, \"total_train_time_s\": 10.451251983642578}", "{\"n\": 12927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.28, \"learn_time_ms\": 8375.947, \"total_train_time_s\": 9.570656299591064}", "{\"n\": 12928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.61, \"learn_time_ms\": 8309.922, \"total_train_time_s\": 9.165470838546753}", "{\"n\": 12929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.99, \"learn_time_ms\": 8517.032, \"total_train_time_s\": 11.571746110916138}", "{\"n\": 12930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.63, \"learn_time_ms\": 8594.427, \"total_train_time_s\": 9.398037910461426}", "{\"n\": 12931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.42, \"learn_time_ms\": 8667.554, \"total_train_time_s\": 11.221827030181885}", "{\"n\": 12932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.34, \"learn_time_ms\": 8679.712, \"total_train_time_s\": 10.175720691680908}", "{\"n\": 12933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.34, \"learn_time_ms\": 8608.427, \"total_train_time_s\": 9.20634651184082}", "{\"n\": 12934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.24, \"learn_time_ms\": 8679.889, \"total_train_time_s\": 10.166248798370361}", "{\"n\": 12935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.17, \"learn_time_ms\": 8717.827, \"total_train_time_s\": 10.438064098358154}", "{\"n\": 12936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.17, \"learn_time_ms\": 8718.059, \"total_train_time_s\": 10.467192888259888}", "{\"n\": 12937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.35, \"learn_time_ms\": 8723.813, \"total_train_time_s\": 9.593912601470947}", "{\"n\": 12938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.24, \"learn_time_ms\": 8737.286, \"total_train_time_s\": 9.258506536483765}", "{\"n\": 12939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.24, \"learn_time_ms\": 8486.52, \"total_train_time_s\": 9.025007247924805}", "{\"n\": 12940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.24, \"learn_time_ms\": 8456.011, \"total_train_time_s\": 9.142849683761597}", "{\"n\": 12941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.09, \"learn_time_ms\": 8341.469, \"total_train_time_s\": 10.106321096420288}", "{\"n\": 12942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.93, \"learn_time_ms\": 8377.211, \"total_train_time_s\": 10.513556480407715}", "{\"n\": 12943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.93, \"learn_time_ms\": 8470.727, \"total_train_time_s\": 10.156597137451172}", "{\"n\": 12944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.88, \"learn_time_ms\": 8359.447, \"total_train_time_s\": 9.057862281799316}", "{\"n\": 12945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.75, \"learn_time_ms\": 8211.443, \"total_train_time_s\": 8.93537449836731}", "{\"n\": 12946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.75, \"learn_time_ms\": 8124.179, \"total_train_time_s\": 9.57599687576294}", "{\"n\": 12947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.75, \"learn_time_ms\": 8282.741, \"total_train_time_s\": 11.24563717842102}", "{\"n\": 12948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.94, \"learn_time_ms\": 8382.205, \"total_train_time_s\": 10.289635181427002}", "{\"n\": 12949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.23, \"learn_time_ms\": 8635.291, \"total_train_time_s\": 11.543159484863281}", "{\"n\": 12950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.23, \"learn_time_ms\": 8827.721, \"total_train_time_s\": 11.00529670715332}", "{\"n\": 12951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.73, \"learn_time_ms\": 8822.316, \"total_train_time_s\": 10.035557508468628}", "{\"n\": 12952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.36, \"learn_time_ms\": 8833.982, \"total_train_time_s\": 10.625069618225098}", "{\"n\": 12953, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.36, \"learn_time_ms\": 8864.434, \"total_train_time_s\": 10.439048290252686}", "{\"n\": 12954, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.11, \"learn_time_ms\": 8947.563, \"total_train_time_s\": 9.817182302474976}", "{\"n\": 12955, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.71, \"learn_time_ms\": 9004.783, \"total_train_time_s\": 9.54654335975647}", "{\"n\": 12956, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.71, \"learn_time_ms\": 9147.951, \"total_train_time_s\": 11.029993057250977}", "{\"n\": 12957, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.71, \"learn_time_ms\": 9146.15, \"total_train_time_s\": 11.202298164367676}", "{\"n\": 12958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.24, \"learn_time_ms\": 9083.147, \"total_train_time_s\": 9.648298978805542}", "{\"n\": 12959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.24, \"learn_time_ms\": 8870.529, \"total_train_time_s\": 9.377047061920166}", "{\"n\": 12960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.24, \"learn_time_ms\": 8722.735, \"total_train_time_s\": 9.546162843704224}", "{\"n\": 12961, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.21, \"learn_time_ms\": 8741.387, \"total_train_time_s\": 10.166796684265137}", "{\"n\": 12962, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.7, \"learn_time_ms\": 8757.053, \"total_train_time_s\": 10.800106048583984}", "{\"n\": 12963, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.7, \"learn_time_ms\": 8689.532, \"total_train_time_s\": 9.719271183013916}", "{\"n\": 12964, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.87, \"learn_time_ms\": 8809.729, \"total_train_time_s\": 11.048896312713623}", "{\"n\": 12965, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.17, \"learn_time_ms\": 8775.286, \"total_train_time_s\": 9.137411832809448}", "{\"n\": 12966, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.77, \"learn_time_ms\": 8596.114, \"total_train_time_s\": 9.288230180740356}", "{\"n\": 12967, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.77, \"learn_time_ms\": 8557.168, \"total_train_time_s\": 10.816952466964722}", "{\"n\": 12968, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.76, \"learn_time_ms\": 8635.579, \"total_train_time_s\": 10.426296949386597}", "{\"n\": 12969, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.76, \"learn_time_ms\": 8554.909, \"total_train_time_s\": 8.588549613952637}", "{\"n\": 12970, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.76, \"learn_time_ms\": 8559.399, \"total_train_time_s\": 9.606251239776611}", "{\"n\": 12971, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.48, \"learn_time_ms\": 8581.762, \"total_train_time_s\": 10.460702180862427}", "{\"n\": 12972, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.62, \"learn_time_ms\": 8415.883, \"total_train_time_s\": 9.108175039291382}", "{\"n\": 12973, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.46, \"learn_time_ms\": 8406.98, \"total_train_time_s\": 9.713661670684814}", "{\"n\": 12974, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.46, \"learn_time_ms\": 8261.102, \"total_train_time_s\": 9.59331464767456}", "{\"n\": 12975, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.55, \"learn_time_ms\": 8231.048, \"total_train_time_s\": 8.816173553466797}", "{\"n\": 12976, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.6, \"learn_time_ms\": 8074.486, \"total_train_time_s\": 7.616253614425659}", "{\"n\": 12977, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.6, \"learn_time_ms\": 8039.239, \"total_train_time_s\": 10.466716527938843}", "{\"n\": 12978, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.76, \"learn_time_ms\": 7960.99, \"total_train_time_s\": 9.643945932388306}", "{\"n\": 12979, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.0, \"learn_time_ms\": 8096.471, \"total_train_time_s\": 9.981832504272461}", "{\"n\": 12980, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.0, \"learn_time_ms\": 8047.447, \"total_train_time_s\": 9.066611528396606}", "{\"n\": 12981, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.08, \"learn_time_ms\": 7950.922, \"total_train_time_s\": 9.456808090209961}", "{\"n\": 12982, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.86, \"learn_time_ms\": 8131.346, \"total_train_time_s\": 10.962690353393555}", "{\"n\": 12983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.38, \"learn_time_ms\": 8112.838, \"total_train_time_s\": 9.51341700553894}", "{\"n\": 12984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.76, \"learn_time_ms\": 8079.083, \"total_train_time_s\": 9.277929067611694}", "{\"n\": 12985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.66, \"learn_time_ms\": 8191.542, \"total_train_time_s\": 9.957412719726562}", "{\"n\": 12986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.15, \"learn_time_ms\": 8450.151, \"total_train_time_s\": 10.182957172393799}", "{\"n\": 12987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.68, \"learn_time_ms\": 8468.588, \"total_train_time_s\": 10.66855001449585}", "{\"n\": 12988, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.56, \"learn_time_ms\": 8415.077, \"total_train_time_s\": 9.07523798942566}", "{\"n\": 12989, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.64, \"learn_time_ms\": 8464.475, \"total_train_time_s\": 10.456799745559692}", "{\"n\": 12990, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.73, \"learn_time_ms\": 8576.529, \"total_train_time_s\": 10.226027965545654}", "{\"n\": 12991, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.51, \"learn_time_ms\": 8547.294, \"total_train_time_s\": 9.156030654907227}", "{\"n\": 12992, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.3, \"learn_time_ms\": 8503.478, \"total_train_time_s\": 10.493102312088013}", "{\"n\": 12993, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.27, \"learn_time_ms\": 8522.798, \"total_train_time_s\": 9.723351955413818}", "{\"n\": 12994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.82, \"learn_time_ms\": 8530.405, \"total_train_time_s\": 9.351210117340088}", "{\"n\": 12995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.26, \"learn_time_ms\": 8505.757, \"total_train_time_s\": 9.734872579574585}", "{\"n\": 12996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.4, \"learn_time_ms\": 8578.785, \"total_train_time_s\": 10.980910539627075}", "{\"n\": 12997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.97, \"learn_time_ms\": 8625.018, \"total_train_time_s\": 11.130383729934692}", "{\"n\": 12998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.24, \"learn_time_ms\": 8732.176, \"total_train_time_s\": 10.193615913391113}", "{\"n\": 12999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.24, \"learn_time_ms\": 8673.601, \"total_train_time_s\": 9.888765573501587}", "{\"n\": 13000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.06, \"learn_time_ms\": 8526.551, \"total_train_time_s\": 8.74968934059143}", "{\"n\": 13001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.88, \"learn_time_ms\": 8600.422, \"total_train_time_s\": 9.938955545425415}", "{\"n\": 13002, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.88, \"learn_time_ms\": 8537.132, \"total_train_time_s\": 9.895608186721802}", "{\"n\": 13003, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.72, \"learn_time_ms\": 8666.433, \"total_train_time_s\": 11.030317544937134}", "{\"n\": 13004, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.94, \"learn_time_ms\": 8754.711, \"total_train_time_s\": 10.27974247932434}", "{\"n\": 13005, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.43, \"learn_time_ms\": 8629.838, \"total_train_time_s\": 8.458102226257324}", "{\"n\": 13006, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.45, \"learn_time_ms\": 8647.967, \"total_train_time_s\": 11.136777639389038}", "{\"n\": 13007, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.5, \"learn_time_ms\": 8418.344, \"total_train_time_s\": 8.80463194847107}", "{\"n\": 13008, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.42, \"learn_time_ms\": 8397.257, \"total_train_time_s\": 9.952891826629639}", "{\"n\": 13009, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.42, \"learn_time_ms\": 8416.659, \"total_train_time_s\": 10.064962148666382}", "{\"n\": 13010, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.51, \"learn_time_ms\": 8475.808, \"total_train_time_s\": 9.281094312667847}", "{\"n\": 13011, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.04, \"learn_time_ms\": 8539.135, \"total_train_time_s\": 10.574627161026001}", "{\"n\": 13012, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.17, \"learn_time_ms\": 8458.958, \"total_train_time_s\": 9.066483974456787}", "{\"n\": 13013, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.8, \"learn_time_ms\": 8429.374, \"total_train_time_s\": 10.707544326782227}", "{\"n\": 13014, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.09, \"learn_time_ms\": 8293.555, \"total_train_time_s\": 8.897362232208252}", "{\"n\": 13015, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.49, \"learn_time_ms\": 8497.904, \"total_train_time_s\": 10.527440786361694}", "{\"n\": 13016, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.02, \"learn_time_ms\": 8446.052, \"total_train_time_s\": 10.631527185440063}", "{\"n\": 13017, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.86, \"learn_time_ms\": 8569.591, \"total_train_time_s\": 10.050746202468872}", "{\"n\": 13018, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.86, \"learn_time_ms\": 8550.797, \"total_train_time_s\": 9.767408609390259}", "{\"n\": 13019, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.94, \"learn_time_ms\": 8551.468, \"total_train_time_s\": 10.078279495239258}", "{\"n\": 13020, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.08, \"learn_time_ms\": 8516.367, \"total_train_time_s\": 8.972683668136597}", "{\"n\": 13021, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.75, \"learn_time_ms\": 8431.642, \"total_train_time_s\": 9.699098348617554}", "{\"n\": 13022, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.75, \"learn_time_ms\": 8358.157, \"total_train_time_s\": 8.295241594314575}", "{\"n\": 13023, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.12, \"learn_time_ms\": 8307.681, \"total_train_time_s\": 10.164362668991089}", "{\"n\": 13024, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.56, \"learn_time_ms\": 8297.825, \"total_train_time_s\": 8.766335487365723}", "{\"n\": 13025, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.56, \"learn_time_ms\": 8332.155, \"total_train_time_s\": 10.934552431106567}", "{\"n\": 13026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.32, \"learn_time_ms\": 8134.185, \"total_train_time_s\": 8.653849363327026}", "{\"n\": 13027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.97, \"learn_time_ms\": 8226.504, \"total_train_time_s\": 10.978182554244995}", "{\"n\": 13028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.09, \"learn_time_ms\": 8185.62, \"total_train_time_s\": 9.33095097541809}", "{\"n\": 13029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.09, \"learn_time_ms\": 8196.152, \"total_train_time_s\": 10.17770528793335}", "{\"n\": 13030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.08, \"learn_time_ms\": 8246.969, \"total_train_time_s\": 9.51988172531128}", "{\"n\": 13031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.54, \"learn_time_ms\": 8396.82, \"total_train_time_s\": 11.168105125427246}", "{\"n\": 13032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.54, \"learn_time_ms\": 8657.148, \"total_train_time_s\": 10.885249137878418}", "{\"n\": 13033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.27, \"learn_time_ms\": 8558.763, \"total_train_time_s\": 9.254941940307617}", "{\"n\": 13034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.6, \"learn_time_ms\": 8698.253, \"total_train_time_s\": 10.19326901435852}", "{\"n\": 13035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.6, \"learn_time_ms\": 8671.936, \"total_train_time_s\": 10.61493968963623}", "{\"n\": 13036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.6, \"learn_time_ms\": 8764.78, \"total_train_time_s\": 9.571013450622559}", "{\"n\": 13037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.38, \"learn_time_ms\": 8636.99, \"total_train_time_s\": 9.739255666732788}", "{\"n\": 13038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.38, \"learn_time_ms\": 8599.615, \"total_train_time_s\": 8.94655156135559}", "{\"n\": 13039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.38, \"learn_time_ms\": 8543.062, \"total_train_time_s\": 9.62051510810852}", "{\"n\": 13040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.52, \"learn_time_ms\": 8458.114, \"total_train_time_s\": 8.683824300765991}", "{\"n\": 13041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.23, \"learn_time_ms\": 8133.431, \"total_train_time_s\": 7.966488838195801}", "{\"n\": 13042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.23, \"learn_time_ms\": 7992.016, \"total_train_time_s\": 9.498188018798828}", "{\"n\": 13043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.96, \"learn_time_ms\": 8107.949, \"total_train_time_s\": 10.393450021743774}", "{\"n\": 13044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.81, \"learn_time_ms\": 7978.966, \"total_train_time_s\": 8.907488584518433}", "{\"n\": 13045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.81, \"learn_time_ms\": 7872.832, \"total_train_time_s\": 9.53742504119873}", "{\"n\": 13046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.01, \"learn_time_ms\": 7876.23, \"total_train_time_s\": 9.60083556175232}", "{\"n\": 13047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.85, \"learn_time_ms\": 7911.098, \"total_train_time_s\": 10.01506781578064}", "{\"n\": 13048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.85, \"learn_time_ms\": 7937.152, \"total_train_time_s\": 9.248777151107788}", "{\"n\": 13049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.8, \"learn_time_ms\": 8079.515, \"total_train_time_s\": 10.991700887680054}", "{\"n\": 13050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.99, \"learn_time_ms\": 8167.064, \"total_train_time_s\": 9.540148973464966}", "{\"n\": 13051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.94, \"learn_time_ms\": 8400.085, \"total_train_time_s\": 10.274374008178711}", "{\"n\": 13052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.79, \"learn_time_ms\": 8328.238, \"total_train_time_s\": 8.811257123947144}", "{\"n\": 13053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.9, \"learn_time_ms\": 8315.515, \"total_train_time_s\": 10.257813215255737}", "{\"n\": 13054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.27, \"learn_time_ms\": 8424.747, \"total_train_time_s\": 9.945765733718872}", "{\"n\": 13055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.27, \"learn_time_ms\": 8533.057, \"total_train_time_s\": 10.617008686065674}", "{\"n\": 13056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.51, \"learn_time_ms\": 8561.677, \"total_train_time_s\": 9.917433977127075}", "{\"n\": 13057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.28, \"learn_time_ms\": 8582.098, \"total_train_time_s\": 10.268006563186646}", "{\"n\": 13058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.3, \"learn_time_ms\": 8716.14, \"total_train_time_s\": 10.592028141021729}", "{\"n\": 13059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.3, \"learn_time_ms\": 8657.827, \"total_train_time_s\": 10.44756817817688}", "{\"n\": 13060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.0, \"learn_time_ms\": 8625.241, \"total_train_time_s\": 9.231125593185425}", "{\"n\": 13061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.89, \"learn_time_ms\": 8348.056, \"total_train_time_s\": 7.4922826290130615}", "{\"n\": 13062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.89, \"learn_time_ms\": 8301.825, \"total_train_time_s\": 8.285722494125366}", "{\"n\": 13063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.39, \"learn_time_ms\": 8269.482, \"total_train_time_s\": 9.960921287536621}", "{\"n\": 13064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8305.66, \"total_train_time_s\": 10.311229467391968}", "{\"n\": 13065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8222.339, \"total_train_time_s\": 9.773447275161743}", "{\"n\": 13066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 8378.605, \"total_train_time_s\": 11.48710298538208}", "{\"n\": 13067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 8440.635, \"total_train_time_s\": 10.874826669692993}", "{\"n\": 13068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 8337.926, \"total_train_time_s\": 9.566269159317017}", "{\"n\": 13069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 8225.423, \"total_train_time_s\": 9.321591854095459}", "{\"n\": 13070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.46, \"learn_time_ms\": 8271.45, \"total_train_time_s\": 9.685819387435913}", "{\"n\": 13071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.46, \"learn_time_ms\": 8515.824, \"total_train_time_s\": 10.007081270217896}", "{\"n\": 13072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.46, \"learn_time_ms\": 8698.35, \"total_train_time_s\": 10.165260553359985}", "{\"n\": 13073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.92, \"learn_time_ms\": 8674.53, \"total_train_time_s\": 9.718942165374756}", "{\"n\": 13074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.27, \"learn_time_ms\": 8605.67, \"total_train_time_s\": 9.681729555130005}", "{\"n\": 13075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.27, \"learn_time_ms\": 8609.127, \"total_train_time_s\": 9.841019868850708}", "{\"n\": 13076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.93, \"learn_time_ms\": 8476.458, \"total_train_time_s\": 10.134058475494385}", "{\"n\": 13077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.3, \"learn_time_ms\": 8263.121, \"total_train_time_s\": 8.743785381317139}", "{\"n\": 13078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.3, \"learn_time_ms\": 8069.533, \"total_train_time_s\": 7.631225824356079}", "{\"n\": 13079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 7971.992, \"total_train_time_s\": 8.36642575263977}", "{\"n\": 13080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 7925.779, \"total_train_time_s\": 9.186505317687988}", "{\"n\": 13081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.5, \"learn_time_ms\": 7988.475, \"total_train_time_s\": 10.57256555557251}", "{\"n\": 13082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.52, \"learn_time_ms\": 8047.839, \"total_train_time_s\": 10.78306245803833}", "{\"n\": 13083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.26, \"learn_time_ms\": 8043.922, \"total_train_time_s\": 9.627935886383057}", "{\"n\": 13084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.05, \"learn_time_ms\": 8042.18, \"total_train_time_s\": 9.61047911643982}", "{\"n\": 13085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.05, \"learn_time_ms\": 8250.446, \"total_train_time_s\": 11.88875675201416}", "{\"n\": 13086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.6, \"learn_time_ms\": 8188.225, \"total_train_time_s\": 9.517388820648193}", "{\"n\": 13087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.99, \"learn_time_ms\": 8405.815, \"total_train_time_s\": 10.916218042373657}", "{\"n\": 13088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.99, \"learn_time_ms\": 8552.523, \"total_train_time_s\": 9.073930740356445}", "{\"n\": 13089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.4, \"learn_time_ms\": 8698.569, \"total_train_time_s\": 9.814735174179077}", "{\"n\": 13090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.59, \"learn_time_ms\": 8887.546, \"total_train_time_s\": 11.075908422470093}", "{\"n\": 13091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.96, \"learn_time_ms\": 8838.181, \"total_train_time_s\": 10.067089796066284}", "{\"n\": 13092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.15, \"learn_time_ms\": 8726.389, \"total_train_time_s\": 9.63139533996582}", "{\"n\": 13093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.38, \"learn_time_ms\": 8735.696, \"total_train_time_s\": 9.693233013153076}", "{\"n\": 13094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.92, \"learn_time_ms\": 8638.45, \"total_train_time_s\": 8.695963144302368}", "{\"n\": 13095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.86, \"learn_time_ms\": 8569.896, \"total_train_time_s\": 11.257995843887329}", "{\"n\": 13096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.57, \"learn_time_ms\": 8449.531, \"total_train_time_s\": 8.36261510848999}", "{\"n\": 13097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.73, \"learn_time_ms\": 8125.213, \"total_train_time_s\": 7.717413902282715}", "{\"n\": 13098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.96, \"learn_time_ms\": 8258.558, \"total_train_time_s\": 10.430389881134033}", "{\"n\": 13099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.71, \"learn_time_ms\": 8350.587, \"total_train_time_s\": 10.741062879562378}", "{\"n\": 13100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.89, \"learn_time_ms\": 8158.096, \"total_train_time_s\": 9.151328802108765}", "{\"n\": 13101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.02, \"learn_time_ms\": 8063.008, \"total_train_time_s\": 9.142414331436157}", "{\"n\": 13102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.43, \"learn_time_ms\": 8080.236, \"total_train_time_s\": 9.80172348022461}", "{\"n\": 13103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.43, \"learn_time_ms\": 8112.338, \"total_train_time_s\": 10.03428030014038}", "{\"n\": 13104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 8301.766, \"total_train_time_s\": 10.606995820999146}", "{\"n\": 13105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 8193.624, \"total_train_time_s\": 10.166681051254272}", "{\"n\": 13106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 8289.718, \"total_train_time_s\": 9.263541460037231}", "{\"n\": 13107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.63, \"learn_time_ms\": 8528.799, \"total_train_time_s\": 10.036511659622192}", "{\"n\": 13108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 8452.771, \"total_train_time_s\": 9.689759254455566}", "{\"n\": 13109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3373.46, \"learn_time_ms\": 8369.933, \"total_train_time_s\": 9.856621742248535}", "{\"n\": 13110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.98, \"learn_time_ms\": 8530.991, \"total_train_time_s\": 10.736091613769531}", "{\"n\": 13111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.09, \"learn_time_ms\": 8702.959, \"total_train_time_s\": 10.867343664169312}", "{\"n\": 13112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.85, \"learn_time_ms\": 8828.771, \"total_train_time_s\": 11.049744844436646}", "{\"n\": 13113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.85, \"learn_time_ms\": 8869.367, \"total_train_time_s\": 10.455077171325684}", "{\"n\": 13114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.74, \"learn_time_ms\": 8754.998, \"total_train_time_s\": 9.39740252494812}", "{\"n\": 13115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.74, \"learn_time_ms\": 8685.465, \"total_train_time_s\": 9.443311929702759}", "{\"n\": 13116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.15, \"learn_time_ms\": 8674.873, \"total_train_time_s\": 9.20963454246521}", "{\"n\": 13117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.01, \"learn_time_ms\": 8744.112, \"total_train_time_s\": 10.769190788269043}", "{\"n\": 13118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.13, \"learn_time_ms\": 8864.306, \"total_train_time_s\": 10.895256042480469}", "{\"n\": 13119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.89, \"learn_time_ms\": 8893.3, \"total_train_time_s\": 10.174466609954834}", "{\"n\": 13120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.82, \"learn_time_ms\": 8873.157, \"total_train_time_s\": 10.531795501708984}", "{\"n\": 13121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.35, \"learn_time_ms\": 8629.645, \"total_train_time_s\": 8.372722864151001}", "{\"n\": 13122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.09, \"learn_time_ms\": 8513.379, \"total_train_time_s\": 9.927436113357544}", "{\"n\": 13123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.09, \"learn_time_ms\": 8497.757, \"total_train_time_s\": 10.29273533821106}", "{\"n\": 13124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.07, \"learn_time_ms\": 8551.23, \"total_train_time_s\": 9.914391040802002}", "{\"n\": 13125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.85, \"learn_time_ms\": 8632.581, \"total_train_time_s\": 10.253578424453735}", "{\"n\": 13126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.85, \"learn_time_ms\": 8685.844, \"total_train_time_s\": 9.700097799301147}", "{\"n\": 13127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 8647.391, \"total_train_time_s\": 10.392725706100464}", "{\"n\": 13128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 8593.321, \"total_train_time_s\": 10.353692770004272}", "{\"n\": 13129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.33, \"learn_time_ms\": 8460.348, \"total_train_time_s\": 8.866636514663696}", "{\"n\": 13130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.69, \"learn_time_ms\": 8372.802, \"total_train_time_s\": 9.704376220703125}", "{\"n\": 13131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.87, \"learn_time_ms\": 8520.703, \"total_train_time_s\": 9.957289934158325}", "{\"n\": 13132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.96, \"learn_time_ms\": 8555.312, \"total_train_time_s\": 10.249680280685425}", "{\"n\": 13133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.19, \"learn_time_ms\": 8574.887, \"total_train_time_s\": 10.4661705493927}", "{\"n\": 13134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.01, \"learn_time_ms\": 8640.257, \"total_train_time_s\": 10.580112218856812}", "{\"n\": 13135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.24, \"learn_time_ms\": 8593.322, \"total_train_time_s\": 9.80839467048645}", "{\"n\": 13136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.24, \"learn_time_ms\": 8662.166, \"total_train_time_s\": 10.393850803375244}", "{\"n\": 13137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.93, \"learn_time_ms\": 8637.796, \"total_train_time_s\": 10.177552461624146}", "{\"n\": 13138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.23, \"learn_time_ms\": 8673.521, \"total_train_time_s\": 10.657042741775513}", "{\"n\": 13139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.23, \"learn_time_ms\": 8751.743, \"total_train_time_s\": 9.642385721206665}", "{\"n\": 13140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.83, \"learn_time_ms\": 8778.607, \"total_train_time_s\": 9.959502220153809}", "{\"n\": 13141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 8766.542, \"total_train_time_s\": 9.759687662124634}", "{\"n\": 13142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.74, \"learn_time_ms\": 8853.462, \"total_train_time_s\": 11.090321063995361}", "{\"n\": 13143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.81, \"learn_time_ms\": 8754.483, \"total_train_time_s\": 9.458837747573853}", "{\"n\": 13144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.67, \"learn_time_ms\": 8807.058, \"total_train_time_s\": 11.10938835144043}", "{\"n\": 13145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.09, \"learn_time_ms\": 8778.362, \"total_train_time_s\": 9.505370140075684}", "{\"n\": 13146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.12, \"learn_time_ms\": 8675.114, \"total_train_time_s\": 9.342374801635742}", "{\"n\": 13147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.98, \"learn_time_ms\": 8592.501, \"total_train_time_s\": 9.305887222290039}", "{\"n\": 13148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.58, \"learn_time_ms\": 8588.002, \"total_train_time_s\": 10.635491132736206}", "{\"n\": 13149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.71, \"learn_time_ms\": 8617.641, \"total_train_time_s\": 9.905490636825562}", "{\"n\": 13150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.47, \"learn_time_ms\": 8495.097, \"total_train_time_s\": 8.711655616760254}", "{\"n\": 13151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.74, \"learn_time_ms\": 8558.302, \"total_train_time_s\": 10.45086407661438}", "{\"n\": 13152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.74, \"learn_time_ms\": 8525.41, \"total_train_time_s\": 10.81131362915039}", "{\"n\": 13153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.14, \"learn_time_ms\": 8518.742, \"total_train_time_s\": 9.436017751693726}", "{\"n\": 13154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.29, \"learn_time_ms\": 8485.602, \"total_train_time_s\": 10.768868446350098}", "{\"n\": 13155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.32, \"learn_time_ms\": 8459.742, \"total_train_time_s\": 9.217825174331665}", "{\"n\": 13156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.58, \"learn_time_ms\": 8467.214, \"total_train_time_s\": 9.372586965560913}", "{\"n\": 13157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.79, \"learn_time_ms\": 8359.545, \"total_train_time_s\": 8.267374038696289}", "{\"n\": 13158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.75, \"learn_time_ms\": 8238.855, \"total_train_time_s\": 9.464455127716064}", "{\"n\": 13159, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8317.053, \"total_train_time_s\": 10.694220542907715}", "{\"n\": 13160, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.07, \"learn_time_ms\": 8501.515, \"total_train_time_s\": 10.55638837814331}", "{\"n\": 13161, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.45, \"learn_time_ms\": 8473.0, \"total_train_time_s\": 10.165027379989624}", "{\"n\": 13162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.72, \"learn_time_ms\": 8499.343, \"total_train_time_s\": 11.06427526473999}", "{\"n\": 13163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.01, \"learn_time_ms\": 8457.764, \"total_train_time_s\": 9.00493860244751}", "{\"n\": 13164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.88, \"learn_time_ms\": 8316.652, \"total_train_time_s\": 9.391256093978882}", "{\"n\": 13165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.55, \"learn_time_ms\": 8279.059, \"total_train_time_s\": 8.911973714828491}", "{\"n\": 13166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.98, \"learn_time_ms\": 8449.995, \"total_train_time_s\": 11.122602224349976}", "{\"n\": 13167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.98, \"learn_time_ms\": 8709.834, \"total_train_time_s\": 10.80433964729309}", "{\"n\": 13168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.66, \"learn_time_ms\": 8743.767, \"total_train_time_s\": 9.763287782669067}", "{\"n\": 13169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.6, \"learn_time_ms\": 8627.855, \"total_train_time_s\": 9.552925109863281}", "{\"n\": 13170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.6, \"learn_time_ms\": 8561.858, \"total_train_time_s\": 9.93013596534729}", "{\"n\": 13171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.18, \"learn_time_ms\": 8623.208, \"total_train_time_s\": 10.74684739112854}", "{\"n\": 13172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.18, \"learn_time_ms\": 8558.678, \"total_train_time_s\": 10.416980266571045}", "{\"n\": 13173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.94, \"learn_time_ms\": 8564.075, \"total_train_time_s\": 9.067407131195068}", "{\"n\": 13174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.16, \"learn_time_ms\": 8555.296, \"total_train_time_s\": 9.307376384735107}", "{\"n\": 13175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.07, \"learn_time_ms\": 8802.766, \"total_train_time_s\": 11.368556499481201}", "{\"n\": 13176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.71, \"learn_time_ms\": 8719.679, \"total_train_time_s\": 10.28741717338562}", "{\"n\": 13177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.71, \"learn_time_ms\": 8617.064, \"total_train_time_s\": 9.82032036781311}", "{\"n\": 13178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.25, \"learn_time_ms\": 8749.933, \"total_train_time_s\": 11.121160984039307}", "{\"n\": 13179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.25, \"learn_time_ms\": 8754.114, \"total_train_time_s\": 9.625081062316895}", "{\"n\": 13180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.89, \"learn_time_ms\": 8768.018, \"total_train_time_s\": 10.067641496658325}", "{\"n\": 13181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.41, \"learn_time_ms\": 8617.868, \"total_train_time_s\": 9.241674661636353}", "{\"n\": 13182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.54, \"learn_time_ms\": 8516.614, \"total_train_time_s\": 9.458890199661255}", "{\"n\": 13183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.26, \"learn_time_ms\": 8665.596, \"total_train_time_s\": 10.605728387832642}", "{\"n\": 13184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.97, \"learn_time_ms\": 8588.364, \"total_train_time_s\": 8.52977705001831}", "{\"n\": 13185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.47, \"learn_time_ms\": 8460.94, \"total_train_time_s\": 10.089104890823364}", "{\"n\": 13186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.67, \"learn_time_ms\": 8454.225, \"total_train_time_s\": 10.21613097190857}", "{\"n\": 13187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.01, \"learn_time_ms\": 8452.797, \"total_train_time_s\": 9.74490737915039}", "{\"n\": 13188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.24, \"learn_time_ms\": 8401.602, \"total_train_time_s\": 10.600009679794312}", "{\"n\": 13189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.72, \"learn_time_ms\": 8530.366, \"total_train_time_s\": 10.880293130874634}", "{\"n\": 13190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.72, \"learn_time_ms\": 8578.959, \"total_train_time_s\": 10.580286026000977}", "{\"n\": 13191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.49, \"learn_time_ms\": 8635.36, \"total_train_time_s\": 9.802388906478882}", "{\"n\": 13192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.02, \"learn_time_ms\": 8530.211, \"total_train_time_s\": 8.339906692504883}", "{\"n\": 13193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.02, \"learn_time_ms\": 8519.808, \"total_train_time_s\": 10.462189674377441}", "{\"n\": 13194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.84, \"learn_time_ms\": 8556.157, \"total_train_time_s\": 8.863680839538574}", "{\"n\": 13195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.34, \"learn_time_ms\": 8621.073, \"total_train_time_s\": 10.72353744506836}", "{\"n\": 13196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.51, \"learn_time_ms\": 8557.117, \"total_train_time_s\": 9.595714330673218}", "{\"n\": 13197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.15, \"learn_time_ms\": 8385.699, \"total_train_time_s\": 8.056345462799072}", "{\"n\": 13198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.47, \"learn_time_ms\": 8396.564, \"total_train_time_s\": 10.70003056526184}", "{\"n\": 13199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.4, \"learn_time_ms\": 8228.478, \"total_train_time_s\": 9.212972640991211}", "{\"n\": 13200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.23, \"learn_time_ms\": 8144.553, \"total_train_time_s\": 9.74476146697998}", "{\"n\": 13201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.23, \"learn_time_ms\": 8063.059, \"total_train_time_s\": 9.005425214767456}", "{\"n\": 13202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.02, \"learn_time_ms\": 8174.039, \"total_train_time_s\": 9.481248140335083}", "{\"n\": 13203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.02, \"learn_time_ms\": 8094.26, \"total_train_time_s\": 9.613528728485107}", "{\"n\": 13204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.52, \"learn_time_ms\": 8292.391, \"total_train_time_s\": 10.893686532974243}", "{\"n\": 13205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.51, \"learn_time_ms\": 8221.967, \"total_train_time_s\": 10.01187801361084}", "{\"n\": 13206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 8254.498, \"total_train_time_s\": 9.927658796310425}", "{\"n\": 13207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.43, \"learn_time_ms\": 8281.813, \"total_train_time_s\": 8.332830667495728}", "{\"n\": 13208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.97, \"learn_time_ms\": 8215.711, \"total_train_time_s\": 10.021542310714722}", "{\"n\": 13209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.82, \"learn_time_ms\": 8424.335, \"total_train_time_s\": 11.314515352249146}", "{\"n\": 13210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.82, \"learn_time_ms\": 8354.577, \"total_train_time_s\": 8.96999192237854}", "{\"n\": 13211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.43, \"learn_time_ms\": 8415.703, \"total_train_time_s\": 9.581525564193726}", "{\"n\": 13212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.62, \"learn_time_ms\": 8438.723, \"total_train_time_s\": 9.695376634597778}", "{\"n\": 13213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.93, \"learn_time_ms\": 8475.842, \"total_train_time_s\": 10.071510076522827}", "{\"n\": 13214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.49, \"learn_time_ms\": 8328.127, \"total_train_time_s\": 9.360323905944824}", "{\"n\": 13215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.3, \"learn_time_ms\": 8431.408, \"total_train_time_s\": 11.104990720748901}", "{\"n\": 13216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.31, \"learn_time_ms\": 8414.894, \"total_train_time_s\": 9.734264850616455}", "{\"n\": 13217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.0, \"learn_time_ms\": 8549.741, \"total_train_time_s\": 9.664254665374756}", "{\"n\": 13218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.39, \"learn_time_ms\": 8586.801, \"total_train_time_s\": 10.408537864685059}", "{\"n\": 13219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.66, \"learn_time_ms\": 8430.777, \"total_train_time_s\": 9.750587224960327}", "{\"n\": 13220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.56, \"learn_time_ms\": 8575.361, \"total_train_time_s\": 10.451105833053589}", "{\"n\": 13221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.56, \"learn_time_ms\": 8573.871, \"total_train_time_s\": 9.570973634719849}", "{\"n\": 13222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.24, \"learn_time_ms\": 8511.041, \"total_train_time_s\": 9.030435800552368}", "{\"n\": 13223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.84, \"learn_time_ms\": 8373.09, \"total_train_time_s\": 8.638861417770386}", "{\"n\": 13224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.84, \"learn_time_ms\": 8493.468, \"total_train_time_s\": 10.541290044784546}", "{\"n\": 13225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.84, \"learn_time_ms\": 8310.674, \"total_train_time_s\": 9.220436334609985}", "{\"n\": 13226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.84, \"learn_time_ms\": 8073.097, \"total_train_time_s\": 7.406733751296997}", "{\"n\": 13227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.59, \"learn_time_ms\": 8214.87, \"total_train_time_s\": 11.11441969871521}", "{\"n\": 13228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.59, \"learn_time_ms\": 8134.52, \"total_train_time_s\": 9.653697490692139}", "{\"n\": 13229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.69, \"learn_time_ms\": 8110.565, \"total_train_time_s\": 9.524576902389526}", "{\"n\": 13230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.69, \"learn_time_ms\": 8150.884, \"total_train_time_s\": 10.872722148895264}", "{\"n\": 13231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.41, \"learn_time_ms\": 8145.872, \"total_train_time_s\": 9.538241386413574}", "{\"n\": 13232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.66, \"learn_time_ms\": 8214.78, \"total_train_time_s\": 9.675803184509277}", "{\"n\": 13233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.9, \"learn_time_ms\": 8339.362, \"total_train_time_s\": 9.895366191864014}", "{\"n\": 13234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.85, \"learn_time_ms\": 8290.513, \"total_train_time_s\": 10.082088708877563}", "{\"n\": 13235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.43, \"learn_time_ms\": 8359.878, \"total_train_time_s\": 9.968825578689575}", "{\"n\": 13236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.25, \"learn_time_ms\": 8571.212, \"total_train_time_s\": 9.538054704666138}", "{\"n\": 13237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.68, \"learn_time_ms\": 8581.062, \"total_train_time_s\": 11.18285083770752}", "{\"n\": 13238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.19, \"learn_time_ms\": 8725.896, \"total_train_time_s\": 11.024561405181885}", "{\"n\": 13239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.33, \"learn_time_ms\": 8799.147, \"total_train_time_s\": 10.238581418991089}", "{\"n\": 13240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.95, \"learn_time_ms\": 8630.109, \"total_train_time_s\": 9.161721229553223}", "{\"n\": 13241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.55, \"learn_time_ms\": 8631.752, \"total_train_time_s\": 9.568305015563965}", "{\"n\": 13242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.98, \"learn_time_ms\": 8647.098, \"total_train_time_s\": 9.910035610198975}", "{\"n\": 13243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.24, \"learn_time_ms\": 8578.983, \"total_train_time_s\": 9.230839967727661}", "{\"n\": 13244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.58, \"learn_time_ms\": 8631.848, \"total_train_time_s\": 10.64936876296997}", "{\"n\": 13245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.58, \"learn_time_ms\": 8638.591, \"total_train_time_s\": 10.010674476623535}", "{\"n\": 13246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.8, \"learn_time_ms\": 8647.297, \"total_train_time_s\": 9.572203636169434}", "{\"n\": 13247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.8, \"learn_time_ms\": 8519.092, \"total_train_time_s\": 9.925043106079102}", "{\"n\": 13248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.52, \"learn_time_ms\": 8420.279, \"total_train_time_s\": 10.085588455200195}", "{\"n\": 13249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.41, \"learn_time_ms\": 8385.983, \"total_train_time_s\": 9.877164363861084}", "{\"n\": 13250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.46, \"learn_time_ms\": 8363.361, \"total_train_time_s\": 8.919232368469238}", "{\"n\": 13251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 8357.316, \"total_train_time_s\": 9.469398975372314}", "{\"n\": 13252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 8347.525, \"total_train_time_s\": 9.779789924621582}", "{\"n\": 13253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.71, \"learn_time_ms\": 8269.453, \"total_train_time_s\": 8.467881202697754}", "{\"n\": 13254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.07, \"learn_time_ms\": 8283.349, \"total_train_time_s\": 10.761991024017334}", "{\"n\": 13255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.07, \"learn_time_ms\": 8429.779, \"total_train_time_s\": 11.466188907623291}", "{\"n\": 13256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 8571.379, \"total_train_time_s\": 11.03557825088501}", "{\"n\": 13257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.75, \"learn_time_ms\": 8687.95, \"total_train_time_s\": 11.060627460479736}", "{\"n\": 13258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.75, \"learn_time_ms\": 8749.173, \"total_train_time_s\": 10.610117197036743}", "{\"n\": 13259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.69, \"learn_time_ms\": 8606.491, \"total_train_time_s\": 8.498373985290527}", "{\"n\": 13260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.38, \"learn_time_ms\": 8802.3, \"total_train_time_s\": 10.912998914718628}", "{\"n\": 13261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.91, \"learn_time_ms\": 8951.158, \"total_train_time_s\": 10.984382629394531}", "{\"n\": 13262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.81, \"learn_time_ms\": 8967.22, \"total_train_time_s\": 9.957603454589844}", "{\"n\": 13263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.07, \"learn_time_ms\": 9233.703, \"total_train_time_s\": 11.140429019927979}", "{\"n\": 13264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.49, \"learn_time_ms\": 9110.856, \"total_train_time_s\": 9.558799505233765}", "{\"n\": 13265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.3, \"learn_time_ms\": 8898.32, \"total_train_time_s\": 9.302977800369263}", "{\"n\": 13266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.54, \"learn_time_ms\": 8919.272, \"total_train_time_s\": 11.21856164932251}", "{\"n\": 13267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.83, \"learn_time_ms\": 8806.631, \"total_train_time_s\": 9.97847604751587}", "{\"n\": 13268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.83, \"learn_time_ms\": 8652.834, \"total_train_time_s\": 9.106026411056519}", "{\"n\": 13269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.77, \"learn_time_ms\": 8777.618, \"total_train_time_s\": 9.714201211929321}", "{\"n\": 13270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.09, \"learn_time_ms\": 8660.254, \"total_train_time_s\": 9.726680040359497}", "{\"n\": 13271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.09, \"learn_time_ms\": 8560.819, \"total_train_time_s\": 10.006092309951782}", "{\"n\": 13272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 8604.426, \"total_train_time_s\": 10.410712718963623}", "{\"n\": 13273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.88, \"learn_time_ms\": 8496.012, \"total_train_time_s\": 10.042722940444946}", "{\"n\": 13274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.88, \"learn_time_ms\": 8611.632, \"total_train_time_s\": 10.694684505462646}", "{\"n\": 13275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 8577.372, \"total_train_time_s\": 9.071309804916382}", "{\"n\": 13276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.08, \"learn_time_ms\": 8506.893, \"total_train_time_s\": 10.5039222240448}", "{\"n\": 13277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.08, \"learn_time_ms\": 8545.067, \"total_train_time_s\": 10.335810899734497}", "{\"n\": 13278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.08, \"learn_time_ms\": 8618.541, \"total_train_time_s\": 9.845327138900757}", "{\"n\": 13279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.72, \"learn_time_ms\": 8813.006, \"total_train_time_s\": 11.659026622772217}", "{\"n\": 13280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.19, \"learn_time_ms\": 8789.298, \"total_train_time_s\": 9.462244272232056}", "{\"n\": 13281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.19, \"learn_time_ms\": 8781.762, \"total_train_time_s\": 9.870583772659302}", "{\"n\": 13282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.4, \"learn_time_ms\": 8616.694, \"total_train_time_s\": 8.766706943511963}", "{\"n\": 13283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.34, \"learn_time_ms\": 8603.225, \"total_train_time_s\": 9.926694393157959}", "{\"n\": 13284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.34, \"learn_time_ms\": 8608.381, \"total_train_time_s\": 10.727232694625854}", "{\"n\": 13285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.31, \"learn_time_ms\": 8767.191, \"total_train_time_s\": 10.569116592407227}", "{\"n\": 13286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.1, \"learn_time_ms\": 8612.912, \"total_train_time_s\": 8.994051456451416}", "{\"n\": 13287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.1, \"learn_time_ms\": 8614.512, \"total_train_time_s\": 10.359010934829712}", "{\"n\": 13288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 8669.95, \"total_train_time_s\": 10.423609972000122}", "{\"n\": 13289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.51, \"learn_time_ms\": 8415.138, \"total_train_time_s\": 9.07794737815857}", "{\"n\": 13290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.31, \"learn_time_ms\": 8409.028, \"total_train_time_s\": 9.389139413833618}", "{\"n\": 13291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.82, \"learn_time_ms\": 8519.959, \"total_train_time_s\": 11.006854772567749}", "{\"n\": 13292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.8, \"learn_time_ms\": 8763.667, \"total_train_time_s\": 11.191373109817505}", "{\"n\": 13293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.89, \"learn_time_ms\": 8724.391, \"total_train_time_s\": 9.547483444213867}", "{\"n\": 13294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.32, \"learn_time_ms\": 8632.503, \"total_train_time_s\": 9.845108985900879}", "{\"n\": 13295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.31, \"learn_time_ms\": 8451.064, \"total_train_time_s\": 8.72822618484497}", "{\"n\": 13296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.99, \"learn_time_ms\": 8460.654, \"total_train_time_s\": 9.059448957443237}", "{\"n\": 13297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.99, \"learn_time_ms\": 8218.896, \"total_train_time_s\": 7.922574520111084}", "{\"n\": 13298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.02, \"learn_time_ms\": 8162.408, \"total_train_time_s\": 9.90657353401184}", "{\"n\": 13299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.27, \"learn_time_ms\": 8229.024, \"total_train_time_s\": 9.804227828979492}", "{\"n\": 13300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.57, \"learn_time_ms\": 8355.284, \"total_train_time_s\": 10.682622909545898}", "{\"n\": 13301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.75, \"learn_time_ms\": 8256.209, \"total_train_time_s\": 10.002222537994385}", "{\"n\": 13302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.04, \"learn_time_ms\": 8178.171, \"total_train_time_s\": 10.411592721939087}", "{\"n\": 13303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.73, \"learn_time_ms\": 8217.236, \"total_train_time_s\": 9.924054861068726}", "{\"n\": 13304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.05, \"learn_time_ms\": 8345.831, \"total_train_time_s\": 11.121131896972656}", "{\"n\": 13305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.4, \"learn_time_ms\": 8392.773, \"total_train_time_s\": 9.226416110992432}", "{\"n\": 13306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.4, \"learn_time_ms\": 8478.923, \"total_train_time_s\": 9.979119777679443}", "{\"n\": 13307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.4, \"learn_time_ms\": 8617.695, \"total_train_time_s\": 9.321331024169922}", "{\"n\": 13308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.0, \"learn_time_ms\": 8644.628, \"total_train_time_s\": 10.16649580001831}", "{\"n\": 13309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.0, \"learn_time_ms\": 8666.941, \"total_train_time_s\": 9.988441467285156}", "{\"n\": 13310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.98, \"learn_time_ms\": 8583.594, \"total_train_time_s\": 9.850717306137085}", "{\"n\": 13311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 8495.785, \"total_train_time_s\": 9.17209529876709}", "{\"n\": 13312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 8492.271, \"total_train_time_s\": 10.367616176605225}", "{\"n\": 13313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.5, \"learn_time_ms\": 8405.693, \"total_train_time_s\": 9.027599573135376}", "{\"n\": 13314, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.98, \"learn_time_ms\": 8217.689, \"total_train_time_s\": 9.21513295173645}", "{\"n\": 13315, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.25, \"learn_time_ms\": 8372.512, \"total_train_time_s\": 10.797755479812622}", "{\"n\": 13316, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.2, \"learn_time_ms\": 8215.991, \"total_train_time_s\": 8.395470380783081}", "{\"n\": 13317, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.2, \"learn_time_ms\": 8378.024, \"total_train_time_s\": 10.943542003631592}", "{\"n\": 13318, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.37, \"learn_time_ms\": 8333.556, \"total_train_time_s\": 9.704020500183105}", "{\"n\": 13319, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.37, \"learn_time_ms\": 8283.048, \"total_train_time_s\": 9.502022981643677}", "{\"n\": 13320, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.12, \"learn_time_ms\": 8302.622, \"total_train_time_s\": 10.07055139541626}", "{\"n\": 13321, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.73, \"learn_time_ms\": 8242.684, \"total_train_time_s\": 8.538438081741333}", "{\"n\": 13322, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.73, \"learn_time_ms\": 8198.169, \"total_train_time_s\": 9.957351446151733}", "{\"n\": 13323, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 8338.094, \"total_train_time_s\": 10.426086664199829}", "{\"n\": 13324, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.66, \"learn_time_ms\": 8398.545, \"total_train_time_s\": 9.87134337425232}", "{\"n\": 13325, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.25, \"learn_time_ms\": 8382.088, \"total_train_time_s\": 10.604443788528442}", "{\"n\": 13326, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.44, \"learn_time_ms\": 8729.778, \"total_train_time_s\": 11.779529809951782}", "{\"n\": 13327, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.44, \"learn_time_ms\": 8620.484, \"total_train_time_s\": 9.848623752593994}", "{\"n\": 13328, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.13, \"learn_time_ms\": 8637.109, \"total_train_time_s\": 9.874964952468872}", "{\"n\": 13329, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.64, \"learn_time_ms\": 8603.563, \"total_train_time_s\": 9.181694030761719}", "{\"n\": 13330, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.64, \"learn_time_ms\": 8563.795, \"total_train_time_s\": 9.623332023620605}", "{\"n\": 13331, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.37, \"learn_time_ms\": 8510.64, \"total_train_time_s\": 7.999911546707153}", "{\"n\": 13332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.5, \"learn_time_ms\": 8553.517, \"total_train_time_s\": 10.35706877708435}", "{\"n\": 13333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.5, \"learn_time_ms\": 8516.822, \"total_train_time_s\": 10.053850412368774}", "{\"n\": 13334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.59, \"learn_time_ms\": 8485.119, \"total_train_time_s\": 9.525523662567139}", "{\"n\": 13335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.38, \"learn_time_ms\": 8566.338, \"total_train_time_s\": 11.379958629608154}", "{\"n\": 13336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.45, \"learn_time_ms\": 8342.681, \"total_train_time_s\": 9.580606698989868}", "{\"n\": 13337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.9, \"learn_time_ms\": 8399.311, \"total_train_time_s\": 10.430309057235718}", "{\"n\": 13338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.78, \"learn_time_ms\": 8454.42, \"total_train_time_s\": 10.394777774810791}", "{\"n\": 13339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.0, \"learn_time_ms\": 8432.629, \"total_train_time_s\": 8.96570897102356}", "{\"n\": 13340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.89, \"learn_time_ms\": 8419.85, \"total_train_time_s\": 9.55567455291748}", "{\"n\": 13341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.89, \"learn_time_ms\": 8705.77, \"total_train_time_s\": 10.916553974151611}", "{\"n\": 13342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.72, \"learn_time_ms\": 8735.803, \"total_train_time_s\": 10.663243293762207}", "{\"n\": 13343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.81, \"learn_time_ms\": 8720.605, \"total_train_time_s\": 9.941378355026245}", "{\"n\": 13344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.81, \"learn_time_ms\": 8769.23, \"total_train_time_s\": 9.994553804397583}", "{\"n\": 13345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.36, \"learn_time_ms\": 8510.079, \"total_train_time_s\": 8.831367492675781}", "{\"n\": 13346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.52, \"learn_time_ms\": 8545.013, \"total_train_time_s\": 9.911991596221924}", "{\"n\": 13347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.52, \"learn_time_ms\": 8588.588, \"total_train_time_s\": 10.82176423072815}", "{\"n\": 13348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.86, \"learn_time_ms\": 8608.195, \"total_train_time_s\": 10.578653573989868}", "{\"n\": 13349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.28, \"learn_time_ms\": 8732.699, \"total_train_time_s\": 10.161030530929565}", "{\"n\": 13350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.75, \"learn_time_ms\": 8691.367, \"total_train_time_s\": 9.123099088668823}", "{\"n\": 13351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.85, \"learn_time_ms\": 8742.123, \"total_train_time_s\": 11.417999505996704}", "{\"n\": 13352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.9, \"learn_time_ms\": 8725.899, \"total_train_time_s\": 10.451038122177124}", "{\"n\": 13353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.91, \"learn_time_ms\": 8812.71, \"total_train_time_s\": 10.784686803817749}", "{\"n\": 13354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.86, \"learn_time_ms\": 8811.499, \"total_train_time_s\": 10.002340078353882}", "{\"n\": 13355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.53, \"learn_time_ms\": 8779.956, \"total_train_time_s\": 8.496456861495972}", "{\"n\": 13356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.53, \"learn_time_ms\": 8697.491, \"total_train_time_s\": 9.104316234588623}", "{\"n\": 13357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.34, \"learn_time_ms\": 8596.656, \"total_train_time_s\": 9.825729370117188}", "{\"n\": 13358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.72, \"learn_time_ms\": 8531.079, \"total_train_time_s\": 9.970864295959473}", "{\"n\": 13359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.72, \"learn_time_ms\": 8639.728, \"total_train_time_s\": 11.30324101448059}", "{\"n\": 13360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.72, \"learn_time_ms\": 8844.737, \"total_train_time_s\": 11.12677526473999}", "{\"n\": 13361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.97, \"learn_time_ms\": 8675.851, \"total_train_time_s\": 9.6905198097229}", "{\"n\": 13362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.97, \"learn_time_ms\": 8815.106, \"total_train_time_s\": 11.876346349716187}", "{\"n\": 13363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.97, \"learn_time_ms\": 8718.625, \"total_train_time_s\": 9.863052129745483}", "{\"n\": 13364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.76, \"learn_time_ms\": 8787.244, \"total_train_time_s\": 10.719916105270386}", "{\"n\": 13365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.76, \"learn_time_ms\": 9027.277, \"total_train_time_s\": 10.908432006835938}", "{\"n\": 13366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.76, \"learn_time_ms\": 9058.126, \"total_train_time_s\": 9.388810157775879}", "{\"n\": 13367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3287.77, \"learn_time_ms\": 9228.795, \"total_train_time_s\": 11.503532409667969}", "{\"n\": 13368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.37, \"learn_time_ms\": 9253.054, \"total_train_time_s\": 10.143431663513184}", "{\"n\": 13369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.37, \"learn_time_ms\": 9281.815, \"total_train_time_s\": 11.582638263702393}", "{\"n\": 13370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3287.72, \"learn_time_ms\": 9283.607, \"total_train_time_s\": 11.182892084121704}", "{\"n\": 13371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.46, \"learn_time_ms\": 9395.278, \"total_train_time_s\": 10.839898347854614}", "{\"n\": 13372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.46, \"learn_time_ms\": 9096.048, \"total_train_time_s\": 8.840084791183472}", "{\"n\": 13373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.46, \"learn_time_ms\": 9074.364, \"total_train_time_s\": 9.579369068145752}", "{\"n\": 13374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.1, \"learn_time_ms\": 8815.089, \"total_train_time_s\": 8.132325410842896}", "{\"n\": 13375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.84, \"learn_time_ms\": 8544.491, \"total_train_time_s\": 8.207610130310059}", "{\"n\": 13376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.84, \"learn_time_ms\": 8548.151, \"total_train_time_s\": 9.480349779129028}", "{\"n\": 13377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.94, \"learn_time_ms\": 8217.599, \"total_train_time_s\": 8.20827031135559}", "{\"n\": 13378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.41, \"learn_time_ms\": 8281.854, \"total_train_time_s\": 10.815118551254272}", "{\"n\": 13379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.02, \"learn_time_ms\": 8117.387, \"total_train_time_s\": 9.91118311882019}", "{\"n\": 13380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.81, \"learn_time_ms\": 7808.426, \"total_train_time_s\": 8.10804295539856}", "{\"n\": 13381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.89, \"learn_time_ms\": 7711.789, \"total_train_time_s\": 9.831864595413208}", "{\"n\": 13382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.11, \"learn_time_ms\": 7976.489, \"total_train_time_s\": 11.540665864944458}", "{\"n\": 13383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.02, \"learn_time_ms\": 8168.146, \"total_train_time_s\": 11.534778356552124}", "{\"n\": 13384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.21, \"learn_time_ms\": 8385.085, \"total_train_time_s\": 10.254349946975708}", "{\"n\": 13385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.36, \"learn_time_ms\": 8530.23, \"total_train_time_s\": 9.647436380386353}", "{\"n\": 13386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.22, \"learn_time_ms\": 8612.915, \"total_train_time_s\": 10.264570951461792}", "{\"n\": 13387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.4, \"learn_time_ms\": 8741.127, \"total_train_time_s\": 9.512952327728271}", "{\"n\": 13388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.04, \"learn_time_ms\": 8654.254, \"total_train_time_s\": 9.996927261352539}", "{\"n\": 13389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.04, \"learn_time_ms\": 8692.492, \"total_train_time_s\": 10.278921365737915}", "{\"n\": 13390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.66, \"learn_time_ms\": 8766.459, \"total_train_time_s\": 8.846256732940674}", "{\"n\": 13391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.24, \"learn_time_ms\": 8863.013, \"total_train_time_s\": 10.819756746292114}", "{\"n\": 13392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.07, \"learn_time_ms\": 8660.135, \"total_train_time_s\": 9.489009380340576}", "{\"n\": 13393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.08, \"learn_time_ms\": 8476.018, \"total_train_time_s\": 9.646736145019531}", "{\"n\": 13394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.3, \"learn_time_ms\": 8442.088, \"total_train_time_s\": 9.904934883117676}", "{\"n\": 13395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.47, \"learn_time_ms\": 8517.365, \"total_train_time_s\": 10.446889162063599}", "{\"n\": 13396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.2, \"learn_time_ms\": 8417.465, \"total_train_time_s\": 9.335624694824219}", "{\"n\": 13397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.85, \"learn_time_ms\": 8475.295, \"total_train_time_s\": 10.148364067077637}", "{\"n\": 13398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.48, \"learn_time_ms\": 8452.378, \"total_train_time_s\": 9.68035340309143}", "{\"n\": 13399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.5, \"learn_time_ms\": 8467.225, \"total_train_time_s\": 10.456505298614502}", "{\"n\": 13400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.16, \"learn_time_ms\": 8465.485, \"total_train_time_s\": 8.791414260864258}", "{\"n\": 13401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.19, \"learn_time_ms\": 8434.489, \"total_train_time_s\": 10.512870788574219}", "{\"n\": 13402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.17, \"learn_time_ms\": 8632.045, \"total_train_time_s\": 11.479061365127563}", "{\"n\": 13403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.71, \"learn_time_ms\": 8735.499, \"total_train_time_s\": 10.687772989273071}", "{\"n\": 13404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.71, \"learn_time_ms\": 8784.877, \"total_train_time_s\": 10.41397213935852}", "{\"n\": 13405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.3, \"learn_time_ms\": 8716.742, \"total_train_time_s\": 9.737101793289185}", "{\"n\": 13406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.48, \"learn_time_ms\": 8659.379, \"total_train_time_s\": 8.725993156433105}", "{\"n\": 13407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.01, \"learn_time_ms\": 8627.37, \"total_train_time_s\": 9.802037477493286}", "{\"n\": 13408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.25, \"learn_time_ms\": 8488.704, \"total_train_time_s\": 8.370240926742554}", "{\"n\": 13409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.25, \"learn_time_ms\": 8515.783, \"total_train_time_s\": 10.763912916183472}", "{\"n\": 13410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 8775.59, \"total_train_time_s\": 11.432364225387573}", "{\"n\": 13411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.88, \"learn_time_ms\": 8694.348, \"total_train_time_s\": 9.647258996963501}", "{\"n\": 13412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.88, \"learn_time_ms\": 8481.206, \"total_train_time_s\": 9.335910320281982}", "{\"n\": 13413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.45, \"learn_time_ms\": 8248.327, \"total_train_time_s\": 8.411808013916016}", "{\"n\": 13414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.6, \"learn_time_ms\": 8256.205, \"total_train_time_s\": 10.492499828338623}", "{\"n\": 13415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.79, \"learn_time_ms\": 8318.39, \"total_train_time_s\": 10.32474946975708}", "{\"n\": 13416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.79, \"learn_time_ms\": 8506.411, \"total_train_time_s\": 10.599093675613403}", "{\"n\": 13417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.69, \"learn_time_ms\": 8567.809, \"total_train_time_s\": 10.415909767150879}", "{\"n\": 13418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.95, \"learn_time_ms\": 8847.863, \"total_train_time_s\": 11.092883825302124}", "{\"n\": 13419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.95, \"learn_time_ms\": 8779.241, \"total_train_time_s\": 10.004075527191162}", "{\"n\": 13420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.72, \"learn_time_ms\": 8721.959, \"total_train_time_s\": 10.85921335220337}", "{\"n\": 13421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.33, \"learn_time_ms\": 8784.84, \"total_train_time_s\": 10.343094825744629}", "{\"n\": 13422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.33, \"learn_time_ms\": 8952.789, \"total_train_time_s\": 11.061786651611328}", "{\"n\": 13423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.33, \"learn_time_ms\": 9025.878, \"total_train_time_s\": 9.101325988769531}", "{\"n\": 13424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8987.95, \"total_train_time_s\": 10.125572681427002}", "{\"n\": 13425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8914.022, \"total_train_time_s\": 9.598254442214966}", "{\"n\": 13426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8943.616, \"total_train_time_s\": 10.852420806884766}", "{\"n\": 13427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.39, \"learn_time_ms\": 8819.485, \"total_train_time_s\": 9.134022951126099}", "{\"n\": 13428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.67, \"learn_time_ms\": 8756.396, \"total_train_time_s\": 10.51931881904602}", "{\"n\": 13429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.67, \"learn_time_ms\": 8791.108, \"total_train_time_s\": 10.341835975646973}", "{\"n\": 13430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.31, \"learn_time_ms\": 8728.288, \"total_train_time_s\": 10.218711614608765}", "{\"n\": 13431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.41, \"learn_time_ms\": 8737.849, \"total_train_time_s\": 10.403618335723877}", "{\"n\": 13432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.41, \"learn_time_ms\": 8718.763, \"total_train_time_s\": 10.852675199508667}", "{\"n\": 13433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.33, \"learn_time_ms\": 8792.887, \"total_train_time_s\": 9.821870803833008}", "{\"n\": 13434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.12, \"learn_time_ms\": 8881.287, \"total_train_time_s\": 11.020323991775513}", "{\"n\": 13435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.12, \"learn_time_ms\": 8889.699, \"total_train_time_s\": 9.708619117736816}", "{\"n\": 13436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.46, \"learn_time_ms\": 8786.38, \"total_train_time_s\": 9.875851154327393}", "{\"n\": 13437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.53, \"learn_time_ms\": 8772.775, \"total_train_time_s\": 9.062610387802124}", "{\"n\": 13438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.24, \"learn_time_ms\": 8828.992, \"total_train_time_s\": 11.114229440689087}", "{\"n\": 13439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.24, \"learn_time_ms\": 8742.869, \"total_train_time_s\": 9.503210544586182}", "{\"n\": 13440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.56, \"learn_time_ms\": 8673.591, \"total_train_time_s\": 9.49198293685913}", "{\"n\": 13441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.58, \"learn_time_ms\": 8702.679, \"total_train_time_s\": 10.692334175109863}", "{\"n\": 13442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.32, \"learn_time_ms\": 8672.533, \"total_train_time_s\": 10.535323143005371}", "{\"n\": 13443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.32, \"learn_time_ms\": 8673.77, \"total_train_time_s\": 9.860177516937256}", "{\"n\": 13444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.06, \"learn_time_ms\": 8531.511, \"total_train_time_s\": 9.588093042373657}", "{\"n\": 13445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 8795.491, \"total_train_time_s\": 12.371253967285156}", "{\"n\": 13446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 8688.798, \"total_train_time_s\": 8.769347190856934}", "{\"n\": 13447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.38, \"learn_time_ms\": 8728.775, \"total_train_time_s\": 9.418750286102295}", "{\"n\": 13448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.61, \"learn_time_ms\": 8676.963, \"total_train_time_s\": 10.56141972541809}", "{\"n\": 13449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.2, \"learn_time_ms\": 8725.058, \"total_train_time_s\": 9.960581064224243}", "{\"n\": 13450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.7, \"learn_time_ms\": 8910.066, \"total_train_time_s\": 11.373372077941895}", "{\"n\": 13451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.66, \"learn_time_ms\": 8950.565, \"total_train_time_s\": 11.095178842544556}", "{\"n\": 13452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.66, \"learn_time_ms\": 8747.517, \"total_train_time_s\": 8.506621837615967}", "{\"n\": 13453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.79, \"learn_time_ms\": 8516.197, \"total_train_time_s\": 7.603243589401245}", "{\"n\": 13454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.63, \"learn_time_ms\": 8526.865, \"total_train_time_s\": 9.714617252349854}", "{\"n\": 13455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.73, \"learn_time_ms\": 8280.323, \"total_train_time_s\": 9.845684289932251}", "{\"n\": 13456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.44, \"learn_time_ms\": 8403.466, \"total_train_time_s\": 10.0191650390625}", "{\"n\": 13457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.73, \"learn_time_ms\": 8425.698, \"total_train_time_s\": 9.637441635131836}", "{\"n\": 13458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.73, \"learn_time_ms\": 8473.634, \"total_train_time_s\": 11.058840990066528}", "{\"n\": 13459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.39, \"learn_time_ms\": 8523.144, \"total_train_time_s\": 10.511986494064331}", "{\"n\": 13460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.0, \"learn_time_ms\": 8493.888, \"total_train_time_s\": 11.117066860198975}", "{\"n\": 13461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.51, \"learn_time_ms\": 8560.306, \"total_train_time_s\": 11.761798620223999}", "{\"n\": 13462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.16, \"learn_time_ms\": 8788.981, \"total_train_time_s\": 10.786128520965576}", "{\"n\": 13463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.57, \"learn_time_ms\": 9031.67, \"total_train_time_s\": 10.0157310962677}", "{\"n\": 13464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.92, \"learn_time_ms\": 8981.202, \"total_train_time_s\": 9.284997463226318}", "{\"n\": 13465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.92, \"learn_time_ms\": 9103.075, \"total_train_time_s\": 11.074823141098022}", "{\"n\": 13466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.81, \"learn_time_ms\": 9047.683, \"total_train_time_s\": 9.501655340194702}", "{\"n\": 13467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.27, \"learn_time_ms\": 9018.718, \"total_train_time_s\": 9.334319114685059}", "{\"n\": 13468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.17, \"learn_time_ms\": 8997.957, \"total_train_time_s\": 10.830021619796753}", "{\"n\": 13469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 8939.601, \"total_train_time_s\": 9.971325397491455}", "{\"n\": 13470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 8827.921, \"total_train_time_s\": 9.937118291854858}", "{\"n\": 13471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.97, \"learn_time_ms\": 8646.643, \"total_train_time_s\": 9.941990613937378}", "{\"n\": 13472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.97, \"learn_time_ms\": 8442.549, \"total_train_time_s\": 8.748520374298096}", "{\"n\": 13473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.24, \"learn_time_ms\": 8418.139, \"total_train_time_s\": 9.726530075073242}", "{\"n\": 13474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.23, \"learn_time_ms\": 8352.629, \"total_train_time_s\": 8.493385791778564}", "{\"n\": 13475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.17, \"learn_time_ms\": 8178.603, \"total_train_time_s\": 9.344981670379639}", "{\"n\": 13476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.61, \"learn_time_ms\": 8322.929, \"total_train_time_s\": 10.903605699539185}", "{\"n\": 13477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.57, \"learn_time_ms\": 8388.963, \"total_train_time_s\": 10.015738487243652}", "{\"n\": 13478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.57, \"learn_time_ms\": 8398.47, \"total_train_time_s\": 10.943031311035156}", "{\"n\": 13479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.89, \"learn_time_ms\": 8439.893, \"total_train_time_s\": 10.32733154296875}", "{\"n\": 13480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.89, \"learn_time_ms\": 8546.76, \"total_train_time_s\": 11.010782241821289}", "{\"n\": 13481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.99, \"learn_time_ms\": 8391.63, \"total_train_time_s\": 8.43651533126831}", "{\"n\": 13482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.27, \"learn_time_ms\": 8372.74, \"total_train_time_s\": 8.591270685195923}", "{\"n\": 13483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.27, \"learn_time_ms\": 8417.117, \"total_train_time_s\": 10.177809476852417}", "{\"n\": 13484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.71, \"learn_time_ms\": 8593.997, \"total_train_time_s\": 10.29412579536438}", "{\"n\": 13485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.62, \"learn_time_ms\": 8595.162, \"total_train_time_s\": 9.389082908630371}", "{\"n\": 13486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.0, \"learn_time_ms\": 8525.294, \"total_train_time_s\": 10.227213144302368}", "{\"n\": 13487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.38, \"learn_time_ms\": 8447.069, \"total_train_time_s\": 9.19873595237732}", "{\"n\": 13488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.38, \"learn_time_ms\": 8302.752, \"total_train_time_s\": 9.46949577331543}", "{\"n\": 13489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.7, \"learn_time_ms\": 8380.25, \"total_train_time_s\": 11.095867395401001}", "{\"n\": 13490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.97, \"learn_time_ms\": 8175.631, \"total_train_time_s\": 8.943775177001953}", "{\"n\": 13491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.48, \"learn_time_ms\": 8209.61, \"total_train_time_s\": 8.719259977340698}", "{\"n\": 13492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.69, \"learn_time_ms\": 8480.216, \"total_train_time_s\": 11.301831483840942}", "{\"n\": 13493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.13, \"learn_time_ms\": 8436.692, \"total_train_time_s\": 9.738537788391113}", "{\"n\": 13494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.1, \"learn_time_ms\": 8547.246, \"total_train_time_s\": 11.449769258499146}", "{\"n\": 13495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.1, \"learn_time_ms\": 8615.082, \"total_train_time_s\": 10.019123554229736}", "{\"n\": 13496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.46, \"learn_time_ms\": 8499.25, \"total_train_time_s\": 9.037325382232666}", "{\"n\": 13497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.6, \"learn_time_ms\": 8568.597, \"total_train_time_s\": 9.915144205093384}", "{\"n\": 13498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3291.6, \"learn_time_ms\": 8790.077, \"total_train_time_s\": 11.724738597869873}", "{\"n\": 13499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.5, \"learn_time_ms\": 8769.779, \"total_train_time_s\": 10.874395847320557}", "{\"n\": 13500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.95, \"learn_time_ms\": 8807.155, \"total_train_time_s\": 9.387986183166504}", "{\"n\": 13501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.95, \"learn_time_ms\": 8925.43, \"total_train_time_s\": 9.93162989616394}", "{\"n\": 13502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.95, \"learn_time_ms\": 8976.239, \"total_train_time_s\": 11.810341596603394}", "{\"n\": 13503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.45, \"learn_time_ms\": 9099.181, \"total_train_time_s\": 10.967633247375488}", "{\"n\": 13504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.54, \"learn_time_ms\": 8980.744, \"total_train_time_s\": 10.184763193130493}", "{\"n\": 13505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.54, \"learn_time_ms\": 8895.016, \"total_train_time_s\": 9.129674196243286}", "{\"n\": 13506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.36, \"learn_time_ms\": 9029.635, \"total_train_time_s\": 10.406290769577026}", "{\"n\": 13507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.15, \"learn_time_ms\": 9181.363, \"total_train_time_s\": 11.428020000457764}", "{\"n\": 13508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3290.91, \"learn_time_ms\": 9014.554, \"total_train_time_s\": 10.041183710098267}", "{\"n\": 13509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3290.24, \"learn_time_ms\": 8914.72, \"total_train_time_s\": 9.867379188537598}", "{\"n\": 13510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3293.81, \"learn_time_ms\": 9101.876, \"total_train_time_s\": 11.22057294845581}", "{\"n\": 13511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.15, \"learn_time_ms\": 9129.018, \"total_train_time_s\": 10.171887159347534}", "{\"n\": 13512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.15, \"learn_time_ms\": 9042.482, \"total_train_time_s\": 10.910385370254517}", "{\"n\": 13513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.76, \"learn_time_ms\": 9008.38, \"total_train_time_s\": 10.61673903465271}", "{\"n\": 13514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.37, \"learn_time_ms\": 8999.135, \"total_train_time_s\": 10.149336814880371}", "{\"n\": 13515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3302.37, \"learn_time_ms\": 9106.281, \"total_train_time_s\": 10.259935140609741}", "{\"n\": 13516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.03, \"learn_time_ms\": 9036.889, \"total_train_time_s\": 9.668073415756226}", "{\"n\": 13517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.24, \"learn_time_ms\": 8997.176, \"total_train_time_s\": 11.07212519645691}", "{\"n\": 13518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.24, \"learn_time_ms\": 9017.186, \"total_train_time_s\": 10.240025758743286}", "{\"n\": 13519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.24, \"learn_time_ms\": 9251.538, \"total_train_time_s\": 12.275872468948364}", "{\"n\": 13520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.39, \"learn_time_ms\": 9223.775, \"total_train_time_s\": 10.960499286651611}", "{\"n\": 13521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.56, \"learn_time_ms\": 9268.779, \"total_train_time_s\": 10.670250415802002}", "{\"n\": 13522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.56, \"learn_time_ms\": 9126.114, \"total_train_time_s\": 9.436434030532837}", "{\"n\": 13523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.19, \"learn_time_ms\": 8960.716, \"total_train_time_s\": 8.997076749801636}", "{\"n\": 13524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3313.88, \"learn_time_ms\": 8998.885, \"total_train_time_s\": 10.498222589492798}", "{\"n\": 13525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3313.88, \"learn_time_ms\": 9054.704, \"total_train_time_s\": 10.812796115875244}", "{\"n\": 13526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3313.88, \"learn_time_ms\": 9062.404, \"total_train_time_s\": 9.727069854736328}", "{\"n\": 13527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.78, \"learn_time_ms\": 8934.497, \"total_train_time_s\": 9.747158527374268}", "{\"n\": 13528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.78, \"learn_time_ms\": 8910.55, \"total_train_time_s\": 9.977264404296875}", "{\"n\": 13529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.78, \"learn_time_ms\": 8706.16, \"total_train_time_s\": 10.17208194732666}", "{\"n\": 13530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.83, \"learn_time_ms\": 8617.946, \"total_train_time_s\": 10.019262790679932}", "{\"n\": 13531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.83, \"learn_time_ms\": 8591.044, \"total_train_time_s\": 10.336138486862183}", "{\"n\": 13532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.83, \"learn_time_ms\": 8607.935, \"total_train_time_s\": 9.641958475112915}", "{\"n\": 13533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.04, \"learn_time_ms\": 8698.529, \"total_train_time_s\": 9.852275133132935}", "{\"n\": 13534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.04, \"learn_time_ms\": 8567.1, \"total_train_time_s\": 9.159076929092407}", "{\"n\": 13535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.04, \"learn_time_ms\": 8449.905, \"total_train_time_s\": 9.652715921401978}", "{\"n\": 13536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.75, \"learn_time_ms\": 8466.311, \"total_train_time_s\": 9.916203022003174}", "{\"n\": 13537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.22, \"learn_time_ms\": 8527.428, \"total_train_time_s\": 10.381482362747192}", "{\"n\": 13538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.22, \"learn_time_ms\": 8539.41, \"total_train_time_s\": 10.074109077453613}", "{\"n\": 13539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3298.51, \"learn_time_ms\": 8390.934, \"total_train_time_s\": 8.686906337738037}", "{\"n\": 13540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.7, \"learn_time_ms\": 8319.5, \"total_train_time_s\": 9.35405445098877}", "{\"n\": 13541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.7, \"learn_time_ms\": 8249.011, \"total_train_time_s\": 9.627092361450195}", "{\"n\": 13542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3309.2, \"learn_time_ms\": 8221.879, \"total_train_time_s\": 9.356016874313354}", "{\"n\": 13543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.38, \"learn_time_ms\": 8285.893, \"total_train_time_s\": 10.550757884979248}", "{\"n\": 13544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.25, \"learn_time_ms\": 8430.742, \"total_train_time_s\": 10.605758666992188}", "{\"n\": 13545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.25, \"learn_time_ms\": 8496.441, \"total_train_time_s\": 10.34606146812439}", "{\"n\": 13546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.3, \"learn_time_ms\": 8518.975, \"total_train_time_s\": 10.147363901138306}", "{\"n\": 13547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.56, \"learn_time_ms\": 8579.42, \"total_train_time_s\": 11.01996660232544}", "{\"n\": 13548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.56, \"learn_time_ms\": 8576.988, \"total_train_time_s\": 10.075617790222168}", "{\"n\": 13549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.96, \"learn_time_ms\": 8855.378, \"total_train_time_s\": 11.520707368850708}", "{\"n\": 13550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.01, \"learn_time_ms\": 8704.139, \"total_train_time_s\": 7.840426921844482}", "{\"n\": 13551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.01, \"learn_time_ms\": 8741.006, \"total_train_time_s\": 10.045073747634888}", "{\"n\": 13552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.78, \"learn_time_ms\": 8735.248, \"total_train_time_s\": 9.326102495193481}", "{\"n\": 13553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.67, \"learn_time_ms\": 8755.991, \"total_train_time_s\": 10.726596593856812}", "{\"n\": 13554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.29, \"learn_time_ms\": 8742.789, \"total_train_time_s\": 10.487056255340576}", "{\"n\": 13555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.7, \"learn_time_ms\": 8743.178, \"total_train_time_s\": 10.313920021057129}", "{\"n\": 13556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.69, \"learn_time_ms\": 8631.626, \"total_train_time_s\": 9.093952894210815}", "{\"n\": 13557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.3, \"learn_time_ms\": 8536.048, \"total_train_time_s\": 10.023426055908203}", "{\"n\": 13558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.64, \"learn_time_ms\": 8562.217, \"total_train_time_s\": 10.364672899246216}", "{\"n\": 13559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.14, \"learn_time_ms\": 8403.534, \"total_train_time_s\": 9.909329414367676}", "{\"n\": 13560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.14, \"learn_time_ms\": 8728.009, \"total_train_time_s\": 11.07408094406128}", "{\"n\": 13561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.91, \"learn_time_ms\": 8874.415, \"total_train_time_s\": 11.520378828048706}", "{\"n\": 13562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.91, \"learn_time_ms\": 8902.948, \"total_train_time_s\": 9.613746404647827}", "{\"n\": 13563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.44, \"learn_time_ms\": 8894.741, \"total_train_time_s\": 10.666272401809692}", "{\"n\": 13564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.51, \"learn_time_ms\": 8918.169, \"total_train_time_s\": 10.718775987625122}", "{\"n\": 13565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.26, \"learn_time_ms\": 8940.026, \"total_train_time_s\": 10.538976907730103}", "{\"n\": 13566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.26, \"learn_time_ms\": 9103.07, \"total_train_time_s\": 10.680853843688965}", "{\"n\": 13567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.86, \"learn_time_ms\": 8986.385, \"total_train_time_s\": 8.864293813705444}", "{\"n\": 13568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.06, \"learn_time_ms\": 8851.469, \"total_train_time_s\": 8.986647605895996}", "{\"n\": 13569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.67, \"learn_time_ms\": 8878.52, \"total_train_time_s\": 10.16208004951477}", "{\"n\": 13570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.93, \"learn_time_ms\": 8815.722, \"total_train_time_s\": 10.420368432998657}", "{\"n\": 13571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.54, \"learn_time_ms\": 8678.493, \"total_train_time_s\": 10.147656917572021}", "{\"n\": 13572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.66, \"learn_time_ms\": 8787.74, \"total_train_time_s\": 10.742120504379272}", "{\"n\": 13573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.28, \"learn_time_ms\": 8700.096, \"total_train_time_s\": 9.748564720153809}", "{\"n\": 13574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.31, \"learn_time_ms\": 8616.567, \"total_train_time_s\": 9.904736757278442}", "{\"n\": 13575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 8660.703, \"total_train_time_s\": 10.992712020874023}", "{\"n\": 13576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.78, \"learn_time_ms\": 8550.144, \"total_train_time_s\": 9.577438354492188}", "{\"n\": 13577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.26, \"learn_time_ms\": 8708.232, \"total_train_time_s\": 10.412750720977783}", "{\"n\": 13578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.28, \"learn_time_ms\": 8762.333, \"total_train_time_s\": 9.530921697616577}", "{\"n\": 13579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.99, \"learn_time_ms\": 8823.607, \"total_train_time_s\": 10.771782875061035}", "{\"n\": 13580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 8792.241, \"total_train_time_s\": 10.124896049499512}", "{\"n\": 13581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.44, \"learn_time_ms\": 8816.969, \"total_train_time_s\": 10.407436609268188}", "{\"n\": 13582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.44, \"learn_time_ms\": 8737.131, \"total_train_time_s\": 9.899887084960938}", "{\"n\": 13583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.31, \"learn_time_ms\": 8718.467, \"total_train_time_s\": 9.521998167037964}", "{\"n\": 13584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.52, \"learn_time_ms\": 8756.81, \"total_train_time_s\": 10.265817642211914}", "{\"n\": 13585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.21, \"learn_time_ms\": 8596.497, \"total_train_time_s\": 9.342259645462036}", "{\"n\": 13586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.1, \"learn_time_ms\": 8748.416, \"total_train_time_s\": 11.091068029403687}", "{\"n\": 13587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.08, \"learn_time_ms\": 8725.145, \"total_train_time_s\": 10.207422971725464}", "{\"n\": 13588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.08, \"learn_time_ms\": 8731.86, \"total_train_time_s\": 9.582907676696777}", "{\"n\": 13589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.35, \"learn_time_ms\": 8550.516, \"total_train_time_s\": 8.950965881347656}", "{\"n\": 13590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.21, \"learn_time_ms\": 8435.24, \"total_train_time_s\": 9.077143907546997}", "{\"n\": 13591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.92, \"learn_time_ms\": 8343.357, \"total_train_time_s\": 9.499115705490112}", "{\"n\": 13592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.14, \"learn_time_ms\": 8490.772, \"total_train_time_s\": 11.40325117111206}", "{\"n\": 13593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.05, \"learn_time_ms\": 8547.984, \"total_train_time_s\": 10.162404775619507}", "{\"n\": 13594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.64, \"learn_time_ms\": 8527.278, \"total_train_time_s\": 10.066266059875488}", "{\"n\": 13595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.1, \"learn_time_ms\": 8640.509, \"total_train_time_s\": 10.466080665588379}", "{\"n\": 13596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.1, \"learn_time_ms\": 8544.232, \"total_train_time_s\": 10.113399267196655}", "{\"n\": 13597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.18, \"learn_time_ms\": 8455.756, \"total_train_time_s\": 9.328518629074097}", "{\"n\": 13598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 8425.891, \"total_train_time_s\": 9.312231063842773}", "{\"n\": 13599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 8625.101, \"total_train_time_s\": 10.960182189941406}", "{\"n\": 13600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.48, \"learn_time_ms\": 8779.591, \"total_train_time_s\": 10.58848762512207}", "{\"n\": 13601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.48, \"learn_time_ms\": 8699.1, \"total_train_time_s\": 8.664028406143188}", "{\"n\": 13602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.22, \"learn_time_ms\": 8378.057, \"total_train_time_s\": 8.168556451797485}", "{\"n\": 13603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.09, \"learn_time_ms\": 8396.293, \"total_train_time_s\": 10.329681634902954}", "{\"n\": 13604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3289.76, \"learn_time_ms\": 8382.167, \"total_train_time_s\": 9.907493591308594}", "{\"n\": 13605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.44, \"learn_time_ms\": 8451.487, \"total_train_time_s\": 11.15054178237915}", "{\"n\": 13606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.36, \"learn_time_ms\": 8406.139, \"total_train_time_s\": 9.643144130706787}", "{\"n\": 13607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3291.28, \"learn_time_ms\": 8528.479, \"total_train_time_s\": 10.604641675949097}", "{\"n\": 13608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.01, \"learn_time_ms\": 8620.064, \"total_train_time_s\": 10.230951070785522}", "{\"n\": 13609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.01, \"learn_time_ms\": 8370.432, \"total_train_time_s\": 8.461859464645386}", "{\"n\": 13610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.75, \"learn_time_ms\": 8491.117, \"total_train_time_s\": 11.74135160446167}", "{\"n\": 13611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.18, \"learn_time_ms\": 8572.589, \"total_train_time_s\": 9.449257612228394}", "{\"n\": 13612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.89, \"learn_time_ms\": 8853.475, \"total_train_time_s\": 11.05988597869873}", "{\"n\": 13613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.31, \"learn_time_ms\": 8815.956, \"total_train_time_s\": 10.002609968185425}", "{\"n\": 13614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.8, \"learn_time_ms\": 8800.044, \"total_train_time_s\": 9.828881025314331}", "{\"n\": 13615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.0, \"learn_time_ms\": 8585.075, \"total_train_time_s\": 9.09155797958374}", "{\"n\": 13616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.87, \"learn_time_ms\": 8608.371, \"total_train_time_s\": 9.954789400100708}", "{\"n\": 13617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.45, \"learn_time_ms\": 8543.246, \"total_train_time_s\": 9.939351081848145}", "{\"n\": 13618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.45, \"learn_time_ms\": 8593.267, \"total_train_time_s\": 10.762560606002808}", "{\"n\": 13619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.99, \"learn_time_ms\": 8760.832, \"total_train_time_s\": 10.143789529800415}", "{\"n\": 13620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.66, \"learn_time_ms\": 8587.984, \"total_train_time_s\": 10.043238162994385}", "{\"n\": 13621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.15, \"learn_time_ms\": 8688.169, \"total_train_time_s\": 10.482483625411987}", "{\"n\": 13622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.16, \"learn_time_ms\": 8558.29, \"total_train_time_s\": 9.699128150939941}", "{\"n\": 13623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.34, \"learn_time_ms\": 8530.575, \"total_train_time_s\": 9.689898014068604}", "{\"n\": 13624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.34, \"learn_time_ms\": 8361.141, \"total_train_time_s\": 8.064139127731323}", "{\"n\": 13625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.58, \"learn_time_ms\": 8528.717, \"total_train_time_s\": 10.752949476242065}", "{\"n\": 13626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.1, \"learn_time_ms\": 8500.098, \"total_train_time_s\": 9.58895206451416}", "{\"n\": 13627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.63, \"learn_time_ms\": 8460.946, \"total_train_time_s\": 9.488893270492554}", "{\"n\": 13628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.63, \"learn_time_ms\": 8521.265, \"total_train_time_s\": 11.352773189544678}", "{\"n\": 13629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.06, \"learn_time_ms\": 8441.704, \"total_train_time_s\": 9.345002889633179}", "{\"n\": 13630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.44, \"learn_time_ms\": 8460.28, \"total_train_time_s\": 10.196941375732422}", "{\"n\": 13631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.44, \"learn_time_ms\": 8414.141, \"total_train_time_s\": 9.995909214019775}", "{\"n\": 13632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.19, \"learn_time_ms\": 8489.973, \"total_train_time_s\": 10.420249223709106}", "{\"n\": 13633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.8, \"learn_time_ms\": 8428.163, \"total_train_time_s\": 9.062236785888672}", "{\"n\": 13634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.8, \"learn_time_ms\": 8552.271, \"total_train_time_s\": 9.280095100402832}", "{\"n\": 13635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.79, \"learn_time_ms\": 8456.181, \"total_train_time_s\": 9.758249759674072}", "{\"n\": 13636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.56, \"learn_time_ms\": 8668.101, \"total_train_time_s\": 11.789030313491821}", "{\"n\": 13637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.56, \"learn_time_ms\": 8792.994, \"total_train_time_s\": 10.792499303817749}", "{\"n\": 13638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.35, \"learn_time_ms\": 8825.878, \"total_train_time_s\": 11.646550178527832}", "{\"n\": 13639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.87, \"learn_time_ms\": 8838.477, \"total_train_time_s\": 9.460311651229858}", "{\"n\": 13640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.82, \"learn_time_ms\": 8869.724, \"total_train_time_s\": 10.532496929168701}", "{\"n\": 13641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.95, \"learn_time_ms\": 8793.889, \"total_train_time_s\": 9.254957437515259}", "{\"n\": 13642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.24, \"learn_time_ms\": 8697.899, \"total_train_time_s\": 9.426965475082397}", "{\"n\": 13643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.3, \"learn_time_ms\": 8887.62, \"total_train_time_s\": 10.973000764846802}", "{\"n\": 13644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.2, \"learn_time_ms\": 9069.2, \"total_train_time_s\": 11.1813325881958}", "{\"n\": 13645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.01, \"learn_time_ms\": 9099.825, \"total_train_time_s\": 10.000059366226196}", "{\"n\": 13646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.89, \"learn_time_ms\": 9119.822, \"total_train_time_s\": 11.943880796432495}", "{\"n\": 13647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.38, \"learn_time_ms\": 8855.864, \"total_train_time_s\": 8.063315391540527}", "{\"n\": 13648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.81, \"learn_time_ms\": 8626.537, \"total_train_time_s\": 9.390517473220825}", "{\"n\": 13649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.31, \"learn_time_ms\": 8663.089, \"total_train_time_s\": 9.867018938064575}", "{\"n\": 13650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.31, \"learn_time_ms\": 8589.42, \"total_train_time_s\": 9.754081726074219}", "{\"n\": 13651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.13, \"learn_time_ms\": 8683.921, \"total_train_time_s\": 10.193736791610718}", "{\"n\": 13652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.79, \"learn_time_ms\": 8790.91, \"total_train_time_s\": 10.636394500732422}", "{\"n\": 13653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.82, \"learn_time_ms\": 8824.626, \"total_train_time_s\": 11.319624423980713}", "{\"n\": 13654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.21, \"learn_time_ms\": 8556.487, \"total_train_time_s\": 8.441153526306152}", "{\"n\": 13655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.53, \"learn_time_ms\": 8546.419, \"total_train_time_s\": 9.94598388671875}", "{\"n\": 13656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.41, \"learn_time_ms\": 8337.159, \"total_train_time_s\": 9.904724597930908}", "{\"n\": 13657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.06, \"learn_time_ms\": 8584.741, \"total_train_time_s\": 10.594620943069458}", "{\"n\": 13658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.58, \"learn_time_ms\": 8600.919, \"total_train_time_s\": 9.528834104537964}", "{\"n\": 13659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.42, \"learn_time_ms\": 8757.868, \"total_train_time_s\": 11.394480228424072}", "{\"n\": 13660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.15, \"learn_time_ms\": 8640.822, \"total_train_time_s\": 8.598149299621582}", "{\"n\": 13661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.98, \"learn_time_ms\": 8513.763, \"total_train_time_s\": 8.89791226387024}", "{\"n\": 13662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.01, \"learn_time_ms\": 8314.185, \"total_train_time_s\": 8.509994506835938}", "{\"n\": 13663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.84, \"learn_time_ms\": 8041.25, \"total_train_time_s\": 8.591584205627441}", "{\"n\": 13664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.49, \"learn_time_ms\": 8232.029, \"total_train_time_s\": 10.394579410552979}", "{\"n\": 13665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.49, \"learn_time_ms\": 8281.791, \"total_train_time_s\": 10.484204769134521}", "{\"n\": 13666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.85, \"learn_time_ms\": 8203.408, \"total_train_time_s\": 9.07581615447998}", "{\"n\": 13667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.12, \"learn_time_ms\": 8020.806, \"total_train_time_s\": 8.777107954025269}", "{\"n\": 13668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.07, \"learn_time_ms\": 8068.038, \"total_train_time_s\": 10.029104232788086}", "{\"n\": 13669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.45, \"learn_time_ms\": 7846.596, \"total_train_time_s\": 9.182619571685791}", "{\"n\": 13670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.45, \"learn_time_ms\": 7969.877, \"total_train_time_s\": 9.849358558654785}", "{\"n\": 13671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.69, \"learn_time_ms\": 8051.816, \"total_train_time_s\": 9.754266738891602}", "{\"n\": 13672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.85, \"learn_time_ms\": 8223.433, \"total_train_time_s\": 10.281625747680664}", "{\"n\": 13673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.54, \"learn_time_ms\": 8351.467, \"total_train_time_s\": 9.845449686050415}", "{\"n\": 13674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.23, \"learn_time_ms\": 8385.275, \"total_train_time_s\": 10.69596004486084}", "{\"n\": 13675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.41, \"learn_time_ms\": 8440.273, \"total_train_time_s\": 10.994270324707031}", "{\"n\": 13676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.77, \"learn_time_ms\": 8738.493, \"total_train_time_s\": 12.033303022384644}", "{\"n\": 13677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.25, \"learn_time_ms\": 8975.109, \"total_train_time_s\": 11.15315842628479}", "{\"n\": 13678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.01, \"learn_time_ms\": 9091.986, \"total_train_time_s\": 11.22028660774231}", "{\"n\": 13679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.88, \"learn_time_ms\": 9225.614, \"total_train_time_s\": 10.501864194869995}", "{\"n\": 13680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.11, \"learn_time_ms\": 9204.964, \"total_train_time_s\": 9.590871334075928}", "{\"n\": 13681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.11, \"learn_time_ms\": 9137.828, \"total_train_time_s\": 9.05019211769104}", "{\"n\": 13682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.08, \"learn_time_ms\": 9112.368, \"total_train_time_s\": 10.003946304321289}", "{\"n\": 13683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.95, \"learn_time_ms\": 9213.373, \"total_train_time_s\": 10.812862157821655}", "{\"n\": 13684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.46, \"learn_time_ms\": 9121.433, \"total_train_time_s\": 9.78672170639038}", "{\"n\": 13685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.58, \"learn_time_ms\": 9062.09, \"total_train_time_s\": 10.424975156784058}", "{\"n\": 13686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.34, \"learn_time_ms\": 8804.725, \"total_train_time_s\": 9.501885890960693}", "{\"n\": 13687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.29, \"learn_time_ms\": 8763.386, \"total_train_time_s\": 10.751096487045288}", "{\"n\": 13688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.31, \"learn_time_ms\": 8481.003, \"total_train_time_s\": 8.33526062965393}", "{\"n\": 13689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.31, \"learn_time_ms\": 8512.898, \"total_train_time_s\": 10.848567485809326}", "{\"n\": 13690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.9, \"learn_time_ms\": 8660.602, \"total_train_time_s\": 11.15135383605957}", "{\"n\": 13691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.73, \"learn_time_ms\": 8866.901, \"total_train_time_s\": 11.169766902923584}", "{\"n\": 13692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.43, \"learn_time_ms\": 8976.259, \"total_train_time_s\": 11.106216430664062}", "{\"n\": 13693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.62, \"learn_time_ms\": 8806.35, \"total_train_time_s\": 9.107914209365845}", "{\"n\": 13694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.12, \"learn_time_ms\": 8791.722, \"total_train_time_s\": 9.64629602432251}", "{\"n\": 13695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.93, \"learn_time_ms\": 8750.375, \"total_train_time_s\": 9.983709812164307}", "{\"n\": 13696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.77, \"learn_time_ms\": 8817.009, \"total_train_time_s\": 10.144141435623169}", "{\"n\": 13697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.88, \"learn_time_ms\": 8689.313, \"total_train_time_s\": 9.468329906463623}", "{\"n\": 13698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.64, \"learn_time_ms\": 8834.663, \"total_train_time_s\": 9.84140157699585}", "{\"n\": 13699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.64, \"learn_time_ms\": 8726.012, \"total_train_time_s\": 9.80778193473816}", "{\"n\": 13700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.72, \"learn_time_ms\": 8550.95, \"total_train_time_s\": 9.34662675857544}", "{\"n\": 13701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.71, \"learn_time_ms\": 8338.108, \"total_train_time_s\": 9.021391868591309}", "{\"n\": 13702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.56, \"learn_time_ms\": 8199.447, \"total_train_time_s\": 9.6903555393219}", "{\"n\": 13703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.95, \"learn_time_ms\": 8230.565, \"total_train_time_s\": 9.42556881904602}", "{\"n\": 13704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.87, \"learn_time_ms\": 8202.684, \"total_train_time_s\": 9.398983240127563}", "{\"n\": 13705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 8263.176, \"total_train_time_s\": 10.614088296890259}", "{\"n\": 13706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.71, \"learn_time_ms\": 8173.841, \"total_train_time_s\": 9.216322898864746}", "{\"n\": 13707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.28, \"learn_time_ms\": 8211.23, \"total_train_time_s\": 9.83251690864563}", "{\"n\": 13708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.28, \"learn_time_ms\": 8370.15, \"total_train_time_s\": 11.360057592391968}", "{\"n\": 13709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.87, \"learn_time_ms\": 8342.083, \"total_train_time_s\": 9.467840194702148}", "{\"n\": 13710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.08, \"learn_time_ms\": 8395.91, \"total_train_time_s\": 9.894827127456665}", "{\"n\": 13711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.57, \"learn_time_ms\": 8574.401, \"total_train_time_s\": 10.798217535018921}", "{\"n\": 13712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.42, \"learn_time_ms\": 8563.761, \"total_train_time_s\": 9.571279048919678}", "{\"n\": 13713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.35, \"learn_time_ms\": 8707.116, \"total_train_time_s\": 10.91920781135559}", "{\"n\": 13714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.23, \"learn_time_ms\": 8696.15, \"total_train_time_s\": 9.2846200466156}", "{\"n\": 13715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.95, \"learn_time_ms\": 8531.74, \"total_train_time_s\": 8.93106460571289}", "{\"n\": 13716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.92, \"learn_time_ms\": 8673.608, \"total_train_time_s\": 10.719372749328613}", "{\"n\": 13717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.94, \"learn_time_ms\": 8897.014, \"total_train_time_s\": 12.048570156097412}", "{\"n\": 13718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.54, \"learn_time_ms\": 8766.598, \"total_train_time_s\": 10.095415115356445}", "{\"n\": 13719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.32, \"learn_time_ms\": 8899.947, \"total_train_time_s\": 10.793097019195557}", "{\"n\": 13720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.42, \"learn_time_ms\": 8865.194, \"total_train_time_s\": 9.504647016525269}", "{\"n\": 13721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.46, \"learn_time_ms\": 8865.774, \"total_train_time_s\": 10.79082727432251}", "{\"n\": 13722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.19, \"learn_time_ms\": 8791.666, \"total_train_time_s\": 8.839009284973145}", "{\"n\": 13723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.33, \"learn_time_ms\": 8699.199, \"total_train_time_s\": 10.00126338005066}", "{\"n\": 13724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.69, \"learn_time_ms\": 8760.346, \"total_train_time_s\": 9.908655643463135}", "{\"n\": 13725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.18, \"learn_time_ms\": 8845.814, \"total_train_time_s\": 9.866716384887695}", "{\"n\": 13726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.19, \"learn_time_ms\": 8667.517, \"total_train_time_s\": 8.872156620025635}", "{\"n\": 13727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.32, \"learn_time_ms\": 8362.903, \"total_train_time_s\": 8.992085456848145}", "{\"n\": 13728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.38, \"learn_time_ms\": 8335.94, \"total_train_time_s\": 9.771867990493774}", "{\"n\": 13729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.38, \"learn_time_ms\": 8309.571, \"total_train_time_s\": 10.53269624710083}", "{\"n\": 13730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.73, \"learn_time_ms\": 8364.585, \"total_train_time_s\": 10.124285697937012}", "{\"n\": 13731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.39, \"learn_time_ms\": 8338.633, \"total_train_time_s\": 10.55111050605774}", "{\"n\": 13732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.39, \"learn_time_ms\": 8590.086, \"total_train_time_s\": 11.413577556610107}", "{\"n\": 13733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.39, \"learn_time_ms\": 8559.152, \"total_train_time_s\": 9.624232292175293}", "{\"n\": 13734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.99, \"learn_time_ms\": 8645.693, \"total_train_time_s\": 10.73496389389038}", "{\"n\": 13735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.48, \"learn_time_ms\": 8656.284, \"total_train_time_s\": 9.989053010940552}", "{\"n\": 13736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.48, \"learn_time_ms\": 8721.375, \"total_train_time_s\": 9.534485816955566}", "{\"n\": 13737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.16, \"learn_time_ms\": 8755.316, \"total_train_time_s\": 9.414914608001709}", "{\"n\": 13738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.59, \"learn_time_ms\": 8716.989, \"total_train_time_s\": 9.40558671951294}", "{\"n\": 13739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.07, \"learn_time_ms\": 8719.034, \"total_train_time_s\": 10.555631399154663}", "{\"n\": 13740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.09, \"learn_time_ms\": 8879.048, \"total_train_time_s\": 11.690143346786499}", "{\"n\": 13741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.57, \"learn_time_ms\": 8778.181, \"total_train_time_s\": 9.561356544494629}", "{\"n\": 13742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.78, \"learn_time_ms\": 8701.761, \"total_train_time_s\": 10.631996393203735}", "{\"n\": 13743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.78, \"learn_time_ms\": 8722.585, \"total_train_time_s\": 9.888882160186768}", "{\"n\": 13744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.1, \"learn_time_ms\": 8665.616, \"total_train_time_s\": 10.124574184417725}", "{\"n\": 13745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.88, \"learn_time_ms\": 8650.987, \"total_train_time_s\": 9.770175457000732}", "{\"n\": 13746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.95, \"learn_time_ms\": 8560.542, \"total_train_time_s\": 8.61243224143982}", "{\"n\": 13747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.67, \"learn_time_ms\": 8692.117, \"total_train_time_s\": 10.669193506240845}", "{\"n\": 13748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.98, \"learn_time_ms\": 8708.038, \"total_train_time_s\": 9.581921577453613}", "{\"n\": 13749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.89, \"learn_time_ms\": 8506.701, \"total_train_time_s\": 8.572191953659058}", "{\"n\": 13750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.71, \"learn_time_ms\": 8219.418, \"total_train_time_s\": 8.819837808609009}", "{\"n\": 13751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.71, \"learn_time_ms\": 8147.81, \"total_train_time_s\": 8.818002223968506}", "{\"n\": 13752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 8106.368, \"total_train_time_s\": 10.20916748046875}", "{\"n\": 13753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 8090.055, \"total_train_time_s\": 9.682804584503174}", "{\"n\": 13754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.43, \"learn_time_ms\": 8021.473, \"total_train_time_s\": 9.483807563781738}", "{\"n\": 13755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.89, \"learn_time_ms\": 8138.45, \"total_train_time_s\": 10.95656418800354}", "{\"n\": 13756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.41, \"learn_time_ms\": 8283.103, \"total_train_time_s\": 10.106728792190552}", "{\"n\": 13757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.32, \"learn_time_ms\": 8200.98, \"total_train_time_s\": 9.86233139038086}", "{\"n\": 13758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.53, \"learn_time_ms\": 8216.624, \"total_train_time_s\": 9.767066717147827}", "{\"n\": 13759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.54, \"learn_time_ms\": 8429.15, \"total_train_time_s\": 10.674466133117676}", "{\"n\": 13760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.54, \"learn_time_ms\": 8659.806, \"total_train_time_s\": 11.093708753585815}", "{\"n\": 13761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.78, \"learn_time_ms\": 8842.149, \"total_train_time_s\": 10.617509365081787}", "{\"n\": 13762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.95, \"learn_time_ms\": 8744.041, \"total_train_time_s\": 9.216744899749756}", "{\"n\": 13763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.95, \"learn_time_ms\": 8821.676, \"total_train_time_s\": 10.508485794067383}", "{\"n\": 13764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.34, \"learn_time_ms\": 8943.888, \"total_train_time_s\": 10.703726291656494}", "{\"n\": 13765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.58, \"learn_time_ms\": 9009.872, \"total_train_time_s\": 11.637608289718628}", "{\"n\": 13766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.73, \"learn_time_ms\": 9026.84, \"total_train_time_s\": 10.257338523864746}", "{\"n\": 13767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.04, \"learn_time_ms\": 9047.368, \"total_train_time_s\": 10.041643619537354}", "{\"n\": 13768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.04, \"learn_time_ms\": 9099.191, \"total_train_time_s\": 10.217792510986328}", "{\"n\": 13769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.4, \"learn_time_ms\": 8957.032, \"total_train_time_s\": 9.296390056610107}", "{\"n\": 13770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.28, \"learn_time_ms\": 8743.866, \"total_train_time_s\": 8.969073057174683}", "{\"n\": 13771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.28, \"learn_time_ms\": 8773.535, \"total_train_time_s\": 10.90587830543518}", "{\"n\": 13772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.38, \"learn_time_ms\": 9043.314, \"total_train_time_s\": 12.052529573440552}", "{\"n\": 13773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.28, \"learn_time_ms\": 9019.582, \"total_train_time_s\": 10.239312648773193}", "{\"n\": 13774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.28, \"learn_time_ms\": 9032.938, \"total_train_time_s\": 10.836537599563599}", "{\"n\": 13775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.28, \"learn_time_ms\": 8778.496, \"total_train_time_s\": 9.029443979263306}", "{\"n\": 13776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.3, \"learn_time_ms\": 8833.405, \"total_train_time_s\": 10.826942443847656}", "{\"n\": 13777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.67, \"learn_time_ms\": 8878.335, \"total_train_time_s\": 10.481208086013794}", "{\"n\": 13778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.67, \"learn_time_ms\": 8822.756, \"total_train_time_s\": 9.745627164840698}", "{\"n\": 13779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.24, \"learn_time_ms\": 8710.502, \"total_train_time_s\": 8.146596431732178}", "{\"n\": 13780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.82, \"learn_time_ms\": 8841.131, \"total_train_time_s\": 10.278156757354736}", "{\"n\": 13781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.82, \"learn_time_ms\": 8760.195, \"total_train_time_s\": 10.119932413101196}", "{\"n\": 13782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.55, \"learn_time_ms\": 8493.111, \"total_train_time_s\": 9.254487991333008}", "{\"n\": 13783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.81, \"learn_time_ms\": 8328.888, \"total_train_time_s\": 8.654020309448242}", "{\"n\": 13784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.0, \"learn_time_ms\": 8255.809, \"total_train_time_s\": 10.128121614456177}", "{\"n\": 13785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.01, \"learn_time_ms\": 8431.216, \"total_train_time_s\": 10.82962942123413}", "{\"n\": 13786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.2, \"learn_time_ms\": 8431.075, \"total_train_time_s\": 10.785317182540894}", "{\"n\": 13787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.17, \"learn_time_ms\": 8372.315, \"total_train_time_s\": 9.93212890625}", "{\"n\": 13788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.68, \"learn_time_ms\": 8300.428, \"total_train_time_s\": 8.991732358932495}", "{\"n\": 13789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.16, \"learn_time_ms\": 8588.649, \"total_train_time_s\": 11.014032363891602}", "{\"n\": 13790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.16, \"learn_time_ms\": 8562.636, \"total_train_time_s\": 10.047041416168213}", "{\"n\": 13791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.14, \"learn_time_ms\": 8547.379, \"total_train_time_s\": 9.962931156158447}", "{\"n\": 13792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.14, \"learn_time_ms\": 8627.895, \"total_train_time_s\": 10.070479154586792}", "{\"n\": 13793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.69, \"learn_time_ms\": 8755.843, \"total_train_time_s\": 9.88266921043396}", "{\"n\": 13794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.03, \"learn_time_ms\": 8764.232, \"total_train_time_s\": 10.214866399765015}", "{\"n\": 13795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 8485.324, \"total_train_time_s\": 8.064513683319092}", "{\"n\": 13796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 8323.048, \"total_train_time_s\": 9.151686906814575}", "{\"n\": 13797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.97, \"learn_time_ms\": 8315.186, \"total_train_time_s\": 9.857434272766113}", "{\"n\": 13798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.8, \"learn_time_ms\": 8361.516, \"total_train_time_s\": 9.450323581695557}", "{\"n\": 13799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.8, \"learn_time_ms\": 8188.945, \"total_train_time_s\": 9.300774097442627}", "{\"n\": 13800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.52, \"learn_time_ms\": 8170.422, \"total_train_time_s\": 9.850531578063965}", "{\"n\": 13801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.55, \"learn_time_ms\": 8080.079, \"total_train_time_s\": 9.050621509552002}", "{\"n\": 13802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.55, \"learn_time_ms\": 8085.526, \"total_train_time_s\": 10.053079843521118}", "{\"n\": 13803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.55, \"learn_time_ms\": 8184.018, \"total_train_time_s\": 10.897767305374146}", "{\"n\": 13804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.57, \"learn_time_ms\": 8287.392, \"total_train_time_s\": 11.275423526763916}", "{\"n\": 13805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.52, \"learn_time_ms\": 8531.858, \"total_train_time_s\": 10.476664543151855}", "{\"n\": 13806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.52, \"learn_time_ms\": 8510.008, \"total_train_time_s\": 8.946623802185059}", "{\"n\": 13807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.07, \"learn_time_ms\": 8528.611, \"total_train_time_s\": 10.021807670593262}", "{\"n\": 13808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.31, \"learn_time_ms\": 8570.865, \"total_train_time_s\": 9.899647951126099}", "{\"n\": 13809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.31, \"learn_time_ms\": 8531.633, \"total_train_time_s\": 8.876414060592651}", "{\"n\": 13810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.5, \"learn_time_ms\": 8508.637, \"total_train_time_s\": 9.602396726608276}", "{\"n\": 13811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.12, \"learn_time_ms\": 8671.003, \"total_train_time_s\": 10.734938383102417}", "{\"n\": 13812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.43, \"learn_time_ms\": 8507.934, \"total_train_time_s\": 8.514074325561523}", "{\"n\": 13813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.31, \"learn_time_ms\": 8514.882, \"total_train_time_s\": 10.983731746673584}", "{\"n\": 13814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.65, \"learn_time_ms\": 8386.401, \"total_train_time_s\": 9.931153059005737}", "{\"n\": 13815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.4, \"learn_time_ms\": 8363.442, \"total_train_time_s\": 10.242813110351562}", "{\"n\": 13816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.77, \"learn_time_ms\": 8536.291, \"total_train_time_s\": 10.67151689529419}", "{\"n\": 13817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.19, \"learn_time_ms\": 8503.607, \"total_train_time_s\": 9.681158304214478}", "{\"n\": 13818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.68, \"learn_time_ms\": 8574.291, \"total_train_time_s\": 10.594629526138306}", "{\"n\": 13819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.73, \"learn_time_ms\": 8812.251, \"total_train_time_s\": 11.322466850280762}", "{\"n\": 13820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.96, \"learn_time_ms\": 8817.875, \"total_train_time_s\": 9.729733228683472}", "{\"n\": 13821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.33, \"learn_time_ms\": 8704.402, \"total_train_time_s\": 9.574947595596313}", "{\"n\": 13822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.57, \"learn_time_ms\": 8876.013, \"total_train_time_s\": 10.156973838806152}", "{\"n\": 13823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.65, \"learn_time_ms\": 8696.445, \"total_train_time_s\": 9.133614540100098}", "{\"n\": 13824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.8, \"learn_time_ms\": 8732.662, \"total_train_time_s\": 10.266476392745972}", "{\"n\": 13825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.8, \"learn_time_ms\": 8671.785, \"total_train_time_s\": 9.631142854690552}", "{\"n\": 13826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.41, \"learn_time_ms\": 8625.365, \"total_train_time_s\": 10.232601165771484}", "{\"n\": 13827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.2, \"learn_time_ms\": 8566.367, \"total_train_time_s\": 9.074909925460815}", "{\"n\": 13828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.2, \"learn_time_ms\": 8455.356, \"total_train_time_s\": 9.437532663345337}", "{\"n\": 13829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.88, \"learn_time_ms\": 8488.224, \"total_train_time_s\": 11.617121934890747}", "{\"n\": 13830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.09, \"learn_time_ms\": 8552.028, \"total_train_time_s\": 10.37233591079712}", "{\"n\": 13831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.17, \"learn_time_ms\": 8588.956, \"total_train_time_s\": 9.918047666549683}", "{\"n\": 13832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.18, \"learn_time_ms\": 8581.646, \"total_train_time_s\": 10.107502222061157}", "{\"n\": 13833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 8634.291, \"total_train_time_s\": 9.654762744903564}", "{\"n\": 13834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.07, \"learn_time_ms\": 8640.356, \"total_train_time_s\": 10.414813995361328}", "{\"n\": 13835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.84, \"learn_time_ms\": 8601.478, \"total_train_time_s\": 9.26741075515747}", "{\"n\": 13836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.84, \"learn_time_ms\": 8484.679, \"total_train_time_s\": 9.043916940689087}", "{\"n\": 13837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.15, \"learn_time_ms\": 8544.022, \"total_train_time_s\": 9.701751232147217}", "{\"n\": 13838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.7, \"learn_time_ms\": 8708.759, \"total_train_time_s\": 11.15134072303772}", "{\"n\": 13839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.39, \"learn_time_ms\": 8567.126, \"total_train_time_s\": 10.19692087173462}", "{\"n\": 13840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.77, \"learn_time_ms\": 8586.789, \"total_train_time_s\": 10.565009355545044}", "{\"n\": 13841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.71, \"learn_time_ms\": 8650.122, \"total_train_time_s\": 10.640804529190063}", "{\"n\": 13842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.03, \"learn_time_ms\": 8683.228, \"total_train_time_s\": 10.487268447875977}", "{\"n\": 13843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.03, \"learn_time_ms\": 8681.121, \"total_train_time_s\": 9.633598327636719}", "{\"n\": 13844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.3, \"learn_time_ms\": 8636.733, \"total_train_time_s\": 9.926159620285034}", "{\"n\": 13845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.75, \"learn_time_ms\": 8638.749, \"total_train_time_s\": 9.273587942123413}", "{\"n\": 13846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.75, \"learn_time_ms\": 8706.177, \"total_train_time_s\": 9.737719297409058}", "{\"n\": 13847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.79, \"learn_time_ms\": 8705.04, \"total_train_time_s\": 9.676950216293335}", "{\"n\": 13848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.09, \"learn_time_ms\": 8598.18, \"total_train_time_s\": 10.074953079223633}", "{\"n\": 13849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.87, \"learn_time_ms\": 8473.432, \"total_train_time_s\": 8.98897933959961}", "{\"n\": 13850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.87, \"learn_time_ms\": 8408.389, \"total_train_time_s\": 9.877270460128784}", "{\"n\": 13851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.39, \"learn_time_ms\": 8362.329, \"total_train_time_s\": 10.092849969863892}", "{\"n\": 13852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.01, \"learn_time_ms\": 8298.362, \"total_train_time_s\": 9.826006650924683}", "{\"n\": 13853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.01, \"learn_time_ms\": 8373.75, \"total_train_time_s\": 10.422619581222534}", "{\"n\": 13854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.66, \"learn_time_ms\": 8412.106, \"total_train_time_s\": 10.353495836257935}", "{\"n\": 13855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.61, \"learn_time_ms\": 8438.192, \"total_train_time_s\": 9.57182002067566}", "{\"n\": 13856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.61, \"learn_time_ms\": 8604.358, \"total_train_time_s\": 11.380187273025513}", "{\"n\": 13857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.03, \"learn_time_ms\": 8743.341, \"total_train_time_s\": 11.044263124465942}", "{\"n\": 13858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.29, \"learn_time_ms\": 8712.487, \"total_train_time_s\": 9.702876806259155}", "{\"n\": 13859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.29, \"learn_time_ms\": 8876.969, \"total_train_time_s\": 10.55383849143982}", "{\"n\": 13860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.07, \"learn_time_ms\": 8995.534, \"total_train_time_s\": 11.036338090896606}", "{\"n\": 13861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.78, \"learn_time_ms\": 9029.931, \"total_train_time_s\": 10.447048425674438}", "{\"n\": 13862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 9115.898, \"total_train_time_s\": 10.700148820877075}", "{\"n\": 13863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 9007.068, \"total_train_time_s\": 9.363858222961426}", "{\"n\": 13864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.12, \"learn_time_ms\": 8912.093, \"total_train_time_s\": 9.316824436187744}", "{\"n\": 13865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.44, \"learn_time_ms\": 8912.502, \"total_train_time_s\": 9.563104152679443}", "{\"n\": 13866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.44, \"learn_time_ms\": 8809.965, \"total_train_time_s\": 10.351213455200195}", "{\"n\": 13867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.23, \"learn_time_ms\": 8670.31, \"total_train_time_s\": 9.738275289535522}", "{\"n\": 13868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.28, \"learn_time_ms\": 8653.585, \"total_train_time_s\": 9.642854690551758}", "{\"n\": 13869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.28, \"learn_time_ms\": 8563.642, \"total_train_time_s\": 9.745830774307251}", "{\"n\": 13870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.74, \"learn_time_ms\": 8482.975, \"total_train_time_s\": 10.226465702056885}", "{\"n\": 13871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.56, \"learn_time_ms\": 8457.018, \"total_train_time_s\": 10.169593811035156}", "{\"n\": 13872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.57, \"learn_time_ms\": 8434.87, \"total_train_time_s\": 10.42299199104309}", "{\"n\": 13873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.49, \"learn_time_ms\": 8518.145, \"total_train_time_s\": 10.148765087127686}", "{\"n\": 13874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.75, \"learn_time_ms\": 8596.412, \"total_train_time_s\": 10.084374904632568}", "{\"n\": 13875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.69, \"learn_time_ms\": 8669.892, \"total_train_time_s\": 10.2542142868042}", "{\"n\": 13876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.69, \"learn_time_ms\": 8604.24, \"total_train_time_s\": 9.66778826713562}", "{\"n\": 13877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.32, \"learn_time_ms\": 8611.47, \"total_train_time_s\": 9.762458562850952}", "{\"n\": 13878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.33, \"learn_time_ms\": 8623.87, \"total_train_time_s\": 9.680879354476929}", "{\"n\": 13879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.4, \"learn_time_ms\": 8679.984, \"total_train_time_s\": 10.253440856933594}", "{\"n\": 13880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.65, \"learn_time_ms\": 8678.082, \"total_train_time_s\": 10.228156566619873}", "{\"n\": 13881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.72, \"learn_time_ms\": 8667.783, \"total_train_time_s\": 10.060869693756104}", "{\"n\": 13882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.12, \"learn_time_ms\": 8544.505, \"total_train_time_s\": 9.285463809967041}", "{\"n\": 13883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.12, \"learn_time_ms\": 8512.277, \"total_train_time_s\": 9.858623743057251}", "{\"n\": 13884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.86, \"learn_time_ms\": 8491.651, \"total_train_time_s\": 9.91977310180664}", "{\"n\": 13885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.86, \"learn_time_ms\": 8440.074, \"total_train_time_s\": 9.782094478607178}", "{\"n\": 13886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.87, \"learn_time_ms\": 8317.71, \"total_train_time_s\": 8.503504991531372}", "{\"n\": 13887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.18, \"learn_time_ms\": 8343.944, \"total_train_time_s\": 10.000147104263306}", "{\"n\": 13888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.58, \"learn_time_ms\": 8244.906, \"total_train_time_s\": 8.731436491012573}", "{\"n\": 13889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.67, \"learn_time_ms\": 8218.579, \"total_train_time_s\": 9.995679378509521}", "{\"n\": 13890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.48, \"learn_time_ms\": 8302.636, \"total_train_time_s\": 11.073539018630981}", "{\"n\": 13891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.83, \"learn_time_ms\": 8338.543, \"total_train_time_s\": 10.421038627624512}", "{\"n\": 13892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.15, \"learn_time_ms\": 8451.658, \"total_train_time_s\": 10.368754625320435}", "{\"n\": 13893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.27, \"learn_time_ms\": 8380.04, \"total_train_time_s\": 9.110153913497925}", "{\"n\": 13894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.54, \"learn_time_ms\": 8423.027, \"total_train_time_s\": 10.334137916564941}", "{\"n\": 13895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.63, \"learn_time_ms\": 8296.25, \"total_train_time_s\": 8.528071403503418}", "{\"n\": 13896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.63, \"learn_time_ms\": 8434.935, \"total_train_time_s\": 9.854034662246704}", "{\"n\": 13897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.55, \"learn_time_ms\": 8448.288, \"total_train_time_s\": 10.188922643661499}", "{\"n\": 13898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.55, \"learn_time_ms\": 8701.014, \"total_train_time_s\": 11.230711221694946}", "{\"n\": 13899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.94, \"learn_time_ms\": 8610.445, \"total_train_time_s\": 9.084605693817139}", "{\"n\": 13900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.54, \"learn_time_ms\": 8613.288, \"total_train_time_s\": 11.080078363418579}", "{\"n\": 13901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.37, \"learn_time_ms\": 8556.513, \"total_train_time_s\": 9.858928203582764}", "{\"n\": 13902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.5, \"learn_time_ms\": 8524.0, \"total_train_time_s\": 10.061269521713257}", "{\"n\": 13903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.5, \"learn_time_ms\": 8718.912, \"total_train_time_s\": 11.032376527786255}", "{\"n\": 13904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.49, \"learn_time_ms\": 8675.95, \"total_train_time_s\": 9.85771918296814}", "{\"n\": 13905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.06, \"learn_time_ms\": 8944.103, \"total_train_time_s\": 11.125548601150513}", "{\"n\": 13906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.07, \"learn_time_ms\": 8936.494, \"total_train_time_s\": 9.789999961853027}", "{\"n\": 13907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.63, \"learn_time_ms\": 8888.316, \"total_train_time_s\": 9.670619249343872}", "{\"n\": 13908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.65, \"learn_time_ms\": 8693.371, \"total_train_time_s\": 9.295311689376831}", "{\"n\": 13909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.35, \"learn_time_ms\": 8806.432, \"total_train_time_s\": 10.2429838180542}", "{\"n\": 13910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.35, \"learn_time_ms\": 8671.907, \"total_train_time_s\": 9.729957580566406}", "{\"n\": 13911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.68, \"learn_time_ms\": 8909.374, \"total_train_time_s\": 12.27341628074646}", "{\"n\": 13912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.99, \"learn_time_ms\": 8816.263, \"total_train_time_s\": 9.124810218811035}", "{\"n\": 13913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.96, \"learn_time_ms\": 8721.682, \"total_train_time_s\": 10.164342403411865}", "{\"n\": 13914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.34, \"learn_time_ms\": 8720.031, \"total_train_time_s\": 9.90238094329834}", "{\"n\": 13915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.37, \"learn_time_ms\": 8504.351, \"total_train_time_s\": 9.018062829971313}", "{\"n\": 13916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.39, \"learn_time_ms\": 8763.874, \"total_train_time_s\": 12.397145748138428}", "{\"n\": 13917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.87, \"learn_time_ms\": 8831.286, \"total_train_time_s\": 10.32760214805603}", "{\"n\": 13918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.94, \"learn_time_ms\": 8995.045, \"total_train_time_s\": 10.92867922782898}", "{\"n\": 13919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.74, \"learn_time_ms\": 8972.132, \"total_train_time_s\": 10.049540281295776}", "{\"n\": 13920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.0, \"learn_time_ms\": 9038.921, \"total_train_time_s\": 10.447953701019287}", "{\"n\": 13921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.67, \"learn_time_ms\": 8808.328, \"total_train_time_s\": 9.95886754989624}", "{\"n\": 13922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.47, \"learn_time_ms\": 8812.317, \"total_train_time_s\": 9.155217409133911}", "{\"n\": 13923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.47, \"learn_time_ms\": 8891.266, \"total_train_time_s\": 10.881140232086182}", "{\"n\": 13924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.06, \"learn_time_ms\": 8816.712, \"total_train_time_s\": 9.127184629440308}", "{\"n\": 13925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.11, \"learn_time_ms\": 8906.539, \"total_train_time_s\": 9.9178307056427}", "{\"n\": 13926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.6, \"learn_time_ms\": 8579.03, \"total_train_time_s\": 9.114856004714966}", "{\"n\": 13927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.68, \"learn_time_ms\": 8579.12, \"total_train_time_s\": 10.377998352050781}", "{\"n\": 13928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.68, \"learn_time_ms\": 8569.845, \"total_train_time_s\": 10.788007020950317}", "{\"n\": 13929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.1, \"learn_time_ms\": 8526.358, \"total_train_time_s\": 9.524739027023315}", "{\"n\": 13930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 8448.369, \"total_train_time_s\": 9.63042688369751}", "{\"n\": 13931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.15, \"learn_time_ms\": 8427.364, \"total_train_time_s\": 9.734474420547485}", "{\"n\": 13932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.45, \"learn_time_ms\": 8495.86, \"total_train_time_s\": 9.829073905944824}", "{\"n\": 13933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.71, \"learn_time_ms\": 8459.114, \"total_train_time_s\": 10.54734992980957}", "{\"n\": 13934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.81, \"learn_time_ms\": 8543.699, \"total_train_time_s\": 9.948779344558716}", "{\"n\": 13935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.81, \"learn_time_ms\": 8606.014, \"total_train_time_s\": 10.535494089126587}", "{\"n\": 13936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.44, \"learn_time_ms\": 8754.223, \"total_train_time_s\": 10.597174167633057}", "{\"n\": 13937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.72, \"learn_time_ms\": 8670.642, \"total_train_time_s\": 9.494655132293701}", "{\"n\": 13938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.66, \"learn_time_ms\": 8550.679, \"total_train_time_s\": 9.699873208999634}", "{\"n\": 13939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.82, \"learn_time_ms\": 8615.976, \"total_train_time_s\": 10.261256456375122}", "{\"n\": 13940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.82, \"learn_time_ms\": 8647.139, \"total_train_time_s\": 9.953002691268921}", "{\"n\": 13941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.02, \"learn_time_ms\": 8674.475, \"total_train_time_s\": 10.004220962524414}", "{\"n\": 13942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.34, \"learn_time_ms\": 8640.757, \"total_train_time_s\": 9.501101970672607}", "{\"n\": 13943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.69, \"learn_time_ms\": 8658.034, \"total_train_time_s\": 10.753013849258423}", "{\"n\": 13944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.7, \"learn_time_ms\": 8723.641, \"total_train_time_s\": 10.638182640075684}", "{\"n\": 13945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 8677.88, \"total_train_time_s\": 10.062490701675415}", "{\"n\": 13946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.86, \"learn_time_ms\": 8683.234, \"total_train_time_s\": 10.651862859725952}", "{\"n\": 13947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.95, \"learn_time_ms\": 8681.474, \"total_train_time_s\": 9.473987102508545}", "{\"n\": 13948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.95, \"learn_time_ms\": 8701.754, \"total_train_time_s\": 9.822941780090332}", "{\"n\": 13949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.67, \"learn_time_ms\": 8673.341, \"total_train_time_s\": 9.915570259094238}", "{\"n\": 13950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.67, \"learn_time_ms\": 8660.822, \"total_train_time_s\": 9.814561128616333}", "{\"n\": 13951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.93, \"learn_time_ms\": 8690.239, \"total_train_time_s\": 10.32660460472107}", "{\"n\": 13952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.93, \"learn_time_ms\": 8846.173, \"total_train_time_s\": 11.029135942459106}", "{\"n\": 13953, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.68, \"learn_time_ms\": 8710.026, \"total_train_time_s\": 9.331048011779785}", "{\"n\": 13954, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.3, \"learn_time_ms\": 8585.38, \"total_train_time_s\": 9.389554262161255}", "{\"n\": 13955, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.21, \"learn_time_ms\": 8736.567, \"total_train_time_s\": 11.55671238899231}", "{\"n\": 13956, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.4, \"learn_time_ms\": 8791.882, \"total_train_time_s\": 11.213898181915283}", "{\"n\": 13957, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.12, \"learn_time_ms\": 8762.601, \"total_train_time_s\": 9.18460488319397}", "{\"n\": 13958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.2, \"learn_time_ms\": 8776.96, \"total_train_time_s\": 9.950900793075562}", "{\"n\": 13959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.01, \"learn_time_ms\": 8698.71, \"total_train_time_s\": 9.18946123123169}", "{\"n\": 13960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.34, \"learn_time_ms\": 8705.656, \"total_train_time_s\": 9.920517444610596}", "{\"n\": 13961, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.34, \"learn_time_ms\": 8680.653, \"total_train_time_s\": 10.070703506469727}", "{\"n\": 13962, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.27, \"learn_time_ms\": 8617.585, \"total_train_time_s\": 10.380647897720337}", "{\"n\": 13963, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.4, \"learn_time_ms\": 8786.325, \"total_train_time_s\": 10.987398624420166}", "{\"n\": 13964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.84, \"learn_time_ms\": 8792.669, \"total_train_time_s\": 9.488985538482666}", "{\"n\": 13965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.65, \"learn_time_ms\": 8741.048, \"total_train_time_s\": 11.06355595588684}", "{\"n\": 13966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.87, \"learn_time_ms\": 8617.353, \"total_train_time_s\": 9.969218730926514}", "{\"n\": 13967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.62, \"learn_time_ms\": 8617.481, \"total_train_time_s\": 9.151771068572998}", "{\"n\": 13968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.83, \"learn_time_ms\": 8663.848, \"total_train_time_s\": 10.466868877410889}", "{\"n\": 13969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.56, \"learn_time_ms\": 8674.532, \"total_train_time_s\": 9.235208511352539}", "{\"n\": 13970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.88, \"learn_time_ms\": 8646.34, \"total_train_time_s\": 9.576042652130127}", "{\"n\": 13971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.88, \"learn_time_ms\": 8592.184, \"total_train_time_s\": 9.574085235595703}", "{\"n\": 13972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.92, \"learn_time_ms\": 8440.68, \"total_train_time_s\": 8.909038782119751}", "{\"n\": 13973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.02, \"learn_time_ms\": 8184.5, \"total_train_time_s\": 8.480035543441772}", "{\"n\": 13974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.68, \"learn_time_ms\": 8225.211, \"total_train_time_s\": 9.883559942245483}", "{\"n\": 13975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.46, \"learn_time_ms\": 8030.165, \"total_train_time_s\": 9.118126153945923}", "{\"n\": 13976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.08, \"learn_time_ms\": 8345.644, \"total_train_time_s\": 13.169095277786255}", "{\"n\": 13977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.41, \"learn_time_ms\": 8309.4, \"total_train_time_s\": 8.806076765060425}", "{\"n\": 13978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.41, \"learn_time_ms\": 8182.829, \"total_train_time_s\": 9.188199758529663}", "{\"n\": 13979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.42, \"learn_time_ms\": 8076.441, \"total_train_time_s\": 8.235299348831177}", "{\"n\": 13980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3400.93, \"learn_time_ms\": 8130.279, \"total_train_time_s\": 10.16534972190857}", "{\"n\": 13981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3400.93, \"learn_time_ms\": 8312.954, \"total_train_time_s\": 11.299656629562378}", "{\"n\": 13982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3396.94, \"learn_time_ms\": 8356.961, \"total_train_time_s\": 9.365501642227173}", "{\"n\": 13983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.26, \"learn_time_ms\": 8400.05, \"total_train_time_s\": 8.913974046707153}", "{\"n\": 13984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3392.82, \"learn_time_ms\": 8488.582, \"total_train_time_s\": 10.75478482246399}", "{\"n\": 13985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.02, \"learn_time_ms\": 8546.442, \"total_train_time_s\": 9.69498324394226}", "{\"n\": 13986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.05, \"learn_time_ms\": 8274.849, \"total_train_time_s\": 10.368850469589233}", "{\"n\": 13987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.48, \"learn_time_ms\": 8530.272, \"total_train_time_s\": 11.388416767120361}", "{\"n\": 13988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.17, \"learn_time_ms\": 8572.373, \"total_train_time_s\": 9.610992908477783}", "{\"n\": 13989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.03, \"learn_time_ms\": 8574.457, \"total_train_time_s\": 8.231120109558105}", "{\"n\": 13990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.39, \"learn_time_ms\": 8497.69, \"total_train_time_s\": 9.399760484695435}", "{\"n\": 13991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.12, \"learn_time_ms\": 8494.48, \"total_train_time_s\": 11.329581260681152}", "{\"n\": 13992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.36, \"learn_time_ms\": 8547.613, \"total_train_time_s\": 9.921688556671143}", "{\"n\": 13993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.03, \"learn_time_ms\": 8714.447, \"total_train_time_s\": 10.61279845237732}", "{\"n\": 13994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 8679.028, \"total_train_time_s\": 10.408753633499146}", "{\"n\": 13995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.74, \"learn_time_ms\": 8711.192, \"total_train_time_s\": 10.020923376083374}", "{\"n\": 13996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.46, \"learn_time_ms\": 8610.24, \"total_train_time_s\": 9.43650197982788}", "{\"n\": 13997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.91, \"learn_time_ms\": 8512.207, \"total_train_time_s\": 10.393855333328247}", "{\"n\": 13998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.91, \"learn_time_ms\": 8453.786, \"total_train_time_s\": 8.984273910522461}", "{\"n\": 13999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.95, \"learn_time_ms\": 8637.039, \"total_train_time_s\": 10.102102518081665}", "{\"n\": 14000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.53, \"learn_time_ms\": 8735.161, \"total_train_time_s\": 10.389783143997192}", "{\"n\": 14001, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.53, \"learn_time_ms\": 8553.791, \"total_train_time_s\": 9.49366307258606}", "{\"n\": 14002, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.34, \"learn_time_ms\": 8551.094, \"total_train_time_s\": 9.829906463623047}", "{\"n\": 14003, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.47, \"learn_time_ms\": 8594.558, \"total_train_time_s\": 10.95264220237732}", "{\"n\": 14004, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3355.16, \"learn_time_ms\": 8390.977, \"total_train_time_s\": 8.357844829559326}", "{\"n\": 14005, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.78, \"learn_time_ms\": 8404.862, \"total_train_time_s\": 10.172067165374756}", "{\"n\": 14006, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3361.71, \"learn_time_ms\": 8586.044, \"total_train_time_s\": 11.205506563186646}", "{\"n\": 14007, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 8452.338, \"total_train_time_s\": 9.088261604309082}", "{\"n\": 14008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 8562.814, \"total_train_time_s\": 10.120294332504272}", "{\"n\": 14009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.37, \"learn_time_ms\": 8515.955, \"total_train_time_s\": 9.553303718566895}", "{\"n\": 14010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.37, \"learn_time_ms\": 8520.561, \"total_train_time_s\": 10.354188442230225}", "{\"n\": 14011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.23, \"learn_time_ms\": 8635.305, \"total_train_time_s\": 10.68627119064331}", "{\"n\": 14012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.23, \"learn_time_ms\": 8640.476, \"total_train_time_s\": 10.029695987701416}", "{\"n\": 14013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.45, \"learn_time_ms\": 8611.982, \"total_train_time_s\": 10.698456048965454}", "{\"n\": 14014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 8752.647, \"total_train_time_s\": 9.80647587776184}", "{\"n\": 14015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 8588.359, \"total_train_time_s\": 8.506138801574707}", "{\"n\": 14016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.02, \"learn_time_ms\": 8503.735, \"total_train_time_s\": 10.381411790847778}", "{\"n\": 14017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.67, \"learn_time_ms\": 8646.407, \"total_train_time_s\": 10.514126777648926}", "{\"n\": 14018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.67, \"learn_time_ms\": 8537.688, \"total_train_time_s\": 9.019382953643799}", "{\"n\": 14019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.12, \"learn_time_ms\": 8562.377, \"total_train_time_s\": 9.809089422225952}", "{\"n\": 14020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.12, \"learn_time_ms\": 8570.169, \"total_train_time_s\": 10.463577032089233}", "{\"n\": 14021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.8, \"learn_time_ms\": 8432.094, \"total_train_time_s\": 9.27751636505127}", "{\"n\": 14022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.8, \"learn_time_ms\": 8540.82, \"total_train_time_s\": 10.966806411743164}", "{\"n\": 14023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.22, \"learn_time_ms\": 8540.041, \"total_train_time_s\": 10.716987371444702}", "{\"n\": 14024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.19, \"learn_time_ms\": 8586.657, \"total_train_time_s\": 10.28005599975586}", "{\"n\": 14025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.19, \"learn_time_ms\": 8791.683, \"total_train_time_s\": 10.572144985198975}", "{\"n\": 14026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.08, \"learn_time_ms\": 8669.144, \"total_train_time_s\": 9.153107404708862}", "{\"n\": 14027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.87, \"learn_time_ms\": 8430.812, \"total_train_time_s\": 8.100510120391846}", "{\"n\": 14028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.52, \"learn_time_ms\": 8486.239, \"total_train_time_s\": 9.574496030807495}", "{\"n\": 14029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.52, \"learn_time_ms\": 8563.803, \"total_train_time_s\": 10.578269720077515}", "{\"n\": 14030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.11, \"learn_time_ms\": 8463.404, \"total_train_time_s\": 9.500114440917969}", "{\"n\": 14031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.17, \"learn_time_ms\": 8607.523, \"total_train_time_s\": 10.703133821487427}", "{\"n\": 14032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.17, \"learn_time_ms\": 8344.663, \"total_train_time_s\": 8.353003978729248}", "{\"n\": 14033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.77, \"learn_time_ms\": 8248.686, \"total_train_time_s\": 9.793975353240967}", "{\"n\": 14034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 8283.462, \"total_train_time_s\": 10.608805894851685}", "{\"n\": 14035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 8229.508, \"total_train_time_s\": 10.024118185043335}", "{\"n\": 14036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 8334.077, \"total_train_time_s\": 10.193670988082886}", "{\"n\": 14037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.56, \"learn_time_ms\": 8557.588, \"total_train_time_s\": 10.334675788879395}", "{\"n\": 14038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.58, \"learn_time_ms\": 8567.283, \"total_train_time_s\": 9.696747303009033}", "{\"n\": 14039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.58, \"learn_time_ms\": 8557.651, \"total_train_time_s\": 10.486377477645874}", "{\"n\": 14040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.23, \"learn_time_ms\": 8611.852, \"total_train_time_s\": 10.041218042373657}", "{\"n\": 14041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3345.12, \"learn_time_ms\": 8465.343, \"total_train_time_s\": 9.238161563873291}", "{\"n\": 14042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3344.48, \"learn_time_ms\": 8827.874, \"total_train_time_s\": 11.993301391601562}", "{\"n\": 14043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3348.12, \"learn_time_ms\": 8868.299, \"total_train_time_s\": 10.16342568397522}", "{\"n\": 14044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3350.13, \"learn_time_ms\": 8901.122, \"total_train_time_s\": 10.941200971603394}", "{\"n\": 14045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.89, \"learn_time_ms\": 8980.079, \"total_train_time_s\": 10.826257705688477}", "{\"n\": 14046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.89, \"learn_time_ms\": 8823.415, \"total_train_time_s\": 8.575917720794678}", "{\"n\": 14047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.65, \"learn_time_ms\": 8819.59, \"total_train_time_s\": 10.272720098495483}", "{\"n\": 14048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.66, \"learn_time_ms\": 8757.127, \"total_train_time_s\": 9.065255403518677}", "{\"n\": 14049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.66, \"learn_time_ms\": 8878.458, \"total_train_time_s\": 11.684497356414795}", "{\"n\": 14050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.28, \"learn_time_ms\": 8890.121, \"total_train_time_s\": 10.153372526168823}", "{\"n\": 14051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.5, \"learn_time_ms\": 8918.185, \"total_train_time_s\": 9.513134002685547}", "{\"n\": 14052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.45, \"learn_time_ms\": 8692.328, \"total_train_time_s\": 9.773257493972778}", "{\"n\": 14053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.45, \"learn_time_ms\": 8938.745, \"total_train_time_s\": 12.611979484558105}", "{\"n\": 14054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.39, \"learn_time_ms\": 8780.546, \"total_train_time_s\": 9.379456043243408}", "{\"n\": 14055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.73, \"learn_time_ms\": 8591.256, \"total_train_time_s\": 8.888719320297241}", "{\"n\": 14056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.73, \"learn_time_ms\": 8649.193, \"total_train_time_s\": 9.177319049835205}", "{\"n\": 14057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.74, \"learn_time_ms\": 8593.679, \"total_train_time_s\": 9.822282552719116}", "{\"n\": 14058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.87, \"learn_time_ms\": 8521.615, \"total_train_time_s\": 8.357671022415161}", "{\"n\": 14059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.65, \"learn_time_ms\": 8390.234, \"total_train_time_s\": 10.379412412643433}", "{\"n\": 14060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.65, \"learn_time_ms\": 8330.463, \"total_train_time_s\": 9.574566841125488}", "{\"n\": 14061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.62, \"learn_time_ms\": 8425.722, \"total_train_time_s\": 10.533022165298462}", "{\"n\": 14062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.1, \"learn_time_ms\": 8342.095, \"total_train_time_s\": 8.885066747665405}", "{\"n\": 14063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.1, \"learn_time_ms\": 8191.483, \"total_train_time_s\": 11.144571542739868}", "{\"n\": 14064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.17, \"learn_time_ms\": 8331.336, \"total_train_time_s\": 10.768613815307617}", "{\"n\": 14065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.13, \"learn_time_ms\": 8461.746, \"total_train_time_s\": 10.224861145019531}", "{\"n\": 14066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.13, \"learn_time_ms\": 8509.711, \"total_train_time_s\": 9.664913654327393}", "{\"n\": 14067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.95, \"learn_time_ms\": 8604.093, \"total_train_time_s\": 10.649063348770142}", "{\"n\": 14068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.92, \"learn_time_ms\": 8778.934, \"total_train_time_s\": 10.050889253616333}", "{\"n\": 14069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.92, \"learn_time_ms\": 8771.495, \"total_train_time_s\": 10.328762531280518}", "{\"n\": 14070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.33, \"learn_time_ms\": 8781.245, \"total_train_time_s\": 9.641514778137207}", "{\"n\": 14071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.19, \"learn_time_ms\": 8832.644, \"total_train_time_s\": 10.97969102859497}", "{\"n\": 14072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.36, \"learn_time_ms\": 9039.771, \"total_train_time_s\": 10.91737985610962}", "{\"n\": 14073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.06, \"learn_time_ms\": 8883.364, \"total_train_time_s\": 9.517480373382568}", "{\"n\": 14074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.46, \"learn_time_ms\": 8859.334, \"total_train_time_s\": 10.527241945266724}", "{\"n\": 14075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.23, \"learn_time_ms\": 8740.566, \"total_train_time_s\": 9.068000078201294}", "{\"n\": 14076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.23, \"learn_time_ms\": 8852.417, \"total_train_time_s\": 10.798775434494019}", "{\"n\": 14077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.41, \"learn_time_ms\": 8696.252, \"total_train_time_s\": 9.123276710510254}", "{\"n\": 14078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.19, \"learn_time_ms\": 8725.986, \"total_train_time_s\": 10.42118239402771}", "{\"n\": 14079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.19, \"learn_time_ms\": 8652.953, \"total_train_time_s\": 9.616845607757568}", "{\"n\": 14080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.91, \"learn_time_ms\": 8823.249, \"total_train_time_s\": 11.36086392402649}", "{\"n\": 14081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.16, \"learn_time_ms\": 8693.369, \"total_train_time_s\": 9.669672012329102}", "{\"n\": 14082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.16, \"learn_time_ms\": 8606.109, \"total_train_time_s\": 10.071532249450684}", "{\"n\": 14083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.32, \"learn_time_ms\": 8707.065, \"total_train_time_s\": 10.573732137680054}", "{\"n\": 14084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.96, \"learn_time_ms\": 8619.763, \"total_train_time_s\": 9.660717487335205}", "{\"n\": 14085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.93, \"learn_time_ms\": 8641.438, \"total_train_time_s\": 9.24384093284607}", "{\"n\": 14086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.93, \"learn_time_ms\": 8505.816, \"total_train_time_s\": 9.426354885101318}", "{\"n\": 14087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.36, \"learn_time_ms\": 8784.006, \"total_train_time_s\": 11.9284987449646}", "{\"n\": 14088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.81, \"learn_time_ms\": 8737.79, \"total_train_time_s\": 9.87932562828064}", "{\"n\": 14089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.81, \"learn_time_ms\": 8704.042, \"total_train_time_s\": 9.289600849151611}", "{\"n\": 14090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.22, \"learn_time_ms\": 8640.84, \"total_train_time_s\": 10.787946939468384}", "{\"n\": 14091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.72, \"learn_time_ms\": 8638.527, \"total_train_time_s\": 9.657127857208252}", "{\"n\": 14092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.22, \"learn_time_ms\": 8551.281, \"total_train_time_s\": 9.19985055923462}", "{\"n\": 14093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.0, \"learn_time_ms\": 8455.128, \"total_train_time_s\": 9.655561923980713}", "{\"n\": 14094, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.27, \"learn_time_ms\": 8518.545, \"total_train_time_s\": 10.2908616065979}", "{\"n\": 14095, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.19, \"learn_time_ms\": 8559.933, \"total_train_time_s\": 9.658521175384521}", "{\"n\": 14096, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.37, \"learn_time_ms\": 8693.948, \"total_train_time_s\": 10.773317337036133}", "{\"n\": 14097, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.82, \"learn_time_ms\": 8628.824, \"total_train_time_s\": 11.26548147201538}", "{\"n\": 14098, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.08, \"learn_time_ms\": 8586.009, \"total_train_time_s\": 9.478466033935547}", "{\"n\": 14099, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.34, \"learn_time_ms\": 8705.642, \"total_train_time_s\": 10.424343347549438}", "{\"n\": 14100, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.37, \"learn_time_ms\": 8540.857, \"total_train_time_s\": 9.07375454902649}", "{\"n\": 14101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.48, \"learn_time_ms\": 8575.143, \"total_train_time_s\": 9.950745820999146}", "{\"n\": 14102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.48, \"learn_time_ms\": 8611.018, \"total_train_time_s\": 9.567255020141602}", "{\"n\": 14103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.41, \"learn_time_ms\": 8629.155, \"total_train_time_s\": 9.822252750396729}", "{\"n\": 14104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.25, \"learn_time_ms\": 8519.456, \"total_train_time_s\": 9.165918588638306}", "{\"n\": 14105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.25, \"learn_time_ms\": 8629.007, \"total_train_time_s\": 10.787513732910156}", "{\"n\": 14106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.76, \"learn_time_ms\": 8458.965, \"total_train_time_s\": 9.125115156173706}", "{\"n\": 14107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.02, \"learn_time_ms\": 8344.515, \"total_train_time_s\": 10.14417290687561}", "{\"n\": 14108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.12, \"learn_time_ms\": 8474.455, \"total_train_time_s\": 10.806371927261353}", "{\"n\": 14109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.12, \"learn_time_ms\": 8326.74, \"total_train_time_s\": 8.974536657333374}", "{\"n\": 14110, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.57, \"learn_time_ms\": 8450.581, \"total_train_time_s\": 10.338665962219238}", "{\"n\": 14111, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.43, \"learn_time_ms\": 8439.505, \"total_train_time_s\": 9.925617456436157}", "{\"n\": 14112, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.43, \"learn_time_ms\": 8570.79, \"total_train_time_s\": 10.92436933517456}", "{\"n\": 14113, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.13, \"learn_time_ms\": 8565.589, \"total_train_time_s\": 9.779789209365845}", "{\"n\": 14114, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.13, \"learn_time_ms\": 8605.324, \"total_train_time_s\": 9.524675846099854}", "{\"n\": 14115, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.71, \"learn_time_ms\": 8555.367, \"total_train_time_s\": 10.294342279434204}", "{\"n\": 14116, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.64, \"learn_time_ms\": 8669.516, \"total_train_time_s\": 10.225609302520752}", "{\"n\": 14117, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.14, \"learn_time_ms\": 8670.634, \"total_train_time_s\": 10.155893087387085}", "{\"n\": 14118, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.34, \"learn_time_ms\": 8403.597, \"total_train_time_s\": 8.096800565719604}", "{\"n\": 14119, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.34, \"learn_time_ms\": 8545.382, \"total_train_time_s\": 10.393746614456177}", "{\"n\": 14120, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.3, \"learn_time_ms\": 8451.246, \"total_train_time_s\": 9.363131523132324}", "{\"n\": 14121, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.03, \"learn_time_ms\": 8393.957, \"total_train_time_s\": 9.279729127883911}", "{\"n\": 14122, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.33, \"learn_time_ms\": 8336.953, \"total_train_time_s\": 10.32997727394104}", "{\"n\": 14123, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.55, \"learn_time_ms\": 8351.743, \"total_train_time_s\": 9.882413864135742}", "{\"n\": 14124, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.75, \"learn_time_ms\": 8274.834, \"total_train_time_s\": 8.81008505821228}", "{\"n\": 14125, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.61, \"learn_time_ms\": 8193.415, \"total_train_time_s\": 9.419453859329224}", "{\"n\": 14126, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.74, \"learn_time_ms\": 8062.535, \"total_train_time_s\": 8.896541118621826}", "{\"n\": 14127, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.44, \"learn_time_ms\": 7981.475, \"total_train_time_s\": 9.308674097061157}", "{\"n\": 14128, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.44, \"learn_time_ms\": 8112.505, \"total_train_time_s\": 9.421589374542236}", "{\"n\": 14129, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.49, \"learn_time_ms\": 8077.269, \"total_train_time_s\": 10.073737382888794}", "{\"n\": 14130, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.82, \"learn_time_ms\": 8142.468, \"total_train_time_s\": 9.971666812896729}", "{\"n\": 14131, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.94, \"learn_time_ms\": 8137.691, \"total_train_time_s\": 9.276421546936035}", "{\"n\": 14132, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.87, \"learn_time_ms\": 8160.674, \"total_train_time_s\": 10.544206142425537}", "{\"n\": 14133, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.87, \"learn_time_ms\": 8238.309, \"total_train_time_s\": 10.671985149383545}", "{\"n\": 14134, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.29, \"learn_time_ms\": 8409.705, \"total_train_time_s\": 10.509076118469238}", "{\"n\": 14135, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.12, \"learn_time_ms\": 8376.115, \"total_train_time_s\": 9.129193782806396}", "{\"n\": 14136, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 8493.919, \"total_train_time_s\": 10.073596477508545}", "{\"n\": 14137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 8490.561, \"total_train_time_s\": 9.287760019302368}", "{\"n\": 14138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.06, \"learn_time_ms\": 8493.319, \"total_train_time_s\": 9.50755262374878}", "{\"n\": 14139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.06, \"learn_time_ms\": 8512.289, \"total_train_time_s\": 10.217807531356812}", "{\"n\": 14140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.83, \"learn_time_ms\": 8405.091, \"total_train_time_s\": 8.940846920013428}", "{\"n\": 14141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.52, \"learn_time_ms\": 8429.575, \"total_train_time_s\": 9.49225664138794}", "{\"n\": 14142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.83, \"learn_time_ms\": 8402.988, \"total_train_time_s\": 10.259855508804321}", "{\"n\": 14143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.83, \"learn_time_ms\": 8253.165, \"total_train_time_s\": 9.166183948516846}", "{\"n\": 14144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.83, \"learn_time_ms\": 8161.827, \"total_train_time_s\": 9.577128648757935}", "{\"n\": 14145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.08, \"learn_time_ms\": 8305.799, \"total_train_time_s\": 10.511279821395874}", "{\"n\": 14146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.83, \"learn_time_ms\": 8420.219, \"total_train_time_s\": 11.253852844238281}", "{\"n\": 14147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.83, \"learn_time_ms\": 8515.148, \"total_train_time_s\": 10.245661497116089}", "{\"n\": 14148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.84, \"learn_time_ms\": 8503.471, \"total_train_time_s\": 9.313495397567749}", "{\"n\": 14149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.36, \"learn_time_ms\": 8445.758, \"total_train_time_s\": 9.656612873077393}", "{\"n\": 14150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.36, \"learn_time_ms\": 8576.843, \"total_train_time_s\": 10.24866008758545}", "{\"n\": 14151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.36, \"learn_time_ms\": 8622.575, \"total_train_time_s\": 9.968698024749756}", "{\"n\": 14152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.5, \"learn_time_ms\": 8523.73, \"total_train_time_s\": 9.267162799835205}", "{\"n\": 14153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.5, \"learn_time_ms\": 8684.486, \"total_train_time_s\": 10.734896659851074}", "{\"n\": 14154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.5, \"learn_time_ms\": 8712.329, \"total_train_time_s\": 9.858944177627563}", "{\"n\": 14155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.44, \"learn_time_ms\": 8674.252, \"total_train_time_s\": 10.150634288787842}", "{\"n\": 14156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.62, \"learn_time_ms\": 8584.191, \"total_train_time_s\": 10.328139066696167}", "{\"n\": 14157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.62, \"learn_time_ms\": 8477.287, \"total_train_time_s\": 9.157521486282349}", "{\"n\": 14158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.75, \"learn_time_ms\": 8609.268, \"total_train_time_s\": 10.639734268188477}", "{\"n\": 14159, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.33, \"learn_time_ms\": 8689.344, \"total_train_time_s\": 10.505069494247437}", "{\"n\": 14160, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.33, \"learn_time_ms\": 8634.341, \"total_train_time_s\": 9.674498796463013}", "{\"n\": 14161, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.33, \"learn_time_ms\": 8644.475, \"total_train_time_s\": 10.071627616882324}", "{\"n\": 14162, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.13, \"learn_time_ms\": 8813.098, \"total_train_time_s\": 10.995515584945679}", "{\"n\": 14163, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.6, \"learn_time_ms\": 8691.786, \"total_train_time_s\": 9.572941780090332}", "{\"n\": 14164, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.6, \"learn_time_ms\": 8725.89, \"total_train_time_s\": 10.212493181228638}", "{\"n\": 14165, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.43, \"learn_time_ms\": 8527.083, \"total_train_time_s\": 8.184436321258545}", "{\"n\": 14166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.19, \"learn_time_ms\": 8459.651, \"total_train_time_s\": 9.636523246765137}", "{\"n\": 14167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.19, \"learn_time_ms\": 8505.667, \"total_train_time_s\": 9.595824718475342}", "{\"n\": 14168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.0, \"learn_time_ms\": 8556.461, \"total_train_time_s\": 11.17091155052185}", "{\"n\": 14169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.9, \"learn_time_ms\": 8449.516, \"total_train_time_s\": 9.41053819656372}", "{\"n\": 14170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.16, \"learn_time_ms\": 8537.713, \"total_train_time_s\": 10.625472784042358}", "{\"n\": 14171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.16, \"learn_time_ms\": 8504.146, \"total_train_time_s\": 9.724356651306152}", "{\"n\": 14172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.59, \"learn_time_ms\": 8533.903, \"total_train_time_s\": 11.283507823944092}", "{\"n\": 14173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.9, \"learn_time_ms\": 8597.646, \"total_train_time_s\": 10.206329345703125}", "{\"n\": 14174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.39, \"learn_time_ms\": 8559.713, \"total_train_time_s\": 9.83728837966919}", "{\"n\": 14175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.1, \"learn_time_ms\": 8843.07, \"total_train_time_s\": 11.050768613815308}", "{\"n\": 14176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.49, \"learn_time_ms\": 8737.376, \"total_train_time_s\": 8.631374597549438}", "{\"n\": 14177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.39, \"learn_time_ms\": 8742.991, \"total_train_time_s\": 9.693882703781128}", "{\"n\": 14178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.62, \"learn_time_ms\": 8570.62, \"total_train_time_s\": 9.405373334884644}", "{\"n\": 14179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.6, \"learn_time_ms\": 8520.708, \"total_train_time_s\": 8.86897873878479}", "{\"n\": 14180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.66, \"learn_time_ms\": 8459.113, \"total_train_time_s\": 10.01080846786499}", "{\"n\": 14181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.22, \"learn_time_ms\": 8504.147, \"total_train_time_s\": 10.203084945678711}", "{\"n\": 14182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.57, \"learn_time_ms\": 8290.466, \"total_train_time_s\": 9.136170864105225}", "{\"n\": 14183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.63, \"learn_time_ms\": 8304.596, \"total_train_time_s\": 10.34120512008667}", "{\"n\": 14184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.84, \"learn_time_ms\": 8381.617, \"total_train_time_s\": 10.676046371459961}", "{\"n\": 14185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.95, \"learn_time_ms\": 8335.517, \"total_train_time_s\": 10.50672960281372}", "{\"n\": 14186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.67, \"learn_time_ms\": 8276.101, \"total_train_time_s\": 8.013159275054932}", "{\"n\": 14187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.22, \"learn_time_ms\": 8405.708, \"total_train_time_s\": 11.00696873664856}", "{\"n\": 14188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.77, \"learn_time_ms\": 8438.994, \"total_train_time_s\": 9.8065824508667}", "{\"n\": 14189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.77, \"learn_time_ms\": 8499.765, \"total_train_time_s\": 9.53230905532837}", "{\"n\": 14190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.41, \"learn_time_ms\": 8488.709, \"total_train_time_s\": 9.83799433708191}", "{\"n\": 14191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.93, \"learn_time_ms\": 8480.832, \"total_train_time_s\": 10.114208936691284}", "{\"n\": 14192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.93, \"learn_time_ms\": 8715.719, \"total_train_time_s\": 11.500004529953003}", "{\"n\": 14193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.5, \"learn_time_ms\": 8679.239, \"total_train_time_s\": 9.969607591629028}", "{\"n\": 14194, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.9, \"learn_time_ms\": 8705.92, \"total_train_time_s\": 10.846370458602905}", "{\"n\": 14195, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.11, \"learn_time_ms\": 8647.709, \"total_train_time_s\": 9.994831800460815}", "{\"n\": 14196, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 8777.566, \"total_train_time_s\": 9.362189531326294}", "{\"n\": 14197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.11, \"learn_time_ms\": 8804.528, \"total_train_time_s\": 11.242042541503906}", "{\"n\": 14198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.98, \"learn_time_ms\": 8812.666, \"total_train_time_s\": 9.8329176902771}", "{\"n\": 14199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.01, \"learn_time_ms\": 8875.283, \"total_train_time_s\": 10.13693118095398}", "{\"n\": 14200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.34, \"learn_time_ms\": 8859.025, \"total_train_time_s\": 9.704411029815674}", "{\"n\": 14201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.11, \"learn_time_ms\": 8712.543, \"total_train_time_s\": 8.639196157455444}", "{\"n\": 14202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.34, \"learn_time_ms\": 8597.115, \"total_train_time_s\": 10.32961106300354}", "{\"n\": 14203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.34, \"learn_time_ms\": 8623.202, \"total_train_time_s\": 10.229788780212402}", "{\"n\": 14204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.56, \"learn_time_ms\": 8423.231, \"total_train_time_s\": 8.876299619674683}", "{\"n\": 14205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.15, \"learn_time_ms\": 8374.287, \"total_train_time_s\": 9.4534273147583}", "{\"n\": 14206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.62, \"learn_time_ms\": 8340.988, \"total_train_time_s\": 8.958407878875732}", "{\"n\": 14207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.84, \"learn_time_ms\": 8363.791, \"total_train_time_s\": 11.453611373901367}", "{\"n\": 14208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.93, \"learn_time_ms\": 8321.588, \"total_train_time_s\": 9.444437265396118}", "{\"n\": 14209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.61, \"learn_time_ms\": 8310.655, \"total_train_time_s\": 9.953088998794556}", "{\"n\": 14210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.61, \"learn_time_ms\": 8324.441, \"total_train_time_s\": 9.82313847541809}", "{\"n\": 14211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.08, \"learn_time_ms\": 8457.023, \"total_train_time_s\": 9.954404830932617}", "{\"n\": 14212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.87, \"learn_time_ms\": 8451.606, \"total_train_time_s\": 10.282172441482544}", "{\"n\": 14213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.89, \"learn_time_ms\": 8477.955, \"total_train_time_s\": 10.543626308441162}", "{\"n\": 14214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.84, \"learn_time_ms\": 8661.178, \"total_train_time_s\": 10.688881397247314}", "{\"n\": 14215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.84, \"learn_time_ms\": 8881.027, \"total_train_time_s\": 11.64075779914856}", "{\"n\": 14216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.62, \"learn_time_ms\": 8959.674, \"total_train_time_s\": 9.746912956237793}", "{\"n\": 14217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.51, \"learn_time_ms\": 8787.792, \"total_train_time_s\": 9.743698120117188}", "{\"n\": 14218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.56, \"learn_time_ms\": 8931.34, \"total_train_time_s\": 10.880993366241455}", "{\"n\": 14219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.0, \"learn_time_ms\": 9001.786, \"total_train_time_s\": 10.70870327949524}", "{\"n\": 14220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.0, \"learn_time_ms\": 9031.377, \"total_train_time_s\": 10.110075950622559}", "{\"n\": 14221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.28, \"learn_time_ms\": 9163.798, \"total_train_time_s\": 11.313709259033203}", "{\"n\": 14222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.28, \"learn_time_ms\": 9116.335, \"total_train_time_s\": 9.872066497802734}", "{\"n\": 14223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.78, \"learn_time_ms\": 8952.402, \"total_train_time_s\": 8.866657495498657}", "{\"n\": 14224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.17, \"learn_time_ms\": 8741.091, \"total_train_time_s\": 8.632583141326904}", "{\"n\": 14225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.53, \"learn_time_ms\": 8588.532, \"total_train_time_s\": 10.128078937530518}", "{\"n\": 14226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.53, \"learn_time_ms\": 8576.835, \"total_train_time_s\": 9.579366207122803}", "{\"n\": 14227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.37, \"learn_time_ms\": 8590.935, \"total_train_time_s\": 9.89716362953186}", "{\"n\": 14228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.84, \"learn_time_ms\": 8406.022, \"total_train_time_s\": 9.02247667312622}", "{\"n\": 14229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.84, \"learn_time_ms\": 8405.305, \"total_train_time_s\": 10.694740295410156}", "{\"n\": 14230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.61, \"learn_time_ms\": 8465.527, \"total_train_time_s\": 10.716769456863403}", "{\"n\": 14231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.37, \"learn_time_ms\": 8268.504, \"total_train_time_s\": 9.325162172317505}", "{\"n\": 14232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.37, \"learn_time_ms\": 8324.612, \"total_train_time_s\": 10.36157512664795}", "{\"n\": 14233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.26, \"learn_time_ms\": 8419.217, \"total_train_time_s\": 9.813117980957031}", "{\"n\": 14234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.55, \"learn_time_ms\": 8484.062, \"total_train_time_s\": 9.21977686882019}", "{\"n\": 14235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.55, \"learn_time_ms\": 8356.003, \"total_train_time_s\": 8.893993377685547}", "{\"n\": 14236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.55, \"learn_time_ms\": 8294.55, \"total_train_time_s\": 9.023404121398926}", "{\"n\": 14237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 8210.514, \"total_train_time_s\": 9.061042070388794}", "{\"n\": 14238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.41, \"learn_time_ms\": 8395.564, \"total_train_time_s\": 10.91304349899292}", "{\"n\": 14239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.41, \"learn_time_ms\": 8408.333, \"total_train_time_s\": 10.815098762512207}", "{\"n\": 14240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.95, \"learn_time_ms\": 8346.499, \"total_train_time_s\": 10.133249044418335}", "{\"n\": 14241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 8432.123, \"total_train_time_s\": 10.224982738494873}", "{\"n\": 14242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 8310.606, \"total_train_time_s\": 9.129713296890259}", "{\"n\": 14243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 8229.119, \"total_train_time_s\": 8.943283796310425}", "{\"n\": 14244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.39, \"learn_time_ms\": 8373.517, \"total_train_time_s\": 10.71010136604309}", "{\"n\": 14245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.2, \"learn_time_ms\": 8518.682, \"total_train_time_s\": 10.338857173919678}", "{\"n\": 14246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.2, \"learn_time_ms\": 8776.471, \"total_train_time_s\": 11.625994682312012}", "{\"n\": 14247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.33, \"learn_time_ms\": 9066.149, \"total_train_time_s\": 11.998990535736084}", "{\"n\": 14248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.12, \"learn_time_ms\": 8907.075, \"total_train_time_s\": 9.290534019470215}", "{\"n\": 14249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.29, \"learn_time_ms\": 8909.478, \"total_train_time_s\": 10.868035078048706}", "{\"n\": 14250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.51, \"learn_time_ms\": 8933.528, \"total_train_time_s\": 10.338385820388794}", "{\"n\": 14251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.62, \"learn_time_ms\": 8797.182, \"total_train_time_s\": 8.799505233764648}", "{\"n\": 14252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.08, \"learn_time_ms\": 8974.851, \"total_train_time_s\": 10.951245546340942}", "{\"n\": 14253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.12, \"learn_time_ms\": 8961.192, \"total_train_time_s\": 8.869692087173462}", "{\"n\": 14254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.55, \"learn_time_ms\": 8938.708, \"total_train_time_s\": 10.471982479095459}", "{\"n\": 14255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.55, \"learn_time_ms\": 8942.718, \"total_train_time_s\": 10.35222840309143}", "{\"n\": 14256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.55, \"learn_time_ms\": 8803.542, \"total_train_time_s\": 10.198645114898682}", "{\"n\": 14257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.59, \"learn_time_ms\": 8527.736, \"total_train_time_s\": 9.157807350158691}", "{\"n\": 14258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8420.496, \"total_train_time_s\": 8.207188367843628}", "{\"n\": 14259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.28, \"learn_time_ms\": 8355.392, \"total_train_time_s\": 10.1791832447052}", "{\"n\": 14260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.81, \"learn_time_ms\": 8294.286, \"total_train_time_s\": 9.710064888000488}", "{\"n\": 14261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.83, \"learn_time_ms\": 8454.234, \"total_train_time_s\": 10.404232740402222}", "{\"n\": 14262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.83, \"learn_time_ms\": 8421.4, \"total_train_time_s\": 10.590311050415039}", "{\"n\": 14263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.62, \"learn_time_ms\": 8546.832, \"total_train_time_s\": 10.088488578796387}", "{\"n\": 14264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.44, \"learn_time_ms\": 8599.519, \"total_train_time_s\": 10.967346429824829}", "{\"n\": 14265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.52, \"learn_time_ms\": 8539.244, \"total_train_time_s\": 9.742910623550415}", "{\"n\": 14266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.2, \"learn_time_ms\": 8594.072, \"total_train_time_s\": 10.783584117889404}", "{\"n\": 14267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.26, \"learn_time_ms\": 8630.501, \"total_train_time_s\": 9.56985068321228}", "{\"n\": 14268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.77, \"learn_time_ms\": 8846.51, \"total_train_time_s\": 10.379339933395386}", "{\"n\": 14269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.77, \"learn_time_ms\": 8830.802, \"total_train_time_s\": 10.05500841140747}", "{\"n\": 14270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.81, \"learn_time_ms\": 8750.036, \"total_train_time_s\": 8.9418785572052}", "{\"n\": 14271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 9051.365, \"total_train_time_s\": 13.456115007400513}", "{\"n\": 14272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.32, \"learn_time_ms\": 8910.588, \"total_train_time_s\": 9.249643802642822}", "{\"n\": 14273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.38, \"learn_time_ms\": 9006.998, \"total_train_time_s\": 11.052217245101929}", "{\"n\": 14274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.28, \"learn_time_ms\": 9026.483, \"total_train_time_s\": 11.239604711532593}", "{\"n\": 14275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.85, \"learn_time_ms\": 9074.52, \"total_train_time_s\": 10.260694980621338}", "{\"n\": 14276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.95, \"learn_time_ms\": 9021.637, \"total_train_time_s\": 10.209360122680664}", "{\"n\": 14277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.23, \"learn_time_ms\": 8952.518, \"total_train_time_s\": 8.853323459625244}", "{\"n\": 14278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.74, \"learn_time_ms\": 8892.518, \"total_train_time_s\": 9.789360046386719}", "{\"n\": 14279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.29, \"learn_time_ms\": 8849.552, \"total_train_time_s\": 9.645115375518799}", "{\"n\": 14280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.06, \"learn_time_ms\": 8867.084, \"total_train_time_s\": 9.15766453742981}", "{\"n\": 14281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.06, \"learn_time_ms\": 8504.059, \"total_train_time_s\": 9.785983324050903}", "{\"n\": 14282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.26, \"learn_time_ms\": 8462.169, \"total_train_time_s\": 8.739194631576538}", "{\"n\": 14283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.67, \"learn_time_ms\": 8356.619, \"total_train_time_s\": 10.001857042312622}", "{\"n\": 14284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.78, \"learn_time_ms\": 8275.308, \"total_train_time_s\": 10.3742995262146}", "{\"n\": 14285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.78, \"learn_time_ms\": 8263.495, \"total_train_time_s\": 10.164705276489258}", "{\"n\": 14286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.86, \"learn_time_ms\": 8153.185, \"total_train_time_s\": 9.13027048110962}", "{\"n\": 14287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.05, \"learn_time_ms\": 8347.715, \"total_train_time_s\": 10.781790018081665}", "{\"n\": 14288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.84, \"learn_time_ms\": 8359.869, \"total_train_time_s\": 9.882734298706055}", "{\"n\": 14289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.47, \"learn_time_ms\": 8513.868, \"total_train_time_s\": 11.132744312286377}", "{\"n\": 14290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.49, \"learn_time_ms\": 8571.825, \"total_train_time_s\": 9.697685956954956}", "{\"n\": 14291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.71, \"learn_time_ms\": 8708.38, \"total_train_time_s\": 11.164111614227295}", "{\"n\": 14292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.9, \"learn_time_ms\": 8772.596, \"total_train_time_s\": 9.361349821090698}", "{\"n\": 14293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.73, \"learn_time_ms\": 8767.942, \"total_train_time_s\": 9.972488164901733}", "{\"n\": 14294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.04, \"learn_time_ms\": 8694.979, \"total_train_time_s\": 9.612338781356812}", "{\"n\": 14295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.04, \"learn_time_ms\": 8574.87, \"total_train_time_s\": 8.90273904800415}", "{\"n\": 14296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.67, \"learn_time_ms\": 8602.666, \"total_train_time_s\": 9.40464997291565}", "{\"n\": 14297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.85, \"learn_time_ms\": 8583.291, \"total_train_time_s\": 10.622886419296265}", "{\"n\": 14298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.85, \"learn_time_ms\": 8544.342, \"total_train_time_s\": 9.44658374786377}", "{\"n\": 14299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.94, \"learn_time_ms\": 8496.73, \"total_train_time_s\": 10.673128604888916}", "{\"n\": 14300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.65, \"learn_time_ms\": 8374.029, \"total_train_time_s\": 8.441691160202026}", "{\"n\": 14301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.97, \"learn_time_ms\": 8315.946, \"total_train_time_s\": 10.577974319458008}", "{\"n\": 14302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.97, \"learn_time_ms\": 8517.451, \"total_train_time_s\": 11.410478353500366}", "{\"n\": 14303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.99, \"learn_time_ms\": 8553.954, \"total_train_time_s\": 10.329200267791748}", "{\"n\": 14304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.02, \"learn_time_ms\": 8694.653, \"total_train_time_s\": 11.08478307723999}", "{\"n\": 14305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.02, \"learn_time_ms\": 8726.146, \"total_train_time_s\": 9.216740131378174}", "{\"n\": 14306, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.99, \"learn_time_ms\": 8795.692, \"total_train_time_s\": 10.127018213272095}", "{\"n\": 14307, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 8766.498, \"total_train_time_s\": 10.362908124923706}", "{\"n\": 14308, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 8805.119, \"total_train_time_s\": 9.901185035705566}", "{\"n\": 14309, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.66, \"learn_time_ms\": 8668.799, \"total_train_time_s\": 9.340795516967773}", "{\"n\": 14310, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.66, \"learn_time_ms\": 9111.738, \"total_train_time_s\": 12.952339172363281}", "{\"n\": 14311, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 8960.322, \"total_train_time_s\": 9.077694654464722}", "{\"n\": 14312, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 8850.966, \"total_train_time_s\": 10.357643365859985}", "{\"n\": 14313, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.83, \"learn_time_ms\": 8765.558, \"total_train_time_s\": 9.493777751922607}", "{\"n\": 14314, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 8633.92, \"total_train_time_s\": 9.737507104873657}", "{\"n\": 14315, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 8583.809, \"total_train_time_s\": 8.701157331466675}", "{\"n\": 14316, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.83, \"learn_time_ms\": 8580.823, \"total_train_time_s\": 10.069678783416748}", "{\"n\": 14317, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.41, \"learn_time_ms\": 8529.791, \"total_train_time_s\": 9.835120439529419}", "{\"n\": 14318, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.24, \"learn_time_ms\": 8482.237, \"total_train_time_s\": 9.409856796264648}", "{\"n\": 14319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.53, \"learn_time_ms\": 8546.318, \"total_train_time_s\": 9.941642999649048}", "{\"n\": 14320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.47, \"learn_time_ms\": 8247.398, \"total_train_time_s\": 9.89438772201538}", "{\"n\": 14321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.17, \"learn_time_ms\": 8341.678, \"total_train_time_s\": 10.024909496307373}", "{\"n\": 14322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.29, \"learn_time_ms\": 8355.228, \"total_train_time_s\": 10.50288987159729}", "{\"n\": 14323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.29, \"learn_time_ms\": 8412.645, \"total_train_time_s\": 10.053781509399414}", "{\"n\": 14324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.78, \"learn_time_ms\": 8465.057, \"total_train_time_s\": 10.267706632614136}", "{\"n\": 14325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.58, \"learn_time_ms\": 8682.644, \"total_train_time_s\": 10.937553644180298}", "{\"n\": 14326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 8705.618, \"total_train_time_s\": 10.263200998306274}", "{\"n\": 14327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 8729.551, \"total_train_time_s\": 10.071629524230957}", "{\"n\": 14328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.12, \"learn_time_ms\": 8834.849, \"total_train_time_s\": 10.51628851890564}", "{\"n\": 14329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.11, \"learn_time_ms\": 8790.534, \"total_train_time_s\": 9.552204608917236}", "{\"n\": 14330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.11, \"learn_time_ms\": 8765.403, \"total_train_time_s\": 9.63103437423706}", "{\"n\": 14331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.26, \"learn_time_ms\": 8795.397, \"total_train_time_s\": 10.334755182266235}", "{\"n\": 14332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.49, \"learn_time_ms\": 8797.369, \"total_train_time_s\": 10.533801794052124}", "{\"n\": 14333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.49, \"learn_time_ms\": 8766.952, \"total_train_time_s\": 9.760066986083984}", "{\"n\": 14334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.49, \"learn_time_ms\": 8702.033, \"total_train_time_s\": 9.622986078262329}", "{\"n\": 14335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.48, \"learn_time_ms\": 8619.941, \"total_train_time_s\": 10.109468698501587}", "{\"n\": 14336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 8522.27, \"total_train_time_s\": 9.355639457702637}", "{\"n\": 14337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8608.733, \"total_train_time_s\": 10.937674760818481}", "{\"n\": 14338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.17, \"learn_time_ms\": 8590.313, \"total_train_time_s\": 10.229303121566772}", "{\"n\": 14339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 8458.951, \"total_train_time_s\": 8.128285884857178}", "{\"n\": 14340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.02, \"learn_time_ms\": 8539.456, \"total_train_time_s\": 10.436875343322754}", "{\"n\": 14341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.98, \"learn_time_ms\": 8303.154, \"total_train_time_s\": 7.941129684448242}", "{\"n\": 14342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.77, \"learn_time_ms\": 8319.781, \"total_train_time_s\": 10.659364461898804}", "{\"n\": 14343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.55, \"learn_time_ms\": 8336.172, \"total_train_time_s\": 9.850464105606079}", "{\"n\": 14344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.55, \"learn_time_ms\": 8316.981, \"total_train_time_s\": 9.37819242477417}", "{\"n\": 14345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.14, \"learn_time_ms\": 8370.941, \"total_train_time_s\": 10.636574029922485}", "{\"n\": 14346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.69, \"learn_time_ms\": 8489.316, \"total_train_time_s\": 10.553595542907715}", "{\"n\": 14347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.69, \"learn_time_ms\": 8488.337, \"total_train_time_s\": 10.872330904006958}", "{\"n\": 14348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.19, \"learn_time_ms\": 8513.894, \"total_train_time_s\": 10.532858848571777}", "{\"n\": 14349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.89, \"learn_time_ms\": 8629.265, \"total_train_time_s\": 9.361851930618286}", "{\"n\": 14350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.98, \"learn_time_ms\": 8647.434, \"total_train_time_s\": 10.691083192825317}", "{\"n\": 14351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.98, \"learn_time_ms\": 9003.361, \"total_train_time_s\": 11.517491102218628}", "{\"n\": 14352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.62, \"learn_time_ms\": 9061.736, \"total_train_time_s\": 11.337660312652588}", "{\"n\": 14353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.63, \"learn_time_ms\": 8920.424, \"total_train_time_s\": 8.50169062614441}", "{\"n\": 14354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.63, \"learn_time_ms\": 8936.866, \"total_train_time_s\": 9.555134534835815}", "{\"n\": 14355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.23, \"learn_time_ms\": 8872.986, \"total_train_time_s\": 10.024235486984253}", "{\"n\": 14356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.47, \"learn_time_ms\": 8829.441, \"total_train_time_s\": 10.06666374206543}", "{\"n\": 14357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.47, \"learn_time_ms\": 8821.738, \"total_train_time_s\": 10.849173069000244}", "{\"n\": 14358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.91, \"learn_time_ms\": 8780.855, \"total_train_time_s\": 10.1446852684021}", "{\"n\": 14359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.62, \"learn_time_ms\": 8959.329, \"total_train_time_s\": 11.149566411972046}", "{\"n\": 14360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.62, \"learn_time_ms\": 8900.507, \"total_train_time_s\": 10.039183139801025}", "{\"n\": 14361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.62, \"learn_time_ms\": 8852.884, \"total_train_time_s\": 11.053411722183228}", "{\"n\": 14362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.6, \"learn_time_ms\": 8811.925, \"total_train_time_s\": 10.802312135696411}", "{\"n\": 14363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.37, \"learn_time_ms\": 9000.753, \"total_train_time_s\": 10.376790046691895}", "{\"n\": 14364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.37, \"learn_time_ms\": 9121.216, \"total_train_time_s\": 10.796019554138184}", "{\"n\": 14365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.3, \"learn_time_ms\": 9179.727, \"total_train_time_s\": 10.633326053619385}", "{\"n\": 14366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.95, \"learn_time_ms\": 9258.261, \"total_train_time_s\": 10.836642980575562}", "{\"n\": 14367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.95, \"learn_time_ms\": 9264.273, \"total_train_time_s\": 10.892265319824219}", "{\"n\": 14368, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.31, \"learn_time_ms\": 9321.275, \"total_train_time_s\": 10.660554885864258}", "{\"n\": 14369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.62, \"learn_time_ms\": 9153.228, \"total_train_time_s\": 9.476701736450195}", "{\"n\": 14370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.94, \"learn_time_ms\": 9300.642, \"total_train_time_s\": 11.515586853027344}", "{\"n\": 14371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.11, \"learn_time_ms\": 9206.24, \"total_train_time_s\": 10.103024005889893}", "{\"n\": 14372, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.1, \"learn_time_ms\": 9280.741, \"total_train_time_s\": 11.57541537284851}", "{\"n\": 14373, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.04, \"learn_time_ms\": 9133.541, \"total_train_time_s\": 8.914482116699219}", "{\"n\": 14374, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.04, \"learn_time_ms\": 9058.204, \"total_train_time_s\": 9.984102964401245}", "{\"n\": 14375, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.2, \"learn_time_ms\": 8981.162, \"total_train_time_s\": 9.817174673080444}", "{\"n\": 14376, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.2, \"learn_time_ms\": 8839.415, \"total_train_time_s\": 9.415321350097656}", "{\"n\": 14377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.7, \"learn_time_ms\": 8722.629, \"total_train_time_s\": 9.710914611816406}", "{\"n\": 14378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.8, \"learn_time_ms\": 8672.84, \"total_train_time_s\": 10.251405000686646}", "{\"n\": 14379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.64, \"learn_time_ms\": 8616.216, \"total_train_time_s\": 8.917263269424438}", "{\"n\": 14380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.79, \"learn_time_ms\": 8432.827, \"total_train_time_s\": 9.698714017868042}", "{\"n\": 14381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.89, \"learn_time_ms\": 8317.568, \"total_train_time_s\": 8.941985607147217}", "{\"n\": 14382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.62, \"learn_time_ms\": 8234.443, \"total_train_time_s\": 10.763849973678589}", "{\"n\": 14383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.31, \"learn_time_ms\": 8219.082, \"total_train_time_s\": 8.741154432296753}", "{\"n\": 14384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.31, \"learn_time_ms\": 8202.071, \"total_train_time_s\": 9.88259506225586}", "{\"n\": 14385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.52, \"learn_time_ms\": 8433.077, \"total_train_time_s\": 12.138630628585815}", "{\"n\": 14386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.52, \"learn_time_ms\": 8490.204, \"total_train_time_s\": 10.02905797958374}", "{\"n\": 14387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.57, \"learn_time_ms\": 8516.819, \"total_train_time_s\": 9.968374252319336}", "{\"n\": 14388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.16, \"learn_time_ms\": 8396.891, \"total_train_time_s\": 9.019240617752075}", "{\"n\": 14389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.16, \"learn_time_ms\": 8577.539, \"total_train_time_s\": 10.694112539291382}", "{\"n\": 14390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.09, \"learn_time_ms\": 8521.197, \"total_train_time_s\": 9.131208896636963}", "{\"n\": 14391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.9, \"learn_time_ms\": 8538.357, \"total_train_time_s\": 9.088828325271606}", "{\"n\": 14392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.9, \"learn_time_ms\": 8527.186, \"total_train_time_s\": 10.586912155151367}", "{\"n\": 14393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.9, \"learn_time_ms\": 8644.538, \"total_train_time_s\": 9.892844200134277}", "{\"n\": 14394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.67, \"learn_time_ms\": 8727.496, \"total_train_time_s\": 10.652698278427124}", "{\"n\": 14395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.42, \"learn_time_ms\": 8523.425, \"total_train_time_s\": 10.132807731628418}", "{\"n\": 14396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.42, \"learn_time_ms\": 8679.268, \"total_train_time_s\": 11.578433275222778}", "{\"n\": 14397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.31, \"learn_time_ms\": 8705.359, \"total_train_time_s\": 10.257214307785034}", "{\"n\": 14398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.91, \"learn_time_ms\": 8857.997, \"total_train_time_s\": 10.529204607009888}", "{\"n\": 14399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.91, \"learn_time_ms\": 8659.428, \"total_train_time_s\": 8.67673659324646}", "{\"n\": 14400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.91, \"learn_time_ms\": 8778.46, \"total_train_time_s\": 10.375179290771484}", "{\"n\": 14401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.62, \"learn_time_ms\": 8861.868, \"total_train_time_s\": 9.968783140182495}", "{\"n\": 14402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.62, \"learn_time_ms\": 8958.948, \"total_train_time_s\": 11.59113597869873}", "{\"n\": 14403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.62, \"learn_time_ms\": 8970.971, \"total_train_time_s\": 10.068268537521362}", "{\"n\": 14404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.47, \"learn_time_ms\": 8949.049, \"total_train_time_s\": 10.477020978927612}", "{\"n\": 14405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.71, \"learn_time_ms\": 8978.575, \"total_train_time_s\": 10.333834171295166}", "{\"n\": 14406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.71, \"learn_time_ms\": 8843.094, \"total_train_time_s\": 10.180147409439087}", "{\"n\": 14407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.07, \"learn_time_ms\": 8625.858, \"total_train_time_s\": 8.072397232055664}", "{\"n\": 14408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.46, \"learn_time_ms\": 8432.778, \"total_train_time_s\": 8.63551950454712}", "{\"n\": 14409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.46, \"learn_time_ms\": 8510.42, \"total_train_time_s\": 9.47905158996582}", "{\"n\": 14410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.83, \"learn_time_ms\": 8476.622, \"total_train_time_s\": 10.03089427947998}", "{\"n\": 14411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.16, \"learn_time_ms\": 8351.649, \"total_train_time_s\": 8.70361065864563}", "{\"n\": 14412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.16, \"learn_time_ms\": 8136.808, \"total_train_time_s\": 9.457308053970337}", "{\"n\": 14413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.16, \"learn_time_ms\": 8013.381, \"total_train_time_s\": 8.784028053283691}", "{\"n\": 14414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.57, \"learn_time_ms\": 8055.059, \"total_train_time_s\": 10.85725998878479}", "{\"n\": 14415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.57, \"learn_time_ms\": 7906.724, \"total_train_time_s\": 8.843889951705933}", "{\"n\": 14416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.57, \"learn_time_ms\": 7818.912, \"total_train_time_s\": 9.30526351928711}", "{\"n\": 14417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.63, \"learn_time_ms\": 8182.391, \"total_train_time_s\": 11.718901634216309}", "{\"n\": 14418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.05, \"learn_time_ms\": 8156.305, \"total_train_time_s\": 8.369184255599976}", "{\"n\": 14419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.05, \"learn_time_ms\": 8310.07, \"total_train_time_s\": 11.04206919670105}", "{\"n\": 14420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.97, \"learn_time_ms\": 8221.312, \"total_train_time_s\": 9.120848178863525}", "{\"n\": 14421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.96, \"learn_time_ms\": 8439.81, \"total_train_time_s\": 10.939547061920166}", "{\"n\": 14422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.96, \"learn_time_ms\": 8592.285, \"total_train_time_s\": 10.953576564788818}", "{\"n\": 14423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.82, \"learn_time_ms\": 8617.756, \"total_train_time_s\": 9.06301999092102}", "{\"n\": 14424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.34, \"learn_time_ms\": 8487.147, \"total_train_time_s\": 9.595391750335693}", "{\"n\": 14425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.34, \"learn_time_ms\": 8676.609, \"total_train_time_s\": 10.777880430221558}", "{\"n\": 14426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.34, \"learn_time_ms\": 8821.575, \"total_train_time_s\": 10.773189067840576}", "{\"n\": 14427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.95, \"learn_time_ms\": 8640.334, \"total_train_time_s\": 9.890114545822144}", "{\"n\": 14428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.55, \"learn_time_ms\": 8703.344, \"total_train_time_s\": 8.996675491333008}", "{\"n\": 14429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.55, \"learn_time_ms\": 8787.552, \"total_train_time_s\": 11.858421087265015}", "{\"n\": 14430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.71, \"learn_time_ms\": 8769.147, \"total_train_time_s\": 8.85630202293396}", "{\"n\": 14431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.07, \"learn_time_ms\": 8727.485, \"total_train_time_s\": 10.481440544128418}", "{\"n\": 14432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.07, \"learn_time_ms\": 8491.575, \"total_train_time_s\": 8.655534029006958}", "{\"n\": 14433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.05, \"learn_time_ms\": 8741.701, \"total_train_time_s\": 11.55710768699646}", "{\"n\": 14434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.13, \"learn_time_ms\": 8767.091, \"total_train_time_s\": 9.827332496643066}", "{\"n\": 14435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.13, \"learn_time_ms\": 8705.832, \"total_train_time_s\": 10.157712936401367}", "{\"n\": 14436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.69, \"learn_time_ms\": 8689.979, \"total_train_time_s\": 10.642687320709229}", "{\"n\": 14437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.77, \"learn_time_ms\": 8774.694, \"total_train_time_s\": 10.80977725982666}", "{\"n\": 14438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.52, \"learn_time_ms\": 8818.396, \"total_train_time_s\": 9.399558782577515}", "{\"n\": 14439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.86, \"learn_time_ms\": 8525.89, \"total_train_time_s\": 8.90988039970398}", "{\"n\": 14440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.96, \"learn_time_ms\": 8624.559, \"total_train_time_s\": 9.953025102615356}", "{\"n\": 14441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.71, \"learn_time_ms\": 8632.643, \"total_train_time_s\": 10.54265809059143}", "{\"n\": 14442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.91, \"learn_time_ms\": 8751.668, \"total_train_time_s\": 9.789133787155151}", "{\"n\": 14443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.69, \"learn_time_ms\": 8600.874, \"total_train_time_s\": 10.052690505981445}", "{\"n\": 14444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.56, \"learn_time_ms\": 8637.89, \"total_train_time_s\": 10.17949628829956}", "{\"n\": 14445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.9, \"learn_time_ms\": 8621.671, \"total_train_time_s\": 10.001134395599365}", "{\"n\": 14446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.9, \"learn_time_ms\": 8511.627, \"total_train_time_s\": 9.523035049438477}", "{\"n\": 14447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.59, \"learn_time_ms\": 8279.94, \"total_train_time_s\": 8.470253229141235}", "{\"n\": 14448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.12, \"learn_time_ms\": 8237.543, \"total_train_time_s\": 8.979032754898071}", "{\"n\": 14449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.94, \"learn_time_ms\": 8420.646, \"total_train_time_s\": 10.778126001358032}", "{\"n\": 14450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.5, \"learn_time_ms\": 8438.035, \"total_train_time_s\": 10.086105108261108}", "{\"n\": 14451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.68, \"learn_time_ms\": 8367.427, \"total_train_time_s\": 9.801393270492554}", "{\"n\": 14452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.68, \"learn_time_ms\": 8302.932, \"total_train_time_s\": 9.131752490997314}", "{\"n\": 14453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.38, \"learn_time_ms\": 8359.599, \"total_train_time_s\": 10.637535333633423}", "{\"n\": 14454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.38, \"learn_time_ms\": 8321.694, \"total_train_time_s\": 9.808028936386108}", "{\"n\": 14455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3300.95, \"learn_time_ms\": 8355.22, \"total_train_time_s\": 10.373770952224731}", "{\"n\": 14456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.54, \"learn_time_ms\": 8284.942, \"total_train_time_s\": 8.821895360946655}", "{\"n\": 14457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.54, \"learn_time_ms\": 8369.417, \"total_train_time_s\": 9.279022932052612}", "{\"n\": 14458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3311.92, \"learn_time_ms\": 8511.313, \"total_train_time_s\": 10.399869203567505}", "{\"n\": 14459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.33, \"learn_time_ms\": 8341.123, \"total_train_time_s\": 9.097418785095215}", "{\"n\": 14460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.33, \"learn_time_ms\": 8341.452, \"total_train_time_s\": 10.064883470535278}", "{\"n\": 14461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.71, \"learn_time_ms\": 8471.472, \"total_train_time_s\": 11.126689195632935}", "{\"n\": 14462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.33, \"learn_time_ms\": 8593.999, \"total_train_time_s\": 10.352200031280518}", "{\"n\": 14463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.93, \"learn_time_ms\": 8452.228, \"total_train_time_s\": 9.180513620376587}", "{\"n\": 14464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.08, \"learn_time_ms\": 8345.757, \"total_train_time_s\": 8.764158487319946}", "{\"n\": 14465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.07, \"learn_time_ms\": 8298.295, \"total_train_time_s\": 9.869199991226196}", "{\"n\": 14466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.75, \"learn_time_ms\": 8228.734, \"total_train_time_s\": 8.14767074584961}", "{\"n\": 14467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.45, \"learn_time_ms\": 8205.843, \"total_train_time_s\": 9.061899900436401}", "{\"n\": 14468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.79, \"learn_time_ms\": 8222.915, \"total_train_time_s\": 10.584871768951416}", "{\"n\": 14469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.15, \"learn_time_ms\": 8282.712, \"total_train_time_s\": 9.736624002456665}", "{\"n\": 14470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.68, \"learn_time_ms\": 8414.956, \"total_train_time_s\": 11.413090229034424}", "{\"n\": 14471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.54, \"learn_time_ms\": 8195.985, \"total_train_time_s\": 8.961603879928589}", "{\"n\": 14472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.94, \"learn_time_ms\": 8156.951, \"total_train_time_s\": 10.023770093917847}", "{\"n\": 14473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.36, \"learn_time_ms\": 8118.598, \"total_train_time_s\": 8.863303422927856}", "{\"n\": 14474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.83, \"learn_time_ms\": 8168.896, \"total_train_time_s\": 9.296991109848022}", "{\"n\": 14475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.59, \"learn_time_ms\": 8170.22, \"total_train_time_s\": 9.876395225524902}", "{\"n\": 14476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.45, \"learn_time_ms\": 8401.259, \"total_train_time_s\": 10.479109764099121}", "{\"n\": 14477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 8642.99, \"total_train_time_s\": 11.490489721298218}", "{\"n\": 14478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 8634.559, \"total_train_time_s\": 10.469046354293823}", "{\"n\": 14479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.77, \"learn_time_ms\": 8560.587, \"total_train_time_s\": 8.954102039337158}", "{\"n\": 14480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.74, \"learn_time_ms\": 8379.404, \"total_train_time_s\": 9.562550783157349}", "{\"n\": 14481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.78, \"learn_time_ms\": 8493.964, \"total_train_time_s\": 10.087019205093384}", "{\"n\": 14482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.55, \"learn_time_ms\": 8480.837, \"total_train_time_s\": 9.90310525894165}", "{\"n\": 14483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.55, \"learn_time_ms\": 8537.85, \"total_train_time_s\": 9.38276219367981}", "{\"n\": 14484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.81, \"learn_time_ms\": 8682.513, \"total_train_time_s\": 10.74544620513916}", "{\"n\": 14485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.82, \"learn_time_ms\": 8598.212, \"total_train_time_s\": 9.043005228042603}", "{\"n\": 14486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.52, \"learn_time_ms\": 8450.915, \"total_train_time_s\": 8.958441257476807}", "{\"n\": 14487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.61, \"learn_time_ms\": 8172.759, \"total_train_time_s\": 8.655399322509766}", "{\"n\": 14488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.21, \"learn_time_ms\": 8151.071, \"total_train_time_s\": 10.265255451202393}", "{\"n\": 14489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.58, \"learn_time_ms\": 8325.848, \"total_train_time_s\": 10.686806917190552}", "{\"n\": 14490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.83, \"learn_time_ms\": 8265.401, \"total_train_time_s\": 8.959216833114624}", "{\"n\": 14491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.98, \"learn_time_ms\": 8208.661, \"total_train_time_s\": 9.498324394226074}", "{\"n\": 14492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.94, \"learn_time_ms\": 8246.289, \"total_train_time_s\": 10.274366617202759}", "{\"n\": 14493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.49, \"learn_time_ms\": 8338.772, \"total_train_time_s\": 10.333909034729004}", "{\"n\": 14494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.06, \"learn_time_ms\": 8221.018, \"total_train_time_s\": 9.548924684524536}", "{\"n\": 14495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.98, \"learn_time_ms\": 8359.228, \"total_train_time_s\": 10.427789211273193}", "{\"n\": 14496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.56, \"learn_time_ms\": 8365.389, \"total_train_time_s\": 9.056956768035889}", "{\"n\": 14497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 8389.068, \"total_train_time_s\": 8.944213390350342}", "{\"n\": 14498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.81, \"learn_time_ms\": 8417.085, \"total_train_time_s\": 10.564728260040283}", "{\"n\": 14499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3316.21, \"learn_time_ms\": 8187.159, \"total_train_time_s\": 8.37067699432373}", "{\"n\": 14500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.67, \"learn_time_ms\": 8207.447, \"total_train_time_s\": 9.14793348312378}", "{\"n\": 14501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.67, \"learn_time_ms\": 8290.903, \"total_train_time_s\": 10.368018627166748}", "{\"n\": 14502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.69, \"learn_time_ms\": 8287.262, \"total_train_time_s\": 10.21226191520691}", "{\"n\": 14503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.56, \"learn_time_ms\": 8249.762, \"total_train_time_s\": 9.926330089569092}", "{\"n\": 14504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.99, \"learn_time_ms\": 8308.855, \"total_train_time_s\": 10.124972343444824}", "{\"n\": 14505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.59, \"learn_time_ms\": 8118.821, \"total_train_time_s\": 8.543734312057495}", "{\"n\": 14506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.59, \"learn_time_ms\": 8220.312, \"total_train_time_s\": 10.049191951751709}", "{\"n\": 14507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.94, \"learn_time_ms\": 8172.548, \"total_train_time_s\": 8.448905944824219}", "{\"n\": 14508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.02, \"learn_time_ms\": 8096.736, \"total_train_time_s\": 9.79518461227417}", "{\"n\": 14509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.48, \"learn_time_ms\": 8192.322, \"total_train_time_s\": 9.349275827407837}", "{\"n\": 14510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.82, \"learn_time_ms\": 8261.559, \"total_train_time_s\": 9.875813961029053}", "{\"n\": 14511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.63, \"learn_time_ms\": 8227.273, \"total_train_time_s\": 10.017081499099731}", "{\"n\": 14512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.6, \"learn_time_ms\": 8309.752, \"total_train_time_s\": 11.04362440109253}", "{\"n\": 14513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.6, \"learn_time_ms\": 8370.903, \"total_train_time_s\": 10.597565412521362}", "{\"n\": 14514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.73, \"learn_time_ms\": 8266.924, \"total_train_time_s\": 9.097550392150879}", "{\"n\": 14515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.33, \"learn_time_ms\": 8406.35, \"total_train_time_s\": 9.911499977111816}", "{\"n\": 14516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.33, \"learn_time_ms\": 8474.345, \"total_train_time_s\": 10.700428247451782}", "{\"n\": 14517, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.7, \"learn_time_ms\": 8587.266, \"total_train_time_s\": 9.581866025924683}", "{\"n\": 14518, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.18, \"learn_time_ms\": 8625.037, \"total_train_time_s\": 10.17789626121521}", "{\"n\": 14519, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.18, \"learn_time_ms\": 8548.088, \"total_train_time_s\": 8.6105318069458}", "{\"n\": 14520, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.04, \"learn_time_ms\": 8506.44, \"total_train_time_s\": 9.424561262130737}", "{\"n\": 14521, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.82, \"learn_time_ms\": 8547.801, \"total_train_time_s\": 10.434151411056519}", "{\"n\": 14522, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.82, \"learn_time_ms\": 8468.601, \"total_train_time_s\": 10.224082231521606}", "{\"n\": 14523, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.06, \"learn_time_ms\": 8422.317, \"total_train_time_s\": 10.113778352737427}", "{\"n\": 14524, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.17, \"learn_time_ms\": 8506.522, \"total_train_time_s\": 9.947253465652466}", "{\"n\": 14525, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.17, \"learn_time_ms\": 8535.121, \"total_train_time_s\": 10.25784945487976}", "{\"n\": 14526, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.17, \"learn_time_ms\": 8442.231, \"total_train_time_s\": 9.787447214126587}", "{\"n\": 14527, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.16, \"learn_time_ms\": 8461.375, \"total_train_time_s\": 9.762107372283936}", "{\"n\": 14528, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.75, \"learn_time_ms\": 8481.781, \"total_train_time_s\": 10.377027988433838}", "{\"n\": 14529, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.75, \"learn_time_ms\": 8712.123, \"total_train_time_s\": 10.852413415908813}", "{\"n\": 14530, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.14, \"learn_time_ms\": 8886.467, \"total_train_time_s\": 11.178806781768799}", "{\"n\": 14531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.38, \"learn_time_ms\": 8952.861, \"total_train_time_s\": 11.07428240776062}", "{\"n\": 14532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.04, \"learn_time_ms\": 9019.996, \"total_train_time_s\": 10.903787851333618}", "{\"n\": 14533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.04, \"learn_time_ms\": 9036.751, \"total_train_time_s\": 10.263387203216553}", "{\"n\": 14534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.45, \"learn_time_ms\": 9046.559, \"total_train_time_s\": 10.037386894226074}", "{\"n\": 14535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.59, \"learn_time_ms\": 9041.406, \"total_train_time_s\": 10.16189455986023}", "{\"n\": 14536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.59, \"learn_time_ms\": 9039.663, \"total_train_time_s\": 9.819883584976196}", "{\"n\": 14537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.75, \"learn_time_ms\": 9170.638, \"total_train_time_s\": 11.054056644439697}", "{\"n\": 14538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.88, \"learn_time_ms\": 9089.488, \"total_train_time_s\": 9.548067569732666}", "{\"n\": 14539, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.88, \"learn_time_ms\": 9105.219, \"total_train_time_s\": 11.025325536727905}", "{\"n\": 14540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.78, \"learn_time_ms\": 9013.226, \"total_train_time_s\": 10.301380395889282}", "{\"n\": 14541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.6, \"learn_time_ms\": 8891.104, \"total_train_time_s\": 9.927117347717285}", "{\"n\": 14542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.6, \"learn_time_ms\": 8842.188, \"total_train_time_s\": 10.42512059211731}", "{\"n\": 14543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.6, \"learn_time_ms\": 8641.232, \"total_train_time_s\": 8.252588510513306}", "{\"n\": 14544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.31, \"learn_time_ms\": 8765.257, \"total_train_time_s\": 11.256931781768799}", "{\"n\": 14545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.75, \"learn_time_ms\": 8844.538, \"total_train_time_s\": 10.878541231155396}", "{\"n\": 14546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.75, \"learn_time_ms\": 8945.896, \"total_train_time_s\": 10.788592338562012}", "{\"n\": 14547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.96, \"learn_time_ms\": 8817.733, \"total_train_time_s\": 9.830554723739624}", "{\"n\": 14548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.31, \"learn_time_ms\": 8864.876, \"total_train_time_s\": 10.069294214248657}", "{\"n\": 14549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.31, \"learn_time_ms\": 8711.23, \"total_train_time_s\": 9.558403491973877}", "{\"n\": 14550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.86, \"learn_time_ms\": 8616.442, \"total_train_time_s\": 9.369473218917847}", "{\"n\": 14551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.7, \"learn_time_ms\": 8462.556, \"total_train_time_s\": 8.360147476196289}", "{\"n\": 14552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.95, \"learn_time_ms\": 8423.975, \"total_train_time_s\": 10.048190832138062}", "{\"n\": 14553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.34, \"learn_time_ms\": 8650.201, \"total_train_time_s\": 10.499421834945679}", "{\"n\": 14554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.58, \"learn_time_ms\": 8469.426, \"total_train_time_s\": 9.427671909332275}", "{\"n\": 14555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.85, \"learn_time_ms\": 8316.879, \"total_train_time_s\": 9.385695695877075}", "{\"n\": 14556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.06, \"learn_time_ms\": 8196.697, \"total_train_time_s\": 9.58151364326477}", "{\"n\": 14557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.89, \"learn_time_ms\": 8259.891, \"total_train_time_s\": 10.444831848144531}", "{\"n\": 14558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.46, \"learn_time_ms\": 8267.87, \"total_train_time_s\": 10.11486530303955}", "{\"n\": 14559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.46, \"learn_time_ms\": 8326.243, \"total_train_time_s\": 10.07360315322876}", "{\"n\": 14560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.0, \"learn_time_ms\": 8415.595, \"total_train_time_s\": 10.225016355514526}", "{\"n\": 14561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.0, \"learn_time_ms\": 8472.201, \"total_train_time_s\": 8.90579891204834}", "{\"n\": 14562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.3, \"learn_time_ms\": 8509.841, \"total_train_time_s\": 10.41446828842163}", "{\"n\": 14563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.3, \"learn_time_ms\": 8190.148, \"total_train_time_s\": 7.32047963142395}", "{\"n\": 14564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.18, \"learn_time_ms\": 8241.383, \"total_train_time_s\": 9.991032600402832}", "{\"n\": 14565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.5, \"learn_time_ms\": 8310.914, \"total_train_time_s\": 10.12624454498291}", "{\"n\": 14566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.86, \"learn_time_ms\": 8277.144, \"total_train_time_s\": 9.261843919754028}", "{\"n\": 14567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.78, \"learn_time_ms\": 8194.175, \"total_train_time_s\": 9.572145700454712}", "{\"n\": 14568, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.78, \"learn_time_ms\": 8108.716, \"total_train_time_s\": 9.269855737686157}", "{\"n\": 14569, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.73, \"learn_time_ms\": 8093.104, \"total_train_time_s\": 9.93167781829834}", "{\"n\": 14570, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.29, \"learn_time_ms\": 8083.051, \"total_train_time_s\": 10.101426124572754}", "{\"n\": 14571, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.29, \"learn_time_ms\": 8121.562, \"total_train_time_s\": 9.260023593902588}", "{\"n\": 14572, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.65, \"learn_time_ms\": 8063.287, \"total_train_time_s\": 9.866547346115112}", "{\"n\": 14573, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.21, \"learn_time_ms\": 8265.697, \"total_train_time_s\": 9.374322414398193}", "{\"n\": 14574, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 8206.284, \"total_train_time_s\": 9.392950057983398}", "{\"n\": 14575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 8207.982, \"total_train_time_s\": 10.169048070907593}", "{\"n\": 14576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.34, \"learn_time_ms\": 8112.453, \"total_train_time_s\": 8.326087951660156}", "{\"n\": 14577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.34, \"learn_time_ms\": 8155.137, \"total_train_time_s\": 10.001332998275757}", "{\"n\": 14578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.52, \"learn_time_ms\": 8212.984, \"total_train_time_s\": 9.806371212005615}", "{\"n\": 14579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.57, \"learn_time_ms\": 8249.88, \"total_train_time_s\": 10.317043542861938}", "{\"n\": 14580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.57, \"learn_time_ms\": 8248.333, \"total_train_time_s\": 10.152931928634644}", "{\"n\": 14581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.32, \"learn_time_ms\": 8376.577, \"total_train_time_s\": 10.558446407318115}", "{\"n\": 14582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.2, \"learn_time_ms\": 8543.047, \"total_train_time_s\": 11.554649353027344}", "{\"n\": 14583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.2, \"learn_time_ms\": 8503.422, \"total_train_time_s\": 8.97907304763794}", "{\"n\": 14584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.78, \"learn_time_ms\": 8539.619, \"total_train_time_s\": 9.746726512908936}", "{\"n\": 14585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.45, \"learn_time_ms\": 8402.183, \"total_train_time_s\": 8.74948525428772}", "{\"n\": 14586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.69, \"learn_time_ms\": 8567.954, \"total_train_time_s\": 9.917264699935913}", "{\"n\": 14587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.69, \"learn_time_ms\": 8504.413, \"total_train_time_s\": 9.366606712341309}", "{\"n\": 14588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.94, \"learn_time_ms\": 8460.972, \"total_train_time_s\": 9.38552451133728}", "{\"n\": 14589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.24, \"learn_time_ms\": 8605.243, \"total_train_time_s\": 11.777803659439087}", "{\"n\": 14590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.24, \"learn_time_ms\": 8699.759, \"total_train_time_s\": 11.046170234680176}", "{\"n\": 14591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.31, \"learn_time_ms\": 8675.8, \"total_train_time_s\": 10.289507627487183}", "{\"n\": 14592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.84, \"learn_time_ms\": 8605.514, \"total_train_time_s\": 10.806540966033936}", "{\"n\": 14593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.67, \"learn_time_ms\": 8739.247, \"total_train_time_s\": 10.276593685150146}", "{\"n\": 14594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.45, \"learn_time_ms\": 8825.617, \"total_train_time_s\": 10.620479345321655}", "{\"n\": 14595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.21, \"learn_time_ms\": 8927.385, \"total_train_time_s\": 9.75333309173584}", "{\"n\": 14596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.51, \"learn_time_ms\": 8868.906, \"total_train_time_s\": 9.391623497009277}", "{\"n\": 14597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.75, \"learn_time_ms\": 8949.461, \"total_train_time_s\": 10.204301834106445}", "{\"n\": 14598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.75, \"learn_time_ms\": 8999.136, \"total_train_time_s\": 9.847565650939941}", "{\"n\": 14599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.09, \"learn_time_ms\": 8635.153, \"total_train_time_s\": 8.077565908432007}", "{\"n\": 14600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.22, \"learn_time_ms\": 8537.763, \"total_train_time_s\": 10.069293737411499}", "{\"n\": 14601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.37, \"learn_time_ms\": 8583.691, \"total_train_time_s\": 10.742730855941772}", "{\"n\": 14602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.23, \"learn_time_ms\": 8561.94, \"total_train_time_s\": 10.54692816734314}", "{\"n\": 14603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.46, \"learn_time_ms\": 8434.295, \"total_train_time_s\": 9.009731531143188}", "{\"n\": 14604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.13, \"learn_time_ms\": 8425.864, \"total_train_time_s\": 10.513283729553223}", "{\"n\": 14605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.31, \"learn_time_ms\": 8460.996, \"total_train_time_s\": 10.129386186599731}", "{\"n\": 14606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.16, \"learn_time_ms\": 8550.359, \"total_train_time_s\": 10.244957685470581}", "{\"n\": 14607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.56, \"learn_time_ms\": 8620.922, \"total_train_time_s\": 10.892271995544434}", "{\"n\": 14608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.56, \"learn_time_ms\": 8664.968, \"total_train_time_s\": 10.33253526687622}", "{\"n\": 14609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.37, \"learn_time_ms\": 8992.771, \"total_train_time_s\": 11.378838539123535}", "{\"n\": 14610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.37, \"learn_time_ms\": 8955.341, \"total_train_time_s\": 9.686401128768921}", "{\"n\": 14611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.5, \"learn_time_ms\": 8886.08, \"total_train_time_s\": 10.060624122619629}", "{\"n\": 14612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.65, \"learn_time_ms\": 8712.674, \"total_train_time_s\": 8.823366403579712}", "{\"n\": 14613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.51, \"learn_time_ms\": 8925.887, \"total_train_time_s\": 11.141194581985474}", "{\"n\": 14614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.51, \"learn_time_ms\": 8626.29, \"total_train_time_s\": 7.519109010696411}", "{\"n\": 14615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.73, \"learn_time_ms\": 8688.527, \"total_train_time_s\": 10.74294376373291}", "{\"n\": 14616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 8713.622, \"total_train_time_s\": 10.530897855758667}", "{\"n\": 14617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 8543.714, \"total_train_time_s\": 9.21638011932373}", "{\"n\": 14618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.15, \"learn_time_ms\": 8459.183, \"total_train_time_s\": 9.442044973373413}", "{\"n\": 14619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.57, \"learn_time_ms\": 8263.809, \"total_train_time_s\": 9.416069984436035}", "{\"n\": 14620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.57, \"learn_time_ms\": 8319.597, \"total_train_time_s\": 10.249703168869019}", "{\"n\": 14621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.16, \"learn_time_ms\": 8243.182, \"total_train_time_s\": 9.357682704925537}", "{\"n\": 14622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.99, \"learn_time_ms\": 8364.491, \"total_train_time_s\": 10.068397045135498}", "{\"n\": 14623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.24, \"learn_time_ms\": 8258.254, \"total_train_time_s\": 10.088821411132812}", "{\"n\": 14624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.0, \"learn_time_ms\": 8348.465, \"total_train_time_s\": 8.490142107009888}", "{\"n\": 14625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.43, \"learn_time_ms\": 8236.551, \"total_train_time_s\": 9.624995946884155}", "{\"n\": 14626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.7, \"learn_time_ms\": 8265.417, \"total_train_time_s\": 10.814021110534668}", "{\"n\": 14627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.19, \"learn_time_ms\": 8362.701, \"total_train_time_s\": 10.203780174255371}", "{\"n\": 14628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.93, \"learn_time_ms\": 8443.968, \"total_train_time_s\": 10.297529935836792}", "{\"n\": 14629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.86, \"learn_time_ms\": 8423.122, \"total_train_time_s\": 9.197943210601807}", "{\"n\": 14630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.64, \"learn_time_ms\": 8369.195, \"total_train_time_s\": 9.753699541091919}", "{\"n\": 14631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.91, \"learn_time_ms\": 8431.798, \"total_train_time_s\": 9.96001410484314}", "{\"n\": 14632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.16, \"learn_time_ms\": 8284.009, \"total_train_time_s\": 8.546326637268066}", "{\"n\": 14633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.2, \"learn_time_ms\": 8295.562, \"total_train_time_s\": 10.176236152648926}", "{\"n\": 14634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.43, \"learn_time_ms\": 8548.312, \"total_train_time_s\": 10.974061727523804}", "{\"n\": 14635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.83, \"learn_time_ms\": 8582.499, \"total_train_time_s\": 9.992198705673218}", "{\"n\": 14636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.83, \"learn_time_ms\": 8541.868, \"total_train_time_s\": 10.397200107574463}", "{\"n\": 14637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.83, \"learn_time_ms\": 8556.855, \"total_train_time_s\": 10.300135374069214}", "{\"n\": 14638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.26, \"learn_time_ms\": 8364.606, \"total_train_time_s\": 8.333596229553223}", "{\"n\": 14639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.2, \"learn_time_ms\": 8547.172, \"total_train_time_s\": 11.035269021987915}", "{\"n\": 14640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.2, \"learn_time_ms\": 8596.294, \"total_train_time_s\": 10.22421646118164}", "{\"n\": 14641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.16, \"learn_time_ms\": 8640.725, \"total_train_time_s\": 10.367959022521973}", "{\"n\": 14642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.72, \"learn_time_ms\": 8753.376, \"total_train_time_s\": 9.716051816940308}", "{\"n\": 14643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.13, \"learn_time_ms\": 8748.087, \"total_train_time_s\": 10.14940357208252}", "{\"n\": 14644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.64, \"learn_time_ms\": 8777.058, \"total_train_time_s\": 11.219700336456299}", "{\"n\": 14645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.39, \"learn_time_ms\": 8791.466, \"total_train_time_s\": 10.13282561302185}", "{\"n\": 14646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.33, \"learn_time_ms\": 8764.79, \"total_train_time_s\": 10.141828536987305}", "{\"n\": 14647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.33, \"learn_time_ms\": 8749.597, \"total_train_time_s\": 10.17487645149231}", "{\"n\": 14648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.27, \"learn_time_ms\": 9003.586, \"total_train_time_s\": 10.913889169692993}", "{\"n\": 14649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.18, \"learn_time_ms\": 8866.588, \"total_train_time_s\": 9.682000875473022}", "{\"n\": 14650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.18, \"learn_time_ms\": 8950.21, \"total_train_time_s\": 11.01065993309021}", "{\"n\": 14651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.18, \"learn_time_ms\": 9000.266, \"total_train_time_s\": 10.921600580215454}", "{\"n\": 14652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.96, \"learn_time_ms\": 9054.19, \"total_train_time_s\": 10.233707666397095}", "{\"n\": 14653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.53, \"learn_time_ms\": 8955.25, \"total_train_time_s\": 9.137337923049927}", "{\"n\": 14654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.53, \"learn_time_ms\": 8943.211, \"total_train_time_s\": 11.09525728225708}", "{\"n\": 14655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.05, \"learn_time_ms\": 8888.002, \"total_train_time_s\": 9.5544114112854}", "{\"n\": 14656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.6, \"learn_time_ms\": 8868.621, \"total_train_time_s\": 9.934099197387695}", "{\"n\": 14657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.6, \"learn_time_ms\": 8794.594, \"total_train_time_s\": 9.44091272354126}", "{\"n\": 14658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.6, \"learn_time_ms\": 8676.764, \"total_train_time_s\": 9.741993188858032}", "{\"n\": 14659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.93, \"learn_time_ms\": 8611.751, \"total_train_time_s\": 9.00319242477417}", "{\"n\": 14660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.93, \"learn_time_ms\": 8502.92, \"total_train_time_s\": 9.996947050094604}", "{\"n\": 14661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.93, \"learn_time_ms\": 8334.123, \"total_train_time_s\": 9.199397802352905}", "{\"n\": 14662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 8264.13, \"total_train_time_s\": 9.512352705001831}", "{\"n\": 14663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 8377.908, \"total_train_time_s\": 10.248421669006348}", "{\"n\": 14664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 8235.804, \"total_train_time_s\": 9.709511756896973}", "{\"n\": 14665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.07, \"learn_time_ms\": 8362.843, \"total_train_time_s\": 10.840744972229004}", "{\"n\": 14666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.19, \"learn_time_ms\": 8384.365, \"total_train_time_s\": 10.140272855758667}", "{\"n\": 14667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.19, \"learn_time_ms\": 8326.755, \"total_train_time_s\": 8.847424507141113}", "{\"n\": 14668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.19, \"learn_time_ms\": 8248.231, \"total_train_time_s\": 8.926167011260986}", "{\"n\": 14669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.52, \"learn_time_ms\": 8391.789, \"total_train_time_s\": 10.430978775024414}", "{\"n\": 14670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.52, \"learn_time_ms\": 8235.235, \"total_train_time_s\": 8.399660110473633}", "{\"n\": 14671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.11, \"learn_time_ms\": 8208.904, \"total_train_time_s\": 8.974621534347534}", "{\"n\": 14672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.76, \"learn_time_ms\": 8095.053, \"total_train_time_s\": 8.397157669067383}", "{\"n\": 14673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 8087.088, \"total_train_time_s\": 10.170088768005371}", "{\"n\": 14674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 8125.555, \"total_train_time_s\": 10.088670492172241}", "{\"n\": 14675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.6, \"learn_time_ms\": 8014.514, \"total_train_time_s\": 9.706674098968506}", "{\"n\": 14676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.08, \"learn_time_ms\": 8117.153, \"total_train_time_s\": 11.114947319030762}", "{\"n\": 14677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.08, \"learn_time_ms\": 8124.259, \"total_train_time_s\": 8.877005338668823}", "{\"n\": 14678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.15, \"learn_time_ms\": 8227.66, \"total_train_time_s\": 10.025887489318848}", "{\"n\": 14679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.09, \"learn_time_ms\": 8125.11, \"total_train_time_s\": 9.44844102859497}", "{\"n\": 14680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.41, \"learn_time_ms\": 8255.156, \"total_train_time_s\": 9.690640926361084}", "{\"n\": 14681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.41, \"learn_time_ms\": 8432.399, \"total_train_time_s\": 10.718738317489624}", "{\"n\": 14682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.66, \"learn_time_ms\": 8547.922, \"total_train_time_s\": 9.568969964981079}", "{\"n\": 14683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.66, \"learn_time_ms\": 8416.478, \"total_train_time_s\": 8.893314838409424}", "{\"n\": 14684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.77, \"learn_time_ms\": 8455.038, \"total_train_time_s\": 10.4480721950531}", "{\"n\": 14685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.36, \"learn_time_ms\": 8439.213, \"total_train_time_s\": 9.576451301574707}", "{\"n\": 14686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.98, \"learn_time_ms\": 8266.419, \"total_train_time_s\": 9.419929027557373}", "{\"n\": 14687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.57, \"learn_time_ms\": 8361.986, \"total_train_time_s\": 9.856112718582153}", "{\"n\": 14688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.64, \"learn_time_ms\": 8288.719, \"total_train_time_s\": 9.230465173721313}", "{\"n\": 14689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.32, \"learn_time_ms\": 8383.683, \"total_train_time_s\": 10.358382225036621}", "{\"n\": 14690, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.87, \"learn_time_ms\": 8482.498, \"total_train_time_s\": 10.701583623886108}", "{\"n\": 14691, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.72, \"learn_time_ms\": 8461.811, \"total_train_time_s\": 10.476013898849487}", "{\"n\": 14692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.58, \"learn_time_ms\": 8423.878, \"total_train_time_s\": 9.18654727935791}", "{\"n\": 14693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.58, \"learn_time_ms\": 8460.641, \"total_train_time_s\": 9.225858688354492}", "{\"n\": 14694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.84, \"learn_time_ms\": 8308.837, \"total_train_time_s\": 8.931944608688354}", "{\"n\": 14695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.05, \"learn_time_ms\": 8467.624, \"total_train_time_s\": 11.174418687820435}", "{\"n\": 14696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.05, \"learn_time_ms\": 8404.729, \"total_train_time_s\": 8.811185359954834}", "{\"n\": 14697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.93, \"learn_time_ms\": 8345.211, \"total_train_time_s\": 9.27797245979309}", "{\"n\": 14698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.96, \"learn_time_ms\": 8456.092, \"total_train_time_s\": 10.370215654373169}", "{\"n\": 14699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.16, \"learn_time_ms\": 8339.843, \"total_train_time_s\": 9.238454580307007}", "{\"n\": 14700, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.49, \"learn_time_ms\": 8391.568, \"total_train_time_s\": 11.215338230133057}", "{\"n\": 14701, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.38, \"learn_time_ms\": 8328.895, \"total_train_time_s\": 9.899898529052734}", "{\"n\": 14702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.81, \"learn_time_ms\": 8304.299, \"total_train_time_s\": 8.929189205169678}", "{\"n\": 14703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.26, \"learn_time_ms\": 8530.484, \"total_train_time_s\": 11.526654481887817}", "{\"n\": 14704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.73, \"learn_time_ms\": 8799.464, \"total_train_time_s\": 11.638015508651733}", "{\"n\": 14705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.73, \"learn_time_ms\": 8745.934, \"total_train_time_s\": 10.586554765701294}", "{\"n\": 14706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.21, \"learn_time_ms\": 8849.582, \"total_train_time_s\": 9.825945377349854}", "{\"n\": 14707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.4, \"learn_time_ms\": 8946.007, \"total_train_time_s\": 10.279731750488281}", "{\"n\": 14708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.4, \"learn_time_ms\": 8983.215, \"total_train_time_s\": 10.754326105117798}", "{\"n\": 14709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.72, \"learn_time_ms\": 9089.719, \"total_train_time_s\": 10.266925573348999}", "{\"n\": 14710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 8916.582, \"total_train_time_s\": 9.459596633911133}", "{\"n\": 14711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.44, \"learn_time_ms\": 8976.165, \"total_train_time_s\": 10.482224702835083}", "{\"n\": 14712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.44, \"learn_time_ms\": 9078.851, \"total_train_time_s\": 9.97990345954895}", "{\"n\": 14713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.69, \"learn_time_ms\": 8883.811, \"total_train_time_s\": 9.57553505897522}", "{\"n\": 14714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.87, \"learn_time_ms\": 8836.052, \"total_train_time_s\": 11.147446870803833}", "{\"n\": 14715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.87, \"learn_time_ms\": 8585.823, \"total_train_time_s\": 8.084578275680542}", "{\"n\": 14716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.99, \"learn_time_ms\": 8702.784, \"total_train_time_s\": 11.019405126571655}", "{\"n\": 14717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.44, \"learn_time_ms\": 8690.06, \"total_train_time_s\": 10.084892272949219}", "{\"n\": 14718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.44, \"learn_time_ms\": 8627.601, \"total_train_time_s\": 10.119934797286987}", "{\"n\": 14719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.55, \"learn_time_ms\": 8542.431, \"total_train_time_s\": 9.435200691223145}", "{\"n\": 14720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 8632.127, \"total_train_time_s\": 10.405997037887573}", "{\"n\": 14721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 8605.4, \"total_train_time_s\": 10.21095895767212}", "{\"n\": 14722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.34, \"learn_time_ms\": 8607.207, \"total_train_time_s\": 9.985499620437622}", "{\"n\": 14723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.09, \"learn_time_ms\": 8504.116, \"total_train_time_s\": 8.545814990997314}", "{\"n\": 14724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.49, \"learn_time_ms\": 8457.023, \"total_train_time_s\": 10.691251039505005}", "{\"n\": 14725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.49, \"learn_time_ms\": 8643.258, \"total_train_time_s\": 9.965528011322021}", "{\"n\": 14726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.8, \"learn_time_ms\": 8404.07, \"total_train_time_s\": 8.64365816116333}", "{\"n\": 14727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.59, \"learn_time_ms\": 8426.955, \"total_train_time_s\": 10.399983882904053}", "{\"n\": 14728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 8486.25, \"total_train_time_s\": 10.741683006286621}", "{\"n\": 14729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.99, \"learn_time_ms\": 8525.738, \"total_train_time_s\": 9.833179712295532}", "{\"n\": 14730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.41, \"learn_time_ms\": 8629.799, \"total_train_time_s\": 11.367030620574951}", "{\"n\": 14731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.79, \"learn_time_ms\": 8603.691, \"total_train_time_s\": 9.974325895309448}", "{\"n\": 14732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.34, \"learn_time_ms\": 8718.76, \"total_train_time_s\": 11.117700576782227}", "{\"n\": 14733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.34, \"learn_time_ms\": 8808.787, \"total_train_time_s\": 9.422492027282715}", "{\"n\": 14734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.03, \"learn_time_ms\": 8740.338, \"total_train_time_s\": 10.00598669052124}", "{\"n\": 14735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.28, \"learn_time_ms\": 8586.309, \"total_train_time_s\": 8.427951097488403}", "{\"n\": 14736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.2, \"learn_time_ms\": 8664.481, \"total_train_time_s\": 9.410483360290527}", "{\"n\": 14737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.2, \"learn_time_ms\": 8591.309, \"total_train_time_s\": 9.619690418243408}", "{\"n\": 14738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.0, \"learn_time_ms\": 8648.387, \"total_train_time_s\": 11.313302755355835}", "{\"n\": 14739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.03, \"learn_time_ms\": 8472.622, \"total_train_time_s\": 8.054810047149658}", "{\"n\": 14740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.03, \"learn_time_ms\": 8368.77, \"total_train_time_s\": 10.335487127304077}", "{\"n\": 14741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.51, \"learn_time_ms\": 8448.527, \"total_train_time_s\": 10.776132583618164}", "{\"n\": 14742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.2, \"learn_time_ms\": 8390.811, \"total_train_time_s\": 10.602081775665283}", "{\"n\": 14743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 8347.814, \"total_train_time_s\": 9.034029006958008}", "{\"n\": 14744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 8318.798, \"total_train_time_s\": 9.706241846084595}", "{\"n\": 14745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.19, \"learn_time_ms\": 8473.359, \"total_train_time_s\": 10.005021095275879}", "{\"n\": 14746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.55, \"learn_time_ms\": 8477.783, \"total_train_time_s\": 9.458293914794922}", "{\"n\": 14747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.55, \"learn_time_ms\": 8481.408, \"total_train_time_s\": 9.643301248550415}", "{\"n\": 14748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.74, \"learn_time_ms\": 8258.421, \"total_train_time_s\": 9.056243419647217}", "{\"n\": 14749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.23, \"learn_time_ms\": 8508.286, \"total_train_time_s\": 10.592989444732666}", "{\"n\": 14750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.23, \"learn_time_ms\": 8514.054, \"total_train_time_s\": 10.448846578598022}", "{\"n\": 14751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.71, \"learn_time_ms\": 8358.45, \"total_train_time_s\": 9.181884765625}", "{\"n\": 14752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 8479.672, \"total_train_time_s\": 11.776984691619873}", "{\"n\": 14753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 8617.122, \"total_train_time_s\": 10.389872550964355}", "{\"n\": 14754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 8611.443, \"total_train_time_s\": 9.613693237304688}", "{\"n\": 14755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 8699.85, \"total_train_time_s\": 10.862196207046509}", "{\"n\": 14756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 8775.957, \"total_train_time_s\": 10.193649530410767}", "{\"n\": 14757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 8781.72, \"total_train_time_s\": 9.735268115997314}", "{\"n\": 14758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.06, \"learn_time_ms\": 8829.585, \"total_train_time_s\": 9.575643539428711}", "{\"n\": 14759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 8820.514, \"total_train_time_s\": 10.439564228057861}", "{\"n\": 14760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 8704.99, \"total_train_time_s\": 9.262926816940308}", "{\"n\": 14761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.81, \"learn_time_ms\": 8819.741, \"total_train_time_s\": 10.364307165145874}", "{\"n\": 14762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.5, \"learn_time_ms\": 8554.382, \"total_train_time_s\": 9.101210832595825}", "{\"n\": 14763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.5, \"learn_time_ms\": 8560.928, \"total_train_time_s\": 10.43403148651123}", "{\"n\": 14764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.91, \"learn_time_ms\": 8631.955, \"total_train_time_s\": 10.354464054107666}", "{\"n\": 14765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.51, \"learn_time_ms\": 8635.259, \"total_train_time_s\": 10.926616430282593}", "{\"n\": 14766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.45, \"learn_time_ms\": 8553.108, \"total_train_time_s\": 9.44610071182251}", "{\"n\": 14767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.45, \"learn_time_ms\": 8580.917, \"total_train_time_s\": 10.020928144454956}", "{\"n\": 14768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.79, \"learn_time_ms\": 8637.245, \"total_train_time_s\": 10.142308950424194}", "{\"n\": 14769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.73, \"learn_time_ms\": 8626.953, \"total_train_time_s\": 10.422010898590088}", "{\"n\": 14770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.56, \"learn_time_ms\": 8716.893, \"total_train_time_s\": 10.160079717636108}", "{\"n\": 14771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.91, \"learn_time_ms\": 8755.438, \"total_train_time_s\": 10.692707300186157}", "{\"n\": 14772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 8931.011, \"total_train_time_s\": 10.836968421936035}", "{\"n\": 14773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 8897.492, \"total_train_time_s\": 10.092344045639038}", "{\"n\": 14774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.71, \"learn_time_ms\": 8952.308, \"total_train_time_s\": 10.899251461029053}", "{\"n\": 14775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.07, \"learn_time_ms\": 8975.573, \"total_train_time_s\": 11.150081634521484}", "{\"n\": 14776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.07, \"learn_time_ms\": 9072.153, \"total_train_time_s\": 10.368777513504028}", "{\"n\": 14777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.9, \"learn_time_ms\": 9088.689, \"total_train_time_s\": 10.164687871932983}", "{\"n\": 14778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.9, \"learn_time_ms\": 9036.861, \"total_train_time_s\": 9.590476036071777}", "{\"n\": 14779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.76, \"learn_time_ms\": 8866.748, \"total_train_time_s\": 8.671753644943237}", "{\"n\": 14780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.76, \"learn_time_ms\": 8720.189, \"total_train_time_s\": 8.733045101165771}", "{\"n\": 14781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.92, \"learn_time_ms\": 8792.218, \"total_train_time_s\": 11.484883785247803}", "{\"n\": 14782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 8726.49, \"total_train_time_s\": 10.231020450592041}", "{\"n\": 14783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.32, \"learn_time_ms\": 8833.187, \"total_train_time_s\": 11.208315134048462}", "{\"n\": 14784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.44, \"learn_time_ms\": 8783.689, \"total_train_time_s\": 10.399152755737305}", "{\"n\": 14785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.99, \"learn_time_ms\": 8563.504, \"total_train_time_s\": 8.941181659698486}", "{\"n\": 14786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.23, \"learn_time_ms\": 8493.092, \"total_train_time_s\": 9.67578935623169}", "{\"n\": 14787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.23, \"learn_time_ms\": 8409.927, \"total_train_time_s\": 9.34190320968628}", "{\"n\": 14788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.99, \"learn_time_ms\": 8451.066, \"total_train_time_s\": 9.982100486755371}", "{\"n\": 14789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.47, \"learn_time_ms\": 8529.582, \"total_train_time_s\": 9.465041637420654}", "{\"n\": 14790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.1, \"learn_time_ms\": 8618.249, \"total_train_time_s\": 9.586543083190918}", "{\"n\": 14791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.1, \"learn_time_ms\": 8531.494, \"total_train_time_s\": 10.546188831329346}", "{\"n\": 14792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.23, \"learn_time_ms\": 8669.382, \"total_train_time_s\": 11.58356761932373}", "{\"n\": 14793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.48, \"learn_time_ms\": 8401.737, \"total_train_time_s\": 8.505157947540283}", "{\"n\": 14794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.35, \"learn_time_ms\": 8293.196, \"total_train_time_s\": 9.331928253173828}", "{\"n\": 14795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.36, \"learn_time_ms\": 8439.489, \"total_train_time_s\": 10.427392482757568}", "{\"n\": 14796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.59, \"learn_time_ms\": 8453.481, \"total_train_time_s\": 9.808916091918945}", "{\"n\": 14797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.5, \"learn_time_ms\": 8394.945, \"total_train_time_s\": 8.723889112472534}", "{\"n\": 14798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.02, \"learn_time_ms\": 8298.064, \"total_train_time_s\": 9.064345359802246}", "{\"n\": 14799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.21, \"learn_time_ms\": 8280.137, \"total_train_time_s\": 9.252073049545288}", "{\"n\": 14800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.32, \"learn_time_ms\": 8183.412, \"total_train_time_s\": 8.654256105422974}", "{\"n\": 14801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.32, \"learn_time_ms\": 8222.641, \"total_train_time_s\": 10.917535543441772}", "{\"n\": 14802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.18, \"learn_time_ms\": 8007.894, \"total_train_time_s\": 9.454664468765259}", "{\"n\": 14803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.64, \"learn_time_ms\": 8145.76, \"total_train_time_s\": 9.887771844863892}", "{\"n\": 14804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.64, \"learn_time_ms\": 8223.407, \"total_train_time_s\": 10.075094938278198}", "{\"n\": 14805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.99, \"learn_time_ms\": 8089.954, \"total_train_time_s\": 9.04720687866211}", "{\"n\": 14806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.17, \"learn_time_ms\": 8151.464, \"total_train_time_s\": 10.409407138824463}", "{\"n\": 14807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.78, \"learn_time_ms\": 8308.457, \"total_train_time_s\": 10.29645848274231}", "{\"n\": 14808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.87, \"learn_time_ms\": 8457.742, \"total_train_time_s\": 10.534587144851685}", "{\"n\": 14809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.43, \"learn_time_ms\": 8423.16, \"total_train_time_s\": 8.877643823623657}", "{\"n\": 14810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.05, \"learn_time_ms\": 8479.76, \"total_train_time_s\": 9.18079137802124}", "{\"n\": 14811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.05, \"learn_time_ms\": 8476.685, \"total_train_time_s\": 10.975465536117554}", "{\"n\": 14812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.54, \"learn_time_ms\": 8536.312, \"total_train_time_s\": 10.04562783241272}", "{\"n\": 14813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.54, \"learn_time_ms\": 8497.985, \"total_train_time_s\": 9.493088483810425}", "{\"n\": 14814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.16, \"learn_time_ms\": 8471.533, \"total_train_time_s\": 9.842097997665405}", "{\"n\": 14815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.75, \"learn_time_ms\": 8680.328, \"total_train_time_s\": 11.123480796813965}", "{\"n\": 14816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.75, \"learn_time_ms\": 8632.788, \"total_train_time_s\": 9.922765731811523}", "{\"n\": 14817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.34, \"learn_time_ms\": 8658.025, \"total_train_time_s\": 10.581099510192871}", "{\"n\": 14818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.73, \"learn_time_ms\": 8616.818, \"total_train_time_s\": 10.159318447113037}", "{\"n\": 14819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.73, \"learn_time_ms\": 8751.909, \"total_train_time_s\": 10.294200897216797}", "{\"n\": 14820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.21, \"learn_time_ms\": 8829.5, \"total_train_time_s\": 9.972164869308472}", "{\"n\": 14821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.59, \"learn_time_ms\": 8539.273, \"total_train_time_s\": 7.997218608856201}", "{\"n\": 14822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.47, \"learn_time_ms\": 8541.113, \"total_train_time_s\": 10.025366306304932}", "{\"n\": 14823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.58, \"learn_time_ms\": 8537.969, \"total_train_time_s\": 9.523938179016113}", "{\"n\": 14824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.65, \"learn_time_ms\": 8596.574, \"total_train_time_s\": 10.457962274551392}", "{\"n\": 14825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.89, \"learn_time_ms\": 8465.876, \"total_train_time_s\": 9.844281673431396}", "{\"n\": 14826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.89, \"learn_time_ms\": 8457.012, \"total_train_time_s\": 9.856976747512817}", "{\"n\": 14827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.56, \"learn_time_ms\": 8517.174, \"total_train_time_s\": 11.161767721176147}", "{\"n\": 14828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.69, \"learn_time_ms\": 8538.687, \"total_train_time_s\": 10.330965280532837}", "{\"n\": 14829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 8543.748, \"total_train_time_s\": 10.30981159210205}", "{\"n\": 14830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 8609.925, \"total_train_time_s\": 10.586589097976685}", "{\"n\": 14831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.16, \"learn_time_ms\": 8580.315, \"total_train_time_s\": 7.72646689414978}", "{\"n\": 14832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.16, \"learn_time_ms\": 8578.012, \"total_train_time_s\": 10.047491788864136}", "{\"n\": 14833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.38, \"learn_time_ms\": 8555.301, \"total_train_time_s\": 9.264262199401855}", "{\"n\": 14834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.98, \"learn_time_ms\": 8563.669, \"total_train_time_s\": 10.522422313690186}", "{\"n\": 14835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.64, \"learn_time_ms\": 8609.046, \"total_train_time_s\": 10.310014486312866}", "{\"n\": 14836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.35, \"learn_time_ms\": 8660.1, \"total_train_time_s\": 10.40720248222351}", "{\"n\": 14837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.34, \"learn_time_ms\": 8501.867, \"total_train_time_s\": 9.622704267501831}", "{\"n\": 14838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.34, \"learn_time_ms\": 8594.431, \"total_train_time_s\": 11.223990440368652}", "{\"n\": 14839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.34, \"learn_time_ms\": 8631.448, \"total_train_time_s\": 10.711275577545166}", "{\"n\": 14840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.41, \"learn_time_ms\": 8508.525, \"total_train_time_s\": 9.440279960632324}", "{\"n\": 14841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.84, \"learn_time_ms\": 8742.738, \"total_train_time_s\": 10.046539783477783}", "{\"n\": 14842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.84, \"learn_time_ms\": 8656.617, \"total_train_time_s\": 9.128117322921753}", "{\"n\": 14843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.24, \"learn_time_ms\": 8675.02, \"total_train_time_s\": 9.428333520889282}", "{\"n\": 14844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.16, \"learn_time_ms\": 8701.007, \"total_train_time_s\": 10.801458358764648}", "{\"n\": 14845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.59, \"learn_time_ms\": 8654.672, \"total_train_time_s\": 9.90110731124878}", "{\"n\": 14846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.59, \"learn_time_ms\": 8669.026, \"total_train_time_s\": 10.531857013702393}", "{\"n\": 14847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.77, \"learn_time_ms\": 8613.701, \"total_train_time_s\": 9.023498773574829}", "{\"n\": 14848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.85, \"learn_time_ms\": 8491.643, \"total_train_time_s\": 10.026653528213501}", "{\"n\": 14849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.85, \"learn_time_ms\": 8482.052, \"total_train_time_s\": 10.587730407714844}", "{\"n\": 14850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.53, \"learn_time_ms\": 8522.011, \"total_train_time_s\": 9.821098566055298}", "{\"n\": 14851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.42, \"learn_time_ms\": 8446.661, \"total_train_time_s\": 9.323966979980469}", "{\"n\": 14852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.88, \"learn_time_ms\": 8501.209, \"total_train_time_s\": 9.696256637573242}", "{\"n\": 14853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.88, \"learn_time_ms\": 8441.48, \"total_train_time_s\": 8.805911540985107}", "{\"n\": 14854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.94, \"learn_time_ms\": 8476.26, \"total_train_time_s\": 11.136037588119507}", "{\"n\": 14855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.7, \"learn_time_ms\": 8689.229, \"total_train_time_s\": 11.93002700805664}", "{\"n\": 14856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.7, \"learn_time_ms\": 8662.55, \"total_train_time_s\": 10.256945133209229}", "{\"n\": 14857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.82, \"learn_time_ms\": 8875.536, \"total_train_time_s\": 11.177391290664673}", "{\"n\": 14858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.63, \"learn_time_ms\": 8985.86, \"total_train_time_s\": 11.090907335281372}", "{\"n\": 14859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.63, \"learn_time_ms\": 8825.329, \"total_train_time_s\": 8.977042198181152}", "{\"n\": 14860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.7, \"learn_time_ms\": 8828.3, \"total_train_time_s\": 9.826635122299194}", "{\"n\": 14861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.7, \"learn_time_ms\": 9001.627, \"total_train_time_s\": 11.039846658706665}", "{\"n\": 14862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.37, \"learn_time_ms\": 9006.878, \"total_train_time_s\": 9.750910997390747}", "{\"n\": 14863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.37, \"learn_time_ms\": 9139.028, \"total_train_time_s\": 10.14885425567627}", "{\"n\": 14864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.61, \"learn_time_ms\": 8840.894, \"total_train_time_s\": 8.17911171913147}", "{\"n\": 14865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.21, \"learn_time_ms\": 8682.352, \"total_train_time_s\": 10.354336023330688}", "{\"n\": 14866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.21, \"learn_time_ms\": 8638.459, \"total_train_time_s\": 9.792774677276611}", "{\"n\": 14867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.4, \"learn_time_ms\": 8347.45, \"total_train_time_s\": 8.294002771377563}", "{\"n\": 14868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.69, \"learn_time_ms\": 8308.994, \"total_train_time_s\": 10.796120166778564}", "{\"n\": 14869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.04, \"learn_time_ms\": 8605.514, \"total_train_time_s\": 11.978964567184448}", "{\"n\": 14870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.26, \"learn_time_ms\": 8597.399, \"total_train_time_s\": 9.773310661315918}", "{\"n\": 14871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.06, \"learn_time_ms\": 8545.322, \"total_train_time_s\": 10.56140947341919}", "{\"n\": 14872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.35, \"learn_time_ms\": 8492.238, \"total_train_time_s\": 9.231518507003784}", "{\"n\": 14873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.11, \"learn_time_ms\": 8368.286, \"total_train_time_s\": 8.925463199615479}", "{\"n\": 14874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.83, \"learn_time_ms\": 8492.615, \"total_train_time_s\": 9.420533180236816}", "{\"n\": 14875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.83, \"learn_time_ms\": 8489.146, \"total_train_time_s\": 10.304868698120117}", "{\"n\": 14876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.25, \"learn_time_ms\": 8484.219, \"total_train_time_s\": 9.739221572875977}", "{\"n\": 14877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.0, \"learn_time_ms\": 8662.83, \"total_train_time_s\": 10.080469846725464}", "{\"n\": 14878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.0, \"learn_time_ms\": 8509.856, \"total_train_time_s\": 9.193905353546143}", "{\"n\": 14879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.9, \"learn_time_ms\": 8289.355, \"total_train_time_s\": 9.758247375488281}", "{\"n\": 14880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.95, \"learn_time_ms\": 8413.423, \"total_train_time_s\": 10.99562120437622}", "{\"n\": 14881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.01, \"learn_time_ms\": 8566.464, \"total_train_time_s\": 12.07129430770874}", "{\"n\": 14882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.01, \"learn_time_ms\": 8683.536, \"total_train_time_s\": 10.368497848510742}", "{\"n\": 14883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.75, \"learn_time_ms\": 8743.838, \"total_train_time_s\": 9.470959663391113}", "{\"n\": 14884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.55, \"learn_time_ms\": 8831.034, \"total_train_time_s\": 10.317006587982178}", "{\"n\": 14885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.21, \"learn_time_ms\": 8800.452, \"total_train_time_s\": 10.022729396820068}", "{\"n\": 14886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.76, \"learn_time_ms\": 8976.558, \"total_train_time_s\": 11.500165462493896}", "{\"n\": 14887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.77, \"learn_time_ms\": 9059.725, \"total_train_time_s\": 10.865579843521118}", "{\"n\": 14888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.77, \"learn_time_ms\": 9104.257, \"total_train_time_s\": 9.650026082992554}", "{\"n\": 14889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.24, \"learn_time_ms\": 9094.682, \"total_train_time_s\": 9.664594173431396}", "{\"n\": 14890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.24, \"learn_time_ms\": 8986.517, \"total_train_time_s\": 9.87320852279663}", "{\"n\": 14891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.49, \"learn_time_ms\": 8715.557, \"total_train_time_s\": 9.389723300933838}", "{\"n\": 14892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.61, \"learn_time_ms\": 8638.278, \"total_train_time_s\": 9.628277063369751}", "{\"n\": 14893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.91, \"learn_time_ms\": 8612.402, \"total_train_time_s\": 9.270341634750366}", "{\"n\": 14894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.91, \"learn_time_ms\": 8520.405, \"total_train_time_s\": 9.363514423370361}", "{\"n\": 14895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.02, \"learn_time_ms\": 8565.545, \"total_train_time_s\": 10.454564094543457}", "{\"n\": 14896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.83, \"learn_time_ms\": 8291.748, \"total_train_time_s\": 8.753755807876587}", "{\"n\": 14897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.63, \"learn_time_ms\": 8157.304, \"total_train_time_s\": 9.491411209106445}", "{\"n\": 14898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.37, \"learn_time_ms\": 8184.939, \"total_train_time_s\": 9.916057348251343}", "{\"n\": 14899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.74, \"learn_time_ms\": 8278.136, \"total_train_time_s\": 10.544319868087769}", "{\"n\": 14900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.14, \"learn_time_ms\": 8202.626, \"total_train_time_s\": 9.137796878814697}", "{\"n\": 14901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.61, \"learn_time_ms\": 8282.097, \"total_train_time_s\": 10.143758773803711}", "{\"n\": 14902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.08, \"learn_time_ms\": 8430.942, \"total_train_time_s\": 11.114720106124878}", "{\"n\": 14903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.08, \"learn_time_ms\": 8445.891, \"total_train_time_s\": 9.386685848236084}", "{\"n\": 14904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.41, \"learn_time_ms\": 8530.18, \"total_train_time_s\": 10.147175788879395}", "{\"n\": 14905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.41, \"learn_time_ms\": 8388.144, \"total_train_time_s\": 9.110824823379517}", "{\"n\": 14906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.67, \"learn_time_ms\": 8593.541, \"total_train_time_s\": 10.812740087509155}", "{\"n\": 14907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.27, \"learn_time_ms\": 8651.066, \"total_train_time_s\": 10.092994451522827}", "{\"n\": 14908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.32, \"learn_time_ms\": 8486.468, \"total_train_time_s\": 8.254957675933838}", "{\"n\": 14909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.51, \"learn_time_ms\": 8383.449, \"total_train_time_s\": 9.5677011013031}", "{\"n\": 14910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.26, \"learn_time_ms\": 8603.94, \"total_train_time_s\": 11.374521970748901}", "{\"n\": 14911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.04, \"learn_time_ms\": 8502.319, \"total_train_time_s\": 9.15140986442566}", "{\"n\": 14912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.04, \"learn_time_ms\": 8420.997, \"total_train_time_s\": 10.365001678466797}", "{\"n\": 14913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.47, \"learn_time_ms\": 8412.66, \"total_train_time_s\": 9.370776414871216}", "{\"n\": 14914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.44, \"learn_time_ms\": 8383.771, \"total_train_time_s\": 9.863595962524414}", "{\"n\": 14915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.44, \"learn_time_ms\": 8461.115, \"total_train_time_s\": 9.842388153076172}", "{\"n\": 14916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.63, \"learn_time_ms\": 8498.0, \"total_train_time_s\": 11.20615267753601}", "{\"n\": 14917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.67, \"learn_time_ms\": 8453.355, \"total_train_time_s\": 9.678088426589966}", "{\"n\": 14918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.67, \"learn_time_ms\": 8751.937, \"total_train_time_s\": 11.232958555221558}", "{\"n\": 14919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.67, \"learn_time_ms\": 8725.143, \"total_train_time_s\": 9.278141260147095}", "{\"n\": 14920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.61, \"learn_time_ms\": 8610.137, \"total_train_time_s\": 10.218009233474731}", "{\"n\": 14921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.64, \"learn_time_ms\": 8674.892, \"total_train_time_s\": 9.81469988822937}", "{\"n\": 14922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.64, \"learn_time_ms\": 8565.286, \"total_train_time_s\": 9.256192922592163}", "{\"n\": 14923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.46, \"learn_time_ms\": 8585.156, \"total_train_time_s\": 9.536067485809326}", "{\"n\": 14924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.16, \"learn_time_ms\": 8465.799, \"total_train_time_s\": 8.712260246276855}", "{\"n\": 14925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.16, \"learn_time_ms\": 8432.194, \"total_train_time_s\": 9.484207153320312}", "{\"n\": 14926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.61, \"learn_time_ms\": 8280.349, \"total_train_time_s\": 9.679767370223999}", "{\"n\": 14927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.6, \"learn_time_ms\": 8362.356, \"total_train_time_s\": 10.488024950027466}", "{\"n\": 14928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.04, \"learn_time_ms\": 8284.195, \"total_train_time_s\": 10.539249420166016}", "{\"n\": 14929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.04, \"learn_time_ms\": 8386.891, \"total_train_time_s\": 10.332223892211914}", "{\"n\": 14930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.43, \"learn_time_ms\": 8310.128, \"total_train_time_s\": 9.434699535369873}", "{\"n\": 14931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.83, \"learn_time_ms\": 8294.304, \"total_train_time_s\": 9.587849140167236}", "{\"n\": 14932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.83, \"learn_time_ms\": 8211.421, \"total_train_time_s\": 8.375236988067627}", "{\"n\": 14933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.1, \"learn_time_ms\": 8132.028, \"total_train_time_s\": 8.721805095672607}", "{\"n\": 14934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.65, \"learn_time_ms\": 8231.046, \"total_train_time_s\": 9.728875637054443}", "{\"n\": 14935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.65, \"learn_time_ms\": 8236.644, \"total_train_time_s\": 9.511484861373901}", "{\"n\": 14936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.65, \"learn_time_ms\": 8364.88, \"total_train_time_s\": 11.006696462631226}", "{\"n\": 14937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.94, \"learn_time_ms\": 8198.821, \"total_train_time_s\": 8.866743803024292}", "{\"n\": 14938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.94, \"learn_time_ms\": 8191.37, \"total_train_time_s\": 10.421876192092896}", "{\"n\": 14939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.94, \"learn_time_ms\": 8094.526, \"total_train_time_s\": 9.311182260513306}", "{\"n\": 14940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.61, \"learn_time_ms\": 8151.848, \"total_train_time_s\": 10.014286518096924}", "{\"n\": 14941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.17, \"learn_time_ms\": 8173.673, \"total_train_time_s\": 9.839257955551147}", "{\"n\": 14942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.17, \"learn_time_ms\": 8305.879, \"total_train_time_s\": 9.701029777526855}", "{\"n\": 14943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.17, \"learn_time_ms\": 8469.461, \"total_train_time_s\": 10.41208004951477}", "{\"n\": 14944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.3, \"learn_time_ms\": 8343.849, \"total_train_time_s\": 8.444204330444336}", "{\"n\": 14945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.3, \"learn_time_ms\": 8336.817, \"total_train_time_s\": 9.435739755630493}", "{\"n\": 14946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.89, \"learn_time_ms\": 8119.271, \"total_train_time_s\": 8.799884557723999}", "{\"n\": 14947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.61, \"learn_time_ms\": 8302.199, \"total_train_time_s\": 10.65869951248169}", "{\"n\": 14948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.11, \"learn_time_ms\": 8258.658, \"total_train_time_s\": 9.993142366409302}", "{\"n\": 14949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.11, \"learn_time_ms\": 8237.384, \"total_train_time_s\": 9.104863166809082}", "{\"n\": 14950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.11, \"learn_time_ms\": 8275.595, \"total_train_time_s\": 10.409846305847168}", "{\"n\": 14951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.95, \"learn_time_ms\": 8213.219, \"total_train_time_s\": 9.233041048049927}", "{\"n\": 14952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.95, \"learn_time_ms\": 8358.492, \"total_train_time_s\": 11.132099866867065}", "{\"n\": 14953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.95, \"learn_time_ms\": 8311.394, \"total_train_time_s\": 9.898720741271973}", "{\"n\": 14954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.26, \"learn_time_ms\": 8467.486, \"total_train_time_s\": 9.983650207519531}", "{\"n\": 14955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.26, \"learn_time_ms\": 8478.189, \"total_train_time_s\": 9.569584369659424}", "{\"n\": 14956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.26, \"learn_time_ms\": 8560.915, \"total_train_time_s\": 9.609862565994263}", "{\"n\": 14957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.69, \"learn_time_ms\": 8538.407, \"total_train_time_s\": 10.471437215805054}", "{\"n\": 14958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.05, \"learn_time_ms\": 8538.475, \"total_train_time_s\": 9.991150140762329}", "{\"n\": 14959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.05, \"learn_time_ms\": 8601.64, \"total_train_time_s\": 9.742061853408813}", "{\"n\": 14960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.46, \"learn_time_ms\": 8475.175, \"total_train_time_s\": 9.134023904800415}", "{\"n\": 14961, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.51, \"learn_time_ms\": 8679.884, \"total_train_time_s\": 11.261717081069946}", "{\"n\": 14962, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.51, \"learn_time_ms\": 8707.025, \"total_train_time_s\": 11.438267707824707}", "{\"n\": 14963, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.86, \"learn_time_ms\": 8716.777, \"total_train_time_s\": 10.000208616256714}", "{\"n\": 14964, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.57, \"learn_time_ms\": 8694.505, \"total_train_time_s\": 9.83925724029541}", "{\"n\": 14965, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.57, \"learn_time_ms\": 8693.632, \"total_train_time_s\": 9.573138236999512}", "{\"n\": 14966, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.57, \"learn_time_ms\": 8718.961, \"total_train_time_s\": 9.86714768409729}", "{\"n\": 14967, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.68, \"learn_time_ms\": 8569.809, \"total_train_time_s\": 8.941402435302734}", "{\"n\": 14968, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.1, \"learn_time_ms\": 8669.716, \"total_train_time_s\": 10.969395160675049}", "{\"n\": 14969, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.1, \"learn_time_ms\": 8685.006, \"total_train_time_s\": 9.96385931968689}", "{\"n\": 14970, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.8, \"learn_time_ms\": 8643.691, \"total_train_time_s\": 8.700451374053955}", "{\"n\": 14971, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.91, \"learn_time_ms\": 8539.495, \"total_train_time_s\": 10.23197627067566}", "{\"n\": 14972, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.91, \"learn_time_ms\": 8288.188, \"total_train_time_s\": 8.934234380722046}", "{\"n\": 14973, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.91, \"learn_time_ms\": 8250.436, \"total_train_time_s\": 9.630065441131592}", "{\"n\": 14974, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.48, \"learn_time_ms\": 8286.379, \"total_train_time_s\": 10.142659187316895}", "{\"n\": 14975, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.86, \"learn_time_ms\": 8479.758, \"total_train_time_s\": 11.542969703674316}", "{\"n\": 14976, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.86, \"learn_time_ms\": 8389.982, \"total_train_time_s\": 8.950467109680176}", "{\"n\": 14977, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.73, \"learn_time_ms\": 8389.623, \"total_train_time_s\": 8.938069820404053}", "{\"n\": 14978, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.62, \"learn_time_ms\": 8279.878, \"total_train_time_s\": 9.923243999481201}", "{\"n\": 14979, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.62, \"learn_time_ms\": 8283.28, \"total_train_time_s\": 9.953703165054321}", "{\"n\": 14980, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.62, \"learn_time_ms\": 8319.595, \"total_train_time_s\": 9.047272443771362}", "{\"n\": 14981, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.45, \"learn_time_ms\": 8217.47, \"total_train_time_s\": 9.208583116531372}", "{\"n\": 14982, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.45, \"learn_time_ms\": 8284.234, \"total_train_time_s\": 9.55432391166687}", "{\"n\": 14983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.45, \"learn_time_ms\": 8352.734, \"total_train_time_s\": 10.277292013168335}", "{\"n\": 14984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.74, \"learn_time_ms\": 8279.595, \"total_train_time_s\": 9.400664806365967}", "{\"n\": 14985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.7, \"learn_time_ms\": 8130.403, \"total_train_time_s\": 10.024182319641113}", "{\"n\": 14986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.7, \"learn_time_ms\": 8215.703, \"total_train_time_s\": 9.842294216156006}", "{\"n\": 14987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.63, \"learn_time_ms\": 8408.112, \"total_train_time_s\": 10.84151315689087}", "{\"n\": 14988, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.56, \"learn_time_ms\": 8447.562, \"total_train_time_s\": 10.279754638671875}", "{\"n\": 14989, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.56, \"learn_time_ms\": 8356.32, \"total_train_time_s\": 9.03524112701416}", "{\"n\": 14990, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.41, \"learn_time_ms\": 8421.66, \"total_train_time_s\": 9.75017523765564}", "{\"n\": 14991, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.58, \"learn_time_ms\": 8564.188, \"total_train_time_s\": 10.66630244255066}", "{\"n\": 14992, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.87, \"learn_time_ms\": 8459.078, \"total_train_time_s\": 8.544998407363892}", "{\"n\": 14993, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.87, \"learn_time_ms\": 8376.699, \"total_train_time_s\": 9.434369325637817}", "{\"n\": 14994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.29, \"learn_time_ms\": 8335.04, \"total_train_time_s\": 8.99916386604309}", "{\"n\": 14995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.29, \"learn_time_ms\": 8411.276, \"total_train_time_s\": 10.814201354980469}", "{\"n\": 14996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.54, \"learn_time_ms\": 8477.773, \"total_train_time_s\": 10.489955186843872}", "{\"n\": 14997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.19, \"learn_time_ms\": 8445.953, \"total_train_time_s\": 10.521115779876709}", "{\"n\": 14998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.86, \"learn_time_ms\": 8458.618, \"total_train_time_s\": 10.412320852279663}", "{\"n\": 14999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.51, \"learn_time_ms\": 8630.751, \"total_train_time_s\": 10.773674964904785}", "{\"n\": 15000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.51, \"learn_time_ms\": 8786.362, \"total_train_time_s\": 11.317261457443237}", "{\"n\": 15001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.62, \"learn_time_ms\": 8649.259, \"total_train_time_s\": 9.24968957901001}", "{\"n\": 15002, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.88, \"learn_time_ms\": 8743.93, \"total_train_time_s\": 9.506244659423828}", "{\"n\": 15003, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.88, \"learn_time_ms\": 8675.21, \"total_train_time_s\": 8.744791030883789}", "{\"n\": 15004, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.13, \"learn_time_ms\": 8887.667, \"total_train_time_s\": 11.12826919555664}", "{\"n\": 15005, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.23, \"learn_time_ms\": 8848.099, \"total_train_time_s\": 10.394454002380371}", "{\"n\": 15006, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.38, \"learn_time_ms\": 8957.063, \"total_train_time_s\": 11.578036546707153}", "{\"n\": 15007, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.62, \"learn_time_ms\": 8996.483, \"total_train_time_s\": 10.976133346557617}", "{\"n\": 15008, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.43, \"learn_time_ms\": 8931.312, \"total_train_time_s\": 9.738380670547485}", "{\"n\": 15009, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.09, \"learn_time_ms\": 8859.821, \"total_train_time_s\": 10.10196828842163}", "{\"n\": 15010, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.01, \"learn_time_ms\": 8742.294, \"total_train_time_s\": 10.10152554512024}", "{\"n\": 15011, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.02, \"learn_time_ms\": 8781.816, \"total_train_time_s\": 9.64285922050476}", "{\"n\": 15012, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.96, \"learn_time_ms\": 8904.653, \"total_train_time_s\": 10.717783689498901}", "{\"n\": 15013, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.08, \"learn_time_ms\": 9001.928, \"total_train_time_s\": 9.79788088798523}", "{\"n\": 15014, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.91, \"learn_time_ms\": 8933.509, \"total_train_time_s\": 10.457891702651978}", "{\"n\": 15015, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.56, \"learn_time_ms\": 8826.187, \"total_train_time_s\": 9.345447778701782}", "{\"n\": 15016, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.2, \"learn_time_ms\": 8680.002, \"total_train_time_s\": 10.188813209533691}", "{\"n\": 15017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.32, \"learn_time_ms\": 8426.37, \"total_train_time_s\": 8.460743188858032}", "{\"n\": 15018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.92, \"learn_time_ms\": 8448.546, \"total_train_time_s\": 10.00685739517212}", "{\"n\": 15019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.98, \"learn_time_ms\": 8602.955, \"total_train_time_s\": 11.595743179321289}", "{\"n\": 15020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.91, \"learn_time_ms\": 8523.064, \"total_train_time_s\": 9.285334825515747}", "{\"n\": 15021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.14, \"learn_time_ms\": 8641.351, \"total_train_time_s\": 10.879894256591797}", "{\"n\": 15022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.73, \"learn_time_ms\": 8571.059, \"total_train_time_s\": 10.001394033432007}", "{\"n\": 15023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.8, \"learn_time_ms\": 8628.023, \"total_train_time_s\": 10.317326068878174}", "{\"n\": 15024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.25, \"learn_time_ms\": 8559.242, \"total_train_time_s\": 9.768717765808105}", "{\"n\": 15025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.25, \"learn_time_ms\": 8768.2, \"total_train_time_s\": 11.414003372192383}", "{\"n\": 15026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.29, \"learn_time_ms\": 8679.761, \"total_train_time_s\": 9.200661182403564}", "{\"n\": 15027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 8943.917, \"total_train_time_s\": 11.00159502029419}", "{\"n\": 15028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.62, \"learn_time_ms\": 8983.674, \"total_train_time_s\": 10.324946641921997}", "{\"n\": 15029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.62, \"learn_time_ms\": 8797.433, \"total_train_time_s\": 9.756320714950562}", "{\"n\": 15030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.99, \"learn_time_ms\": 8900.373, \"total_train_time_s\": 10.39773678779602}", "{\"n\": 15031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.99, \"learn_time_ms\": 8681.504, \"total_train_time_s\": 8.676792860031128}", "{\"n\": 15032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.62, \"learn_time_ms\": 8735.189, \"total_train_time_s\": 10.564987182617188}", "{\"n\": 15033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.32, \"learn_time_ms\": 8665.773, \"total_train_time_s\": 9.647468566894531}", "{\"n\": 15034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.06, \"learn_time_ms\": 8676.652, \"total_train_time_s\": 9.843779563903809}", "{\"n\": 15035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.46, \"learn_time_ms\": 8429.407, \"total_train_time_s\": 8.89702820777893}", "{\"n\": 15036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.46, \"learn_time_ms\": 8333.119, \"total_train_time_s\": 8.275268077850342}", "{\"n\": 15037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.68, \"learn_time_ms\": 8090.439, \"total_train_time_s\": 8.564337253570557}", "{\"n\": 15038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.6, \"learn_time_ms\": 8123.797, \"total_train_time_s\": 10.676998853683472}", "{\"n\": 15039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.6, \"learn_time_ms\": 8141.604, \"total_train_time_s\": 9.85540246963501}", "{\"n\": 15040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.57, \"learn_time_ms\": 8098.566, \"total_train_time_s\": 9.903562068939209}", "{\"n\": 15041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.57, \"learn_time_ms\": 8248.154, \"total_train_time_s\": 10.101203680038452}", "{\"n\": 15042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.33, \"learn_time_ms\": 8076.926, \"total_train_time_s\": 8.82347059249878}", "{\"n\": 15043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.02, \"learn_time_ms\": 8073.442, \"total_train_time_s\": 9.628515720367432}", "{\"n\": 15044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.1, \"learn_time_ms\": 7985.275, \"total_train_time_s\": 8.99104642868042}", "{\"n\": 15045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.33, \"learn_time_ms\": 8068.218, \"total_train_time_s\": 9.732625246047974}", "{\"n\": 15046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.17, \"learn_time_ms\": 8160.387, \"total_train_time_s\": 9.194897413253784}", "{\"n\": 15047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.8, \"learn_time_ms\": 8296.622, \"total_train_time_s\": 9.989929437637329}", "{\"n\": 15048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.37, \"learn_time_ms\": 8077.135, \"total_train_time_s\": 8.489066362380981}", "{\"n\": 15049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.58, \"learn_time_ms\": 8181.735, \"total_train_time_s\": 10.948435068130493}", "{\"n\": 15050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.28, \"learn_time_ms\": 8188.376, \"total_train_time_s\": 9.980540037155151}", "{\"n\": 15051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.49, \"learn_time_ms\": 8225.546, \"total_train_time_s\": 10.514957189559937}", "{\"n\": 15052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.49, \"learn_time_ms\": 8303.932, \"total_train_time_s\": 9.609078168869019}", "{\"n\": 15053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.16, \"learn_time_ms\": 8287.255, \"total_train_time_s\": 9.483154296875}", "{\"n\": 15054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.91, \"learn_time_ms\": 8378.719, \"total_train_time_s\": 9.894434452056885}", "{\"n\": 15055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.91, \"learn_time_ms\": 8447.253, \"total_train_time_s\": 10.41674518585205}", "{\"n\": 15056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.86, \"learn_time_ms\": 8440.174, \"total_train_time_s\": 9.10526156425476}", "{\"n\": 15057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.13, \"learn_time_ms\": 8453.277, \"total_train_time_s\": 10.089757680892944}", "{\"n\": 15058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.13, \"learn_time_ms\": 8576.359, \"total_train_time_s\": 9.725037574768066}", "{\"n\": 15059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.78, \"learn_time_ms\": 8592.644, \"total_train_time_s\": 11.098512411117554}", "{\"n\": 15060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.7, \"learn_time_ms\": 8631.876, \"total_train_time_s\": 10.412580966949463}", "{\"n\": 15061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.7, \"learn_time_ms\": 8526.454, \"total_train_time_s\": 9.493635177612305}", "{\"n\": 15062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.37, \"learn_time_ms\": 8483.089, \"total_train_time_s\": 9.222844362258911}", "{\"n\": 15063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.06, \"learn_time_ms\": 8510.241, \"total_train_time_s\": 9.738234281539917}", "{\"n\": 15064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.39, \"learn_time_ms\": 8556.314, \"total_train_time_s\": 10.352904319763184}", "{\"n\": 15065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.78, \"learn_time_ms\": 8449.981, \"total_train_time_s\": 9.357902765274048}", "{\"n\": 15066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.78, \"learn_time_ms\": 8676.367, \"total_train_time_s\": 11.371641159057617}", "{\"n\": 15067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.29, \"learn_time_ms\": 8742.463, \"total_train_time_s\": 10.777528047561646}", "{\"n\": 15068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.29, \"learn_time_ms\": 8739.993, \"total_train_time_s\": 9.702202081680298}", "{\"n\": 15069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.53, \"learn_time_ms\": 8615.93, \"total_train_time_s\": 9.889550924301147}", "{\"n\": 15070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.82, \"learn_time_ms\": 8679.825, \"total_train_time_s\": 11.001635789871216}", "{\"n\": 15071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.82, \"learn_time_ms\": 8792.529, \"total_train_time_s\": 10.608630180358887}", "{\"n\": 15072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.41, \"learn_time_ms\": 8807.777, \"total_train_time_s\": 9.348945140838623}", "{\"n\": 15073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.41, \"learn_time_ms\": 8845.21, \"total_train_time_s\": 10.112179517745972}", "{\"n\": 15074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.76, \"learn_time_ms\": 8837.475, \"total_train_time_s\": 10.310490131378174}", "{\"n\": 15075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.22, \"learn_time_ms\": 8810.974, \"total_train_time_s\": 9.102790594100952}", "{\"n\": 15076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.22, \"learn_time_ms\": 8659.484, \"total_train_time_s\": 9.881042718887329}", "{\"n\": 15077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.43, \"learn_time_ms\": 8559.642, \"total_train_time_s\": 9.77242660522461}", "{\"n\": 15078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.8, \"learn_time_ms\": 8613.963, \"total_train_time_s\": 10.293365478515625}", "{\"n\": 15079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.8, \"learn_time_ms\": 8703.424, \"total_train_time_s\": 10.793398380279541}", "{\"n\": 15080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.48, \"learn_time_ms\": 8555.515, \"total_train_time_s\": 9.512999296188354}", "{\"n\": 15081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.48, \"learn_time_ms\": 8439.389, \"total_train_time_s\": 9.413148403167725}", "{\"n\": 15082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.43, \"learn_time_ms\": 8655.372, \"total_train_time_s\": 11.503161907196045}", "{\"n\": 15083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.52, \"learn_time_ms\": 8618.307, \"total_train_time_s\": 9.7337327003479}", "{\"n\": 15084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.68, \"learn_time_ms\": 8626.809, \"total_train_time_s\": 10.333130359649658}", "{\"n\": 15085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.34, \"learn_time_ms\": 8759.234, \"total_train_time_s\": 10.43117356300354}", "{\"n\": 15086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.37, \"learn_time_ms\": 8800.772, \"total_train_time_s\": 10.283904075622559}", "{\"n\": 15087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.01, \"learn_time_ms\": 8785.113, \"total_train_time_s\": 9.604345560073853}", "{\"n\": 15088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.01, \"learn_time_ms\": 8722.932, \"total_train_time_s\": 9.603525638580322}", "{\"n\": 15089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.18, \"learn_time_ms\": 8735.42, \"total_train_time_s\": 10.88338041305542}", "{\"n\": 15090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.39, \"learn_time_ms\": 8849.977, \"total_train_time_s\": 10.681788206100464}", "{\"n\": 15091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.51, \"learn_time_ms\": 8984.604, \"total_train_time_s\": 10.792060852050781}", "{\"n\": 15092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.51, \"learn_time_ms\": 8812.249, \"total_train_time_s\": 9.77321481704712}", "{\"n\": 15093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.65, \"learn_time_ms\": 8913.936, \"total_train_time_s\": 10.74477767944336}", "{\"n\": 15094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.85, \"learn_time_ms\": 9007.55, \"total_train_time_s\": 11.292317628860474}", "{\"n\": 15095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.85, \"learn_time_ms\": 8933.468, \"total_train_time_s\": 9.717286825180054}", "{\"n\": 15096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.15, \"learn_time_ms\": 9046.48, \"total_train_time_s\": 11.397932767868042}", "{\"n\": 15097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.32, \"learn_time_ms\": 9081.34, \"total_train_time_s\": 9.920304775238037}", "{\"n\": 15098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.03, \"learn_time_ms\": 9164.022, \"total_train_time_s\": 10.479230165481567}", "{\"n\": 15099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.03, \"learn_time_ms\": 8930.64, \"total_train_time_s\": 8.592660188674927}", "{\"n\": 15100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.07, \"learn_time_ms\": 8857.047, \"total_train_time_s\": 9.970854759216309}", "{\"n\": 15101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.75, \"learn_time_ms\": 8737.13, \"total_train_time_s\": 9.610816240310669}", "{\"n\": 15102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.75, \"learn_time_ms\": 8766.037, \"total_train_time_s\": 10.059725284576416}", "{\"n\": 15103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.2, \"learn_time_ms\": 8603.409, \"total_train_time_s\": 9.109374284744263}", "{\"n\": 15104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.37, \"learn_time_ms\": 8501.577, \"total_train_time_s\": 10.289631366729736}", "{\"n\": 15105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.04, \"learn_time_ms\": 8485.169, \"total_train_time_s\": 9.547895669937134}", "{\"n\": 15106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.86, \"learn_time_ms\": 8329.821, \"total_train_time_s\": 9.899816989898682}", "{\"n\": 15107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.64, \"learn_time_ms\": 8364.955, \"total_train_time_s\": 10.284557819366455}", "{\"n\": 15108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.64, \"learn_time_ms\": 8276.514, \"total_train_time_s\": 9.562071800231934}", "{\"n\": 15109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.61, \"learn_time_ms\": 8379.092, \"total_train_time_s\": 9.61214566230774}", "{\"n\": 15110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 8332.361, \"total_train_time_s\": 9.472635984420776}", "{\"n\": 15111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 8415.34, \"total_train_time_s\": 10.371994972229004}", "{\"n\": 15112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.37, \"learn_time_ms\": 8374.476, \"total_train_time_s\": 9.65063190460205}", "{\"n\": 15113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.07, \"learn_time_ms\": 8453.025, \"total_train_time_s\": 9.889066696166992}", "{\"n\": 15114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.46, \"learn_time_ms\": 8468.453, \"total_train_time_s\": 10.467636823654175}", "{\"n\": 15115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.63, \"learn_time_ms\": 8499.765, \"total_train_time_s\": 9.880919694900513}", "{\"n\": 15116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.39, \"learn_time_ms\": 8533.214, \"total_train_time_s\": 10.229346513748169}", "{\"n\": 15117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.31, \"learn_time_ms\": 8336.844, \"total_train_time_s\": 8.310737371444702}", "{\"n\": 15118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.89, \"learn_time_ms\": 8346.029, \"total_train_time_s\": 9.645471096038818}", "{\"n\": 15119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.89, \"learn_time_ms\": 8289.29, \"total_train_time_s\": 9.022454261779785}", "{\"n\": 15120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.18, \"learn_time_ms\": 8232.754, \"total_train_time_s\": 8.890638828277588}", "{\"n\": 15121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.18, \"learn_time_ms\": 8072.688, \"total_train_time_s\": 8.841646909713745}", "{\"n\": 15122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.07, \"learn_time_ms\": 8127.946, \"total_train_time_s\": 10.197996854782104}", "{\"n\": 15123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.91, \"learn_time_ms\": 8242.084, \"total_train_time_s\": 11.077843427658081}", "{\"n\": 15124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.38, \"learn_time_ms\": 8244.568, \"total_train_time_s\": 10.452574491500854}", "{\"n\": 15125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.14, \"learn_time_ms\": 8282.601, \"total_train_time_s\": 10.257912874221802}", "{\"n\": 15126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.57, \"learn_time_ms\": 8248.069, \"total_train_time_s\": 9.837865591049194}", "{\"n\": 15127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.13, \"learn_time_ms\": 8326.955, \"total_train_time_s\": 9.12274169921875}", "{\"n\": 15128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.98, \"learn_time_ms\": 8555.006, \"total_train_time_s\": 11.943821668624878}", "{\"n\": 15129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.1, \"learn_time_ms\": 8679.417, \"total_train_time_s\": 10.287675619125366}", "{\"n\": 15130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.32, \"learn_time_ms\": 8727.819, \"total_train_time_s\": 9.390812158584595}", "{\"n\": 15131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.99, \"learn_time_ms\": 8864.331, \"total_train_time_s\": 10.180391073226929}", "{\"n\": 15132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.57, \"learn_time_ms\": 8823.848, \"total_train_time_s\": 9.842841386795044}", "{\"n\": 15133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 8833.582, \"total_train_time_s\": 11.147480249404907}", "{\"n\": 15134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.23, \"learn_time_ms\": 8880.835, \"total_train_time_s\": 10.907768964767456}", "{\"n\": 15135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.94, \"learn_time_ms\": 8831.711, \"total_train_time_s\": 9.786427974700928}", "{\"n\": 15136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.07, \"learn_time_ms\": 8885.877, \"total_train_time_s\": 10.42849612236023}", "{\"n\": 15137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.32, \"learn_time_ms\": 8983.519, \"total_train_time_s\": 10.094213008880615}", "{\"n\": 15138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.09, \"learn_time_ms\": 8728.123, \"total_train_time_s\": 9.399992942810059}", "{\"n\": 15139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.57, \"learn_time_ms\": 8744.139, \"total_train_time_s\": 10.485509157180786}", "{\"n\": 15140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.57, \"learn_time_ms\": 8788.86, \"total_train_time_s\": 9.842031478881836}", "{\"n\": 15141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.71, \"learn_time_ms\": 8734.391, \"total_train_time_s\": 9.654351711273193}", "{\"n\": 15142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.22, \"learn_time_ms\": 8698.119, \"total_train_time_s\": 9.436999559402466}", "{\"n\": 15143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.22, \"learn_time_ms\": 8633.687, \"total_train_time_s\": 10.441071510314941}", "{\"n\": 15144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.92, \"learn_time_ms\": 8507.928, \"total_train_time_s\": 9.654315948486328}", "{\"n\": 15145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.34, \"learn_time_ms\": 8639.568, \"total_train_time_s\": 11.071195125579834}", "{\"n\": 15146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.58, \"learn_time_ms\": 8802.398, \"total_train_time_s\": 12.003716468811035}", "{\"n\": 15147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.1, \"learn_time_ms\": 8869.512, \"total_train_time_s\": 10.763253211975098}", "{\"n\": 15148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.08, \"learn_time_ms\": 8972.916, \"total_train_time_s\": 10.453799486160278}", "{\"n\": 15149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.86, \"learn_time_ms\": 8943.574, \"total_train_time_s\": 10.144975423812866}", "{\"n\": 15150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.22, \"learn_time_ms\": 8936.492, \"total_train_time_s\": 9.778674840927124}", "{\"n\": 15151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.9, \"learn_time_ms\": 9029.908, \"total_train_time_s\": 10.538924932479858}", "{\"n\": 15152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.44, \"learn_time_ms\": 9185.76, \"total_train_time_s\": 11.001948118209839}", "{\"n\": 15153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.35, \"learn_time_ms\": 9121.116, \"total_train_time_s\": 9.876965999603271}", "{\"n\": 15154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.89, \"learn_time_ms\": 9156.2, \"total_train_time_s\": 9.999498844146729}", "{\"n\": 15155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.89, \"learn_time_ms\": 9177.181, \"total_train_time_s\": 11.270600080490112}", "{\"n\": 15156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.23, \"learn_time_ms\": 9019.206, \"total_train_time_s\": 10.426464319229126}", "{\"n\": 15157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.62, \"learn_time_ms\": 8924.821, \"total_train_time_s\": 9.813807249069214}", "{\"n\": 15158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.37, \"learn_time_ms\": 8888.258, \"total_train_time_s\": 10.085912227630615}", "{\"n\": 15159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.82, \"learn_time_ms\": 8978.543, \"total_train_time_s\": 11.08861255645752}", "{\"n\": 15160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.08, \"learn_time_ms\": 9087.357, \"total_train_time_s\": 10.89009976387024}", "{\"n\": 15161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.98, \"learn_time_ms\": 8946.232, \"total_train_time_s\": 9.188434839248657}", "{\"n\": 15162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.98, \"learn_time_ms\": 8749.617, \"total_train_time_s\": 9.027496576309204}", "{\"n\": 15163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.64, \"learn_time_ms\": 8747.988, \"total_train_time_s\": 9.800388813018799}", "{\"n\": 15164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.12, \"learn_time_ms\": 8770.727, \"total_train_time_s\": 10.196509838104248}", "{\"n\": 15165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.74, \"learn_time_ms\": 8579.809, \"total_train_time_s\": 9.363748550415039}", "{\"n\": 15166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.74, \"learn_time_ms\": 8619.259, \"total_train_time_s\": 10.8528733253479}", "{\"n\": 15167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.38, \"learn_time_ms\": 8579.483, \"total_train_time_s\": 9.464802265167236}", "{\"n\": 15168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.77, \"learn_time_ms\": 8637.946, \"total_train_time_s\": 10.675249099731445}", "{\"n\": 15169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.77, \"learn_time_ms\": 8617.166, \"total_train_time_s\": 10.794288873672485}", "{\"n\": 15170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.75, \"learn_time_ms\": 8495.244, \"total_train_time_s\": 9.676774263381958}", "{\"n\": 15171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.19, \"learn_time_ms\": 8400.835, \"total_train_time_s\": 8.21044397354126}", "{\"n\": 15172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.19, \"learn_time_ms\": 8500.426, \"total_train_time_s\": 9.988937377929688}", "{\"n\": 15173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.31, \"learn_time_ms\": 8495.234, \"total_train_time_s\": 9.764366626739502}", "{\"n\": 15174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.12, \"learn_time_ms\": 8456.733, \"total_train_time_s\": 9.856860637664795}", "{\"n\": 15175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.12, \"learn_time_ms\": 8507.418, \"total_train_time_s\": 9.874330043792725}", "{\"n\": 15176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.05, \"learn_time_ms\": 8391.625, \"total_train_time_s\": 9.693889856338501}", "{\"n\": 15177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.78, \"learn_time_ms\": 8386.168, \"total_train_time_s\": 9.405468940734863}", "{\"n\": 15178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.81, \"learn_time_ms\": 8210.941, \"total_train_time_s\": 8.886259317398071}", "{\"n\": 15179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.48, \"learn_time_ms\": 8117.945, \"total_train_time_s\": 9.906452417373657}", "{\"n\": 15180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.51, \"learn_time_ms\": 8117.135, \"total_train_time_s\": 9.64328646659851}", "{\"n\": 15181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.93, \"learn_time_ms\": 8302.219, \"total_train_time_s\": 10.048627853393555}", "{\"n\": 15182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.93, \"learn_time_ms\": 8358.804, \"total_train_time_s\": 10.573530197143555}", "{\"n\": 15183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.11, \"learn_time_ms\": 8394.928, \"total_train_time_s\": 10.15391206741333}", "{\"n\": 15184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.79, \"learn_time_ms\": 8524.819, \"total_train_time_s\": 11.145883560180664}", "{\"n\": 15185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 8612.08, \"total_train_time_s\": 10.732949256896973}", "{\"n\": 15186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.59, \"learn_time_ms\": 8736.89, \"total_train_time_s\": 10.938371419906616}", "{\"n\": 15187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.18, \"learn_time_ms\": 8636.63, \"total_train_time_s\": 8.40716814994812}", "{\"n\": 15188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.39, \"learn_time_ms\": 8696.145, \"total_train_time_s\": 9.506695032119751}", "{\"n\": 15189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 8768.806, \"total_train_time_s\": 10.629268884658813}", "{\"n\": 15190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.94, \"learn_time_ms\": 8905.142, \"total_train_time_s\": 11.01671814918518}", "{\"n\": 15191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.94, \"learn_time_ms\": 8823.754, \"total_train_time_s\": 9.282277822494507}", "{\"n\": 15192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.32, \"learn_time_ms\": 8856.075, \"total_train_time_s\": 10.929612874984741}", "{\"n\": 15193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.63, \"learn_time_ms\": 8744.261, \"total_train_time_s\": 9.057603359222412}", "{\"n\": 15194, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.38, \"learn_time_ms\": 8638.638, \"total_train_time_s\": 10.103129625320435}", "{\"n\": 15195, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.7, \"learn_time_ms\": 8598.272, \"total_train_time_s\": 10.360589504241943}", "{\"n\": 15196, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.03, \"learn_time_ms\": 8506.875, \"total_train_time_s\": 10.018247604370117}", "{\"n\": 15197, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.99, \"learn_time_ms\": 8771.536, \"total_train_time_s\": 11.046477794647217}", "{\"n\": 15198, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.38, \"learn_time_ms\": 8780.817, \"total_train_time_s\": 9.6346116065979}", "{\"n\": 15199, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.81, \"learn_time_ms\": 8403.429, \"total_train_time_s\": 6.852433204650879}", "{\"n\": 15200, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.2, \"learn_time_ms\": 8253.91, \"total_train_time_s\": 9.545332193374634}", "{\"n\": 15201, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.51, \"learn_time_ms\": 8388.126, \"total_train_time_s\": 10.583725452423096}", "{\"n\": 15202, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.51, \"learn_time_ms\": 8552.562, \"total_train_time_s\": 12.59062123298645}", "{\"n\": 15203, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.3, \"learn_time_ms\": 8767.316, \"total_train_time_s\": 11.199888229370117}", "{\"n\": 15204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.74, \"learn_time_ms\": 8724.403, \"total_train_time_s\": 9.654461860656738}", "{\"n\": 15205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.73, \"learn_time_ms\": 8740.647, \"total_train_time_s\": 10.529426336288452}", "{\"n\": 15206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.49, \"learn_time_ms\": 8598.085, \"total_train_time_s\": 8.634702920913696}", "{\"n\": 15207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.48, \"learn_time_ms\": 8585.731, \"total_train_time_s\": 10.92194128036499}", "{\"n\": 15208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.16, \"learn_time_ms\": 8547.501, \"total_train_time_s\": 9.206724643707275}", "{\"n\": 15209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.16, \"learn_time_ms\": 8839.174, \"total_train_time_s\": 9.750812768936157}", "{\"n\": 15210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 8916.844, \"total_train_time_s\": 10.32471251487732}", "{\"n\": 15211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 8861.501, \"total_train_time_s\": 10.000356435775757}", "{\"n\": 15212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.37, \"learn_time_ms\": 8549.812, \"total_train_time_s\": 9.393424987792969}", "{\"n\": 15213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.82, \"learn_time_ms\": 8639.43, \"total_train_time_s\": 12.044649124145508}", "{\"n\": 15214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.82, \"learn_time_ms\": 8794.359, \"total_train_time_s\": 11.260976552963257}", "{\"n\": 15215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.82, \"learn_time_ms\": 8725.5, \"total_train_time_s\": 9.804255485534668}", "{\"n\": 15216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.53, \"learn_time_ms\": 8863.814, \"total_train_time_s\": 9.98257303237915}", "{\"n\": 15217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.7, \"learn_time_ms\": 8752.181, \"total_train_time_s\": 9.781208992004395}", "{\"n\": 15218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.7, \"learn_time_ms\": 8797.858, \"total_train_time_s\": 9.660855531692505}", "{\"n\": 15219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.7, \"learn_time_ms\": 8870.718, \"total_train_time_s\": 10.470240354537964}", "{\"n\": 15220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.66, \"learn_time_ms\": 8732.498, \"total_train_time_s\": 8.882985353469849}", "{\"n\": 15221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.97, \"learn_time_ms\": 8774.271, \"total_train_time_s\": 10.432955026626587}", "{\"n\": 15222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.12, \"learn_time_ms\": 8814.285, \"total_train_time_s\": 9.848348617553711}", "{\"n\": 15223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.07, \"learn_time_ms\": 8675.602, \"total_train_time_s\": 10.679053544998169}", "{\"n\": 15224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.29, \"learn_time_ms\": 8632.543, \"total_train_time_s\": 10.800018310546875}", "{\"n\": 15225, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.29, \"learn_time_ms\": 8699.08, \"total_train_time_s\": 10.50283408164978}", "{\"n\": 15226, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.19, \"learn_time_ms\": 8640.486, \"total_train_time_s\": 9.441411972045898}", "{\"n\": 15227, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.11, \"learn_time_ms\": 8704.205, \"total_train_time_s\": 10.46558403968811}", "{\"n\": 15228, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.7, \"learn_time_ms\": 8760.017, \"total_train_time_s\": 10.228107452392578}", "{\"n\": 15229, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.84, \"learn_time_ms\": 8880.967, \"total_train_time_s\": 11.747098922729492}", "{\"n\": 15230, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.82, \"learn_time_ms\": 9010.235, \"total_train_time_s\": 10.180678367614746}", "{\"n\": 15231, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.52, \"learn_time_ms\": 8900.898, \"total_train_time_s\": 9.356088876724243}", "{\"n\": 15232, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.92, \"learn_time_ms\": 8808.285, \"total_train_time_s\": 8.947938442230225}", "{\"n\": 15233, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.94, \"learn_time_ms\": 8904.688, \"total_train_time_s\": 11.641858339309692}", "{\"n\": 15234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.94, \"learn_time_ms\": 8848.579, \"total_train_time_s\": 10.193430185317993}", "{\"n\": 15235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.56, \"learn_time_ms\": 8860.276, \"total_train_time_s\": 10.59696912765503}", "{\"n\": 15236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.05, \"learn_time_ms\": 8980.677, \"total_train_time_s\": 10.572542190551758}", "{\"n\": 15237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.26, \"learn_time_ms\": 8837.369, \"total_train_time_s\": 8.959632396697998}", "{\"n\": 15238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.47, \"learn_time_ms\": 8739.187, \"total_train_time_s\": 9.233145236968994}", "{\"n\": 15239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.59, \"learn_time_ms\": 8469.531, \"total_train_time_s\": 9.00771689414978}", "{\"n\": 15240, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.26, \"learn_time_ms\": 8326.379, \"total_train_time_s\": 8.728642702102661}", "{\"n\": 15241, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.92, \"learn_time_ms\": 8397.035, \"total_train_time_s\": 10.064908504486084}", "{\"n\": 15242, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.92, \"learn_time_ms\": 8407.476, \"total_train_time_s\": 9.016687631607056}", "{\"n\": 15243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.81, \"learn_time_ms\": 8223.942, \"total_train_time_s\": 9.80871868133545}", "{\"n\": 15244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.75, \"learn_time_ms\": 8247.848, \"total_train_time_s\": 10.474787950515747}", "{\"n\": 15245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.75, \"learn_time_ms\": 8144.915, \"total_train_time_s\": 9.612642288208008}", "{\"n\": 15246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.56, \"learn_time_ms\": 8189.745, \"total_train_time_s\": 11.050718545913696}", "{\"n\": 15247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.26, \"learn_time_ms\": 8445.024, \"total_train_time_s\": 11.546778678894043}", "{\"n\": 15248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.84, \"learn_time_ms\": 8461.089, \"total_train_time_s\": 9.431707859039307}", "{\"n\": 15249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.84, \"learn_time_ms\": 8579.774, \"total_train_time_s\": 10.183648824691772}", "{\"n\": 15250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.25, \"learn_time_ms\": 8601.132, \"total_train_time_s\": 8.975009202957153}", "{\"n\": 15251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.39, \"learn_time_ms\": 8630.091, \"total_train_time_s\": 10.342252969741821}", "{\"n\": 15252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.39, \"learn_time_ms\": 8822.974, \"total_train_time_s\": 10.967535495758057}", "{\"n\": 15253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.85, \"learn_time_ms\": 8798.693, \"total_train_time_s\": 9.601576566696167}", "{\"n\": 15254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.12, \"learn_time_ms\": 8820.261, \"total_train_time_s\": 10.709428310394287}", "{\"n\": 15255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.12, \"learn_time_ms\": 9040.104, \"total_train_time_s\": 11.789961099624634}", "{\"n\": 15256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.12, \"learn_time_ms\": 8912.91, \"total_train_time_s\": 9.812353372573853}", "{\"n\": 15257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.77, \"learn_time_ms\": 8671.5, \"total_train_time_s\": 9.160044193267822}", "{\"n\": 15258, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.36, \"learn_time_ms\": 8688.67, \"total_train_time_s\": 9.551541805267334}", "{\"n\": 15259, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.36, \"learn_time_ms\": 8632.958, \"total_train_time_s\": 9.635439157485962}", "{\"n\": 15260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.28, \"learn_time_ms\": 8577.409, \"total_train_time_s\": 8.386476278305054}", "{\"n\": 15261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.05, \"learn_time_ms\": 8625.695, \"total_train_time_s\": 10.822504758834839}", "{\"n\": 15262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.05, \"learn_time_ms\": 8471.416, \"total_train_time_s\": 9.410026550292969}", "{\"n\": 15263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.76, \"learn_time_ms\": 8627.26, \"total_train_time_s\": 11.081504583358765}", "{\"n\": 15264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.99, \"learn_time_ms\": 8510.46, \"total_train_time_s\": 9.569535732269287}", "{\"n\": 15265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.03, \"learn_time_ms\": 8283.794, \"total_train_time_s\": 9.478240489959717}", "{\"n\": 15266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.02, \"learn_time_ms\": 8345.201, \"total_train_time_s\": 10.369969844818115}", "{\"n\": 15267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.31, \"learn_time_ms\": 8221.473, \"total_train_time_s\": 7.8854289054870605}", "{\"n\": 15268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.33, \"learn_time_ms\": 8245.685, \"total_train_time_s\": 9.828160285949707}", "{\"n\": 15269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.33, \"learn_time_ms\": 8439.114, \"total_train_time_s\": 11.599529504776001}", "{\"n\": 15270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.98, \"learn_time_ms\": 8663.161, \"total_train_time_s\": 10.703126430511475}", "{\"n\": 15271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.49, \"learn_time_ms\": 8634.601, \"total_train_time_s\": 10.581409215927124}", "{\"n\": 15272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.01, \"learn_time_ms\": 8691.009, \"total_train_time_s\": 10.017096519470215}", "{\"n\": 15273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.41, \"learn_time_ms\": 8544.457, \"total_train_time_s\": 9.624638795852661}", "{\"n\": 15274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.17, \"learn_time_ms\": 8649.868, \"total_train_time_s\": 10.606740713119507}", "{\"n\": 15275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.17, \"learn_time_ms\": 8586.556, \"total_train_time_s\": 8.984457731246948}", "{\"n\": 15276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.86, \"learn_time_ms\": 8652.353, \"total_train_time_s\": 11.061796426773071}", "{\"n\": 15277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.86, \"learn_time_ms\": 8745.891, \"total_train_time_s\": 8.817633628845215}", "{\"n\": 15278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.91, \"learn_time_ms\": 8945.628, \"total_train_time_s\": 11.860562801361084}", "{\"n\": 15279, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.07, \"learn_time_ms\": 8781.528, \"total_train_time_s\": 9.918062686920166}", "{\"n\": 15280, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.7, \"learn_time_ms\": 8767.99, \"total_train_time_s\": 10.51897406578064}", "{\"n\": 15281, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.4, \"learn_time_ms\": 8675.902, \"total_train_time_s\": 9.626428127288818}", "{\"n\": 15282, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.4, \"learn_time_ms\": 8754.287, \"total_train_time_s\": 10.7337806224823}", "{\"n\": 15283, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.1, \"learn_time_ms\": 8736.388, \"total_train_time_s\": 9.432206392288208}", "{\"n\": 15284, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.1, \"learn_time_ms\": 8685.893, \"total_train_time_s\": 10.094830513000488}", "{\"n\": 15285, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.7, \"learn_time_ms\": 8748.108, \"total_train_time_s\": 9.495421409606934}", "{\"n\": 15286, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.7, \"learn_time_ms\": 8639.331, \"total_train_time_s\": 9.911860466003418}", "{\"n\": 15287, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.27, \"learn_time_ms\": 8747.792, \"total_train_time_s\": 9.901341676712036}", "{\"n\": 15288, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.81, \"learn_time_ms\": 8623.304, \"total_train_time_s\": 10.534816265106201}", "{\"n\": 15289, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.81, \"learn_time_ms\": 8563.312, \"total_train_time_s\": 9.360585451126099}", "{\"n\": 15290, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.28, \"learn_time_ms\": 8538.339, \"total_train_time_s\": 10.276833772659302}", "{\"n\": 15291, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.12, \"learn_time_ms\": 8544.088, \"total_train_time_s\": 9.706523656845093}", "{\"n\": 15292, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.12, \"learn_time_ms\": 8467.075, \"total_train_time_s\": 9.971800804138184}", "{\"n\": 15293, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.12, \"learn_time_ms\": 8561.438, \"total_train_time_s\": 10.396782636642456}", "{\"n\": 15294, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.29, \"learn_time_ms\": 8531.63, \"total_train_time_s\": 9.749350547790527}", "{\"n\": 15295, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.78, \"learn_time_ms\": 8595.288, \"total_train_time_s\": 10.119051218032837}", "{\"n\": 15296, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.5, \"learn_time_ms\": 8571.058, \"total_train_time_s\": 9.677146196365356}", "{\"n\": 15297, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.11, \"learn_time_ms\": 8428.029, \"total_train_time_s\": 8.481580257415771}", "{\"n\": 15298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.4, \"learn_time_ms\": 8328.336, \"total_train_time_s\": 9.60797381401062}", "{\"n\": 15299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.28, \"learn_time_ms\": 8345.998, \"total_train_time_s\": 9.518496990203857}", "{\"n\": 15300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.06, \"learn_time_ms\": 8205.6, \"total_train_time_s\": 8.82862901687622}", "{\"n\": 15301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3422.5, \"learn_time_ms\": 8194.118, \"total_train_time_s\": 9.593663454055786}", "{\"n\": 15302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.2, \"learn_time_ms\": 8181.934, \"total_train_time_s\": 9.880724430084229}", "{\"n\": 15303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.2, \"learn_time_ms\": 8177.85, \"total_train_time_s\": 10.350650072097778}", "{\"n\": 15304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.25, \"learn_time_ms\": 8087.264, \"total_train_time_s\": 8.909754514694214}", "{\"n\": 15305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3412.4, \"learn_time_ms\": 8034.237, \"total_train_time_s\": 9.644890785217285}", "{\"n\": 15306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3409.84, \"learn_time_ms\": 8029.718, \"total_train_time_s\": 9.636585474014282}", "{\"n\": 15307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3409.08, \"learn_time_ms\": 8049.11, \"total_train_time_s\": 8.693196058273315}", "{\"n\": 15308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3412.37, \"learn_time_ms\": 8142.184, \"total_train_time_s\": 10.504458665847778}", "{\"n\": 15309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.45, \"learn_time_ms\": 8189.687, \"total_train_time_s\": 10.005604028701782}", "{\"n\": 15310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.45, \"learn_time_ms\": 8321.367, \"total_train_time_s\": 10.251636505126953}", "{\"n\": 15311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3401.48, \"learn_time_ms\": 8519.374, \"total_train_time_s\": 11.592965841293335}", "{\"n\": 15312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.35, \"learn_time_ms\": 8601.799, \"total_train_time_s\": 10.71880316734314}", "{\"n\": 15313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.35, \"learn_time_ms\": 8674.84, \"total_train_time_s\": 11.084815263748169}", "{\"n\": 15314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3405.55, \"learn_time_ms\": 8699.118, \"total_train_time_s\": 9.123024940490723}", "{\"n\": 15315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.65, \"learn_time_ms\": 8946.861, \"total_train_time_s\": 12.045813083648682}", "{\"n\": 15316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.65, \"learn_time_ms\": 9013.895, \"total_train_time_s\": 10.3113374710083}", "{\"n\": 15317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.74, \"learn_time_ms\": 9156.622, \"total_train_time_s\": 10.126411437988281}", "{\"n\": 15318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.36, \"learn_time_ms\": 9180.986, \"total_train_time_s\": 10.786062479019165}", "{\"n\": 15319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.51, \"learn_time_ms\": 9002.999, \"total_train_time_s\": 8.259532928466797}", "{\"n\": 15320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.93, \"learn_time_ms\": 9014.978, \"total_train_time_s\": 10.322310209274292}", "{\"n\": 15321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.93, \"learn_time_ms\": 8709.811, \"total_train_time_s\": 8.498565912246704}", "{\"n\": 15322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.91, \"learn_time_ms\": 8682.204, \"total_train_time_s\": 10.393212080001831}", "{\"n\": 15323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.64, \"learn_time_ms\": 8545.961, \"total_train_time_s\": 9.734387397766113}", "{\"n\": 15324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.64, \"learn_time_ms\": 8660.623, \"total_train_time_s\": 10.2332603931427}", "{\"n\": 15325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.69, \"learn_time_ms\": 8443.169, \"total_train_time_s\": 9.88811993598938}", "{\"n\": 15326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3395.52, \"learn_time_ms\": 8465.004, \"total_train_time_s\": 10.564087867736816}", "{\"n\": 15327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3395.52, \"learn_time_ms\": 8457.338, \"total_train_time_s\": 10.007697105407715}", "{\"n\": 15328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.91, \"learn_time_ms\": 8333.955, \"total_train_time_s\": 9.50589919090271}", "{\"n\": 15329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.84, \"learn_time_ms\": 8527.18, \"total_train_time_s\": 10.153684616088867}", "{\"n\": 15330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.84, \"learn_time_ms\": 8387.831, \"total_train_time_s\": 8.863640308380127}", "{\"n\": 15331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.84, \"learn_time_ms\": 8732.701, \"total_train_time_s\": 11.95076608657837}", "{\"n\": 15332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.77, \"learn_time_ms\": 8744.858, \"total_train_time_s\": 10.52233624458313}", "{\"n\": 15333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.94, \"learn_time_ms\": 8852.309, \"total_train_time_s\": 10.819496393203735}", "{\"n\": 15334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.94, \"learn_time_ms\": 9036.946, \"total_train_time_s\": 12.089950561523438}", "{\"n\": 15335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.58, \"learn_time_ms\": 9121.692, \"total_train_time_s\": 10.765919208526611}", "{\"n\": 15336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.5, \"learn_time_ms\": 8982.679, \"total_train_time_s\": 9.161298513412476}", "{\"n\": 15337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.5, \"learn_time_ms\": 8988.812, \"total_train_time_s\": 10.065116167068481}", "{\"n\": 15338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.3, \"learn_time_ms\": 8931.725, \"total_train_time_s\": 8.920804262161255}", "{\"n\": 15339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.64, \"learn_time_ms\": 8792.539, \"total_train_time_s\": 8.743280172348022}", "{\"n\": 15340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.64, \"learn_time_ms\": 8997.832, \"total_train_time_s\": 10.950886011123657}", "{\"n\": 15341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.35, \"learn_time_ms\": 8681.291, \"total_train_time_s\": 8.778924465179443}", "{\"n\": 15342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.35, \"learn_time_ms\": 8652.343, \"total_train_time_s\": 10.27085280418396}", "{\"n\": 15343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.53, \"learn_time_ms\": 8500.9, \"total_train_time_s\": 9.323697566986084}", "{\"n\": 15344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.38, \"learn_time_ms\": 8287.692, \"total_train_time_s\": 9.933286666870117}", "{\"n\": 15345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.2, \"learn_time_ms\": 8175.903, \"total_train_time_s\": 9.639437913894653}", "{\"n\": 15346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.16, \"learn_time_ms\": 8226.241, \"total_train_time_s\": 9.697786808013916}", "{\"n\": 15347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.36, \"learn_time_ms\": 8254.871, \"total_train_time_s\": 10.374020099639893}", "{\"n\": 15348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.36, \"learn_time_ms\": 8366.774, \"total_train_time_s\": 10.021918773651123}", "{\"n\": 15349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.46, \"learn_time_ms\": 8511.178, \"total_train_time_s\": 10.154489994049072}", "{\"n\": 15350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.2, \"learn_time_ms\": 8390.683, \"total_train_time_s\": 9.741342067718506}", "{\"n\": 15351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.2, \"learn_time_ms\": 8454.311, \"total_train_time_s\": 9.440829515457153}", "{\"n\": 15352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.46, \"learn_time_ms\": 8393.643, \"total_train_time_s\": 9.652361869812012}", "{\"n\": 15353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 8350.76, \"total_train_time_s\": 8.863937139511108}", "{\"n\": 15354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 8414.023, \"total_train_time_s\": 10.617642164230347}", "{\"n\": 15355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.49, \"learn_time_ms\": 8452.647, \"total_train_time_s\": 10.036791801452637}", "{\"n\": 15356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.82, \"learn_time_ms\": 8491.147, \"total_train_time_s\": 10.021894931793213}", "{\"n\": 15357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.82, \"learn_time_ms\": 8262.584, \"total_train_time_s\": 8.067273378372192}", "{\"n\": 15358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.82, \"learn_time_ms\": 8330.975, \"total_train_time_s\": 10.777472496032715}", "{\"n\": 15359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.61, \"learn_time_ms\": 8366.302, \"total_train_time_s\": 10.549251317977905}", "{\"n\": 15360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.61, \"learn_time_ms\": 8434.751, \"total_train_time_s\": 10.432084083557129}", "{\"n\": 15361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.61, \"learn_time_ms\": 8545.915, \"total_train_time_s\": 10.505760669708252}", "{\"n\": 15362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.18, \"learn_time_ms\": 8587.166, \"total_train_time_s\": 10.071356058120728}", "{\"n\": 15363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.19, \"learn_time_ms\": 8738.266, \"total_train_time_s\": 10.39784288406372}", "{\"n\": 15364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.19, \"learn_time_ms\": 8733.467, \"total_train_time_s\": 10.509658575057983}", "{\"n\": 15365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.16, \"learn_time_ms\": 8759.05, \"total_train_time_s\": 10.230921983718872}", "{\"n\": 15366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.6, \"learn_time_ms\": 8529.908, \"total_train_time_s\": 7.725735664367676}", "{\"n\": 15367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.6, \"learn_time_ms\": 8716.184, \"total_train_time_s\": 9.902253150939941}", "{\"n\": 15368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.84, \"learn_time_ms\": 8748.587, \"total_train_time_s\": 11.062476873397827}", "{\"n\": 15369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.8, \"learn_time_ms\": 8625.548, \"total_train_time_s\": 9.316313982009888}", "{\"n\": 15370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.8, \"learn_time_ms\": 8501.398, \"total_train_time_s\": 9.26225757598877}", "{\"n\": 15371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.09, \"learn_time_ms\": 8407.792, \"total_train_time_s\": 9.619949579238892}", "{\"n\": 15372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.64, \"learn_time_ms\": 8350.328, \"total_train_time_s\": 9.45957612991333}", "{\"n\": 15373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.64, \"learn_time_ms\": 8260.725, \"total_train_time_s\": 9.451889753341675}", "{\"n\": 15374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.34, \"learn_time_ms\": 8223.784, \"total_train_time_s\": 10.176381349563599}", "{\"n\": 15375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.25, \"learn_time_ms\": 8211.901, \"total_train_time_s\": 10.174363136291504}", "{\"n\": 15376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.68, \"learn_time_ms\": 8395.123, \"total_train_time_s\": 9.573312759399414}", "{\"n\": 15377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.78, \"learn_time_ms\": 8435.616, \"total_train_time_s\": 10.327722549438477}", "{\"n\": 15378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.55, \"learn_time_ms\": 8390.467, \"total_train_time_s\": 10.58599591255188}", "{\"n\": 15379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.52, \"learn_time_ms\": 8361.621, \"total_train_time_s\": 9.049831628799438}", "{\"n\": 15380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.52, \"learn_time_ms\": 8337.19, \"total_train_time_s\": 8.923447370529175}", "{\"n\": 15381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.62, \"learn_time_ms\": 8236.64, \"total_train_time_s\": 8.572175979614258}", "{\"n\": 15382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.38, \"learn_time_ms\": 8277.577, \"total_train_time_s\": 9.872380018234253}", "{\"n\": 15383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.33, \"learn_time_ms\": 8282.274, \"total_train_time_s\": 9.511284351348877}", "{\"n\": 15384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8270.974, \"total_train_time_s\": 10.05242395401001}", "{\"n\": 15385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8178.754, \"total_train_time_s\": 9.239176988601685}", "{\"n\": 15386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.99, \"learn_time_ms\": 8179.902, \"total_train_time_s\": 9.607283353805542}", "{\"n\": 15387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.19, \"learn_time_ms\": 8237.989, \"total_train_time_s\": 10.940064907073975}", "{\"n\": 15388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.23, \"learn_time_ms\": 8185.758, \"total_train_time_s\": 10.110367059707642}", "{\"n\": 15389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 8321.747, \"total_train_time_s\": 10.417904376983643}", "{\"n\": 15390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.46, \"learn_time_ms\": 8499.429, \"total_train_time_s\": 10.75229525566101}", "{\"n\": 15391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3298.46, \"learn_time_ms\": 8659.938, \"total_train_time_s\": 10.175637006759644}", "{\"n\": 15392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.65, \"learn_time_ms\": 8601.256, \"total_train_time_s\": 9.308028221130371}", "{\"n\": 15393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.19, \"learn_time_ms\": 8591.574, \"total_train_time_s\": 9.472001552581787}", "{\"n\": 15394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.19, \"learn_time_ms\": 8710.819, \"total_train_time_s\": 11.250180721282959}", "{\"n\": 15395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.84, \"learn_time_ms\": 8720.894, \"total_train_time_s\": 9.323494911193848}", "{\"n\": 15396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.53, \"learn_time_ms\": 8878.886, \"total_train_time_s\": 11.175498723983765}", "{\"n\": 15397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.17, \"learn_time_ms\": 8768.908, \"total_train_time_s\": 9.851712465286255}", "{\"n\": 15398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.77, \"learn_time_ms\": 8898.386, \"total_train_time_s\": 11.403778553009033}", "{\"n\": 15399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.5, \"learn_time_ms\": 8851.385, \"total_train_time_s\": 9.909936666488647}", "{\"n\": 15400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.84, \"learn_time_ms\": 8884.689, \"total_train_time_s\": 11.042301416397095}", "{\"n\": 15401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.84, \"learn_time_ms\": 8960.96, \"total_train_time_s\": 10.96152949333191}", "{\"n\": 15402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.1, \"learn_time_ms\": 9052.815, \"total_train_time_s\": 10.207436561584473}", "{\"n\": 15403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.73, \"learn_time_ms\": 9163.168, \"total_train_time_s\": 10.581080675125122}", "{\"n\": 15404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.52, \"learn_time_ms\": 9139.658, \"total_train_time_s\": 10.970447540283203}", "{\"n\": 15405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.26, \"learn_time_ms\": 9175.091, \"total_train_time_s\": 9.677883386611938}", "{\"n\": 15406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.83, \"learn_time_ms\": 9040.303, \"total_train_time_s\": 9.822095394134521}", "{\"n\": 15407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.54, \"learn_time_ms\": 9097.468, \"total_train_time_s\": 10.406078815460205}", "{\"n\": 15408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.88, \"learn_time_ms\": 9052.665, \"total_train_time_s\": 10.928951978683472}", "{\"n\": 15409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.16, \"learn_time_ms\": 8999.324, \"total_train_time_s\": 9.371655702590942}", "{\"n\": 15410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.77, \"learn_time_ms\": 9109.727, \"total_train_time_s\": 12.168015480041504}", "{\"n\": 15411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.78, \"learn_time_ms\": 9067.726, \"total_train_time_s\": 10.525436639785767}", "{\"n\": 15412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.78, \"learn_time_ms\": 9024.707, \"total_train_time_s\": 9.761555910110474}", "{\"n\": 15413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.65, \"learn_time_ms\": 8949.242, \"total_train_time_s\": 9.785167932510376}", "{\"n\": 15414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.33, \"learn_time_ms\": 8904.886, \"total_train_time_s\": 10.584654331207275}", "{\"n\": 15415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.33, \"learn_time_ms\": 8900.34, \"total_train_time_s\": 9.641158819198608}", "{\"n\": 15416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.86, \"learn_time_ms\": 8905.229, \"total_train_time_s\": 9.871224641799927}", "{\"n\": 15417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.86, \"learn_time_ms\": 8787.015, \"total_train_time_s\": 9.273240089416504}", "{\"n\": 15418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.96, \"learn_time_ms\": 8682.18, \"total_train_time_s\": 9.90467643737793}", "{\"n\": 15419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.96, \"learn_time_ms\": 8685.847, \"total_train_time_s\": 9.414370059967041}", "{\"n\": 15420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.77, \"learn_time_ms\": 8487.166, \"total_train_time_s\": 10.200146675109863}", "{\"n\": 15421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.51, \"learn_time_ms\": 8457.316, \"total_train_time_s\": 10.225756883621216}", "{\"n\": 15422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.51, \"learn_time_ms\": 8470.551, \"total_train_time_s\": 9.90876579284668}", "{\"n\": 15423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.12, \"learn_time_ms\": 8469.744, \"total_train_time_s\": 9.774292707443237}", "{\"n\": 15424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.35, \"learn_time_ms\": 8309.098, \"total_train_time_s\": 8.949849843978882}", "{\"n\": 15425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.77, \"learn_time_ms\": 8269.312, \"total_train_time_s\": 9.281362056732178}", "{\"n\": 15426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.77, \"learn_time_ms\": 8325.652, \"total_train_time_s\": 10.400823831558228}", "{\"n\": 15427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.39, \"learn_time_ms\": 8464.567, \"total_train_time_s\": 10.66577434539795}", "{\"n\": 15428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.73, \"learn_time_ms\": 8384.788, \"total_train_time_s\": 9.111143350601196}", "{\"n\": 15429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.73, \"learn_time_ms\": 8484.667, \"total_train_time_s\": 10.482736587524414}", "{\"n\": 15430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.08, \"learn_time_ms\": 8500.495, \"total_train_time_s\": 10.354094505310059}", "{\"n\": 15431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.03, \"learn_time_ms\": 8403.204, \"total_train_time_s\": 9.306026458740234}", "{\"n\": 15432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.03, \"learn_time_ms\": 8467.773, \"total_train_time_s\": 10.548446655273438}", "{\"n\": 15433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.14, \"learn_time_ms\": 8456.3, \"total_train_time_s\": 9.637413501739502}", "{\"n\": 15434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.77, \"learn_time_ms\": 8530.144, \"total_train_time_s\": 9.698862075805664}", "{\"n\": 15435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.33, \"learn_time_ms\": 8660.007, \"total_train_time_s\": 10.551969289779663}", "{\"n\": 15436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.33, \"learn_time_ms\": 8598.19, \"total_train_time_s\": 9.827965259552002}", "{\"n\": 15437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.12, \"learn_time_ms\": 8434.918, \"total_train_time_s\": 8.98677110671997}", "{\"n\": 15438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.39, \"learn_time_ms\": 8488.332, \"total_train_time_s\": 9.691076517105103}", "{\"n\": 15439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.77, \"learn_time_ms\": 8392.188, \"total_train_time_s\": 9.475133180618286}", "{\"n\": 15440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.21, \"learn_time_ms\": 8259.419, \"total_train_time_s\": 8.984861850738525}", "{\"n\": 15441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.59, \"learn_time_ms\": 8317.591, \"total_train_time_s\": 9.85139775276184}", "{\"n\": 15442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.65, \"learn_time_ms\": 8285.092, \"total_train_time_s\": 10.214129209518433}", "{\"n\": 15443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.21, \"learn_time_ms\": 8428.187, \"total_train_time_s\": 11.133405447006226}", "{\"n\": 15444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.81, \"learn_time_ms\": 8323.94, \"total_train_time_s\": 8.68428921699524}", "{\"n\": 15445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.96, \"learn_time_ms\": 8171.682, \"total_train_time_s\": 9.022220134735107}", "{\"n\": 15446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.37, \"learn_time_ms\": 8292.18, \"total_train_time_s\": 11.03110384941101}", "{\"n\": 15447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.93, \"learn_time_ms\": 8380.562, \"total_train_time_s\": 9.845949172973633}", "{\"n\": 15448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.32, \"learn_time_ms\": 8468.616, \"total_train_time_s\": 10.470292329788208}", "{\"n\": 15449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.32, \"learn_time_ms\": 8531.913, \"total_train_time_s\": 10.061396598815918}", "{\"n\": 15450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.8, \"learn_time_ms\": 8595.468, \"total_train_time_s\": 9.653141260147095}", "{\"n\": 15451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.19, \"learn_time_ms\": 8738.19, \"total_train_time_s\": 11.247910261154175}", "{\"n\": 15452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.92, \"learn_time_ms\": 8763.799, \"total_train_time_s\": 10.526129007339478}", "{\"n\": 15453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.75, \"learn_time_ms\": 8606.82, \"total_train_time_s\": 9.539469003677368}", "{\"n\": 15454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.72, \"learn_time_ms\": 8608.591, \"total_train_time_s\": 8.713013172149658}", "{\"n\": 15455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.96, \"learn_time_ms\": 8773.63, \"total_train_time_s\": 10.724708795547485}", "{\"n\": 15456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.29, \"learn_time_ms\": 8707.418, \"total_train_time_s\": 10.397415399551392}", "{\"n\": 15457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 8756.799, \"total_train_time_s\": 10.39458680152893}", "{\"n\": 15458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.59, \"learn_time_ms\": 8648.567, \"total_train_time_s\": 9.396508693695068}", "{\"n\": 15459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.09, \"learn_time_ms\": 8595.621, \"total_train_time_s\": 9.547473669052124}", "{\"n\": 15460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.86, \"learn_time_ms\": 8788.874, \"total_train_time_s\": 11.584813594818115}", "{\"n\": 15461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.69, \"learn_time_ms\": 8362.531, \"total_train_time_s\": 7.0448503494262695}", "{\"n\": 15462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.6, \"learn_time_ms\": 8330.529, \"total_train_time_s\": 10.202286958694458}", "{\"n\": 15463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.56, \"learn_time_ms\": 8363.641, \"total_train_time_s\": 9.86793327331543}", "{\"n\": 15464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.56, \"learn_time_ms\": 8473.779, \"total_train_time_s\": 9.743007183074951}", "{\"n\": 15465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.62, \"learn_time_ms\": 8404.303, \"total_train_time_s\": 9.980180263519287}", "{\"n\": 15466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.9, \"learn_time_ms\": 8384.368, \"total_train_time_s\": 10.159456253051758}", "{\"n\": 15467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.2, \"learn_time_ms\": 8432.186, \"total_train_time_s\": 10.84000015258789}", "{\"n\": 15468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.5, \"learn_time_ms\": 8520.017, \"total_train_time_s\": 10.35424542427063}", "{\"n\": 15469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.05, \"learn_time_ms\": 8643.87, \"total_train_time_s\": 10.81483507156372}", "{\"n\": 15470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.0, \"learn_time_ms\": 8492.597, \"total_train_time_s\": 10.102842092514038}", "{\"n\": 15471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.0, \"learn_time_ms\": 8818.911, \"total_train_time_s\": 10.27152967453003}", "{\"n\": 15472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.45, \"learn_time_ms\": 8857.722, \"total_train_time_s\": 10.533255577087402}", "{\"n\": 15473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.47, \"learn_time_ms\": 8896.392, \"total_train_time_s\": 10.25487208366394}", "{\"n\": 15474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.73, \"learn_time_ms\": 8934.122, \"total_train_time_s\": 10.174718379974365}", "{\"n\": 15475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.13, \"learn_time_ms\": 9009.835, \"total_train_time_s\": 10.720695972442627}", "{\"n\": 15476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.19, \"learn_time_ms\": 9011.544, \"total_train_time_s\": 10.133519887924194}", "{\"n\": 15477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.47, \"learn_time_ms\": 8944.24, \"total_train_time_s\": 10.183698415756226}", "{\"n\": 15478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.47, \"learn_time_ms\": 8933.868, \"total_train_time_s\": 10.20491361618042}", "{\"n\": 15479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.97, \"learn_time_ms\": 8909.434, \"total_train_time_s\": 10.55461311340332}", "{\"n\": 15480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.96, \"learn_time_ms\": 8838.563, \"total_train_time_s\": 9.3586585521698}", "{\"n\": 15481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.02, \"learn_time_ms\": 8843.553, \"total_train_time_s\": 10.32312798500061}", "{\"n\": 15482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.28, \"learn_time_ms\": 8743.265, \"total_train_time_s\": 9.558735847473145}", "{\"n\": 15483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.56, \"learn_time_ms\": 8718.949, \"total_train_time_s\": 10.029064178466797}", "{\"n\": 15484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.38, \"learn_time_ms\": 8788.812, \"total_train_time_s\": 10.845854759216309}", "{\"n\": 15485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.2, \"learn_time_ms\": 8804.77, \"total_train_time_s\": 10.877019166946411}", "{\"n\": 15486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.36, \"learn_time_ms\": 8783.11, \"total_train_time_s\": 9.984555006027222}", "{\"n\": 15487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.5, \"learn_time_ms\": 8721.756, \"total_train_time_s\": 9.565140008926392}", "{\"n\": 15488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.94, \"learn_time_ms\": 8758.467, \"total_train_time_s\": 10.58666205406189}", "{\"n\": 15489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.94, \"learn_time_ms\": 8620.501, \"total_train_time_s\": 9.142764329910278}", "{\"n\": 15490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.33, \"learn_time_ms\": 8577.935, \"total_train_time_s\": 8.969876766204834}", "{\"n\": 15491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.33, \"learn_time_ms\": 8560.889, \"total_train_time_s\": 10.207939863204956}", "{\"n\": 15492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.29, \"learn_time_ms\": 8584.372, \"total_train_time_s\": 9.878180980682373}", "{\"n\": 15493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.19, \"learn_time_ms\": 8682.393, \"total_train_time_s\": 10.980594873428345}", "{\"n\": 15494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.89, \"learn_time_ms\": 8596.331, \"total_train_time_s\": 9.991575479507446}", "{\"n\": 15495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.14, \"learn_time_ms\": 8506.256, \"total_train_time_s\": 9.986408233642578}", "{\"n\": 15496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.21, \"learn_time_ms\": 8583.707, \"total_train_time_s\": 10.743177890777588}", "{\"n\": 15497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.49, \"learn_time_ms\": 8717.396, \"total_train_time_s\": 10.910747766494751}", "{\"n\": 15498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.06, \"learn_time_ms\": 8670.514, \"total_train_time_s\": 10.069234371185303}", "{\"n\": 15499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.05, \"learn_time_ms\": 8614.497, \"total_train_time_s\": 8.635602712631226}", "{\"n\": 15500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.8, \"learn_time_ms\": 8745.134, \"total_train_time_s\": 10.227317810058594}", "{\"n\": 15501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 8579.13, \"total_train_time_s\": 8.486302375793457}", "{\"n\": 15502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.01, \"learn_time_ms\": 8535.603, \"total_train_time_s\": 9.305998802185059}", "{\"n\": 15503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.56, \"learn_time_ms\": 8371.089, \"total_train_time_s\": 9.353882551193237}", "{\"n\": 15504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.34, \"learn_time_ms\": 8187.86, \"total_train_time_s\": 8.136950969696045}", "{\"n\": 15505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.32, \"learn_time_ms\": 8226.546, \"total_train_time_s\": 10.397254705429077}", "{\"n\": 15506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.35, \"learn_time_ms\": 8191.255, \"total_train_time_s\": 10.418976545333862}", "{\"n\": 15507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.86, \"learn_time_ms\": 8162.466, \"total_train_time_s\": 10.601515293121338}", "{\"n\": 15508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.53, \"learn_time_ms\": 8178.785, \"total_train_time_s\": 10.286525964736938}", "{\"n\": 15509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.24, \"learn_time_ms\": 8477.177, \"total_train_time_s\": 11.577266216278076}", "{\"n\": 15510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.14, \"learn_time_ms\": 8504.004, \"total_train_time_s\": 10.52509093284607}", "{\"n\": 15511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 8611.169, \"total_train_time_s\": 9.588583946228027}", "{\"n\": 15512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 8708.401, \"total_train_time_s\": 10.2961905002594}", "{\"n\": 15513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.9, \"learn_time_ms\": 8830.41, \"total_train_time_s\": 10.589791774749756}", "{\"n\": 15514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.24, \"learn_time_ms\": 9022.685, \"total_train_time_s\": 10.13782525062561}", "{\"n\": 15515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.24, \"learn_time_ms\": 8919.306, \"total_train_time_s\": 9.319902896881104}", "{\"n\": 15516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.72, \"learn_time_ms\": 8807.101, \"total_train_time_s\": 9.291509866714478}", "{\"n\": 15517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.64, \"learn_time_ms\": 8812.05, \"total_train_time_s\": 10.643720388412476}", "{\"n\": 15518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.64, \"learn_time_ms\": 8826.414, \"total_train_time_s\": 10.389154434204102}", "{\"n\": 15519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.74, \"learn_time_ms\": 8757.114, \"total_train_time_s\": 10.990989208221436}", "{\"n\": 15520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.66, \"learn_time_ms\": 8637.31, \"total_train_time_s\": 9.292790174484253}", "{\"n\": 15521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.57, \"learn_time_ms\": 8711.201, \"total_train_time_s\": 10.285184144973755}", "{\"n\": 15522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.13, \"learn_time_ms\": 8773.469, \"total_train_time_s\": 10.941524028778076}", "{\"n\": 15523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.88, \"learn_time_ms\": 8718.736, \"total_train_time_s\": 10.0422523021698}", "{\"n\": 15524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.41, \"learn_time_ms\": 8685.906, \"total_train_time_s\": 9.763404607772827}", "{\"n\": 15525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.43, \"learn_time_ms\": 8858.359, \"total_train_time_s\": 11.074111938476562}", "{\"n\": 15526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.52, \"learn_time_ms\": 8986.077, \"total_train_time_s\": 10.571717739105225}", "{\"n\": 15527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.17, \"learn_time_ms\": 8883.478, \"total_train_time_s\": 9.609957695007324}", "{\"n\": 15528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.27, \"learn_time_ms\": 9052.732, \"total_train_time_s\": 12.148226976394653}", "{\"n\": 15529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.74, \"learn_time_ms\": 8911.446, \"total_train_time_s\": 9.507838726043701}", "{\"n\": 15530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.77, \"learn_time_ms\": 8927.825, \"total_train_time_s\": 9.441627979278564}", "{\"n\": 15531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 8737.751, \"total_train_time_s\": 8.428937911987305}", "{\"n\": 15532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 8526.27, \"total_train_time_s\": 8.842937469482422}", "{\"n\": 15533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.39, \"learn_time_ms\": 8370.004, \"total_train_time_s\": 8.44787311553955}", "{\"n\": 15534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.3, \"learn_time_ms\": 8421.194, \"total_train_time_s\": 10.25662350654602}", "{\"n\": 15535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.08, \"learn_time_ms\": 8262.376, \"total_train_time_s\": 9.461894750595093}", "{\"n\": 15536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.61, \"learn_time_ms\": 8212.363, \"total_train_time_s\": 10.082058191299438}", "{\"n\": 15537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.8, \"learn_time_ms\": 8277.892, \"total_train_time_s\": 10.301121234893799}", "{\"n\": 15538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.5, \"learn_time_ms\": 8073.099, \"total_train_time_s\": 10.06847333908081}", "{\"n\": 15539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.5, \"learn_time_ms\": 8004.579, \"total_train_time_s\": 8.824319839477539}", "{\"n\": 15540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.61, \"learn_time_ms\": 8011.602, \"total_train_time_s\": 9.552402257919312}", "{\"n\": 15541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.26, \"learn_time_ms\": 8133.627, \"total_train_time_s\": 9.621081590652466}", "{\"n\": 15542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.93, \"learn_time_ms\": 8212.487, \"total_train_time_s\": 9.60095477104187}", "{\"n\": 15543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.65, \"learn_time_ms\": 8318.574, \"total_train_time_s\": 9.507332801818848}", "{\"n\": 15544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.41, \"learn_time_ms\": 8283.747, \"total_train_time_s\": 9.952131271362305}", "{\"n\": 15545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.53, \"learn_time_ms\": 8302.3, \"total_train_time_s\": 9.665626525878906}", "{\"n\": 15546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.01, \"learn_time_ms\": 8438.54, \"total_train_time_s\": 11.446084022521973}", "{\"n\": 15547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.01, \"learn_time_ms\": 8582.718, \"total_train_time_s\": 11.725365400314331}", "{\"n\": 15548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.86, \"learn_time_ms\": 8636.505, \"total_train_time_s\": 10.583134174346924}", "{\"n\": 15549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.1, \"learn_time_ms\": 8753.498, \"total_train_time_s\": 9.975941896438599}", "{\"n\": 15550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.74, \"learn_time_ms\": 8681.582, \"total_train_time_s\": 8.835112571716309}", "{\"n\": 15551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.11, \"learn_time_ms\": 8669.791, \"total_train_time_s\": 9.487617492675781}", "{\"n\": 15552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.14, \"learn_time_ms\": 8764.002, \"total_train_time_s\": 10.592167139053345}", "{\"n\": 15553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.16, \"learn_time_ms\": 8795.638, \"total_train_time_s\": 9.828225374221802}", "{\"n\": 15554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 8734.712, \"total_train_time_s\": 9.364551544189453}", "{\"n\": 15555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.28, \"learn_time_ms\": 8904.001, \"total_train_time_s\": 11.365954160690308}", "{\"n\": 15556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.22, \"learn_time_ms\": 8556.109, \"total_train_time_s\": 7.944911956787109}", "{\"n\": 15557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.43, \"learn_time_ms\": 8200.292, \"total_train_time_s\": 8.152776002883911}", "{\"n\": 15558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.87, \"learn_time_ms\": 8138.745, \"total_train_time_s\": 9.956084489822388}", "{\"n\": 15559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.87, \"learn_time_ms\": 8129.165, \"total_train_time_s\": 9.901070356369019}", "{\"n\": 15560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.22, \"learn_time_ms\": 8414.435, \"total_train_time_s\": 11.717610836029053}", "{\"n\": 15561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.22, \"learn_time_ms\": 8397.152, \"total_train_time_s\": 9.300975322723389}", "{\"n\": 15562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.45, \"learn_time_ms\": 8387.441, \"total_train_time_s\": 10.469339609146118}", "{\"n\": 15563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.95, \"learn_time_ms\": 8448.911, \"total_train_time_s\": 10.440637826919556}", "{\"n\": 15564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.55, \"learn_time_ms\": 8507.553, \"total_train_time_s\": 9.926865577697754}", "{\"n\": 15565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.74, \"learn_time_ms\": 8404.957, \"total_train_time_s\": 10.317104816436768}", "{\"n\": 15566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.74, \"learn_time_ms\": 8633.074, \"total_train_time_s\": 10.219210863113403}", "{\"n\": 15567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.4, \"learn_time_ms\": 8868.554, \"total_train_time_s\": 10.612112045288086}", "{\"n\": 15568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.71, \"learn_time_ms\": 8811.183, \"total_train_time_s\": 9.455127239227295}", "{\"n\": 15569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.71, \"learn_time_ms\": 8859.971, \"total_train_time_s\": 10.366833686828613}", "{\"n\": 15570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.67, \"learn_time_ms\": 8686.098, \"total_train_time_s\": 9.918494939804077}", "{\"n\": 15571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.11, \"learn_time_ms\": 8748.652, \"total_train_time_s\": 10.016431093215942}", "{\"n\": 15572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.11, \"learn_time_ms\": 8795.773, \"total_train_time_s\": 10.933749914169312}", "{\"n\": 15573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.26, \"learn_time_ms\": 8659.052, \"total_train_time_s\": 9.097692012786865}", "{\"n\": 15574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.62, \"learn_time_ms\": 8727.966, \"total_train_time_s\": 10.585023880004883}", "{\"n\": 15575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.36, \"learn_time_ms\": 8859.607, \"total_train_time_s\": 11.625810384750366}", "{\"n\": 15576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.36, \"learn_time_ms\": 8724.874, \"total_train_time_s\": 8.844042301177979}", "{\"n\": 15577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.75, \"learn_time_ms\": 8554.918, \"total_train_time_s\": 8.80617904663086}", "{\"n\": 15578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.32, \"learn_time_ms\": 8720.134, \"total_train_time_s\": 11.016063213348389}", "{\"n\": 15579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.32, \"learn_time_ms\": 8618.012, \"total_train_time_s\": 9.32440733909607}", "{\"n\": 15580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.46, \"learn_time_ms\": 8525.575, \"total_train_time_s\": 9.049521923065186}", "{\"n\": 15581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.59, \"learn_time_ms\": 8544.435, \"total_train_time_s\": 10.177504777908325}", "{\"n\": 15582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.59, \"learn_time_ms\": 8508.663, \"total_train_time_s\": 10.60337519645691}", "{\"n\": 15583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.59, \"learn_time_ms\": 8679.383, \"total_train_time_s\": 10.762900114059448}", "{\"n\": 15584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.45, \"learn_time_ms\": 8671.676, \"total_train_time_s\": 10.498692989349365}", "{\"n\": 15585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.27, \"learn_time_ms\": 8573.047, \"total_train_time_s\": 10.674604654312134}", "{\"n\": 15586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.27, \"learn_time_ms\": 8687.856, \"total_train_time_s\": 10.030435562133789}", "{\"n\": 15587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.52, \"learn_time_ms\": 8848.296, \"total_train_time_s\": 10.390042304992676}", "{\"n\": 15588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.84, \"learn_time_ms\": 8800.5, \"total_train_time_s\": 10.562824010848999}", "{\"n\": 15589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.84, \"learn_time_ms\": 8994.176, \"total_train_time_s\": 11.250832796096802}", "{\"n\": 15590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.31, \"learn_time_ms\": 9052.267, \"total_train_time_s\": 9.599607229232788}", "{\"n\": 15591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.1, \"learn_time_ms\": 9022.157, \"total_train_time_s\": 9.889675855636597}", "{\"n\": 15592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.1, \"learn_time_ms\": 8890.147, \"total_train_time_s\": 9.257909774780273}", "{\"n\": 15593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.1, \"learn_time_ms\": 8769.363, \"total_train_time_s\": 9.567237854003906}", "{\"n\": 15594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.8, \"learn_time_ms\": 8782.87, \"total_train_time_s\": 10.694404602050781}", "{\"n\": 15595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.17, \"learn_time_ms\": 8638.978, \"total_train_time_s\": 9.23900032043457}", "{\"n\": 15596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.17, \"learn_time_ms\": 8721.013, \"total_train_time_s\": 10.825438737869263}", "{\"n\": 15597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.4, \"learn_time_ms\": 8653.796, \"total_train_time_s\": 9.71778917312622}", "{\"n\": 15598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.11, \"learn_time_ms\": 8739.255, \"total_train_time_s\": 11.446592092514038}", "{\"n\": 15599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.11, \"learn_time_ms\": 8617.668, \"total_train_time_s\": 10.106896877288818}", "{\"n\": 15600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.11, \"learn_time_ms\": 8709.263, \"total_train_time_s\": 10.542388439178467}", "{\"n\": 15601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.14, \"learn_time_ms\": 8659.935, \"total_train_time_s\": 9.401002645492554}", "{\"n\": 15602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.14, \"learn_time_ms\": 8777.512, \"total_train_time_s\": 10.424419164657593}", "{\"n\": 15603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.14, \"learn_time_ms\": 8712.087, \"total_train_time_s\": 8.902635097503662}", "{\"n\": 15604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 8649.063, \"total_train_time_s\": 10.087536573410034}", "{\"n\": 15605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 8721.443, \"total_train_time_s\": 9.914408206939697}", "{\"n\": 15606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 8667.993, \"total_train_time_s\": 10.28186321258545}", "{\"n\": 15607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.84, \"learn_time_ms\": 8765.043, \"total_train_time_s\": 10.731762170791626}", "{\"n\": 15608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.99, \"learn_time_ms\": 8635.275, \"total_train_time_s\": 10.115127801895142}", "{\"n\": 15609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.99, \"learn_time_ms\": 8654.03, \"total_train_time_s\": 10.284503936767578}", "{\"n\": 15610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.99, \"learn_time_ms\": 8561.125, \"total_train_time_s\": 9.55226993560791}", "{\"n\": 15611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 8677.392, \"total_train_time_s\": 10.55908751487732}", "{\"n\": 15612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 8718.462, \"total_train_time_s\": 10.839303970336914}", "{\"n\": 15613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 8753.778, \"total_train_time_s\": 9.289444208145142}", "{\"n\": 15614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.03, \"learn_time_ms\": 8567.079, \"total_train_time_s\": 8.153674364089966}", "{\"n\": 15615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8637.094, \"total_train_time_s\": 10.638769626617432}", "{\"n\": 15616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8596.43, \"total_train_time_s\": 9.882731676101685}", "{\"n\": 15617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 8605.865, \"total_train_time_s\": 10.767562866210938}", "{\"n\": 15618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.63, \"learn_time_ms\": 8558.182, \"total_train_time_s\": 9.683743953704834}", "{\"n\": 15619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.63, \"learn_time_ms\": 8553.237, \"total_train_time_s\": 10.213666915893555}", "{\"n\": 15620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.63, \"learn_time_ms\": 8667.073, \"total_train_time_s\": 10.717293739318848}", "{\"n\": 15621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.46, \"learn_time_ms\": 8702.703, \"total_train_time_s\": 10.932612657546997}", "{\"n\": 15622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.44, \"learn_time_ms\": 8562.096, \"total_train_time_s\": 9.439040184020996}", "{\"n\": 15623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.44, \"learn_time_ms\": 8673.071, \"total_train_time_s\": 10.368484258651733}", "{\"n\": 15624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.68, \"learn_time_ms\": 8789.426, \"total_train_time_s\": 9.34723448753357}", "{\"n\": 15625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 8713.698, \"total_train_time_s\": 9.943010807037354}", "{\"n\": 15626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 8657.936, \"total_train_time_s\": 9.340004444122314}", "{\"n\": 15627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.59, \"learn_time_ms\": 8669.723, \"total_train_time_s\": 10.963459491729736}", "{\"n\": 15628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 8789.727, \"total_train_time_s\": 10.887882232666016}", "{\"n\": 15629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 8974.105, \"total_train_time_s\": 12.065674781799316}", "{\"n\": 15630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.73, \"learn_time_ms\": 8800.751, \"total_train_time_s\": 8.962457418441772}", "{\"n\": 15631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.75, \"learn_time_ms\": 8682.326, \"total_train_time_s\": 9.695133686065674}", "{\"n\": 15632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.6, \"learn_time_ms\": 8815.722, \"total_train_time_s\": 10.764790058135986}", "{\"n\": 15633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.6, \"learn_time_ms\": 8837.771, \"total_train_time_s\": 10.600901365280151}", "{\"n\": 15634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.08, \"learn_time_ms\": 9047.328, \"total_train_time_s\": 11.408329963684082}", "{\"n\": 15635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.02, \"learn_time_ms\": 9162.009, \"total_train_time_s\": 11.04017186164856}", "{\"n\": 15636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.02, \"learn_time_ms\": 9256.405, \"total_train_time_s\": 10.269747257232666}", "{\"n\": 15637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.51, \"learn_time_ms\": 9120.257, \"total_train_time_s\": 9.54976773262024}", "{\"n\": 15638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.84, \"learn_time_ms\": 9050.905, \"total_train_time_s\": 10.11626648902893}", "{\"n\": 15639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.56, \"learn_time_ms\": 8865.199, \"total_train_time_s\": 10.206697225570679}", "{\"n\": 15640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.51, \"learn_time_ms\": 8914.302, \"total_train_time_s\": 9.477424144744873}", "{\"n\": 15641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.03, \"learn_time_ms\": 9059.187, \"total_train_time_s\": 11.139529943466187}", "{\"n\": 15642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.03, \"learn_time_ms\": 9048.709, \"total_train_time_s\": 10.622099876403809}", "{\"n\": 15643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.69, \"learn_time_ms\": 8968.192, \"total_train_time_s\": 9.800321340560913}", "{\"n\": 15644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.69, \"learn_time_ms\": 8912.087, \"total_train_time_s\": 10.850610971450806}", "{\"n\": 15645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.08, \"learn_time_ms\": 8711.698, \"total_train_time_s\": 9.031750202178955}", "{\"n\": 15646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.34, \"learn_time_ms\": 8652.619, \"total_train_time_s\": 9.702692747116089}", "{\"n\": 15647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.42, \"learn_time_ms\": 8694.167, \"total_train_time_s\": 9.959761142730713}", "{\"n\": 15648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.56, \"learn_time_ms\": 8791.157, \"total_train_time_s\": 11.070367097854614}", "{\"n\": 15649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.67, \"learn_time_ms\": 8967.905, \"total_train_time_s\": 11.997031927108765}", "{\"n\": 15650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.64, \"learn_time_ms\": 8786.008, \"total_train_time_s\": 7.627776384353638}", "{\"n\": 15651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.71, \"learn_time_ms\": 8635.122, \"total_train_time_s\": 9.634396076202393}", "{\"n\": 15652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.39, \"learn_time_ms\": 8537.94, \"total_train_time_s\": 9.687493324279785}", "{\"n\": 15653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.33, \"learn_time_ms\": 8574.931, \"total_train_time_s\": 10.15139365196228}", "{\"n\": 15654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.33, \"learn_time_ms\": 8444.585, \"total_train_time_s\": 9.539173126220703}", "{\"n\": 15655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.28, \"learn_time_ms\": 8443.85, \"total_train_time_s\": 9.016832113265991}", "{\"n\": 15656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.66, \"learn_time_ms\": 8549.426, \"total_train_time_s\": 10.773913145065308}", "{\"n\": 15657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.65, \"learn_time_ms\": 8479.79, \"total_train_time_s\": 9.274574041366577}", "{\"n\": 15658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.64, \"learn_time_ms\": 8418.2, \"total_train_time_s\": 10.505614042282104}", "{\"n\": 15659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 8329.298, \"total_train_time_s\": 11.061042070388794}", "{\"n\": 15660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.35, \"learn_time_ms\": 8752.795, \"total_train_time_s\": 11.943991422653198}", "{\"n\": 15661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.3, \"learn_time_ms\": 8764.305, \"total_train_time_s\": 9.771263599395752}", "{\"n\": 15662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.95, \"learn_time_ms\": 8803.525, \"total_train_time_s\": 10.090808391571045}", "{\"n\": 15663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.59, \"learn_time_ms\": 8900.195, \"total_train_time_s\": 11.11650037765503}", "{\"n\": 15664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.71, \"learn_time_ms\": 8878.789, \"total_train_time_s\": 9.326974391937256}", "{\"n\": 15665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.71, \"learn_time_ms\": 8977.711, \"total_train_time_s\": 10.009207963943481}", "{\"n\": 15666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.8, \"learn_time_ms\": 8968.411, \"total_train_time_s\": 10.64232587814331}", "{\"n\": 15667, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.0, \"learn_time_ms\": 8999.138, \"total_train_time_s\": 9.615342617034912}", "{\"n\": 15668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.79, \"learn_time_ms\": 8804.274, \"total_train_time_s\": 8.570351600646973}", "{\"n\": 15669, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.02, \"learn_time_ms\": 8737.546, \"total_train_time_s\": 10.423253059387207}", "{\"n\": 15670, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.02, \"learn_time_ms\": 8454.152, \"total_train_time_s\": 8.983581066131592}", "{\"n\": 15671, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.53, \"learn_time_ms\": 8514.404, \"total_train_time_s\": 10.366576671600342}", "{\"n\": 15672, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.53, \"learn_time_ms\": 8511.59, \"total_train_time_s\": 10.083805561065674}", "{\"n\": 15673, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.76, \"learn_time_ms\": 8320.897, \"total_train_time_s\": 9.224909543991089}", "{\"n\": 15674, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.13, \"learn_time_ms\": 8125.05, \"total_train_time_s\": 7.359212160110474}", "{\"n\": 15675, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.13, \"learn_time_ms\": 8186.33, \"total_train_time_s\": 10.623247861862183}", "{\"n\": 15676, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 8079.612, \"total_train_time_s\": 9.564004182815552}", "{\"n\": 15677, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.02, \"learn_time_ms\": 8062.324, \"total_train_time_s\": 9.408626317977905}", "{\"n\": 15678, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.81, \"learn_time_ms\": 8317.101, \"total_train_time_s\": 11.116766214370728}", "{\"n\": 15679, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.81, \"learn_time_ms\": 8317.737, \"total_train_time_s\": 10.452791213989258}", "{\"n\": 15680, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.17, \"learn_time_ms\": 8517.38, \"total_train_time_s\": 11.12322449684143}", "{\"n\": 15681, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.13, \"learn_time_ms\": 8513.216, \"total_train_time_s\": 10.309453964233398}", "{\"n\": 15682, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.01, \"learn_time_ms\": 8569.786, \"total_train_time_s\": 10.634296178817749}", "{\"n\": 15683, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.11, \"learn_time_ms\": 8727.708, \"total_train_time_s\": 10.81337833404541}", "{\"n\": 15684, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.48, \"learn_time_ms\": 8906.365, \"total_train_time_s\": 9.183149337768555}", "{\"n\": 15685, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.48, \"learn_time_ms\": 9010.739, \"total_train_time_s\": 11.665068864822388}", "{\"n\": 15686, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.54, \"learn_time_ms\": 8975.513, \"total_train_time_s\": 9.24213194847107}", "{\"n\": 15687, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.11, \"learn_time_ms\": 9090.964, \"total_train_time_s\": 10.634236812591553}", "{\"n\": 15688, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.12, \"learn_time_ms\": 9005.313, \"total_train_time_s\": 10.253619194030762}", "{\"n\": 15689, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.16, \"learn_time_ms\": 9024.688, \"total_train_time_s\": 10.594160079956055}", "{\"n\": 15690, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.73, \"learn_time_ms\": 8887.147, \"total_train_time_s\": 9.679653882980347}", "{\"n\": 15691, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.08, \"learn_time_ms\": 9020.222, \"total_train_time_s\": 11.66351056098938}", "{\"n\": 15692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.05, \"learn_time_ms\": 9065.553, \"total_train_time_s\": 11.095046997070312}", "{\"n\": 15693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.51, \"learn_time_ms\": 8979.418, \"total_train_time_s\": 9.906921148300171}", "{\"n\": 15694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.34, \"learn_time_ms\": 9143.723, \"total_train_time_s\": 10.791975259780884}", "{\"n\": 15695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.92, \"learn_time_ms\": 8990.251, \"total_train_time_s\": 10.173920392990112}", "{\"n\": 15696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.92, \"learn_time_ms\": 9138.715, \"total_train_time_s\": 10.707486867904663}", "{\"n\": 15697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.75, \"learn_time_ms\": 9152.902, \"total_train_time_s\": 10.724448204040527}", "{\"n\": 15698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.53, \"learn_time_ms\": 9121.06, \"total_train_time_s\": 9.952443838119507}", "{\"n\": 15699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.53, \"learn_time_ms\": 9146.144, \"total_train_time_s\": 10.85029149055481}", "{\"n\": 15700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.15, \"learn_time_ms\": 9166.366, \"total_train_time_s\": 9.899545669555664}", "{\"n\": 15701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 8896.778, \"total_train_time_s\": 8.93582797050476}", "{\"n\": 15702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 8652.504, \"total_train_time_s\": 8.674205303192139}", "{\"n\": 15703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.83, \"learn_time_ms\": 8598.016, \"total_train_time_s\": 9.393749713897705}", "{\"n\": 15704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.06, \"learn_time_ms\": 8585.69, \"total_train_time_s\": 10.692330360412598}", "{\"n\": 15705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.06, \"learn_time_ms\": 8554.963, \"total_train_time_s\": 9.809003353118896}", "{\"n\": 15706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.06, \"learn_time_ms\": 8532.372, \"total_train_time_s\": 10.512229204177856}", "{\"n\": 15707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3368.46, \"learn_time_ms\": 8452.071, \"total_train_time_s\": 9.928815603256226}", "{\"n\": 15708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.0, \"learn_time_ms\": 8221.976, \"total_train_time_s\": 7.628742218017578}", "{\"n\": 15709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3371.21, \"learn_time_ms\": 8067.896, \"total_train_time_s\": 9.274190902709961}", "{\"n\": 15710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.87, \"learn_time_ms\": 8114.265, \"total_train_time_s\": 10.356764078140259}", "{\"n\": 15711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3372.59, \"learn_time_ms\": 8211.635, \"total_train_time_s\": 9.936603307723999}", "{\"n\": 15712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.58, \"learn_time_ms\": 8371.375, \"total_train_time_s\": 10.231640577316284}", "{\"n\": 15713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.58, \"learn_time_ms\": 8358.427, \"total_train_time_s\": 9.229994773864746}", "{\"n\": 15714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.29, \"learn_time_ms\": 8323.155, \"total_train_time_s\": 10.285608053207397}", "{\"n\": 15715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.79, \"learn_time_ms\": 8282.253, \"total_train_time_s\": 9.4300377368927}", "{\"n\": 15716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.79, \"learn_time_ms\": 8373.484, \"total_train_time_s\": 11.386443376541138}", "{\"n\": 15717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.02, \"learn_time_ms\": 8514.955, \"total_train_time_s\": 11.322596788406372}", "{\"n\": 15718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3382.96, \"learn_time_ms\": 8739.231, \"total_train_time_s\": 9.861156225204468}", "{\"n\": 15719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.47, \"learn_time_ms\": 8823.731, \"total_train_time_s\": 10.157967567443848}", "{\"n\": 15720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.37, \"learn_time_ms\": 8771.885, \"total_train_time_s\": 9.850234031677246}", "{\"n\": 15721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3377.33, \"learn_time_ms\": 8699.524, \"total_train_time_s\": 9.244257688522339}", "{\"n\": 15722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.58, \"learn_time_ms\": 8631.863, \"total_train_time_s\": 9.60304594039917}", "{\"n\": 15723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.58, \"learn_time_ms\": 8711.494, \"total_train_time_s\": 10.028382539749146}", "{\"n\": 15724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3384.88, \"learn_time_ms\": 8628.672, \"total_train_time_s\": 9.490898609161377}", "{\"n\": 15725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.48, \"learn_time_ms\": 8673.524, \"total_train_time_s\": 9.839591979980469}", "{\"n\": 15726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.55, \"learn_time_ms\": 8498.654, \"total_train_time_s\": 9.641347885131836}", "{\"n\": 15727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.78, \"learn_time_ms\": 8346.067, \"total_train_time_s\": 9.803074836730957}", "{\"n\": 15728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.73, \"learn_time_ms\": 8356.522, \"total_train_time_s\": 10.04008173942566}", "{\"n\": 15729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3414.28, \"learn_time_ms\": 8387.688, \"total_train_time_s\": 10.43470287322998}", "{\"n\": 15730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3414.28, \"learn_time_ms\": 8265.591, \"total_train_time_s\": 8.562658548355103}", "{\"n\": 15731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3419.63, \"learn_time_ms\": 8382.308, \"total_train_time_s\": 10.389198780059814}", "{\"n\": 15732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3419.63, \"learn_time_ms\": 8546.811, \"total_train_time_s\": 11.23874807357788}", "{\"n\": 15733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3419.38, \"learn_time_ms\": 8421.065, \"total_train_time_s\": 8.799899101257324}", "{\"n\": 15734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3421.21, \"learn_time_ms\": 8396.482, \"total_train_time_s\": 9.229594469070435}", "{\"n\": 15735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3422.08, \"learn_time_ms\": 8446.582, \"total_train_time_s\": 10.409393072128296}", "{\"n\": 15736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3425.44, \"learn_time_ms\": 8467.263, \"total_train_time_s\": 9.858105182647705}", "{\"n\": 15737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3418.6, \"learn_time_ms\": 8461.999, \"total_train_time_s\": 9.771417140960693}", "{\"n\": 15738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3417.65, \"learn_time_ms\": 8408.182, \"total_train_time_s\": 9.425481796264648}", "{\"n\": 15739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3421.82, \"learn_time_ms\": 8383.212, \"total_train_time_s\": 10.259047508239746}", "{\"n\": 15740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3420.28, \"learn_time_ms\": 8550.837, \"total_train_time_s\": 10.28151822090149}", "{\"n\": 15741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3421.21, \"learn_time_ms\": 8518.612, \"total_train_time_s\": 10.042093515396118}", "{\"n\": 15742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 8535.428, \"total_train_time_s\": 11.379883527755737}", "{\"n\": 15743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.9, \"learn_time_ms\": 8838.356, \"total_train_time_s\": 11.833425045013428}", "{\"n\": 15744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3422.02, \"learn_time_ms\": 9120.217, \"total_train_time_s\": 12.062956094741821}", "{\"n\": 15745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.53, \"learn_time_ms\": 9208.285, \"total_train_time_s\": 11.25684142112732}", "{\"n\": 15746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.43, \"learn_time_ms\": 9226.964, \"total_train_time_s\": 10.065036296844482}", "{\"n\": 15747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.15, \"learn_time_ms\": 9331.341, \"total_train_time_s\": 10.810056924819946}", "{\"n\": 15748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.82, \"learn_time_ms\": 9413.413, \"total_train_time_s\": 10.276497840881348}", "{\"n\": 15749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.11, \"learn_time_ms\": 9407.932, \"total_train_time_s\": 10.1798996925354}", "{\"n\": 15750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.11, \"learn_time_ms\": 9460.045, \"total_train_time_s\": 10.857401847839355}", "{\"n\": 15751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.94, \"learn_time_ms\": 9467.416, \"total_train_time_s\": 10.10337781906128}", "{\"n\": 15752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.93, \"learn_time_ms\": 9253.707, \"total_train_time_s\": 9.245543479919434}", "{\"n\": 15753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.02, \"learn_time_ms\": 9150.429, \"total_train_time_s\": 10.789407968521118}", "{\"n\": 15754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.02, \"learn_time_ms\": 8937.468, \"total_train_time_s\": 9.961408853530884}", "{\"n\": 15755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3428.46, \"learn_time_ms\": 8846.62, \"total_train_time_s\": 10.364865064620972}", "{\"n\": 15756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.32, \"learn_time_ms\": 8705.116, \"total_train_time_s\": 8.630499124526978}", "{\"n\": 15757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.32, \"learn_time_ms\": 8580.887, \"total_train_time_s\": 9.559215068817139}", "{\"n\": 15758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3434.49, \"learn_time_ms\": 8552.894, \"total_train_time_s\": 9.970435619354248}", "{\"n\": 15759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.42, \"learn_time_ms\": 8468.744, \"total_train_time_s\": 9.288519382476807}", "{\"n\": 15760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3431.01, \"learn_time_ms\": 8289.096, \"total_train_time_s\": 9.008898258209229}", "{\"n\": 15761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3428.07, \"learn_time_ms\": 8361.375, \"total_train_time_s\": 10.846756219863892}", "{\"n\": 15762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.03, \"learn_time_ms\": 8461.318, \"total_train_time_s\": 10.291731119155884}", "{\"n\": 15763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.06, \"learn_time_ms\": 8403.654, \"total_train_time_s\": 10.229329586029053}", "{\"n\": 15764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.06, \"learn_time_ms\": 8378.89, \"total_train_time_s\": 9.686206817626953}", "{\"n\": 15765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.19, \"learn_time_ms\": 8492.525, \"total_train_time_s\": 11.477636575698853}", "{\"n\": 15766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.77, \"learn_time_ms\": 8773.946, \"total_train_time_s\": 11.485781192779541}", "{\"n\": 15767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.22, \"learn_time_ms\": 8787.947, \"total_train_time_s\": 9.733242988586426}", "{\"n\": 15768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.22, \"learn_time_ms\": 8776.915, \"total_train_time_s\": 9.854359149932861}", "{\"n\": 15769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.36, \"learn_time_ms\": 8970.393, \"total_train_time_s\": 11.29028582572937}", "{\"n\": 15770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.36, \"learn_time_ms\": 9084.244, \"total_train_time_s\": 10.110187292098999}", "{\"n\": 15771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.87, \"learn_time_ms\": 9035.558, \"total_train_time_s\": 10.341888904571533}", "{\"n\": 15772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.8, \"learn_time_ms\": 8902.352, \"total_train_time_s\": 8.899317741394043}", "{\"n\": 15773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.12, \"learn_time_ms\": 8706.365, \"total_train_time_s\": 8.241645574569702}", "{\"n\": 15774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3423.54, \"learn_time_ms\": 8759.233, \"total_train_time_s\": 10.238640308380127}", "{\"n\": 15775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3423.54, \"learn_time_ms\": 8575.584, \"total_train_time_s\": 9.620636701583862}", "{\"n\": 15776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.44, \"learn_time_ms\": 8487.957, \"total_train_time_s\": 10.584612607955933}", "{\"n\": 15777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.44, \"learn_time_ms\": 8661.444, \"total_train_time_s\": 11.437176704406738}", "{\"n\": 15778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.85, \"learn_time_ms\": 8780.689, \"total_train_time_s\": 11.078569412231445}", "{\"n\": 15779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.89, \"learn_time_ms\": 8690.95, \"total_train_time_s\": 10.353200197219849}", "{\"n\": 15780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.72, \"learn_time_ms\": 8698.354, \"total_train_time_s\": 10.219122886657715}", "{\"n\": 15781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.72, \"learn_time_ms\": 8706.745, \"total_train_time_s\": 10.415268182754517}", "{\"n\": 15782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3430.59, \"learn_time_ms\": 8824.049, \"total_train_time_s\": 10.078004121780396}", "{\"n\": 15783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3436.78, \"learn_time_ms\": 8901.939, \"total_train_time_s\": 9.01180648803711}", "{\"n\": 15784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3436.78, \"learn_time_ms\": 8950.517, \"total_train_time_s\": 10.699841499328613}", "{\"n\": 15785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3446.48, \"learn_time_ms\": 8966.805, \"total_train_time_s\": 9.802402257919312}", "{\"n\": 15786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3445.73, \"learn_time_ms\": 8913.783, \"total_train_time_s\": 9.999695062637329}", "{\"n\": 15787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3443.87, \"learn_time_ms\": 8754.385, \"total_train_time_s\": 9.876212120056152}", "{\"n\": 15788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3443.87, \"learn_time_ms\": 8609.711, \"total_train_time_s\": 9.637090682983398}", "{\"n\": 15789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 8655.577, \"total_train_time_s\": 10.808030605316162}", "{\"n\": 15790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3457.47, \"learn_time_ms\": 8460.678, \"total_train_time_s\": 8.264869928359985}", "{\"n\": 15791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3457.47, \"learn_time_ms\": 8532.264, \"total_train_time_s\": 11.158846855163574}", "{\"n\": 15792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3459.62, \"learn_time_ms\": 8522.703, \"total_train_time_s\": 9.971518278121948}", "{\"n\": 15793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3464.76, \"learn_time_ms\": 8671.505, \"total_train_time_s\": 10.515952587127686}", "{\"n\": 15794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3466.79, \"learn_time_ms\": 8682.528, \"total_train_time_s\": 10.819562911987305}", "{\"n\": 15795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3466.79, \"learn_time_ms\": 8668.402, \"total_train_time_s\": 9.66576600074768}", "{\"n\": 15796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3473.03, \"learn_time_ms\": 8624.393, \"total_train_time_s\": 9.666109561920166}", "{\"n\": 15797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3483.49, \"learn_time_ms\": 8692.901, \"total_train_time_s\": 10.521050930023193}", "{\"n\": 15798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3483.49, \"learn_time_ms\": 8798.941, \"total_train_time_s\": 10.713937282562256}", "{\"n\": 15799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.16, \"learn_time_ms\": 8705.695, \"total_train_time_s\": 9.862411737442017}", "{\"n\": 15800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.94, \"learn_time_ms\": 8917.758, \"total_train_time_s\": 10.385038375854492}", "{\"n\": 15801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.55, \"learn_time_ms\": 8695.781, \"total_train_time_s\": 8.962958812713623}", "{\"n\": 15802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.64, \"learn_time_ms\": 8648.555, \"total_train_time_s\": 9.473536968231201}", "{\"n\": 15803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.17, \"learn_time_ms\": 8556.511, \"total_train_time_s\": 9.586169004440308}", "{\"n\": 15804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.1, \"learn_time_ms\": 8361.27, \"total_train_time_s\": 8.83291506767273}", "{\"n\": 15805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.1, \"learn_time_ms\": 8416.447, \"total_train_time_s\": 10.203775644302368}", "{\"n\": 15806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.09, \"learn_time_ms\": 8632.099, \"total_train_time_s\": 11.791860580444336}", "{\"n\": 15807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.27, \"learn_time_ms\": 8685.72, \"total_train_time_s\": 11.04813289642334}", "{\"n\": 15808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.27, \"learn_time_ms\": 8649.258, \"total_train_time_s\": 10.302950620651245}", "{\"n\": 15809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.33, \"learn_time_ms\": 8706.696, \"total_train_time_s\": 10.508503675460815}", "{\"n\": 15810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.44, \"learn_time_ms\": 8746.077, \"total_train_time_s\": 10.785553216934204}", "{\"n\": 15811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.44, \"learn_time_ms\": 8858.648, \"total_train_time_s\": 10.042541980743408}", "{\"n\": 15812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.46, \"learn_time_ms\": 8911.659, \"total_train_time_s\": 10.052374362945557}", "{\"n\": 15813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.93, \"learn_time_ms\": 8881.395, \"total_train_time_s\": 9.293812274932861}", "{\"n\": 15814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.24, \"learn_time_ms\": 9003.945, \"total_train_time_s\": 10.114053726196289}", "{\"n\": 15815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.6, \"learn_time_ms\": 9054.651, \"total_train_time_s\": 10.750521183013916}", "{\"n\": 15816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.6, \"learn_time_ms\": 8770.603, \"total_train_time_s\": 8.954424619674683}", "{\"n\": 15817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.34, \"learn_time_ms\": 8680.1, \"total_train_time_s\": 10.16875147819519}", "{\"n\": 15818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.34, \"learn_time_ms\": 8616.741, \"total_train_time_s\": 9.70332646369934}", "{\"n\": 15819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.7, \"learn_time_ms\": 8425.058, \"total_train_time_s\": 8.554500102996826}", "{\"n\": 15820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.67, \"learn_time_ms\": 8355.539, \"total_train_time_s\": 10.056065559387207}", "{\"n\": 15821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.67, \"learn_time_ms\": 8248.928, \"total_train_time_s\": 8.963155508041382}", "{\"n\": 15822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.03, \"learn_time_ms\": 8242.124, \"total_train_time_s\": 9.963029861450195}", "{\"n\": 15823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.56, \"learn_time_ms\": 8344.718, \"total_train_time_s\": 10.286076307296753}", "{\"n\": 15824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.56, \"learn_time_ms\": 8372.545, \"total_train_time_s\": 10.362054347991943}", "{\"n\": 15825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.06, \"learn_time_ms\": 8233.428, \"total_train_time_s\": 9.324599504470825}", "{\"n\": 15826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.33, \"learn_time_ms\": 8389.85, \"total_train_time_s\": 10.47698974609375}", "{\"n\": 15827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.72, \"learn_time_ms\": 8419.795, \"total_train_time_s\": 10.421872615814209}", "{\"n\": 15828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.79, \"learn_time_ms\": 8560.478, \"total_train_time_s\": 11.084326028823853}", "{\"n\": 15829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.88, \"learn_time_ms\": 8861.695, \"total_train_time_s\": 11.577879905700684}", "{\"n\": 15830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.04, \"learn_time_ms\": 8830.187, \"total_train_time_s\": 9.715903997421265}", "{\"n\": 15831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.16, \"learn_time_ms\": 9073.316, \"total_train_time_s\": 11.393681526184082}", "{\"n\": 15832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.88, \"learn_time_ms\": 9104.346, \"total_train_time_s\": 10.268097639083862}", "{\"n\": 15833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.22, \"learn_time_ms\": 9279.28, \"total_train_time_s\": 12.112067699432373}", "{\"n\": 15834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.52, \"learn_time_ms\": 9255.809, \"total_train_time_s\": 10.091652393341064}", "{\"n\": 15835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.84, \"learn_time_ms\": 9293.943, \"total_train_time_s\": 9.753060102462769}", "{\"n\": 15836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3442.18, \"learn_time_ms\": 9368.639, \"total_train_time_s\": 11.219507694244385}", "{\"n\": 15837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.97, \"learn_time_ms\": 9351.132, \"total_train_time_s\": 10.286387920379639}", "{\"n\": 15838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.97, \"learn_time_ms\": 9139.486, \"total_train_time_s\": 8.99989104270935}", "{\"n\": 15839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.14, \"learn_time_ms\": 8916.763, \"total_train_time_s\": 9.313604593276978}", "{\"n\": 15840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.84, \"learn_time_ms\": 9018.075, \"total_train_time_s\": 10.780173301696777}", "{\"n\": 15841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.22, \"learn_time_ms\": 8800.407, \"total_train_time_s\": 9.248809576034546}", "{\"n\": 15842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.22, \"learn_time_ms\": 8690.439, \"total_train_time_s\": 9.21276307106018}", "{\"n\": 15843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.2, \"learn_time_ms\": 8386.746, \"total_train_time_s\": 9.035469055175781}", "{\"n\": 15844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.44, \"learn_time_ms\": 8438.774, \"total_train_time_s\": 10.686177968978882}", "{\"n\": 15845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.44, \"learn_time_ms\": 8553.975, \"total_train_time_s\": 10.825142621994019}", "{\"n\": 15846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.83, \"learn_time_ms\": 8414.338, \"total_train_time_s\": 9.822292566299438}", "{\"n\": 15847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.43, \"learn_time_ms\": 8405.3, \"total_train_time_s\": 10.160136222839355}", "{\"n\": 15848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.43, \"learn_time_ms\": 8401.934, \"total_train_time_s\": 8.9296715259552}", "{\"n\": 15849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.43, \"learn_time_ms\": 8466.367, \"total_train_time_s\": 9.95688509941101}", "{\"n\": 15850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3436.19, \"learn_time_ms\": 8274.297, \"total_train_time_s\": 8.859048128128052}", "{\"n\": 15851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.14, \"learn_time_ms\": 8368.013, \"total_train_time_s\": 10.178027391433716}", "{\"n\": 15852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.14, \"learn_time_ms\": 8446.072, \"total_train_time_s\": 9.95107126235962}", "{\"n\": 15853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.43, \"learn_time_ms\": 8484.201, \"total_train_time_s\": 9.400956630706787}", "{\"n\": 15854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.21, \"learn_time_ms\": 8421.19, \"total_train_time_s\": 10.044702529907227}", "{\"n\": 15855, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.82, \"learn_time_ms\": 8264.12, \"total_train_time_s\": 9.301581859588623}", "{\"n\": 15856, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.55, \"learn_time_ms\": 8265.331, \"total_train_time_s\": 9.832439661026001}", "{\"n\": 15857, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.99, \"learn_time_ms\": 8284.462, \"total_train_time_s\": 10.331223964691162}", "{\"n\": 15858, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.01, \"learn_time_ms\": 8300.13, \"total_train_time_s\": 9.077690362930298}", "{\"n\": 15859, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.01, \"learn_time_ms\": 8105.313, \"total_train_time_s\": 8.026901721954346}", "{\"n\": 15860, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.25, \"learn_time_ms\": 8261.494, \"total_train_time_s\": 10.449270486831665}", "{\"n\": 15861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.91, \"learn_time_ms\": 8187.96, \"total_train_time_s\": 9.431014776229858}", "{\"n\": 15862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3436.03, \"learn_time_ms\": 8255.371, \"total_train_time_s\": 10.62285041809082}", "{\"n\": 15863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.67, \"learn_time_ms\": 8303.716, \"total_train_time_s\": 9.906808853149414}", "{\"n\": 15864, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.67, \"learn_time_ms\": 8301.245, \"total_train_time_s\": 9.955945253372192}", "{\"n\": 15865, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.26, \"learn_time_ms\": 8321.281, \"total_train_time_s\": 9.479356050491333}", "{\"n\": 15866, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.92, \"learn_time_ms\": 8314.355, \"total_train_time_s\": 9.800034046173096}", "{\"n\": 15867, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.28, \"learn_time_ms\": 8470.863, \"total_train_time_s\": 11.914810419082642}", "{\"n\": 15868, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.75, \"learn_time_ms\": 8696.919, \"total_train_time_s\": 11.333869457244873}", "{\"n\": 15869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.75, \"learn_time_ms\": 8950.137, \"total_train_time_s\": 10.53009581565857}", "{\"n\": 15870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.12, \"learn_time_ms\": 8951.577, \"total_train_time_s\": 10.483479261398315}", "{\"n\": 15871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.28, \"learn_time_ms\": 8890.41, \"total_train_time_s\": 8.874655723571777}", "{\"n\": 15872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.83, \"learn_time_ms\": 8821.266, \"total_train_time_s\": 9.948807001113892}", "{\"n\": 15873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.75, \"learn_time_ms\": 8853.157, \"total_train_time_s\": 10.262506246566772}", "{\"n\": 15874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.75, \"learn_time_ms\": 8740.34, \"total_train_time_s\": 8.835267543792725}", "{\"n\": 15875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.24, \"learn_time_ms\": 8772.391, \"total_train_time_s\": 9.840211391448975}", "{\"n\": 15876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.24, \"learn_time_ms\": 8784.314, \"total_train_time_s\": 9.941147565841675}", "{\"n\": 15877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.56, \"learn_time_ms\": 8625.222, \"total_train_time_s\": 10.418238639831543}", "{\"n\": 15878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.85, \"learn_time_ms\": 8363.139, \"total_train_time_s\": 8.782429695129395}", "{\"n\": 15879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.25, \"learn_time_ms\": 8405.162, \"total_train_time_s\": 10.996774911880493}", "{\"n\": 15880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.3, \"learn_time_ms\": 8290.539, \"total_train_time_s\": 9.31662130355835}", "{\"n\": 15881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.07, \"learn_time_ms\": 8403.524, \"total_train_time_s\": 9.981163740158081}", "{\"n\": 15882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.15, \"learn_time_ms\": 8512.308, \"total_train_time_s\": 11.027331352233887}", "{\"n\": 15883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.21, \"learn_time_ms\": 8394.933, \"total_train_time_s\": 9.031625509262085}", "{\"n\": 15884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.66, \"learn_time_ms\": 8362.541, \"total_train_time_s\": 8.542474508285522}", "{\"n\": 15885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.21, \"learn_time_ms\": 8226.375, \"total_train_time_s\": 8.46608567237854}", "{\"n\": 15886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.21, \"learn_time_ms\": 8087.07, \"total_train_time_s\": 8.492777347564697}", "{\"n\": 15887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.89, \"learn_time_ms\": 8170.271, \"total_train_time_s\": 11.166483402252197}", "{\"n\": 15888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.14, \"learn_time_ms\": 8309.198, \"total_train_time_s\": 10.136881589889526}", "{\"n\": 15889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.94, \"learn_time_ms\": 8192.598, \"total_train_time_s\": 9.833228588104248}", "{\"n\": 15890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.56, \"learn_time_ms\": 8296.127, \"total_train_time_s\": 10.334636926651001}", "{\"n\": 15891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.82, \"learn_time_ms\": 8289.12, \"total_train_time_s\": 9.867063760757446}", "{\"n\": 15892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.24, \"learn_time_ms\": 8260.897, \"total_train_time_s\": 10.740141153335571}", "{\"n\": 15893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.42, \"learn_time_ms\": 8399.627, \"total_train_time_s\": 10.425810813903809}", "{\"n\": 15894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.53, \"learn_time_ms\": 8732.337, \"total_train_time_s\": 11.875933170318604}", "{\"n\": 15895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.98, \"learn_time_ms\": 8921.425, \"total_train_time_s\": 10.316253185272217}", "{\"n\": 15896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.04, \"learn_time_ms\": 9084.582, \"total_train_time_s\": 10.111246824264526}", "{\"n\": 15897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.04, \"learn_time_ms\": 8776.449, \"total_train_time_s\": 8.108991146087646}", "{\"n\": 15898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.27, \"learn_time_ms\": 8689.789, \"total_train_time_s\": 9.263193130493164}", "{\"n\": 15899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3376.99, \"learn_time_ms\": 8765.838, \"total_train_time_s\": 10.596896886825562}", "{\"n\": 15900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.44, \"learn_time_ms\": 8722.081, \"total_train_time_s\": 9.918576002120972}", "{\"n\": 15901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3371.19, \"learn_time_ms\": 8742.247, \"total_train_time_s\": 10.073048830032349}", "{\"n\": 15902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3371.02, \"learn_time_ms\": 8622.266, \"total_train_time_s\": 9.532880306243896}", "{\"n\": 15903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.71, \"learn_time_ms\": 8529.19, \"total_train_time_s\": 9.546695947647095}", "{\"n\": 15904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.71, \"learn_time_ms\": 8302.532, \"total_train_time_s\": 9.595962285995483}", "{\"n\": 15905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.42, \"learn_time_ms\": 8230.431, \"total_train_time_s\": 9.651365041732788}", "{\"n\": 15906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.31, \"learn_time_ms\": 8095.312, \"total_train_time_s\": 8.772294282913208}", "{\"n\": 15907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.31, \"learn_time_ms\": 8303.773, \"total_train_time_s\": 10.133363962173462}", "{\"n\": 15908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.72, \"learn_time_ms\": 8329.724, \"total_train_time_s\": 9.521778583526611}", "{\"n\": 15909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.45, \"learn_time_ms\": 8222.131, \"total_train_time_s\": 9.476969480514526}", "{\"n\": 15910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.45, \"learn_time_ms\": 8193.59, \"total_train_time_s\": 9.578064441680908}", "{\"n\": 15911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.45, \"learn_time_ms\": 8245.959, \"total_train_time_s\": 10.617317914962769}", "{\"n\": 15912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.6, \"learn_time_ms\": 8334.786, \"total_train_time_s\": 10.497053623199463}", "{\"n\": 15913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.56, \"learn_time_ms\": 8321.035, \"total_train_time_s\": 9.419977903366089}", "{\"n\": 15914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.56, \"learn_time_ms\": 8572.737, \"total_train_time_s\": 12.117205381393433}", "{\"n\": 15915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.3, \"learn_time_ms\": 8585.983, \"total_train_time_s\": 9.771400690078735}", "{\"n\": 15916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.9, \"learn_time_ms\": 8843.666, \"total_train_time_s\": 11.365363359451294}", "{\"n\": 15917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.78, \"learn_time_ms\": 8842.861, \"total_train_time_s\": 10.16550064086914}", "{\"n\": 15918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.73, \"learn_time_ms\": 8985.591, \"total_train_time_s\": 10.929072856903076}", "{\"n\": 15919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.93, \"learn_time_ms\": 9016.925, \"total_train_time_s\": 9.796672344207764}", "{\"n\": 15920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.71, \"learn_time_ms\": 9048.459, \"total_train_time_s\": 9.919902563095093}", "{\"n\": 15921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.71, \"learn_time_ms\": 9132.694, \"total_train_time_s\": 11.454658269882202}", "{\"n\": 15922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.75, \"learn_time_ms\": 9175.312, \"total_train_time_s\": 10.866147994995117}", "{\"n\": 15923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.87, \"learn_time_ms\": 9282.955, \"total_train_time_s\": 10.465669631958008}", "{\"n\": 15924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.5, \"learn_time_ms\": 9212.008, \"total_train_time_s\": 11.433459758758545}", "{\"n\": 15925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.25, \"learn_time_ms\": 9272.54, \"total_train_time_s\": 10.333682298660278}", "{\"n\": 15926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.24, \"learn_time_ms\": 9103.035, \"total_train_time_s\": 9.699524879455566}", "{\"n\": 15927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.59, \"learn_time_ms\": 9192.262, \"total_train_time_s\": 11.069061994552612}", "{\"n\": 15928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.42, \"learn_time_ms\": 9150.008, \"total_train_time_s\": 10.562771558761597}", "{\"n\": 15929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.93, \"learn_time_ms\": 8925.026, \"total_train_time_s\": 7.541424989700317}", "{\"n\": 15930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 8568.567, \"total_train_time_s\": 6.463529109954834}", "{\"n\": 15931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 8084.066, \"total_train_time_s\": 6.755255460739136}", "{\"n\": 15932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.29, \"learn_time_ms\": 8059.815, \"total_train_time_s\": 10.593406915664673}", "{\"n\": 15933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.69, \"learn_time_ms\": 8016.654, \"total_train_time_s\": 10.169600009918213}", "{\"n\": 15934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.69, \"learn_time_ms\": 7893.817, \"total_train_time_s\": 10.16566252708435}", "{\"n\": 15935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.34, \"learn_time_ms\": 7789.35, \"total_train_time_s\": 9.328992128372192}", "{\"n\": 15936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 7805.118, \"total_train_time_s\": 9.839931964874268}", "{\"n\": 15937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 7627.35, \"total_train_time_s\": 9.277540922164917}", "{\"n\": 15938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 7506.705, \"total_train_time_s\": 9.333004713058472}", "{\"n\": 15939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.22, \"learn_time_ms\": 7779.908, \"total_train_time_s\": 10.279267072677612}", "{\"n\": 15940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.24, \"learn_time_ms\": 8167.336, \"total_train_time_s\": 10.232829570770264}", "{\"n\": 15941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.24, \"learn_time_ms\": 8449.21, \"total_train_time_s\": 9.430672407150269}", "{\"n\": 15942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 8414.804, \"total_train_time_s\": 10.241573333740234}", "{\"n\": 15943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 8359.032, \"total_train_time_s\": 9.481208086013794}", "{\"n\": 15944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 8457.261, \"total_train_time_s\": 11.140684127807617}", "{\"n\": 15945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.89, \"learn_time_ms\": 8483.066, \"total_train_time_s\": 9.561278581619263}", "{\"n\": 15946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.16, \"learn_time_ms\": 8437.812, \"total_train_time_s\": 9.327393054962158}", "{\"n\": 15947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.83, \"learn_time_ms\": 8444.706, \"total_train_time_s\": 9.341306209564209}", "{\"n\": 15948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.83, \"learn_time_ms\": 8466.317, \"total_train_time_s\": 9.511392593383789}", "{\"n\": 15949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.69, \"learn_time_ms\": 8480.163, \"total_train_time_s\": 10.469039916992188}", "{\"n\": 15950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.38, \"learn_time_ms\": 8562.523, \"total_train_time_s\": 11.075022220611572}", "{\"n\": 15951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.38, \"learn_time_ms\": 8592.336, \"total_train_time_s\": 9.758639097213745}"]