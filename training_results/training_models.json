["{\"n\": 14152, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10631.466, \"total_train_time_s\": 13.051432371139526}", "{\"n\": 14153, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10716.352, \"total_train_time_s\": 12.702216625213623}", "{\"n\": 14154, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10793.319, \"total_train_time_s\": 12.838826179504395}", "{\"n\": 14155, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10431.214, \"total_train_time_s\": 11.24973464012146}", "{\"n\": 14156, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10318.556, \"total_train_time_s\": 11.745831489562988}", "{\"n\": 14157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 2613.0, \"learn_time_ms\": 10265.272, \"total_train_time_s\": 11.911189794540405}", "{\"n\": 14158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3142.5, \"learn_time_ms\": 10282.441, \"total_train_time_s\": 12.335097074508667}", "{\"n\": 14159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.0, \"learn_time_ms\": 10309.087, \"total_train_time_s\": 12.41108751296997}", "{\"n\": 14160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3285.2, \"learn_time_ms\": 10278.821, \"total_train_time_s\": 11.970726251602173}", "{\"n\": 14161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3285.2, \"learn_time_ms\": 10140.634, \"total_train_time_s\": 10.842216730117798}", "{\"n\": 14162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.166666666666667, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3207.0, \"learn_time_ms\": 10060.722, \"total_train_time_s\": 11.752584457397461}", "{\"n\": 14163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3357.8888888888887, \"learn_time_ms\": 9897.825, \"total_train_time_s\": 11.161962032318115}", "{\"n\": 14164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3357.8888888888887, \"learn_time_ms\": 9738.188, \"total_train_time_s\": 11.251864671707153}", "{\"n\": 14165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3357.8888888888887, \"learn_time_ms\": 9823.166, \"total_train_time_s\": 12.130712509155273}", "{\"n\": 14166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3425.8, \"learn_time_ms\": 9739.397, \"total_train_time_s\": 10.95795226097107}", "{\"n\": 14167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0833333333333335, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.9166666666665, \"learn_time_ms\": 9785.892, \"total_train_time_s\": 12.362500429153442}", "{\"n\": 14168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.1538461538461537, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3485.6153846153848, \"learn_time_ms\": 9810.412, \"total_train_time_s\": 12.544942378997803}", "{\"n\": 14169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.7857142857142858, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.9285714285716, \"learn_time_ms\": 9835.466, \"total_train_time_s\": 12.654553651809692}", "{\"n\": 14170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.375, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.375, \"learn_time_ms\": 9886.631, \"total_train_time_s\": 12.48414945602417}", "{\"n\": 14171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.2352941176470589, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.823529411765, \"learn_time_ms\": 10047.813, \"total_train_time_s\": 12.414630651473999}", "{\"n\": 14172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.7777777777777778, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.1111111111113, \"learn_time_ms\": 10055.246, \"total_train_time_s\": 11.770457744598389}", "{\"n\": 14173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.3157894736842105, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.157894736842, \"learn_time_ms\": 10170.76, \"total_train_time_s\": 12.223678827285767}", "{\"n\": 14174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3597.8, \"learn_time_ms\": 10338.942, \"total_train_time_s\": 12.924041748046875}", "{\"n\": 14175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -0.14285714285714285, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.285714285714, \"learn_time_ms\": 10408.66, \"total_train_time_s\": 12.83107328414917}", "{\"n\": 14176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.36363636363636365, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3583.4545454545455, \"learn_time_ms\": 10485.387, \"total_train_time_s\": 11.730897426605225}", "{\"n\": 14177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.8695652173913043, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3551.6521739130435, \"learn_time_ms\": 10398.151, \"total_train_time_s\": 11.499689102172852}", "{\"n\": 14178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0416666666666667, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.9166666666665, \"learn_time_ms\": 10278.579, \"total_train_time_s\": 11.323299407958984}", "{\"n\": 14179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1923076923076923, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.0384615384614, \"learn_time_ms\": 10324.109, \"total_train_time_s\": 13.083959579467773}", "{\"n\": 14180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.5185185185187, \"learn_time_ms\": 10122.857, \"total_train_time_s\": 10.442285299301147}", "{\"n\": 14181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.8928571428573, \"learn_time_ms\": 10033.403, \"total_train_time_s\": 11.504929780960083}", "{\"n\": 14182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.6, \"learn_time_ms\": 10023.567, \"total_train_time_s\": 11.68917989730835}", "{\"n\": 14183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.6, \"learn_time_ms\": 10046.727, \"total_train_time_s\": 12.43485975265503}", "{\"n\": 14184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.71875, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.34375, \"learn_time_ms\": 9940.281, \"total_train_time_s\": 11.85563850402832}", "{\"n\": 14185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.71875, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.34375, \"learn_time_ms\": 9921.939, \"total_train_time_s\": 12.59000563621521}", "{\"n\": 14186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.060606060606, \"learn_time_ms\": 9981.661, \"total_train_time_s\": 12.311475276947021}", "{\"n\": 14187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3888888888888888, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.4166666666665, \"learn_time_ms\": 10089.326, \"total_train_time_s\": 12.578850269317627}", "{\"n\": 14188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3888888888888888, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.4166666666665, \"learn_time_ms\": 10171.284, \"total_train_time_s\": 12.12533187866211}", "{\"n\": 14189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3888888888888888, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3552.4166666666665, \"learn_time_ms\": 10060.356, \"total_train_time_s\": 11.966430425643921}", "{\"n\": 14190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.631578947368421, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.1052631578946, \"learn_time_ms\": 10216.817, \"total_train_time_s\": 12.015343189239502}", "{\"n\": 14191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.725, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.725, \"learn_time_ms\": 10191.231, \"total_train_time_s\": 11.275631427764893}", "{\"n\": 14192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.725, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.725, \"learn_time_ms\": 10227.192, \"total_train_time_s\": 12.0883047580719}", "{\"n\": 14193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.809523809524, \"learn_time_ms\": 10194.427, \"total_train_time_s\": 12.149491310119629}", "{\"n\": 14194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.5116279069767442, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.8837209302324, \"learn_time_ms\": 10253.059, \"total_train_time_s\": 12.502976179122925}", "{\"n\": 14195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3863636363636365, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.409090909091, \"learn_time_ms\": 10157.876, \"total_train_time_s\": 11.667410135269165}", "{\"n\": 14196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3863636363636365, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.409090909091, \"learn_time_ms\": 10144.644, \"total_train_time_s\": 12.156534910202026}", "{\"n\": 14197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.127659574468085, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.6382978723404, \"learn_time_ms\": 10083.535, \"total_train_time_s\": 11.970277070999146}", "{\"n\": 14198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1666666666666667, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.3541666666665, \"learn_time_ms\": 10024.704, \"total_train_time_s\": 11.594945669174194}", "{\"n\": 14199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1666666666666667, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.3541666666665, \"learn_time_ms\": 10062.577, \"total_train_time_s\": 12.360555171966553}", "{\"n\": 14200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3535.0, \"learn_time_ms\": 10204.824, \"total_train_time_s\": 13.414987325668335}", "{\"n\": 14201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9423076923076923, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.75, \"learn_time_ms\": 10266.942, \"total_train_time_s\": 12.016677379608154}", "{\"n\": 14202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9423076923076923, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.75, \"learn_time_ms\": 10292.368, \"total_train_time_s\": 12.317489862442017}", "{\"n\": 14203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1320754716981132, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.9056603773583, \"learn_time_ms\": 10237.264, \"total_train_time_s\": 11.587169408798218}", "{\"n\": 14204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3527.4, \"learn_time_ms\": 10289.147, \"total_train_time_s\": 13.003226518630981}", "{\"n\": 14205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3392857142857142, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.4464285714284, \"learn_time_ms\": 10290.355, \"total_train_time_s\": 11.671204566955566}", "{\"n\": 14206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.543859649122807, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3509.59649122807, \"learn_time_ms\": 10285.219, \"total_train_time_s\": 12.158158540725708}", "{\"n\": 14207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6551724137931034, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3506.362068965517, \"learn_time_ms\": 10255.435, \"total_train_time_s\": 11.637929677963257}", "{\"n\": 14208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.5333333333333334, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3514.116666666667, \"learn_time_ms\": 10403.866, \"total_train_time_s\": 13.0254225730896}", "{\"n\": 14209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6721311475409837, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3506.754098360656, \"learn_time_ms\": 10443.186, \"total_train_time_s\": 12.73493504524231}", "{\"n\": 14210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6721311475409837, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3506.754098360656, \"learn_time_ms\": 10315.97, \"total_train_time_s\": 12.117186307907104}", "{\"n\": 14211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.4603174603174602, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3511.6190476190477, \"learn_time_ms\": 10410.118, \"total_train_time_s\": 12.835610628128052}", "{\"n\": 14212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.34375, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3510.265625, \"learn_time_ms\": 10387.243, \"total_train_time_s\": 12.117499828338623}", "{\"n\": 14213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.3692307692307693, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3511.123076923077, \"learn_time_ms\": 10420.658, \"total_train_time_s\": 11.945557117462158}", "{\"n\": 14214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.2424242424242424, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.590909090909, \"learn_time_ms\": 10327.171, \"total_train_time_s\": 12.048302412033081}", "{\"n\": 14215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1791044776119404, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.9850746268658, \"learn_time_ms\": 10380.251, \"total_train_time_s\": 12.237650632858276}", "{\"n\": 14216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9710144927536232, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3500.246376811594, \"learn_time_ms\": 10405.103, \"total_train_time_s\": 12.335082769393921}", "{\"n\": 14217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9710144927536232, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3500.246376811594, \"learn_time_ms\": 10598.754, \"total_train_time_s\": 13.606645345687866}", "{\"n\": 14218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0285714285714285, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3503.442857142857, \"learn_time_ms\": 10489.228, \"total_train_time_s\": 11.956656694412231}", "{\"n\": 14219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3518.222222222222, \"learn_time_ms\": 10413.233, \"total_train_time_s\": 12.039530992507935}", "{\"n\": 14220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0273972602739727, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.972602739726, \"learn_time_ms\": 10421.824, \"total_train_time_s\": 12.232026100158691}", "{\"n\": 14221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0273972602739727, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.972602739726, \"learn_time_ms\": 10503.92, \"total_train_time_s\": 13.666237592697144}", "{\"n\": 14222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.2, \"learn_time_ms\": 10568.375, \"total_train_time_s\": 12.739313840866089}", "{\"n\": 14223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1168831168831168, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.5194805194806, \"learn_time_ms\": 10633.946, \"total_train_time_s\": 12.60319709777832}", "{\"n\": 14224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1168831168831168, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.5194805194806, \"learn_time_ms\": 10558.541, \"total_train_time_s\": 11.345743179321289}", "{\"n\": 14225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.1168831168831168, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.5194805194806, \"learn_time_ms\": 10472.769, \"total_train_time_s\": 11.335116863250732}", "{\"n\": 14226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9125, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.8625, \"learn_time_ms\": 10361.507, \"total_train_time_s\": 11.2857985496521}", "{\"n\": 14227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.8024691358024691, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.5555555555557, \"learn_time_ms\": 10176.825, \"total_train_time_s\": 11.761065006256104}", "{\"n\": 14228, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.8024691358024691, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.5555555555557, \"learn_time_ms\": 10127.395, \"total_train_time_s\": 11.43421459197998}", "{\"n\": 14229, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.8024691358024691, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.5555555555557, \"learn_time_ms\": 10147.225, \"total_train_time_s\": 12.221500158309937}", "{\"n\": 14230, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0119047619047619, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.8690476190477, \"learn_time_ms\": 10094.69, \"total_train_time_s\": 11.810886859893799}", "{\"n\": 14231, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9529411764705882, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.3529411764707, \"learn_time_ms\": 9948.401, \"total_train_time_s\": 12.214152812957764}", "{\"n\": 14232, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9529411764705882, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.3529411764707, \"learn_time_ms\": 9894.557, \"total_train_time_s\": 12.180207967758179}", "{\"n\": 14233, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9529411764705882, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.3529411764707, \"learn_time_ms\": 9887.022, \"total_train_time_s\": 12.50348448753357}", "{\"n\": 14234, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.4044943820227, \"learn_time_ms\": 10080.189, \"total_train_time_s\": 13.238706111907959}", "{\"n\": 14235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.4044943820227, \"learn_time_ms\": 10137.021, \"total_train_time_s\": 11.941484689712524}", "{\"n\": 14236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.4044943820227, \"learn_time_ms\": 10274.769, \"total_train_time_s\": 12.671696901321411}", "{\"n\": 14237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.8586956521739131, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.3478260869565, \"learn_time_ms\": 10268.763, \"total_train_time_s\": 11.725944519042969}", "{\"n\": 14238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.946236559139785, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.0860215053763, \"learn_time_ms\": 10260.55, \"total_train_time_s\": 11.396305084228516}", "{\"n\": 14239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.946236559139785, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.0860215053763, \"learn_time_ms\": 10238.757, \"total_train_time_s\": 11.962076902389526}", "{\"n\": 14240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.946236559139785, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.0860215053763, \"learn_time_ms\": 10413.43, \"total_train_time_s\": 13.471285343170166}", "{\"n\": 14241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.90625, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.4270833333335, \"learn_time_ms\": 10485.768, \"total_train_time_s\": 12.93198299407959}", "{\"n\": 14242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9278350515463918, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.536082474227, \"learn_time_ms\": 10370.617, \"total_train_time_s\": 11.089012145996094}", "{\"n\": 14243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.9278350515463918, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.536082474227, \"learn_time_ms\": 10385.968, \"total_train_time_s\": 12.658034801483154}", "{\"n\": 14244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.0408163265306123, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.6326530612246, \"learn_time_ms\": 10269.171, \"total_train_time_s\": 12.056591272354126}", "{\"n\": 14245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.33, \"learn_time_ms\": 10229.029, \"total_train_time_s\": 11.524360418319702}", "{\"n\": 14246, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.41, \"learn_time_ms\": 10110.435, \"total_train_time_s\": 11.465707540512085}", "{\"n\": 14247, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.41, \"learn_time_ms\": 10126.406, \"total_train_time_s\": 11.840026617050171}", "{\"n\": 14248, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.8, \"learn_time_ms\": 10295.495, \"total_train_time_s\": 13.095791578292847}", "{\"n\": 14249, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 10461.498, \"total_train_time_s\": 13.678960800170898}", "{\"n\": 14250, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 10298.32, \"total_train_time_s\": 11.973312616348267}", "{\"n\": 14251, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 10273.95, \"total_train_time_s\": 12.661145210266113}", "{\"n\": 14252, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.3, \"learn_time_ms\": 10399.357, \"total_train_time_s\": 12.37158989906311}", "{\"n\": 14253, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.67, \"learn_time_ms\": 10294.288, \"total_train_time_s\": 11.670235633850098}", "{\"n\": 14254, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.67, \"learn_time_ms\": 10215.662, \"total_train_time_s\": 11.278198957443237}", "{\"n\": 14255, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.29, \"learn_time_ms\": 10258.414, \"total_train_time_s\": 11.924100160598755}", "{\"n\": 14256, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.37, \"learn_time_ms\": 10417.637, \"total_train_time_s\": 13.056785821914673}", "{\"n\": 14257, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.69, \"learn_time_ms\": 10426.056, \"total_train_time_s\": 11.928654193878174}", "{\"n\": 14258, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.57, \"learn_time_ms\": 10216.903, \"total_train_time_s\": 11.007814407348633}", "{\"n\": 14259, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.3, \"learn_time_ms\": 10070.709, \"total_train_time_s\": 12.208304166793823}", "{\"n\": 14260, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.32, \"learn_time_ms\": 10119.39, \"total_train_time_s\": 12.313727855682373}", "{\"n\": 14261, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.74, \"learn_time_ms\": 10094.495, \"total_train_time_s\": 12.396791934967041}", "{\"n\": 14262, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.34, \"learn_time_ms\": 10174.92, \"total_train_time_s\": 13.127384185791016}", "{\"n\": 14263, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.15, \"learn_time_ms\": 10252.563, \"total_train_time_s\": 12.4245924949646}", "{\"n\": 14264, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.54, \"learn_time_ms\": 10383.296, \"total_train_time_s\": 12.609103679656982}", "{\"n\": 14265, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.54, \"learn_time_ms\": 10356.297, \"total_train_time_s\": 11.688467264175415}", "{\"n\": 14266, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.73, \"learn_time_ms\": 10150.447, \"total_train_time_s\": 10.990166187286377}", "{\"n\": 14267, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.49, \"learn_time_ms\": 10210.929, \"total_train_time_s\": 12.516711235046387}", "{\"n\": 14268, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 10271.198, \"total_train_time_s\": 11.567529439926147}", "{\"n\": 14269, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 10247.944, \"total_train_time_s\": 11.986294031143188}", "{\"n\": 14270, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.17, \"learn_time_ms\": 10144.894, \"total_train_time_s\": 11.305299520492554}", "{\"n\": 14271, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.17, \"learn_time_ms\": 10112.068, \"total_train_time_s\": 12.069823741912842}", "{\"n\": 14272, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.07, \"learn_time_ms\": 10032.429, \"total_train_time_s\": 12.28356647491455}", "{\"n\": 14273, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.98, \"learn_time_ms\": 10089.737, \"total_train_time_s\": 12.955087900161743}", "{\"n\": 14274, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.75, \"learn_time_ms\": 10019.655, \"total_train_time_s\": 11.8819739818573}", "{\"n\": 14275, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.7, \"learn_time_ms\": 9939.755, \"total_train_time_s\": 10.926929473876953}", "{\"n\": 14276, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.7, \"learn_time_ms\": 10084.133, \"total_train_time_s\": 12.415937900543213}", "{\"n\": 14277, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.07, \"learn_time_ms\": 10045.584, \"total_train_time_s\": 12.182962894439697}", "{\"n\": 14278, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.32, \"learn_time_ms\": 10157.458, \"total_train_time_s\": 12.673124313354492}", "{\"n\": 14279, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10167.751, \"total_train_time_s\": 12.052608728408813}", "{\"n\": 14280, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.26, \"learn_time_ms\": 10198.119, \"total_train_time_s\": 11.605867624282837}", "{\"n\": 14281, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.84, \"learn_time_ms\": 10086.832, \"total_train_time_s\": 11.008631944656372}", "{\"n\": 14282, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.84, \"learn_time_ms\": 10118.387, \"total_train_time_s\": 12.609036445617676}", "{\"n\": 14283, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.57, \"learn_time_ms\": 10018.776, \"total_train_time_s\": 11.91888689994812}", "{\"n\": 14284, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.34, \"learn_time_ms\": 10023.533, \"total_train_time_s\": 11.891092300415039}", "{\"n\": 14285, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 10224.891, \"total_train_time_s\": 12.890496253967285}", "{\"n\": 14286, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 10264.188, \"total_train_time_s\": 12.84176254272461}", "{\"n\": 14287, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.28, \"learn_time_ms\": 10277.184, \"total_train_time_s\": 12.309911489486694}", "{\"n\": 14288, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.63, \"learn_time_ms\": 10110.211, \"total_train_time_s\": 11.042394876480103}", "{\"n\": 14289, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.74, \"learn_time_ms\": 10200.441, \"total_train_time_s\": 13.022428750991821}", "{\"n\": 14290, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.74, \"learn_time_ms\": 10158.845, \"total_train_time_s\": 11.184337377548218}", "{\"n\": 14291, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.31, \"learn_time_ms\": 10288.251, \"total_train_time_s\": 12.306191682815552}", "{\"n\": 14292, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.24, \"learn_time_ms\": 10180.138, \"total_train_time_s\": 11.586743831634521}", "{\"n\": 14293, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.24, \"learn_time_ms\": 10180.437, \"total_train_time_s\": 11.95667576789856}", "{\"n\": 14294, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.24, \"learn_time_ms\": 10120.016, \"total_train_time_s\": 11.315386295318604}", "{\"n\": 14295, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.26, \"learn_time_ms\": 10073.059, \"total_train_time_s\": 12.423262357711792}", "{\"n\": 14296, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.13, \"learn_time_ms\": 10052.498, \"total_train_time_s\": 12.604232549667358}", "{\"n\": 14297, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.13, \"learn_time_ms\": 9989.367, \"total_train_time_s\": 11.622435092926025}", "{\"n\": 14298, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.13, \"learn_time_ms\": 10121.81, \"total_train_time_s\": 12.351311206817627}", "{\"n\": 14299, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.73, \"learn_time_ms\": 10057.165, \"total_train_time_s\": 12.345478773117065}", "{\"n\": 14300, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.67, \"learn_time_ms\": 10094.142, \"total_train_time_s\": 11.583627700805664}", "{\"n\": 14301, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.67, \"learn_time_ms\": 10184.495, \"total_train_time_s\": 13.177250862121582}", "{\"n\": 14302, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.88, \"learn_time_ms\": 10185.24, \"total_train_time_s\": 11.547814846038818}", "{\"n\": 14303, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.3, \"learn_time_ms\": 10164.423, \"total_train_time_s\": 11.747175931930542}", "{\"n\": 14304, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.3, \"learn_time_ms\": 10262.884, \"total_train_time_s\": 12.285920143127441}", "{\"n\": 14305, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.05, \"learn_time_ms\": 10254.064, \"total_train_time_s\": 12.327091217041016}", "{\"n\": 14306, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.62, \"learn_time_ms\": 10223.418, \"total_train_time_s\": 12.31781792640686}", "{\"n\": 14307, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.56, \"learn_time_ms\": 10273.938, \"total_train_time_s\": 12.133663177490234}", "{\"n\": 14308, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.56, \"learn_time_ms\": 10133.177, \"total_train_time_s\": 10.943481922149658}", "{\"n\": 14309, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.02, \"learn_time_ms\": 10184.223, \"total_train_time_s\": 12.809158086776733}", "{\"n\": 14310, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.27, \"learn_time_ms\": 10238.261, \"total_train_time_s\": 12.08326530456543}", "{\"n\": 14311, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.86, \"learn_time_ms\": 10132.185, \"total_train_time_s\": 12.146684169769287}", "{\"n\": 14312, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.86, \"learn_time_ms\": 10227.353, \"total_train_time_s\": 12.524214506149292}", "{\"n\": 14313, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.77, \"learn_time_ms\": 10244.381, \"total_train_time_s\": 11.905023097991943}", "{\"n\": 14314, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 10254.676, \"total_train_time_s\": 12.44898509979248}", "{\"n\": 14315, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 10343.634, \"total_train_time_s\": 13.227266073226929}", "{\"n\": 14316, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 10299.671, \"total_train_time_s\": 11.840034484863281}", "{\"n\": 14317, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.2, \"learn_time_ms\": 10234.881, \"total_train_time_s\": 11.549268245697021}", "{\"n\": 14318, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.97, \"learn_time_ms\": 10281.092, \"total_train_time_s\": 11.42765474319458}", "{\"n\": 14319, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.97, \"learn_time_ms\": 10063.607, \"total_train_time_s\": 10.664167881011963}", "{\"n\": 14320, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.67, \"learn_time_ms\": 10114.528, \"total_train_time_s\": 12.63135313987732}", "{\"n\": 14321, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.3, \"learn_time_ms\": 10064.095, \"total_train_time_s\": 11.629502773284912}", "{\"n\": 14322, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.54, \"learn_time_ms\": 10018.609, \"total_train_time_s\": 12.059225797653198}", "{\"n\": 14323, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3685.64, \"learn_time_ms\": 10015.492, \"total_train_time_s\": 11.864200115203857}", "{\"n\": 14324, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3682.64, \"learn_time_ms\": 10016.598, \"total_train_time_s\": 12.395013332366943}", "{\"n\": 14325, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.24, \"learn_time_ms\": 9866.079, \"total_train_time_s\": 11.695805549621582}", "{\"n\": 14326, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3681.25, \"learn_time_ms\": 9838.88, \"total_train_time_s\": 11.580745458602905}", "{\"n\": 14327, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3681.25, \"learn_time_ms\": 9956.658, \"total_train_time_s\": 12.70886492729187}", "{\"n\": 14328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.48, \"learn_time_ms\": 9919.789, \"total_train_time_s\": 11.043959617614746}", "{\"n\": 14329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.48, \"learn_time_ms\": 10049.201, \"total_train_time_s\": 11.911320209503174}", "{\"n\": 14330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.97, \"learn_time_ms\": 10073.089, \"total_train_time_s\": 12.778504610061646}", "{\"n\": 14331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3649.12, \"learn_time_ms\": 10088.795, \"total_train_time_s\": 11.794943571090698}", "{\"n\": 14332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3654.67, \"learn_time_ms\": 10128.218, \"total_train_time_s\": 12.4294753074646}", "{\"n\": 14333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.88, \"learn_time_ms\": 10139.937, \"total_train_time_s\": 12.012196779251099}", "{\"n\": 14334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.88, \"learn_time_ms\": 10107.572, \"total_train_time_s\": 12.09567642211914}", "{\"n\": 14335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 10130.281, \"total_train_time_s\": 11.969128370285034}", "{\"n\": 14336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.76, \"learn_time_ms\": 10134.132, \"total_train_time_s\": 11.641960382461548}", "{\"n\": 14337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.9, \"learn_time_ms\": 10027.462, \"total_train_time_s\": 11.668007373809814}", "{\"n\": 14338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.18, \"learn_time_ms\": 10126.197, \"total_train_time_s\": 12.059885025024414}", "{\"n\": 14339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3655.51, \"learn_time_ms\": 10290.202, \"total_train_time_s\": 13.568805694580078}", "{\"n\": 14340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3649.75, \"learn_time_ms\": 10233.229, \"total_train_time_s\": 12.24258017539978}", "{\"n\": 14341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.16, \"learn_time_ms\": 10258.779, \"total_train_time_s\": 12.031750917434692}", "{\"n\": 14342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3648.05, \"learn_time_ms\": 10280.562, \"total_train_time_s\": 12.690333366394043}", "{\"n\": 14343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.55, \"learn_time_ms\": 10351.155, \"total_train_time_s\": 12.705178022384644}", "{\"n\": 14344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3648.81, \"learn_time_ms\": 10306.542, \"total_train_time_s\": 11.648167848587036}", "{\"n\": 14345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3648.81, \"learn_time_ms\": 10207.386, \"total_train_time_s\": 10.92161750793457}", "{\"n\": 14346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.18, \"learn_time_ms\": 10301.422, \"total_train_time_s\": 12.628329038619995}", "{\"n\": 14347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3647.18, \"learn_time_ms\": 10357.53, \"total_train_time_s\": 12.152653455734253}", "{\"n\": 14348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.23, \"learn_time_ms\": 10362.905, \"total_train_time_s\": 12.11200761795044}", "{\"n\": 14349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.51, \"learn_time_ms\": 10242.103, \"total_train_time_s\": 12.369895458221436}", "{\"n\": 14350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.04, \"learn_time_ms\": 10200.234, \"total_train_time_s\": 11.820549488067627}", "{\"n\": 14351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.04, \"learn_time_ms\": 10167.577, \"total_train_time_s\": 11.686255931854248}", "{\"n\": 14352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3645.86, \"learn_time_ms\": 10109.468, \"total_train_time_s\": 12.094593048095703}", "{\"n\": 14353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.73, \"learn_time_ms\": 9959.126, \"total_train_time_s\": 11.21889853477478}", "{\"n\": 14354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.73, \"learn_time_ms\": 10104.155, \"total_train_time_s\": 13.105194568634033}", "{\"n\": 14355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3640.16, \"learn_time_ms\": 10176.21, \"total_train_time_s\": 11.723713397979736}", "{\"n\": 14356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 10203.017, \"total_train_time_s\": 12.888094186782837}", "{\"n\": 14357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.56, \"learn_time_ms\": 10190.381, \"total_train_time_s\": 12.09581971168518}", "{\"n\": 14358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.56, \"learn_time_ms\": 10378.166, \"total_train_time_s\": 13.949272632598877}", "{\"n\": 14359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3623.72, \"learn_time_ms\": 10393.531, \"total_train_time_s\": 12.570951700210571}", "{\"n\": 14360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3624.53, \"learn_time_ms\": 10449.766, \"total_train_time_s\": 12.46042537689209}", "{\"n\": 14361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3623.93, \"learn_time_ms\": 10478.442, \"total_train_time_s\": 12.010651588439941}", "{\"n\": 14362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 10468.959, \"total_train_time_s\": 12.019542217254639}", "{\"n\": 14363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 10565.177, \"total_train_time_s\": 12.145768165588379}", "{\"n\": 14364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.5, \"learn_time_ms\": 10522.48, \"total_train_time_s\": 12.684656858444214}", "{\"n\": 14365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.86, \"learn_time_ms\": 10718.396, \"total_train_time_s\": 13.668986797332764}", "{\"n\": 14366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.07, \"learn_time_ms\": 10649.882, \"total_train_time_s\": 12.177565336227417}", "{\"n\": 14367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.07, \"learn_time_ms\": 10575.695, \"total_train_time_s\": 11.333646774291992}", "{\"n\": 14368, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.51, \"learn_time_ms\": 10365.987, \"total_train_time_s\": 11.850694417953491}", "{\"n\": 14369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.51, \"learn_time_ms\": 10027.923, \"total_train_time_s\": 9.176738977432251}", "{\"n\": 14370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.43, \"learn_time_ms\": 9871.826, \"total_train_time_s\": 11.07694959640503}", "{\"n\": 14371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.44, \"learn_time_ms\": 9989.072, \"total_train_time_s\": 13.1467444896698}", "{\"n\": 14372, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.95, \"learn_time_ms\": 10101.93, \"total_train_time_s\": 13.123890161514282}", "{\"n\": 14373, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.95, \"learn_time_ms\": 10105.543, \"total_train_time_s\": 12.195106267929077}", "{\"n\": 14374, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.09, \"learn_time_ms\": 10059.346, \"total_train_time_s\": 12.207820415496826}", "{\"n\": 14375, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 9983.999, \"total_train_time_s\": 12.93562126159668}", "{\"n\": 14376, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 9985.003, \"total_train_time_s\": 12.134317874908447}", "{\"n\": 14377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 10148.127, \"total_train_time_s\": 12.961170196533203}", "{\"n\": 14378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 10159.094, \"total_train_time_s\": 11.974241733551025}", "{\"n\": 14379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.07, \"learn_time_ms\": 10378.643, \"total_train_time_s\": 11.357914209365845}", "{\"n\": 14380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.07, \"learn_time_ms\": 10484.24, \"total_train_time_s\": 11.917448282241821}", "{\"n\": 14381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.45, \"learn_time_ms\": 10410.891, \"total_train_time_s\": 12.426040887832642}", "{\"n\": 14382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.24, \"learn_time_ms\": 10424.883, \"total_train_time_s\": 13.242494821548462}", "{\"n\": 14383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.24, \"learn_time_ms\": 10357.038, \"total_train_time_s\": 11.518743753433228}", "{\"n\": 14384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.24, \"learn_time_ms\": 10346.842, \"total_train_time_s\": 12.106946468353271}", "{\"n\": 14385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.65, \"learn_time_ms\": 10233.985, \"total_train_time_s\": 11.77142333984375}", "{\"n\": 14386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3588.63, \"learn_time_ms\": 10273.624, \"total_train_time_s\": 12.543664455413818}", "{\"n\": 14387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.96, \"learn_time_ms\": 10229.437, \"total_train_time_s\": 12.51602816581726}", "{\"n\": 14388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3586.6, \"learn_time_ms\": 10231.836, \"total_train_time_s\": 12.016083240509033}", "{\"n\": 14389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3591.69, \"learn_time_ms\": 10312.408, \"total_train_time_s\": 12.193012952804565}", "{\"n\": 14390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10243.275, \"total_train_time_s\": 11.245136976242065}", "{\"n\": 14391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10313.457, \"total_train_time_s\": 13.14353895187378}", "{\"n\": 14392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10247.752, \"total_train_time_s\": 12.604708194732666}", "{\"n\": 14393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.88, \"learn_time_ms\": 10365.443, \"total_train_time_s\": 12.731016635894775}", "{\"n\": 14394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.86, \"learn_time_ms\": 10230.769, \"total_train_time_s\": 10.773914575576782}", "{\"n\": 14395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.86, \"learn_time_ms\": 10278.784, \"total_train_time_s\": 12.29671573638916}", "{\"n\": 14396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.49, \"learn_time_ms\": 10192.705, \"total_train_time_s\": 11.723621129989624}", "{\"n\": 14397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.33, \"learn_time_ms\": 10214.585, \"total_train_time_s\": 12.723516702651978}", "{\"n\": 14398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3607.0, \"learn_time_ms\": 10206.198, \"total_train_time_s\": 11.893579483032227}", "{\"n\": 14399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.53, \"learn_time_ms\": 10231.704, \"total_train_time_s\": 12.400444746017456}", "{\"n\": 14400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.46, \"learn_time_ms\": 10433.672, \"total_train_time_s\": 13.2467200756073}", "{\"n\": 14401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.46, \"learn_time_ms\": 10414.132, \"total_train_time_s\": 12.913269996643066}", "{\"n\": 14402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3607.76, \"learn_time_ms\": 10360.728, \"total_train_time_s\": 12.097223281860352}", "{\"n\": 14403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.08, \"learn_time_ms\": 10272.38, \"total_train_time_s\": 11.841853141784668}", "{\"n\": 14404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 10409.738, \"total_train_time_s\": 12.164380311965942}", "{\"n\": 14405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 10409.36, \"total_train_time_s\": 12.222918033599854}", "{\"n\": 14406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.21, \"learn_time_ms\": 10380.123, \"total_train_time_s\": 11.39642333984375}", "{\"n\": 14407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3586.17, \"learn_time_ms\": 10407.793, \"total_train_time_s\": 12.994927644729614}", "{\"n\": 14408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3586.17, \"learn_time_ms\": 10418.462, \"total_train_time_s\": 11.962387084960938}", "{\"n\": 14409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3587.19, \"learn_time_ms\": 10447.366, \"total_train_time_s\": 12.70543360710144}", "{\"n\": 14410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.4, \"learn_time_ms\": 10287.878, \"total_train_time_s\": 11.620189189910889}", "{\"n\": 14411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.22, \"learn_time_ms\": 10170.506, \"total_train_time_s\": 11.77491307258606}", "{\"n\": 14412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.08, \"learn_time_ms\": 10229.74, \"total_train_time_s\": 12.657624006271362}", "{\"n\": 14413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.12, \"learn_time_ms\": 10194.453, \"total_train_time_s\": 11.495180130004883}", "{\"n\": 14414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.29, \"learn_time_ms\": 10156.504, \"total_train_time_s\": 11.778903484344482}", "{\"n\": 14415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.11, \"learn_time_ms\": 10323.374, \"total_train_time_s\": 13.920504093170166}", "{\"n\": 14416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.99, \"learn_time_ms\": 10432.042, \"total_train_time_s\": 12.541978359222412}", "{\"n\": 14417, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.61, \"learn_time_ms\": 10353.321, \"total_train_time_s\": 12.229141235351562}", "{\"n\": 14418, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.53, \"learn_time_ms\": 10380.715, \"total_train_time_s\": 12.285538911819458}", "{\"n\": 14419, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 10353.784, \"total_train_time_s\": 12.398535966873169}", "{\"n\": 14420, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.46, \"learn_time_ms\": 10416.784, \"total_train_time_s\": 12.262973070144653}", "{\"n\": 14421, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.23, \"learn_time_ms\": 10408.677, \"total_train_time_s\": 11.705193042755127}", "{\"n\": 14422, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.23, \"learn_time_ms\": 10357.93, \"total_train_time_s\": 12.15914535522461}", "{\"n\": 14423, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.33, \"learn_time_ms\": 10540.187, \"total_train_time_s\": 13.313714981079102}", "{\"n\": 14424, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.63, \"learn_time_ms\": 10541.295, \"total_train_time_s\": 11.771895170211792}", "{\"n\": 14425, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.63, \"learn_time_ms\": 10306.936, \"total_train_time_s\": 11.55590558052063}", "{\"n\": 14426, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.63, \"learn_time_ms\": 10323.559, \"total_train_time_s\": 12.649331092834473}", "{\"n\": 14427, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.64, \"learn_time_ms\": 10315.969, \"total_train_time_s\": 12.161795377731323}", "{\"n\": 14428, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.33, \"learn_time_ms\": 10272.856, \"total_train_time_s\": 11.885890483856201}", "{\"n\": 14429, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.21, \"learn_time_ms\": 10194.377, \"total_train_time_s\": 11.639284372329712}", "{\"n\": 14430, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.28, \"learn_time_ms\": 10151.449, \"total_train_time_s\": 11.866785526275635}", "{\"n\": 14431, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.2, \"learn_time_ms\": 10181.886, \"total_train_time_s\": 11.959011554718018}", "{\"n\": 14432, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.32, \"learn_time_ms\": 10243.715, \"total_train_time_s\": 12.774780750274658}", "{\"n\": 14433, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.32, \"learn_time_ms\": 10014.0, \"total_train_time_s\": 11.01893663406372}", "{\"n\": 14434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.92, \"learn_time_ms\": 10020.947, \"total_train_time_s\": 11.793100833892822}", "{\"n\": 14435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.6, \"learn_time_ms\": 10041.726, \"total_train_time_s\": 11.776320695877075}", "{\"n\": 14436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3562.6, \"learn_time_ms\": 9949.841, \"total_train_time_s\": 11.731642246246338}", "{\"n\": 14437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.84, \"learn_time_ms\": 10000.708, \"total_train_time_s\": 12.667405366897583}", "{\"n\": 14438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.84, \"learn_time_ms\": 10058.579, \"total_train_time_s\": 12.510581970214844}", "{\"n\": 14439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.3, \"learn_time_ms\": 10047.013, \"total_train_time_s\": 11.564203262329102}", "{\"n\": 14440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.3, \"learn_time_ms\": 10051.595, \"total_train_time_s\": 11.876575469970703}", "{\"n\": 14441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.25, \"learn_time_ms\": 10048.247, \"total_train_time_s\": 11.960489511489868}", "{\"n\": 14442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 10016.699, \"total_train_time_s\": 12.481293201446533}", "{\"n\": 14443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.59, \"learn_time_ms\": 10197.438, \"total_train_time_s\": 12.835611581802368}", "{\"n\": 14444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.11, \"learn_time_ms\": 10259.478, \"total_train_time_s\": 12.46401047706604}", "{\"n\": 14445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.53, \"learn_time_ms\": 10275.784, \"total_train_time_s\": 11.95020580291748}", "{\"n\": 14446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.59, \"learn_time_ms\": 10261.752, \"total_train_time_s\": 11.596433877944946}", "{\"n\": 14447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.59, \"learn_time_ms\": 10180.562, \"total_train_time_s\": 11.853304147720337}", "{\"n\": 14448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.63, \"learn_time_ms\": 10213.909, \"total_train_time_s\": 12.918123245239258}", "{\"n\": 14449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3584.63, \"learn_time_ms\": 10215.198, \"total_train_time_s\": 11.532473087310791}", "{\"n\": 14450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.61, \"learn_time_ms\": 10127.567, \"total_train_time_s\": 11.025444269180298}", "{\"n\": 14451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.61, \"learn_time_ms\": 10071.835, \"total_train_time_s\": 11.425447225570679}", "{\"n\": 14452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.25, \"learn_time_ms\": 9955.782, \"total_train_time_s\": 11.258967638015747}", "{\"n\": 14453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.33, \"learn_time_ms\": 9862.49, \"total_train_time_s\": 11.886602878570557}", "{\"n\": 14454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.33, \"learn_time_ms\": 9799.706, \"total_train_time_s\": 11.853484630584717}", "{\"n\": 14455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.74, \"learn_time_ms\": 9783.825, \"total_train_time_s\": 11.799051761627197}", "{\"n\": 14456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.37, \"learn_time_ms\": 9917.682, \"total_train_time_s\": 12.94616413116455}", "{\"n\": 14457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.0, \"learn_time_ms\": 9906.24, \"total_train_time_s\": 11.69765019416809}", "{\"n\": 14458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.68, \"learn_time_ms\": 9885.008, \"total_train_time_s\": 12.548096895217896}", "{\"n\": 14459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.68, \"learn_time_ms\": 9933.228, \"total_train_time_s\": 12.03062915802002}", "{\"n\": 14460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.91, \"learn_time_ms\": 9987.39, \"total_train_time_s\": 11.582258701324463}", "{\"n\": 14461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.19, \"learn_time_ms\": 10074.823, \"total_train_time_s\": 12.246918439865112}", "{\"n\": 14462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.22, \"learn_time_ms\": 10180.915, \"total_train_time_s\": 12.375397205352783}", "{\"n\": 14463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.22, \"learn_time_ms\": 10184.597, \"total_train_time_s\": 11.929104089736938}", "{\"n\": 14464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.65, \"learn_time_ms\": 10192.948, \"total_train_time_s\": 11.8853759765625}", "{\"n\": 14465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 10276.215, \"total_train_time_s\": 12.60639238357544}", "{\"n\": 14466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 10121.915, \"total_train_time_s\": 11.42531967163086}", "{\"n\": 14467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.52, \"learn_time_ms\": 10148.455, \"total_train_time_s\": 12.00295090675354}", "{\"n\": 14468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.17, \"learn_time_ms\": 10138.666, \"total_train_time_s\": 12.49031400680542}", "{\"n\": 14469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.12, \"learn_time_ms\": 10111.931, \"total_train_time_s\": 11.751492023468018}", "{\"n\": 14470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.12, \"learn_time_ms\": 10175.408, \"total_train_time_s\": 12.167306900024414}", "{\"n\": 14471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.38, \"learn_time_ms\": 10162.785, \"total_train_time_s\": 12.12966275215149}", "{\"n\": 14472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.96, \"learn_time_ms\": 10103.394, \"total_train_time_s\": 11.76357913017273}", "{\"n\": 14473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3600.41, \"learn_time_ms\": 10165.482, \"total_train_time_s\": 12.544938564300537}", "{\"n\": 14474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.72, \"learn_time_ms\": 10143.098, \"total_train_time_s\": 11.683393716812134}", "{\"n\": 14475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.72, \"learn_time_ms\": 10032.311, \"total_train_time_s\": 11.489357233047485}", "{\"n\": 14476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.16, \"learn_time_ms\": 10037.986, \"total_train_time_s\": 11.450639247894287}", "{\"n\": 14477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.16, \"learn_time_ms\": 9948.629, \"total_train_time_s\": 11.10127878189087}", "{\"n\": 14478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3593.45, \"learn_time_ms\": 9894.826, \"total_train_time_s\": 11.958702564239502}", "{\"n\": 14479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.89, \"learn_time_ms\": 9875.258, \"total_train_time_s\": 11.576863765716553}", "{\"n\": 14480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.17, \"learn_time_ms\": 9881.766, \"total_train_time_s\": 12.271818399429321}", "{\"n\": 14481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.06, \"learn_time_ms\": 9788.835, \"total_train_time_s\": 11.22727370262146}", "{\"n\": 14482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.06, \"learn_time_ms\": 9820.397, \"total_train_time_s\": 12.086324691772461}", "{\"n\": 14483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.35, \"learn_time_ms\": 9676.913, \"total_train_time_s\": 11.076841354370117}", "{\"n\": 14484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.33, \"learn_time_ms\": 9665.345, \"total_train_time_s\": 11.563539028167725}", "{\"n\": 14485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.4, \"learn_time_ms\": 9736.053, \"total_train_time_s\": 12.229537725448608}", "{\"n\": 14486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.88, \"learn_time_ms\": 9909.542, \"total_train_time_s\": 13.223118305206299}", "{\"n\": 14487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.88, \"learn_time_ms\": 10064.656, \"total_train_time_s\": 12.711765050888062}", "{\"n\": 14488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.5, \"learn_time_ms\": 10184.783, \"total_train_time_s\": 13.18024468421936}", "{\"n\": 14489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.99, \"learn_time_ms\": 10263.768, \"total_train_time_s\": 12.360448122024536}", "{\"n\": 14490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.04, \"learn_time_ms\": 10224.62, \"total_train_time_s\": 11.903126001358032}", "{\"n\": 14491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.36, \"learn_time_ms\": 10388.956, \"total_train_time_s\": 12.864983320236206}", "{\"n\": 14492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.36, \"learn_time_ms\": 10348.748, \"total_train_time_s\": 11.719271898269653}", "{\"n\": 14493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.2, \"learn_time_ms\": 10567.679, \"total_train_time_s\": 13.337223291397095}", "{\"n\": 14494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.0, \"learn_time_ms\": 10603.147, \"total_train_time_s\": 11.948837041854858}", "{\"n\": 14495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.74, \"learn_time_ms\": 10611.312, \"total_train_time_s\": 12.322361707687378}", "{\"n\": 14496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.74, \"learn_time_ms\": 10437.004, \"total_train_time_s\": 11.47534966468811}", "{\"n\": 14497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.48, \"learn_time_ms\": 10345.312, \"total_train_time_s\": 11.784131288528442}", "{\"n\": 14498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.68, \"learn_time_ms\": 10167.01, \"total_train_time_s\": 11.563222169876099}", "{\"n\": 14499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.71, \"learn_time_ms\": 10180.331, \"total_train_time_s\": 12.464805126190186}", "{\"n\": 14500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.71, \"learn_time_ms\": 10225.098, \"total_train_time_s\": 12.31875991821289}", "{\"n\": 14501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.88, \"learn_time_ms\": 10148.158, \"total_train_time_s\": 12.074431419372559}", "{\"n\": 14502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.56, \"learn_time_ms\": 10138.614, \"total_train_time_s\": 11.626687288284302}", "{\"n\": 14503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.56, \"learn_time_ms\": 10008.245, \"total_train_time_s\": 11.983702659606934}", "{\"n\": 14504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.42, \"learn_time_ms\": 9967.541, \"total_train_time_s\": 11.579167604446411}", "{\"n\": 14505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.4, \"learn_time_ms\": 10017.825, \"total_train_time_s\": 12.835693836212158}", "{\"n\": 14506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.4, \"learn_time_ms\": 10000.327, \"total_train_time_s\": 11.285418033599854}", "{\"n\": 14507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.78, \"learn_time_ms\": 10051.387, \"total_train_time_s\": 12.23083209991455}", "{\"n\": 14508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.76, \"learn_time_ms\": 10040.255, \"total_train_time_s\": 11.232828855514526}", "{\"n\": 14509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.22, \"learn_time_ms\": 10075.503, \"total_train_time_s\": 12.831273078918457}", "{\"n\": 14510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.22, \"learn_time_ms\": 10197.134, \"total_train_time_s\": 13.588328123092651}", "{\"n\": 14511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.54, \"learn_time_ms\": 10220.888, \"total_train_time_s\": 12.309301137924194}", "{\"n\": 14512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.82, \"learn_time_ms\": 10232.597, \"total_train_time_s\": 11.686855792999268}", "{\"n\": 14513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.81, \"learn_time_ms\": 10293.4, \"total_train_time_s\": 12.573349714279175}", "{\"n\": 14514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.81, \"learn_time_ms\": 10368.305, \"total_train_time_s\": 12.270617485046387}", "{\"n\": 14515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.46, \"learn_time_ms\": 10221.552, \"total_train_time_s\": 11.282348871231079}", "{\"n\": 14516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.03, \"learn_time_ms\": 10387.527, \"total_train_time_s\": 12.92484974861145}", "{\"n\": 14517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.91, \"learn_time_ms\": 10483.064, \"total_train_time_s\": 13.200011253356934}", "{\"n\": 14518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.91, \"learn_time_ms\": 10578.681, \"total_train_time_s\": 12.186002731323242}", "{\"n\": 14519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.99, \"learn_time_ms\": 10365.16, \"total_train_time_s\": 10.67426061630249}", "{\"n\": 14520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.72, \"learn_time_ms\": 10274.414, \"total_train_time_s\": 12.612671136856079}", "{\"n\": 14521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.42, \"learn_time_ms\": 10235.612, \"total_train_time_s\": 11.92559289932251}", "{\"n\": 14522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.76, \"learn_time_ms\": 10310.265, \"total_train_time_s\": 12.45819354057312}", "{\"n\": 14523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.76, \"learn_time_ms\": 10267.181, \"total_train_time_s\": 12.204150915145874}", "{\"n\": 14524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.78, \"learn_time_ms\": 10211.483, \"total_train_time_s\": 11.727895498275757}", "{\"n\": 14525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.78, \"learn_time_ms\": 10249.05, \"total_train_time_s\": 11.703917980194092}", "{\"n\": 14526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.89, \"learn_time_ms\": 10271.515, \"total_train_time_s\": 13.1921968460083}", "{\"n\": 14527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.89, \"learn_time_ms\": 10133.308, \"total_train_time_s\": 11.772443294525146}", "{\"n\": 14528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.25, \"learn_time_ms\": 10161.857, \"total_train_time_s\": 12.505059003829956}", "{\"n\": 14529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.29, \"learn_time_ms\": 10370.508, \"total_train_time_s\": 12.766992330551147}", "{\"n\": 14530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.29, \"learn_time_ms\": 10261.904, \"total_train_time_s\": 11.50376582145691}", "{\"n\": 14531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.78, \"learn_time_ms\": 10351.321, \"total_train_time_s\": 12.82758355140686}", "{\"n\": 14532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.53, \"learn_time_ms\": 10317.294, \"total_train_time_s\": 12.104623079299927}", "{\"n\": 14533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10175.401, \"total_train_time_s\": 10.736598491668701}", "{\"n\": 14534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.04, \"learn_time_ms\": 10224.987, \"total_train_time_s\": 12.245105028152466}", "{\"n\": 14535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.12, \"learn_time_ms\": 10211.605, \"total_train_time_s\": 11.57485055923462}", "{\"n\": 14536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.59, \"learn_time_ms\": 10150.764, \"total_train_time_s\": 12.548469066619873}", "{\"n\": 14537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3668.59, \"learn_time_ms\": 10221.71, \"total_train_time_s\": 12.525745391845703}", "{\"n\": 14538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.27, \"learn_time_ms\": 10253.967, \"total_train_time_s\": 12.842154026031494}", "{\"n\": 14539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.45, \"learn_time_ms\": 10156.886, \"total_train_time_s\": 11.772267580032349}", "{\"n\": 14540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.0, \"learn_time_ms\": 10301.642, \"total_train_time_s\": 12.96035099029541}", "{\"n\": 14541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.06, \"learn_time_ms\": 10297.514, \"total_train_time_s\": 12.786823511123657}", "{\"n\": 14542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.13, \"learn_time_ms\": 10211.919, \"total_train_time_s\": 11.273695468902588}", "{\"n\": 14543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.56, \"learn_time_ms\": 10284.816, \"total_train_time_s\": 11.465204954147339}", "{\"n\": 14544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.46, \"learn_time_ms\": 10345.095, \"total_train_time_s\": 12.804416418075562}", "{\"n\": 14545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.04, \"learn_time_ms\": 10321.342, \"total_train_time_s\": 11.288618564605713}", "{\"n\": 14546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.52, \"learn_time_ms\": 10305.188, \"total_train_time_s\": 12.406560182571411}", "{\"n\": 14547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.04, \"learn_time_ms\": 10232.105, \"total_train_time_s\": 11.79060173034668}", "{\"n\": 14548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.44, \"learn_time_ms\": 10157.612, \"total_train_time_s\": 12.03116226196289}", "{\"n\": 14549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.35, \"learn_time_ms\": 10115.237, \"total_train_time_s\": 11.403427362442017}", "{\"n\": 14550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.95, \"learn_time_ms\": 9917.66, \"total_train_time_s\": 10.973825454711914}", "{\"n\": 14551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.87, \"learn_time_ms\": 9749.054, \"total_train_time_s\": 11.088809251785278}", "{\"n\": 14552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 9757.964, \"total_train_time_s\": 11.34542465209961}", "{\"n\": 14553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.05, \"learn_time_ms\": 9876.881, \"total_train_time_s\": 12.673708438873291}", "{\"n\": 14554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.09, \"learn_time_ms\": 9777.48, \"total_train_time_s\": 11.831414222717285}", "{\"n\": 14555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.48, \"learn_time_ms\": 9784.131, \"total_train_time_s\": 11.392548561096191}", "{\"n\": 14556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.03, \"learn_time_ms\": 9728.679, \"total_train_time_s\": 11.82624888420105}", "{\"n\": 14557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3631.33, \"learn_time_ms\": 9721.983, \"total_train_time_s\": 11.684408903121948}", "{\"n\": 14558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3631.33, \"learn_time_ms\": 9716.172, \"total_train_time_s\": 12.035430908203125}", "{\"n\": 14559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.81, \"learn_time_ms\": 9680.509, \"total_train_time_s\": 11.093833446502686}", "{\"n\": 14560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.81, \"learn_time_ms\": 9801.941, \"total_train_time_s\": 12.222685098648071}", "{\"n\": 14561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 9975.333, \"total_train_time_s\": 12.826688051223755}", "{\"n\": 14562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 9914.292, \"total_train_time_s\": 10.725952625274658}", "{\"n\": 14563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3643.32, \"learn_time_ms\": 9826.122, \"total_train_time_s\": 11.79820990562439}", "{\"n\": 14564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3643.32, \"learn_time_ms\": 9864.596, \"total_train_time_s\": 12.22356104850769}", "{\"n\": 14565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3651.5, \"learn_time_ms\": 9924.801, \"total_train_time_s\": 11.99045205116272}", "{\"n\": 14566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3651.89, \"learn_time_ms\": 10124.436, \"total_train_time_s\": 13.826167821884155}", "{\"n\": 14567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3658.81, \"learn_time_ms\": 10094.033, \"total_train_time_s\": 11.419337034225464}", "{\"n\": 14568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3666.86, \"learn_time_ms\": 10097.953, \"total_train_time_s\": 12.06261944770813}", "{\"n\": 14569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3666.86, \"learn_time_ms\": 10307.756, \"total_train_time_s\": 13.145060300827026}", "{\"n\": 14570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 10252.583, \"total_train_time_s\": 11.670604467391968}", "{\"n\": 14571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3658.82, \"learn_time_ms\": 10085.126, \"total_train_time_s\": 11.137126684188843}", "{\"n\": 14572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3648.46, \"learn_time_ms\": 10223.864, \"total_train_time_s\": 12.11769413948059}", "{\"n\": 14573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3648.46, \"learn_time_ms\": 10349.739, \"total_train_time_s\": 13.068496704101562}", "{\"n\": 14574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3664.87, \"learn_time_ms\": 10393.173, \"total_train_time_s\": 12.666872262954712}", "{\"n\": 14575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3664.87, \"learn_time_ms\": 10317.706, \"total_train_time_s\": 11.220309495925903}", "{\"n\": 14576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3673.58, \"learn_time_ms\": 10253.101, \"total_train_time_s\": 13.199145078659058}", "{\"n\": 14577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3673.58, \"learn_time_ms\": 10311.886, \"total_train_time_s\": 12.030935764312744}", "{\"n\": 14578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3684.48, \"learn_time_ms\": 10312.5, \"total_train_time_s\": 12.079313516616821}", "{\"n\": 14579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.43, \"learn_time_ms\": 10210.009, \"total_train_time_s\": 12.100329160690308}", "{\"n\": 14580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.8, \"learn_time_ms\": 10265.186, \"total_train_time_s\": 12.235608577728271}", "{\"n\": 14581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.8, \"learn_time_ms\": 10458.359, \"total_train_time_s\": 13.075193405151367}", "{\"n\": 14582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3690.78, \"learn_time_ms\": 10312.571, \"total_train_time_s\": 10.676946878433228}", "{\"n\": 14583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3690.78, \"learn_time_ms\": 10203.745, \"total_train_time_s\": 11.94442081451416}", "{\"n\": 14584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3696.51, \"learn_time_ms\": 10193.484, \"total_train_time_s\": 12.583127975463867}", "{\"n\": 14585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3696.63, \"learn_time_ms\": 10259.627, \"total_train_time_s\": 11.922436952590942}", "{\"n\": 14586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3701.4, \"learn_time_ms\": 10188.722, \"total_train_time_s\": 12.456130743026733}", "{\"n\": 14587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3706.78, \"learn_time_ms\": 10098.366, \"total_train_time_s\": 11.12884521484375}", "{\"n\": 14588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3706.78, \"learn_time_ms\": 10126.309, \"total_train_time_s\": 12.351897716522217}", "{\"n\": 14589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3708.97, \"learn_time_ms\": 10070.373, \"total_train_time_s\": 11.571009874343872}", "{\"n\": 14590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3702.79, \"learn_time_ms\": 10025.138, \"total_train_time_s\": 11.802483558654785}", "{\"n\": 14591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3702.79, \"learn_time_ms\": 9885.072, \"total_train_time_s\": 11.665109395980835}", "{\"n\": 14592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3702.79, \"learn_time_ms\": 10154.494, \"total_train_time_s\": 13.32386064529419}", "{\"n\": 14593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3702.79, \"learn_time_ms\": 10202.596, \"total_train_time_s\": 12.44190001487732}", "{\"n\": 14594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.61, \"learn_time_ms\": 10191.668, \"total_train_time_s\": 12.468120574951172}", "{\"n\": 14595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3728.86, \"learn_time_ms\": 10195.443, \"total_train_time_s\": 11.943509578704834}", "{\"n\": 14596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3728.86, \"learn_time_ms\": 10212.304, \"total_train_time_s\": 12.622062921524048}", "{\"n\": 14597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3732.24, \"learn_time_ms\": 10305.644, \"total_train_time_s\": 12.061309337615967}", "{\"n\": 14598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3732.24, \"learn_time_ms\": 10263.201, \"total_train_time_s\": 11.903786420822144}", "{\"n\": 14599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3738.41, \"learn_time_ms\": 10296.508, \"total_train_time_s\": 11.890007972717285}", "{\"n\": 14600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3738.41, \"learn_time_ms\": 10319.224, \"total_train_time_s\": 12.02845287322998}", "{\"n\": 14601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3733.53, \"learn_time_ms\": 10344.564, \"total_train_time_s\": 11.985831260681152}", "{\"n\": 14602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3733.53, \"learn_time_ms\": 10209.319, \"total_train_time_s\": 11.98850965499878}", "{\"n\": 14603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3735.63, \"learn_time_ms\": 10189.851, \"total_train_time_s\": 12.23286747932434}", "{\"n\": 14604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3735.63, \"learn_time_ms\": 10184.344, \"total_train_time_s\": 12.339341878890991}", "{\"n\": 14605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3729.05, \"learn_time_ms\": 10153.979, \"total_train_time_s\": 11.624109983444214}", "{\"n\": 14606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3729.05, \"learn_time_ms\": 10045.642, \"total_train_time_s\": 11.523762702941895}", "{\"n\": 14607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3735.18, \"learn_time_ms\": 10030.022, \"total_train_time_s\": 11.897652387619019}", "{\"n\": 14608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3735.4, \"learn_time_ms\": 10137.327, \"total_train_time_s\": 13.000354051589966}", "{\"n\": 14609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3737.96, \"learn_time_ms\": 10130.463, \"total_train_time_s\": 11.809098482131958}", "{\"n\": 14610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3737.96, \"learn_time_ms\": 10121.512, \"total_train_time_s\": 11.928571939468384}", "{\"n\": 14611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3734.12, \"learn_time_ms\": 10022.791, \"total_train_time_s\": 11.008761167526245}", "{\"n\": 14612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3735.05, \"learn_time_ms\": 10101.903, \"total_train_time_s\": 12.791838884353638}", "{\"n\": 14613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3738.55, \"learn_time_ms\": 10116.624, \"total_train_time_s\": 12.35006308555603}", "{\"n\": 14614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3736.74, \"learn_time_ms\": 10103.828, \"total_train_time_s\": 12.271212100982666}", "{\"n\": 14615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3736.74, \"learn_time_ms\": 10129.234, \"total_train_time_s\": 11.911056518554688}", "{\"n\": 14616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3742.23, \"learn_time_ms\": 10186.981, \"total_train_time_s\": 12.153820037841797}", "{\"n\": 14617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3739.07, \"learn_time_ms\": 10118.93, \"total_train_time_s\": 11.225924253463745}", "{\"n\": 14618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3741.93, \"learn_time_ms\": 9997.782, \"total_train_time_s\": 11.733143329620361}", "{\"n\": 14619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3748.24, \"learn_time_ms\": 10024.985, \"total_train_time_s\": 12.083392143249512}", "{\"n\": 14620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3745.06, \"learn_time_ms\": 10120.212, \"total_train_time_s\": 12.8958261013031}", "{\"n\": 14621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3745.06, \"learn_time_ms\": 10285.484, \"total_train_time_s\": 12.615458488464355}", "{\"n\": 14622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3738.23, \"learn_time_ms\": 10121.591, \"total_train_time_s\": 11.153904914855957}", "{\"n\": 14623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3733.4, \"learn_time_ms\": 10089.101, \"total_train_time_s\": 12.08204174041748}", "{\"n\": 14624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3731.41, \"learn_time_ms\": 10091.97, \"total_train_time_s\": 12.301254272460938}", "{\"n\": 14625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3731.41, \"learn_time_ms\": 10066.918, \"total_train_time_s\": 11.631880521774292}", "{\"n\": 14626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3730.34, \"learn_time_ms\": 10131.43, \"total_train_time_s\": 12.808584451675415}", "{\"n\": 14627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3736.62, \"learn_time_ms\": 10198.357, \"total_train_time_s\": 11.915118932723999}", "{\"n\": 14628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3741.36, \"learn_time_ms\": 10181.9, \"total_train_time_s\": 11.605852127075195}", "{\"n\": 14629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3742.36, \"learn_time_ms\": 10165.901, \"total_train_time_s\": 11.937049627304077}", "{\"n\": 14630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3742.36, \"learn_time_ms\": 10065.158, \"total_train_time_s\": 11.867592334747314}", "{\"n\": 14631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3748.09, \"learn_time_ms\": 10008.789, \"total_train_time_s\": 12.071843147277832}", "{\"n\": 14632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3754.98, \"learn_time_ms\": 10090.232, \"total_train_time_s\": 11.964917182922363}", "{\"n\": 14633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3754.98, \"learn_time_ms\": 10068.246, \"total_train_time_s\": 11.809345006942749}", "{\"n\": 14634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3762.92, \"learn_time_ms\": 9970.594, \"total_train_time_s\": 11.294537782669067}", "{\"n\": 14635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3762.92, \"learn_time_ms\": 9979.531, \"total_train_time_s\": 11.665542125701904}", "{\"n\": 14636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3779.32, \"learn_time_ms\": 9870.443, \"total_train_time_s\": 11.69061803817749}", "{\"n\": 14637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3777.82, \"learn_time_ms\": 9846.612, \"total_train_time_s\": 11.648956298828125}", "{\"n\": 14638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3770.34, \"learn_time_ms\": 9962.318, \"total_train_time_s\": 12.76554822921753}", "{\"n\": 14639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3770.34, \"learn_time_ms\": 9936.961, \"total_train_time_s\": 11.683561086654663}", "{\"n\": 14640, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3790.66, \"learn_time_ms\": 9903.4, \"total_train_time_s\": 11.495644092559814}", "{\"n\": 14641, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3790.66, \"learn_time_ms\": 9952.712, \"total_train_time_s\": 12.523043632507324}", "{\"n\": 14642, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3788.67, \"learn_time_ms\": 9930.359, \"total_train_time_s\": 11.749521493911743}", "{\"n\": 14643, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3803.58, \"learn_time_ms\": 9975.493, \"total_train_time_s\": 12.309015989303589}", "{\"n\": 14644, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3804.6, \"learn_time_ms\": 10057.662, \"total_train_time_s\": 12.100621938705444}", "{\"n\": 14645, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3805.84, \"learn_time_ms\": 10070.083, \"total_train_time_s\": 11.854649543762207}", "{\"n\": 14646, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3805.84, \"learn_time_ms\": 10061.072, \"total_train_time_s\": 11.567782163619995}", "{\"n\": 14647, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3800.72, \"learn_time_ms\": 10120.835, \"total_train_time_s\": 12.21763563156128}", "{\"n\": 14648, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3792.77, \"learn_time_ms\": 10131.914, \"total_train_time_s\": 12.847813606262207}", "{\"n\": 14649, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3792.77, \"learn_time_ms\": 10169.107, \"total_train_time_s\": 12.044827938079834}", "{\"n\": 14650, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3796.63, \"learn_time_ms\": 10255.206, \"total_train_time_s\": 12.342268705368042}", "{\"n\": 14651, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3803.65, \"learn_time_ms\": 10193.188, \"total_train_time_s\": 11.906813144683838}", "{\"n\": 14652, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3801.96, \"learn_time_ms\": 10245.883, \"total_train_time_s\": 12.27265477180481}", "{\"n\": 14653, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3801.96, \"learn_time_ms\": 10166.683, \"total_train_time_s\": 11.505132675170898}", "{\"n\": 14654, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3793.57, \"learn_time_ms\": 10165.211, \"total_train_time_s\": 12.089318752288818}", "{\"n\": 14655, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3796.12, \"learn_time_ms\": 10199.211, \"total_train_time_s\": 12.163291215896606}", "{\"n\": 14656, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3788.63, \"learn_time_ms\": 10248.432, \"total_train_time_s\": 12.106074094772339}", "{\"n\": 14657, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3780.09, \"learn_time_ms\": 10157.505, \"total_train_time_s\": 11.339669704437256}", "{\"n\": 14658, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3780.09, \"learn_time_ms\": 10009.865, \"total_train_time_s\": 11.387723684310913}", "{\"n\": 14659, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3778.87, \"learn_time_ms\": 9951.256, \"total_train_time_s\": 11.505679607391357}", "{\"n\": 14660, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3775.25, \"learn_time_ms\": 9850.069, \"total_train_time_s\": 11.349077224731445}", "{\"n\": 14661, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3768.46, \"learn_time_ms\": 9931.284, \"total_train_time_s\": 12.73537540435791}", "{\"n\": 14662, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3768.46, \"learn_time_ms\": 10024.905, \"total_train_time_s\": 13.202866315841675}", "{\"n\": 14663, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3776.59, \"learn_time_ms\": 10012.561, \"total_train_time_s\": 11.38581371307373}", "{\"n\": 14664, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3777.22, \"learn_time_ms\": 10050.048, \"total_train_time_s\": 12.477267503738403}", "{\"n\": 14665, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3777.22, \"learn_time_ms\": 10040.08, \"total_train_time_s\": 12.054778814315796}", "{\"n\": 14666, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3777.22, \"learn_time_ms\": 10052.997, \"total_train_time_s\": 12.228703498840332}", "{\"n\": 14667, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3778.23, \"learn_time_ms\": 10112.271, \"total_train_time_s\": 11.924253463745117}", "{\"n\": 14668, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3775.56, \"learn_time_ms\": 10204.908, \"total_train_time_s\": 12.314931392669678}", "{\"n\": 14669, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3775.56, \"learn_time_ms\": 10197.923, \"total_train_time_s\": 11.381657838821411}", "{\"n\": 14670, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3770.01, \"learn_time_ms\": 10279.254, \"total_train_time_s\": 12.20179009437561}", "{\"n\": 14671, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3767.03, \"learn_time_ms\": 10202.741, \"total_train_time_s\": 11.950681209564209}", "{\"n\": 14672, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3766.69, \"learn_time_ms\": 10010.432, \"total_train_time_s\": 11.262132167816162}", "{\"n\": 14673, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3770.97, \"learn_time_ms\": 10054.643, \"total_train_time_s\": 11.83086371421814}", "{\"n\": 14674, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3772.38, \"learn_time_ms\": 9998.316, \"total_train_time_s\": 11.920150756835938}", "{\"n\": 14675, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3773.91, \"learn_time_ms\": 10104.307, \"total_train_time_s\": 13.147782802581787}", "{\"n\": 14676, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3764.25, \"learn_time_ms\": 10026.832, \"total_train_time_s\": 11.452570676803589}", "{\"n\": 14677, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3764.25, \"learn_time_ms\": 10034.343, \"total_train_time_s\": 11.973549842834473}", "{\"n\": 14678, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3764.72, \"learn_time_ms\": 10004.751, \"total_train_time_s\": 12.045060873031616}", "{\"n\": 14679, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3765.05, \"learn_time_ms\": 9966.12, \"total_train_time_s\": 11.039676666259766}", "{\"n\": 14680, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3765.05, \"learn_time_ms\": 9891.284, \"total_train_time_s\": 11.443426609039307}", "{\"n\": 14681, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3758.62, \"learn_time_ms\": 9974.399, \"total_train_time_s\": 12.80412745475769}", "{\"n\": 14682, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3752.28, \"learn_time_ms\": 10022.782, \"total_train_time_s\": 11.75153636932373}", "{\"n\": 14683, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3753.4, \"learn_time_ms\": 10055.914, \"total_train_time_s\": 12.133153200149536}", "{\"n\": 14684, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3753.4, \"learn_time_ms\": 10163.31, \"total_train_time_s\": 13.004046440124512}", "{\"n\": 14685, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.45, \"learn_time_ms\": 9986.022, \"total_train_time_s\": 11.395909309387207}", "{\"n\": 14686, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.67, \"learn_time_ms\": 10117.428, \"total_train_time_s\": 12.750360488891602}", "{\"n\": 14687, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3730.67, \"learn_time_ms\": 10094.053, \"total_train_time_s\": 11.781641244888306}", "{\"n\": 14688, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3729.29, \"learn_time_ms\": 10011.257, \"total_train_time_s\": 11.188358783721924}", "{\"n\": 14689, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.19, \"learn_time_ms\": 10117.818, \"total_train_time_s\": 12.042237520217896}", "{\"n\": 14690, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.19, \"learn_time_ms\": 10236.137, \"total_train_time_s\": 12.592583417892456}", "{\"n\": 14691, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.19, \"learn_time_ms\": 10183.984, \"total_train_time_s\": 12.26606559753418}", "{\"n\": 14692, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3699.76, \"learn_time_ms\": 10141.456, \"total_train_time_s\": 11.334379434585571}", "{\"n\": 14693, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.96, \"learn_time_ms\": 10168.543, \"total_train_time_s\": 12.436297178268433}", "{\"n\": 14694, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.96, \"learn_time_ms\": 9982.882, \"total_train_time_s\": 11.130278825759888}", "{\"n\": 14695, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.96, \"learn_time_ms\": 10092.729, \"total_train_time_s\": 12.47270679473877}", "{\"n\": 14696, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.42, \"learn_time_ms\": 10022.87, \"total_train_time_s\": 12.12999939918518}", "{\"n\": 14697, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.42, \"learn_time_ms\": 9985.043, \"total_train_time_s\": 11.410770893096924}", "{\"n\": 14698, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.42, \"learn_time_ms\": 10032.302, \"total_train_time_s\": 11.668298721313477}", "{\"n\": 14699, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.05, \"learn_time_ms\": 10026.364, \"total_train_time_s\": 12.004590272903442}", "{\"n\": 14700, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.02, \"learn_time_ms\": 10008.83, \"total_train_time_s\": 12.387461185455322}", "{\"n\": 14701, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.02, \"learn_time_ms\": 9947.187, \"total_train_time_s\": 11.660170555114746}", "{\"n\": 14702, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3664.61, \"learn_time_ms\": 10046.477, \"total_train_time_s\": 12.359549522399902}", "{\"n\": 14703, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3664.96, \"learn_time_ms\": 10069.242, \"total_train_time_s\": 12.702868938446045}", "{\"n\": 14704, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3663.27, \"learn_time_ms\": 10177.944, \"total_train_time_s\": 12.2322256565094}", "{\"n\": 14705, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3663.27, \"learn_time_ms\": 10203.498, \"total_train_time_s\": 12.74062180519104}", "{\"n\": 14706, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3662.68, \"learn_time_ms\": 10163.151, \"total_train_time_s\": 11.678983926773071}", "{\"n\": 14707, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3656.33, \"learn_time_ms\": 10198.679, \"total_train_time_s\": 11.730993270874023}", "{\"n\": 14708, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3656.33, \"learn_time_ms\": 10291.03, \"total_train_time_s\": 12.559563636779785}", "{\"n\": 14709, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3653.72, \"learn_time_ms\": 10332.198, \"total_train_time_s\": 12.402560949325562}", "{\"n\": 14710, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3649.31, \"learn_time_ms\": 10414.657, \"total_train_time_s\": 13.276790142059326}", "{\"n\": 14711, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3649.17, \"learn_time_ms\": 10436.586, \"total_train_time_s\": 11.912368774414062}", "{\"n\": 14712, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3649.17, \"learn_time_ms\": 10377.86, \"total_train_time_s\": 11.759289264678955}", "{\"n\": 14713, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3651.61, \"learn_time_ms\": 10194.001, \"total_train_time_s\": 10.804392337799072}", "{\"n\": 14714, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3656.73, \"learn_time_ms\": 10102.056, \"total_train_time_s\": 11.310431241989136}", "{\"n\": 14715, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3661.16, \"learn_time_ms\": 9959.606, \"total_train_time_s\": 11.331670761108398}", "{\"n\": 14716, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3658.06, \"learn_time_ms\": 10095.507, \"total_train_time_s\": 13.019264936447144}", "{\"n\": 14717, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3649.41, \"learn_time_ms\": 10105.345, \"total_train_time_s\": 11.815503120422363}", "{\"n\": 14718, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.4, \"learn_time_ms\": 10145.033, \"total_train_time_s\": 12.979521751403809}", "{\"n\": 14719, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.4, \"learn_time_ms\": 9990.065, \"total_train_time_s\": 10.89156723022461}", "{\"n\": 14720, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3640.96, \"learn_time_ms\": 9922.807, \"total_train_time_s\": 12.597543001174927}", "{\"n\": 14721, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.78, \"learn_time_ms\": 9897.113, \"total_train_time_s\": 11.630677938461304}", "{\"n\": 14722, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.6, \"learn_time_ms\": 9805.825, \"total_train_time_s\": 10.834464073181152}", "{\"n\": 14723, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.6, \"learn_time_ms\": 10030.224, \"total_train_time_s\": 13.073548793792725}", "{\"n\": 14724, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10241.166, \"total_train_time_s\": 13.4045991897583}", "{\"n\": 14725, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.69, \"learn_time_ms\": 10293.38, \"total_train_time_s\": 11.824656009674072}", "{\"n\": 14726, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.69, \"learn_time_ms\": 10186.391, \"total_train_time_s\": 11.928129196166992}", "{\"n\": 14727, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.59, \"learn_time_ms\": 10202.998, \"total_train_time_s\": 12.016093969345093}", "{\"n\": 14728, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.59, \"learn_time_ms\": 10107.138, \"total_train_time_s\": 12.07579517364502}", "{\"n\": 14729, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.91, \"learn_time_ms\": 10169.436, \"total_train_time_s\": 11.502182006835938}", "{\"n\": 14730, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.91, \"learn_time_ms\": 10091.977, \"total_train_time_s\": 11.765992879867554}", "{\"n\": 14731, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.19, \"learn_time_ms\": 10058.434, \"total_train_time_s\": 11.287252426147461}", "{\"n\": 14732, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.06, \"learn_time_ms\": 10120.666, \"total_train_time_s\": 11.431521654129028}", "{\"n\": 14733, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.06, \"learn_time_ms\": 10162.162, \"total_train_time_s\": 13.431492328643799}", "{\"n\": 14734, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.86, \"learn_time_ms\": 10008.756, \"total_train_time_s\": 11.905042886734009}", "{\"n\": 14735, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.56, \"learn_time_ms\": 10019.036, \"total_train_time_s\": 11.952107667922974}", "{\"n\": 14736, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.64, \"learn_time_ms\": 10002.702, \"total_train_time_s\": 11.783920288085938}", "{\"n\": 14737, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.51, \"learn_time_ms\": 10029.024, \"total_train_time_s\": 12.243792295455933}", "{\"n\": 14738, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.26, \"learn_time_ms\": 9965.406, \"total_train_time_s\": 11.383903980255127}", "{\"n\": 14739, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.73, \"learn_time_ms\": 9924.292, \"total_train_time_s\": 11.111714363098145}", "{\"n\": 14740, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.73, \"learn_time_ms\": 10005.3, \"total_train_time_s\": 12.6274573802948}", "{\"n\": 14741, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.45, \"learn_time_ms\": 10079.864, \"total_train_time_s\": 12.025853633880615}", "{\"n\": 14742, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.85, \"learn_time_ms\": 10196.403, \"total_train_time_s\": 12.610248804092407}", "{\"n\": 14743, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.85, \"learn_time_ms\": 10116.082, \"total_train_time_s\": 12.648091793060303}", "{\"n\": 14744, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.16, \"learn_time_ms\": 10186.33, \"total_train_time_s\": 12.54150938987732}", "{\"n\": 14745, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.71, \"learn_time_ms\": 10263.697, \"total_train_time_s\": 12.715871810913086}", "{\"n\": 14746, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.83, \"learn_time_ms\": 10310.527, \"total_train_time_s\": 12.281709909439087}", "{\"n\": 14747, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.9, \"learn_time_ms\": 10347.324, \"total_train_time_s\": 12.628912687301636}", "{\"n\": 14748, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.53, \"learn_time_ms\": 10476.26, \"total_train_time_s\": 12.702627897262573}", "{\"n\": 14749, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.28, \"learn_time_ms\": 10520.896, \"total_train_time_s\": 11.494632720947266}", "{\"n\": 14750, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.51, \"learn_time_ms\": 10661.407, \"total_train_time_s\": 14.024654388427734}", "{\"n\": 14751, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.13, \"learn_time_ms\": 10814.76, \"total_train_time_s\": 13.613308429718018}", "{\"n\": 14752, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.05, \"learn_time_ms\": 10832.468, \"total_train_time_s\": 12.814383268356323}", "{\"n\": 14753, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.7, \"learn_time_ms\": 10786.63, \"total_train_time_s\": 12.16618013381958}", "{\"n\": 14754, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.16, \"learn_time_ms\": 10589.021, \"total_train_time_s\": 10.645730972290039}", "{\"n\": 14755, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.9, \"learn_time_ms\": 10636.315, \"total_train_time_s\": 13.191822528839111}", "{\"n\": 14756, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.98, \"learn_time_ms\": 10575.538, \"total_train_time_s\": 11.677372932434082}", "{\"n\": 14757, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.44, \"learn_time_ms\": 10422.196, \"total_train_time_s\": 11.096495151519775}", "{\"n\": 14758, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.89, \"learn_time_ms\": 10316.86, \"total_train_time_s\": 11.601629972457886}", "{\"n\": 14759, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3575.97, \"learn_time_ms\": 10311.682, \"total_train_time_s\": 11.470852375030518}", "{\"n\": 14760, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.13, \"learn_time_ms\": 10072.552, \"total_train_time_s\": 11.607487678527832}", "{\"n\": 14761, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.13, \"learn_time_ms\": 9877.446, \"total_train_time_s\": 11.649256229400635}", "{\"n\": 14762, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.65, \"learn_time_ms\": 9786.728, \"total_train_time_s\": 11.904671907424927}", "{\"n\": 14763, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.73, \"learn_time_ms\": 9786.885, \"total_train_time_s\": 12.17206072807312}", "{\"n\": 14764, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.22, \"learn_time_ms\": 9986.0, \"total_train_time_s\": 12.621825456619263}", "{\"n\": 14765, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3552.97, \"learn_time_ms\": 9977.128, \"total_train_time_s\": 13.099059343338013}", "{\"n\": 14766, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.98, \"learn_time_ms\": 9995.538, \"total_train_time_s\": 11.82291316986084}", "{\"n\": 14767, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.98, \"learn_time_ms\": 10138.311, \"total_train_time_s\": 12.54468035697937}", "{\"n\": 14768, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.44, \"learn_time_ms\": 10105.807, \"total_train_time_s\": 11.317432165145874}", "{\"n\": 14769, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3547.44, \"learn_time_ms\": 10244.163, \"total_train_time_s\": 12.894920110702515}", "{\"n\": 14770, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3551.43, \"learn_time_ms\": 10216.052, \"total_train_time_s\": 11.352711915969849}", "{\"n\": 14771, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.41, \"learn_time_ms\": 10204.652, \"total_train_time_s\": 11.494650602340698}", "{\"n\": 14772, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3560.36, \"learn_time_ms\": 10205.096, \"total_train_time_s\": 11.88946533203125}", "{\"n\": 14773, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3560.36, \"learn_time_ms\": 10119.177, \"total_train_time_s\": 11.350406646728516}", "{\"n\": 14774, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.28, \"learn_time_ms\": 10111.357, \"total_train_time_s\": 12.501657962799072}", "{\"n\": 14775, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.72, \"learn_time_ms\": 10065.959, \"total_train_time_s\": 12.610992670059204}", "{\"n\": 14776, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.72, \"learn_time_ms\": 9991.759, \"total_train_time_s\": 11.090397357940674}", "{\"n\": 14777, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.9, \"learn_time_ms\": 9985.289, \"total_train_time_s\": 12.45832347869873}", "{\"n\": 14778, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.06, \"learn_time_ms\": 9990.539, \"total_train_time_s\": 11.351323127746582}", "{\"n\": 14779, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.1, \"learn_time_ms\": 9910.257, \"total_train_time_s\": 12.051825761795044}", "{\"n\": 14780, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.91, \"learn_time_ms\": 9898.591, \"total_train_time_s\": 11.215922117233276}", "{\"n\": 14781, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3580.25, \"learn_time_ms\": 9885.026, \"total_train_time_s\": 11.357740640640259}", "{\"n\": 14782, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.37, \"learn_time_ms\": 9823.54, \"total_train_time_s\": 11.312820434570312}", "{\"n\": 14783, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3573.5, \"learn_time_ms\": 10018.921, \"total_train_time_s\": 13.322662115097046}", "{\"n\": 14784, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.31, \"learn_time_ms\": 9905.79, \"total_train_time_s\": 11.361883640289307}", "{\"n\": 14785, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3559.22, \"learn_time_ms\": 9871.846, \"total_train_time_s\": 12.262036800384521}", "{\"n\": 14786, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3559.22, \"learn_time_ms\": 9967.21, \"total_train_time_s\": 12.008647203445435}", "{\"n\": 14787, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.05, \"learn_time_ms\": 9925.608, \"total_train_time_s\": 12.033082962036133}", "{\"n\": 14788, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3567.04, \"learn_time_ms\": 9973.721, \"total_train_time_s\": 11.858996629714966}", "{\"n\": 14789, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3567.04, \"learn_time_ms\": 9893.43, \"total_train_time_s\": 11.255158185958862}", "{\"n\": 14790, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.83, \"learn_time_ms\": 9968.571, \"total_train_time_s\": 11.992538213729858}", "{\"n\": 14791, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3591.54, \"learn_time_ms\": 10014.165, \"total_train_time_s\": 11.802480936050415}", "{\"n\": 14792, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 10142.736, \"total_train_time_s\": 12.612823009490967}", "{\"n\": 14793, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 10070.226, \"total_train_time_s\": 12.575498104095459}", "{\"n\": 14794, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3590.99, \"learn_time_ms\": 10235.712, \"total_train_time_s\": 13.086937665939331}", "{\"n\": 14795, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3588.68, \"learn_time_ms\": 10114.876, \"total_train_time_s\": 11.07074761390686}", "{\"n\": 14796, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3587.32, \"learn_time_ms\": 10115.005, \"total_train_time_s\": 12.070909023284912}", "{\"n\": 14797, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3587.11, \"learn_time_ms\": 10069.033, \"total_train_time_s\": 11.760497808456421}", "{\"n\": 14798, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3581.33, \"learn_time_ms\": 10094.898, \"total_train_time_s\": 12.112934827804565}", "{\"n\": 14799, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3581.64, \"learn_time_ms\": 10113.022, \"total_train_time_s\": 11.500851392745972}", "{\"n\": 14800, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.19, \"learn_time_ms\": 10113.94, \"total_train_time_s\": 12.002916812896729}", "{\"n\": 14801, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.2, \"learn_time_ms\": 10199.488, \"total_train_time_s\": 12.635903358459473}", "{\"n\": 14802, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3583.85, \"learn_time_ms\": 10138.09, \"total_train_time_s\": 11.946455717086792}", "{\"n\": 14803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.89, \"learn_time_ms\": 10040.626, \"total_train_time_s\": 11.609029769897461}", "{\"n\": 14804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3560.27, \"learn_time_ms\": 9993.456, \"total_train_time_s\": 12.550813913345337}", "{\"n\": 14805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3559.5, \"learn_time_ms\": 10072.285, \"total_train_time_s\": 11.877222776412964}", "{\"n\": 14806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3554.8, \"learn_time_ms\": 10003.966, \"total_train_time_s\": 11.405554294586182}", "{\"n\": 14807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3548.8, \"learn_time_ms\": 10086.188, \"total_train_time_s\": 12.4433753490448}", "{\"n\": 14808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3552.69, \"learn_time_ms\": 10097.325, \"total_train_time_s\": 12.200138807296753}", "{\"n\": 14809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3548.64, \"learn_time_ms\": 10141.121, \"total_train_time_s\": 11.88698124885559}", "{\"n\": 14810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3550.62, \"learn_time_ms\": 10109.273, \"total_train_time_s\": 11.692777633666992}", "{\"n\": 14811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3559.35, \"learn_time_ms\": 10024.848, \"total_train_time_s\": 11.8960542678833}", "{\"n\": 14812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3559.35, \"learn_time_ms\": 9997.178, \"total_train_time_s\": 11.714884996414185}", "{\"n\": 14813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3558.46, \"learn_time_ms\": 10137.149, \"total_train_time_s\": 13.033543825149536}", "{\"n\": 14814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3558.13, \"learn_time_ms\": 10209.271, \"total_train_time_s\": 13.335358381271362}", "{\"n\": 14815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3557.49, \"learn_time_ms\": 10280.506, \"total_train_time_s\": 12.649799346923828}", "{\"n\": 14816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3557.49, \"learn_time_ms\": 10379.681, \"total_train_time_s\": 12.373674869537354}", "{\"n\": 14817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3563.76, \"learn_time_ms\": 10352.21, \"total_train_time_s\": 12.108658790588379}", "{\"n\": 14818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3554.05, \"learn_time_ms\": 10262.804, \"total_train_time_s\": 11.333161115646362}", "{\"n\": 14819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3558.65, \"learn_time_ms\": 10222.566, \"total_train_time_s\": 11.463887453079224}", "{\"n\": 14820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.97, \"learn_time_ms\": 10254.101, \"total_train_time_s\": 11.969484329223633}", "{\"n\": 14821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.83, \"learn_time_ms\": 10301.137, \"total_train_time_s\": 12.269422054290771}", "{\"n\": 14822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3564.81, \"learn_time_ms\": 10354.256, \"total_train_time_s\": 12.203546047210693}", "{\"n\": 14823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3564.81, \"learn_time_ms\": 10264.792, \"total_train_time_s\": 12.122211694717407}", "{\"n\": 14824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3560.88, \"learn_time_ms\": 10162.166, \"total_train_time_s\": 12.27500867843628}", "{\"n\": 14825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3563.81, \"learn_time_ms\": 10139.05, \"total_train_time_s\": 12.382578611373901}", "{\"n\": 14826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3563.81, \"learn_time_ms\": 10141.349, \"total_train_time_s\": 12.377213716506958}", "{\"n\": 14827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3571.02, \"learn_time_ms\": 10215.851, \"total_train_time_s\": 12.862780332565308}", "{\"n\": 14828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3574.74, \"learn_time_ms\": 10265.545, \"total_train_time_s\": 11.790279388427734}", "{\"n\": 14829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3579.76, \"learn_time_ms\": 10331.149, \"total_train_time_s\": 12.10359501838684}", "{\"n\": 14830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.65, \"learn_time_ms\": 10365.244, \"total_train_time_s\": 12.359109878540039}", "{\"n\": 14831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.65, \"learn_time_ms\": 10231.859, \"total_train_time_s\": 10.986770153045654}", "{\"n\": 14832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.03, \"learn_time_ms\": 10199.635, \"total_train_time_s\": 11.897465467453003}", "{\"n\": 14833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.54, \"learn_time_ms\": 10168.095, \"total_train_time_s\": 11.767946243286133}", "{\"n\": 14834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.94, \"learn_time_ms\": 10127.022, \"total_train_time_s\": 11.852735757827759}", "{\"n\": 14835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.94, \"learn_time_ms\": 10116.407, \"total_train_time_s\": 12.202672719955444}", "{\"n\": 14836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.68, \"learn_time_ms\": 9978.082, \"total_train_time_s\": 11.025570631027222}", "{\"n\": 14837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.68, \"learn_time_ms\": 9857.119, \"total_train_time_s\": 11.653913021087646}", "{\"n\": 14838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3615.64, \"learn_time_ms\": 9868.359, \"total_train_time_s\": 11.955756902694702}", "{\"n\": 14839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.01, \"learn_time_ms\": 9829.299, \"total_train_time_s\": 11.785429239273071}", "{\"n\": 14840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.06, \"learn_time_ms\": 9787.073, \"total_train_time_s\": 11.92558240890503}", "{\"n\": 14841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.83, \"learn_time_ms\": 9921.692, \"total_train_time_s\": 12.318480014801025}", "{\"n\": 14842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.83, \"learn_time_ms\": 9953.858, \"total_train_time_s\": 12.1715567111969}", "{\"n\": 14843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.09, \"learn_time_ms\": 9911.277, \"total_train_time_s\": 11.374682903289795}", "{\"n\": 14844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.02, \"learn_time_ms\": 9898.718, \"total_train_time_s\": 11.71878457069397}", "{\"n\": 14845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3616.42, \"learn_time_ms\": 9818.061, \"total_train_time_s\": 11.468669652938843}", "{\"n\": 14846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3614.12, \"learn_time_ms\": 9905.035, \"total_train_time_s\": 11.847169876098633}", "{\"n\": 14847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.97, \"learn_time_ms\": 9913.715, \"total_train_time_s\": 11.871412992477417}", "{\"n\": 14848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.95, \"learn_time_ms\": 10000.742, \"total_train_time_s\": 12.82816457748413}", "{\"n\": 14849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.95, \"learn_time_ms\": 10057.712, \"total_train_time_s\": 12.361543655395508}", "{\"n\": 14850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.55, \"learn_time_ms\": 10067.16, \"total_train_time_s\": 12.038644552230835}", "{\"n\": 14851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3625.4, \"learn_time_ms\": 10062.611, \"total_train_time_s\": 12.269367218017578}", "{\"n\": 14852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.46, \"learn_time_ms\": 10134.205, \"total_train_time_s\": 12.938068151473999}", "{\"n\": 14853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.46, \"learn_time_ms\": 10246.072, \"total_train_time_s\": 12.50268030166626}", "{\"n\": 14854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3629.6, \"learn_time_ms\": 10337.455, \"total_train_time_s\": 12.659424781799316}", "{\"n\": 14855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3630.6, \"learn_time_ms\": 10328.964, \"total_train_time_s\": 11.341727018356323}", "{\"n\": 14856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3627.33, \"learn_time_ms\": 10242.776, \"total_train_time_s\": 11.001850605010986}", "{\"n\": 14857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.41, \"learn_time_ms\": 10309.74, \"total_train_time_s\": 12.453920364379883}", "{\"n\": 14858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.64, \"learn_time_ms\": 10256.754, \"total_train_time_s\": 12.292319536209106}", "{\"n\": 14859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3625.86, \"learn_time_ms\": 10204.268, \"total_train_time_s\": 11.866602420806885}", "{\"n\": 14860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.67, \"learn_time_ms\": 10225.516, \"total_train_time_s\": 12.236495018005371}", "{\"n\": 14861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3615.56, \"learn_time_ms\": 10216.473, \"total_train_time_s\": 12.182028532028198}", "{\"n\": 14862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.79, \"learn_time_ms\": 10158.445, \"total_train_time_s\": 12.368987798690796}", "{\"n\": 14863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.18, \"learn_time_ms\": 10163.396, \"total_train_time_s\": 12.556680679321289}", "{\"n\": 14864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.16, \"learn_time_ms\": 10063.39, \"total_train_time_s\": 11.648658275604248}", "{\"n\": 14865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.16, \"learn_time_ms\": 10007.505, \"total_train_time_s\": 10.829371690750122}", "{\"n\": 14866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3608.14, \"learn_time_ms\": 10067.138, \"total_train_time_s\": 11.58424162864685}", "{\"n\": 14867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.56, \"learn_time_ms\": 10206.468, \"total_train_time_s\": 13.824404239654541}", "{\"n\": 14868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.92, \"learn_time_ms\": 10213.723, \"total_train_time_s\": 12.356845617294312}", "{\"n\": 14869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.92, \"learn_time_ms\": 10263.425, \"total_train_time_s\": 12.300460815429688}", "{\"n\": 14870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.16, \"learn_time_ms\": 10197.593, \"total_train_time_s\": 11.593662977218628}", "{\"n\": 14871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.58, \"learn_time_ms\": 10117.511, \"total_train_time_s\": 11.401127576828003}", "{\"n\": 14872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3637.65, \"learn_time_ms\": 10194.016, \"total_train_time_s\": 13.13583779335022}", "{\"n\": 14873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3634.77, \"learn_time_ms\": 10113.899, \"total_train_time_s\": 11.735375165939331}", "{\"n\": 14874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3644.91, \"learn_time_ms\": 10070.151, \"total_train_time_s\": 11.1750168800354}", "{\"n\": 14875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.66, \"learn_time_ms\": 10261.985, \"total_train_time_s\": 12.746870517730713}", "{\"n\": 14876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.66, \"learn_time_ms\": 10199.575, \"total_train_time_s\": 10.974321365356445}", "{\"n\": 14877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.55, \"learn_time_ms\": 10078.006, \"total_train_time_s\": 12.596346616744995}", "{\"n\": 14878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.65, \"learn_time_ms\": 10114.833, \"total_train_time_s\": 12.692904233932495}", "{\"n\": 14879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3636.87, \"learn_time_ms\": 10138.673, \"total_train_time_s\": 12.47256851196289}", "{\"n\": 14880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3637.64, \"learn_time_ms\": 10309.968, \"total_train_time_s\": 13.276259422302246}", "{\"n\": 14881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3637.64, \"learn_time_ms\": 10451.339, \"total_train_time_s\": 12.80302119255066}", "{\"n\": 14882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3633.97, \"learn_time_ms\": 10287.243, \"total_train_time_s\": 11.48852825164795}", "{\"n\": 14883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3633.64, \"learn_time_ms\": 10288.824, \"total_train_time_s\": 11.757441997528076}", "{\"n\": 14884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3629.57, \"learn_time_ms\": 10509.194, \"total_train_time_s\": 13.382253408432007}", "{\"n\": 14885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.35, \"learn_time_ms\": 10389.151, \"total_train_time_s\": 11.575268507003784}", "{\"n\": 14886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.35, \"learn_time_ms\": 10511.73, \"total_train_time_s\": 12.173922300338745}", "{\"n\": 14887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.93, \"learn_time_ms\": 10436.79, \"total_train_time_s\": 11.861074924468994}", "{\"n\": 14888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3628.17, \"learn_time_ms\": 10505.693, \"total_train_time_s\": 13.392380952835083}", "{\"n\": 14889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3631.8, \"learn_time_ms\": 10448.027, \"total_train_time_s\": 11.933379888534546}", "{\"n\": 14890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3631.8, \"learn_time_ms\": 10376.736, \"total_train_time_s\": 12.510684728622437}", "{\"n\": 14891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.18, \"learn_time_ms\": 10312.986, \"total_train_time_s\": 12.18493914604187}", "{\"n\": 14892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3635.76, \"learn_time_ms\": 10374.121, \"total_train_time_s\": 12.083723068237305}", "{\"n\": 14893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.14, \"learn_time_ms\": 10373.496, \"total_train_time_s\": 11.742090940475464}", "{\"n\": 14894, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.15, \"learn_time_ms\": 10177.366, \"total_train_time_s\": 11.45209288597107}", "{\"n\": 14895, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.85, \"learn_time_ms\": 10155.85, \"total_train_time_s\": 11.288248777389526}", "{\"n\": 14896, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.16, \"learn_time_ms\": 10124.533, \"total_train_time_s\": 11.904271841049194}", "{\"n\": 14897, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.16, \"learn_time_ms\": 10142.545, \"total_train_time_s\": 11.980778217315674}", "{\"n\": 14898, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3657.25, \"learn_time_ms\": 10029.376, \"total_train_time_s\": 12.253629922866821}", "{\"n\": 14899, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.68, \"learn_time_ms\": 10004.291, \"total_train_time_s\": 11.691751480102539}", "{\"n\": 14900, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3669.1, \"learn_time_ms\": 9974.999, \"total_train_time_s\": 12.281739234924316}", "{\"n\": 14901, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3669.1, \"learn_time_ms\": 9886.743, \"total_train_time_s\": 11.221181392669678}", "{\"n\": 14902, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3670.95, \"learn_time_ms\": 9820.42, \"total_train_time_s\": 11.405237436294556}", "{\"n\": 14903, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3669.66, \"learn_time_ms\": 9908.948, \"total_train_time_s\": 12.643595457077026}", "{\"n\": 14904, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3669.66, \"learn_time_ms\": 9972.577, \"total_train_time_s\": 12.099677801132202}", "{\"n\": 14905, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3676.66, \"learn_time_ms\": 10153.324, \"total_train_time_s\": 13.112821340560913}", "{\"n\": 14906, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3675.07, \"learn_time_ms\": 10222.978, \"total_train_time_s\": 12.557903289794922}", "{\"n\": 14907, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 10276.726, \"total_train_time_s\": 12.55848503112793}", "{\"n\": 14908, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 10265.928, \"total_train_time_s\": 12.184063911437988}", "{\"n\": 14909, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3666.46, \"learn_time_ms\": 10329.896, \"total_train_time_s\": 12.321342468261719}", "{\"n\": 14910, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.32, \"learn_time_ms\": 10295.314, \"total_train_time_s\": 11.9355149269104}", "{\"n\": 14911, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.07, \"learn_time_ms\": 10353.81, \"total_train_time_s\": 11.835641860961914}", "{\"n\": 14912, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.07, \"learn_time_ms\": 10379.547, \"total_train_time_s\": 11.648842334747314}", "{\"n\": 14913, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3663.26, \"learn_time_ms\": 10416.905, \"total_train_time_s\": 13.046838521957397}", "{\"n\": 14914, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10369.659, \"total_train_time_s\": 11.650820016860962}", "{\"n\": 14915, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3660.7, \"learn_time_ms\": 10223.533, \"total_train_time_s\": 11.635659456253052}", "{\"n\": 14916, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3669.67, \"learn_time_ms\": 10066.206, \"total_train_time_s\": 10.993857383728027}", "{\"n\": 14917, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3654.76, \"learn_time_ms\": 9936.228, \"total_train_time_s\": 11.266282081604004}", "{\"n\": 14918, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3657.14, \"learn_time_ms\": 9863.747, \"total_train_time_s\": 11.470831871032715}", "{\"n\": 14919, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.35, \"learn_time_ms\": 9834.155, \"total_train_time_s\": 12.005640029907227}", "{\"n\": 14920, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.66, \"learn_time_ms\": 9796.889, \"total_train_time_s\": 11.584687232971191}", "{\"n\": 14921, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3645.95, \"learn_time_ms\": 9871.294, \"total_train_time_s\": 12.601922035217285}", "{\"n\": 14922, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.48, \"learn_time_ms\": 9820.148, \"total_train_time_s\": 11.13318133354187}", "{\"n\": 14923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.48, \"learn_time_ms\": 9712.198, \"total_train_time_s\": 11.915175437927246}", "{\"n\": 14924, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3639.11, \"learn_time_ms\": 9745.508, \"total_train_time_s\": 11.940916538238525}", "{\"n\": 14925, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3637.22, \"learn_time_ms\": 9821.801, \"total_train_time_s\": 12.426054000854492}", "{\"n\": 14926, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3633.55, \"learn_time_ms\": 9868.282, \"total_train_time_s\": 11.487874746322632}", "{\"n\": 14927, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3633.55, \"learn_time_ms\": 9965.183, \"total_train_time_s\": 12.251591682434082}", "{\"n\": 14928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.42, \"learn_time_ms\": 10025.801, \"total_train_time_s\": 12.033655643463135}", "{\"n\": 14929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.06, \"learn_time_ms\": 9904.975, \"total_train_time_s\": 10.861008405685425}", "{\"n\": 14930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.06, \"learn_time_ms\": 10025.542, \"total_train_time_s\": 12.79463791847229}", "{\"n\": 14931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.06, \"learn_time_ms\": 10034.176, \"total_train_time_s\": 12.70545744895935}", "{\"n\": 14932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.66, \"learn_time_ms\": 10162.812, \"total_train_time_s\": 12.509421348571777}", "{\"n\": 14933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3618.66, \"learn_time_ms\": 10212.174, \"total_train_time_s\": 12.410656690597534}", "{\"n\": 14934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.04, \"learn_time_ms\": 10228.347, \"total_train_time_s\": 12.125972747802734}", "{\"n\": 14935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.73, \"learn_time_ms\": 10283.605, \"total_train_time_s\": 12.974573373794556}", "{\"n\": 14936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.59, \"learn_time_ms\": 10315.44, \"total_train_time_s\": 11.81767749786377}", "{\"n\": 14937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.83, \"learn_time_ms\": 10253.748, \"total_train_time_s\": 11.569561958312988}", "{\"n\": 14938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.94, \"learn_time_ms\": 10393.073, \"total_train_time_s\": 13.412224292755127}", "{\"n\": 14939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.9, \"learn_time_ms\": 10532.435, \"total_train_time_s\": 12.197130680084229}", "{\"n\": 14940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.18, \"learn_time_ms\": 10588.869, \"total_train_time_s\": 13.311781406402588}", "{\"n\": 14941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.0, \"learn_time_ms\": 10566.256, \"total_train_time_s\": 12.445961236953735}", "{\"n\": 14942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.38, \"learn_time_ms\": 10514.012, \"total_train_time_s\": 11.896138191223145}", "{\"n\": 14943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.25, \"learn_time_ms\": 10481.265, \"total_train_time_s\": 12.10848593711853}", "{\"n\": 14944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.23, \"learn_time_ms\": 10551.796, \"total_train_time_s\": 12.83324146270752}", "{\"n\": 14945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.23, \"learn_time_ms\": 10456.655, \"total_train_time_s\": 12.038556575775146}", "{\"n\": 14946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.69, \"learn_time_ms\": 10540.93, \"total_train_time_s\": 12.642688989639282}", "{\"n\": 14947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.97, \"learn_time_ms\": 10634.969, \"total_train_time_s\": 12.565207719802856}", "{\"n\": 14948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.97, \"learn_time_ms\": 10449.152, \"total_train_time_s\": 11.589598417282104}", "{\"n\": 14949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.24, \"learn_time_ms\": 10479.886, \"total_train_time_s\": 12.561156272888184}", "{\"n\": 14950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3601.1, \"learn_time_ms\": 10449.932, \"total_train_time_s\": 13.05867338180542}", "{\"n\": 14951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 10387.314, \"total_train_time_s\": 11.828662395477295}", "{\"n\": 14952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 10373.345, \"total_train_time_s\": 11.783727884292603}", "{\"n\": 14953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 10465.078, \"total_train_time_s\": 13.010133266448975}", "{\"n\": 14954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.99, \"learn_time_ms\": 10353.378, \"total_train_time_s\": 11.677937269210815}", "{\"n\": 14955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.99, \"learn_time_ms\": 10313.055, \"total_train_time_s\": 11.601822853088379}", "{\"n\": 14956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.41, \"learn_time_ms\": 10285.427, \"total_train_time_s\": 12.360819339752197}", "{\"n\": 14957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.22, \"learn_time_ms\": 10183.077, \"total_train_time_s\": 11.574766397476196}", "{\"n\": 14958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.9, \"learn_time_ms\": 10250.705, \"total_train_time_s\": 12.231327772140503}", "{\"n\": 14959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.9, \"learn_time_ms\": 10207.152, \"total_train_time_s\": 12.081618309020996}", "{\"n\": 14960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.7, \"learn_time_ms\": 10000.326, \"total_train_time_s\": 10.951105833053589}", "{\"n\": 14961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3578.29, \"learn_time_ms\": 9941.166, \"total_train_time_s\": 11.245198726654053}", "{\"n\": 14962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3578.29, \"learn_time_ms\": 9961.269, \"total_train_time_s\": 11.951432704925537}", "{\"n\": 14963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3570.43, \"learn_time_ms\": 9877.572, \"total_train_time_s\": 12.143348932266235}", "{\"n\": 14964, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3570.43, \"learn_time_ms\": 10053.059, \"total_train_time_s\": 13.449872016906738}", "{\"n\": 14965, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.64, \"learn_time_ms\": 10155.124, \"total_train_time_s\": 12.690099239349365}", "{\"n\": 14966, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.35, \"learn_time_ms\": 10139.013, \"total_train_time_s\": 12.201629877090454}", "{\"n\": 14967, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.35, \"learn_time_ms\": 10251.629, \"total_train_time_s\": 12.616678953170776}", "{\"n\": 14968, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.74, \"learn_time_ms\": 10162.195, \"total_train_time_s\": 11.374845743179321}", "{\"n\": 14969, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.88, \"learn_time_ms\": 10150.98, \"total_train_time_s\": 11.947159767150879}", "{\"n\": 14970, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.06, \"learn_time_ms\": 10275.349, \"total_train_time_s\": 12.185341358184814}", "{\"n\": 14971, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.06, \"learn_time_ms\": 10407.795, \"total_train_time_s\": 12.579092025756836}", "{\"n\": 14972, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.18, \"learn_time_ms\": 10347.192, \"total_train_time_s\": 11.374886274337769}", "{\"n\": 14973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.18, \"learn_time_ms\": 10390.032, \"total_train_time_s\": 12.601118326187134}", "{\"n\": 14974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.69, \"learn_time_ms\": 10222.459, \"total_train_time_s\": 11.736257314682007}", "{\"n\": 14975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.2, \"learn_time_ms\": 10110.168, \"total_train_time_s\": 11.551322937011719}", "{\"n\": 14976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.61, \"learn_time_ms\": 10073.95, \"total_train_time_s\": 11.825511455535889}", "{\"n\": 14977, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.09, \"learn_time_ms\": 10038.64, \"total_train_time_s\": 12.322901964187622}", "{\"n\": 14978, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.44, \"learn_time_ms\": 10127.013, \"total_train_time_s\": 12.252474546432495}", "{\"n\": 14979, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.44, \"learn_time_ms\": 10196.954, \"total_train_time_s\": 12.693965435028076}", "{\"n\": 14980, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.17, \"learn_time_ms\": 10185.016, \"total_train_time_s\": 12.065566062927246}", "{\"n\": 14981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.49, \"learn_time_ms\": 10108.229, \"total_train_time_s\": 11.771446943283081}", "{\"n\": 14982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.46, \"learn_time_ms\": 10154.349, \"total_train_time_s\": 11.815399169921875}", "{\"n\": 14983, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.07, \"learn_time_ms\": 10136.782, \"total_train_time_s\": 12.475070714950562}", "{\"n\": 14984, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10156.932, \"total_train_time_s\": 12.04340934753418}", "{\"n\": 14985, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.05, \"learn_time_ms\": 10197.779, \"total_train_time_s\": 11.903818607330322}", "{\"n\": 14986, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.14, \"learn_time_ms\": 10171.948, \"total_train_time_s\": 11.556073904037476}", "{\"n\": 14987, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.14, \"learn_time_ms\": 10200.537, \"total_train_time_s\": 12.623071908950806}", "{\"n\": 14988, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.98, \"learn_time_ms\": 10136.433, \"total_train_time_s\": 11.632834196090698}", "{\"n\": 14989, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.03, \"learn_time_ms\": 10023.112, \"total_train_time_s\": 11.506331443786621}", "{\"n\": 14990, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.03, \"learn_time_ms\": 10038.045, \"total_train_time_s\": 12.203007936477661}", "{\"n\": 14991, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.14, \"learn_time_ms\": 10044.845, \"total_train_time_s\": 11.880370140075684}", "{\"n\": 14992, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.14, \"learn_time_ms\": 10139.861, \"total_train_time_s\": 12.764329195022583}", "{\"n\": 14993, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.77, \"learn_time_ms\": 10066.824, \"total_train_time_s\": 11.702122688293457}", "{\"n\": 14994, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.41, \"learn_time_ms\": 10042.826, \"total_train_time_s\": 11.72468376159668}", "{\"n\": 14995, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.02, \"learn_time_ms\": 10147.09, \"total_train_time_s\": 13.018903970718384}", "{\"n\": 14996, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.02, \"learn_time_ms\": 10148.907, \"total_train_time_s\": 11.587235450744629}", "{\"n\": 14997, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.35, \"learn_time_ms\": 10018.056, \"total_train_time_s\": 11.31008768081665}", "{\"n\": 14998, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.35, \"learn_time_ms\": 10012.639, \"total_train_time_s\": 11.523303031921387}", "{\"n\": 14999, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.2, \"learn_time_ms\": 10065.808, \"total_train_time_s\": 12.085466146469116}", "{\"n\": 15000, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.2, \"learn_time_ms\": 10077.212, \"total_train_time_s\": 12.370224475860596}", "{\"n\": 15001, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.57, \"learn_time_ms\": 10051.205, \"total_train_time_s\": 11.622818946838379}", "{\"n\": 15002, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.71, \"learn_time_ms\": 9979.637, \"total_train_time_s\": 12.056137084960938}", "{\"n\": 15003, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.71, \"learn_time_ms\": 10022.158, \"total_train_time_s\": 12.122971534729004}", "{\"n\": 15004, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.93, \"learn_time_ms\": 10092.226, \"total_train_time_s\": 12.422369241714478}", "{\"n\": 15005, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.2, \"learn_time_ms\": 10033.637, \"total_train_time_s\": 12.337838411331177}", "{\"n\": 15006, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.2, \"learn_time_ms\": 10112.532, \"total_train_time_s\": 12.376100540161133}", "{\"n\": 15007, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3566.21, \"learn_time_ms\": 10141.535, \"total_train_time_s\": 11.578691959381104}", "{\"n\": 15008, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.32, \"learn_time_ms\": 10223.567, \"total_train_time_s\": 12.382123708724976}", "{\"n\": 15009, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.43, \"learn_time_ms\": 10171.315, \"total_train_time_s\": 11.546337842941284}", "{\"n\": 15010, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3568.43, \"learn_time_ms\": 10167.08, \"total_train_time_s\": 12.293626546859741}", "{\"n\": 15011, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.54, \"learn_time_ms\": 10218.197, \"total_train_time_s\": 12.122269630432129}", "{\"n\": 15012, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 10208.57, \"total_train_time_s\": 11.99966287612915}", "{\"n\": 15013, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 10191.769, \"total_train_time_s\": 11.927014112472534}", "{\"n\": 15014, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 10201.748, \"total_train_time_s\": 12.530543327331543}", "{\"n\": 15015, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.25, \"learn_time_ms\": 10172.801, \"total_train_time_s\": 12.081087112426758}", "{\"n\": 15016, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.76, \"learn_time_ms\": 10124.217, \"total_train_time_s\": 11.948971509933472}", "{\"n\": 15017, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.76, \"learn_time_ms\": 10167.943, \"total_train_time_s\": 12.05987000465393}", "{\"n\": 15018, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3557.76, \"learn_time_ms\": 10126.67, \"total_train_time_s\": 11.941576719284058}", "{\"n\": 15019, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.26, \"learn_time_ms\": 10207.984, \"total_train_time_s\": 12.38734745979309}", "{\"n\": 15020, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.26, \"learn_time_ms\": 10195.417, \"total_train_time_s\": 12.165793180465698}", "{\"n\": 15021, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.26, \"learn_time_ms\": 10094.552, \"total_train_time_s\": 11.107937812805176}", "{\"n\": 15022, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.39, \"learn_time_ms\": 10227.683, \"total_train_time_s\": 13.294827222824097}", "{\"n\": 15023, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 10251.641, \"total_train_time_s\": 12.14155912399292}", "{\"n\": 15024, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 10130.764, \"total_train_time_s\": 11.32859754562378}", "{\"n\": 15025, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.1, \"learn_time_ms\": 10022.186, \"total_train_time_s\": 11.008286714553833}", "{\"n\": 15026, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.91, \"learn_time_ms\": 10066.451, \"total_train_time_s\": 12.338154077529907}", "{\"n\": 15027, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.74, \"learn_time_ms\": 10166.283, \"total_train_time_s\": 13.01294207572937}", "{\"n\": 15028, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.74, \"learn_time_ms\": 10154.355, \"total_train_time_s\": 11.839052200317383}", "{\"n\": 15029, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.92, \"learn_time_ms\": 10273.924, \"total_train_time_s\": 13.569087743759155}", "{\"n\": 15030, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.32, \"learn_time_ms\": 10314.732, \"total_train_time_s\": 12.59235167503357}", "{\"n\": 15031, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.32, \"learn_time_ms\": 10423.465, \"total_train_time_s\": 12.18501353263855}", "{\"n\": 15032, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.13, \"learn_time_ms\": 10263.244, \"total_train_time_s\": 11.667633771896362}", "{\"n\": 15033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.45, \"learn_time_ms\": 10292.845, \"total_train_time_s\": 12.483877420425415}", "{\"n\": 15034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.45, \"learn_time_ms\": 10310.221, \"total_train_time_s\": 11.463245868682861}", "{\"n\": 15035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3560.45, \"learn_time_ms\": 10457.648, \"total_train_time_s\": 12.522335767745972}", "{\"n\": 15036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.29, \"learn_time_ms\": 10374.346, \"total_train_time_s\": 11.547412395477295}", "{\"n\": 15037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3565.37, \"learn_time_ms\": 10240.129, \"total_train_time_s\": 11.679311037063599}", "{\"n\": 15038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.51, \"learn_time_ms\": 10247.322, \"total_train_time_s\": 11.875313997268677}", "{\"n\": 15039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.51, \"learn_time_ms\": 10046.425, \"total_train_time_s\": 11.592974424362183}", "{\"n\": 15040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.0, \"learn_time_ms\": 9945.263, \"total_train_time_s\": 11.59416389465332}", "{\"n\": 15041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 9919.398, \"total_train_time_s\": 11.926589727401733}", "{\"n\": 15042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 9995.203, \"total_train_time_s\": 12.45225214958191}", "{\"n\": 15043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.36, \"learn_time_ms\": 10014.931, \"total_train_time_s\": 12.695655584335327}", "{\"n\": 15044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9975.601, \"total_train_time_s\": 11.13889193534851}", "{\"n\": 15045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9926.495, \"total_train_time_s\": 12.03686237335205}", "{\"n\": 15046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 9983.034, \"total_train_time_s\": 12.120553493499756}", "{\"n\": 15047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 10004.642, \"total_train_time_s\": 11.886301517486572}", "{\"n\": 15048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.92, \"learn_time_ms\": 10093.069, \"total_train_time_s\": 12.760828018188477}", "{\"n\": 15049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.92, \"learn_time_ms\": 10172.916, \"total_train_time_s\": 12.359985828399658}", "{\"n\": 15050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.92, \"learn_time_ms\": 10234.785, \"total_train_time_s\": 12.193612098693848}", "{\"n\": 15051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.02, \"learn_time_ms\": 10188.922, \"total_train_time_s\": 11.493976593017578}", "{\"n\": 15052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.12, \"learn_time_ms\": 10147.762, \"total_train_time_s\": 12.05955171585083}", "{\"n\": 15053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.12, \"learn_time_ms\": 9979.345, \"total_train_time_s\": 10.974870204925537}", "{\"n\": 15054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.05, \"learn_time_ms\": 10127.499, \"total_train_time_s\": 12.627537965774536}", "{\"n\": 15055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 10043.061, \"total_train_time_s\": 11.163341045379639}", "{\"n\": 15056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 10044.952, \"total_train_time_s\": 12.106175661087036}", "{\"n\": 15057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 10070.346, \"total_train_time_s\": 12.157878637313843}", "{\"n\": 15058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.04, \"learn_time_ms\": 10038.953, \"total_train_time_s\": 12.466013669967651}", "{\"n\": 15059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.43, \"learn_time_ms\": 9882.534, \"total_train_time_s\": 10.800826072692871}", "{\"n\": 15060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.91, \"learn_time_ms\": 9939.109, \"total_train_time_s\": 12.741517543792725}", "{\"n\": 15061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.67, \"learn_time_ms\": 9945.698, \"total_train_time_s\": 11.534541368484497}", "{\"n\": 15062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.78, \"learn_time_ms\": 9870.253, \"total_train_time_s\": 11.343173742294312}", "{\"n\": 15063, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 9961.908, \"total_train_time_s\": 11.894492387771606}", "{\"n\": 15064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 9859.023, \"total_train_time_s\": 11.577987432479858}", "{\"n\": 15065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.91, \"learn_time_ms\": 10084.739, \"total_train_time_s\": 13.397157430648804}", "{\"n\": 15066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.72, \"learn_time_ms\": 10091.264, \"total_train_time_s\": 12.13594388961792}", "{\"n\": 15067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.72, \"learn_time_ms\": 10092.118, \"total_train_time_s\": 12.110450983047485}", "{\"n\": 15068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.01, \"learn_time_ms\": 10048.533, \"total_train_time_s\": 12.03466796875}", "{\"n\": 15069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.5, \"learn_time_ms\": 10069.059, \"total_train_time_s\": 11.020507335662842}", "{\"n\": 15070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.83, \"learn_time_ms\": 9946.353, \"total_train_time_s\": 11.5608971118927}", "{\"n\": 15071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.89, \"learn_time_ms\": 10091.585, \"total_train_time_s\": 12.980803966522217}", "{\"n\": 15072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.57, \"learn_time_ms\": 10213.714, \"total_train_time_s\": 12.552708864212036}", "{\"n\": 15073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.54, \"learn_time_ms\": 10327.835, \"total_train_time_s\": 13.07909607887268}", "{\"n\": 15074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 10351.403, \"total_train_time_s\": 11.778883457183838}", "{\"n\": 15075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 10177.296, \"total_train_time_s\": 11.615993738174438}", "{\"n\": 15076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.99, \"learn_time_ms\": 10197.055, \"total_train_time_s\": 12.374593257904053}", "{\"n\": 15077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.0, \"learn_time_ms\": 10187.48, \"total_train_time_s\": 12.084490776062012}", "{\"n\": 15078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.66, \"learn_time_ms\": 10196.45, \"total_train_time_s\": 12.111723184585571}", "{\"n\": 15079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.66, \"learn_time_ms\": 10263.19, \"total_train_time_s\": 11.624145030975342}", "{\"n\": 15080, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.27, \"learn_time_ms\": 10335.693, \"total_train_time_s\": 12.256932258605957}", "{\"n\": 15081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.57, \"learn_time_ms\": 10278.893, \"total_train_time_s\": 12.438872814178467}", "{\"n\": 15082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.57, \"learn_time_ms\": 10260.93, \"total_train_time_s\": 12.36186671257019}", "{\"n\": 15083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.57, \"learn_time_ms\": 10140.585, \"total_train_time_s\": 11.810804843902588}", "{\"n\": 15084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.78, \"learn_time_ms\": 10176.165, \"total_train_time_s\": 12.123642683029175}", "{\"n\": 15085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 10143.789, \"total_train_time_s\": 11.335192680358887}", "{\"n\": 15086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 10103.709, \"total_train_time_s\": 11.885592699050903}", "{\"n\": 15087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.55, \"learn_time_ms\": 10141.227, \"total_train_time_s\": 12.42503809928894}", "{\"n\": 15088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.93, \"learn_time_ms\": 10048.933, \"total_train_time_s\": 11.257539749145508}", "{\"n\": 15089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.93, \"learn_time_ms\": 10079.157, \"total_train_time_s\": 11.941530227661133}", "{\"n\": 15090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.3, \"learn_time_ms\": 10024.717, \"total_train_time_s\": 11.707125425338745}", "{\"n\": 15091, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.0, \"learn_time_ms\": 10018.021, \"total_train_time_s\": 12.42573070526123}", "{\"n\": 15092, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.77, \"learn_time_ms\": 10004.814, \"total_train_time_s\": 12.2578284740448}", "{\"n\": 15093, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.77, \"learn_time_ms\": 10142.14, \"total_train_time_s\": 13.231453895568848}", "{\"n\": 15094, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.41, \"learn_time_ms\": 10187.207, \"total_train_time_s\": 12.602135181427002}", "{\"n\": 15095, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.74, \"learn_time_ms\": 10204.191, \"total_train_time_s\": 11.651541948318481}", "{\"n\": 15096, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.74, \"learn_time_ms\": 10175.092, \"total_train_time_s\": 11.668668270111084}", "{\"n\": 15097, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.74, \"learn_time_ms\": 10071.717, \"total_train_time_s\": 11.411203384399414}", "{\"n\": 15098, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.99, \"learn_time_ms\": 10258.896, \"total_train_time_s\": 13.089702844619751}", "{\"n\": 15099, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.42, \"learn_time_ms\": 10189.51, \"total_train_time_s\": 11.239569425582886}", "{\"n\": 15100, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.42, \"learn_time_ms\": 10222.082, \"total_train_time_s\": 12.024075984954834}", "{\"n\": 15101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.65, \"learn_time_ms\": 10062.06, \"total_train_time_s\": 10.797250509262085}", "{\"n\": 15102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.72, \"learn_time_ms\": 10038.657, \"total_train_time_s\": 11.98210096359253}", "{\"n\": 15103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.07, \"learn_time_ms\": 9962.403, \"total_train_time_s\": 12.495003938674927}", "{\"n\": 15104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.18, \"learn_time_ms\": 9905.839, \"total_train_time_s\": 12.047861099243164}", "{\"n\": 15105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.79, \"learn_time_ms\": 9923.891, \"total_train_time_s\": 11.669705152511597}", "{\"n\": 15106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.45, \"learn_time_ms\": 10015.79, \"total_train_time_s\": 12.59410572052002}", "{\"n\": 15107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.97, \"learn_time_ms\": 10090.02, \"total_train_time_s\": 12.12002444267273}", "{\"n\": 15108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.15, \"learn_time_ms\": 9972.512, \"total_train_time_s\": 11.895243883132935}", "{\"n\": 15109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.34, \"learn_time_ms\": 10182.609, \"total_train_time_s\": 13.36951756477356}", "{\"n\": 15110, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 10275.827, \"total_train_time_s\": 12.999422073364258}", "{\"n\": 15111, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 10413.376, \"total_train_time_s\": 12.158503293991089}", "{\"n\": 15112, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.88, \"learn_time_ms\": 10514.488, \"total_train_time_s\": 13.009847402572632}", "{\"n\": 15113, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.26, \"learn_time_ms\": 10436.441, \"total_train_time_s\": 11.752298831939697}", "{\"n\": 15114, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.26, \"learn_time_ms\": 10459.167, \"total_train_time_s\": 12.269325733184814}", "{\"n\": 15115, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.28, \"learn_time_ms\": 10447.211, \"total_train_time_s\": 11.572194576263428}", "{\"n\": 15116, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.07, \"learn_time_ms\": 10252.75, \"total_train_time_s\": 10.660601139068604}", "{\"n\": 15117, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.07, \"learn_time_ms\": 10372.698, \"total_train_time_s\": 13.33835768699646}", "{\"n\": 15118, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.06, \"learn_time_ms\": 10403.338, \"total_train_time_s\": 12.223392009735107}", "{\"n\": 15119, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.87, \"learn_time_ms\": 10318.24, \"total_train_time_s\": 12.528648376464844}", "{\"n\": 15120, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.13, \"learn_time_ms\": 10294.555, \"total_train_time_s\": 12.74998664855957}", "{\"n\": 15121, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.65, \"learn_time_ms\": 10394.059, \"total_train_time_s\": 13.122586250305176}", "{\"n\": 15122, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.91, \"learn_time_ms\": 10296.322, \"total_train_time_s\": 12.003327369689941}", "{\"n\": 15123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.0, \"learn_time_ms\": 10429.516, \"total_train_time_s\": 13.01836085319519}", "{\"n\": 15124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.63, \"learn_time_ms\": 10489.702, \"total_train_time_s\": 12.853219509124756}", "{\"n\": 15125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.54, \"learn_time_ms\": 10534.255, \"total_train_time_s\": 11.97174620628357}", "{\"n\": 15126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.14, \"learn_time_ms\": 10641.314, \"total_train_time_s\": 11.662412643432617}", "{\"n\": 15127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.39, \"learn_time_ms\": 10416.442, \"total_train_time_s\": 11.13711428642273}", "{\"n\": 15128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.28, \"learn_time_ms\": 10359.547, \"total_train_time_s\": 11.66319465637207}", "{\"n\": 15129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.11, \"learn_time_ms\": 10294.203, \"total_train_time_s\": 11.902424097061157}", "{\"n\": 15130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.21, \"learn_time_ms\": 10278.573, \"total_train_time_s\": 12.590789318084717}", "{\"n\": 15131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.34, \"learn_time_ms\": 10154.758, \"total_train_time_s\": 11.87867784500122}", "{\"n\": 15132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.43, \"learn_time_ms\": 10073.873, \"total_train_time_s\": 11.219208240509033}", "{\"n\": 15133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.49, \"learn_time_ms\": 9978.952, \"total_train_time_s\": 12.080518007278442}", "{\"n\": 15134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.49, \"learn_time_ms\": 9860.546, \"total_train_time_s\": 11.726576328277588}", "{\"n\": 15135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.49, \"learn_time_ms\": 10023.041, \"total_train_time_s\": 13.678224325180054}", "{\"n\": 15136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.88, \"learn_time_ms\": 10118.011, \"total_train_time_s\": 12.651095628738403}", "{\"n\": 15137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.93, \"learn_time_ms\": 10213.954, \"total_train_time_s\": 12.050840139389038}", "{\"n\": 15138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.66, \"learn_time_ms\": 10244.369, \"total_train_time_s\": 11.949142932891846}", "{\"n\": 15139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.66, \"learn_time_ms\": 10206.429, \"total_train_time_s\": 11.473520040512085}", "{\"n\": 15140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.17, \"learn_time_ms\": 10172.516, \"total_train_time_s\": 12.174592733383179}", "{\"n\": 15141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 10121.511, \"total_train_time_s\": 11.365228414535522}", "{\"n\": 15142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.47, \"learn_time_ms\": 10131.205, \"total_train_time_s\": 11.287416219711304}", "{\"n\": 15143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.47, \"learn_time_ms\": 10128.311, \"total_train_time_s\": 12.016612768173218}", "{\"n\": 15144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.15, \"learn_time_ms\": 10194.366, \"total_train_time_s\": 12.371245622634888}", "{\"n\": 15145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.96, \"learn_time_ms\": 10124.232, \"total_train_time_s\": 12.967146635055542}", "{\"n\": 15146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.96, \"learn_time_ms\": 9954.927, \"total_train_time_s\": 10.949385643005371}", "{\"n\": 15147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.61, \"learn_time_ms\": 10000.109, \"total_train_time_s\": 12.486825942993164}", "{\"n\": 15148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.34, \"learn_time_ms\": 10010.963, \"total_train_time_s\": 12.033771991729736}", "{\"n\": 15149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.61, \"learn_time_ms\": 10119.726, \"total_train_time_s\": 12.580302238464355}", "{\"n\": 15150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.61, \"learn_time_ms\": 10165.436, \"total_train_time_s\": 12.660611629486084}", "{\"n\": 15151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.99, \"learn_time_ms\": 10335.517, \"total_train_time_s\": 13.101208925247192}", "{\"n\": 15152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.84, \"learn_time_ms\": 10531.428, \"total_train_time_s\": 13.27318263053894}", "{\"n\": 15153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.84, \"learn_time_ms\": 10542.719, \"total_train_time_s\": 12.12617826461792}", "{\"n\": 15154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.63, \"learn_time_ms\": 10593.518, \"total_train_time_s\": 12.82576584815979}", "{\"n\": 15155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.67, \"learn_time_ms\": 10469.886, \"total_train_time_s\": 11.686165571212769}", "{\"n\": 15156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.76, \"learn_time_ms\": 10489.616, \"total_train_time_s\": 11.148438453674316}", "{\"n\": 15157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.76, \"learn_time_ms\": 10439.638, \"total_train_time_s\": 12.023268461227417}", "{\"n\": 15158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.26, \"learn_time_ms\": 10497.775, \"total_train_time_s\": 12.607102632522583}", "{\"n\": 15159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.31, \"learn_time_ms\": 10389.994, \"total_train_time_s\": 11.462893962860107}", "{\"n\": 15160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.09, \"learn_time_ms\": 10269.463, \"total_train_time_s\": 11.486280679702759}", "{\"n\": 15161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.09, \"learn_time_ms\": 10151.954, \"total_train_time_s\": 11.928956747055054}", "{\"n\": 15162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.31, \"learn_time_ms\": 10154.203, \"total_train_time_s\": 13.292249917984009}", "{\"n\": 15163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.02, \"learn_time_ms\": 10133.479, \"total_train_time_s\": 11.916664838790894}", "{\"n\": 15164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.02, \"learn_time_ms\": 10019.229, \"total_train_time_s\": 11.690980195999146}", "{\"n\": 15165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.02, \"learn_time_ms\": 9929.15, \"total_train_time_s\": 10.788373708724976}", "{\"n\": 15166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.05, \"learn_time_ms\": 10140.44, \"total_train_time_s\": 13.255142211914062}", "{\"n\": 15167, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.11, \"learn_time_ms\": 10119.849, \"total_train_time_s\": 11.781098365783691}", "{\"n\": 15168, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.11, \"learn_time_ms\": 10136.872, \"total_train_time_s\": 12.827261209487915}", "{\"n\": 15169, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.11, \"learn_time_ms\": 10240.387, \"total_train_time_s\": 12.554154872894287}", "{\"n\": 15170, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10305.623, \"total_train_time_s\": 12.147525787353516}", "{\"n\": 15171, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10413.01, \"total_train_time_s\": 12.97423243522644}", "{\"n\": 15172, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10423.067, \"total_train_time_s\": 13.337239027023315}", "{\"n\": 15173, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.57, \"learn_time_ms\": 10452.179, \"total_train_time_s\": 12.228973627090454}", "{\"n\": 15174, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.12, \"learn_time_ms\": 10520.48, \"total_train_time_s\": 12.403789281845093}", "{\"n\": 15175, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.12, \"learn_time_ms\": 10636.813, \"total_train_time_s\": 11.953984498977661}", "{\"n\": 15176, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.12, \"learn_time_ms\": 10575.803, \"total_train_time_s\": 12.64894723892212}", "{\"n\": 15177, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.25, \"learn_time_ms\": 10691.886, \"total_train_time_s\": 12.920660018920898}", "{\"n\": 15178, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10527.381, \"total_train_time_s\": 11.158413887023926}", "{\"n\": 15179, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10459.526, \"total_train_time_s\": 11.836329698562622}", "{\"n\": 15180, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.47, \"learn_time_ms\": 10449.151, \"total_train_time_s\": 12.057940483093262}", "{\"n\": 15181, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.43, \"learn_time_ms\": 10378.939, \"total_train_time_s\": 12.302715539932251}", "{\"n\": 15182, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.62, \"learn_time_ms\": 10340.173, \"total_train_time_s\": 12.999315738677979}", "{\"n\": 15183, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.02, \"learn_time_ms\": 10367.083, \"total_train_time_s\": 12.514739751815796}", "{\"n\": 15184, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.86, \"learn_time_ms\": 10361.233, \"total_train_time_s\": 12.309393882751465}", "{\"n\": 15185, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.53, \"learn_time_ms\": 10462.862, \"total_train_time_s\": 12.949295043945312}", "{\"n\": 15186, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.53, \"learn_time_ms\": 10443.737, \"total_train_time_s\": 12.476121664047241}", "{\"n\": 15187, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.07, \"learn_time_ms\": 10353.095, \"total_train_time_s\": 12.070488929748535}", "{\"n\": 15188, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.93, \"learn_time_ms\": 10549.449, \"total_train_time_s\": 13.09813141822815}", "{\"n\": 15189, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.93, \"learn_time_ms\": 10621.695, \"total_train_time_s\": 12.576332569122314}", "{\"n\": 15190, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.49, \"learn_time_ms\": 10649.854, \"total_train_time_s\": 12.320360898971558}", "{\"n\": 15191, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.82, \"learn_time_ms\": 10686.851, \"total_train_time_s\": 12.700922966003418}", "{\"n\": 15192, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.44, \"learn_time_ms\": 10513.198, \"total_train_time_s\": 11.260587215423584}", "{\"n\": 15193, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.39, \"learn_time_ms\": 10400.204, \"total_train_time_s\": 11.348103284835815}", "{\"n\": 15194, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.74, \"learn_time_ms\": 10343.025, \"total_train_time_s\": 11.725191116333008}", "{\"n\": 15195, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.75, \"learn_time_ms\": 10235.606, \"total_train_time_s\": 11.904903411865234}", "{\"n\": 15196, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.08, \"learn_time_ms\": 10147.618, \"total_train_time_s\": 11.592287540435791}", "{\"n\": 15197, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.12, \"learn_time_ms\": 10050.482, \"total_train_time_s\": 11.087847232818604}", "{\"n\": 15198, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.25, \"learn_time_ms\": 9902.719, \"total_train_time_s\": 11.633969783782959}", "{\"n\": 15199, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.3, \"learn_time_ms\": 9801.262, \"total_train_time_s\": 11.560256719589233}", "{\"n\": 15200, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.83, \"learn_time_ms\": 9724.497, \"total_train_time_s\": 11.568631887435913}", "{\"n\": 15201, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.91, \"learn_time_ms\": 9620.972, \"total_train_time_s\": 11.61916470527649}", "{\"n\": 15202, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3728.79, \"learn_time_ms\": 9753.1, \"total_train_time_s\": 12.588682651519775}", "{\"n\": 15203, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3725.76, \"learn_time_ms\": 9798.317, \"total_train_time_s\": 11.814612627029419}", "{\"n\": 15204, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3723.4, \"learn_time_ms\": 9833.341, \"total_train_time_s\": 12.089738368988037}", "{\"n\": 15205, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.86, \"learn_time_ms\": 9856.602, \"total_train_time_s\": 12.083701133728027}", "{\"n\": 15206, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.85, \"learn_time_ms\": 9799.378, \"total_train_time_s\": 10.990633964538574}", "{\"n\": 15207, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3719.93, \"learn_time_ms\": 9861.153, \"total_train_time_s\": 11.687113761901855}", "{\"n\": 15208, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.0, \"learn_time_ms\": 9857.729, \"total_train_time_s\": 11.567657232284546}", "{\"n\": 15209, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3731.6, \"learn_time_ms\": 9898.785, \"total_train_time_s\": 12.008338928222656}", "{\"n\": 15210, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3735.52, \"learn_time_ms\": 10015.881, \"total_train_time_s\": 12.773874521255493}", "{\"n\": 15211, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3735.52, \"learn_time_ms\": 10068.233, \"total_train_time_s\": 12.116657972335815}", "{\"n\": 15212, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.93, \"learn_time_ms\": 10054.522, \"total_train_time_s\": 12.428462982177734}", "{\"n\": 15213, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.46, \"learn_time_ms\": 9992.447, \"total_train_time_s\": 11.207160472869873}", "{\"n\": 15214, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.46, \"learn_time_ms\": 9983.917, \"total_train_time_s\": 12.026406049728394}", "{\"n\": 15215, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3743.46, \"learn_time_ms\": 9911.912, \"total_train_time_s\": 11.392387390136719}", "{\"n\": 15216, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.23, \"learn_time_ms\": 9946.807, \"total_train_time_s\": 11.412906885147095}", "{\"n\": 15217, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.23, \"learn_time_ms\": 10044.367, \"total_train_time_s\": 12.649343013763428}", "{\"n\": 15218, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.23, \"learn_time_ms\": 10058.387, \"total_train_time_s\": 11.722358703613281}", "{\"n\": 15219, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3736.59, \"learn_time_ms\": 9965.798, \"total_train_time_s\": 11.05694842338562}", "{\"n\": 15220, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3719.89, \"learn_time_ms\": 9820.828, \"total_train_time_s\": 11.276199102401733}", "{\"n\": 15221, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3719.89, \"learn_time_ms\": 9786.01, \"total_train_time_s\": 11.79190731048584}", "{\"n\": 15222, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3719.89, \"learn_time_ms\": 9773.659, \"total_train_time_s\": 12.324915647506714}", "{\"n\": 15223, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3715.06, \"learn_time_ms\": 9885.558, \"total_train_time_s\": 12.308500528335571}", "{\"n\": 15224, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3727.41, \"learn_time_ms\": 9953.484, \"total_train_time_s\": 12.710857629776001}", "{\"n\": 15225, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3727.41, \"learn_time_ms\": 10104.646, \"total_train_time_s\": 12.944401025772095}", "{\"n\": 15226, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3727.41, \"learn_time_ms\": 10163.475, \"total_train_time_s\": 11.963879585266113}", "{\"n\": 15227, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3740.8, \"learn_time_ms\": 10118.105, \"total_train_time_s\": 12.247087717056274}", "{\"n\": 15228, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3737.85, \"learn_time_ms\": 10167.702, \"total_train_time_s\": 12.248133182525635}", "{\"n\": 15229, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3737.85, \"learn_time_ms\": 10197.235, \"total_train_time_s\": 11.339593887329102}", "{\"n\": 15230, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3737.85, \"learn_time_ms\": 10198.799, \"total_train_time_s\": 11.247208595275879}", "{\"n\": 15231, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3733.79, \"learn_time_ms\": 10296.208, \"total_train_time_s\": 12.827051639556885}", "{\"n\": 15232, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3742.81, \"learn_time_ms\": 10241.998, \"total_train_time_s\": 11.80035924911499}", "{\"n\": 15233, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3742.81, \"learn_time_ms\": 10252.448, \"total_train_time_s\": 12.41754674911499}", "{\"n\": 15234, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3742.73, \"learn_time_ms\": 10212.703, \"total_train_time_s\": 12.341984510421753}", "{\"n\": 15235, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3744.99, \"learn_time_ms\": 10081.826, \"total_train_time_s\": 11.645854234695435}", "{\"n\": 15236, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3744.61, \"learn_time_ms\": 10066.266, \"total_train_time_s\": 11.84183645248413}", "{\"n\": 15237, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3744.61, \"learn_time_ms\": 10075.94, \"total_train_time_s\": 12.353194236755371}", "{\"n\": 15238, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3746.86, \"learn_time_ms\": 10040.842, \"total_train_time_s\": 11.937154769897461}", "{\"n\": 15239, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3748.37, \"learn_time_ms\": 10133.299, \"total_train_time_s\": 12.293837070465088}", "{\"n\": 15240, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3755.27, \"learn_time_ms\": 10326.713, \"total_train_time_s\": 13.247687339782715}", "{\"n\": 15241, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3754.73, \"learn_time_ms\": 10360.246, \"total_train_time_s\": 13.07171106338501}", "{\"n\": 15242, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3746.74, \"learn_time_ms\": 10344.77, \"total_train_time_s\": 11.622853517532349}", "{\"n\": 15243, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3746.74, \"learn_time_ms\": 10286.642, \"total_train_time_s\": 11.837864637374878}", "{\"n\": 15244, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3738.45, \"learn_time_ms\": 10293.049, \"total_train_time_s\": 12.364255905151367}", "{\"n\": 15245, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3741.76, \"learn_time_ms\": 10274.798, \"total_train_time_s\": 11.461448907852173}", "{\"n\": 15246, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3738.83, \"learn_time_ms\": 10256.725, \"total_train_time_s\": 11.627954006195068}", "{\"n\": 15247, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3748.06, \"learn_time_ms\": 10255.269, \"total_train_time_s\": 12.328359365463257}", "{\"n\": 15248, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.95, \"learn_time_ms\": 10403.013, \"total_train_time_s\": 13.414787769317627}", "{\"n\": 15249, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.95, \"learn_time_ms\": 10291.758, \"total_train_time_s\": 11.19097900390625}", "{\"n\": 15250, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.95, \"learn_time_ms\": 10145.08, \"total_train_time_s\": 11.772824048995972}", "{\"n\": 15251, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.27, \"learn_time_ms\": 10031.831, \"total_train_time_s\": 11.993500471115112}", "{\"n\": 15252, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3748.68, \"learn_time_ms\": 10006.952, \"total_train_time_s\": 11.415130615234375}", "{\"n\": 15253, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3748.68, \"learn_time_ms\": 9990.159, \"total_train_time_s\": 11.652077674865723}", "{\"n\": 15254, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.74, \"learn_time_ms\": 9997.73, \"total_train_time_s\": 12.438327312469482}", "{\"n\": 15255, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3749.86, \"learn_time_ms\": 10022.49, \"total_train_time_s\": 11.652961730957031}", "{\"n\": 15256, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.6, \"learn_time_ms\": 10061.214, \"total_train_time_s\": 11.988400936126709}", "{\"n\": 15257, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.6, \"learn_time_ms\": 9945.841, \"total_train_time_s\": 11.166008234024048}", "{\"n\": 15258, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3742.83, \"learn_time_ms\": 9847.231, \"total_train_time_s\": 12.397214412689209}", "{\"n\": 15259, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3738.53, \"learn_time_ms\": 10015.348, \"total_train_time_s\": 12.879853248596191}", "{\"n\": 15260, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3746.23, \"learn_time_ms\": 10009.825, \"total_train_time_s\": 11.680840253829956}", "{\"n\": 15261, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.19, \"learn_time_ms\": 10057.783, \"total_train_time_s\": 12.45096206665039}", "{\"n\": 15262, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3747.19, \"learn_time_ms\": 10042.753, \"total_train_time_s\": 11.22931981086731}", "{\"n\": 15263, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3746.73, \"learn_time_ms\": 10116.505, \"total_train_time_s\": 12.429889678955078}", "{\"n\": 15264, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3751.02, \"learn_time_ms\": 10132.641, \"total_train_time_s\": 12.612176179885864}", "{\"n\": 15265, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3751.02, \"learn_time_ms\": 10309.214, \"total_train_time_s\": 13.469606161117554}", "{\"n\": 15266, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3741.78, \"learn_time_ms\": 10332.975, \"total_train_time_s\": 12.27551555633545}", "{\"n\": 15267, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3741.02, \"learn_time_ms\": 10367.935, \"total_train_time_s\": 11.490716695785522}", "{\"n\": 15268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3735.82, \"learn_time_ms\": 10232.55, \"total_train_time_s\": 11.018488883972168}", "{\"n\": 15269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3748.56, \"learn_time_ms\": 10171.372, \"total_train_time_s\": 12.262839555740356}", "{\"n\": 15270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3743.71, \"learn_time_ms\": 10198.388, \"total_train_time_s\": 11.998785972595215}", "{\"n\": 15271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3741.12, \"learn_time_ms\": 10120.938, \"total_train_time_s\": 11.67571210861206}", "{\"n\": 15272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3742.43, \"learn_time_ms\": 10238.415, \"total_train_time_s\": 12.420960664749146}", "{\"n\": 15273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3739.51, \"learn_time_ms\": 10223.65, \"total_train_time_s\": 12.291839122772217}", "{\"n\": 15274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3741.02, \"learn_time_ms\": 10241.004, \"total_train_time_s\": 12.82423710823059}", "{\"n\": 15275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3734.29, \"learn_time_ms\": 10050.306, \"total_train_time_s\": 11.510379076004028}", "{\"n\": 15276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3733.66, \"learn_time_ms\": 9952.049, \"total_train_time_s\": 11.246111154556274}", "{\"n\": 15277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3733.66, \"learn_time_ms\": 10008.004, \"total_train_time_s\": 12.073709487915039}", "{\"n\": 15278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3733.0, \"learn_time_ms\": 10117.006, \"total_train_time_s\": 12.133369207382202}", "{\"n\": 15279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3722.67, \"learn_time_ms\": 10084.632, \"total_train_time_s\": 11.895982265472412}", "{\"n\": 15280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3720.82, \"learn_time_ms\": 10276.589, \"total_train_time_s\": 13.892553329467773}", "{\"n\": 15281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3722.25, \"learn_time_ms\": 10305.559, \"total_train_time_s\": 11.964797258377075}", "{\"n\": 15282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3707.39, \"learn_time_ms\": 10296.48, \"total_train_time_s\": 12.320485353469849}", "{\"n\": 15283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3707.39, \"learn_time_ms\": 10259.212, \"total_train_time_s\": 11.909013271331787}", "{\"n\": 15284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3708.49, \"learn_time_ms\": 10205.831, \"total_train_time_s\": 12.251270294189453}", "{\"n\": 15285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3704.32, \"learn_time_ms\": 10130.801, \"total_train_time_s\": 10.799566268920898}", "{\"n\": 15286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3707.31, \"learn_time_ms\": 10195.468, \"total_train_time_s\": 11.953569173812866}", "{\"n\": 15287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3707.31, \"learn_time_ms\": 10211.429, \"total_train_time_s\": 12.241019248962402}", "{\"n\": 15288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3700.56, \"learn_time_ms\": 10149.02, \"total_train_time_s\": 11.534257173538208}", "{\"n\": 15289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3701.16, \"learn_time_ms\": 10194.144, \"total_train_time_s\": 12.40210509300232}", "{\"n\": 15290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3700.33, \"learn_time_ms\": 9970.464, \"total_train_time_s\": 11.643600463867188}", "{\"n\": 15291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3700.33, \"learn_time_ms\": 9906.738, \"total_train_time_s\": 11.306286096572876}", "{\"n\": 15292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3685.38, \"learn_time_ms\": 9891.022, \"total_train_time_s\": 12.209142208099365}", "{\"n\": 15293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3685.38, \"learn_time_ms\": 9869.491, \"total_train_time_s\": 11.701852321624756}", "{\"n\": 15294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3678.85, \"learn_time_ms\": 9784.423, \"total_train_time_s\": 11.409698486328125}", "{\"n\": 15295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3673.66, \"learn_time_ms\": 9840.075, \"total_train_time_s\": 11.313182592391968}", "{\"n\": 15296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.6, \"learn_time_ms\": 9956.674, \"total_train_time_s\": 13.092740058898926}", "{\"n\": 15297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.6, \"learn_time_ms\": 9903.708, \"total_train_time_s\": 11.7671217918396}", "{\"n\": 15298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3682.7, \"learn_time_ms\": 9962.157, \"total_train_time_s\": 12.078828573226929}", "{\"n\": 15299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3681.76, \"learn_time_ms\": 9955.388, \"total_train_time_s\": 12.308291912078857}", "{\"n\": 15300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.03, \"learn_time_ms\": 9997.984, \"total_train_time_s\": 12.07297420501709}", "{\"n\": 15301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.57, \"learn_time_ms\": 10070.681, \"total_train_time_s\": 12.07365369796753}", "{\"n\": 15302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.57, \"learn_time_ms\": 10160.373, \"total_train_time_s\": 13.036362886428833}", "{\"n\": 15303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3680.07, \"learn_time_ms\": 10242.685, \"total_train_time_s\": 12.530236959457397}", "{\"n\": 15304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3680.07, \"learn_time_ms\": 10329.801, \"total_train_time_s\": 12.291396856307983}", "{\"n\": 15305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3680.99, \"learn_time_ms\": 10319.532, \"total_train_time_s\": 11.228145837783813}", "{\"n\": 15306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3684.47, \"learn_time_ms\": 10208.643, \"total_train_time_s\": 11.988459348678589}", "{\"n\": 15307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3688.08, \"learn_time_ms\": 10352.476, \"total_train_time_s\": 13.165234804153442}", "{\"n\": 15308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3688.08, \"learn_time_ms\": 10255.628, \"total_train_time_s\": 11.13857913017273}", "{\"n\": 15309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.09, \"learn_time_ms\": 10213.813, \"total_train_time_s\": 11.88807463645935}", "{\"n\": 15310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3691.55, \"learn_time_ms\": 10171.818, \"total_train_time_s\": 11.636766195297241}", "{\"n\": 15311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3697.48, \"learn_time_ms\": 10159.434, \"total_train_time_s\": 11.923693180084229}", "{\"n\": 15312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3697.48, \"learn_time_ms\": 10097.434, \"total_train_time_s\": 12.442794799804688}", "{\"n\": 15313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3705.65, \"learn_time_ms\": 9980.356, \"total_train_time_s\": 11.3263258934021}", "{\"n\": 15314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.9, \"learn_time_ms\": 9939.866, \"total_train_time_s\": 11.846663475036621}", "{\"n\": 15315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.18, \"learn_time_ms\": 10003.779, \"total_train_time_s\": 11.83722472190857}", "{\"n\": 15316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.18, \"learn_time_ms\": 9930.798, \"total_train_time_s\": 11.237645626068115}", "{\"n\": 15317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.84, \"learn_time_ms\": 9766.292, \"total_train_time_s\": 11.500725030899048}", "{\"n\": 15318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.18, \"learn_time_ms\": 9917.407, \"total_train_time_s\": 12.616946697235107}", "{\"n\": 15319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.18, \"learn_time_ms\": 9892.145, \"total_train_time_s\": 11.598819732666016}", "{\"n\": 15320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.18, \"learn_time_ms\": 9990.042, \"total_train_time_s\": 12.609151363372803}", "{\"n\": 15321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.73, \"learn_time_ms\": 10006.771, \"total_train_time_s\": 12.068041563034058}", "{\"n\": 15322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.97, \"learn_time_ms\": 9994.166, \"total_train_time_s\": 12.266796112060547}", "{\"n\": 15323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.97, \"learn_time_ms\": 10135.135, \"total_train_time_s\": 12.727904081344604}", "{\"n\": 15324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.63, \"learn_time_ms\": 10176.759, \"total_train_time_s\": 12.262935161590576}", "{\"n\": 15325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.68, \"learn_time_ms\": 10238.889, \"total_train_time_s\": 12.510955095291138}", "{\"n\": 15326, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.63, \"learn_time_ms\": 10269.423, \"total_train_time_s\": 11.523711442947388}", "{\"n\": 15327, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.63, \"learn_time_ms\": 10278.047, \"total_train_time_s\": 11.548105716705322}", "{\"n\": 15328, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.43, \"learn_time_ms\": 10310.558, \"total_train_time_s\": 12.924144983291626}", "{\"n\": 15329, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.04, \"learn_time_ms\": 10458.521, \"total_train_time_s\": 13.121910572052002}", "{\"n\": 15330, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.04, \"learn_time_ms\": 10347.787, \"total_train_time_s\": 11.538606405258179}", "{\"n\": 15331, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.11, \"learn_time_ms\": 10345.995, \"total_train_time_s\": 12.050862312316895}", "{\"n\": 15332, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.98, \"learn_time_ms\": 10309.495, \"total_train_time_s\": 11.911950588226318}", "{\"n\": 15333, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.54, \"learn_time_ms\": 10267.079, \"total_train_time_s\": 12.335133075714111}", "{\"n\": 15334, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.54, \"learn_time_ms\": 10274.775, \"total_train_time_s\": 12.346012830734253}", "{\"n\": 15335, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.32, \"learn_time_ms\": 10203.941, \"total_train_time_s\": 11.793992042541504}", "{\"n\": 15336, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.61, \"learn_time_ms\": 10159.737, \"total_train_time_s\": 11.117496013641357}", "{\"n\": 15337, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.97, \"learn_time_ms\": 10140.066, \"total_train_time_s\": 11.354316473007202}", "{\"n\": 15338, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.25, \"learn_time_ms\": 10131.35, \"total_train_time_s\": 12.846530675888062}", "{\"n\": 15339, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.19, \"learn_time_ms\": 9858.35, \"total_train_time_s\": 10.323748350143433}", "{\"n\": 15340, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.19, \"learn_time_ms\": 9912.977, \"total_train_time_s\": 12.064937353134155}", "{\"n\": 15341, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.29, \"learn_time_ms\": 9940.973, \"total_train_time_s\": 12.321252584457397}", "{\"n\": 15342, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.96, \"learn_time_ms\": 9907.29, \"total_train_time_s\": 11.610190391540527}", "{\"n\": 15343, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.09, \"learn_time_ms\": 9878.882, \"total_train_time_s\": 12.01864743232727}", "{\"n\": 15344, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.09, \"learn_time_ms\": 9864.097, \"total_train_time_s\": 12.196049451828003}", "{\"n\": 15345, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.24, \"learn_time_ms\": 9949.442, \"total_train_time_s\": 12.612712383270264}", "{\"n\": 15346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.79, \"learn_time_ms\": 10059.516, \"total_train_time_s\": 12.220072507858276}", "{\"n\": 15347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.79, \"learn_time_ms\": 10138.552, \"total_train_time_s\": 12.169069051742554}", "{\"n\": 15348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.93, \"learn_time_ms\": 10098.381, \"total_train_time_s\": 12.434929370880127}", "{\"n\": 15349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.19, \"learn_time_ms\": 10169.123, \"total_train_time_s\": 11.033737421035767}", "{\"n\": 15350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.14, \"learn_time_ms\": 10210.86, \"total_train_time_s\": 12.481730222702026}", "{\"n\": 15351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.07, \"learn_time_ms\": 10174.1, \"total_train_time_s\": 11.996817588806152}", "{\"n\": 15352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.81, \"learn_time_ms\": 10219.006, \"total_train_time_s\": 12.085217475891113}", "{\"n\": 15353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.94, \"learn_time_ms\": 10244.839, \"total_train_time_s\": 12.250461339950562}", "{\"n\": 15354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.0, \"learn_time_ms\": 10189.635, \"total_train_time_s\": 11.650766849517822}", "{\"n\": 15355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.71, \"learn_time_ms\": 10250.541, \"total_train_time_s\": 13.204752683639526}", "{\"n\": 15356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.12, \"learn_time_ms\": 10247.664, \"total_train_time_s\": 12.16329836845398}", "{\"n\": 15357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.44, \"learn_time_ms\": 10194.083, \"total_train_time_s\": 11.633143901824951}", "{\"n\": 15358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.44, \"learn_time_ms\": 10107.312, \"total_train_time_s\": 11.66493272781372}", "{\"n\": 15359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.88, \"learn_time_ms\": 10178.731, \"total_train_time_s\": 11.822053909301758}", "{\"n\": 15360, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.75, \"learn_time_ms\": 10205.061, \"total_train_time_s\": 12.727629899978638}", "{\"n\": 15361, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.62, \"learn_time_ms\": 10291.406, \"total_train_time_s\": 12.872097730636597}", "{\"n\": 15362, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.62, \"learn_time_ms\": 10467.721, \"total_train_time_s\": 13.84117865562439}", "{\"n\": 15363, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.01, \"learn_time_ms\": 10590.189, \"total_train_time_s\": 13.553841590881348}", "{\"n\": 15364, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.31, \"learn_time_ms\": 10765.576, \"total_train_time_s\": 13.403923749923706}", "{\"n\": 15365, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.33, \"learn_time_ms\": 10704.943, \"total_train_time_s\": 12.64648151397705}", "{\"n\": 15366, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.31, \"learn_time_ms\": 10680.952, \"total_train_time_s\": 11.900220394134521}", "{\"n\": 15367, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.94, \"learn_time_ms\": 10800.477, \"total_train_time_s\": 12.800920724868774}", "{\"n\": 15368, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.94, \"learn_time_ms\": 10876.079, \"total_train_time_s\": 12.362455606460571}", "{\"n\": 15369, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.87, \"learn_time_ms\": 10922.697, \"total_train_time_s\": 12.249613046646118}", "{\"n\": 15370, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.4, \"learn_time_ms\": 10855.344, \"total_train_time_s\": 12.057304620742798}", "{\"n\": 15371, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.05, \"learn_time_ms\": 10754.77, \"total_train_time_s\": 11.826554536819458}", "{\"n\": 15372, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.27, \"learn_time_ms\": 10687.927, \"total_train_time_s\": 13.175370693206787}", "{\"n\": 15373, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.27, \"learn_time_ms\": 10454.097, \"total_train_time_s\": 11.177668333053589}", "{\"n\": 15374, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.19, \"learn_time_ms\": 10300.746, \"total_train_time_s\": 11.908010005950928}", "{\"n\": 15375, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.04, \"learn_time_ms\": 10257.926, \"total_train_time_s\": 12.203491687774658}", "{\"n\": 15376, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.86, \"learn_time_ms\": 10314.364, \"total_train_time_s\": 12.535272359848022}", "{\"n\": 15377, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.86, \"learn_time_ms\": 10244.937, \"total_train_time_s\": 12.117323160171509}", "{\"n\": 15378, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.65, \"learn_time_ms\": 10235.213, \"total_train_time_s\": 12.263876914978027}", "{\"n\": 15379, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.93, \"learn_time_ms\": 10194.45, \"total_train_time_s\": 11.842787027359009}", "{\"n\": 15380, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.93, \"learn_time_ms\": 10143.738, \"total_train_time_s\": 11.595372200012207}", "{\"n\": 15381, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.64, \"learn_time_ms\": 10128.433, \"total_train_time_s\": 11.688981771469116}", "{\"n\": 15382, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 9985.817, \"total_train_time_s\": 11.704794883728027}", "{\"n\": 15383, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 10021.496, \"total_train_time_s\": 11.536290645599365}", "{\"n\": 15384, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.88, \"learn_time_ms\": 10210.405, \"total_train_time_s\": 13.777794361114502}", "{\"n\": 15385, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.51, \"learn_time_ms\": 10218.008, \"total_train_time_s\": 12.299152135848999}", "{\"n\": 15386, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.51, \"learn_time_ms\": 10251.105, \"total_train_time_s\": 12.847230195999146}", "{\"n\": 15387, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.36, \"learn_time_ms\": 10236.584, \"total_train_time_s\": 11.998793840408325}", "{\"n\": 15388, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.47, \"learn_time_ms\": 10334.267, \"total_train_time_s\": 13.21214509010315}", "{\"n\": 15389, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.81, \"learn_time_ms\": 10380.649, \"total_train_time_s\": 12.339395761489868}", "{\"n\": 15390, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.81, \"learn_time_ms\": 10393.445, \"total_train_time_s\": 11.708455085754395}", "{\"n\": 15391, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.93, \"learn_time_ms\": 10356.13, \"total_train_time_s\": 11.352888107299805}", "{\"n\": 15392, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.53, \"learn_time_ms\": 10383.177, \"total_train_time_s\": 12.003702878952026}", "{\"n\": 15393, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.65, \"learn_time_ms\": 10477.184, \"total_train_time_s\": 12.461055278778076}", "{\"n\": 15394, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.65, \"learn_time_ms\": 10351.182, \"total_train_time_s\": 12.5106840133667}", "{\"n\": 15395, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.92, \"learn_time_ms\": 10278.482, \"total_train_time_s\": 11.570611953735352}", "{\"n\": 15396, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.2, \"learn_time_ms\": 10212.0, \"total_train_time_s\": 12.15696668624878}", "{\"n\": 15397, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.49, \"learn_time_ms\": 10169.114, \"total_train_time_s\": 11.537375211715698}", "{\"n\": 15398, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.49, \"learn_time_ms\": 10004.892, \"total_train_time_s\": 11.589831352233887}", "{\"n\": 15399, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.46, \"learn_time_ms\": 10073.408, \"total_train_time_s\": 13.012349367141724}", "{\"n\": 15400, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.81, \"learn_time_ms\": 10053.212, \"total_train_time_s\": 11.48329782485962}", "{\"n\": 15401, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.81, \"learn_time_ms\": 10081.874, \"total_train_time_s\": 11.594148635864258}", "{\"n\": 15402, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.24, \"learn_time_ms\": 10092.927, \"total_train_time_s\": 12.079872131347656}", "{\"n\": 15403, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.99, \"learn_time_ms\": 9990.008, \"total_train_time_s\": 11.441311836242676}", "{\"n\": 15404, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.18, \"learn_time_ms\": 9939.985, \"total_train_time_s\": 11.97783875465393}", "{\"n\": 15405, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.18, \"learn_time_ms\": 9915.549, \"total_train_time_s\": 11.350239515304565}", "{\"n\": 15406, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.54, \"learn_time_ms\": 9909.5, \"total_train_time_s\": 12.130110263824463}", "{\"n\": 15407, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.66, \"learn_time_ms\": 10017.964, \"total_train_time_s\": 12.61055588722229}", "{\"n\": 15408, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.01, \"learn_time_ms\": 10034.691, \"total_train_time_s\": 11.77028775215149}", "{\"n\": 15409, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.55, \"learn_time_ms\": 9873.968, \"total_train_time_s\": 11.362385034561157}", "{\"n\": 15410, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.55, \"learn_time_ms\": 9945.712, \"total_train_time_s\": 12.218273878097534}", "{\"n\": 15411, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.23, \"learn_time_ms\": 9987.492, \"total_train_time_s\": 12.060629606246948}", "{\"n\": 15412, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.23, \"learn_time_ms\": 10007.31, \"total_train_time_s\": 12.30288028717041}", "{\"n\": 15413, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.08, \"learn_time_ms\": 10099.508, \"total_train_time_s\": 12.374007940292358}", "{\"n\": 15414, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.45, \"learn_time_ms\": 10086.884, \"total_train_time_s\": 11.843528985977173}", "{\"n\": 15415, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.45, \"learn_time_ms\": 10139.644, \"total_train_time_s\": 11.846508741378784}", "{\"n\": 15416, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.45, \"learn_time_ms\": 10003.489, \"total_train_time_s\": 10.75956130027771}", "{\"n\": 15417, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.8, \"learn_time_ms\": 9945.208, \"total_train_time_s\": 12.05361294746399}", "{\"n\": 15418, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.11, \"learn_time_ms\": 10016.146, \"total_train_time_s\": 12.453794956207275}", "{\"n\": 15419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.05, \"learn_time_ms\": 10088.771, \"total_train_time_s\": 12.106141090393066}", "{\"n\": 15420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.15, \"learn_time_ms\": 10185.44, \"total_train_time_s\": 13.171884298324585}", "{\"n\": 15421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.38, \"learn_time_ms\": 10187.827, \"total_train_time_s\": 12.05805778503418}", "{\"n\": 15422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 10147.406, \"total_train_time_s\": 11.906552791595459}", "{\"n\": 15423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.52, \"learn_time_ms\": 10103.688, \"total_train_time_s\": 11.967976570129395}", "{\"n\": 15424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.58, \"learn_time_ms\": 10111.554, \"total_train_time_s\": 11.95991039276123}", "{\"n\": 15425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.48, \"learn_time_ms\": 10094.869, \"total_train_time_s\": 11.692591905593872}", "{\"n\": 15426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.26, \"learn_time_ms\": 10382.306, \"total_train_time_s\": 13.609784364700317}", "{\"n\": 15427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.03, \"learn_time_ms\": 10335.08, \"total_train_time_s\": 11.587809801101685}", "{\"n\": 15428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.03, \"learn_time_ms\": 10256.386, \"total_train_time_s\": 11.674881219863892}", "{\"n\": 15429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.76, \"learn_time_ms\": 10243.544, \"total_train_time_s\": 11.991877555847168}", "{\"n\": 15430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.58, \"learn_time_ms\": 10130.607, \"total_train_time_s\": 12.050040006637573}", "{\"n\": 15431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.63, \"learn_time_ms\": 10110.07, \"total_train_time_s\": 11.809142589569092}", "{\"n\": 15432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.08, \"learn_time_ms\": 10169.522, \"total_train_time_s\": 12.428447246551514}", "{\"n\": 15433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.02, \"learn_time_ms\": 10258.794, \"total_train_time_s\": 12.827721118927002}", "{\"n\": 15434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.79, \"learn_time_ms\": 10431.11, \"total_train_time_s\": 13.703168392181396}", "{\"n\": 15435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.94, \"learn_time_ms\": 10381.452, \"total_train_time_s\": 11.156888246536255}", "{\"n\": 15436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.69, \"learn_time_ms\": 10231.32, \"total_train_time_s\": 12.115288734436035}", "{\"n\": 15437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.69, \"learn_time_ms\": 10204.758, \"total_train_time_s\": 11.269551753997803}", "{\"n\": 15438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.68, \"learn_time_ms\": 10220.09, \"total_train_time_s\": 11.822741985321045}", "{\"n\": 15439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.85, \"learn_time_ms\": 10188.217, \"total_train_time_s\": 11.693976402282715}", "{\"n\": 15440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.85, \"learn_time_ms\": 10167.468, \"total_train_time_s\": 11.859863042831421}", "{\"n\": 15441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.72, \"learn_time_ms\": 10266.185, \"total_train_time_s\": 12.827499151229858}", "{\"n\": 15442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.4, \"learn_time_ms\": 10133.926, \"total_train_time_s\": 11.196960687637329}", "{\"n\": 15443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.52, \"learn_time_ms\": 10068.771, \"total_train_time_s\": 12.18157148361206}", "{\"n\": 15444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.67, \"learn_time_ms\": 9910.045, \"total_train_time_s\": 12.076339483261108}", "{\"n\": 15445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10052.53, \"total_train_time_s\": 12.612807512283325}", "{\"n\": 15446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.22, \"learn_time_ms\": 10089.886, \"total_train_time_s\": 12.482689619064331}", "{\"n\": 15447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.22, \"learn_time_ms\": 10286.718, \"total_train_time_s\": 13.287730693817139}", "{\"n\": 15448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.54, \"learn_time_ms\": 10421.021, \"total_train_time_s\": 13.16788387298584}", "{\"n\": 15449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.57, \"learn_time_ms\": 10442.607, \"total_train_time_s\": 11.904764413833618}", "{\"n\": 15450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.57, \"learn_time_ms\": 10459.655, \"total_train_time_s\": 11.97454833984375}", "{\"n\": 15451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.57, \"learn_time_ms\": 10339.211, \"total_train_time_s\": 11.558430671691895}", "{\"n\": 15452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10362.53, \"total_train_time_s\": 11.36173963546753}", "{\"n\": 15453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10310.852, \"total_train_time_s\": 11.617475986480713}", "{\"n\": 15454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10278.82, \"total_train_time_s\": 11.751475811004639}", "{\"n\": 15455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10233.306, \"total_train_time_s\": 12.139920949935913}", "{\"n\": 15456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.57, \"learn_time_ms\": 10212.067, \"total_train_time_s\": 12.273406744003296}", "{\"n\": 15457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.51, \"learn_time_ms\": 10210.648, \"total_train_time_s\": 13.258131265640259}", "{\"n\": 15458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.63, \"learn_time_ms\": 10069.919, \"total_train_time_s\": 11.775728464126587}", "{\"n\": 15459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.63, \"learn_time_ms\": 10008.208, \"total_train_time_s\": 11.307739019393921}", "{\"n\": 15460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.54, \"learn_time_ms\": 10198.605, \"total_train_time_s\": 13.955172300338745}", "{\"n\": 15461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.25, \"learn_time_ms\": 10168.57, \"total_train_time_s\": 11.316433429718018}", "{\"n\": 15462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.25, \"learn_time_ms\": 10184.862, \"total_train_time_s\": 11.539493560791016}", "{\"n\": 15463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.25, \"learn_time_ms\": 10123.992, \"total_train_time_s\": 11.022571802139282}", "{\"n\": 15464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.71, \"learn_time_ms\": 10204.327, \"total_train_time_s\": 12.55484938621521}", "{\"n\": 15465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 10169.328, \"total_train_time_s\": 11.818971872329712}", "{\"n\": 15466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.53, \"learn_time_ms\": 10216.862, \"total_train_time_s\": 12.790268421173096}", "{\"n\": 15467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.02, \"learn_time_ms\": 10112.255, \"total_train_time_s\": 12.25064492225647}", "{\"n\": 15468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.57, \"learn_time_ms\": 10147.096, \"total_train_time_s\": 12.130144119262695}", "{\"n\": 15469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.57, \"learn_time_ms\": 10356.81, \"total_train_time_s\": 13.392090797424316}", "{\"n\": 15470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.95, \"learn_time_ms\": 10147.107, \"total_train_time_s\": 11.772851943969727}", "{\"n\": 15471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.02, \"learn_time_ms\": 10256.208, \"total_train_time_s\": 12.373556137084961}", "{\"n\": 15472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.02, \"learn_time_ms\": 10299.902, \"total_train_time_s\": 12.006277799606323}", "{\"n\": 15473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.02, \"learn_time_ms\": 10387.257, \"total_train_time_s\": 11.918466567993164}", "{\"n\": 15474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.81, \"learn_time_ms\": 10357.6, \"total_train_time_s\": 12.26059889793396}", "{\"n\": 15475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.27, \"learn_time_ms\": 10447.696, \"total_train_time_s\": 12.683135747909546}", "{\"n\": 15476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.27, \"learn_time_ms\": 10343.105, \"total_train_time_s\": 11.713305234909058}", "{\"n\": 15477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.27, \"learn_time_ms\": 10389.854, \"total_train_time_s\": 12.712580919265747}", "{\"n\": 15478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.77, \"learn_time_ms\": 10455.99, \"total_train_time_s\": 12.774798154830933}", "{\"n\": 15479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10379.576, \"total_train_time_s\": 12.622190475463867}", "{\"n\": 15480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.45, \"learn_time_ms\": 10408.265, \"total_train_time_s\": 12.098532676696777}", "{\"n\": 15481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.06, \"learn_time_ms\": 10364.337, \"total_train_time_s\": 11.974340438842773}", "{\"n\": 15482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.63, \"learn_time_ms\": 10373.564, \"total_train_time_s\": 12.07250428199768}", "{\"n\": 15483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.56, \"learn_time_ms\": 10364.589, \"total_train_time_s\": 11.85119104385376}", "{\"n\": 15484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.56, \"learn_time_ms\": 10372.824, \"total_train_time_s\": 12.359589338302612}", "{\"n\": 15485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.28, \"learn_time_ms\": 10380.737, \"total_train_time_s\": 12.77041506767273}", "{\"n\": 15486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.37, \"learn_time_ms\": 10301.171, \"total_train_time_s\": 10.878795623779297}", "{\"n\": 15487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.24, \"learn_time_ms\": 10234.623, \"total_train_time_s\": 12.029977560043335}", "{\"n\": 15488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.24, \"learn_time_ms\": 10195.195, \"total_train_time_s\": 12.40729808807373}", "{\"n\": 15489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.66, \"learn_time_ms\": 10051.126, \"total_train_time_s\": 11.19307804107666}", "{\"n\": 15490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.46, \"learn_time_ms\": 10073.22, \"total_train_time_s\": 12.29900598526001}", "{\"n\": 15491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.46, \"learn_time_ms\": 9977.29, \"total_train_time_s\": 11.024204969406128}", "{\"n\": 15492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.46, \"learn_time_ms\": 10044.504, \"total_train_time_s\": 12.780462503433228}", "{\"n\": 15493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.43, \"learn_time_ms\": 10134.082, \"total_train_time_s\": 12.752854824066162}", "{\"n\": 15494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.53, \"learn_time_ms\": 10147.765, \"total_train_time_s\": 12.463988065719604}", "{\"n\": 15495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.53, \"learn_time_ms\": 10085.387, \"total_train_time_s\": 12.177974700927734}", "{\"n\": 15496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.53, \"learn_time_ms\": 10220.025, \"total_train_time_s\": 12.251102685928345}", "{\"n\": 15497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.08, \"learn_time_ms\": 10256.394, \"total_train_time_s\": 12.385765314102173}", "{\"n\": 15498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.13, \"learn_time_ms\": 10205.399, \"total_train_time_s\": 11.860825300216675}", "{\"n\": 15499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.13, \"learn_time_ms\": 10259.807, \"total_train_time_s\": 11.69106936454773}", "{\"n\": 15500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.88, \"learn_time_ms\": 10242.722, \"total_train_time_s\": 12.169592142105103}", "{\"n\": 15501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.42, \"learn_time_ms\": 10241.418, \"total_train_time_s\": 11.012223243713379}", "{\"n\": 15502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.83, \"learn_time_ms\": 10194.95, \"total_train_time_s\": 12.290073871612549}", "{\"n\": 15503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.83, \"learn_time_ms\": 10104.836, \"total_train_time_s\": 11.835670709609985}", "{\"n\": 15504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.52, \"learn_time_ms\": 10092.094, \"total_train_time_s\": 12.406062364578247}", "{\"n\": 15505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.17, \"learn_time_ms\": 10071.826, \"total_train_time_s\": 12.017292022705078}", "{\"n\": 15506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.17, \"learn_time_ms\": 10090.123, \"total_train_time_s\": 12.416071891784668}", "{\"n\": 15507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.17, \"learn_time_ms\": 10159.733, \"total_train_time_s\": 13.118149042129517}", "{\"n\": 15508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 10150.065, \"total_train_time_s\": 11.80578351020813}", "{\"n\": 15509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.57, \"learn_time_ms\": 10274.284, \"total_train_time_s\": 12.938858270645142}", "{\"n\": 15510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.57, \"learn_time_ms\": 10267.574, \"total_train_time_s\": 12.059123754501343}", "{\"n\": 15511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.09, \"learn_time_ms\": 10348.649, \"total_train_time_s\": 11.84459924697876}", "{\"n\": 15512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.68, \"learn_time_ms\": 10426.716, \"total_train_time_s\": 13.125820636749268}", "{\"n\": 15513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.08, \"learn_time_ms\": 10395.126, \"total_train_time_s\": 11.499981164932251}", "{\"n\": 15514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.08, \"learn_time_ms\": 10398.021, \"total_train_time_s\": 12.385828018188477}", "{\"n\": 15515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.51, \"learn_time_ms\": 10508.908, \"total_train_time_s\": 13.04175591468811}", "{\"n\": 15516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.17, \"learn_time_ms\": 10503.992, \"total_train_time_s\": 12.409180879592896}", "{\"n\": 15517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.83, \"learn_time_ms\": 10356.339, \"total_train_time_s\": 11.62018632888794}", "{\"n\": 15518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.5, \"learn_time_ms\": 10487.669, \"total_train_time_s\": 13.102446556091309}", "{\"n\": 15519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.26, \"learn_time_ms\": 10504.384, \"total_train_time_s\": 13.100819826126099}", "{\"n\": 15520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.0, \"learn_time_ms\": 10459.534, \"total_train_time_s\": 11.651621103286743}", "{\"n\": 15521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.0, \"learn_time_ms\": 10435.234, \"total_train_time_s\": 11.586579084396362}", "{\"n\": 15522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.61, \"learn_time_ms\": 10229.45, \"total_train_time_s\": 11.013848304748535}", "{\"n\": 15523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.89, \"learn_time_ms\": 10191.366, \"total_train_time_s\": 11.223751306533813}", "{\"n\": 15524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.38, \"learn_time_ms\": 10248.12, \"total_train_time_s\": 13.011224269866943}", "{\"n\": 15525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.38, \"learn_time_ms\": 10058.429, \"total_train_time_s\": 11.168941020965576}", "{\"n\": 15526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.71, \"learn_time_ms\": 10000.263, \"total_train_time_s\": 11.849913597106934}", "{\"n\": 15527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.15, \"learn_time_ms\": 10076.925, \"total_train_time_s\": 12.409079313278198}", "{\"n\": 15528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.15, \"learn_time_ms\": 9955.152, \"total_train_time_s\": 11.84185242652893}", "{\"n\": 15529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.72, \"learn_time_ms\": 9957.457, \"total_train_time_s\": 13.136923789978027}", "{\"n\": 15530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.35, \"learn_time_ms\": 10025.087, \"total_train_time_s\": 12.338164806365967}", "{\"n\": 15531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 10027.703, \"total_train_time_s\": 11.601459741592407}", "{\"n\": 15532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 10062.005, \"total_train_time_s\": 11.343758344650269}", "{\"n\": 15533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.69, \"learn_time_ms\": 10121.328, \"total_train_time_s\": 11.72117829322815}", "{\"n\": 15534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.31, \"learn_time_ms\": 10045.42, \"total_train_time_s\": 12.21869444847107}", "{\"n\": 15535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.9, \"learn_time_ms\": 10044.799, \"total_train_time_s\": 11.142428398132324}", "{\"n\": 15536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.03, \"learn_time_ms\": 10209.494, \"total_train_time_s\": 13.446650505065918}", "{\"n\": 15537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.97, \"learn_time_ms\": 10241.783, \"total_train_time_s\": 12.703920602798462}", "{\"n\": 15538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.36, \"learn_time_ms\": 10304.767, \"total_train_time_s\": 12.453046798706055}", "{\"n\": 15539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.32, \"learn_time_ms\": 10234.418, \"total_train_time_s\": 12.412443161010742}", "{\"n\": 15540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.69, \"learn_time_ms\": 10137.713, \"total_train_time_s\": 11.334191799163818}", "{\"n\": 15541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.69, \"learn_time_ms\": 10188.789, \"total_train_time_s\": 12.24527621269226}", "{\"n\": 15542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.02, \"learn_time_ms\": 10413.075, \"total_train_time_s\": 13.59586501121521}", "{\"n\": 15543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.02, \"learn_time_ms\": 10491.803, \"total_train_time_s\": 12.470328569412231}", "{\"n\": 15544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3719.96, \"learn_time_ms\": 10493.043, \"total_train_time_s\": 12.199244022369385}", "{\"n\": 15545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.61, \"learn_time_ms\": 10683.992, \"total_train_time_s\": 13.077563762664795}", "{\"n\": 15546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.61, \"learn_time_ms\": 10543.736, \"total_train_time_s\": 12.070364952087402}", "{\"n\": 15547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3731.25, \"learn_time_ms\": 10413.547, \"total_train_time_s\": 11.412045001983643}", "{\"n\": 15548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3721.1, \"learn_time_ms\": 10460.245, \"total_train_time_s\": 12.979015350341797}", "{\"n\": 15549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3719.46, \"learn_time_ms\": 10371.717, \"total_train_time_s\": 11.550952672958374}", "{\"n\": 15550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3719.46, \"learn_time_ms\": 10473.849, \"total_train_time_s\": 12.334357976913452}", "{\"n\": 15551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.42, \"learn_time_ms\": 10582.967, \"total_train_time_s\": 13.253435134887695}", "{\"n\": 15552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.42, \"learn_time_ms\": 10482.706, \"total_train_time_s\": 12.622857809066772}", "{\"n\": 15553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.93, \"learn_time_ms\": 10517.96, \"total_train_time_s\": 12.835583925247192}", "{\"n\": 15554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.04, \"learn_time_ms\": 10448.499, \"total_train_time_s\": 11.522106647491455}", "{\"n\": 15555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.41, \"learn_time_ms\": 10337.89, \"total_train_time_s\": 11.967989921569824}", "{\"n\": 15556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.41, \"learn_time_ms\": 10344.06, \"total_train_time_s\": 12.087476253509521}", "{\"n\": 15557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.42, \"learn_time_ms\": 10352.525, \"total_train_time_s\": 11.490616798400879}", "{\"n\": 15558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.71, \"learn_time_ms\": 10318.985, \"total_train_time_s\": 12.646800756454468}", "{\"n\": 15559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.71, \"learn_time_ms\": 10386.821, \"total_train_time_s\": 12.225248336791992}", "{\"n\": 15560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.78, \"learn_time_ms\": 10334.839, \"total_train_time_s\": 11.87844729423523}", "{\"n\": 15561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.0, \"learn_time_ms\": 10313.618, \"total_train_time_s\": 13.048509120941162}", "{\"n\": 15562, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.19, \"learn_time_ms\": 10174.288, \"total_train_time_s\": 11.224848747253418}", "{\"n\": 15563, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.4, \"learn_time_ms\": 10124.673, \"total_train_time_s\": 12.386996030807495}", "{\"n\": 15564, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.4, \"learn_time_ms\": 10237.586, \"total_train_time_s\": 12.667068243026733}", "{\"n\": 15565, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.99, \"learn_time_ms\": 10354.116, \"total_train_time_s\": 13.182750463485718}", "{\"n\": 15566, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.68, \"learn_time_ms\": 10336.237, \"total_train_time_s\": 11.953494310379028}", "{\"n\": 15567, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.38, \"learn_time_ms\": 10405.046, \"total_train_time_s\": 12.13987135887146}", "{\"n\": 15568, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.65, \"learn_time_ms\": 10248.568, \"total_train_time_s\": 11.086192607879639}", "{\"n\": 15569, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.13, \"learn_time_ms\": 10248.484, \"total_train_time_s\": 12.289374113082886}", "{\"n\": 15570, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.06, \"learn_time_ms\": 10205.622, \"total_train_time_s\": 11.419746398925781}", "{\"n\": 15571, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.06, \"learn_time_ms\": 10027.089, \"total_train_time_s\": 11.21689772605896}", "{\"n\": 15572, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.01, \"learn_time_ms\": 10101.552, \"total_train_time_s\": 11.962717294692993}", "{\"n\": 15573, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.95, \"learn_time_ms\": 10082.946, \"total_train_time_s\": 12.202799320220947}", "{\"n\": 15574, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.55, \"learn_time_ms\": 9991.127, \"total_train_time_s\": 11.71098804473877}", "{\"n\": 15575, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.11, \"learn_time_ms\": 9929.556, \"total_train_time_s\": 12.530683755874634}", "{\"n\": 15576, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.11, \"learn_time_ms\": 10058.822, \"total_train_time_s\": 13.240100383758545}", "{\"n\": 15577, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.66, \"learn_time_ms\": 9958.604, \"total_train_time_s\": 11.159593105316162}", "{\"n\": 15578, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.86, \"learn_time_ms\": 10041.361, \"total_train_time_s\": 11.915682315826416}", "{\"n\": 15579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.56, \"learn_time_ms\": 10053.093, \"total_train_time_s\": 12.404641389846802}", "{\"n\": 15580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.02, \"learn_time_ms\": 10097.057, \"total_train_time_s\": 11.90300440788269}", "{\"n\": 15581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.35, \"learn_time_ms\": 10201.343, \"total_train_time_s\": 12.22897982597351}", "{\"n\": 15582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.35, \"learn_time_ms\": 10213.454, \"total_train_time_s\": 12.053866863250732}", "{\"n\": 15583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.04, \"learn_time_ms\": 10215.074, \"total_train_time_s\": 12.17017936706543}", "{\"n\": 15584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.5, \"learn_time_ms\": 10251.724, \"total_train_time_s\": 12.136083126068115}", "{\"n\": 15585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.2, \"learn_time_ms\": 10228.733, \"total_train_time_s\": 12.292569160461426}", "{\"n\": 15586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.2, \"learn_time_ms\": 10194.296, \"total_train_time_s\": 12.852946519851685}", "{\"n\": 15587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.57, \"learn_time_ms\": 10278.482, \"total_train_time_s\": 11.986806631088257}", "{\"n\": 15588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.75, \"learn_time_ms\": 10303.877, \"total_train_time_s\": 12.130522727966309}", "{\"n\": 15589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.75, \"learn_time_ms\": 10212.48, \"total_train_time_s\": 11.365102052688599}", "{\"n\": 15590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.67, \"learn_time_ms\": 10267.904, \"total_train_time_s\": 12.4220449924469}", "{\"n\": 15591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.51, \"learn_time_ms\": 10210.6, \"total_train_time_s\": 11.701397180557251}", "{\"n\": 15592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.01, \"learn_time_ms\": 10280.047, \"total_train_time_s\": 12.749621868133545}", "{\"n\": 15593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.51, \"learn_time_ms\": 10176.762, \"total_train_time_s\": 11.145556449890137}", "{\"n\": 15594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.59, \"learn_time_ms\": 10203.062, \"total_train_time_s\": 12.380153894424438}", "{\"n\": 15595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10151.797, \"total_train_time_s\": 11.845220804214478}", "{\"n\": 15596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10048.211, \"total_train_time_s\": 11.858304977416992}", "{\"n\": 15597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.53, \"learn_time_ms\": 10092.243, \"total_train_time_s\": 12.451400756835938}", "{\"n\": 15598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.54, \"learn_time_ms\": 10103.077, \"total_train_time_s\": 12.292006492614746}", "{\"n\": 15599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.68, \"learn_time_ms\": 10151.929, \"total_train_time_s\": 11.888090372085571}", "{\"n\": 15600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.89, \"learn_time_ms\": 10077.233, \"total_train_time_s\": 11.658089399337769}", "{\"n\": 15601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.31, \"learn_time_ms\": 10094.365, \"total_train_time_s\": 11.837965488433838}", "{\"n\": 15602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.12, \"learn_time_ms\": 10152.409, \"total_train_time_s\": 13.353001117706299}", "{\"n\": 15603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.12, \"learn_time_ms\": 10241.734, \"total_train_time_s\": 12.059517621994019}", "{\"n\": 15604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.25, \"learn_time_ms\": 10180.031, \"total_train_time_s\": 11.79588794708252}", "{\"n\": 15605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.03, \"learn_time_ms\": 10183.931, \"total_train_time_s\": 11.804712533950806}", "{\"n\": 15606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 10260.64, \"total_train_time_s\": 12.65364694595337}", "{\"n\": 15607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 10200.518, \"total_train_time_s\": 11.818105220794678}", "{\"n\": 15608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.61, \"learn_time_ms\": 10167.214, \"total_train_time_s\": 11.92408013343811}", "{\"n\": 15609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.42, \"learn_time_ms\": 10135.524, \"total_train_time_s\": 11.619653224945068}", "{\"n\": 15610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.15, \"learn_time_ms\": 10347.327, \"total_train_time_s\": 13.785956382751465}", "{\"n\": 15611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.15, \"learn_time_ms\": 10375.911, \"total_train_time_s\": 12.161995887756348}", "{\"n\": 15612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.47, \"learn_time_ms\": 10167.836, \"total_train_time_s\": 11.306554555892944}", "{\"n\": 15613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.62, \"learn_time_ms\": 10127.694, \"total_train_time_s\": 11.673100709915161}", "{\"n\": 15614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.27, \"learn_time_ms\": 10292.144, \"total_train_time_s\": 13.416816234588623}", "{\"n\": 15615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.27, \"learn_time_ms\": 10324.343, \"total_train_time_s\": 12.135438680648804}", "{\"n\": 15616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.78, \"learn_time_ms\": 10265.957, \"total_train_time_s\": 12.053977251052856}", "{\"n\": 15617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.22, \"learn_time_ms\": 10197.45, \"total_train_time_s\": 11.164422988891602}", "{\"n\": 15618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.22, \"learn_time_ms\": 10245.049, \"total_train_time_s\": 12.387836694717407}", "{\"n\": 15619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.61, \"learn_time_ms\": 10331.503, \"total_train_time_s\": 12.452142715454102}", "{\"n\": 15620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.19, \"learn_time_ms\": 10119.532, \"total_train_time_s\": 11.682794332504272}", "{\"n\": 15621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.8, \"learn_time_ms\": 10131.03, \"total_train_time_s\": 12.241865396499634}", "{\"n\": 15622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.8, \"learn_time_ms\": 10212.618, \"total_train_time_s\": 12.069338083267212}", "{\"n\": 15623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.79, \"learn_time_ms\": 10256.305, \"total_train_time_s\": 12.160278797149658}", "{\"n\": 15624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.79, \"learn_time_ms\": 10086.099, \"total_train_time_s\": 11.65871810913086}", "{\"n\": 15625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10019.873, \"total_train_time_s\": 11.463273286819458}", "{\"n\": 15626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 10121.918, \"total_train_time_s\": 13.045732975006104}", "{\"n\": 15627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.83, \"learn_time_ms\": 10218.083, \"total_train_time_s\": 12.16596531867981}", "{\"n\": 15628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.83, \"learn_time_ms\": 10242.634, \"total_train_time_s\": 12.6578369140625}", "{\"n\": 15629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.5, \"learn_time_ms\": 10335.46, \"total_train_time_s\": 13.416536808013916}", "{\"n\": 15630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.5, \"learn_time_ms\": 10335.39, \"total_train_time_s\": 11.641960620880127}", "{\"n\": 15631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 10243.895, \"total_train_time_s\": 11.32520580291748}", "{\"n\": 15632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 10403.769, \"total_train_time_s\": 13.715865135192871}", "{\"n\": 15633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.88, \"learn_time_ms\": 10407.08, \"total_train_time_s\": 12.099594593048096}", "{\"n\": 15634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.29, \"learn_time_ms\": 10456.933, \"total_train_time_s\": 12.146559000015259}", "{\"n\": 15635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.05, \"learn_time_ms\": 10592.104, \"total_train_time_s\": 12.771319389343262}", "{\"n\": 15636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.05, \"learn_time_ms\": 10337.777, \"total_train_time_s\": 10.514731168746948}", "{\"n\": 15637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.01, \"learn_time_ms\": 10432.915, \"total_train_time_s\": 13.071953296661377}", "{\"n\": 15638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.66, \"learn_time_ms\": 10298.059, \"total_train_time_s\": 11.259925603866577}", "{\"n\": 15639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.8, \"learn_time_ms\": 10071.749, \"total_train_time_s\": 11.150812149047852}", "{\"n\": 15640, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.19, \"learn_time_ms\": 10260.319, \"total_train_time_s\": 13.563907384872437}", "{\"n\": 15641, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.19, \"learn_time_ms\": 10289.063, \"total_train_time_s\": 11.632564783096313}", "{\"n\": 15642, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.71, \"learn_time_ms\": 10089.231, \"total_train_time_s\": 11.72189450263977}", "{\"n\": 15643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.44, \"learn_time_ms\": 10017.951, \"total_train_time_s\": 11.397773504257202}", "{\"n\": 15644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.47, \"learn_time_ms\": 9984.092, \"total_train_time_s\": 11.863014459609985}", "{\"n\": 15645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.09, \"learn_time_ms\": 9836.135, \"total_train_time_s\": 11.342633247375488}", "{\"n\": 15646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.03, \"learn_time_ms\": 10001.272, \"total_train_time_s\": 12.173692464828491}", "{\"n\": 15647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.03, \"learn_time_ms\": 9889.076, \"total_train_time_s\": 11.982484579086304}", "{\"n\": 15648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3681.42, \"learn_time_ms\": 9976.815, \"total_train_time_s\": 12.156564712524414}", "{\"n\": 15649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3676.9, \"learn_time_ms\": 10165.023, \"total_train_time_s\": 13.028998851776123}", "{\"n\": 15650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3679.77, \"learn_time_ms\": 9963.284, \"total_train_time_s\": 11.584831476211548}", "{\"n\": 15651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3679.77, \"learn_time_ms\": 9987.46, \"total_train_time_s\": 11.86402153968811}", "{\"n\": 15652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.09, \"learn_time_ms\": 10034.017, \"total_train_time_s\": 12.173017263412476}", "{\"n\": 15653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.09, \"learn_time_ms\": 10172.463, \"total_train_time_s\": 12.848703622817993}", "{\"n\": 15654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.58, \"learn_time_ms\": 10188.379, \"total_train_time_s\": 12.014164686203003}", "{\"n\": 15655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3699.8, \"learn_time_ms\": 10256.379, \"total_train_time_s\": 12.05790638923645}", "{\"n\": 15656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3700.27, \"learn_time_ms\": 10147.536, \"total_train_time_s\": 11.079472303390503}", "{\"n\": 15657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3700.27, \"learn_time_ms\": 10184.702, \"total_train_time_s\": 12.336642742156982}", "{\"n\": 15658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3698.4, \"learn_time_ms\": 10068.067, \"total_train_time_s\": 10.98731517791748}", "{\"n\": 15659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3701.65, \"learn_time_ms\": 10074.694, \"total_train_time_s\": 13.068167448043823}", "{\"n\": 15660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3701.82, \"learn_time_ms\": 10239.929, \"total_train_time_s\": 13.22590708732605}", "{\"n\": 15661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3701.82, \"learn_time_ms\": 10301.849, \"total_train_time_s\": 12.470629215240479}", "{\"n\": 15662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3696.85, \"learn_time_ms\": 10308.915, \"total_train_time_s\": 12.279672145843506}", "{\"n\": 15663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3704.47, \"learn_time_ms\": 10270.526, \"total_train_time_s\": 12.418704986572266}", "{\"n\": 15664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3704.47, \"learn_time_ms\": 10223.652, \"total_train_time_s\": 11.52621603012085}", "{\"n\": 15665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3696.32, \"learn_time_ms\": 10174.675, \"total_train_time_s\": 11.517560958862305}", "{\"n\": 15666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3702.2, \"learn_time_ms\": 10339.08, \"total_train_time_s\": 12.717341661453247}", "{\"n\": 15667, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3703.9, \"learn_time_ms\": 10264.191, \"total_train_time_s\": 11.585142374038696}", "{\"n\": 15668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3703.9, \"learn_time_ms\": 10326.68, \"total_train_time_s\": 11.615320920944214}", "{\"n\": 15669, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.88, \"learn_time_ms\": 10090.265, \"total_train_time_s\": 10.741928100585938}", "{\"n\": 15670, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.88, \"learn_time_ms\": 9996.238, \"total_train_time_s\": 12.262968301773071}", "{\"n\": 15671, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3698.36, \"learn_time_ms\": 9929.035, \"total_train_time_s\": 11.799412965774536}", "{\"n\": 15672, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3698.08, \"learn_time_ms\": 9886.935, \"total_train_time_s\": 11.814568281173706}", "{\"n\": 15673, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.83, \"learn_time_ms\": 9955.361, \"total_train_time_s\": 13.09295392036438}", "{\"n\": 15674, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3688.11, \"learn_time_ms\": 10047.016, \"total_train_time_s\": 12.48312258720398}", "{\"n\": 15675, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3688.11, \"learn_time_ms\": 10213.443, \"total_train_time_s\": 13.225137948989868}", "{\"n\": 15676, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3680.75, \"learn_time_ms\": 10109.422, \"total_train_time_s\": 11.723482370376587}", "{\"n\": 15677, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3689.14, \"learn_time_ms\": 10254.075, \"total_train_time_s\": 13.062906742095947}", "{\"n\": 15678, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3688.05, \"learn_time_ms\": 10389.961, \"total_train_time_s\": 12.991180419921875}", "{\"n\": 15679, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3690.94, \"learn_time_ms\": 10573.639, \"total_train_time_s\": 12.589346647262573}", "{\"n\": 15680, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3698.73, \"learn_time_ms\": 10508.144, \"total_train_time_s\": 11.606690645217896}", "{\"n\": 15681, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3694.43, \"learn_time_ms\": 10558.234, \"total_train_time_s\": 12.26195764541626}", "{\"n\": 15682, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3694.43, \"learn_time_ms\": 10580.617, \"total_train_time_s\": 12.029854536056519}", "{\"n\": 15683, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3691.36, \"learn_time_ms\": 10502.923, \"total_train_time_s\": 12.31816577911377}", "{\"n\": 15684, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3683.81, \"learn_time_ms\": 10504.853, \"total_train_time_s\": 12.463681936264038}", "{\"n\": 15685, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3678.45, \"learn_time_ms\": 10437.889, \"total_train_time_s\": 12.510533809661865}", "{\"n\": 15686, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3679.76, \"learn_time_ms\": 10496.764, \"total_train_time_s\": 12.297519445419312}", "{\"n\": 15687, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3685.91, \"learn_time_ms\": 10303.045, \"total_train_time_s\": 11.107530117034912}", "{\"n\": 15688, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3688.42, \"learn_time_ms\": 10185.417, \"total_train_time_s\": 11.84099817276001}", "{\"n\": 15689, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 10178.385, \"total_train_time_s\": 12.464938879013062}", "{\"n\": 15690, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 10158.442, \"total_train_time_s\": 11.391239166259766}", "{\"n\": 15691, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3704.79, \"learn_time_ms\": 10242.827, \"total_train_time_s\": 13.132053136825562}", "{\"n\": 15692, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3701.95, \"learn_time_ms\": 10351.594, \"total_train_time_s\": 13.148058652877808}", "{\"n\": 15693, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3703.75, \"learn_time_ms\": 10238.271, \"total_train_time_s\": 11.219782829284668}", "{\"n\": 15694, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3703.75, \"learn_time_ms\": 10171.25, \"total_train_time_s\": 11.783148527145386}", "{\"n\": 15695, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3705.58, \"learn_time_ms\": 10102.368, \"total_train_time_s\": 11.82920527458191}", "{\"n\": 15696, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3709.89, \"learn_time_ms\": 9986.894, \"total_train_time_s\": 11.143740177154541}", "{\"n\": 15697, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3713.07, \"learn_time_ms\": 10036.984, \"total_train_time_s\": 11.606629848480225}", "{\"n\": 15698, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3717.95, \"learn_time_ms\": 10046.148, \"total_train_time_s\": 11.98304796218872}", "{\"n\": 15699, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3720.64, \"learn_time_ms\": 9925.302, \"total_train_time_s\": 11.257429122924805}", "{\"n\": 15700, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3720.64, \"learn_time_ms\": 9971.738, \"total_train_time_s\": 11.851752996444702}", "{\"n\": 15701, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3717.25, \"learn_time_ms\": 9940.525, \"total_train_time_s\": 12.866166114807129}", "{\"n\": 15702, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3717.25, \"learn_time_ms\": 9857.04, \"total_train_time_s\": 12.267060995101929}", "{\"n\": 15703, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3721.88, \"learn_time_ms\": 9869.201, \"total_train_time_s\": 11.312435388565063}", "{\"n\": 15704, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3729.53, \"learn_time_ms\": 9913.53, \"total_train_time_s\": 12.230350732803345}", "{\"n\": 15705, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3718.86, \"learn_time_ms\": 10095.35, \"total_train_time_s\": 13.660176515579224}", "{\"n\": 15706, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3711.31, \"learn_time_ms\": 10175.449, \"total_train_time_s\": 11.89819622039795}", "{\"n\": 15707, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3711.31, \"learn_time_ms\": 10265.434, \"total_train_time_s\": 12.467345714569092}", "{\"n\": 15708, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3721.13, \"learn_time_ms\": 10240.946, \"total_train_time_s\": 11.667685508728027}", "{\"n\": 15709, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3720.31, \"learn_time_ms\": 10243.856, \"total_train_time_s\": 11.269025325775146}", "{\"n\": 15710, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3717.45, \"learn_time_ms\": 10337.73, \"total_train_time_s\": 12.798900604248047}", "{\"n\": 15711, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3717.45, \"learn_time_ms\": 10249.533, \"total_train_time_s\": 11.940361261367798}", "{\"n\": 15712, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3716.36, \"learn_time_ms\": 10273.637, \"total_train_time_s\": 12.474130868911743}", "{\"n\": 15713, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3716.36, \"learn_time_ms\": 10315.838, \"total_train_time_s\": 11.707714080810547}", "{\"n\": 15714, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 10229.337, \"total_train_time_s\": 11.401626348495483}", "{\"n\": 15715, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.91, \"learn_time_ms\": 10050.765, \"total_train_time_s\": 11.879927158355713}", "{\"n\": 15716, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.56, \"learn_time_ms\": 9972.267, \"total_train_time_s\": 11.084727048873901}", "{\"n\": 15717, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.56, \"learn_time_ms\": 9922.487, \"total_train_time_s\": 11.974092483520508}", "{\"n\": 15718, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.73, \"learn_time_ms\": 10025.507, \"total_train_time_s\": 12.65545392036438}", "{\"n\": 15719, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3722.09, \"learn_time_ms\": 10078.04, \"total_train_time_s\": 11.867887496948242}", "{\"n\": 15720, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3726.5, \"learn_time_ms\": 9937.313, \"total_train_time_s\": 11.406289339065552}", "{\"n\": 15721, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3726.5, \"learn_time_ms\": 10006.67, \"total_train_time_s\": 12.659579038619995}", "{\"n\": 15722, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3726.87, \"learn_time_ms\": 10038.253, \"total_train_time_s\": 12.803708791732788}", "{\"n\": 15723, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3723.51, \"learn_time_ms\": 10127.839, \"total_train_time_s\": 12.601924896240234}", "{\"n\": 15724, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3731.36, \"learn_time_ms\": 10170.501, \"total_train_time_s\": 11.827723979949951}", "{\"n\": 15725, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3731.36, \"learn_time_ms\": 10370.948, \"total_train_time_s\": 13.87568187713623}", "{\"n\": 15726, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3720.75, \"learn_time_ms\": 10477.971, \"total_train_time_s\": 12.195963144302368}", "{\"n\": 15727, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3721.25, \"learn_time_ms\": 10488.574, \"total_train_time_s\": 12.143577337265015}", "{\"n\": 15728, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3721.43, \"learn_time_ms\": 10446.498, \"total_train_time_s\": 12.282864809036255}", "{\"n\": 15729, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3718.67, \"learn_time_ms\": 10494.521, \"total_train_time_s\": 12.292735576629639}", "{\"n\": 15730, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3715.82, \"learn_time_ms\": 10544.151, \"total_train_time_s\": 11.870946168899536}", "{\"n\": 15731, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3715.76, \"learn_time_ms\": 10393.461, \"total_train_time_s\": 11.143081665039062}", "{\"n\": 15732, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3708.79, \"learn_time_ms\": 10316.349, \"total_train_time_s\": 12.083137512207031}", "{\"n\": 15733, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3708.79, \"learn_time_ms\": 10217.272, \"total_train_time_s\": 11.609951257705688}", "{\"n\": 15734, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3710.57, \"learn_time_ms\": 10244.755, \"total_train_time_s\": 12.097980260848999}", "{\"n\": 15735, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3719.17, \"learn_time_ms\": 10068.804, \"total_train_time_s\": 12.098774433135986}", "{\"n\": 15736, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3725.02, \"learn_time_ms\": 10031.984, \"total_train_time_s\": 11.780573844909668}", "{\"n\": 15737, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3730.1, \"learn_time_ms\": 10014.24, \"total_train_time_s\": 11.92861533164978}", "{\"n\": 15738, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3727.76, \"learn_time_ms\": 9957.205, \"total_train_time_s\": 11.697864055633545}", "{\"n\": 15739, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3720.57, \"learn_time_ms\": 9909.988, \"total_train_time_s\": 11.981165647506714}", "{\"n\": 15740, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.82, \"learn_time_ms\": 9908.696, \"total_train_time_s\": 11.87177562713623}", "{\"n\": 15741, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.43, \"learn_time_ms\": 10028.296, \"total_train_time_s\": 12.344812154769897}", "{\"n\": 15742, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3725.86, \"learn_time_ms\": 10194.598, \"total_train_time_s\": 13.71155333518982}", "{\"n\": 15743, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.9, \"learn_time_ms\": 10231.549, \"total_train_time_s\": 11.970678091049194}", "{\"n\": 15744, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.9, \"learn_time_ms\": 10245.722, \"total_train_time_s\": 12.227848529815674}", "{\"n\": 15745, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.91, \"learn_time_ms\": 10246.645, \"total_train_time_s\": 12.121582508087158}", "{\"n\": 15746, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.65, \"learn_time_ms\": 10250.576, \"total_train_time_s\": 11.871158599853516}", "{\"n\": 15747, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.05, \"learn_time_ms\": 10301.64, \"total_train_time_s\": 12.457249402999878}", "{\"n\": 15748, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.49, \"learn_time_ms\": 10241.979, \"total_train_time_s\": 11.114431858062744}", "{\"n\": 15749, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.54, \"learn_time_ms\": 10158.005, \"total_train_time_s\": 10.984834671020508}", "{\"n\": 15750, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.19, \"learn_time_ms\": 10285.087, \"total_train_time_s\": 13.212947845458984}", "{\"n\": 15751, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.19, \"learn_time_ms\": 10280.562, \"total_train_time_s\": 12.374619960784912}", "{\"n\": 15752, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.53, \"learn_time_ms\": 10137.705, \"total_train_time_s\": 12.37020993232727}", "{\"n\": 15753, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.03, \"learn_time_ms\": 10067.894, \"total_train_time_s\": 11.323639869689941}", "{\"n\": 15754, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.01, \"learn_time_ms\": 9946.691, \"total_train_time_s\": 11.012842178344727}", "{\"n\": 15755, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.01, \"learn_time_ms\": 9921.795, \"total_train_time_s\": 11.87069582939148}", "{\"n\": 15756, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3703.0, \"learn_time_ms\": 9906.648, \"total_train_time_s\": 11.72818899154663}", "{\"n\": 15757, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.55, \"learn_time_ms\": 9819.784, \"total_train_time_s\": 11.584808826446533}", "{\"n\": 15758, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.59, \"learn_time_ms\": 9788.764, \"total_train_time_s\": 10.751958131790161}", "{\"n\": 15759, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.64, \"learn_time_ms\": 9898.7, \"total_train_time_s\": 12.084790468215942}", "{\"n\": 15760, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.41, \"learn_time_ms\": 9878.45, \"total_train_time_s\": 12.993656158447266}", "{\"n\": 15761, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.41, \"learn_time_ms\": 9868.216, \"total_train_time_s\": 12.22928261756897}", "{\"n\": 15762, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.1, \"learn_time_ms\": 9935.08, \"total_train_time_s\": 12.994033098220825}", "{\"n\": 15763, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.47, \"learn_time_ms\": 9963.179, \"total_train_time_s\": 11.533635139465332}", "{\"n\": 15764, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3715.85, \"learn_time_ms\": 10154.229, \"total_train_time_s\": 12.94911241531372}", "{\"n\": 15765, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.46, \"learn_time_ms\": 10120.328, \"total_train_time_s\": 11.5075101852417}", "{\"n\": 15766, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.27, \"learn_time_ms\": 10134.628, \"total_train_time_s\": 11.845827341079712}", "{\"n\": 15767, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.24, \"learn_time_ms\": 10059.663, \"total_train_time_s\": 10.795253038406372}", "{\"n\": 15768, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3746.68, \"learn_time_ms\": 10198.106, \"total_train_time_s\": 12.187969207763672}", "{\"n\": 15769, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3746.68, \"learn_time_ms\": 10238.067, \"total_train_time_s\": 12.479515075683594}", "{\"n\": 15770, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3750.32, \"learn_time_ms\": 10211.986, \"total_train_time_s\": 12.685426950454712}", "{\"n\": 15771, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3753.59, \"learn_time_ms\": 10109.045, \"total_train_time_s\": 11.186650276184082}", "{\"n\": 15772, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3749.25, \"learn_time_ms\": 9952.118, \"total_train_time_s\": 11.39293646812439}", "{\"n\": 15773, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3749.25, \"learn_time_ms\": 10095.14, \"total_train_time_s\": 13.041951179504395}", "{\"n\": 15774, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3742.83, \"learn_time_ms\": 10025.413, \"total_train_time_s\": 12.29386568069458}", "{\"n\": 15775, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3742.83, \"learn_time_ms\": 10156.919, \"total_train_time_s\": 12.848397254943848}", "{\"n\": 15776, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3744.01, \"learn_time_ms\": 10143.448, \"total_train_time_s\": 11.698101282119751}", "{\"n\": 15777, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3750.3, \"learn_time_ms\": 10338.951, \"total_train_time_s\": 12.76933240890503}", "{\"n\": 15778, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3746.94, \"learn_time_ms\": 10330.48, \"total_train_time_s\": 12.147148609161377}", "{\"n\": 15779, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3746.94, \"learn_time_ms\": 10178.719, \"total_train_time_s\": 11.02125334739685}", "{\"n\": 15780, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3747.77, \"learn_time_ms\": 10008.426, \"total_train_time_s\": 10.982388257980347}", "{\"n\": 15781, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3744.91, \"learn_time_ms\": 10072.746, \"total_train_time_s\": 11.752517938613892}", "{\"n\": 15782, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 9939.657, \"total_train_time_s\": 10.045506477355957}", "{\"n\": 15783, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 9840.51, \"total_train_time_s\": 12.020148277282715}", "{\"n\": 15784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3734.55, \"learn_time_ms\": 9840.352, \"total_train_time_s\": 12.24958848953247}", "{\"n\": 15785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3734.75, \"learn_time_ms\": 9816.775, \"total_train_time_s\": 12.611270427703857}", "{\"n\": 15786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3734.75, \"learn_time_ms\": 9964.576, \"total_train_time_s\": 13.18256139755249}", "{\"n\": 15787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3729.49, \"learn_time_ms\": 9969.512, \"total_train_time_s\": 12.833791017532349}", "{\"n\": 15788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3722.59, \"learn_time_ms\": 9947.04, \"total_train_time_s\": 11.885687828063965}", "{\"n\": 15789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.6, \"learn_time_ms\": 9959.832, \"total_train_time_s\": 11.18921446800232}", "{\"n\": 15790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.15, \"learn_time_ms\": 10118.471, \"total_train_time_s\": 12.524150133132935}", "{\"n\": 15791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.06, \"learn_time_ms\": 10177.108, \"total_train_time_s\": 12.412524700164795}", "{\"n\": 15792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.92, \"learn_time_ms\": 10312.112, \"total_train_time_s\": 11.440748691558838}", "{\"n\": 15793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.08, \"learn_time_ms\": 10300.329, \"total_train_time_s\": 11.892916679382324}", "{\"n\": 15794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.08, \"learn_time_ms\": 10298.996, \"total_train_time_s\": 12.218321561813354}", "{\"n\": 15795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.57, \"learn_time_ms\": 10273.065, \"total_train_time_s\": 12.382222890853882}", "{\"n\": 15796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.72, \"learn_time_ms\": 10086.758, \"total_train_time_s\": 11.366997003555298}", "{\"n\": 15797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.39, \"learn_time_ms\": 10016.67, \"total_train_time_s\": 12.121927738189697}", "{\"n\": 15798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.39, \"learn_time_ms\": 10107.135, \"total_train_time_s\": 12.726048469543457}", "{\"n\": 15799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.2, \"learn_time_ms\": 10248.301, \"total_train_time_s\": 12.521312952041626}", "{\"n\": 15800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.2, \"learn_time_ms\": 10260.305, \"total_train_time_s\": 12.692426443099976}", "{\"n\": 15801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.7, \"learn_time_ms\": 10307.437, \"total_train_time_s\": 12.888527393341064}", "{\"n\": 15802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.27, \"learn_time_ms\": 10299.783, \"total_train_time_s\": 11.379707098007202}", "{\"n\": 15803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.51, \"learn_time_ms\": 10544.97, \"total_train_time_s\": 14.390600442886353}", "{\"n\": 15804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.19, \"learn_time_ms\": 10502.38, \"total_train_time_s\": 11.816515445709229}", "{\"n\": 15805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.69, \"learn_time_ms\": 10515.484, \"total_train_time_s\": 12.503485918045044}", "{\"n\": 15806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.78, \"learn_time_ms\": 10616.37, \"total_train_time_s\": 12.369506120681763}", "{\"n\": 15807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.55, \"learn_time_ms\": 10617.246, \"total_train_time_s\": 12.097724914550781}", "{\"n\": 15808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.55, \"learn_time_ms\": 10465.229, \"total_train_time_s\": 11.254819869995117}", "{\"n\": 15809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.2, \"learn_time_ms\": 10481.936, \"total_train_time_s\": 12.66690707206726}", "{\"n\": 15810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.47, \"learn_time_ms\": 10439.004, \"total_train_time_s\": 12.281099081039429}", "{\"n\": 15811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3654.2, \"learn_time_ms\": 10314.722, \"total_train_time_s\": 11.59649109840393}", "{\"n\": 15812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3654.2, \"learn_time_ms\": 10235.937, \"total_train_time_s\": 10.552844285964966}", "{\"n\": 15813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.15, \"learn_time_ms\": 9975.359, \"total_train_time_s\": 11.779460191726685}", "{\"n\": 15814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3653.65, \"learn_time_ms\": 10033.544, \"total_train_time_s\": 12.373689651489258}", "{\"n\": 15815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3653.06, \"learn_time_ms\": 9879.356, \"total_train_time_s\": 10.97595739364624}", "{\"n\": 15816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3649.35, \"learn_time_ms\": 9728.562, \"total_train_time_s\": 10.86794638633728}", "{\"n\": 15817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3652.37, \"learn_time_ms\": 9775.947, \"total_train_time_s\": 12.61982774734497}", "{\"n\": 15818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.78, \"learn_time_ms\": 10040.204, \"total_train_time_s\": 13.900737524032593}", "{\"n\": 15819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.78, \"learn_time_ms\": 9973.434, \"total_train_time_s\": 12.011600494384766}", "{\"n\": 15820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3648.79, \"learn_time_ms\": 10074.608, \"total_train_time_s\": 13.2617506980896}", "{\"n\": 15821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 10123.926, \"total_train_time_s\": 12.125600814819336}", "{\"n\": 15822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 10327.94, \"total_train_time_s\": 12.554892301559448}", "{\"n\": 15823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.56, \"learn_time_ms\": 10317.352, \"total_train_time_s\": 11.65487551689148}", "{\"n\": 15824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3634.55, \"learn_time_ms\": 10281.595, \"total_train_time_s\": 12.035613298416138}", "{\"n\": 15825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3625.19, \"learn_time_ms\": 10369.092, \"total_train_time_s\": 11.832558870315552}", "{\"n\": 15826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3621.81, \"learn_time_ms\": 10478.101, \"total_train_time_s\": 11.929258346557617}", "{\"n\": 15827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.28, \"learn_time_ms\": 10323.056, \"total_train_time_s\": 11.11153531074524}", "{\"n\": 15828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.37, \"learn_time_ms\": 10127.061, \"total_train_time_s\": 11.952311277389526}", "{\"n\": 15829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.08, \"learn_time_ms\": 10127.022, \"total_train_time_s\": 12.026786088943481}", "{\"n\": 15830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.08, \"learn_time_ms\": 10143.714, \"total_train_time_s\": 13.42477536201477}", "{\"n\": 15831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 10083.28, \"total_train_time_s\": 11.47467565536499}", "{\"n\": 15832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 10044.588, \"total_train_time_s\": 12.188382625579834}", "{\"n\": 15833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.11, \"learn_time_ms\": 10141.885, \"total_train_time_s\": 12.600480079650879}", "{\"n\": 15834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.11, \"learn_time_ms\": 10199.434, \"total_train_time_s\": 12.584668159484863}", "{\"n\": 15835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.06, \"learn_time_ms\": 10262.308, \"total_train_time_s\": 12.468635559082031}", "{\"n\": 15836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.01, \"learn_time_ms\": 10187.409, \"total_train_time_s\": 11.202661752700806}", "{\"n\": 15837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.54, \"learn_time_ms\": 10186.976, \"total_train_time_s\": 11.064854860305786}", "{\"n\": 15838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3645.48, \"learn_time_ms\": 10225.475, \"total_train_time_s\": 12.363734245300293}", "{\"n\": 15839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.91, \"learn_time_ms\": 10228.388, \"total_train_time_s\": 12.060685396194458}", "{\"n\": 15840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3651.91, \"learn_time_ms\": 10191.655, \"total_train_time_s\": 13.077262878417969}", "{\"n\": 15841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.28, \"learn_time_ms\": 10254.146, \"total_train_time_s\": 12.14124846458435}", "{\"n\": 15842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3652.02, \"learn_time_ms\": 10268.847, \"total_train_time_s\": 12.347567558288574}", "{\"n\": 15843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.44, \"learn_time_ms\": 10249.253, \"total_train_time_s\": 12.453359365463257}", "{\"n\": 15844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3665.43, \"learn_time_ms\": 10236.299, \"total_train_time_s\": 12.499612092971802}", "{\"n\": 15845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3670.88, \"learn_time_ms\": 10184.858, \"total_train_time_s\": 11.93165922164917}", "{\"n\": 15846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3668.34, \"learn_time_ms\": 10184.645, \"total_train_time_s\": 11.199306011199951}", "{\"n\": 15847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3672.27, \"learn_time_ms\": 10319.24, \"total_train_time_s\": 12.348347663879395}", "{\"n\": 15848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.28, \"learn_time_ms\": 10306.805, \"total_train_time_s\": 12.226874589920044}", "{\"n\": 15849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3673.49, \"learn_time_ms\": 10234.786, \"total_train_time_s\": 11.321730852127075}", "{\"n\": 15850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3666.86, \"learn_time_ms\": 10085.712, \"total_train_time_s\": 11.603870153427124}", "{\"n\": 15851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3666.11, \"learn_time_ms\": 10086.623, \"total_train_time_s\": 12.154438495635986}", "{\"n\": 15852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3662.47, \"learn_time_ms\": 10069.491, \"total_train_time_s\": 12.193728685379028}", "{\"n\": 15853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3664.2, \"learn_time_ms\": 9962.09, \"total_train_time_s\": 11.338681936264038}", "{\"n\": 15854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3666.4, \"learn_time_ms\": 9920.732, \"total_train_time_s\": 12.03272557258606}", "{\"n\": 15855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3666.4, \"learn_time_ms\": 9988.172, \"total_train_time_s\": 12.645481586456299}", "{\"n\": 15856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3661.41, \"learn_time_ms\": 10116.077, \"total_train_time_s\": 12.454077959060669}", "{\"n\": 15857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3656.77, \"learn_time_ms\": 10012.199, \"total_train_time_s\": 11.329902172088623}", "{\"n\": 15858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3646.81, \"learn_time_ms\": 9952.981, \"total_train_time_s\": 11.59630274772644}", "{\"n\": 15859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3639.86, \"learn_time_ms\": 10065.804, \"total_train_time_s\": 12.475499868392944}", "{\"n\": 15860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3639.86, \"learn_time_ms\": 10153.108, \"total_train_time_s\": 12.480156183242798}", "{\"n\": 15861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3633.56, \"learn_time_ms\": 10212.401, \"total_train_time_s\": 12.737943410873413}", "{\"n\": 15862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3635.94, \"learn_time_ms\": 10105.339, \"total_train_time_s\": 11.146062850952148}", "{\"n\": 15863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3636.58, \"learn_time_ms\": 10115.728, \"total_train_time_s\": 11.452323913574219}", "{\"n\": 15864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3636.58, \"learn_time_ms\": 10155.679, \"total_train_time_s\": 12.430170774459839}", "{\"n\": 15865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3635.99, \"learn_time_ms\": 10062.097, \"total_train_time_s\": 11.676860094070435}", "{\"n\": 15866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3634.35, \"learn_time_ms\": 10024.705, \"total_train_time_s\": 12.094647407531738}", "{\"n\": 15867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3634.35, \"learn_time_ms\": 10091.068, \"total_train_time_s\": 12.014156818389893}", "{\"n\": 15868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3638.39, \"learn_time_ms\": 10119.645, \"total_train_time_s\": 11.872344970703125}", "{\"n\": 15869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3637.73, \"learn_time_ms\": 10071.264, \"total_train_time_s\": 11.974877834320068}", "{\"n\": 15870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3630.82, \"learn_time_ms\": 10029.257, \"total_train_time_s\": 12.04447317123413}", "{\"n\": 15871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3630.82, \"learn_time_ms\": 10050.539, \"total_train_time_s\": 12.922911167144775}", "{\"n\": 15872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3629.49, \"learn_time_ms\": 10182.539, \"total_train_time_s\": 12.435230731964111}", "{\"n\": 15873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.71, \"learn_time_ms\": 10222.854, \"total_train_time_s\": 11.89277172088623}", "{\"n\": 15874, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.88, \"learn_time_ms\": 10032.217, \"total_train_time_s\": 10.523861646652222}", "{\"n\": 15875, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.88, \"learn_time_ms\": 10212.266, \"total_train_time_s\": 13.474385499954224}", "{\"n\": 15876, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.72, \"learn_time_ms\": 10383.573, \"total_train_time_s\": 13.867684602737427}", "{\"n\": 15877, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.45, \"learn_time_ms\": 10372.967, \"total_train_time_s\": 11.967835664749146}", "{\"n\": 15878, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.45, \"learn_time_ms\": 10371.432, \"total_train_time_s\": 11.91302490234375}", "{\"n\": 15879, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.37, \"learn_time_ms\": 10301.335, \"total_train_time_s\": 11.241256952285767}", "{\"n\": 15880, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.36, \"learn_time_ms\": 10331.341, \"total_train_time_s\": 12.296683311462402}", "{\"n\": 15881, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.25, \"learn_time_ms\": 10175.959, \"total_train_time_s\": 11.403772115707397}", "{\"n\": 15882, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.25, \"learn_time_ms\": 10150.828, \"total_train_time_s\": 12.159924268722534}", "{\"n\": 15883, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.69, \"learn_time_ms\": 10162.095, \"total_train_time_s\": 11.982146978378296}", "{\"n\": 15884, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.14, \"learn_time_ms\": 10348.978, \"total_train_time_s\": 12.46727991104126}", "{\"n\": 15885, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.89, \"learn_time_ms\": 10320.697, \"total_train_time_s\": 13.2218017578125}", "{\"n\": 15886, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.65, \"learn_time_ms\": 10123.918, \"total_train_time_s\": 11.81394338607788}", "{\"n\": 15887, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.29, \"learn_time_ms\": 10046.558, \"total_train_time_s\": 11.150918960571289}", "{\"n\": 15888, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.48, \"learn_time_ms\": 9980.531, \"total_train_time_s\": 11.224018096923828}", "{\"n\": 15889, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.48, \"learn_time_ms\": 9973.28, \"total_train_time_s\": 11.160799980163574}", "{\"n\": 15890, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.26, \"learn_time_ms\": 9944.658, \"total_train_time_s\": 12.024207592010498}", "{\"n\": 15891, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.18, \"learn_time_ms\": 10012.362, \"total_train_time_s\": 12.070051670074463}", "{\"n\": 15892, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.89, \"learn_time_ms\": 9985.598, \"total_train_time_s\": 11.876659631729126}", "{\"n\": 15893, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.07, \"learn_time_ms\": 10090.827, \"total_train_time_s\": 13.01787519454956}", "{\"n\": 15894, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.07, \"learn_time_ms\": 10086.101, \"total_train_time_s\": 12.367127895355225}", "{\"n\": 15895, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.29, \"learn_time_ms\": 10054.396, \"total_train_time_s\": 12.910689115524292}", "{\"n\": 15896, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 9967.846, \"total_train_time_s\": 10.947882175445557}", "{\"n\": 15897, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10153.05, \"total_train_time_s\": 12.982885122299194}", "{\"n\": 15898, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.02, \"learn_time_ms\": 10227.496, \"total_train_time_s\": 12.010526657104492}", "{\"n\": 15899, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.3, \"learn_time_ms\": 10295.838, \"total_train_time_s\": 11.87307858467102}", "{\"n\": 15900, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.3, \"learn_time_ms\": 10315.283, \"total_train_time_s\": 12.253013134002686}", "{\"n\": 15901, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.84, \"learn_time_ms\": 10370.424, \"total_train_time_s\": 12.68113923072815}", "{\"n\": 15902, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.79, \"learn_time_ms\": 10393.135, \"total_train_time_s\": 12.177783489227295}", "{\"n\": 15903, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.35, \"learn_time_ms\": 10364.189, \"total_train_time_s\": 12.717938899993896}", "{\"n\": 15904, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3648.19, \"learn_time_ms\": 10334.06, \"total_train_time_s\": 12.070241689682007}", "{\"n\": 15905, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.74, \"learn_time_ms\": 10245.961, \"total_train_time_s\": 11.982940196990967}", "{\"n\": 15906, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.53, \"learn_time_ms\": 10435.672, \"total_train_time_s\": 12.829086542129517}", "{\"n\": 15907, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.78, \"learn_time_ms\": 10374.276, \"total_train_time_s\": 12.388867139816284}", "{\"n\": 15908, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.78, \"learn_time_ms\": 10453.647, \"total_train_time_s\": 12.788943529129028}", "{\"n\": 15909, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.17, \"learn_time_ms\": 10428.357, \"total_train_time_s\": 11.626364946365356}", "{\"n\": 15910, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.82, \"learn_time_ms\": 10353.112, \"total_train_time_s\": 11.489823341369629}", "{\"n\": 15911, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10400.038, \"total_train_time_s\": 13.088279008865356}", "{\"n\": 15912, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.63, \"learn_time_ms\": 10411.71, \"total_train_time_s\": 12.23331093788147}", "{\"n\": 15913, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.83, \"learn_time_ms\": 10310.36, \"total_train_time_s\": 11.712054967880249}", "{\"n\": 15914, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.78, \"learn_time_ms\": 10288.186, \"total_train_time_s\": 11.893123149871826}", "{\"n\": 15915, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.78, \"learn_time_ms\": 10297.49, \"total_train_time_s\": 12.08462905883789}", "{\"n\": 15916, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.85, \"learn_time_ms\": 10131.232, \"total_train_time_s\": 11.183372497558594}", "{\"n\": 15917, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3666.88, \"learn_time_ms\": 10136.366, \"total_train_time_s\": 12.395374774932861}", "{\"n\": 15918, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 10123.663, \"total_train_time_s\": 12.659893989562988}", "{\"n\": 15919, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.93, \"learn_time_ms\": 10188.48, \"total_train_time_s\": 12.237863779067993}", "{\"n\": 15920, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.65, \"learn_time_ms\": 10222.986, \"total_train_time_s\": 11.798648834228516}", "{\"n\": 15921, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.65, \"learn_time_ms\": 10156.553, \"total_train_time_s\": 12.428394317626953}", "{\"n\": 15922, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.38, \"learn_time_ms\": 9992.21, \"total_train_time_s\": 10.59209942817688}", "{\"n\": 15923, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.21, \"learn_time_ms\": 10153.512, \"total_train_time_s\": 13.321027040481567}", "{\"n\": 15924, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.61, \"learn_time_ms\": 10212.124, \"total_train_time_s\": 12.39796495437622}", "{\"n\": 15925, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.18, \"learn_time_ms\": 10059.164, \"total_train_time_s\": 10.556273698806763}", "{\"n\": 15926, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.85, \"learn_time_ms\": 10272.944, \"total_train_time_s\": 13.336369276046753}", "{\"n\": 15927, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.71, \"learn_time_ms\": 10315.615, \"total_train_time_s\": 12.83210825920105}", "{\"n\": 15928, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.71, \"learn_time_ms\": 10227.08, \"total_train_time_s\": 11.729555130004883}", "{\"n\": 15929, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.18, \"learn_time_ms\": 10187.822, \"total_train_time_s\": 11.87203049659729}", "{\"n\": 15930, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.18, \"learn_time_ms\": 10150.604, \"total_train_time_s\": 11.484678745269775}", "{\"n\": 15931, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.98, \"learn_time_ms\": 10034.92, \"total_train_time_s\": 11.307701110839844}", "{\"n\": 15932, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.98, \"learn_time_ms\": 10119.026, \"total_train_time_s\": 11.435277938842773}", "{\"n\": 15933, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.34, \"learn_time_ms\": 10051.542, \"total_train_time_s\": 12.655412197113037}", "{\"n\": 15934, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.16, \"learn_time_ms\": 10106.322, \"total_train_time_s\": 12.935003757476807}", "{\"n\": 15935, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.51, \"learn_time_ms\": 10343.494, \"total_train_time_s\": 12.909743309020996}", "{\"n\": 15936, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.23, \"learn_time_ms\": 10200.322, \"total_train_time_s\": 11.933679103851318}", "{\"n\": 15937, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.07, \"learn_time_ms\": 10048.827, \"total_train_time_s\": 11.312899112701416}", "{\"n\": 15938, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.82, \"learn_time_ms\": 10044.731, \"total_train_time_s\": 11.660921096801758}", "{\"n\": 15939, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 10071.301, \"total_train_time_s\": 12.13422179222107}", "{\"n\": 15940, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 10062.927, \"total_train_time_s\": 11.37372875213623}", "{\"n\": 15941, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.64, \"learn_time_ms\": 10131.787, \"total_train_time_s\": 11.973334312438965}", "{\"n\": 15942, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3603.14, \"learn_time_ms\": 10047.349, \"total_train_time_s\": 10.59218978881836}", "{\"n\": 15943, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.49, \"learn_time_ms\": 10006.278, \"total_train_time_s\": 12.216119289398193}", "{\"n\": 15944, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.49, \"learn_time_ms\": 9975.886, \"total_train_time_s\": 12.679982662200928}", "{\"n\": 15945, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.96, \"learn_time_ms\": 9998.077, \"total_train_time_s\": 13.193803310394287}", "{\"n\": 15946, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 9968.488, \"total_train_time_s\": 11.606608390808105}", "{\"n\": 15947, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 9956.428, \"total_train_time_s\": 11.221364974975586}", "{\"n\": 15948, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.76, \"learn_time_ms\": 9960.426, \"total_train_time_s\": 11.76593279838562}", "{\"n\": 15949, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.37, \"learn_time_ms\": 9935.417, \"total_train_time_s\": 11.930273294448853}", "{\"n\": 15950, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.95, \"learn_time_ms\": 9932.577, \"total_train_time_s\": 11.343228101730347}", "{\"n\": 15951, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.95, \"learn_time_ms\": 9865.368, \"total_train_time_s\": 11.285572290420532}", "{\"n\": 15952, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3602.89, \"learn_time_ms\": 9988.501, \"total_train_time_s\": 11.81397557258606}", "{\"n\": 15953, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3596.95, \"learn_time_ms\": 9969.721, \"total_train_time_s\": 12.058436155319214}", "{\"n\": 15954, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.0, \"learn_time_ms\": 9848.82, \"total_train_time_s\": 11.46835470199585}", "{\"n\": 15955, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 9803.593, \"total_train_time_s\": 12.716580390930176}", "{\"n\": 15956, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 10010.603, \"total_train_time_s\": 13.68952989578247}", "{\"n\": 15957, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3590.24, \"learn_time_ms\": 10127.579, \"total_train_time_s\": 12.40748405456543}", "{\"n\": 15958, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3590.24, \"learn_time_ms\": 10144.747, \"total_train_time_s\": 11.922620058059692}", "{\"n\": 15959, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.13, \"learn_time_ms\": 10214.055, \"total_train_time_s\": 12.61029601097107}", "{\"n\": 15960, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.45, \"learn_time_ms\": 10272.229, \"total_train_time_s\": 11.938262939453125}", "{\"n\": 15961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3589.09, \"learn_time_ms\": 10391.904, \"total_train_time_s\": 12.501413106918335}", "{\"n\": 15962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.3, \"learn_time_ms\": 10394.332, \"total_train_time_s\": 11.874354124069214}", "{\"n\": 15963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.1, \"learn_time_ms\": 10281.228, \"total_train_time_s\": 10.884807586669922}", "{\"n\": 15964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.18, \"learn_time_ms\": 10247.727, \"total_train_time_s\": 11.12723684310913}", "{\"n\": 15965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.84, \"learn_time_ms\": 10148.371, \"total_train_time_s\": 11.755042314529419}", "{\"n\": 15966, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.84, \"learn_time_ms\": 10010.682, \"total_train_time_s\": 12.297942399978638}", "{\"n\": 15967, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.17, \"learn_time_ms\": 10030.444, \"total_train_time_s\": 12.586398124694824}", "{\"n\": 15968, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.24, \"learn_time_ms\": 10072.752, \"total_train_time_s\": 12.339063882827759}", "{\"n\": 15969, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.83, \"learn_time_ms\": 9949.156, \"total_train_time_s\": 11.369499206542969}", "{\"n\": 15970, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.69, \"learn_time_ms\": 9883.695, \"total_train_time_s\": 11.31258225440979}", "{\"n\": 15971, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.45, \"learn_time_ms\": 9951.219, \"total_train_time_s\": 13.149210453033447}", "{\"n\": 15972, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.84, \"learn_time_ms\": 9994.782, \"total_train_time_s\": 12.25001049041748}", "{\"n\": 15973, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.84, \"learn_time_ms\": 10057.944, \"total_train_time_s\": 11.53111457824707}", "{\"n\": 15974, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.37, \"learn_time_ms\": 10036.464, \"total_train_time_s\": 10.90255856513977}", "{\"n\": 15975, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.01, \"learn_time_ms\": 10027.972, \"total_train_time_s\": 11.620648384094238}", "{\"n\": 15976, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 9968.055, \"total_train_time_s\": 11.660181045532227}", "{\"n\": 15977, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 9948.992, \"total_train_time_s\": 12.356293678283691}", "{\"n\": 15978, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.04, \"learn_time_ms\": 9989.822, \"total_train_time_s\": 12.740722179412842}", "{\"n\": 15979, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.71, \"learn_time_ms\": 9995.873, \"total_train_time_s\": 11.389946222305298}", "{\"n\": 15980, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.71, \"learn_time_ms\": 10182.346, \"total_train_time_s\": 13.093520402908325}", "{\"n\": 15981, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.71, \"learn_time_ms\": 10034.431, \"total_train_time_s\": 11.686396837234497}", "{\"n\": 15982, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.79, \"learn_time_ms\": 9938.639, \"total_train_time_s\": 11.386614561080933}", "{\"n\": 15983, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.12, \"learn_time_ms\": 10062.416, \"total_train_time_s\": 12.751341819763184}", "{\"n\": 15984, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.12, \"learn_time_ms\": 10172.873, \"total_train_time_s\": 12.052818536758423}", "{\"n\": 15985, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.12, \"learn_time_ms\": 10226.637, \"total_train_time_s\": 12.179872989654541}", "{\"n\": 15986, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.05, \"learn_time_ms\": 10237.825, \"total_train_time_s\": 11.84131646156311}", "{\"n\": 15987, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 10123.975, \"total_train_time_s\": 11.265705585479736}", "{\"n\": 15988, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 10062.162, \"total_train_time_s\": 12.11068058013916}", "{\"n\": 15989, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.63, \"learn_time_ms\": 10111.437, \"total_train_time_s\": 11.885714292526245}", "{\"n\": 15990, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.22, \"learn_time_ms\": 9941.239, \"total_train_time_s\": 11.497984647750854}", "{\"n\": 15991, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3629.87, \"learn_time_ms\": 9953.021, \"total_train_time_s\": 11.79319429397583}", "{\"n\": 15992, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.76, \"learn_time_ms\": 9962.448, \"total_train_time_s\": 11.440831661224365}", "{\"n\": 15993, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3624.55, \"learn_time_ms\": 9897.436, \"total_train_time_s\": 12.170801162719727}", "{\"n\": 15994, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.83, \"learn_time_ms\": 9895.251, \"total_train_time_s\": 11.997591018676758}", "{\"n\": 15995, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.83, \"learn_time_ms\": 9839.423, \"total_train_time_s\": 11.606362104415894}", "{\"n\": 15996, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.19, \"learn_time_ms\": 9850.083, \"total_train_time_s\": 11.89676284790039}", "{\"n\": 15997, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.25, \"learn_time_ms\": 10040.967, \"total_train_time_s\": 13.154144525527954}", "{\"n\": 15998, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.35, \"learn_time_ms\": 10010.672, \"total_train_time_s\": 11.792086601257324}", "{\"n\": 15999, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.56, \"learn_time_ms\": 10064.424, \"total_train_time_s\": 12.45340871810913}", "{\"n\": 16000, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.43, \"learn_time_ms\": 10135.324, \"total_train_time_s\": 12.164879322052002}", "{\"n\": 16001, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.64, \"learn_time_ms\": 10108.143, \"total_train_time_s\": 11.546231746673584}", "{\"n\": 16002, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.13, \"learn_time_ms\": 10125.201, \"total_train_time_s\": 11.62191390991211}", "{\"n\": 16003, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.05, \"learn_time_ms\": 10053.044, \"total_train_time_s\": 11.438570737838745}", "{\"n\": 16004, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.47, \"learn_time_ms\": 10106.27, \"total_train_time_s\": 12.517404794692993}", "{\"n\": 16005, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.09, \"learn_time_ms\": 10146.942, \"total_train_time_s\": 11.99079442024231}", "{\"n\": 16006, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.09, \"learn_time_ms\": 10155.586, \"total_train_time_s\": 12.015845775604248}", "{\"n\": 16007, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.79, \"learn_time_ms\": 9977.245, \"total_train_time_s\": 11.396899938583374}", "{\"n\": 16008, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.5, \"learn_time_ms\": 10064.159, \"total_train_time_s\": 12.71357274055481}", "{\"n\": 16009, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.34, \"learn_time_ms\": 9963.082, \"total_train_time_s\": 11.459012269973755}", "{\"n\": 16010, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.77, \"learn_time_ms\": 9924.835, \"total_train_time_s\": 11.76201605796814}", "{\"n\": 16011, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.77, \"learn_time_ms\": 9961.798, \"total_train_time_s\": 11.910504817962646}", "{\"n\": 16012, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.63, \"learn_time_ms\": 10059.085, \"total_train_time_s\": 12.603673458099365}", "{\"n\": 16013, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.63, \"learn_time_ms\": 10093.773, \"total_train_time_s\": 11.71384882926941}", "{\"n\": 16014, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.91, \"learn_time_ms\": 10019.657, \"total_train_time_s\": 11.796992540359497}", "{\"n\": 16015, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.08, \"learn_time_ms\": 10123.544, \"total_train_time_s\": 13.056203365325928}", "{\"n\": 16016, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.35, \"learn_time_ms\": 10134.418, \"total_train_time_s\": 12.101026058197021}", "{\"n\": 16017, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.35, \"learn_time_ms\": 10247.292, \"total_train_time_s\": 12.483906984329224}", "{\"n\": 16018, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.22, \"learn_time_ms\": 10199.427, \"total_train_time_s\": 12.186546564102173}", "{\"n\": 16019, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.22, \"learn_time_ms\": 10231.738, \"total_train_time_s\": 11.758112668991089}", "{\"n\": 16020, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.26, \"learn_time_ms\": 10283.241, \"total_train_time_s\": 12.282723188400269}", "{\"n\": 16021, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.07, \"learn_time_ms\": 10254.974, \"total_train_time_s\": 11.639781475067139}", "{\"n\": 16022, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.39, \"learn_time_ms\": 10194.324, \"total_train_time_s\": 11.946280241012573}", "{\"n\": 16023, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.39, \"learn_time_ms\": 10217.939, \"total_train_time_s\": 11.993753433227539}", "{\"n\": 16024, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.45, \"learn_time_ms\": 10229.35, \"total_train_time_s\": 11.89246392250061}", "{\"n\": 16025, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.42, \"learn_time_ms\": 10047.807, \"total_train_time_s\": 11.28850793838501}", "{\"n\": 16026, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.88, \"learn_time_ms\": 10000.666, \"total_train_time_s\": 11.685405731201172}", "{\"n\": 16027, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.88, \"learn_time_ms\": 9888.468, \"total_train_time_s\": 11.394624710083008}", "{\"n\": 16028, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.9, \"learn_time_ms\": 9864.45, \"total_train_time_s\": 11.994751453399658}", "{\"n\": 16029, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.9, \"learn_time_ms\": 9868.911, \"total_train_time_s\": 11.816209316253662}", "{\"n\": 16030, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.44, \"learn_time_ms\": 9750.046, \"total_train_time_s\": 11.066700458526611}", "{\"n\": 16031, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.41, \"learn_time_ms\": 9753.565, \"total_train_time_s\": 11.630279541015625}", "{\"n\": 16032, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 9702.649, \"total_train_time_s\": 11.480105638504028}", "{\"n\": 16033, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 9601.213, \"total_train_time_s\": 10.966398239135742}", "{\"n\": 16034, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.96, \"learn_time_ms\": 9489.378, \"total_train_time_s\": 10.758845329284668}", "{\"n\": 16035, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.91, \"learn_time_ms\": 9643.222, \"total_train_time_s\": 12.825040817260742}", "{\"n\": 16036, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.76, \"learn_time_ms\": 9671.784, \"total_train_time_s\": 11.93671703338623}", "{\"n\": 16037, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.96, \"learn_time_ms\": 9742.986, \"total_train_time_s\": 12.08910584449768}", "{\"n\": 16038, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.32, \"learn_time_ms\": 9872.34, \"total_train_time_s\": 13.274485111236572}", "{\"n\": 16039, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.32, \"learn_time_ms\": 9923.391, \"total_train_time_s\": 12.334015846252441}", "{\"n\": 16040, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.58, \"learn_time_ms\": 10097.135, \"total_train_time_s\": 12.846748113632202}", "{\"n\": 16041, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.72, \"learn_time_ms\": 10286.375, \"total_train_time_s\": 13.552472352981567}", "{\"n\": 16042, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.63, \"learn_time_ms\": 10313.155, \"total_train_time_s\": 11.76119065284729}", "{\"n\": 16043, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.66, \"learn_time_ms\": 10413.157, \"total_train_time_s\": 11.980693101882935}", "{\"n\": 16044, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.45, \"learn_time_ms\": 10489.451, \"total_train_time_s\": 11.547544717788696}", "{\"n\": 16045, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.45, \"learn_time_ms\": 10449.741, \"total_train_time_s\": 12.367670059204102}", "{\"n\": 16046, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.81, \"learn_time_ms\": 10470.055, \"total_train_time_s\": 12.171401977539062}", "{\"n\": 16047, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.81, \"learn_time_ms\": 10504.081, \"total_train_time_s\": 12.446388721466064}", "{\"n\": 16048, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.29, \"learn_time_ms\": 10346.902, \"total_train_time_s\": 11.723636627197266}", "{\"n\": 16049, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.03, \"learn_time_ms\": 10299.552, \"total_train_time_s\": 11.869939088821411}", "{\"n\": 16050, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.03, \"learn_time_ms\": 10262.273, \"total_train_time_s\": 12.485447406768799}", "{\"n\": 16051, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.41, \"learn_time_ms\": 10144.341, \"total_train_time_s\": 12.339478492736816}", "{\"n\": 16052, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 10189.007, \"total_train_time_s\": 12.21133041381836}", "{\"n\": 16053, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 10082.709, \"total_train_time_s\": 10.919539451599121}", "{\"n\": 16054, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.6, \"learn_time_ms\": 10054.756, \"total_train_time_s\": 11.263684272766113}", "{\"n\": 16055, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.28, \"learn_time_ms\": 10074.285, \"total_train_time_s\": 12.558475255966187}", "{\"n\": 16056, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.08, \"learn_time_ms\": 10081.597, \"total_train_time_s\": 12.262513875961304}", "{\"n\": 16057, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.08, \"learn_time_ms\": 10030.228, \"total_train_time_s\": 11.943994760513306}", "{\"n\": 16058, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.77, \"learn_time_ms\": 10015.697, \"total_train_time_s\": 11.494328022003174}", "{\"n\": 16059, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.21, \"learn_time_ms\": 10024.612, \"total_train_time_s\": 11.926271200180054}", "{\"n\": 16060, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.73, \"learn_time_ms\": 9947.956, \"total_train_time_s\": 11.735045671463013}", "{\"n\": 16061, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.73, \"learn_time_ms\": 9999.414, \"total_train_time_s\": 12.891420125961304}", "{\"n\": 16062, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.89, \"learn_time_ms\": 9966.337, \"total_train_time_s\": 11.875220537185669}", "{\"n\": 16063, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.06, \"learn_time_ms\": 10048.438, \"total_train_time_s\": 11.761568069458008}", "{\"n\": 16064, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.06, \"learn_time_ms\": 10077.717, \"total_train_time_s\": 11.544431447982788}", "{\"n\": 16065, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.06, \"learn_time_ms\": 10029.243, \"total_train_time_s\": 12.058659553527832}", "{\"n\": 16066, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.85, \"learn_time_ms\": 10001.641, \"total_train_time_s\": 11.92058801651001}", "{\"n\": 16067, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 9999.326, \"total_train_time_s\": 11.888009071350098}", "{\"n\": 16068, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.1, \"learn_time_ms\": 10149.36, \"total_train_time_s\": 13.092895984649658}", "{\"n\": 16069, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.42, \"learn_time_ms\": 10305.101, \"total_train_time_s\": 13.469687461853027}", "{\"n\": 16070, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10362.918, \"total_train_time_s\": 12.30388331413269}", "{\"n\": 16071, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10324.027, \"total_train_time_s\": 12.52278757095337}", "{\"n\": 16072, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10299.853, \"total_train_time_s\": 11.598607063293457}", "{\"n\": 16073, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.01, \"learn_time_ms\": 10430.452, \"total_train_time_s\": 13.066754579544067}", "{\"n\": 16074, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.79, \"learn_time_ms\": 10520.637, \"total_train_time_s\": 12.521470069885254}", "{\"n\": 16075, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.79, \"learn_time_ms\": 10501.994, \"total_train_time_s\": 11.91434121131897}", "{\"n\": 16076, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.85, \"learn_time_ms\": 10492.916, \"total_train_time_s\": 11.84626317024231}", "{\"n\": 16077, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.09, \"learn_time_ms\": 10637.53, \"total_train_time_s\": 13.364764213562012}", "{\"n\": 16078, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.78, \"learn_time_ms\": 10611.053, \"total_train_time_s\": 12.793978452682495}", "{\"n\": 16079, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.11, \"learn_time_ms\": 10501.893, \"total_train_time_s\": 12.36680555343628}", "{\"n\": 16080, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.11, \"learn_time_ms\": 10385.981, \"total_train_time_s\": 11.118199586868286}", "{\"n\": 16081, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.61, \"learn_time_ms\": 10373.29, \"total_train_time_s\": 12.364313840866089}", "{\"n\": 16082, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.61, \"learn_time_ms\": 10443.451, \"total_train_time_s\": 12.301005601882935}", "{\"n\": 16083, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.85, \"learn_time_ms\": 10326.823, \"total_train_time_s\": 11.854018688201904}", "{\"n\": 16084, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.87, \"learn_time_ms\": 10275.956, \"total_train_time_s\": 11.961024284362793}", "{\"n\": 16085, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.95, \"learn_time_ms\": 10379.747, \"total_train_time_s\": 12.974522829055786}", "{\"n\": 16086, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.95, \"learn_time_ms\": 10448.624, \"total_train_time_s\": 12.526070833206177}", "{\"n\": 16087, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.84, \"learn_time_ms\": 10337.812, \"total_train_time_s\": 12.207952499389648}", "{\"n\": 16088, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.84, \"learn_time_ms\": 10334.216, \"total_train_time_s\": 12.723031520843506}", "{\"n\": 16089, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.84, \"learn_time_ms\": 10381.145, \"total_train_time_s\": 12.873898267745972}", "{\"n\": 16090, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.86, \"learn_time_ms\": 10401.737, \"total_train_time_s\": 11.296597003936768}", "{\"n\": 16091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.86, \"learn_time_ms\": 10320.469, \"total_train_time_s\": 11.566653490066528}", "{\"n\": 16092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.38, \"learn_time_ms\": 10322.442, \"total_train_time_s\": 12.339913606643677}", "{\"n\": 16093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.01, \"learn_time_ms\": 10396.4, \"total_train_time_s\": 12.608267784118652}", "{\"n\": 16094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.14, \"learn_time_ms\": 10267.071, \"total_train_time_s\": 10.670060396194458}", "{\"n\": 16095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.04, \"learn_time_ms\": 10172.191, \"total_train_time_s\": 11.971474170684814}", "{\"n\": 16096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.04, \"learn_time_ms\": 10178.015, \"total_train_time_s\": 12.595952033996582}", "{\"n\": 16097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.74, \"learn_time_ms\": 10107.041, \"total_train_time_s\": 11.558619022369385}", "{\"n\": 16098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.19, \"learn_time_ms\": 9990.147, \"total_train_time_s\": 11.612576007843018}", "{\"n\": 16099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.91, \"learn_time_ms\": 9827.303, \"total_train_time_s\": 11.208996057510376}", "{\"n\": 16100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 9826.755, \"total_train_time_s\": 11.293797492980957}", "{\"n\": 16101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.35, \"learn_time_ms\": 9929.893, \"total_train_time_s\": 12.640620708465576}", "{\"n\": 16102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.35, \"learn_time_ms\": 9980.8, \"total_train_time_s\": 12.836581945419312}", "{\"n\": 16103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.16, \"learn_time_ms\": 9911.208, \"total_train_time_s\": 11.9041907787323}", "{\"n\": 16104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.35, \"learn_time_ms\": 10137.918, \"total_train_time_s\": 12.970638990402222}", "{\"n\": 16105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.42, \"learn_time_ms\": 10069.811, \"total_train_time_s\": 11.310064792633057}", "{\"n\": 16106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.2, \"learn_time_ms\": 9979.228, \"total_train_time_s\": 11.71849799156189}", "{\"n\": 16107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.2, \"learn_time_ms\": 9993.627, \"total_train_time_s\": 11.683637619018555}", "{\"n\": 16108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.49, \"learn_time_ms\": 10029.813, \"total_train_time_s\": 11.91476559638977}", "{\"n\": 16109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.33, \"learn_time_ms\": 10201.654, \"total_train_time_s\": 12.953221321105957}", "{\"n\": 16110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10242.822, \"total_train_time_s\": 11.723512411117554}", "{\"n\": 16111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.12, \"learn_time_ms\": 10148.16, \"total_train_time_s\": 11.585916519165039}", "{\"n\": 16112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.46, \"learn_time_ms\": 10120.0, \"total_train_time_s\": 12.56494927406311}", "{\"n\": 16113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.87, \"learn_time_ms\": 10150.305, \"total_train_time_s\": 12.23984432220459}", "{\"n\": 16114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.87, \"learn_time_ms\": 10065.036, \"total_train_time_s\": 12.119381189346313}", "{\"n\": 16115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.82, \"learn_time_ms\": 10109.597, \"total_train_time_s\": 11.763602495193481}", "{\"n\": 16116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.78, \"learn_time_ms\": 10103.783, \"total_train_time_s\": 11.67478632926941}", "{\"n\": 16117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.61, \"learn_time_ms\": 10134.157, \"total_train_time_s\": 11.999620199203491}", "{\"n\": 16118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.61, \"learn_time_ms\": 10225.297, \"total_train_time_s\": 12.858026504516602}", "{\"n\": 16119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.51, \"learn_time_ms\": 10096.459, \"total_train_time_s\": 11.664396047592163}", "{\"n\": 16120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.33, \"learn_time_ms\": 10107.658, \"total_train_time_s\": 11.837291240692139}", "{\"n\": 16121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.33, \"learn_time_ms\": 10213.59, \"total_train_time_s\": 12.704909324645996}", "{\"n\": 16122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.33, \"learn_time_ms\": 10076.815, \"total_train_time_s\": 11.180193185806274}", "{\"n\": 16123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.44, \"learn_time_ms\": 10071.521, \"total_train_time_s\": 12.17540192604065}", "{\"n\": 16124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.27, \"learn_time_ms\": 10075.912, \"total_train_time_s\": 12.094447612762451}", "{\"n\": 16125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.27, \"learn_time_ms\": 10037.089, \"total_train_time_s\": 11.345897912979126}", "{\"n\": 16126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.55, \"learn_time_ms\": 9989.238, \"total_train_time_s\": 11.122861385345459}", "{\"n\": 16127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.73, \"learn_time_ms\": 9971.521, \"total_train_time_s\": 11.803326845169067}", "{\"n\": 16128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.73, \"learn_time_ms\": 9899.057, \"total_train_time_s\": 12.138271570205688}", "{\"n\": 16129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.58, \"learn_time_ms\": 9820.69, \"total_train_time_s\": 10.867053031921387}", "{\"n\": 16130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.58, \"learn_time_ms\": 9786.528, \"total_train_time_s\": 11.485151290893555}", "{\"n\": 16131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.27, \"learn_time_ms\": 9697.654, \"total_train_time_s\": 11.783682107925415}", "{\"n\": 16132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.27, \"learn_time_ms\": 9866.559, \"total_train_time_s\": 12.848624229431152}", "{\"n\": 16133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.84, \"learn_time_ms\": 9845.679, \"total_train_time_s\": 11.96613097190857}", "{\"n\": 16134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.49, \"learn_time_ms\": 9844.046, \"total_train_time_s\": 12.128156185150146}", "{\"n\": 16135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.37, \"learn_time_ms\": 9986.863, \"total_train_time_s\": 12.788240194320679}", "{\"n\": 16136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.37, \"learn_time_ms\": 9993.71, \"total_train_time_s\": 11.183931827545166}", "{\"n\": 16137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.68, \"learn_time_ms\": 10040.817, \"total_train_time_s\": 12.2979416847229}", "{\"n\": 16138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.68, \"learn_time_ms\": 9966.463, \"total_train_time_s\": 11.33789348602295}", "{\"n\": 16139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.38, \"learn_time_ms\": 10016.014, \"total_train_time_s\": 11.380453109741211}", "{\"n\": 16140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.52, \"learn_time_ms\": 10059.777, \"total_train_time_s\": 11.921779155731201}", "{\"n\": 16141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.83, \"learn_time_ms\": 10175.248, \"total_train_time_s\": 12.94972562789917}", "{\"n\": 16142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.68, \"learn_time_ms\": 10114.763, \"total_train_time_s\": 12.248860836029053}", "{\"n\": 16143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.68, \"learn_time_ms\": 10139.885, \"total_train_time_s\": 12.235572099685669}", "{\"n\": 16144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.31, \"learn_time_ms\": 10070.968, \"total_train_time_s\": 11.418725490570068}", "{\"n\": 16145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 10074.353, \"total_train_time_s\": 12.878898620605469}", "{\"n\": 16146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.24, \"learn_time_ms\": 10217.621, \"total_train_time_s\": 12.637540102005005}", "{\"n\": 16147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.03, \"learn_time_ms\": 10125.321, \"total_train_time_s\": 11.338388442993164}", "{\"n\": 16148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.03, \"learn_time_ms\": 10147.997, \"total_train_time_s\": 11.628717184066772}", "{\"n\": 16149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.15, \"learn_time_ms\": 10160.958, \"total_train_time_s\": 11.518779277801514}", "{\"n\": 16150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.78, \"learn_time_ms\": 10154.401, \"total_train_time_s\": 11.858706951141357}", "{\"n\": 16151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.92, \"learn_time_ms\": 10080.609, \"total_train_time_s\": 12.235077619552612}", "{\"n\": 16152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.92, \"learn_time_ms\": 10011.013, \"total_train_time_s\": 11.530245542526245}", "{\"n\": 16153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.75, \"learn_time_ms\": 10029.604, \"total_train_time_s\": 12.414178609848022}", "{\"n\": 16154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.51, \"learn_time_ms\": 10149.426, \"total_train_time_s\": 12.607131004333496}", "{\"n\": 16155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.7, \"learn_time_ms\": 10018.649, \"total_train_time_s\": 11.533194780349731}", "{\"n\": 16156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.09, \"learn_time_ms\": 10047.427, \"total_train_time_s\": 12.903678178787231}", "{\"n\": 16157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.7, \"learn_time_ms\": 10174.627, \"total_train_time_s\": 12.591253757476807}", "{\"n\": 16158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.7, \"learn_time_ms\": 10296.42, \"total_train_time_s\": 12.826266765594482}", "{\"n\": 16159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.79, \"learn_time_ms\": 10345.926, \"total_train_time_s\": 12.002476930618286}", "{\"n\": 16160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.38, \"learn_time_ms\": 10302.114, \"total_train_time_s\": 11.418397665023804}", "{\"n\": 16161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.17, \"learn_time_ms\": 10356.568, \"total_train_time_s\": 12.781982421875}", "{\"n\": 16162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.17, \"learn_time_ms\": 10379.92, \"total_train_time_s\": 11.806371927261353}", "{\"n\": 16163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.91, \"learn_time_ms\": 10309.565, \"total_train_time_s\": 11.656776189804077}", "{\"n\": 16164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.2, \"learn_time_ms\": 10191.486, \"total_train_time_s\": 11.433254480361938}", "{\"n\": 16165, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.76, \"learn_time_ms\": 10310.774, \"total_train_time_s\": 12.719339609146118}", "{\"n\": 16166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.76, \"learn_time_ms\": 10334.988, \"total_train_time_s\": 13.179412603378296}", "{\"n\": 16167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.79, \"learn_time_ms\": 10222.581, \"total_train_time_s\": 11.527979850769043}", "{\"n\": 16168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.94, \"learn_time_ms\": 10129.082, \"total_train_time_s\": 11.87846040725708}", "{\"n\": 16169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.94, \"learn_time_ms\": 10179.84, \"total_train_time_s\": 12.498422622680664}", "{\"n\": 16170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.94, \"learn_time_ms\": 10261.723, \"total_train_time_s\": 12.248751878738403}", "{\"n\": 16171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.39, \"learn_time_ms\": 10144.357, \"total_train_time_s\": 11.631219148635864}", "{\"n\": 16172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.66, \"learn_time_ms\": 10083.964, \"total_train_time_s\": 11.203940868377686}", "{\"n\": 16173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.66, \"learn_time_ms\": 10130.833, \"total_train_time_s\": 12.168328285217285}", "{\"n\": 16174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3635.84, \"learn_time_ms\": 10214.365, \"total_train_time_s\": 12.243299722671509}", "{\"n\": 16175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.07, \"learn_time_ms\": 10145.552, \"total_train_time_s\": 12.005815267562866}", "{\"n\": 16176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.25, \"learn_time_ms\": 9962.109, \"total_train_time_s\": 11.360907554626465}", "{\"n\": 16177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.25, \"learn_time_ms\": 10003.414, \"total_train_time_s\": 11.925277471542358}", "{\"n\": 16178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.98, \"learn_time_ms\": 10066.493, \"total_train_time_s\": 12.524736166000366}", "{\"n\": 16179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.51, \"learn_time_ms\": 10070.927, \"total_train_time_s\": 12.580294609069824}", "{\"n\": 16180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.51, \"learn_time_ms\": 10015.403, \"total_train_time_s\": 11.680455684661865}", "{\"n\": 16181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.55, \"learn_time_ms\": 10111.822, \"total_train_time_s\": 12.578621864318848}", "{\"n\": 16182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.83, \"learn_time_ms\": 10205.24, \"total_train_time_s\": 12.14751648902893}", "{\"n\": 16183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.78, \"learn_time_ms\": 10265.615, \"total_train_time_s\": 12.784177541732788}", "{\"n\": 16184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.78, \"learn_time_ms\": 10237.104, \"total_train_time_s\": 11.971464157104492}", "{\"n\": 16185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.51, \"learn_time_ms\": 10198.404, \"total_train_time_s\": 11.632852554321289}", "{\"n\": 16186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.51, \"learn_time_ms\": 10306.113, \"total_train_time_s\": 12.421422004699707}", "{\"n\": 16187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.54, \"learn_time_ms\": 10261.426, \"total_train_time_s\": 11.474955081939697}", "{\"n\": 16188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 10228.495, \"total_train_time_s\": 12.183396577835083}", "{\"n\": 16189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.78, \"learn_time_ms\": 10164.942, \"total_train_time_s\": 11.906890630722046}", "{\"n\": 16190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.32, \"learn_time_ms\": 10180.547, \"total_train_time_s\": 11.850964784622192}", "{\"n\": 16191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.93, \"learn_time_ms\": 10143.423, \"total_train_time_s\": 12.179301500320435}", "{\"n\": 16192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.93, \"learn_time_ms\": 10144.692, \"total_train_time_s\": 12.176691770553589}", "{\"n\": 16193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.12, \"learn_time_ms\": 10071.442, \"total_train_time_s\": 12.056849002838135}", "{\"n\": 16194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.02, \"learn_time_ms\": 10122.825, \"total_train_time_s\": 12.459292888641357}", "{\"n\": 16195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.02, \"learn_time_ms\": 10283.859, \"total_train_time_s\": 13.24901556968689}", "{\"n\": 16196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.29, \"learn_time_ms\": 10286.86, \"total_train_time_s\": 12.429820537567139}", "{\"n\": 16197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.03, \"learn_time_ms\": 10345.108, \"total_train_time_s\": 12.061001062393188}", "{\"n\": 16198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.03, \"learn_time_ms\": 10218.946, \"total_train_time_s\": 10.900212049484253}", "{\"n\": 16199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.03, \"learn_time_ms\": 10211.065, \"total_train_time_s\": 11.838352680206299}", "{\"n\": 16200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.65, \"learn_time_ms\": 10373.725, \"total_train_time_s\": 13.437948942184448}", "{\"n\": 16201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.93, \"learn_time_ms\": 10373.387, \"total_train_time_s\": 12.168771028518677}", "{\"n\": 16202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.93, \"learn_time_ms\": 10230.008, \"total_train_time_s\": 10.72758436203003}", "{\"n\": 16203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.93, \"learn_time_ms\": 10185.068, \"total_train_time_s\": 11.586668252944946}", "{\"n\": 16204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.16, \"learn_time_ms\": 10222.046, \"total_train_time_s\": 12.852689027786255}", "{\"n\": 16205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.71, \"learn_time_ms\": 10063.302, \"total_train_time_s\": 11.653995752334595}", "{\"n\": 16206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.71, \"learn_time_ms\": 10030.867, \"total_train_time_s\": 12.119791984558105}", "{\"n\": 16207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.84, \"learn_time_ms\": 10007.798, \"total_train_time_s\": 11.777810335159302}", "{\"n\": 16208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3625.84, \"learn_time_ms\": 10079.102, \"total_train_time_s\": 11.657865762710571}", "{\"n\": 16209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10086.433, \"total_train_time_s\": 11.901474475860596}", "{\"n\": 16210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 9995.693, \"total_train_time_s\": 12.535936117172241}", "{\"n\": 16211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.34, \"learn_time_ms\": 10004.541, \"total_train_time_s\": 12.31811237335205}", "{\"n\": 16212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.44, \"learn_time_ms\": 10072.541, \"total_train_time_s\": 11.38558316230774}", "{\"n\": 16213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.34, \"learn_time_ms\": 10100.319, \"total_train_time_s\": 11.850348949432373}", "{\"n\": 16214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.1, \"learn_time_ms\": 10043.206, \"total_train_time_s\": 12.295556545257568}", "{\"n\": 16215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.4, \"learn_time_ms\": 10084.587, \"total_train_time_s\": 12.03438663482666}", "{\"n\": 16216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.4, \"learn_time_ms\": 10117.549, \"total_train_time_s\": 12.429744958877563}", "{\"n\": 16217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.88, \"learn_time_ms\": 10171.161, \"total_train_time_s\": 12.395716428756714}", "{\"n\": 16218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.5, \"learn_time_ms\": 10234.41, \"total_train_time_s\": 12.296379566192627}", "{\"n\": 16219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.41, \"learn_time_ms\": 10127.458, \"total_train_time_s\": 10.794199705123901}", "{\"n\": 16220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.1, \"learn_time_ms\": 9982.854, \"total_train_time_s\": 11.105797290802002}", "{\"n\": 16221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.74, \"learn_time_ms\": 9871.416, \"total_train_time_s\": 11.188698053359985}", "{\"n\": 16222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.74, \"learn_time_ms\": 9883.855, \"total_train_time_s\": 11.512166023254395}", "{\"n\": 16223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.05, \"learn_time_ms\": 9896.215, \"total_train_time_s\": 11.979751348495483}", "{\"n\": 16224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.59, \"learn_time_ms\": 9855.14, \"total_train_time_s\": 11.87318205833435}", "{\"n\": 16225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.59, \"learn_time_ms\": 9889.203, \"total_train_time_s\": 12.390648126602173}", "{\"n\": 16226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.63, \"learn_time_ms\": 9849.312, \"total_train_time_s\": 12.09534502029419}", "{\"n\": 16227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.31, \"learn_time_ms\": 9861.888, \"total_train_time_s\": 12.51716685295105}", "{\"n\": 16228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.33, \"learn_time_ms\": 9850.702, \"total_train_time_s\": 12.14082670211792}", "{\"n\": 16229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.43, \"learn_time_ms\": 9961.615, \"total_train_time_s\": 11.971018075942993}", "{\"n\": 16230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.82, \"learn_time_ms\": 10006.362, \"total_train_time_s\": 11.539673328399658}", "{\"n\": 16231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.04, \"learn_time_ms\": 9957.832, \"total_train_time_s\": 10.696574687957764}", "{\"n\": 16232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.91, \"learn_time_ms\": 9985.651, \"total_train_time_s\": 11.832814693450928}", "{\"n\": 16233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.81, \"learn_time_ms\": 9884.03, \"total_train_time_s\": 11.026320219039917}", "{\"n\": 16234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.71, \"learn_time_ms\": 9896.804, \"total_train_time_s\": 12.03029465675354}", "{\"n\": 16235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.36, \"learn_time_ms\": 9869.699, \"total_train_time_s\": 12.147094488143921}", "{\"n\": 16236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.64, \"learn_time_ms\": 9809.677, \"total_train_time_s\": 11.440931558609009}", "{\"n\": 16237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.21, \"learn_time_ms\": 9778.122, \"total_train_time_s\": 12.14555287361145}", "{\"n\": 16238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.11, \"learn_time_ms\": 9834.56, \"total_train_time_s\": 12.740856647491455}", "{\"n\": 16239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.24, \"learn_time_ms\": 9909.98, \"total_train_time_s\": 12.700928926467896}", "{\"n\": 16240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.85, \"learn_time_ms\": 9931.218, \"total_train_time_s\": 11.766780853271484}", "{\"n\": 16241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.93, \"learn_time_ms\": 10055.291, \"total_train_time_s\": 11.922621726989746}", "{\"n\": 16242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.75, \"learn_time_ms\": 10087.196, \"total_train_time_s\": 12.143401384353638}", "{\"n\": 16243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.16, \"learn_time_ms\": 10287.912, \"total_train_time_s\": 12.97794222831726}", "{\"n\": 16244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.08, \"learn_time_ms\": 10316.833, \"total_train_time_s\": 12.27707815170288}", "{\"n\": 16245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.08, \"learn_time_ms\": 10334.494, \"total_train_time_s\": 12.287814140319824}", "{\"n\": 16246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.18, \"learn_time_ms\": 10320.611, \"total_train_time_s\": 11.336484670639038}", "{\"n\": 16247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.97, \"learn_time_ms\": 10411.894, \"total_train_time_s\": 13.106616973876953}", "{\"n\": 16248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.97, \"learn_time_ms\": 10320.121, \"total_train_time_s\": 11.801745176315308}", "{\"n\": 16249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.83, \"learn_time_ms\": 10323.893, \"total_train_time_s\": 12.72217082977295}", "{\"n\": 16250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.45, \"learn_time_ms\": 10235.759, \"total_train_time_s\": 10.895025730133057}", "{\"n\": 16251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.52, \"learn_time_ms\": 10313.852, \"total_train_time_s\": 12.65934705734253}", "{\"n\": 16252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.52, \"learn_time_ms\": 10279.11, \"total_train_time_s\": 11.767349481582642}", "{\"n\": 16253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 10261.616, \"total_train_time_s\": 12.830679893493652}", "{\"n\": 16254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.72, \"learn_time_ms\": 10128.638, \"total_train_time_s\": 10.976769208908081}", "{\"n\": 16255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.7, \"learn_time_ms\": 10167.599, \"total_train_time_s\": 12.657164573669434}", "{\"n\": 16256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.7, \"learn_time_ms\": 10170.698, \"total_train_time_s\": 11.317051887512207}", "{\"n\": 16257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.35, \"learn_time_ms\": 10109.844, \"total_train_time_s\": 12.48509669303894}", "{\"n\": 16258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.27, \"learn_time_ms\": 10164.284, \"total_train_time_s\": 12.34995150566101}", "{\"n\": 16259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.6, \"learn_time_ms\": 10149.696, \"total_train_time_s\": 12.559834003448486}", "{\"n\": 16260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.46, \"learn_time_ms\": 10176.903, \"total_train_time_s\": 11.169315099716187}", "{\"n\": 16261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.84, \"learn_time_ms\": 10195.428, \"total_train_time_s\": 12.908485174179077}", "{\"n\": 16262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.84, \"learn_time_ms\": 10105.02, \"total_train_time_s\": 10.863101482391357}", "{\"n\": 16263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.03, \"learn_time_ms\": 9898.548, \"total_train_time_s\": 10.776412010192871}", "{\"n\": 16264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.03, \"learn_time_ms\": 9960.128, \"total_train_time_s\": 11.594117403030396}", "{\"n\": 16265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.85, \"learn_time_ms\": 9989.21, \"total_train_time_s\": 13.014732122421265}", "{\"n\": 16266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.84, \"learn_time_ms\": 10098.976, \"total_train_time_s\": 12.507219076156616}", "{\"n\": 16267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.34, \"learn_time_ms\": 10085.875, \"total_train_time_s\": 12.328003168106079}", "{\"n\": 16268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 10157.206, \"total_train_time_s\": 13.081366300582886}", "{\"n\": 16269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.62, \"learn_time_ms\": 10222.218, \"total_train_time_s\": 13.280875444412231}", "{\"n\": 16270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.77, \"learn_time_ms\": 10247.366, \"total_train_time_s\": 11.401570320129395}", "{\"n\": 16271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.77, \"learn_time_ms\": 10170.927, \"total_train_time_s\": 12.062605857849121}", "{\"n\": 16272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.71, \"learn_time_ms\": 10221.961, \"total_train_time_s\": 11.390773296356201}", "{\"n\": 16273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.71, \"learn_time_ms\": 10340.937, \"total_train_time_s\": 11.918960332870483}", "{\"n\": 16274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.6, \"learn_time_ms\": 10359.486, \"total_train_time_s\": 11.799714088439941}", "{\"n\": 16275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.6, \"learn_time_ms\": 10330.313, \"total_train_time_s\": 12.704771995544434}", "{\"n\": 16276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 10344.655, \"total_train_time_s\": 12.587154626846313}", "{\"n\": 16277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 10286.167, \"total_train_time_s\": 11.751610040664673}", "{\"n\": 16278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.56, \"learn_time_ms\": 10216.601, \"total_train_time_s\": 12.38786268234253}", "{\"n\": 16279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.56, \"learn_time_ms\": 10101.693, \"total_train_time_s\": 12.146695613861084}", "{\"n\": 16280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.06, \"learn_time_ms\": 10065.245, \"total_train_time_s\": 11.060784816741943}", "{\"n\": 16281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.06, \"learn_time_ms\": 10172.006, \"total_train_time_s\": 13.203155279159546}", "{\"n\": 16282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.06, \"learn_time_ms\": 10292.837, \"total_train_time_s\": 12.624470710754395}", "{\"n\": 16283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.86, \"learn_time_ms\": 10299.297, \"total_train_time_s\": 12.005326509475708}", "{\"n\": 16284, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 10438.724, \"total_train_time_s\": 13.1946861743927}", "{\"n\": 16285, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 10440.5, \"total_train_time_s\": 12.739129066467285}", "{\"n\": 16286, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.88, \"learn_time_ms\": 10378.364, \"total_train_time_s\": 11.95815634727478}", "{\"n\": 16287, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.07, \"learn_time_ms\": 10441.376, \"total_train_time_s\": 12.371822118759155}", "{\"n\": 16288, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.44, \"learn_time_ms\": 10413.239, \"total_train_time_s\": 12.107022047042847}", "{\"n\": 16289, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.14, \"learn_time_ms\": 10458.095, \"total_train_time_s\": 12.525078773498535}", "{\"n\": 16290, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.09, \"learn_time_ms\": 10586.349, \"total_train_time_s\": 12.33215069770813}", "{\"n\": 16291, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.98, \"learn_time_ms\": 10411.026, \"total_train_time_s\": 11.424562454223633}", "{\"n\": 16292, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.71, \"learn_time_ms\": 10330.635, \"total_train_time_s\": 11.71566653251648}", "{\"n\": 16293, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.64, \"learn_time_ms\": 10409.167, \"total_train_time_s\": 12.775028228759766}", "{\"n\": 16294, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.09, \"learn_time_ms\": 10289.67, \"total_train_time_s\": 11.972322702407837}", "{\"n\": 16295, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.09, \"learn_time_ms\": 10049.96, \"total_train_time_s\": 10.311142206192017}", "{\"n\": 16296, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.47, \"learn_time_ms\": 9972.339, \"total_train_time_s\": 11.158411264419556}", "{\"n\": 16297, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.51, \"learn_time_ms\": 9917.919, \"total_train_time_s\": 11.825870513916016}", "{\"n\": 16298, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.51, \"learn_time_ms\": 9923.935, \"total_train_time_s\": 12.134006261825562}", "{\"n\": 16299, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.99, \"learn_time_ms\": 9786.836, \"total_train_time_s\": 11.167858362197876}", "{\"n\": 16300, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.79, \"learn_time_ms\": 9755.852, \"total_train_time_s\": 12.038900136947632}", "{\"n\": 16301, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.8, \"learn_time_ms\": 9919.868, \"total_train_time_s\": 13.083170175552368}", "{\"n\": 16302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.59, \"learn_time_ms\": 10003.855, \"total_train_time_s\": 12.628790378570557}", "{\"n\": 16303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.59, \"learn_time_ms\": 10008.564, \"total_train_time_s\": 12.871548414230347}", "{\"n\": 16304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.12, \"learn_time_ms\": 10049.872, \"total_train_time_s\": 12.410216569900513}", "{\"n\": 16305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.79, \"learn_time_ms\": 10337.447, \"total_train_time_s\": 13.185626983642578}", "{\"n\": 16306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.79, \"learn_time_ms\": 10295.608, \"total_train_time_s\": 10.764096975326538}", "{\"n\": 16307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10333.013, \"total_train_time_s\": 12.180941581726074}", "{\"n\": 16308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.61, \"learn_time_ms\": 10397.844, \"total_train_time_s\": 12.818136930465698}", "{\"n\": 16309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.61, \"learn_time_ms\": 10450.45, \"total_train_time_s\": 11.685140609741211}", "{\"n\": 16310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.81, \"learn_time_ms\": 10488.106, \"total_train_time_s\": 12.42229676246643}", "{\"n\": 16311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.85, \"learn_time_ms\": 10461.208, \"total_train_time_s\": 12.823784828186035}", "{\"n\": 16312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.2, \"learn_time_ms\": 10343.582, \"total_train_time_s\": 11.433074235916138}", "{\"n\": 16313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.2, \"learn_time_ms\": 10267.133, \"total_train_time_s\": 12.06221342086792}", "{\"n\": 16314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.76, \"learn_time_ms\": 10207.69, \"total_train_time_s\": 11.800020456314087}", "{\"n\": 16315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.79, \"learn_time_ms\": 10152.066, \"total_train_time_s\": 12.714331150054932}", "{\"n\": 16316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 10187.812, \"total_train_time_s\": 11.151869297027588}", "{\"n\": 16317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.45, \"learn_time_ms\": 10144.415, \"total_train_time_s\": 11.79639983177185}", "{\"n\": 16318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.03, \"learn_time_ms\": 9993.817, \"total_train_time_s\": 11.292028903961182}", "{\"n\": 16319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.03, \"learn_time_ms\": 10120.745, \"total_train_time_s\": 12.923305749893188}", "{\"n\": 16320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.34, \"learn_time_ms\": 10107.096, \"total_train_time_s\": 12.253233432769775}", "{\"n\": 16321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.96, \"learn_time_ms\": 9969.6, \"total_train_time_s\": 11.42699646949768}", "{\"n\": 16322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.61, \"learn_time_ms\": 9952.308, \"total_train_time_s\": 11.291372060775757}", "{\"n\": 16323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.42, \"learn_time_ms\": 9975.158, \"total_train_time_s\": 12.281321287155151}", "{\"n\": 16324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.71, \"learn_time_ms\": 9975.718, \"total_train_time_s\": 11.754284143447876}", "{\"n\": 16325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.37, \"learn_time_ms\": 9844.556, \"total_train_time_s\": 11.321283102035522}", "{\"n\": 16326, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.37, \"learn_time_ms\": 9902.57, \"total_train_time_s\": 11.689193964004517}", "{\"n\": 16327, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.31, \"learn_time_ms\": 9888.36, \"total_train_time_s\": 11.668741941452026}", "{\"n\": 16328, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.75, \"learn_time_ms\": 9879.692, \"total_train_time_s\": 11.235038042068481}", "{\"n\": 16329, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.78, \"learn_time_ms\": 9839.176, \"total_train_time_s\": 12.573460578918457}", "{\"n\": 16330, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.78, \"learn_time_ms\": 9788.698, \"total_train_time_s\": 11.772175312042236}", "{\"n\": 16331, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.53, \"learn_time_ms\": 9820.913, \"total_train_time_s\": 11.791993856430054}", "{\"n\": 16332, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.87, \"learn_time_ms\": 9815.487, \"total_train_time_s\": 11.22696566581726}", "{\"n\": 16333, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.89, \"learn_time_ms\": 9812.877, \"total_train_time_s\": 12.282304763793945}", "{\"n\": 16334, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.21, \"learn_time_ms\": 9956.436, \"total_train_time_s\": 13.267425060272217}", "{\"n\": 16335, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.93, \"learn_time_ms\": 10100.35, \"total_train_time_s\": 12.806369304656982}", "{\"n\": 16336, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.22, \"learn_time_ms\": 10165.478, \"total_train_time_s\": 12.385787963867188}", "{\"n\": 16337, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.29, \"learn_time_ms\": 10209.812, \"total_train_time_s\": 12.077116966247559}", "{\"n\": 16338, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.29, \"learn_time_ms\": 10232.012, \"total_train_time_s\": 11.444557428359985}", "{\"n\": 16339, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.71, \"learn_time_ms\": 10249.061, \"total_train_time_s\": 12.770908832550049}", "{\"n\": 16340, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.3, \"learn_time_ms\": 10216.474, \"total_train_time_s\": 11.408763647079468}", "{\"n\": 16341, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.3, \"learn_time_ms\": 10181.579, \"total_train_time_s\": 11.371442556381226}", "{\"n\": 16342, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.53, \"learn_time_ms\": 10207.754, \"total_train_time_s\": 11.444066524505615}", "{\"n\": 16343, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.95, \"learn_time_ms\": 10245.435, \"total_train_time_s\": 12.676692008972168}", "{\"n\": 16344, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.95, \"learn_time_ms\": 10111.501, \"total_train_time_s\": 11.861064195632935}", "{\"n\": 16345, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.95, \"learn_time_ms\": 9997.901, \"total_train_time_s\": 11.638921976089478}", "{\"n\": 16346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.2, \"learn_time_ms\": 9969.726, \"total_train_time_s\": 12.139708280563354}", "{\"n\": 16347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.67, \"learn_time_ms\": 9942.051, \"total_train_time_s\": 11.80808711051941}", "{\"n\": 16348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.67, \"learn_time_ms\": 10009.245, \"total_train_time_s\": 12.089433431625366}", "{\"n\": 16349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.67, \"learn_time_ms\": 9879.884, \"total_train_time_s\": 11.45746111869812}", "{\"n\": 16350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.67, \"learn_time_ms\": 9931.706, \"total_train_time_s\": 11.976012229919434}", "{\"n\": 16351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 9957.399, \"total_train_time_s\": 11.671382427215576}", "{\"n\": 16352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 10015.884, \"total_train_time_s\": 12.083309650421143}", "{\"n\": 16353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.43, \"learn_time_ms\": 10029.598, \"total_train_time_s\": 12.82429027557373}", "{\"n\": 16354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.55, \"learn_time_ms\": 9970.815, \"total_train_time_s\": 11.29126238822937}", "{\"n\": 16355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.52, \"learn_time_ms\": 10045.253, \"total_train_time_s\": 12.412550926208496}", "{\"n\": 16356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.52, \"learn_time_ms\": 9971.51, \"total_train_time_s\": 11.347761869430542}", "{\"n\": 16357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.12, \"learn_time_ms\": 9964.54, \"total_train_time_s\": 11.730678081512451}", "{\"n\": 16358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.65, \"learn_time_ms\": 10000.25, \"total_train_time_s\": 12.47799015045166}", "{\"n\": 16359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.57, \"learn_time_ms\": 9966.739, \"total_train_time_s\": 11.087884902954102}", "{\"n\": 16360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.31, \"learn_time_ms\": 9942.403, \"total_train_time_s\": 11.779191493988037}", "{\"n\": 16361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.31, \"learn_time_ms\": 9919.895, \"total_train_time_s\": 11.448014259338379}", "{\"n\": 16362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.87, \"learn_time_ms\": 9873.539, \"total_train_time_s\": 11.602827787399292}", "{\"n\": 16363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.87, \"learn_time_ms\": 9767.012, \"total_train_time_s\": 11.70863389968872}", "{\"n\": 16364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.55, \"learn_time_ms\": 9812.704, \"total_train_time_s\": 11.750312328338623}", "{\"n\": 16365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.55, \"learn_time_ms\": 9737.786, \"total_train_time_s\": 11.654510021209717}", "{\"n\": 16366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.55, \"learn_time_ms\": 9772.619, \"total_train_time_s\": 11.695894002914429}", "{\"n\": 16367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.55, \"learn_time_ms\": 9871.259, \"total_train_time_s\": 12.70068645477295}", "{\"n\": 16368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.52, \"learn_time_ms\": 9862.164, \"total_train_time_s\": 12.408694982528687}", "{\"n\": 16369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.56, \"learn_time_ms\": 9954.592, \"total_train_time_s\": 12.058945417404175}", "{\"n\": 16370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.56, \"learn_time_ms\": 9943.265, \"total_train_time_s\": 11.62144923210144}", "{\"n\": 16371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.11, \"learn_time_ms\": 9976.368, \"total_train_time_s\": 11.746773958206177}", "{\"n\": 16372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.81, \"learn_time_ms\": 9974.861, \"total_train_time_s\": 11.532015562057495}", "{\"n\": 16373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.14, \"learn_time_ms\": 10010.548, \"total_train_time_s\": 12.119285583496094}", "{\"n\": 16374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.78, \"learn_time_ms\": 10008.048, \"total_train_time_s\": 11.718502283096313}", "{\"n\": 16375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.86, \"learn_time_ms\": 9875.523, \"total_train_time_s\": 10.340563297271729}", "{\"n\": 16376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.25, \"learn_time_ms\": 9833.864, \"total_train_time_s\": 11.278613090515137}", "{\"n\": 16377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.19, \"learn_time_ms\": 9814.861, \"total_train_time_s\": 12.519721269607544}", "{\"n\": 16378, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.07, \"learn_time_ms\": 9739.104, \"total_train_time_s\": 11.580575227737427}", "{\"n\": 16379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.38, \"learn_time_ms\": 9734.364, \"total_train_time_s\": 12.00732946395874}", "{\"n\": 16380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.94, \"learn_time_ms\": 9750.625, \"total_train_time_s\": 11.787638664245605}", "{\"n\": 16381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3622.21, \"learn_time_ms\": 9699.28, \"total_train_time_s\": 11.286896228790283}", "{\"n\": 16382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.31, \"learn_time_ms\": 9784.304, \"total_train_time_s\": 12.51400089263916}", "{\"n\": 16383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3618.78, \"learn_time_ms\": 9801.324, \"total_train_time_s\": 12.266088008880615}", "{\"n\": 16384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.72, \"learn_time_ms\": 9753.702, \"total_train_time_s\": 11.24254584312439}", "{\"n\": 16385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.72, \"learn_time_ms\": 9844.158, \"total_train_time_s\": 11.210658073425293}", "{\"n\": 16386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.2, \"learn_time_ms\": 9881.48, \"total_train_time_s\": 11.634237051010132}", "{\"n\": 16387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 9824.046, \"total_train_time_s\": 11.959804773330688}", "{\"n\": 16388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3617.34, \"learn_time_ms\": 9803.428, \"total_train_time_s\": 11.445051908493042}", "{\"n\": 16389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.09, \"learn_time_ms\": 9867.827, \"total_train_time_s\": 12.650343418121338}", "{\"n\": 16390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.96, \"learn_time_ms\": 9929.373, \"total_train_time_s\": 12.398162603378296}", "{\"n\": 16391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.96, \"learn_time_ms\": 10120.324, \"total_train_time_s\": 13.175003051757812}", "{\"n\": 16392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.32, \"learn_time_ms\": 10073.086, \"total_train_time_s\": 12.018439769744873}", "{\"n\": 16393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.43, \"learn_time_ms\": 10106.661, \"total_train_time_s\": 12.598300218582153}", "{\"n\": 16394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.19, \"learn_time_ms\": 10140.735, \"total_train_time_s\": 11.607858419418335}", "{\"n\": 16395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.38, \"learn_time_ms\": 10109.811, \"total_train_time_s\": 10.902343511581421}", "{\"n\": 16396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.38, \"learn_time_ms\": 10092.252, \"total_train_time_s\": 11.436761617660522}", "{\"n\": 16397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.44, \"learn_time_ms\": 10088.245, \"total_train_time_s\": 11.881122589111328}", "{\"n\": 16398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.0, \"learn_time_ms\": 10108.426, \"total_train_time_s\": 11.597389936447144}", "{\"n\": 16399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.89, \"learn_time_ms\": 10023.437, \"total_train_time_s\": 11.764511585235596}", "{\"n\": 16400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.43, \"learn_time_ms\": 10055.871, \"total_train_time_s\": 12.732337951660156}", "{\"n\": 16401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.55, \"learn_time_ms\": 9937.465, \"total_train_time_s\": 11.995352745056152}", "{\"n\": 16402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.55, \"learn_time_ms\": 9998.95, \"total_train_time_s\": 12.578059673309326}", "{\"n\": 16403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 10074.931, \"total_train_time_s\": 13.393577337265015}", "{\"n\": 16404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 10055.549, \"total_train_time_s\": 11.373743534088135}", "{\"n\": 16405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.54, \"learn_time_ms\": 10167.519, \"total_train_time_s\": 12.01755166053772}", "{\"n\": 16406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.54, \"learn_time_ms\": 10232.297, \"total_train_time_s\": 12.109253168106079}", "{\"n\": 16407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.42, \"learn_time_ms\": 10216.528, \"total_train_time_s\": 11.75806736946106}", "{\"n\": 16408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.48, \"learn_time_ms\": 10269.666, \"total_train_time_s\": 12.119144916534424}", "{\"n\": 16409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.32, \"learn_time_ms\": 10257.444, \"total_train_time_s\": 11.672825336456299}", "{\"n\": 16410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.91, \"learn_time_ms\": 10249.473, \"total_train_time_s\": 12.650077104568481}", "{\"n\": 16411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.91, \"learn_time_ms\": 10222.318, \"total_train_time_s\": 11.71500539779663}", "{\"n\": 16412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.97, \"learn_time_ms\": 10132.733, \"total_train_time_s\": 11.741057395935059}", "{\"n\": 16413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.36, \"learn_time_ms\": 9978.144, \"total_train_time_s\": 11.858688116073608}", "{\"n\": 16414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.49, \"learn_time_ms\": 10059.983, \"total_train_time_s\": 12.222838640213013}", "{\"n\": 16415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.49, \"learn_time_ms\": 10069.151, \"total_train_time_s\": 12.1260507106781}", "{\"n\": 16416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.39, \"learn_time_ms\": 10106.323, \"total_train_time_s\": 12.544108390808105}", "{\"n\": 16417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.38, \"learn_time_ms\": 10178.835, \"total_train_time_s\": 12.515436887741089}", "{\"n\": 16418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.45, \"learn_time_ms\": 10069.413, \"total_train_time_s\": 11.078581809997559}", "{\"n\": 16419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.23, \"learn_time_ms\": 10046.95, \"total_train_time_s\": 11.434353113174438}", "{\"n\": 16420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.95, \"learn_time_ms\": 9988.47, \"total_train_time_s\": 12.054507493972778}", "{\"n\": 16421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.59, \"learn_time_ms\": 9967.556, \"total_train_time_s\": 11.522390365600586}", "{\"n\": 16422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.97, \"learn_time_ms\": 10057.585, \"total_train_time_s\": 12.598128080368042}", "{\"n\": 16423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.41, \"learn_time_ms\": 10079.882, \"total_train_time_s\": 12.011504888534546}", "{\"n\": 16424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.72, \"learn_time_ms\": 10146.977, \"total_train_time_s\": 12.877743005752563}", "{\"n\": 16425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.72, \"learn_time_ms\": 10152.367, \"total_train_time_s\": 12.151801586151123}", "{\"n\": 16426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.07, \"learn_time_ms\": 10079.517, \"total_train_time_s\": 11.743130922317505}", "{\"n\": 16427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.2, \"learn_time_ms\": 10044.138, \"total_train_time_s\": 12.10155701637268}", "{\"n\": 16428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.67, \"learn_time_ms\": 10085.27, \"total_train_time_s\": 11.480748176574707}", "{\"n\": 16429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.88, \"learn_time_ms\": 10269.218, \"total_train_time_s\": 13.281151056289673}", "{\"n\": 16430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.88, \"learn_time_ms\": 10281.177, \"total_train_time_s\": 12.165873050689697}", "{\"n\": 16431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.94, \"learn_time_ms\": 10377.048, \"total_train_time_s\": 12.454349994659424}", "{\"n\": 16432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.09, \"learn_time_ms\": 10295.176, \"total_train_time_s\": 11.726819038391113}", "{\"n\": 16433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.07, \"learn_time_ms\": 10388.274, \"total_train_time_s\": 12.99225664138794}", "{\"n\": 16434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.07, \"learn_time_ms\": 10343.317, \"total_train_time_s\": 12.471375465393066}", "{\"n\": 16435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.36, \"learn_time_ms\": 10298.005, \"total_train_time_s\": 11.70456576347351}", "{\"n\": 16436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.23, \"learn_time_ms\": 10466.984, \"total_train_time_s\": 13.433013677597046}", "{\"n\": 16437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.84, \"learn_time_ms\": 10378.909, \"total_train_time_s\": 11.366886615753174}", "{\"n\": 16438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.0, \"learn_time_ms\": 10422.094, \"total_train_time_s\": 11.896352052688599}", "{\"n\": 16439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.88, \"learn_time_ms\": 10370.49, \"total_train_time_s\": 12.753201484680176}", "{\"n\": 16440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.88, \"learn_time_ms\": 10361.258, \"total_train_time_s\": 12.034742593765259}", "{\"n\": 16441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.55, \"learn_time_ms\": 10255.881, \"total_train_time_s\": 11.451703071594238}", "{\"n\": 16442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.13, \"learn_time_ms\": 10267.782, \"total_train_time_s\": 11.89088225364685}", "{\"n\": 16443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.13, \"learn_time_ms\": 10148.208, \"total_train_time_s\": 11.735715627670288}", "{\"n\": 16444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.54, \"learn_time_ms\": 10168.336, \"total_train_time_s\": 12.606048583984375}", "{\"n\": 16445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.03, \"learn_time_ms\": 10358.162, \"total_train_time_s\": 13.641285181045532}", "{\"n\": 16446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.9, \"learn_time_ms\": 10215.047, \"total_train_time_s\": 11.975993871688843}", "{\"n\": 16447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.9, \"learn_time_ms\": 10307.607, \"total_train_time_s\": 12.171126127243042}", "{\"n\": 16448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.65, \"learn_time_ms\": 10350.023, \"total_train_time_s\": 12.296332597732544}", "{\"n\": 16449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.64, \"learn_time_ms\": 10332.924, \"total_train_time_s\": 12.6027512550354}", "{\"n\": 16450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.64, \"learn_time_ms\": 10273.3, \"total_train_time_s\": 11.436511754989624}", "{\"n\": 16451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.32, \"learn_time_ms\": 10369.942, \"total_train_time_s\": 12.326626062393188}", "{\"n\": 16452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.43, \"learn_time_ms\": 10407.579, \"total_train_time_s\": 12.25585389137268}", "{\"n\": 16453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.33, \"learn_time_ms\": 10414.76, \"total_train_time_s\": 11.83277940750122}", "{\"n\": 16454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.33, \"learn_time_ms\": 10273.078, \"total_train_time_s\": 11.261400938034058}", "{\"n\": 16455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.81, \"learn_time_ms\": 10053.858, \"total_train_time_s\": 11.432236433029175}", "{\"n\": 16456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.81, \"learn_time_ms\": 10119.197, \"total_train_time_s\": 12.704393148422241}", "{\"n\": 16457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.47, \"learn_time_ms\": 10060.981, \"total_train_time_s\": 11.584620714187622}", "{\"n\": 16458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.46, \"learn_time_ms\": 10046.511, \"total_train_time_s\": 12.136885404586792}", "{\"n\": 16459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.46, \"learn_time_ms\": 9958.237, \"total_train_time_s\": 11.711707830429077}", "{\"n\": 16460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.49, \"learn_time_ms\": 10045.898, \"total_train_time_s\": 12.356040239334106}", "{\"n\": 16461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.58, \"learn_time_ms\": 9988.823, \"total_train_time_s\": 11.775814533233643}", "{\"n\": 16462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.34, \"learn_time_ms\": 9868.536, \"total_train_time_s\": 11.059707403182983}", "{\"n\": 16463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.34, \"learn_time_ms\": 9940.985, \"total_train_time_s\": 12.583025455474854}", "{\"n\": 16464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.57, \"learn_time_ms\": 10092.225, \"total_train_time_s\": 12.731247186660767}", "{\"n\": 16465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.64, \"learn_time_ms\": 10144.081, \"total_train_time_s\": 11.932515859603882}", "{\"n\": 16466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.62, \"learn_time_ms\": 9964.731, \"total_train_time_s\": 10.838026762008667}", "{\"n\": 16467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 10100.359, \"total_train_time_s\": 12.944912195205688}", "{\"n\": 16468, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.26, \"learn_time_ms\": 10052.166, \"total_train_time_s\": 11.663403987884521}", "{\"n\": 16469, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.58, \"learn_time_ms\": 10113.283, \"total_train_time_s\": 12.352831363677979}", "{\"n\": 16470, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.88, \"learn_time_ms\": 10043.918, \"total_train_time_s\": 11.632513523101807}", "{\"n\": 16471, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.14, \"learn_time_ms\": 9979.794, \"total_train_time_s\": 11.154139995574951}", "{\"n\": 16472, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.14, \"learn_time_ms\": 10070.503, \"total_train_time_s\": 11.983617305755615}", "{\"n\": 16473, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.24, \"learn_time_ms\": 9969.133, \"total_train_time_s\": 11.552762508392334}", "{\"n\": 16474, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.24, \"learn_time_ms\": 9973.902, \"total_train_time_s\": 12.784381866455078}", "{\"n\": 16475, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.67, \"learn_time_ms\": 9964.608, \"total_train_time_s\": 11.838623523712158}", "{\"n\": 16476, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.11, \"learn_time_ms\": 10097.925, \"total_train_time_s\": 12.23804759979248}", "{\"n\": 16477, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.11, \"learn_time_ms\": 9954.402, \"total_train_time_s\": 11.508823871612549}", "{\"n\": 16478, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3573.06, \"learn_time_ms\": 9975.195, \"total_train_time_s\": 11.870877742767334}", "{\"n\": 16479, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.57, \"learn_time_ms\": 9976.636, \"total_train_time_s\": 12.322010278701782}", "{\"n\": 16480, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.56, \"learn_time_ms\": 10024.25, \"total_train_time_s\": 12.16734266281128}", "{\"n\": 16481, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.76, \"learn_time_ms\": 10044.13, \"total_train_time_s\": 11.361706972122192}", "{\"n\": 16482, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.76, \"learn_time_ms\": 10077.121, \"total_train_time_s\": 12.299428939819336}", "{\"n\": 16483, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.31, \"learn_time_ms\": 10035.364, \"total_train_time_s\": 11.108988285064697}", "{\"n\": 16484, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3540.92, \"learn_time_ms\": 9972.511, \"total_train_time_s\": 12.173117399215698}", "{\"n\": 16485, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3532.54, \"learn_time_ms\": 10078.439, \"total_train_time_s\": 12.893025159835815}", "{\"n\": 16486, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3532.54, \"learn_time_ms\": 10010.518, \"total_train_time_s\": 11.550199031829834}", "{\"n\": 16487, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3534.01, \"learn_time_ms\": 10114.286, \"total_train_time_s\": 12.662959337234497}", "{\"n\": 16488, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3535.45, \"learn_time_ms\": 10201.18, \"total_train_time_s\": 12.775612592697144}", "{\"n\": 16489, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3535.45, \"learn_time_ms\": 10132.892, \"total_train_time_s\": 11.651610374450684}", "{\"n\": 16490, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3536.06, \"learn_time_ms\": 10123.575, \"total_train_time_s\": 12.048952579498291}", "{\"n\": 16491, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3536.23, \"learn_time_ms\": 10150.943, \"total_train_time_s\": 11.604759454727173}", "{\"n\": 16492, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3533.43, \"learn_time_ms\": 10121.273, \"total_train_time_s\": 11.97792911529541}", "{\"n\": 16493, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3530.14, \"learn_time_ms\": 10219.813, \"total_train_time_s\": 12.111992120742798}", "{\"n\": 16494, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3520.37, \"learn_time_ms\": 10150.367, \"total_train_time_s\": 11.44144606590271}", "{\"n\": 16495, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3512.53, \"learn_time_ms\": 10047.143, \"total_train_time_s\": 11.90562891960144}", "{\"n\": 16496, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3509.56, \"learn_time_ms\": 10046.729, \"total_train_time_s\": 11.541263580322266}", "{\"n\": 16497, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3508.01, \"learn_time_ms\": 9946.824, \"total_train_time_s\": 11.557006597518921}", "{\"n\": 16498, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3507.93, \"learn_time_ms\": 9953.906, \"total_train_time_s\": 12.87481427192688}", "{\"n\": 16499, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3503.14, \"learn_time_ms\": 10050.377, \"total_train_time_s\": 12.612180233001709}", "{\"n\": 16500, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3503.14, \"learn_time_ms\": 10010.317, \"total_train_time_s\": 11.628405570983887}", "{\"n\": 16501, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3503.96, \"learn_time_ms\": 10111.566, \"total_train_time_s\": 12.634615898132324}", "{\"n\": 16502, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3497.48, \"learn_time_ms\": 10041.03, \"total_train_time_s\": 11.281313419342041}", "{\"n\": 16503, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3490.65, \"learn_time_ms\": 9922.431, \"total_train_time_s\": 10.900598049163818}", "{\"n\": 16504, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3491.6, \"learn_time_ms\": 9933.959, \"total_train_time_s\": 11.574345111846924}", "{\"n\": 16505, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3499.77, \"learn_time_ms\": 9971.53, \"total_train_time_s\": 12.266069889068604}", "{\"n\": 16506, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3498.42, \"learn_time_ms\": 10163.071, \"total_train_time_s\": 13.444553136825562}", "{\"n\": 16507, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3496.03, \"learn_time_ms\": 10260.723, \"total_train_time_s\": 12.51122784614563}", "{\"n\": 16508, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3492.99, \"learn_time_ms\": 10223.335, \"total_train_time_s\": 12.45746397972107}", "{\"n\": 16509, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3484.76, \"learn_time_ms\": 10194.783, \"total_train_time_s\": 12.305455684661865}", "{\"n\": 16510, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3500.49, \"learn_time_ms\": 10284.307, \"total_train_time_s\": 12.51466417312622}", "{\"n\": 16511, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3500.49, \"learn_time_ms\": 10286.856, \"total_train_time_s\": 12.644736766815186}", "{\"n\": 16512, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3493.27, \"learn_time_ms\": 10375.281, \"total_train_time_s\": 12.178988456726074}", "{\"n\": 16513, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3493.27, \"learn_time_ms\": 10492.183, \"total_train_time_s\": 12.094058513641357}", "{\"n\": 16514, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3503.2, \"learn_time_ms\": 10551.356, \"total_train_time_s\": 12.173184871673584}", "{\"n\": 16515, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.37, \"learn_time_ms\": 10494.372, \"total_train_time_s\": 11.695679903030396}", "{\"n\": 16516, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.37, \"learn_time_ms\": 10352.521, \"total_train_time_s\": 12.035648345947266}", "{\"n\": 16517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.33, \"learn_time_ms\": 10483.44, \"total_train_time_s\": 13.87138557434082}", "{\"n\": 16518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.21, \"learn_time_ms\": 10485.148, \"total_train_time_s\": 12.486903667449951}", "{\"n\": 16519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.49, \"learn_time_ms\": 10502.354, \"total_train_time_s\": 12.49839997291565}", "{\"n\": 16520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3527.68, \"learn_time_ms\": 10419.376, \"total_train_time_s\": 11.688626527786255}", "{\"n\": 16521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3535.42, \"learn_time_ms\": 10306.901, \"total_train_time_s\": 11.532668113708496}", "{\"n\": 16522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.82, \"learn_time_ms\": 10292.518, \"total_train_time_s\": 12.023984432220459}", "{\"n\": 16523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.82, \"learn_time_ms\": 10301.785, \"total_train_time_s\": 12.159298658370972}", "{\"n\": 16524, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.07, \"learn_time_ms\": 10323.768, \"total_train_time_s\": 12.375533819198608}", "{\"n\": 16525, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.86, \"learn_time_ms\": 10316.104, \"total_train_time_s\": 11.598076820373535}", "{\"n\": 16526, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.87, \"learn_time_ms\": 10255.265, \"total_train_time_s\": 11.408159494400024}", "{\"n\": 16527, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3507.96, \"learn_time_ms\": 10062.376, \"total_train_time_s\": 11.931838035583496}", "{\"n\": 16528, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3508.25, \"learn_time_ms\": 9933.423, \"total_train_time_s\": 11.188948392868042}", "{\"n\": 16529, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3508.25, \"learn_time_ms\": 9951.535, \"total_train_time_s\": 12.670846223831177}", "{\"n\": 16530, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.38, \"learn_time_ms\": 9994.25, \"total_train_time_s\": 12.12913203239441}", "{\"n\": 16531, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.87, \"learn_time_ms\": 10007.605, \"total_train_time_s\": 11.658012866973877}", "{\"n\": 16532, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.28, \"learn_time_ms\": 10012.043, \"total_train_time_s\": 12.050107717514038}", "{\"n\": 16533, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.64, \"learn_time_ms\": 10111.883, \"total_train_time_s\": 13.179181337356567}", "{\"n\": 16534, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.64, \"learn_time_ms\": 10109.905, \"total_train_time_s\": 12.34682035446167}", "{\"n\": 16535, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3520.53, \"learn_time_ms\": 10188.656, \"total_train_time_s\": 12.414013385772705}", "{\"n\": 16536, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.21, \"learn_time_ms\": 10277.167, \"total_train_time_s\": 12.311401844024658}", "{\"n\": 16537, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.21, \"learn_time_ms\": 10207.691, \"total_train_time_s\": 11.209799528121948}", "{\"n\": 16538, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.23, \"learn_time_ms\": 10362.443, \"total_train_time_s\": 12.718170881271362}", "{\"n\": 16539, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.18, \"learn_time_ms\": 10262.655, \"total_train_time_s\": 11.665103673934937}", "{\"n\": 16540, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3511.28, \"learn_time_ms\": 10319.936, \"total_train_time_s\": 12.706666231155396}", "{\"n\": 16541, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3511.28, \"learn_time_ms\": 10323.367, \"total_train_time_s\": 11.690433025360107}", "{\"n\": 16542, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3505.35, \"learn_time_ms\": 10231.397, \"total_train_time_s\": 11.14400577545166}", "{\"n\": 16543, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3503.74, \"learn_time_ms\": 10179.508, \"total_train_time_s\": 12.651033878326416}", "{\"n\": 16544, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3503.74, \"learn_time_ms\": 10186.023, \"total_train_time_s\": 12.417617559432983}", "{\"n\": 16545, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3505.84, \"learn_time_ms\": 10089.531, \"total_train_time_s\": 11.463838338851929}", "{\"n\": 16546, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3489.24, \"learn_time_ms\": 10160.208, \"total_train_time_s\": 13.078559875488281}", "{\"n\": 16547, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3489.24, \"learn_time_ms\": 10274.249, \"total_train_time_s\": 12.315335512161255}", "{\"n\": 16548, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3489.24, \"learn_time_ms\": 10313.982, \"total_train_time_s\": 13.13582444190979}", "{\"n\": 16549, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3476.9, \"learn_time_ms\": 10432.475, \"total_train_time_s\": 12.858282804489136}", "{\"n\": 16550, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3483.65, \"learn_time_ms\": 10308.755, \"total_train_time_s\": 11.463447332382202}", "{\"n\": 16551, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3483.65, \"learn_time_ms\": 10398.77, \"total_train_time_s\": 12.587717533111572}", "{\"n\": 16552, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3478.8, \"learn_time_ms\": 10525.579, \"total_train_time_s\": 12.418132066726685}", "{\"n\": 16553, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3489.54, \"learn_time_ms\": 10545.918, \"total_train_time_s\": 12.876863956451416}", "{\"n\": 16554, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3501.54, \"learn_time_ms\": 10549.537, \"total_train_time_s\": 12.415641069412231}", "{\"n\": 16555, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.88, \"learn_time_ms\": 10625.57, \"total_train_time_s\": 12.169597625732422}", "{\"n\": 16556, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3483.04, \"learn_time_ms\": 10595.441, \"total_train_time_s\": 12.757936716079712}", "{\"n\": 16557, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3484.32, \"learn_time_ms\": 10603.198, \"total_train_time_s\": 12.432472705841064}", "{\"n\": 16558, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3481.58, \"learn_time_ms\": 10598.345, \"total_train_time_s\": 13.083820581436157}", "{\"n\": 16559, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3482.69, \"learn_time_ms\": 10459.296, \"total_train_time_s\": 11.437950611114502}", "{\"n\": 16560, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3490.95, \"learn_time_ms\": 10520.745, \"total_train_time_s\": 12.08131718635559}", "{\"n\": 16561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3490.95, \"learn_time_ms\": 10399.625, \"total_train_time_s\": 11.405505180358887}", "{\"n\": 16562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3502.02, \"learn_time_ms\": 10481.974, \"total_train_time_s\": 13.23351526260376}", "{\"n\": 16563, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3491.93, \"learn_time_ms\": 10489.946, \"total_train_time_s\": 12.982035160064697}", "{\"n\": 16564, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3497.01, \"learn_time_ms\": 10511.164, \"total_train_time_s\": 12.653232336044312}", "{\"n\": 16565, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3502.0, \"learn_time_ms\": 10467.557, \"total_train_time_s\": 11.728036642074585}", "{\"n\": 16566, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3500.57, \"learn_time_ms\": 10422.223, \"total_train_time_s\": 12.25285816192627}", "{\"n\": 16567, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3504.97, \"learn_time_ms\": 10379.339, \"total_train_time_s\": 12.01769495010376}", "{\"n\": 16568, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3504.97, \"learn_time_ms\": 10267.442, \"total_train_time_s\": 11.94809365272522}", "{\"n\": 16569, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3512.1, \"learn_time_ms\": 10304.65, \"total_train_time_s\": 11.827918291091919}", "{\"n\": 16570, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3508.96, \"learn_time_ms\": 10230.003, \"total_train_time_s\": 11.368609428405762}", "{\"n\": 16571, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3516.34, \"learn_time_ms\": 10259.446, \"total_train_time_s\": 11.701914310455322}", "{\"n\": 16572, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3516.34, \"learn_time_ms\": 10124.805, \"total_train_time_s\": 11.94858694076538}", "{\"n\": 16573, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3521.02, \"learn_time_ms\": 10137.136, \"total_train_time_s\": 13.071962118148804}", "{\"n\": 16574, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3523.27, \"learn_time_ms\": 10082.51, \"total_train_time_s\": 12.12973666191101}", "{\"n\": 16575, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3525.06, \"learn_time_ms\": 10093.598, \"total_train_time_s\": 11.873379468917847}", "{\"n\": 16576, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3527.52, \"learn_time_ms\": 10119.46, \"total_train_time_s\": 12.525439500808716}", "{\"n\": 16577, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3540.22, \"learn_time_ms\": 10247.807, \"total_train_time_s\": 13.31919264793396}", "{\"n\": 16578, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 10201.328, \"total_train_time_s\": 11.500879764556885}", "{\"n\": 16579, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 10290.934, \"total_train_time_s\": 12.745672702789307}", "{\"n\": 16580, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3540.58, \"learn_time_ms\": 10439.581, \"total_train_time_s\": 12.807985067367554}", "{\"n\": 16581, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3543.63, \"learn_time_ms\": 10494.525, \"total_train_time_s\": 12.213464736938477}", "{\"n\": 16582, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3542.24, \"learn_time_ms\": 10481.868, \"total_train_time_s\": 11.769443273544312}", "{\"n\": 16583, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3547.52, \"learn_time_ms\": 10444.426, \"total_train_time_s\": 12.694327592849731}", "{\"n\": 16584, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3547.52, \"learn_time_ms\": 10348.17, \"total_train_time_s\": 11.148410558700562}", "{\"n\": 16585, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.37, \"learn_time_ms\": 10380.502, \"total_train_time_s\": 12.163144826889038}", "{\"n\": 16586, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.37, \"learn_time_ms\": 10313.291, \"total_train_time_s\": 11.84448790550232}", "{\"n\": 16587, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3550.21, \"learn_time_ms\": 10231.908, \"total_train_time_s\": 12.490195989608765}", "{\"n\": 16588, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3546.32, \"learn_time_ms\": 10305.202, \"total_train_time_s\": 12.260883808135986}", "{\"n\": 16589, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3550.19, \"learn_time_ms\": 10184.227, \"total_train_time_s\": 11.52263879776001}", "{\"n\": 16590, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3552.57, \"learn_time_ms\": 10047.178, \"total_train_time_s\": 11.438965082168579}", "{\"n\": 16591, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3552.57, \"learn_time_ms\": 10069.121, \"total_train_time_s\": 12.462384462356567}", "{\"n\": 16592, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3564.51, \"learn_time_ms\": 9948.639, \"total_train_time_s\": 10.569255113601685}", "{\"n\": 16593, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3564.51, \"learn_time_ms\": 9881.103, \"total_train_time_s\": 12.003174066543579}", "{\"n\": 16594, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3564.51, \"learn_time_ms\": 9990.542, \"total_train_time_s\": 12.225110292434692}", "{\"n\": 16595, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.41, \"learn_time_ms\": 9986.046, \"total_train_time_s\": 12.143779993057251}", "{\"n\": 16596, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3559.89, \"learn_time_ms\": 10076.002, \"total_train_time_s\": 12.750004053115845}", "{\"n\": 16597, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3559.89, \"learn_time_ms\": 10010.496, \"total_train_time_s\": 11.815443277359009}", "{\"n\": 16598, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.49, \"learn_time_ms\": 10095.6, \"total_train_time_s\": 13.118773460388184}", "{\"n\": 16599, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.11, \"learn_time_ms\": 10153.873, \"total_train_time_s\": 12.082446575164795}", "{\"n\": 16600, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.11, \"learn_time_ms\": 10267.696, \"total_train_time_s\": 12.549355745315552}", "{\"n\": 16601, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.87, \"learn_time_ms\": 10243.588, \"total_train_time_s\": 12.286882400512695}", "{\"n\": 16602, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.87, \"learn_time_ms\": 10431.991, \"total_train_time_s\": 12.530847311019897}", "{\"n\": 16603, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.17, \"learn_time_ms\": 10337.511, \"total_train_time_s\": 11.086881637573242}", "{\"n\": 16604, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.17, \"learn_time_ms\": 10399.587, \"total_train_time_s\": 12.891445875167847}", "{\"n\": 16605, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3567.17, \"learn_time_ms\": 10359.811, \"total_train_time_s\": 11.745684146881104}", "{\"n\": 16606, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.15, \"learn_time_ms\": 10225.666, \"total_train_time_s\": 11.419276475906372}", "{\"n\": 16607, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.15, \"learn_time_ms\": 10218.673, \"total_train_time_s\": 11.71623945236206}", "{\"n\": 16608, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.53, \"learn_time_ms\": 10231.507, \"total_train_time_s\": 13.238657474517822}", "{\"n\": 16609, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.53, \"learn_time_ms\": 10168.093, \"total_train_time_s\": 11.483155727386475}", "{\"n\": 16610, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.68, \"learn_time_ms\": 10048.998, \"total_train_time_s\": 11.39814281463623}", "{\"n\": 16611, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10029.79, \"total_train_time_s\": 12.07800579071045}", "{\"n\": 16612, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 10066.017, \"total_train_time_s\": 12.796045303344727}", "{\"n\": 16613, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.8, \"learn_time_ms\": 10198.117, \"total_train_time_s\": 12.38357663154602}", "{\"n\": 16614, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.41, \"learn_time_ms\": 10135.177, \"total_train_time_s\": 12.260742902755737}", "{\"n\": 16615, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.88, \"learn_time_ms\": 10209.031, \"total_train_time_s\": 12.43586277961731}", "{\"n\": 16616, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.88, \"learn_time_ms\": 10297.623, \"total_train_time_s\": 12.288946628570557}", "{\"n\": 16617, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.39, \"learn_time_ms\": 10330.499, \"total_train_time_s\": 12.08013129234314}", "{\"n\": 16618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 10120.519, \"total_train_time_s\": 11.132763624191284}", "{\"n\": 16619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.81, \"learn_time_ms\": 10202.017, \"total_train_time_s\": 12.30976390838623}", "{\"n\": 16620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.36, \"learn_time_ms\": 10235.401, \"total_train_time_s\": 11.714446067810059}", "{\"n\": 16621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.81, \"learn_time_ms\": 10244.354, \"total_train_time_s\": 12.064208507537842}", "{\"n\": 16622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.97, \"learn_time_ms\": 10195.931, \"total_train_time_s\": 12.34565544128418}", "{\"n\": 16623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.97, \"learn_time_ms\": 10160.75, \"total_train_time_s\": 12.044901132583618}", "{\"n\": 16624, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.33, \"learn_time_ms\": 10056.505, \"total_train_time_s\": 11.228710651397705}", "{\"n\": 16625, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.59, \"learn_time_ms\": 10013.665, \"total_train_time_s\": 12.062676429748535}", "{\"n\": 16626, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.06, \"learn_time_ms\": 9948.4, \"total_train_time_s\": 11.623274326324463}", "{\"n\": 16627, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.88, \"learn_time_ms\": 9956.968, \"total_train_time_s\": 12.180078029632568}", "{\"n\": 16628, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.63, \"learn_time_ms\": 9994.989, \"total_train_time_s\": 11.498930931091309}", "{\"n\": 16629, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.61, \"learn_time_ms\": 9890.799, \"total_train_time_s\": 11.23351526260376}", "{\"n\": 16630, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.4, \"learn_time_ms\": 9867.858, \"total_train_time_s\": 11.476626634597778}", "{\"n\": 16631, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.4, \"learn_time_ms\": 9849.879, \"total_train_time_s\": 11.945504188537598}", "{\"n\": 16632, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.41, \"learn_time_ms\": 9882.928, \"total_train_time_s\": 12.663507223129272}", "{\"n\": 16633, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.01, \"learn_time_ms\": 9819.638, \"total_train_time_s\": 11.449537992477417}", "{\"n\": 16634, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.95, \"learn_time_ms\": 9866.38, \"total_train_time_s\": 11.647325277328491}", "{\"n\": 16635, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.95, \"learn_time_ms\": 9928.237, \"total_train_time_s\": 12.674998044967651}", "{\"n\": 16636, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.47, \"learn_time_ms\": 10024.849, \"total_train_time_s\": 12.610343217849731}", "{\"n\": 16637, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.41, \"learn_time_ms\": 10051.345, \"total_train_time_s\": 12.47000002861023}", "{\"n\": 16638, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.23, \"learn_time_ms\": 10025.032, \"total_train_time_s\": 11.259919881820679}", "{\"n\": 16639, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.66, \"learn_time_ms\": 10078.008, \"total_train_time_s\": 11.75898289680481}", "{\"n\": 16640, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.38, \"learn_time_ms\": 10104.313, \"total_train_time_s\": 11.7772798538208}", "{\"n\": 16641, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.02, \"learn_time_ms\": 10054.677, \"total_train_time_s\": 11.4370596408844}", "{\"n\": 16642, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.02, \"learn_time_ms\": 9972.012, \"total_train_time_s\": 11.80820918083191}", "{\"n\": 16643, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.42, \"learn_time_ms\": 10091.434, \"total_train_time_s\": 12.618645906448364}", "{\"n\": 16644, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.96, \"learn_time_ms\": 10184.07, \"total_train_time_s\": 12.669991970062256}", "{\"n\": 16645, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.52, \"learn_time_ms\": 10068.759, \"total_train_time_s\": 11.51134967803955}", "{\"n\": 16646, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.88, \"learn_time_ms\": 9998.148, \"total_train_time_s\": 11.946741580963135}", "{\"n\": 16647, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.73, \"learn_time_ms\": 9969.072, \"total_train_time_s\": 12.136467456817627}", "{\"n\": 16648, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.7, \"learn_time_ms\": 9956.379, \"total_train_time_s\": 11.084737062454224}", "{\"n\": 16649, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.04, \"learn_time_ms\": 9927.347, \"total_train_time_s\": 11.533828258514404}", "{\"n\": 16650, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.85, \"learn_time_ms\": 10009.683, \"total_train_time_s\": 12.607688665390015}", "{\"n\": 16651, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3626.43, \"learn_time_ms\": 10056.807, \"total_train_time_s\": 11.902544975280762}", "{\"n\": 16652, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.06, \"learn_time_ms\": 9980.551, \"total_train_time_s\": 11.043470859527588}", "{\"n\": 16653, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.59, \"learn_time_ms\": 9885.494, \"total_train_time_s\": 11.647122859954834}", "{\"n\": 16654, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.59, \"learn_time_ms\": 9931.154, \"total_train_time_s\": 13.049615144729614}", "{\"n\": 16655, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.19, \"learn_time_ms\": 10026.48, \"total_train_time_s\": 12.47458028793335}", "{\"n\": 16656, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.19, \"learn_time_ms\": 10032.787, \"total_train_time_s\": 11.929884672164917}", "{\"n\": 16657, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3619.84, \"learn_time_ms\": 10083.365, \"total_train_time_s\": 12.67336130142212}", "{\"n\": 16658, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.23, \"learn_time_ms\": 10118.707, \"total_train_time_s\": 11.5046865940094}", "{\"n\": 16659, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.63, \"learn_time_ms\": 10207.201, \"total_train_time_s\": 12.459966897964478}", "{\"n\": 16660, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.99, \"learn_time_ms\": 10167.907, \"total_train_time_s\": 12.175934553146362}", "{\"n\": 16661, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.99, \"learn_time_ms\": 10157.314, \"total_train_time_s\": 11.778079509735107}", "{\"n\": 16662, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.9, \"learn_time_ms\": 10213.759, \"total_train_time_s\": 11.654502391815186}", "{\"n\": 16663, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.06, \"learn_time_ms\": 10284.028, \"total_train_time_s\": 12.373722791671753}", "{\"n\": 16664, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.87, \"learn_time_ms\": 10212.434, \"total_train_time_s\": 12.314175844192505}", "{\"n\": 16665, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.56, \"learn_time_ms\": 10136.133, \"total_train_time_s\": 11.685482025146484}", "{\"n\": 16666, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.44, \"learn_time_ms\": 10175.621, \"total_train_time_s\": 12.352652549743652}", "{\"n\": 16667, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.15, \"learn_time_ms\": 10236.134, \"total_train_time_s\": 13.24526071548462}", "{\"n\": 16668, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.15, \"learn_time_ms\": 10243.345, \"total_train_time_s\": 11.496622562408447}", "{\"n\": 16669, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 10251.977, \"total_train_time_s\": 12.43818473815918}", "{\"n\": 16670, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.98, \"learn_time_ms\": 10188.729, \"total_train_time_s\": 11.49353837966919}", "{\"n\": 16671, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.01, \"learn_time_ms\": 10305.05, \"total_train_time_s\": 12.962320327758789}", "{\"n\": 16672, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.05, \"learn_time_ms\": 10228.364, \"total_train_time_s\": 10.897217273712158}", "{\"n\": 16673, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.05, \"learn_time_ms\": 10215.81, \"total_train_time_s\": 12.203265905380249}", "{\"n\": 16674, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.72, \"learn_time_ms\": 10082.024, \"total_train_time_s\": 11.015330076217651}", "{\"n\": 16675, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.47, \"learn_time_ms\": 10129.321, \"total_train_time_s\": 12.143179893493652}", "{\"n\": 16676, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.27, \"learn_time_ms\": 10084.801, \"total_train_time_s\": 11.923319101333618}", "{\"n\": 16677, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.27, \"learn_time_ms\": 9940.656, \"total_train_time_s\": 11.800689458847046}", "{\"n\": 16678, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.59, \"learn_time_ms\": 9973.648, \"total_train_time_s\": 11.875550270080566}", "{\"n\": 16679, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.84, \"learn_time_ms\": 10014.27, \"total_train_time_s\": 12.899120569229126}", "{\"n\": 16680, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.84, \"learn_time_ms\": 10003.946, \"total_train_time_s\": 11.46381688117981}", "{\"n\": 16681, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.84, \"learn_time_ms\": 9899.808, \"total_train_time_s\": 11.929802894592285}", "{\"n\": 16682, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.52, \"learn_time_ms\": 10116.294, \"total_train_time_s\": 13.050361156463623}", "{\"n\": 16683, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.39, \"learn_time_ms\": 10126.268, \"total_train_time_s\": 12.367091178894043}", "{\"n\": 16684, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.39, \"learn_time_ms\": 10154.802, \"total_train_time_s\": 11.33034062385559}", "{\"n\": 16685, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.05, \"learn_time_ms\": 10111.586, \"total_train_time_s\": 11.774561882019043}", "{\"n\": 16686, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.46, \"learn_time_ms\": 10106.973, \"total_train_time_s\": 11.86437201499939}", "{\"n\": 16687, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.46, \"learn_time_ms\": 10177.762, \"total_train_time_s\": 12.507657289505005}", "{\"n\": 16688, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.46, \"learn_time_ms\": 10230.498, \"total_train_time_s\": 12.411141157150269}", "{\"n\": 16689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.27, \"learn_time_ms\": 10178.699, \"total_train_time_s\": 12.33855676651001}", "{\"n\": 16690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.11, \"learn_time_ms\": 10160.211, \"total_train_time_s\": 11.276596069335938}", "{\"n\": 16691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.11, \"learn_time_ms\": 10128.687, \"total_train_time_s\": 11.604318380355835}", "{\"n\": 16692, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.7, \"learn_time_ms\": 10078.275, \"total_train_time_s\": 12.535802364349365}", "{\"n\": 16693, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.73, \"learn_time_ms\": 10009.616, \"total_train_time_s\": 11.703346252441406}", "{\"n\": 16694, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.63, \"learn_time_ms\": 10096.832, \"total_train_time_s\": 12.184498310089111}", "{\"n\": 16695, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.63, \"learn_time_ms\": 10057.929, \"total_train_time_s\": 11.344458818435669}", "{\"n\": 16696, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.16, \"learn_time_ms\": 10159.031, \"total_train_time_s\": 12.864468574523926}", "{\"n\": 16697, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.93, \"learn_time_ms\": 10103.168, \"total_train_time_s\": 11.947767496109009}", "{\"n\": 16698, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.93, \"learn_time_ms\": 10010.851, \"total_train_time_s\": 11.491558313369751}", "{\"n\": 16699, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3610.59, \"learn_time_ms\": 9953.27, \"total_train_time_s\": 11.769184350967407}", "{\"n\": 16700, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.5, \"learn_time_ms\": 10008.466, \"total_train_time_s\": 11.80777907371521}", "{\"n\": 16701, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.75, \"learn_time_ms\": 10078.436, \"total_train_time_s\": 12.293325662612915}", "{\"n\": 16702, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.75, \"learn_time_ms\": 10002.589, \"total_train_time_s\": 11.765706062316895}", "{\"n\": 16703, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.68, \"learn_time_ms\": 10100.597, \"total_train_time_s\": 12.625215768814087}", "{\"n\": 16704, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3605.73, \"learn_time_ms\": 10145.353, \"total_train_time_s\": 12.623077869415283}", "{\"n\": 16705, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3616.79, \"learn_time_ms\": 10252.57, \"total_train_time_s\": 12.431586027145386}", "{\"n\": 16706, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.42, \"learn_time_ms\": 10141.589, \"total_train_time_s\": 11.723536968231201}", "{\"n\": 16707, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.42, \"learn_time_ms\": 10165.867, \"total_train_time_s\": 12.163260698318481}", "{\"n\": 16708, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.65, \"learn_time_ms\": 10208.59, \"total_train_time_s\": 11.88486909866333}", "{\"n\": 16709, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3608.9, \"learn_time_ms\": 10294.401, \"total_train_time_s\": 12.642411947250366}", "{\"n\": 16710, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.6, \"learn_time_ms\": 10244.933, \"total_train_time_s\": 11.316824674606323}", "{\"n\": 16711, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.61, \"learn_time_ms\": 10218.47, \"total_train_time_s\": 12.01475977897644}", "{\"n\": 16712, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.89, \"learn_time_ms\": 10235.794, \"total_train_time_s\": 11.915779829025269}", "{\"n\": 16713, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.38, \"learn_time_ms\": 10168.284, \"total_train_time_s\": 11.939319610595703}", "{\"n\": 16714, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3590.01, \"learn_time_ms\": 9991.538, \"total_train_time_s\": 10.887328147888184}", "{\"n\": 16715, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3583.3, \"learn_time_ms\": 9926.702, \"total_train_time_s\": 11.802148818969727}", "{\"n\": 16716, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.04, \"learn_time_ms\": 10100.514, \"total_train_time_s\": 13.515676975250244}", "{\"n\": 16717, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.04, \"learn_time_ms\": 10192.532, \"total_train_time_s\": 13.094184875488281}", "{\"n\": 16718, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3591.81, \"learn_time_ms\": 10228.022, \"total_train_time_s\": 12.240998983383179}", "{\"n\": 16719, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.03, \"learn_time_ms\": 10169.429, \"total_train_time_s\": 12.074171304702759}", "{\"n\": 16720, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.67, \"learn_time_ms\": 10242.169, \"total_train_time_s\": 12.060806274414062}", "{\"n\": 16721, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.61, \"learn_time_ms\": 10169.369, \"total_train_time_s\": 11.352951765060425}", "{\"n\": 16722, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.19, \"learn_time_ms\": 10135.408, \"total_train_time_s\": 11.614973545074463}", "{\"n\": 16723, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.58, \"learn_time_ms\": 10150.708, \"total_train_time_s\": 12.117810010910034}", "{\"n\": 16724, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.27, \"learn_time_ms\": 10295.254, \"total_train_time_s\": 12.373422861099243}", "{\"n\": 16725, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.27, \"learn_time_ms\": 10359.418, \"total_train_time_s\": 12.473633527755737}", "{\"n\": 16726, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.85, \"learn_time_ms\": 10169.404, \"total_train_time_s\": 11.626279354095459}", "{\"n\": 16727, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.85, \"learn_time_ms\": 10135.16, \"total_train_time_s\": 12.713673830032349}", "{\"n\": 16728, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.51, \"learn_time_ms\": 10122.634, \"total_train_time_s\": 12.122649431228638}", "{\"n\": 16729, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.71, \"learn_time_ms\": 10210.381, \"total_train_time_s\": 12.912666082382202}", "{\"n\": 16730, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.4, \"learn_time_ms\": 10268.492, \"total_train_time_s\": 12.60560941696167}", "{\"n\": 16731, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.4, \"learn_time_ms\": 10291.75, \"total_train_time_s\": 11.550114154815674}", "{\"n\": 16732, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.16, \"learn_time_ms\": 10313.669, \"total_train_time_s\": 11.822306632995605}", "{\"n\": 16733, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.74, \"learn_time_ms\": 10347.613, \"total_train_time_s\": 12.403748035430908}", "{\"n\": 16734, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.63, \"learn_time_ms\": 10379.44, \"total_train_time_s\": 12.549497604370117}", "{\"n\": 16735, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.01, \"learn_time_ms\": 10286.64, \"total_train_time_s\": 11.608517169952393}", "{\"n\": 16736, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3588.29, \"learn_time_ms\": 10309.655, \"total_train_time_s\": 11.86227035522461}", "{\"n\": 16737, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3588.07, \"learn_time_ms\": 10279.426, \"total_train_time_s\": 12.494182348251343}", "{\"n\": 16738, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.31, \"learn_time_ms\": 10310.319, \"total_train_time_s\": 12.419650077819824}", "{\"n\": 16739, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3591.3, \"learn_time_ms\": 10155.556, \"total_train_time_s\": 11.363961458206177}", "{\"n\": 16740, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3591.3, \"learn_time_ms\": 10074.482, \"total_train_time_s\": 11.814809799194336}", "{\"n\": 16741, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.84, \"learn_time_ms\": 10162.445, \"total_train_time_s\": 12.449899435043335}", "{\"n\": 16742, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3587.64, \"learn_time_ms\": 10219.893, \"total_train_time_s\": 12.413416624069214}", "{\"n\": 16743, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3583.55, \"learn_time_ms\": 10144.634, \"total_train_time_s\": 11.723002195358276}", "{\"n\": 16744, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3583.55, \"learn_time_ms\": 10077.578, \"total_train_time_s\": 12.0006582736969}", "{\"n\": 16745, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.13, \"learn_time_ms\": 10244.917, \"total_train_time_s\": 13.179187774658203}", "{\"n\": 16746, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.71, \"learn_time_ms\": 10280.432, \"total_train_time_s\": 12.240370512008667}", "{\"n\": 16747, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.43, \"learn_time_ms\": 10254.328, \"total_train_time_s\": 12.19994068145752}", "{\"n\": 16748, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.66, \"learn_time_ms\": 10223.73, \"total_train_time_s\": 12.122494459152222}", "{\"n\": 16749, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.86, \"learn_time_ms\": 10388.652, \"total_train_time_s\": 13.061456441879272}", "{\"n\": 16750, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.47, \"learn_time_ms\": 10399.6, \"total_train_time_s\": 11.967997550964355}", "{\"n\": 16751, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.47, \"learn_time_ms\": 10401.333, \"total_train_time_s\": 12.425156354904175}", "{\"n\": 16752, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.95, \"learn_time_ms\": 10308.626, \"total_train_time_s\": 11.490252256393433}", "{\"n\": 16753, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.86, \"learn_time_ms\": 10295.1, \"total_train_time_s\": 11.587724685668945}", "{\"n\": 16754, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.03, \"learn_time_ms\": 10297.784, \"total_train_time_s\": 11.928034782409668}", "{\"n\": 16755, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.03, \"learn_time_ms\": 10192.999, \"total_train_time_s\": 12.117757797241211}", "{\"n\": 16756, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.51, \"learn_time_ms\": 10087.174, \"total_train_time_s\": 11.112690448760986}", "{\"n\": 16757, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.7, \"learn_time_ms\": 9964.691, \"total_train_time_s\": 10.976718425750732}", "{\"n\": 16758, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.18, \"learn_time_ms\": 9965.449, \"total_train_time_s\": 12.117332935333252}", "{\"n\": 16759, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.18, \"learn_time_ms\": 9823.462, \"total_train_time_s\": 11.596731662750244}", "{\"n\": 16760, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.84, \"learn_time_ms\": 9734.432, \"total_train_time_s\": 11.048673152923584}", "{\"n\": 16761, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.11, \"learn_time_ms\": 9732.992, \"total_train_time_s\": 12.461689949035645}", "{\"n\": 16762, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.11, \"learn_time_ms\": 9913.044, \"total_train_time_s\": 13.281013488769531}", "{\"n\": 16763, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.01, \"learn_time_ms\": 9900.3, \"total_train_time_s\": 11.433956623077393}", "{\"n\": 16764, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.15, \"learn_time_ms\": 9896.013, \"total_train_time_s\": 11.939376831054688}", "{\"n\": 16765, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.2, \"learn_time_ms\": 9736.192, \"total_train_time_s\": 10.504379272460938}", "{\"n\": 16766, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.2, \"learn_time_ms\": 9745.848, \"total_train_time_s\": 11.177062511444092}", "{\"n\": 16767, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.63, \"learn_time_ms\": 9889.567, \"total_train_time_s\": 12.451008081436157}", "{\"n\": 16768, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3598.63, \"learn_time_ms\": 9917.324, \"total_train_time_s\": 12.415911436080933}", "{\"n\": 16769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 9959.687, \"total_train_time_s\": 12.060055255889893}", "{\"n\": 16770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 10134.695, \"total_train_time_s\": 12.809727907180786}", "{\"n\": 16771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.0, \"learn_time_ms\": 10119.181, \"total_train_time_s\": 12.298704385757446}", "{\"n\": 16772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3607.33, \"learn_time_ms\": 10078.788, \"total_train_time_s\": 12.882254838943481}", "{\"n\": 16773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3607.33, \"learn_time_ms\": 10225.565, \"total_train_time_s\": 12.917854309082031}", "{\"n\": 16774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.51, \"learn_time_ms\": 10186.994, \"total_train_time_s\": 11.522801160812378}", "{\"n\": 16775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3615.7, \"learn_time_ms\": 10438.915, \"total_train_time_s\": 13.072029113769531}", "{\"n\": 16776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.42, \"learn_time_ms\": 10523.305, \"total_train_time_s\": 12.062315940856934}", "{\"n\": 16777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.42, \"learn_time_ms\": 10513.094, \"total_train_time_s\": 12.301833629608154}", "{\"n\": 16778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3614.87, \"learn_time_ms\": 10383.179, \"total_train_time_s\": 11.084531784057617}", "{\"n\": 16779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.25, \"learn_time_ms\": 10385.308, \"total_train_time_s\": 12.076866149902344}", "{\"n\": 16780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3620.25, \"learn_time_ms\": 10288.778, \"total_train_time_s\": 11.814618349075317}", "{\"n\": 16781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.89, \"learn_time_ms\": 10244.075, \"total_train_time_s\": 11.835857391357422}", "{\"n\": 16782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3617.6, \"learn_time_ms\": 10115.701, \"total_train_time_s\": 11.60959792137146}", "{\"n\": 16783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10110.795, \"total_train_time_s\": 12.826172828674316}", "{\"n\": 16784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3610.35, \"learn_time_ms\": 10146.081, \"total_train_time_s\": 11.90891408920288}", "{\"n\": 16785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3615.48, \"learn_time_ms\": 10119.418, \"total_train_time_s\": 12.772089719772339}", "{\"n\": 16786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3616.12, \"learn_time_ms\": 10218.384, \"total_train_time_s\": 13.033631563186646}", "{\"n\": 16787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3609.74, \"learn_time_ms\": 10198.544, \"total_train_time_s\": 12.129247903823853}", "{\"n\": 16788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3609.74, \"learn_time_ms\": 10303.223, \"total_train_time_s\": 12.16804838180542}", "{\"n\": 16789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3586.88, \"learn_time_ms\": 10225.223, \"total_train_time_s\": 11.268304347991943}", "{\"n\": 16790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.27, \"learn_time_ms\": 10218.971, \"total_train_time_s\": 11.729913711547852}", "{\"n\": 16791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3599.98, \"learn_time_ms\": 10210.577, \"total_train_time_s\": 11.71528434753418}", "{\"n\": 16792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.05, \"learn_time_ms\": 10371.106, \"total_train_time_s\": 13.213133573532104}", "{\"n\": 16793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.05, \"learn_time_ms\": 10336.312, \"total_train_time_s\": 12.480312585830688}", "{\"n\": 16794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3596.68, \"learn_time_ms\": 10319.125, \"total_train_time_s\": 11.70426869392395}", "{\"n\": 16795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.08, \"learn_time_ms\": 10195.754, \"total_train_time_s\": 11.55201530456543}", "{\"n\": 16796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.08, \"learn_time_ms\": 10129.303, \"total_train_time_s\": 12.390381813049316}", "{\"n\": 16797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.57, \"learn_time_ms\": 10229.306, \"total_train_time_s\": 13.110846042633057}", "{\"n\": 16798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.81, \"learn_time_ms\": 10166.153, \"total_train_time_s\": 11.550763368606567}", "{\"n\": 16799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.9, \"learn_time_ms\": 10302.382, \"total_train_time_s\": 12.681172609329224}", "{\"n\": 16800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.9, \"learn_time_ms\": 10320.358, \"total_train_time_s\": 11.946837902069092}", "{\"n\": 16801, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3590.43, \"learn_time_ms\": 10266.325, \"total_train_time_s\": 11.206343412399292}", "{\"n\": 16802, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.18, \"learn_time_ms\": 10149.603, \"total_train_time_s\": 12.019262075424194}", "{\"n\": 16803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.97, \"learn_time_ms\": 10075.005, \"total_train_time_s\": 11.761862993240356}", "{\"n\": 16804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.97, \"learn_time_ms\": 10112.791, \"total_train_time_s\": 12.08338975906372}", "{\"n\": 16805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.19, \"learn_time_ms\": 10123.213, \"total_train_time_s\": 11.656171560287476}", "{\"n\": 16806, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.15, \"learn_time_ms\": 9973.863, \"total_train_time_s\": 10.896150827407837}", "{\"n\": 16807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.28, \"learn_time_ms\": 9885.306, \"total_train_time_s\": 12.265626668930054}", "{\"n\": 16808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.28, \"learn_time_ms\": 9989.81, \"total_train_time_s\": 12.563307046890259}", "{\"n\": 16809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.91, \"learn_time_ms\": 9990.435, \"total_train_time_s\": 12.607445001602173}", "{\"n\": 16810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.53, \"learn_time_ms\": 10045.227, \"total_train_time_s\": 12.452672958374023}", "{\"n\": 16811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.12, \"learn_time_ms\": 10163.733, \"total_train_time_s\": 12.391708135604858}", "{\"n\": 16812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.12, \"learn_time_ms\": 10109.559, \"total_train_time_s\": 11.461298942565918}", "{\"n\": 16813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.28, \"learn_time_ms\": 10118.018, \"total_train_time_s\": 11.840307474136353}", "{\"n\": 16814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.1, \"learn_time_ms\": 10099.041, \"total_train_time_s\": 11.90476393699646}", "{\"n\": 16815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.91, \"learn_time_ms\": 10273.558, \"total_train_time_s\": 13.433107852935791}", "{\"n\": 16816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.91, \"learn_time_ms\": 10427.537, \"total_train_time_s\": 12.49189281463623}", "{\"n\": 16817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.91, \"learn_time_ms\": 10437.607, \"total_train_time_s\": 12.38577914237976}", "{\"n\": 16818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.65, \"learn_time_ms\": 10305.031, \"total_train_time_s\": 11.297293663024902}", "{\"n\": 16819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.48, \"learn_time_ms\": 10301.514, \"total_train_time_s\": 12.618278741836548}", "{\"n\": 16820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.45, \"learn_time_ms\": 10214.368, \"total_train_time_s\": 11.619282007217407}", "{\"n\": 16821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.63, \"learn_time_ms\": 10121.724, \"total_train_time_s\": 11.457822561264038}", "{\"n\": 16822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.6, \"learn_time_ms\": 10162.752, \"total_train_time_s\": 11.903978109359741}", "{\"n\": 16823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.18, \"learn_time_ms\": 10265.055, \"total_train_time_s\": 12.886587381362915}", "{\"n\": 16824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.58, \"learn_time_ms\": 10308.153, \"total_train_time_s\": 12.36656403541565}", "{\"n\": 16825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.23, \"learn_time_ms\": 10249.044, \"total_train_time_s\": 12.822601318359375}", "{\"n\": 16826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.23, \"learn_time_ms\": 10154.251, \"total_train_time_s\": 11.480694770812988}", "{\"n\": 16827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 10042.768, \"total_train_time_s\": 11.19327998161316}", "{\"n\": 16828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 10086.632, \"total_train_time_s\": 11.667801141738892}", "{\"n\": 16829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.44, \"learn_time_ms\": 10052.451, \"total_train_time_s\": 12.275050163269043}", "{\"n\": 16830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.79, \"learn_time_ms\": 10003.01, \"total_train_time_s\": 11.13624906539917}", "{\"n\": 16831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.53, \"learn_time_ms\": 10098.399, \"total_train_time_s\": 12.437057971954346}", "{\"n\": 16832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.84, \"learn_time_ms\": 10088.362, \"total_train_time_s\": 11.80938982963562}", "{\"n\": 16833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.03, \"learn_time_ms\": 9979.042, \"total_train_time_s\": 11.774494171142578}", "{\"n\": 16834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.03, \"learn_time_ms\": 10076.702, \"total_train_time_s\": 13.290037393569946}", "{\"n\": 16835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.28, \"learn_time_ms\": 10035.561, \"total_train_time_s\": 12.406339645385742}", "{\"n\": 16836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.19, \"learn_time_ms\": 10113.229, \"total_train_time_s\": 12.287192821502686}", "{\"n\": 16837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.53, \"learn_time_ms\": 10198.038, \"total_train_time_s\": 12.021767854690552}", "{\"n\": 16838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3614.57, \"learn_time_ms\": 10194.727, \"total_train_time_s\": 11.657796144485474}", "{\"n\": 16839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.83, \"learn_time_ms\": 10174.616, \"total_train_time_s\": 12.035736560821533}", "{\"n\": 16840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.83, \"learn_time_ms\": 10251.731, \"total_train_time_s\": 11.914388656616211}", "{\"n\": 16841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.11, \"learn_time_ms\": 10195.976, \"total_train_time_s\": 11.871155738830566}", "{\"n\": 16842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.11, \"learn_time_ms\": 10121.487, \"total_train_time_s\": 11.037396430969238}", "{\"n\": 16843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.17, \"learn_time_ms\": 10121.334, \"total_train_time_s\": 11.792848348617554}", "{\"n\": 16844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.17, \"learn_time_ms\": 9998.005, \"total_train_time_s\": 12.082906007766724}", "{\"n\": 16845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.54, \"learn_time_ms\": 9936.148, \"total_train_time_s\": 11.783156633377075}", "{\"n\": 16846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.96, \"learn_time_ms\": 9971.437, \"total_train_time_s\": 12.631203413009644}", "{\"n\": 16847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.96, \"learn_time_ms\": 9955.81, \"total_train_time_s\": 11.88726258277893}", "{\"n\": 16848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.96, \"learn_time_ms\": 9981.745, \"total_train_time_s\": 11.9000084400177}", "{\"n\": 16849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3607.43, \"learn_time_ms\": 9921.399, \"total_train_time_s\": 11.49558687210083}", "{\"n\": 16850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.72, \"learn_time_ms\": 9858.735, \"total_train_time_s\": 11.302340507507324}", "{\"n\": 16851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.72, \"learn_time_ms\": 9812.972, \"total_train_time_s\": 11.401415348052979}", "{\"n\": 16852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3603.97, \"learn_time_ms\": 9865.095, \"total_train_time_s\": 11.573940753936768}", "{\"n\": 16853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.42, \"learn_time_ms\": 9877.183, \"total_train_time_s\": 11.914291143417358}", "{\"n\": 16854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.42, \"learn_time_ms\": 9865.535, \"total_train_time_s\": 11.945168495178223}", "{\"n\": 16855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.88, \"learn_time_ms\": 9879.658, \"total_train_time_s\": 11.980555772781372}", "{\"n\": 16856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.94, \"learn_time_ms\": 9862.827, \"total_train_time_s\": 12.503736734390259}", "{\"n\": 16857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.27, \"learn_time_ms\": 9808.631, \"total_train_time_s\": 11.335244417190552}", "{\"n\": 16858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.27, \"learn_time_ms\": 9716.513, \"total_train_time_s\": 11.00141978263855}", "{\"n\": 16859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.52, \"learn_time_ms\": 9751.962, \"total_train_time_s\": 11.847856998443604}", "{\"n\": 16860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.46, \"learn_time_ms\": 9748.592, \"total_train_time_s\": 11.282496452331543}", "{\"n\": 16861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.75, \"learn_time_ms\": 9827.865, \"total_train_time_s\": 12.214591979980469}", "{\"n\": 16862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3603.61, \"learn_time_ms\": 9848.156, \"total_train_time_s\": 11.799388647079468}", "{\"n\": 16863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3606.81, \"learn_time_ms\": 9811.918, \"total_train_time_s\": 11.496323823928833}", "{\"n\": 16864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.76, \"learn_time_ms\": 9922.376, \"total_train_time_s\": 13.081949949264526}", "{\"n\": 16865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.76, \"learn_time_ms\": 9888.568, \"total_train_time_s\": 11.625563621520996}", "{\"n\": 16866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.07, \"learn_time_ms\": 9782.313, \"total_train_time_s\": 11.3764808177948}", "{\"n\": 16867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.97, \"learn_time_ms\": 9810.338, \"total_train_time_s\": 11.660460472106934}", "{\"n\": 16868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.49, \"learn_time_ms\": 9862.883, \"total_train_time_s\": 11.47095251083374}", "{\"n\": 16869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.34, \"learn_time_ms\": 9901.351, \"total_train_time_s\": 12.170464515686035}", "{\"n\": 16870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.34, \"learn_time_ms\": 10007.669, \"total_train_time_s\": 12.306141138076782}", "{\"n\": 16871, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.79, \"learn_time_ms\": 9874.011, \"total_train_time_s\": 10.865125894546509}", "{\"n\": 16872, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.56, \"learn_time_ms\": 9893.256, \"total_train_time_s\": 11.942511558532715}", "{\"n\": 16873, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.54, \"learn_time_ms\": 9958.33, \"total_train_time_s\": 12.184139490127563}", "{\"n\": 16874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.36, \"learn_time_ms\": 9886.182, \"total_train_time_s\": 12.352262735366821}", "{\"n\": 16875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3589.25, \"learn_time_ms\": 9924.642, \"total_train_time_s\": 11.976146697998047}", "{\"n\": 16876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.46, \"learn_time_ms\": 10093.524, \"total_train_time_s\": 13.08156967163086}", "{\"n\": 16877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.64, \"learn_time_ms\": 10107.405, \"total_train_time_s\": 11.851678133010864}", "{\"n\": 16878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.29, \"learn_time_ms\": 10121.167, \"total_train_time_s\": 11.633713722229004}", "{\"n\": 16879, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3621.58, \"learn_time_ms\": 10192.565, \"total_train_time_s\": 12.900806665420532}", "{\"n\": 16880, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3617.41, \"learn_time_ms\": 10228.104, \"total_train_time_s\": 12.68203067779541}", "{\"n\": 16881, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.0, \"learn_time_ms\": 10369.604, \"total_train_time_s\": 12.278117895126343}", "{\"n\": 16882, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3620.0, \"learn_time_ms\": 10472.524, \"total_train_time_s\": 13.035884380340576}", "{\"n\": 16883, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.32, \"learn_time_ms\": 10420.69, \"total_train_time_s\": 11.64480972290039}", "{\"n\": 16884, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.06, \"learn_time_ms\": 10328.048, \"total_train_time_s\": 11.384079456329346}", "{\"n\": 16885, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.06, \"learn_time_ms\": 10358.923, \"total_train_time_s\": 12.277539730072021}", "{\"n\": 16886, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3623.06, \"learn_time_ms\": 10273.185, \"total_train_time_s\": 12.206938743591309}", "{\"n\": 16887, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.6, \"learn_time_ms\": 10242.005, \"total_train_time_s\": 11.50800108909607}", "{\"n\": 16888, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10289.06, \"total_train_time_s\": 12.1049222946167}", "{\"n\": 16889, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.48, \"learn_time_ms\": 10229.152, \"total_train_time_s\": 12.319157361984253}", "{\"n\": 16890, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.71, \"learn_time_ms\": 10178.782, \"total_train_time_s\": 12.173441648483276}", "{\"n\": 16891, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.69, \"learn_time_ms\": 10111.198, \"total_train_time_s\": 11.586514472961426}", "{\"n\": 16892, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 9917.468, \"total_train_time_s\": 11.04562258720398}", "{\"n\": 16893, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 10053.469, \"total_train_time_s\": 13.023210763931274}", "{\"n\": 16894, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.84, \"learn_time_ms\": 10060.239, \"total_train_time_s\": 11.47455906867981}", "{\"n\": 16895, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 9923.785, \"total_train_time_s\": 10.886756420135498}", "{\"n\": 16896, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.87, \"learn_time_ms\": 9954.884, \"total_train_time_s\": 12.552873849868774}", "{\"n\": 16897, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.26, \"learn_time_ms\": 9962.041, \"total_train_time_s\": 11.529404401779175}", "{\"n\": 16898, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.33, \"learn_time_ms\": 9993.037, \"total_train_time_s\": 12.414921045303345}", "{\"n\": 16899, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.53, \"learn_time_ms\": 9926.6, \"total_train_time_s\": 11.685950517654419}", "{\"n\": 16900, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.53, \"learn_time_ms\": 9961.774, \"total_train_time_s\": 12.480862855911255}", "{\"n\": 16901, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.42, \"learn_time_ms\": 10086.714, \"total_train_time_s\": 12.864964723587036}", "{\"n\": 16902, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.42, \"learn_time_ms\": 10241.895, \"total_train_time_s\": 12.623579502105713}", "{\"n\": 16903, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.02, \"learn_time_ms\": 10132.222, \"total_train_time_s\": 11.90509843826294}", "{\"n\": 16904, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.38, \"learn_time_ms\": 10198.053, \"total_train_time_s\": 12.166550874710083}", "{\"n\": 16905, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.89, \"learn_time_ms\": 10244.359, \"total_train_time_s\": 11.410022735595703}", "{\"n\": 16906, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.62, \"learn_time_ms\": 10186.352, \"total_train_time_s\": 11.93818473815918}", "{\"n\": 16907, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.71, \"learn_time_ms\": 10341.632, \"total_train_time_s\": 13.12990927696228}", "{\"n\": 16908, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.81, \"learn_time_ms\": 10296.985, \"total_train_time_s\": 12.008103370666504}", "{\"n\": 16909, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.72, \"learn_time_ms\": 10352.4, \"total_train_time_s\": 12.240342617034912}", "{\"n\": 16910, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3573.09, \"learn_time_ms\": 10263.096, \"total_train_time_s\": 11.637341022491455}", "{\"n\": 16911, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.12, \"learn_time_ms\": 10117.739, \"total_train_time_s\": 11.406660795211792}", "{\"n\": 16912, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.12, \"learn_time_ms\": 10080.428, \"total_train_time_s\": 12.210695505142212}", "{\"n\": 16913, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.2, \"learn_time_ms\": 10037.474, \"total_train_time_s\": 11.512543678283691}", "{\"n\": 16914, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.09, \"learn_time_ms\": 10114.054, \"total_train_time_s\": 12.947910070419312}", "{\"n\": 16915, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.09, \"learn_time_ms\": 10157.646, \"total_train_time_s\": 11.811594247817993}", "{\"n\": 16916, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.32, \"learn_time_ms\": 10047.231, \"total_train_time_s\": 10.856689453125}", "{\"n\": 16917, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.28, \"learn_time_ms\": 9956.05, \"total_train_time_s\": 12.220376968383789}", "{\"n\": 16918, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.73, \"learn_time_ms\": 9842.38, \"total_train_time_s\": 10.81012511253357}", "{\"n\": 16919, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.73, \"learn_time_ms\": 9834.359, \"total_train_time_s\": 12.113337278366089}", "{\"n\": 16920, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.38, \"learn_time_ms\": 9816.023, \"total_train_time_s\": 11.443750619888306}", "{\"n\": 16921, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3569.08, \"learn_time_ms\": 9791.962, \"total_train_time_s\": 11.180822372436523}", "{\"n\": 16922, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3569.08, \"learn_time_ms\": 9776.694, \"total_train_time_s\": 12.116172075271606}", "{\"n\": 16923, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.23, \"learn_time_ms\": 9748.517, \"total_train_time_s\": 11.202896118164062}", "{\"n\": 16924, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 9666.495, \"total_train_time_s\": 12.111791849136353}", "{\"n\": 16925, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 9747.341, \"total_train_time_s\": 12.613417148590088}", "{\"n\": 16926, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.81, \"learn_time_ms\": 9797.795, \"total_train_time_s\": 11.355279445648193}", "{\"n\": 16927, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3565.32, \"learn_time_ms\": 9676.378, \"total_train_time_s\": 11.00772213935852}", "{\"n\": 16928, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.26, \"learn_time_ms\": 9796.116, \"total_train_time_s\": 12.126813173294067}", "{\"n\": 16929, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.26, \"learn_time_ms\": 9843.463, \"total_train_time_s\": 12.605923175811768}", "{\"n\": 16930, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.76, \"learn_time_ms\": 9840.091, \"total_train_time_s\": 11.397567749023438}", "{\"n\": 16931, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.1, \"learn_time_ms\": 9905.477, \"total_train_time_s\": 11.824656963348389}", "{\"n\": 16932, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.1, \"learn_time_ms\": 9991.996, \"total_train_time_s\": 12.922369241714478}", "{\"n\": 16933, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.1, \"learn_time_ms\": 10036.312, \"total_train_time_s\": 11.649056911468506}", "{\"n\": 16934, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.97, \"learn_time_ms\": 9980.321, \"total_train_time_s\": 11.513301849365234}", "{\"n\": 16935, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3563.98, \"learn_time_ms\": 9913.041, \"total_train_time_s\": 12.057273387908936}", "{\"n\": 16936, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3563.98, \"learn_time_ms\": 9878.916, \"total_train_time_s\": 10.97586965560913}", "{\"n\": 16937, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.44, \"learn_time_ms\": 10018.672, \"total_train_time_s\": 12.362890481948853}", "{\"n\": 16938, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3556.32, \"learn_time_ms\": 10070.886, \"total_train_time_s\": 12.565825462341309}", "{\"n\": 16939, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3560.31, \"learn_time_ms\": 9979.606, \"total_train_time_s\": 11.679852724075317}", "{\"n\": 16940, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3560.31, \"learn_time_ms\": 10125.207, \"total_train_time_s\": 12.841560125350952}", "{\"n\": 16941, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3561.59, \"learn_time_ms\": 10205.394, \"total_train_time_s\": 12.601614713668823}", "{\"n\": 16942, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.9, \"learn_time_ms\": 10240.648, \"total_train_time_s\": 13.310357570648193}", "{\"n\": 16943, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.9, \"learn_time_ms\": 10334.873, \"total_train_time_s\": 12.593991994857788}", "{\"n\": 16944, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.9, \"learn_time_ms\": 10426.008, \"total_train_time_s\": 12.43056321144104}", "{\"n\": 16945, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.03, \"learn_time_ms\": 10408.573, \"total_train_time_s\": 11.782805681228638}", "{\"n\": 16946, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.96, \"learn_time_ms\": 10533.449, \"total_train_time_s\": 12.283864736557007}", "{\"n\": 16947, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.96, \"learn_time_ms\": 10564.593, \"total_train_time_s\": 12.666923522949219}", "{\"n\": 16948, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.96, \"learn_time_ms\": 10510.313, \"total_train_time_s\": 12.020106315612793}", "{\"n\": 16949, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.36, \"learn_time_ms\": 10594.32, \"total_train_time_s\": 12.525477886199951}", "{\"n\": 16950, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 10517.859, \"total_train_time_s\": 12.08780312538147}", "{\"n\": 16951, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 10512.603, \"total_train_time_s\": 12.591949462890625}", "{\"n\": 16952, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3587.45, \"learn_time_ms\": 10385.411, \"total_train_time_s\": 12.046887874603271}", "{\"n\": 16953, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.12, \"learn_time_ms\": 10288.063, \"total_train_time_s\": 11.640634059906006}", "{\"n\": 16954, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.12, \"learn_time_ms\": 10259.595, \"total_train_time_s\": 12.18727707862854}", "{\"n\": 16955, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.12, \"learn_time_ms\": 10313.165, \"total_train_time_s\": 12.277359008789062}", "{\"n\": 16956, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.92, \"learn_time_ms\": 10295.653, \"total_train_time_s\": 12.073868036270142}", "{\"n\": 16957, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.87, \"learn_time_ms\": 10248.919, \"total_train_time_s\": 12.206079721450806}", "{\"n\": 16958, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.87, \"learn_time_ms\": 10192.056, \"total_train_time_s\": 11.456558465957642}", "{\"n\": 16959, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.54, \"learn_time_ms\": 10109.605, \"total_train_time_s\": 11.688987493515015}", "{\"n\": 16960, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.89, \"learn_time_ms\": 10158.288, \"total_train_time_s\": 12.563643455505371}", "{\"n\": 16961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.99, \"learn_time_ms\": 10069.265, \"total_train_time_s\": 11.680038928985596}", "{\"n\": 16962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.75, \"learn_time_ms\": 10060.893, \"total_train_time_s\": 11.95257830619812}", "{\"n\": 16963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.75, \"learn_time_ms\": 10047.367, \"total_train_time_s\": 11.465423583984375}", "{\"n\": 16964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.77, \"learn_time_ms\": 10147.388, \"total_train_time_s\": 13.148389339447021}", "{\"n\": 16965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.35, \"learn_time_ms\": 10074.795, \"total_train_time_s\": 11.548152685165405}", "{\"n\": 16966, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3561.17, \"learn_time_ms\": 10037.808, \"total_train_time_s\": 11.705940246582031}", "{\"n\": 16967, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3556.38, \"learn_time_ms\": 9983.04, \"total_train_time_s\": 11.716655015945435}", "{\"n\": 16968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3550.54, \"learn_time_ms\": 10090.869, \"total_train_time_s\": 12.502230644226074}", "{\"n\": 16969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3554.55, \"learn_time_ms\": 10158.753, \"total_train_time_s\": 12.373001337051392}", "{\"n\": 16970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3554.55, \"learn_time_ms\": 10072.717, \"total_train_time_s\": 11.746920824050903}", "{\"n\": 16971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.21, \"learn_time_ms\": 10088.471, \"total_train_time_s\": 11.820872783660889}", "{\"n\": 16972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.22, \"learn_time_ms\": 10054.718, \"total_train_time_s\": 11.609872579574585}", "{\"n\": 16973, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.22, \"learn_time_ms\": 10032.75, \"total_train_time_s\": 11.259546041488647}", "{\"n\": 16974, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.22, \"learn_time_ms\": 9844.218, \"total_train_time_s\": 11.292436361312866}", "{\"n\": 16975, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3549.56, \"learn_time_ms\": 9797.798, \"total_train_time_s\": 11.12603497505188}", "{\"n\": 16976, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.66, \"learn_time_ms\": 9983.107, \"total_train_time_s\": 13.5985689163208}", "{\"n\": 16977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.66, \"learn_time_ms\": 10008.07, \"total_train_time_s\": 11.91982388496399}", "{\"n\": 16978, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.17, \"learn_time_ms\": 9963.587, \"total_train_time_s\": 12.097767114639282}", "{\"n\": 16979, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.6, \"learn_time_ms\": 9910.305, \"total_train_time_s\": 11.907190322875977}", "{\"n\": 16980, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.41, \"learn_time_ms\": 9914.42, \"total_train_time_s\": 11.798891544342041}", "{\"n\": 16981, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.41, \"learn_time_ms\": 9842.311, \"total_train_time_s\": 11.116913557052612}", "{\"n\": 16982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.35, \"learn_time_ms\": 9882.77, \"total_train_time_s\": 12.027040481567383}", "{\"n\": 16983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.5, \"learn_time_ms\": 9934.484, \"total_train_time_s\": 11.802202463150024}", "{\"n\": 16984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.69, \"learn_time_ms\": 9846.738, \"total_train_time_s\": 10.409372091293335}", "{\"n\": 16985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.73, \"learn_time_ms\": 9957.752, \"total_train_time_s\": 12.37507176399231}", "{\"n\": 16986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.65, \"learn_time_ms\": 9919.71, \"total_train_time_s\": 13.205544233322144}", "{\"n\": 16987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.31, \"learn_time_ms\": 9947.706, \"total_train_time_s\": 12.178053617477417}", "{\"n\": 16988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3572.31, \"learn_time_ms\": 9934.625, \"total_train_time_s\": 11.933214902877808}", "{\"n\": 16989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.36, \"learn_time_ms\": 9979.7, \"total_train_time_s\": 12.279281616210938}", "{\"n\": 16990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.45, \"learn_time_ms\": 10046.706, \"total_train_time_s\": 12.462531089782715}", "{\"n\": 16991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.45, \"learn_time_ms\": 10172.824, \"total_train_time_s\": 12.394210815429688}", "{\"n\": 16992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.45, \"learn_time_ms\": 10152.287, \"total_train_time_s\": 11.830134630203247}", "{\"n\": 16993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.29, \"learn_time_ms\": 10174.661, \"total_train_time_s\": 12.027097702026367}", "{\"n\": 16994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.73, \"learn_time_ms\": 10208.147, \"total_train_time_s\": 10.742069005966187}", "{\"n\": 16995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.73, \"learn_time_ms\": 10181.169, \"total_train_time_s\": 11.92832636833191}", "{\"n\": 16996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.73, \"learn_time_ms\": 10059.028, \"total_train_time_s\": 11.98764967918396}", "{\"n\": 16997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.5, \"learn_time_ms\": 10007.278, \"total_train_time_s\": 11.671916007995605}", "{\"n\": 16998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.5, \"learn_time_ms\": 10092.875, \"total_train_time_s\": 12.8540940284729}", "{\"n\": 16999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.5, \"learn_time_ms\": 10062.682, \"total_train_time_s\": 11.999820709228516}", "{\"n\": 17000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.03, \"learn_time_ms\": 10126.801, \"total_train_time_s\": 13.09139633178711}", "{\"n\": 17001, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.2, \"learn_time_ms\": 10045.807, \"total_train_time_s\": 11.56332516670227}", "{\"n\": 17002, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.2, \"learn_time_ms\": 10091.012, \"total_train_time_s\": 12.28169846534729}", "{\"n\": 17003, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.48, \"learn_time_ms\": 10039.49, \"total_train_time_s\": 11.50369381904602}", "{\"n\": 17004, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.27, \"learn_time_ms\": 10237.744, \"total_train_time_s\": 12.734176397323608}", "{\"n\": 17005, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.27, \"learn_time_ms\": 10278.549, \"total_train_time_s\": 12.370282173156738}", "{\"n\": 17006, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.27, \"learn_time_ms\": 10245.881, \"total_train_time_s\": 11.64913535118103}", "{\"n\": 17007, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.25, \"learn_time_ms\": 10259.002, \"total_train_time_s\": 11.829445838928223}", "{\"n\": 17008, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.21, \"learn_time_ms\": 10059.498, \"total_train_time_s\": 10.805242538452148}", "{\"n\": 17009, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.21, \"learn_time_ms\": 9973.199, \"total_train_time_s\": 11.1173996925354}", "{\"n\": 17010, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.21, \"learn_time_ms\": 9823.246, \"total_train_time_s\": 11.56933045387268}", "{\"n\": 17011, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.55, \"learn_time_ms\": 9976.071, \"total_train_time_s\": 13.078810214996338}", "{\"n\": 17012, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.27, \"learn_time_ms\": 9993.066, \"total_train_time_s\": 12.423133611679077}", "{\"n\": 17013, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.27, \"learn_time_ms\": 10018.109, \"total_train_time_s\": 11.718070268630981}", "{\"n\": 17014, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.27, \"learn_time_ms\": 9873.487, \"total_train_time_s\": 11.256669282913208}", "{\"n\": 17015, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.28, \"learn_time_ms\": 9911.907, \"total_train_time_s\": 12.77986454963684}", "{\"n\": 17016, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.28, \"learn_time_ms\": 10137.951, \"total_train_time_s\": 13.922762393951416}", "{\"n\": 17017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.41, \"learn_time_ms\": 10172.015, \"total_train_time_s\": 12.161673784255981}", "{\"n\": 17018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.41, \"learn_time_ms\": 10307.637, \"total_train_time_s\": 12.184670209884644}", "{\"n\": 17019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.24, \"learn_time_ms\": 10337.514, \"total_train_time_s\": 11.434617280960083}", "{\"n\": 17020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.24, \"learn_time_ms\": 10355.603, \"total_train_time_s\": 11.765143394470215}", "{\"n\": 17021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.38, \"learn_time_ms\": 10251.488, \"total_train_time_s\": 12.084259033203125}", "{\"n\": 17022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.06, \"learn_time_ms\": 10287.55, \"total_train_time_s\": 12.80252718925476}", "{\"n\": 17023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.12, \"learn_time_ms\": 10297.525, \"total_train_time_s\": 11.854081392288208}", "{\"n\": 17024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.12, \"learn_time_ms\": 10417.969, \"total_train_time_s\": 12.492232322692871}", "{\"n\": 17025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3592.55, \"learn_time_ms\": 10416.935, \"total_train_time_s\": 12.725680589675903}", "{\"n\": 17026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.47, \"learn_time_ms\": 10180.553, \"total_train_time_s\": 11.512985229492188}", "{\"n\": 17027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.47, \"learn_time_ms\": 10184.472, \"total_train_time_s\": 12.192782640457153}", "{\"n\": 17028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.27, \"learn_time_ms\": 10227.268, \"total_train_time_s\": 12.572927474975586}", "{\"n\": 17029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3611.27, \"learn_time_ms\": 10375.596, \"total_train_time_s\": 12.87551498413086}", "{\"n\": 17030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.35, \"learn_time_ms\": 10443.262, \"total_train_time_s\": 12.460386991500854}", "{\"n\": 17031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.5, \"learn_time_ms\": 10359.402, \"total_train_time_s\": 11.223402500152588}", "{\"n\": 17032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.5, \"learn_time_ms\": 10336.245, \"total_train_time_s\": 12.589074611663818}", "{\"n\": 17033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.52, \"learn_time_ms\": 10307.175, \"total_train_time_s\": 11.546872615814209}", "{\"n\": 17034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.14, \"learn_time_ms\": 10289.207, \"total_train_time_s\": 12.322373151779175}", "{\"n\": 17035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.14, \"learn_time_ms\": 10310.037, \"total_train_time_s\": 12.889331340789795}", "{\"n\": 17036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.14, \"learn_time_ms\": 10225.067, \"total_train_time_s\": 10.66211462020874}", "{\"n\": 17037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.8, \"learn_time_ms\": 10265.598, \"total_train_time_s\": 12.60739541053772}", "{\"n\": 17038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.9, \"learn_time_ms\": 10278.791, \"total_train_time_s\": 12.702725648880005}", "{\"n\": 17039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.9, \"learn_time_ms\": 10228.711, \"total_train_time_s\": 12.359046459197998}", "{\"n\": 17040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3575.44, \"learn_time_ms\": 10245.631, \"total_train_time_s\": 12.578344583511353}", "{\"n\": 17041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.5, \"learn_time_ms\": 10315.787, \"total_train_time_s\": 11.87790822982788}", "{\"n\": 17042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.61, \"learn_time_ms\": 10216.503, \"total_train_time_s\": 11.5568106174469}", "{\"n\": 17043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3576.61, \"learn_time_ms\": 10279.97, \"total_train_time_s\": 12.184096097946167}", "{\"n\": 17044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3583.25, \"learn_time_ms\": 10188.017, \"total_train_time_s\": 11.385224342346191}", "{\"n\": 17045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.05, \"learn_time_ms\": 10129.048, \"total_train_time_s\": 12.364075899124146}", "{\"n\": 17046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.05, \"learn_time_ms\": 10231.289, \"total_train_time_s\": 11.729610443115234}", "{\"n\": 17047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3588.04, \"learn_time_ms\": 10144.047, \"total_train_time_s\": 11.70224380493164}", "{\"n\": 17048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.33, \"learn_time_ms\": 10065.081, \"total_train_time_s\": 11.968488931655884}", "{\"n\": 17049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.44, \"learn_time_ms\": 10022.581, \"total_train_time_s\": 12.021666765213013}", "{\"n\": 17050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.44, \"learn_time_ms\": 9973.556, \"total_train_time_s\": 12.093282461166382}", "{\"n\": 17051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.96, \"learn_time_ms\": 10052.211, \"total_train_time_s\": 12.697530031204224}", "{\"n\": 17052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.96, \"learn_time_ms\": 10159.535, \"total_train_time_s\": 12.646836280822754}", "{\"n\": 17053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.46, \"learn_time_ms\": 10254.837, \"total_train_time_s\": 13.15256142616272}", "{\"n\": 17054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.46, \"learn_time_ms\": 10403.532, \"total_train_time_s\": 12.893787145614624}", "{\"n\": 17055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.91, \"learn_time_ms\": 10360.425, \"total_train_time_s\": 11.919196367263794}", "{\"n\": 17056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.69, \"learn_time_ms\": 10348.534, \"total_train_time_s\": 11.616400957107544}", "{\"n\": 17057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.3, \"learn_time_ms\": 10416.629, \"total_train_time_s\": 12.40173864364624}", "{\"n\": 17058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.96, \"learn_time_ms\": 10374.107, \"total_train_time_s\": 11.541635751724243}", "{\"n\": 17059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.71, \"learn_time_ms\": 10492.068, \"total_train_time_s\": 13.17398452758789}", "{\"n\": 17060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.13, \"learn_time_ms\": 10511.956, \"total_train_time_s\": 12.3302640914917}", "{\"n\": 17061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.13, \"learn_time_ms\": 10443.195, \"total_train_time_s\": 12.011898756027222}", "{\"n\": 17062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.38, \"learn_time_ms\": 10355.899, \"total_train_time_s\": 11.751289367675781}", "{\"n\": 17063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 10180.844, \"total_train_time_s\": 11.389850854873657}", "{\"n\": 17064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.4, \"learn_time_ms\": 10106.68, \"total_train_time_s\": 12.152786016464233}", "{\"n\": 17065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3630.4, \"learn_time_ms\": 10139.84, \"total_train_time_s\": 12.286750793457031}", "{\"n\": 17066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10146.981, \"total_train_time_s\": 11.643954992294312}", "{\"n\": 17067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10164.498, \"total_train_time_s\": 12.578539848327637}", "{\"n\": 17068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.68, \"learn_time_ms\": 10259.688, \"total_train_time_s\": 12.447419166564941}", "{\"n\": 17069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3637.72, \"learn_time_ms\": 10124.292, \"total_train_time_s\": 11.80941128730774}", "{\"n\": 17070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.31, \"learn_time_ms\": 10144.54, \"total_train_time_s\": 12.516072511672974}", "{\"n\": 17071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3625.31, \"learn_time_ms\": 10200.908, \"total_train_time_s\": 12.56311845779419}", "{\"n\": 17072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.62, \"learn_time_ms\": 10311.067, \"total_train_time_s\": 12.838398933410645}", "{\"n\": 17073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.62, \"learn_time_ms\": 10373.182, \"total_train_time_s\": 12.026746273040771}", "{\"n\": 17074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.81, \"learn_time_ms\": 10350.544, \"total_train_time_s\": 11.921698808670044}", "{\"n\": 17075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10304.49, \"total_train_time_s\": 11.822614908218384}", "{\"n\": 17076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.71, \"learn_time_ms\": 10344.548, \"total_train_time_s\": 12.054173707962036}", "{\"n\": 17077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3629.1, \"learn_time_ms\": 10268.089, \"total_train_time_s\": 11.79380202293396}", "{\"n\": 17078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3627.76, \"learn_time_ms\": 10233.422, \"total_train_time_s\": 12.164594173431396}", "{\"n\": 17079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.56, \"learn_time_ms\": 10272.289, \"total_train_time_s\": 12.241576671600342}", "{\"n\": 17080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.27, \"learn_time_ms\": 10198.854, \"total_train_time_s\": 11.767858982086182}", "{\"n\": 17081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.4, \"learn_time_ms\": 10181.069, \"total_train_time_s\": 12.390374660491943}", "{\"n\": 17082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3629.05, \"learn_time_ms\": 10052.19, \"total_train_time_s\": 11.5339994430542}", "{\"n\": 17083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3631.2, \"learn_time_ms\": 10175.035, \"total_train_time_s\": 13.263299942016602}", "{\"n\": 17084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3637.3, \"learn_time_ms\": 10080.461, \"total_train_time_s\": 10.94179105758667}", "{\"n\": 17085, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3645.94, \"learn_time_ms\": 10156.67, \"total_train_time_s\": 12.54802942276001}", "{\"n\": 17086, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3641.79, \"learn_time_ms\": 10026.51, \"total_train_time_s\": 10.762969732284546}", "{\"n\": 17087, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3646.65, \"learn_time_ms\": 10082.471, \"total_train_time_s\": 12.394662857055664}", "{\"n\": 17088, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3645.19, \"learn_time_ms\": 10151.58, \"total_train_time_s\": 12.798722267150879}", "{\"n\": 17089, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3645.19, \"learn_time_ms\": 10257.248, \"total_train_time_s\": 13.26243281364441}", "{\"n\": 17090, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3648.25, \"learn_time_ms\": 10414.597, \"total_train_time_s\": 13.36723518371582}", "{\"n\": 17091, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3650.8, \"learn_time_ms\": 10383.139, \"total_train_time_s\": 12.103774785995483}", "{\"n\": 17092, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.29, \"learn_time_ms\": 10381.704, \"total_train_time_s\": 11.556628942489624}", "{\"n\": 17093, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3645.61, \"learn_time_ms\": 10211.999, \"total_train_time_s\": 11.557363271713257}", "{\"n\": 17094, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3660.75, \"learn_time_ms\": 10247.692, \"total_train_time_s\": 11.302834510803223}", "{\"n\": 17095, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3673.73, \"learn_time_ms\": 10099.847, \"total_train_time_s\": 11.059205770492554}", "{\"n\": 17096, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3673.19, \"learn_time_ms\": 10240.554, \"total_train_time_s\": 12.189079523086548}", "{\"n\": 17097, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3673.19, \"learn_time_ms\": 10164.265, \"total_train_time_s\": 11.599455118179321}", "{\"n\": 17098, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3646.51, \"learn_time_ms\": 10036.427, \"total_train_time_s\": 11.567067623138428}", "{\"n\": 17099, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3639.52, \"learn_time_ms\": 9901.488, \"total_train_time_s\": 11.884957075119019}", "{\"n\": 17100, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3639.52, \"learn_time_ms\": 9797.543, \"total_train_time_s\": 12.264141321182251}", "{\"n\": 17101, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3639.52, \"learn_time_ms\": 9767.632, \"total_train_time_s\": 11.773320436477661}", "{\"n\": 17102, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3628.11, \"learn_time_ms\": 9843.604, \"total_train_time_s\": 12.354273557662964}", "{\"n\": 17103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 9931.112, \"total_train_time_s\": 12.412593364715576}", "{\"n\": 17104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3620.04, \"learn_time_ms\": 9956.974, \"total_train_time_s\": 11.607035398483276}", "{\"n\": 17105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3622.53, \"learn_time_ms\": 10067.315, \"total_train_time_s\": 12.20667028427124}", "{\"n\": 17106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.45, \"learn_time_ms\": 9932.34, \"total_train_time_s\": 10.859623193740845}", "{\"n\": 17107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.45, \"learn_time_ms\": 10006.018, \"total_train_time_s\": 12.31875228881836}", "{\"n\": 17108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.45, \"learn_time_ms\": 9949.696, \"total_train_time_s\": 10.964123010635376}", "{\"n\": 17109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.77, \"learn_time_ms\": 10005.712, \"total_train_time_s\": 12.494777917861938}", "{\"n\": 17110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 9986.459, \"total_train_time_s\": 12.093466758728027}", "{\"n\": 17111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 9876.589, \"total_train_time_s\": 10.661777019500732}", "{\"n\": 17112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.49, \"learn_time_ms\": 9874.99, \"total_train_time_s\": 12.281347751617432}", "{\"n\": 17113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.56, \"learn_time_ms\": 9820.214, \"total_train_time_s\": 11.90496015548706}", "{\"n\": 17114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.69, \"learn_time_ms\": 9933.511, \"total_train_time_s\": 12.769979476928711}", "{\"n\": 17115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.63, \"learn_time_ms\": 9945.23, \"total_train_time_s\": 12.334522485733032}", "{\"n\": 17116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.9, \"learn_time_ms\": 10041.166, \"total_train_time_s\": 11.800675630569458}", "{\"n\": 17117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.72, \"learn_time_ms\": 9902.589, \"total_train_time_s\": 10.989720821380615}", "{\"n\": 17118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.46, \"learn_time_ms\": 10013.921, \"total_train_time_s\": 12.085493326187134}", "{\"n\": 17119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.65, \"learn_time_ms\": 9915.669, \"total_train_time_s\": 11.457034826278687}", "{\"n\": 17120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3601.76, \"learn_time_ms\": 9974.823, \"total_train_time_s\": 12.770830392837524}", "{\"n\": 17121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.67, \"learn_time_ms\": 10157.712, \"total_train_time_s\": 12.520586013793945}", "{\"n\": 17122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.67, \"learn_time_ms\": 10174.713, \"total_train_time_s\": 12.50463318824768}", "{\"n\": 17123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.54, \"learn_time_ms\": 10158.955, \"total_train_time_s\": 11.71387529373169}", "{\"n\": 17124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.62, \"learn_time_ms\": 10059.063, \"total_train_time_s\": 11.706362009048462}", "{\"n\": 17125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.1, \"learn_time_ms\": 10032.664, \"total_train_time_s\": 12.050050020217896}", "{\"n\": 17126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.1, \"learn_time_ms\": 9952.282, \"total_train_time_s\": 10.971224784851074}", "{\"n\": 17127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.62, \"learn_time_ms\": 9963.994, \"total_train_time_s\": 11.066341161727905}", "{\"n\": 17128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.14, \"learn_time_ms\": 9903.276, \"total_train_time_s\": 11.496151447296143}", "{\"n\": 17129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.14, \"learn_time_ms\": 10004.519, \"total_train_time_s\": 12.487077474594116}", "{\"n\": 17130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.77, \"learn_time_ms\": 10001.942, \"total_train_time_s\": 12.674052000045776}", "{\"n\": 17131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.2, \"learn_time_ms\": 9967.143, \"total_train_time_s\": 12.183587551116943}", "{\"n\": 17132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.09, \"learn_time_ms\": 9907.925, \"total_train_time_s\": 11.887034177780151}", "{\"n\": 17133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3603.49, \"learn_time_ms\": 9909.083, \"total_train_time_s\": 11.734008550643921}", "{\"n\": 17134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.19, \"learn_time_ms\": 9988.059, \"total_train_time_s\": 12.497570753097534}", "{\"n\": 17135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.19, \"learn_time_ms\": 10051.697, \"total_train_time_s\": 12.705437421798706}", "{\"n\": 17136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3603.12, \"learn_time_ms\": 10099.536, \"total_train_time_s\": 11.474001169204712}", "{\"n\": 17137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.83, \"learn_time_ms\": 10239.593, \"total_train_time_s\": 12.44072961807251}", "{\"n\": 17138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3596.45, \"learn_time_ms\": 10340.37, \"total_train_time_s\": 12.53433895111084}", "{\"n\": 17139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3596.45, \"learn_time_ms\": 10301.069, \"total_train_time_s\": 12.102522134780884}", "{\"n\": 17140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.22, \"learn_time_ms\": 10368.742, \"total_train_time_s\": 13.32930040359497}", "{\"n\": 17141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.22, \"learn_time_ms\": 10389.2, \"total_train_time_s\": 12.364106178283691}", "{\"n\": 17142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.52, \"learn_time_ms\": 10474.721, \"total_train_time_s\": 12.758159160614014}", "{\"n\": 17143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 10586.064, \"total_train_time_s\": 12.846368789672852}", "{\"n\": 17144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 10500.859, \"total_train_time_s\": 11.635384559631348}", "{\"n\": 17145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 10383.055, \"total_train_time_s\": 11.475053787231445}", "{\"n\": 17146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.06, \"learn_time_ms\": 10426.147, \"total_train_time_s\": 11.895683526992798}", "{\"n\": 17147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.06, \"learn_time_ms\": 10471.986, \"total_train_time_s\": 12.925197839736938}", "{\"n\": 17148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.55, \"learn_time_ms\": 10437.937, \"total_train_time_s\": 12.14379096031189}", "{\"n\": 17149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.16, \"learn_time_ms\": 10370.754, \"total_train_time_s\": 11.40226149559021}", "{\"n\": 17150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.4, \"learn_time_ms\": 10291.946, \"total_train_time_s\": 12.53110647201538}", "{\"n\": 17151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.52, \"learn_time_ms\": 10234.986, \"total_train_time_s\": 11.76938509941101}", "{\"n\": 17152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.52, \"learn_time_ms\": 10047.092, \"total_train_time_s\": 10.844332218170166}", "{\"n\": 17153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 9956.289, \"total_train_time_s\": 11.933342933654785}", "{\"n\": 17154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 10022.764, \"total_train_time_s\": 12.333208560943604}", "{\"n\": 17155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.89, \"learn_time_ms\": 10176.791, \"total_train_time_s\": 13.023881673812866}", "{\"n\": 17156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.97, \"learn_time_ms\": 10177.025, \"total_train_time_s\": 11.870502471923828}", "{\"n\": 17157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.68, \"learn_time_ms\": 10074.27, \"total_train_time_s\": 11.923535823822021}", "{\"n\": 17158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.68, \"learn_time_ms\": 10133.884, \"total_train_time_s\": 12.752983331680298}", "{\"n\": 17159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3637.75, \"learn_time_ms\": 10332.921, \"total_train_time_s\": 13.455473899841309}", "{\"n\": 17160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.22, \"learn_time_ms\": 10297.935, \"total_train_time_s\": 12.228551864624023}", "{\"n\": 17161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.64, \"learn_time_ms\": 10385.297, \"total_train_time_s\": 12.634112358093262}", "{\"n\": 17162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.64, \"learn_time_ms\": 10471.547, \"total_train_time_s\": 11.71535611152649}", "{\"n\": 17163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.99, \"learn_time_ms\": 10476.518, \"total_train_time_s\": 11.982622861862183}", "{\"n\": 17164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.91, \"learn_time_ms\": 10374.939, \"total_train_time_s\": 11.302216053009033}", "{\"n\": 17165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.91, \"learn_time_ms\": 10220.619, \"total_train_time_s\": 11.525779247283936}", "{\"n\": 17166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.6, \"learn_time_ms\": 10209.585, \"total_train_time_s\": 11.829322576522827}", "{\"n\": 17167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.6, \"learn_time_ms\": 10251.322, \"total_train_time_s\": 12.319784164428711}", "{\"n\": 17168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.62, \"learn_time_ms\": 10107.139, \"total_train_time_s\": 11.295891523361206}", "{\"n\": 17169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.62, \"learn_time_ms\": 9882.418, \"total_train_time_s\": 11.1596097946167}", "{\"n\": 17170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.61, \"learn_time_ms\": 9983.819, \"total_train_time_s\": 13.19770336151123}", "{\"n\": 17171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.61, \"learn_time_ms\": 9814.357, \"total_train_time_s\": 10.930510997772217}", "{\"n\": 17172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 9862.299, \"total_train_time_s\": 12.207800388336182}", "{\"n\": 17173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.73, \"learn_time_ms\": 9845.164, \"total_train_time_s\": 11.809013605117798}", "{\"n\": 17174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.67, \"learn_time_ms\": 9935.089, \"total_train_time_s\": 12.196299076080322}", "{\"n\": 17175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.56, \"learn_time_ms\": 9970.105, \"total_train_time_s\": 11.8400297164917}", "{\"n\": 17176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.56, \"learn_time_ms\": 9942.849, \"total_train_time_s\": 11.52302861213684}", "{\"n\": 17177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.39, \"learn_time_ms\": 9881.021, \"total_train_time_s\": 11.707432508468628}", "{\"n\": 17178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.47, \"learn_time_ms\": 9967.197, \"total_train_time_s\": 12.146551370620728}", "{\"n\": 17179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.29, \"learn_time_ms\": 10020.86, \"total_train_time_s\": 11.703856229782104}", "{\"n\": 17180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.08, \"learn_time_ms\": 9962.289, \"total_train_time_s\": 12.663365840911865}", "{\"n\": 17181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.08, \"learn_time_ms\": 9967.753, \"total_train_time_s\": 11.048792600631714}", "{\"n\": 17182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.36, \"learn_time_ms\": 9934.519, \"total_train_time_s\": 11.869955778121948}", "{\"n\": 17183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.51, \"learn_time_ms\": 9993.066, \"total_train_time_s\": 12.37818717956543}", "{\"n\": 17184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.92, \"learn_time_ms\": 10100.965, \"total_train_time_s\": 13.266050100326538}", "{\"n\": 17185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3622.92, \"learn_time_ms\": 10133.581, \"total_train_time_s\": 12.177335977554321}", "{\"n\": 17186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.24, \"learn_time_ms\": 10219.928, \"total_train_time_s\": 12.349433422088623}", "{\"n\": 17187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.47, \"learn_time_ms\": 10180.777, \"total_train_time_s\": 11.352348804473877}", "{\"n\": 17188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.47, \"learn_time_ms\": 10182.372, \"total_train_time_s\": 12.168579816818237}", "{\"n\": 17189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.56, \"learn_time_ms\": 10236.424, \"total_train_time_s\": 12.224324226379395}", "{\"n\": 17190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.27, \"learn_time_ms\": 10174.592, \"total_train_time_s\": 12.015251398086548}", "{\"n\": 17191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.75, \"learn_time_ms\": 10272.511, \"total_train_time_s\": 11.984743118286133}", "{\"n\": 17192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.75, \"learn_time_ms\": 10240.843, \"total_train_time_s\": 11.495916604995728}", "{\"n\": 17193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.9, \"learn_time_ms\": 10105.515, \"total_train_time_s\": 11.025646924972534}", "{\"n\": 17194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.96, \"learn_time_ms\": 10021.198, \"total_train_time_s\": 12.394864082336426}", "{\"n\": 17195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.15, \"learn_time_ms\": 10093.083, \"total_train_time_s\": 12.86418867111206}", "{\"n\": 17196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.15, \"learn_time_ms\": 10103.724, \"total_train_time_s\": 12.489106893539429}", "{\"n\": 17197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.3, \"learn_time_ms\": 10201.094, \"total_train_time_s\": 12.320855379104614}", "{\"n\": 17198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.65, \"learn_time_ms\": 10214.769, \"total_train_time_s\": 12.33695125579834}", "{\"n\": 17199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.65, \"learn_time_ms\": 10152.022, \"total_train_time_s\": 11.638431549072266}", "{\"n\": 17200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.65, \"learn_time_ms\": 10040.394, \"total_train_time_s\": 10.915613651275635}", "{\"n\": 17201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3653.7, \"learn_time_ms\": 9996.698, \"total_train_time_s\": 11.565617322921753}", "{\"n\": 17202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.92, \"learn_time_ms\": 10121.137, \"total_train_time_s\": 12.834239482879639}", "{\"n\": 17203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.92, \"learn_time_ms\": 10270.698, \"total_train_time_s\": 12.555980920791626}", "{\"n\": 17204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.5, \"learn_time_ms\": 10291.32, \"total_train_time_s\": 12.629879236221313}", "{\"n\": 17205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3668.22, \"learn_time_ms\": 10225.515, \"total_train_time_s\": 12.188039064407349}", "{\"n\": 17206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.41, \"learn_time_ms\": 10209.726, \"total_train_time_s\": 12.323591709136963}", "{\"n\": 17207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.41, \"learn_time_ms\": 10152.66, \"total_train_time_s\": 11.702483654022217}", "{\"n\": 17208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.32, \"learn_time_ms\": 10076.945, \"total_train_time_s\": 11.583722591400146}", "{\"n\": 17209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3670.57, \"learn_time_ms\": 10289.539, \"total_train_time_s\": 13.766379594802856}", "{\"n\": 17210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3678.45, \"learn_time_ms\": 10371.259, \"total_train_time_s\": 11.746200323104858}", "{\"n\": 17211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3678.45, \"learn_time_ms\": 10480.411, \"total_train_time_s\": 12.615422248840332}", "{\"n\": 17212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.58, \"learn_time_ms\": 10381.049, \"total_train_time_s\": 11.805371522903442}", "{\"n\": 17213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.35, \"learn_time_ms\": 10392.33, \"total_train_time_s\": 12.655123472213745}", "{\"n\": 17214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.35, \"learn_time_ms\": 10341.068, \"total_train_time_s\": 12.079700231552124}", "{\"n\": 17215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.38, \"learn_time_ms\": 10360.292, \"total_train_time_s\": 12.47269582748413}", "{\"n\": 17216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.53, \"learn_time_ms\": 10426.856, \"total_train_time_s\": 13.012742280960083}", "{\"n\": 17217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.76, \"learn_time_ms\": 10502.603, \"total_train_time_s\": 12.479767322540283}", "{\"n\": 17218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.76, \"learn_time_ms\": 10580.988, \"total_train_time_s\": 12.34159803390503}", "{\"n\": 17219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.59, \"learn_time_ms\": 10470.374, \"total_train_time_s\": 12.666891813278198}", "{\"n\": 17220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.98, \"learn_time_ms\": 10414.974, \"total_train_time_s\": 11.193275928497314}", "{\"n\": 17221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.72, \"learn_time_ms\": 10311.057, \"total_train_time_s\": 11.556923866271973}", "{\"n\": 17222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.72, \"learn_time_ms\": 10354.94, \"total_train_time_s\": 12.198334455490112}", "{\"n\": 17223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.8, \"learn_time_ms\": 10339.314, \"total_train_time_s\": 12.51637887954712}", "{\"n\": 17224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.08, \"learn_time_ms\": 10292.491, \"total_train_time_s\": 11.676117658615112}", "{\"n\": 17225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.08, \"learn_time_ms\": 10231.987, \"total_train_time_s\": 11.810665845870972}", "{\"n\": 17226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.08, \"learn_time_ms\": 10197.078, \"total_train_time_s\": 12.642213106155396}", "{\"n\": 17227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.35, \"learn_time_ms\": 10201.375, \"total_train_time_s\": 12.531900882720947}", "{\"n\": 17228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.35, \"learn_time_ms\": 10288.149, \"total_train_time_s\": 13.172241449356079}", "{\"n\": 17229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.48, \"learn_time_ms\": 10226.75, \"total_train_time_s\": 12.046106100082397}", "{\"n\": 17230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.58, \"learn_time_ms\": 10345.081, \"total_train_time_s\": 12.363982915878296}", "{\"n\": 17231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.89, \"learn_time_ms\": 10521.02, \"total_train_time_s\": 13.38553500175476}", "{\"n\": 17232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.82, \"learn_time_ms\": 10570.935, \"total_train_time_s\": 12.784080743789673}", "{\"n\": 17233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.25, \"learn_time_ms\": 10549.723, \"total_train_time_s\": 12.308257818222046}", "{\"n\": 17234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.78, \"learn_time_ms\": 10617.317, \"total_train_time_s\": 12.357743263244629}", "{\"n\": 17235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.75, \"learn_time_ms\": 10617.897, \"total_train_time_s\": 11.779197454452515}", "{\"n\": 17236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.87, \"learn_time_ms\": 10520.787, \"total_train_time_s\": 11.678641319274902}", "{\"n\": 17237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.87, \"learn_time_ms\": 10561.746, \"total_train_time_s\": 12.904836654663086}", "{\"n\": 17238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.04, \"learn_time_ms\": 10452.34, \"total_train_time_s\": 12.11741590499878}", "{\"n\": 17239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.04, \"learn_time_ms\": 10648.155, \"total_train_time_s\": 13.974706411361694}", "{\"n\": 17240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.2, \"learn_time_ms\": 10686.701, \"total_train_time_s\": 12.741718530654907}", "{\"n\": 17241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.2, \"learn_time_ms\": 10535.855, \"total_train_time_s\": 11.865659713745117}", "{\"n\": 17242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.34, \"learn_time_ms\": 10451.369, \"total_train_time_s\": 11.895314931869507}", "{\"n\": 17243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.85, \"learn_time_ms\": 10505.551, \"total_train_time_s\": 12.851927280426025}", "{\"n\": 17244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.85, \"learn_time_ms\": 10380.545, \"total_train_time_s\": 11.093616485595703}", "{\"n\": 17245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.2, \"learn_time_ms\": 10342.207, \"total_train_time_s\": 11.429770469665527}", "{\"n\": 17246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.55, \"learn_time_ms\": 10418.887, \"total_train_time_s\": 12.439573287963867}", "{\"n\": 17247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.48, \"learn_time_ms\": 10400.339, \"total_train_time_s\": 12.729572057723999}", "{\"n\": 17248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.48, \"learn_time_ms\": 10348.124, \"total_train_time_s\": 11.580329895019531}", "{\"n\": 17249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.42, \"learn_time_ms\": 10106.063, \"total_train_time_s\": 11.585604429244995}", "{\"n\": 17250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.86, \"learn_time_ms\": 10031.972, \"total_train_time_s\": 12.017504930496216}", "{\"n\": 17251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.86, \"learn_time_ms\": 10144.226, \"total_train_time_s\": 13.030570983886719}", "{\"n\": 17252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.78, \"learn_time_ms\": 10278.496, \"total_train_time_s\": 13.236831903457642}", "{\"n\": 17253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.86, \"learn_time_ms\": 10269.318, \"total_train_time_s\": 12.690798044204712}", "{\"n\": 17254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.84, \"learn_time_ms\": 10289.577, \"total_train_time_s\": 11.275990009307861}", "{\"n\": 17255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.87, \"learn_time_ms\": 10350.776, \"total_train_time_s\": 12.086049318313599}", "{\"n\": 17256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.87, \"learn_time_ms\": 10343.032, \"total_train_time_s\": 12.379204750061035}", "{\"n\": 17257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.64, \"learn_time_ms\": 10268.434, \"total_train_time_s\": 11.997692823410034}", "{\"n\": 17258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.5, \"learn_time_ms\": 10313.46, \"total_train_time_s\": 12.035504817962646}", "{\"n\": 17259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.5, \"learn_time_ms\": 10322.81, \"total_train_time_s\": 11.707842350006104}", "{\"n\": 17260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.52, \"learn_time_ms\": 10294.828, \"total_train_time_s\": 11.76107382774353}", "{\"n\": 17261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.65, \"learn_time_ms\": 10219.448, \"total_train_time_s\": 12.228108167648315}", "{\"n\": 17262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.65, \"learn_time_ms\": 10016.836, \"total_train_time_s\": 11.235121011734009}", "{\"n\": 17263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.12, \"learn_time_ms\": 10004.793, \"total_train_time_s\": 12.645091772079468}", "{\"n\": 17264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.45, \"learn_time_ms\": 10134.504, \"total_train_time_s\": 12.583942174911499}", "{\"n\": 17265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.62, \"learn_time_ms\": 10094.689, \"total_train_time_s\": 11.63800859451294}", "{\"n\": 17266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.62, \"learn_time_ms\": 10162.844, \"total_train_time_s\": 13.03476595878601}", "{\"n\": 17267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.9, \"learn_time_ms\": 10249.394, \"total_train_time_s\": 12.828056573867798}", "{\"n\": 17268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.9, \"learn_time_ms\": 10262.522, \"total_train_time_s\": 12.162585020065308}", "{\"n\": 17269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.33, \"learn_time_ms\": 10294.029, \"total_train_time_s\": 11.995314836502075}", "{\"n\": 17270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.9, \"learn_time_ms\": 10262.486, \"total_train_time_s\": 11.463964462280273}", "{\"n\": 17271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.9, \"learn_time_ms\": 10221.72, \"total_train_time_s\": 11.807471752166748}", "{\"n\": 17272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.9, \"learn_time_ms\": 10323.336, \"total_train_time_s\": 12.192018508911133}", "{\"n\": 17273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 10147.815, \"total_train_time_s\": 10.840569496154785}", "{\"n\": 17274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 10177.111, \"total_train_time_s\": 12.914279460906982}", "{\"n\": 17275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 10157.449, \"total_train_time_s\": 11.515769958496094}", "{\"n\": 17276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.68, \"learn_time_ms\": 9910.93, \"total_train_time_s\": 10.579870462417603}", "{\"n\": 17277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.66, \"learn_time_ms\": 9707.305, \"total_train_time_s\": 10.880486726760864}", "{\"n\": 17278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.7, \"learn_time_ms\": 9713.4, \"total_train_time_s\": 12.275493860244751}", "{\"n\": 17279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.7, \"learn_time_ms\": 9643.292, \"total_train_time_s\": 11.278666257858276}", "{\"n\": 17280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.07, \"learn_time_ms\": 9766.234, \"total_train_time_s\": 12.632650136947632}", "{\"n\": 17281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.07, \"learn_time_ms\": 9878.033, \"total_train_time_s\": 12.917781591415405}", "{\"n\": 17282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.72, \"learn_time_ms\": 9898.815, \"total_train_time_s\": 12.419996738433838}", "{\"n\": 17283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.92, \"learn_time_ms\": 10092.717, \"total_train_time_s\": 12.792318105697632}", "{\"n\": 17284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.25, \"learn_time_ms\": 10092.862, \"total_train_time_s\": 12.863785982131958}", "{\"n\": 17285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.91, \"learn_time_ms\": 10112.156, \"total_train_time_s\": 11.655664205551147}", "{\"n\": 17286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.3, \"learn_time_ms\": 10182.927, \"total_train_time_s\": 11.277966976165771}", "{\"n\": 17287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.24, \"learn_time_ms\": 10342.119, \"total_train_time_s\": 12.391414403915405}", "{\"n\": 17288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.57, \"learn_time_ms\": 10296.366, \"total_train_time_s\": 11.768918514251709}", "{\"n\": 17289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 10320.637, \"total_train_time_s\": 11.509917497634888}", "{\"n\": 17290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 10310.117, \"total_train_time_s\": 12.493006706237793}", "{\"n\": 17291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.85, \"learn_time_ms\": 10181.217, \"total_train_time_s\": 11.655006885528564}", "{\"n\": 17292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.25, \"learn_time_ms\": 10228.807, \"total_train_time_s\": 12.915518999099731}", "{\"n\": 17293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.08, \"learn_time_ms\": 10200.794, \"total_train_time_s\": 12.50734806060791}", "{\"n\": 17294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.08, \"learn_time_ms\": 10198.984, \"total_train_time_s\": 12.886052370071411}", "{\"n\": 17295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.47, \"learn_time_ms\": 10263.42, \"total_train_time_s\": 12.297887325286865}", "{\"n\": 17296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.11, \"learn_time_ms\": 10389.881, \"total_train_time_s\": 12.553289890289307}", "{\"n\": 17297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.0, \"learn_time_ms\": 10358.069, \"total_train_time_s\": 12.126410961151123}", "{\"n\": 17298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.0, \"learn_time_ms\": 10316.697, \"total_train_time_s\": 11.428107738494873}", "{\"n\": 17299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.38, \"learn_time_ms\": 10386.977, \"total_train_time_s\": 12.255323648452759}", "{\"n\": 17300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.67, \"learn_time_ms\": 10323.088, \"total_train_time_s\": 11.90192723274231}", "{\"n\": 17301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.67, \"learn_time_ms\": 10361.925, \"total_train_time_s\": 12.02366018295288}", "{\"n\": 17302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.36, \"learn_time_ms\": 10288.828, \"total_train_time_s\": 12.199172735214233}", "{\"n\": 17303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.78, \"learn_time_ms\": 10255.902, \"total_train_time_s\": 12.181136131286621}", "{\"n\": 17304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.3, \"learn_time_ms\": 10130.84, \"total_train_time_s\": 11.575484991073608}", "{\"n\": 17305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.3, \"learn_time_ms\": 10167.725, \"total_train_time_s\": 12.666564702987671}", "{\"n\": 17306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.92, \"learn_time_ms\": 10153.45, \"total_train_time_s\": 12.397926092147827}", "{\"n\": 17307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.94, \"learn_time_ms\": 10232.189, \"total_train_time_s\": 12.876989841461182}", "{\"n\": 17308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.39, \"learn_time_ms\": 10304.599, \"total_train_time_s\": 12.099027633666992}", "{\"n\": 17309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.39, \"learn_time_ms\": 10256.978, \"total_train_time_s\": 11.770190000534058}", "{\"n\": 17310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.8, \"learn_time_ms\": 10206.725, \"total_train_time_s\": 11.419006109237671}", "{\"n\": 17311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.31, \"learn_time_ms\": 10241.325, \"total_train_time_s\": 12.43471908569336}", "{\"n\": 17312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.31, \"learn_time_ms\": 10228.2, \"total_train_time_s\": 12.038820743560791}", "{\"n\": 17313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.31, \"learn_time_ms\": 10116.588, \"total_train_time_s\": 11.08128571510315}", "{\"n\": 17314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.03, \"learn_time_ms\": 10148.095, \"total_train_time_s\": 11.9299795627594}", "{\"n\": 17315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.69, \"learn_time_ms\": 10206.323, \"total_train_time_s\": 13.249085426330566}", "{\"n\": 17316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.69, \"learn_time_ms\": 10120.607, \"total_train_time_s\": 11.550897359848022}", "{\"n\": 17317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.85, \"learn_time_ms\": 10065.041, \"total_train_time_s\": 12.342357635498047}", "{\"n\": 17318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.2, \"learn_time_ms\": 10011.975, \"total_train_time_s\": 11.556587219238281}", "{\"n\": 17319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.94, \"learn_time_ms\": 10019.608, \"total_train_time_s\": 11.833921432495117}", "{\"n\": 17320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.94, \"learn_time_ms\": 10091.467, \"total_train_time_s\": 12.092397451400757}", "{\"n\": 17321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.73, \"learn_time_ms\": 10034.294, \"total_train_time_s\": 11.821150302886963}", "{\"n\": 17322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.97, \"learn_time_ms\": 10036.464, \"total_train_time_s\": 12.064450979232788}", "{\"n\": 17323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.0, \"learn_time_ms\": 10129.072, \"total_train_time_s\": 12.03939175605774}", "{\"n\": 17324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.0, \"learn_time_ms\": 10108.22, \"total_train_time_s\": 11.700399160385132}", "{\"n\": 17325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.94, \"learn_time_ms\": 9908.985, \"total_train_time_s\": 11.264307022094727}", "{\"n\": 17326, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.57, \"learn_time_ms\": 9995.551, \"total_train_time_s\": 12.410705327987671}", "{\"n\": 17327, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.0, \"learn_time_ms\": 9964.658, \"total_train_time_s\": 12.036738395690918}", "{\"n\": 17328, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.22, \"learn_time_ms\": 9955.746, \"total_train_time_s\": 11.481174230575562}", "{\"n\": 17329, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.99, \"learn_time_ms\": 10030.258, \"total_train_time_s\": 12.589716672897339}", "{\"n\": 17330, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.99, \"learn_time_ms\": 10047.148, \"total_train_time_s\": 12.24487042427063}", "{\"n\": 17331, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.21, \"learn_time_ms\": 10116.581, \"total_train_time_s\": 12.52031683921814}", "{\"n\": 17332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.28, \"learn_time_ms\": 10181.714, \"total_train_time_s\": 12.745968580245972}", "{\"n\": 17333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.32, \"learn_time_ms\": 10167.49, \"total_train_time_s\": 11.886837720870972}", "{\"n\": 17334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.32, \"learn_time_ms\": 10232.876, \"total_train_time_s\": 12.349416732788086}", "{\"n\": 17335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.15, \"learn_time_ms\": 10376.481, \"total_train_time_s\": 12.669000148773193}", "{\"n\": 17336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.53, \"learn_time_ms\": 10329.798, \"total_train_time_s\": 11.90620493888855}", "{\"n\": 17337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.39, \"learn_time_ms\": 10271.705, \"total_train_time_s\": 11.429029941558838}", "{\"n\": 17338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.39, \"learn_time_ms\": 10329.547, \"total_train_time_s\": 12.060924530029297}", "{\"n\": 17339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3679.04, \"learn_time_ms\": 10280.076, \"total_train_time_s\": 12.093815088272095}", "{\"n\": 17340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3679.04, \"learn_time_ms\": 10344.805, \"total_train_time_s\": 12.925416707992554}", "{\"n\": 17341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3679.02, \"learn_time_ms\": 10357.621, \"total_train_time_s\": 12.710733652114868}", "{\"n\": 17342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3678.99, \"learn_time_ms\": 10297.75, \"total_train_time_s\": 12.136822938919067}", "{\"n\": 17343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3671.29, \"learn_time_ms\": 10329.601, \"total_train_time_s\": 12.12711215019226}", "{\"n\": 17344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3671.29, \"learn_time_ms\": 10245.218, \"total_train_time_s\": 11.521834373474121}", "{\"n\": 17345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.18, \"learn_time_ms\": 10112.765, \"total_train_time_s\": 11.348926782608032}", "{\"n\": 17346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.47, \"learn_time_ms\": 10114.536, \"total_train_time_s\": 11.948938608169556}", "{\"n\": 17347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.36, \"learn_time_ms\": 10146.917, \"total_train_time_s\": 11.769174337387085}", "{\"n\": 17348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.09, \"learn_time_ms\": 10155.418, \"total_train_time_s\": 12.157822847366333}", "{\"n\": 17349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3682.03, \"learn_time_ms\": 10120.356, \"total_train_time_s\": 11.692869424819946}", "{\"n\": 17350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3681.5, \"learn_time_ms\": 10185.525, \"total_train_time_s\": 13.567221403121948}", "{\"n\": 17351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3681.5, \"learn_time_ms\": 10211.093, \"total_train_time_s\": 12.878072500228882}", "{\"n\": 17352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.13, \"learn_time_ms\": 10195.629, \"total_train_time_s\": 11.972150564193726}", "{\"n\": 17353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.91, \"learn_time_ms\": 10116.798, \"total_train_time_s\": 11.378239870071411}", "{\"n\": 17354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.18, \"learn_time_ms\": 10121.941, \"total_train_time_s\": 11.58707070350647}", "{\"n\": 17355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3665.97, \"learn_time_ms\": 10170.565, \"total_train_time_s\": 11.848696947097778}", "{\"n\": 17356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3667.02, \"learn_time_ms\": 10253.888, \"total_train_time_s\": 12.76626181602478}", "{\"n\": 17357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.69, \"learn_time_ms\": 10289.91, \"total_train_time_s\": 12.152928829193115}", "{\"n\": 17358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.2, \"learn_time_ms\": 10207.509, \"total_train_time_s\": 11.303724527359009}", "{\"n\": 17359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.2, \"learn_time_ms\": 10224.049, \"total_train_time_s\": 11.915618181228638}", "{\"n\": 17360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.22, \"learn_time_ms\": 10066.88, \"total_train_time_s\": 12.00624132156372}", "{\"n\": 17361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.01, \"learn_time_ms\": 9978.049, \"total_train_time_s\": 12.011622667312622}", "{\"n\": 17362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.01, \"learn_time_ms\": 9922.818, \"total_train_time_s\": 11.409170866012573}", "{\"n\": 17363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.01, \"learn_time_ms\": 10015.878, \"total_train_time_s\": 12.288456916809082}", "{\"n\": 17364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.41, \"learn_time_ms\": 10065.359, \"total_train_time_s\": 12.082582950592041}", "{\"n\": 17365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.65, \"learn_time_ms\": 10041.001, \"total_train_time_s\": 11.604871273040771}", "{\"n\": 17366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.65, \"learn_time_ms\": 9923.612, \"total_train_time_s\": 11.58001184463501}", "{\"n\": 17367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.94, \"learn_time_ms\": 9835.193, \"total_train_time_s\": 11.24205994606018}", "{\"n\": 17368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.37, \"learn_time_ms\": 9947.616, \"total_train_time_s\": 12.443756580352783}", "{\"n\": 17369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.37, \"learn_time_ms\": 10063.458, \"total_train_time_s\": 13.00935173034668}", "{\"n\": 17370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.29, \"learn_time_ms\": 10170.387, \"total_train_time_s\": 13.085776805877686}", "{\"n\": 17371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.47, \"learn_time_ms\": 10220.864, \"total_train_time_s\": 12.523001670837402}", "{\"n\": 17372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.31, \"learn_time_ms\": 10293.021, \"total_train_time_s\": 12.10206651687622}", "{\"n\": 17373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.31, \"learn_time_ms\": 10215.624, \"total_train_time_s\": 11.540396690368652}", "{\"n\": 17374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.96, \"learn_time_ms\": 10207.824, \"total_train_time_s\": 12.037201404571533}", "{\"n\": 17375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.96, \"learn_time_ms\": 10273.846, \"total_train_time_s\": 12.270017862319946}", "{\"n\": 17376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.93, \"learn_time_ms\": 10231.517, \"total_train_time_s\": 11.190311431884766}", "{\"n\": 17377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.5, \"learn_time_ms\": 10372.922, \"total_train_time_s\": 12.669635772705078}", "{\"n\": 17378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.5, \"learn_time_ms\": 10417.147, \"total_train_time_s\": 12.878884077072144}", "{\"n\": 17379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.48, \"learn_time_ms\": 10262.809, \"total_train_time_s\": 11.514536619186401}", "{\"n\": 17380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.33, \"learn_time_ms\": 10155.249, \"total_train_time_s\": 11.978349208831787}", "{\"n\": 17381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.18, \"learn_time_ms\": 10083.026, \"total_train_time_s\": 11.795006513595581}", "{\"n\": 17382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.19, \"learn_time_ms\": 10007.031, \"total_train_time_s\": 11.39357876777649}", "{\"n\": 17383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3632.5, \"learn_time_ms\": 10121.205, \"total_train_time_s\": 12.6795654296875}", "{\"n\": 17384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3632.5, \"learn_time_ms\": 10176.589, \"total_train_time_s\": 12.555981874465942}", "{\"n\": 17385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.42, \"learn_time_ms\": 10222.983, \"total_train_time_s\": 12.7280752658844}", "{\"n\": 17386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.61, \"learn_time_ms\": 10349.395, \"total_train_time_s\": 12.471914529800415}", "{\"n\": 17387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3620.57, \"learn_time_ms\": 10183.139, \"total_train_time_s\": 10.987581968307495}", "{\"n\": 17388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.0, \"learn_time_ms\": 10032.663, \"total_train_time_s\": 11.407000303268433}", "{\"n\": 17389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3611.0, \"learn_time_ms\": 10086.116, \"total_train_time_s\": 12.041433572769165}", "{\"n\": 17390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.41, \"learn_time_ms\": 10053.633, \"total_train_time_s\": 11.681027889251709}", "{\"n\": 17391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 10007.876, \"total_train_time_s\": 11.34652304649353}", "{\"n\": 17392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.97, \"learn_time_ms\": 10051.778, \"total_train_time_s\": 11.853037357330322}", "{\"n\": 17393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3602.14, \"learn_time_ms\": 10075.135, \"total_train_time_s\": 12.933299541473389}", "{\"n\": 17394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3602.14, \"learn_time_ms\": 10034.969, \"total_train_time_s\": 12.148823499679565}", "{\"n\": 17395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3602.14, \"learn_time_ms\": 9856.426, \"total_train_time_s\": 10.911344766616821}", "{\"n\": 17396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3590.88, \"learn_time_ms\": 9785.952, \"total_train_time_s\": 11.733129262924194}", "{\"n\": 17397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.83, \"learn_time_ms\": 9960.695, \"total_train_time_s\": 12.721235990524292}", "{\"n\": 17398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.83, \"learn_time_ms\": 10139.738, \"total_train_time_s\": 13.147691488265991}", "{\"n\": 17399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.71, \"learn_time_ms\": 10080.501, \"total_train_time_s\": 11.462631940841675}", "{\"n\": 17400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.71, \"learn_time_ms\": 10286.155, \"total_train_time_s\": 13.759680271148682}", "{\"n\": 17401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.08, \"learn_time_ms\": 10335.729, \"total_train_time_s\": 11.843415021896362}", "{\"n\": 17402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.08, \"learn_time_ms\": 10250.455, \"total_train_time_s\": 10.947104692459106}", "{\"n\": 17403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 10128.146, \"total_train_time_s\": 11.720219850540161}", "{\"n\": 17404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 10014.789, \"total_train_time_s\": 10.967809200286865}", "{\"n\": 17405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.32, \"learn_time_ms\": 10109.238, \"total_train_time_s\": 11.88602900505066}", "{\"n\": 17406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.22, \"learn_time_ms\": 10056.894, \"total_train_time_s\": 11.23724102973938}", "{\"n\": 17407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.22, \"learn_time_ms\": 10050.263, \"total_train_time_s\": 12.66909122467041}", "{\"n\": 17408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.22, \"learn_time_ms\": 10000.603, \"total_train_time_s\": 12.688629388809204}", "{\"n\": 17409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3589.83, \"learn_time_ms\": 10017.886, \"total_train_time_s\": 11.635045528411865}", "{\"n\": 17410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.72, \"learn_time_ms\": 9894.333, \"total_train_time_s\": 12.476715803146362}", "{\"n\": 17411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.66, \"learn_time_ms\": 9894.154, \"total_train_time_s\": 11.814664602279663}", "{\"n\": 17412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.66, \"learn_time_ms\": 10067.251, \"total_train_time_s\": 12.697881698608398}", "{\"n\": 17413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.81, \"learn_time_ms\": 10100.322, \"total_train_time_s\": 12.012875080108643}", "{\"n\": 17414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.79, \"learn_time_ms\": 10149.948, \"total_train_time_s\": 11.509057521820068}", "{\"n\": 17415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.79, \"learn_time_ms\": 10140.28, \"total_train_time_s\": 11.767651319503784}", "{\"n\": 17416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.93, \"learn_time_ms\": 10244.033, \"total_train_time_s\": 12.27517318725586}", "{\"n\": 17417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.81, \"learn_time_ms\": 10225.919, \"total_train_time_s\": 12.530908107757568}", "{\"n\": 17418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.81, \"learn_time_ms\": 10284.411, \"total_train_time_s\": 13.261679887771606}", "{\"n\": 17419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.02, \"learn_time_ms\": 10342.543, \"total_train_time_s\": 12.21019983291626}", "{\"n\": 17420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3547.96, \"learn_time_ms\": 10320.61, \"total_train_time_s\": 12.302222490310669}", "{\"n\": 17421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3547.96, \"learn_time_ms\": 10355.2, \"total_train_time_s\": 12.193474531173706}", "{\"n\": 17422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.31, \"learn_time_ms\": 10240.982, \"total_train_time_s\": 11.566802978515625}", "{\"n\": 17423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.31, \"learn_time_ms\": 10219.378, \"total_train_time_s\": 11.80199646949768}", "{\"n\": 17424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.21, \"learn_time_ms\": 10186.552, \"total_train_time_s\": 11.213349103927612}", "{\"n\": 17425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.06, \"learn_time_ms\": 10160.296, \"total_train_time_s\": 11.55023193359375}", "{\"n\": 17426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3524.56, \"learn_time_ms\": 10039.202, \"total_train_time_s\": 11.097058773040771}", "{\"n\": 17427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3518.67, \"learn_time_ms\": 10018.037, \"total_train_time_s\": 12.284419298171997}", "{\"n\": 17428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3518.67, \"learn_time_ms\": 9931.884, \"total_train_time_s\": 12.366300821304321}", "{\"n\": 17429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3513.09, \"learn_time_ms\": 9898.113, \"total_train_time_s\": 11.84598159790039}", "{\"n\": 17430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3521.82, \"learn_time_ms\": 9855.673, \"total_train_time_s\": 11.869594812393188}", "{\"n\": 17431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3519.51, \"learn_time_ms\": 9853.199, \"total_train_time_s\": 12.14414668083191}", "{\"n\": 17432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.43, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3519.51, \"learn_time_ms\": 9920.818, \"total_train_time_s\": 12.21127963066101}", "{\"n\": 17433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3529.24, \"learn_time_ms\": 9933.464, \"total_train_time_s\": 11.922933578491211}", "{\"n\": 17434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3529.24, \"learn_time_ms\": 10000.023, \"total_train_time_s\": 11.833793640136719}", "{\"n\": 17435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.23, \"learn_time_ms\": 9969.364, \"total_train_time_s\": 11.226458549499512}", "{\"n\": 17436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.5, \"learn_time_ms\": 9974.266, \"total_train_time_s\": 11.098770380020142}", "{\"n\": 17437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.5, \"learn_time_ms\": 10072.586, \"total_train_time_s\": 13.23382306098938}", "{\"n\": 17438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.64, \"learn_time_ms\": 10135.36, \"total_train_time_s\": 13.032837390899658}", "{\"n\": 17439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.42, \"learn_time_ms\": 10316.872, \"total_train_time_s\": 13.732267141342163}", "{\"n\": 17440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3533.76, \"learn_time_ms\": 10358.922, \"total_train_time_s\": 12.31077527999878}", "{\"n\": 17441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.47, \"learn_time_ms\": 10388.673, \"total_train_time_s\": 12.497642278671265}", "{\"n\": 17442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.71, \"learn_time_ms\": 10300.419, \"total_train_time_s\": 11.353765964508057}", "{\"n\": 17443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.71, \"learn_time_ms\": 10214.717, \"total_train_time_s\": 11.035150527954102}", "{\"n\": 17444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.97, \"learn_time_ms\": 10328.771, \"total_train_time_s\": 12.979012966156006}", "{\"n\": 17445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.97, \"learn_time_ms\": 10348.366, \"total_train_time_s\": 11.399638175964355}", "{\"n\": 17446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.97, \"learn_time_ms\": 10443.315, \"total_train_time_s\": 12.054020643234253}", "{\"n\": 17447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3535.12, \"learn_time_ms\": 10306.95, \"total_train_time_s\": 11.879448652267456}", "{\"n\": 17448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.66, \"learn_time_ms\": 10345.841, \"total_train_time_s\": 13.396362543106079}", "{\"n\": 17449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.05, \"learn_time_ms\": 10231.379, \"total_train_time_s\": 12.540937900543213}", "{\"n\": 17450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.05, \"learn_time_ms\": 10264.36, \"total_train_time_s\": 12.592320919036865}", "{\"n\": 17451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3559.24, \"learn_time_ms\": 10241.301, \"total_train_time_s\": 12.24728512763977}", "{\"n\": 17452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.28, \"learn_time_ms\": 10419.565, \"total_train_time_s\": 13.112424612045288}", "{\"n\": 17453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.28, \"learn_time_ms\": 10472.238, \"total_train_time_s\": 11.59271240234375}", "{\"n\": 17454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3546.22, \"learn_time_ms\": 10520.2, \"total_train_time_s\": 13.47932243347168}", "{\"n\": 17455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.38, \"learn_time_ms\": 10591.596, \"total_train_time_s\": 12.15253233909607}", "{\"n\": 17456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.38, \"learn_time_ms\": 10533.514, \"total_train_time_s\": 11.434588432312012}", "{\"n\": 17457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.85, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.43, \"learn_time_ms\": 10511.485, \"total_train_time_s\": 11.726730346679688}", "{\"n\": 17458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3558.75, \"learn_time_ms\": 10422.887, \"total_train_time_s\": 12.536927938461304}", "{\"n\": 17459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3557.29, \"learn_time_ms\": 10311.022, \"total_train_time_s\": 11.438762187957764}", "{\"n\": 17460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3557.29, \"learn_time_ms\": 10283.799, \"total_train_time_s\": 12.287418842315674}", "{\"n\": 17461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3554.75, \"learn_time_ms\": 10230.243, \"total_train_time_s\": 11.662730932235718}", "{\"n\": 17462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3571.11, \"learn_time_ms\": 10296.856, \"total_train_time_s\": 13.77884554862976}", "{\"n\": 17463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3571.11, \"learn_time_ms\": 10289.025, \"total_train_time_s\": 11.545006513595581}", "{\"n\": 17464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3571.11, \"learn_time_ms\": 10086.54, \"total_train_time_s\": 11.399673461914062}", "{\"n\": 17465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3578.17, \"learn_time_ms\": 10117.855, \"total_train_time_s\": 12.412809371948242}", "{\"n\": 17466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3578.17, \"learn_time_ms\": 10238.112, \"total_train_time_s\": 12.692679166793823}", "{\"n\": 17467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3573.29, \"learn_time_ms\": 10219.681, \"total_train_time_s\": 11.538643836975098}", "{\"n\": 17468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3569.24, \"learn_time_ms\": 10142.681, \"total_train_time_s\": 11.743130683898926}", "{\"n\": 17469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3569.81, \"learn_time_ms\": 10140.698, \"total_train_time_s\": 11.370394706726074}", "{\"n\": 17470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3569.81, \"learn_time_ms\": 10014.074, \"total_train_time_s\": 11.03782844543457}", "{\"n\": 17471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.48, \"learn_time_ms\": 10049.543, \"total_train_time_s\": 12.049080848693848}", "{\"n\": 17472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3565.2, \"learn_time_ms\": 9790.445, \"total_train_time_s\": 11.20716905593872}", "{\"n\": 17473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3565.07, \"learn_time_ms\": 9782.872, \"total_train_time_s\": 11.439271450042725}", "{\"n\": 17474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3565.07, \"learn_time_ms\": 9882.897, \"total_train_time_s\": 12.42587661743164}", "{\"n\": 17475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3568.93, \"learn_time_ms\": 9946.848, \"total_train_time_s\": 13.0667564868927}", "{\"n\": 17476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.37, \"learn_time_ms\": 9885.513, \"total_train_time_s\": 12.075660228729248}", "{\"n\": 17477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.68, \"learn_time_ms\": 10043.127, \"total_train_time_s\": 13.11528754234314}", "{\"n\": 17478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.94, \"learn_time_ms\": 10096.479, \"total_train_time_s\": 12.321751117706299}", "{\"n\": 17479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3579.94, \"learn_time_ms\": 10148.543, \"total_train_time_s\": 11.951077699661255}", "{\"n\": 17480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.41, \"learn_time_ms\": 10261.383, \"total_train_time_s\": 12.206089735031128}", "{\"n\": 17481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.89, \"learn_time_ms\": 10341.675, \"total_train_time_s\": 12.834222316741943}", "{\"n\": 17482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.89, \"learn_time_ms\": 10459.474, \"total_train_time_s\": 12.372623205184937}", "{\"n\": 17483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3586.25, \"learn_time_ms\": 10486.004, \"total_train_time_s\": 11.677032470703125}", "{\"n\": 17484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3591.33, \"learn_time_ms\": 10555.299, \"total_train_time_s\": 13.094995260238647}", "{\"n\": 17485, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.33, \"learn_time_ms\": 10433.392, \"total_train_time_s\": 11.830492734909058}", "{\"n\": 17486, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3598.56, \"learn_time_ms\": 10520.203, \"total_train_time_s\": 12.957401514053345}", "{\"n\": 17487, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.21, \"learn_time_ms\": 10442.332, \"total_train_time_s\": 12.303917646408081}", "{\"n\": 17488, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3597.84, \"learn_time_ms\": 10418.305, \"total_train_time_s\": 12.0553138256073}", "{\"n\": 17489, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3607.89, \"learn_time_ms\": 10369.112, \"total_train_time_s\": 11.431143522262573}", "{\"n\": 17490, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.94, \"learn_time_ms\": 10379.965, \"total_train_time_s\": 12.310299396514893}", "{\"n\": 17491, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3603.46, \"learn_time_ms\": 10276.843, \"total_train_time_s\": 11.809821128845215}", "{\"n\": 17492, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3603.46, \"learn_time_ms\": 10329.531, \"total_train_time_s\": 12.878339529037476}", "{\"n\": 17493, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.03, \"learn_time_ms\": 10233.281, \"total_train_time_s\": 10.762989282608032}", "{\"n\": 17494, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3600.03, \"learn_time_ms\": 10194.016, \"total_train_time_s\": 12.724273920059204}", "{\"n\": 17495, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.1, \"learn_time_ms\": 10191.334, \"total_train_time_s\": 11.847163915634155}", "{\"n\": 17496, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3583.1, \"learn_time_ms\": 9984.13, \"total_train_time_s\": 10.844871282577515}", "{\"n\": 17497, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.29, \"learn_time_ms\": 9920.222, \"total_train_time_s\": 11.656174182891846}", "{\"n\": 17498, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.48, \"learn_time_ms\": 9817.682, \"total_train_time_s\": 11.023926496505737}", "{\"n\": 17499, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3576.32, \"learn_time_ms\": 9951.262, \"total_train_time_s\": 12.75635313987732}", "{\"n\": 17500, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3577.12, \"learn_time_ms\": 9805.475, \"total_train_time_s\": 10.860119819641113}", "{\"n\": 17501, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3578.99, \"learn_time_ms\": 9853.323, \"total_train_time_s\": 12.272383689880371}", "{\"n\": 17502, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3574.92, \"learn_time_ms\": 9837.807, \"total_train_time_s\": 12.765709400177002}", "{\"n\": 17503, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3585.23, \"learn_time_ms\": 9957.497, \"total_train_time_s\": 11.943614482879639}", "{\"n\": 17504, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3585.23, \"learn_time_ms\": 9924.816, \"total_train_time_s\": 12.374567747116089}", "{\"n\": 17505, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3576.89, \"learn_time_ms\": 9970.855, \"total_train_time_s\": 12.31057095527649}", "{\"n\": 17506, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3582.68, \"learn_time_ms\": 10160.452, \"total_train_time_s\": 12.768004417419434}", "{\"n\": 17507, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3591.26, \"learn_time_ms\": 10234.544, \"total_train_time_s\": 12.443493127822876}", "{\"n\": 17508, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3591.26, \"learn_time_ms\": 10306.874, \"total_train_time_s\": 11.734119892120361}", "{\"n\": 17509, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3606.51, \"learn_time_ms\": 10303.3, \"total_train_time_s\": 12.712813377380371}", "{\"n\": 17510, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3594.09, \"learn_time_ms\": 10453.963, \"total_train_time_s\": 12.364310503005981}", "{\"n\": 17511, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3596.39, \"learn_time_ms\": 10458.964, \"total_train_time_s\": 12.358280658721924}", "{\"n\": 17512, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3596.39, \"learn_time_ms\": 10342.742, \"total_train_time_s\": 11.585222482681274}", "{\"n\": 17513, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3607.31, \"learn_time_ms\": 10267.788, \"total_train_time_s\": 11.17534065246582}", "{\"n\": 17514, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3607.31, \"learn_time_ms\": 10243.017, \"total_train_time_s\": 12.126891613006592}", "{\"n\": 17515, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3617.64, \"learn_time_ms\": 10188.309, \"total_train_time_s\": 11.708094596862793}", "{\"n\": 17516, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3617.58, \"learn_time_ms\": 10085.42, \"total_train_time_s\": 11.672730922698975}", "{\"n\": 17517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3623.71, \"learn_time_ms\": 10061.665, \"total_train_time_s\": 12.153928518295288}", "{\"n\": 17518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3623.71, \"learn_time_ms\": 10164.966, \"total_train_time_s\": 12.774224758148193}", "{\"n\": 17519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3630.72, \"learn_time_ms\": 10126.683, \"total_train_time_s\": 12.3902006149292}", "{\"n\": 17520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3638.3, \"learn_time_ms\": 10067.346, \"total_train_time_s\": 11.77752137184143}", "{\"n\": 17521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3638.3, \"learn_time_ms\": 10028.513, \"total_train_time_s\": 11.939374446868896}", "{\"n\": 17522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3640.52, \"learn_time_ms\": 10089.765, \"total_train_time_s\": 12.202839136123657}", "{\"n\": 17523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3636.77, \"learn_time_ms\": 10234.123, \"total_train_time_s\": 12.631345748901367}", "{\"n\": 17524, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3641.26, \"learn_time_ms\": 10168.637, \"total_train_time_s\": 11.469511032104492}", "{\"n\": 17525, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3641.26, \"learn_time_ms\": 10264.34, \"total_train_time_s\": 12.694034814834595}", "{\"n\": 17526, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3643.23, \"learn_time_ms\": 10368.139, \"total_train_time_s\": 12.79668927192688}", "{\"n\": 17527, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10457.787, \"total_train_time_s\": 13.0311918258667}", "{\"n\": 17528, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10392.569, \"total_train_time_s\": 12.098013877868652}", "{\"n\": 17529, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10420.66, \"total_train_time_s\": 12.638261556625366}", "{\"n\": 17530, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3636.48, \"learn_time_ms\": 10450.476, \"total_train_time_s\": 12.082821130752563}", "{\"n\": 17531, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3635.13, \"learn_time_ms\": 10516.52, \"total_train_time_s\": 12.622737884521484}", "{\"n\": 17532, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3646.46, \"learn_time_ms\": 10535.569, \"total_train_time_s\": 12.425771474838257}", "{\"n\": 17533, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3644.75, \"learn_time_ms\": 10560.342, \"total_train_time_s\": 12.860302686691284}", "{\"n\": 17534, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3652.19, \"learn_time_ms\": 10636.036, \"total_train_time_s\": 12.284795045852661}", "{\"n\": 17535, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3651.97, \"learn_time_ms\": 10542.68, \"total_train_time_s\": 11.796560287475586}", "{\"n\": 17536, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3646.5, \"learn_time_ms\": 10430.193, \"total_train_time_s\": 11.683216333389282}", "{\"n\": 17537, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3646.49, \"learn_time_ms\": 10411.715, \"total_train_time_s\": 12.855291843414307}", "{\"n\": 17538, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3646.49, \"learn_time_ms\": 10447.52, \"total_train_time_s\": 12.48281192779541}", "{\"n\": 17539, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3645.31, \"learn_time_ms\": 10426.371, \"total_train_time_s\": 12.421964168548584}", "{\"n\": 17540, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3642.0, \"learn_time_ms\": 10539.8, \"total_train_time_s\": 13.166353225708008}", "{\"n\": 17541, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3635.32, \"learn_time_ms\": 10380.874, \"total_train_time_s\": 11.013105154037476}", "{\"n\": 17542, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3631.35, \"learn_time_ms\": 10247.652, \"total_train_time_s\": 11.079442024230957}", "{\"n\": 17543, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3629.04, \"learn_time_ms\": 10220.484, \"total_train_time_s\": 12.577993392944336}", "{\"n\": 17544, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3637.9, \"learn_time_ms\": 10154.957, \"total_train_time_s\": 11.552452087402344}", "{\"n\": 17545, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 10184.555, \"total_train_time_s\": 12.096181154251099}", "{\"n\": 17546, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 10238.585, \"total_train_time_s\": 12.172656536102295}", "{\"n\": 17547, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.12, \"learn_time_ms\": 10202.355, \"total_train_time_s\": 12.498262643814087}", "{\"n\": 17548, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.22, \"learn_time_ms\": 10095.009, \"total_train_time_s\": 11.360658407211304}", "{\"n\": 17549, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.04, \"learn_time_ms\": 10095.066, \"total_train_time_s\": 12.45353651046753}", "{\"n\": 17550, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.04, \"learn_time_ms\": 9896.861, \"total_train_time_s\": 11.175859928131104}", "{\"n\": 17551, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.88, \"learn_time_ms\": 10059.843, \"total_train_time_s\": 12.644922018051147}", "{\"n\": 17552, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.72, \"learn_time_ms\": 10150.793, \"total_train_time_s\": 11.986851692199707}", "{\"n\": 17553, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.72, \"learn_time_ms\": 10089.403, \"total_train_time_s\": 11.98312759399414}", "{\"n\": 17554, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.72, \"learn_time_ms\": 10080.969, \"total_train_time_s\": 11.517288208007812}", "{\"n\": 17555, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.73, \"learn_time_ms\": 10135.275, \"total_train_time_s\": 12.624971628189087}", "{\"n\": 17556, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 10064.532, \"total_train_time_s\": 11.469934463500977}", "{\"n\": 17557, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 9998.946, \"total_train_time_s\": 11.845082998275757}", "{\"n\": 17558, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.22, \"learn_time_ms\": 10086.934, \"total_train_time_s\": 12.305949926376343}", "{\"n\": 17559, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.21, \"learn_time_ms\": 9922.445, \"total_train_time_s\": 10.752036809921265}", "{\"n\": 17560, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.16, \"learn_time_ms\": 10000.031, \"total_train_time_s\": 11.996692419052124}", "{\"n\": 17561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.58, \"learn_time_ms\": 9895.631, \"total_train_time_s\": 11.637237548828125}", "{\"n\": 17562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.58, \"learn_time_ms\": 9928.095, \"total_train_time_s\": 12.28980541229248}", "{\"n\": 17563, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.79, \"learn_time_ms\": 9908.177, \"total_train_time_s\": 11.815215587615967}", "{\"n\": 17564, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.79, \"learn_time_ms\": 9993.209, \"total_train_time_s\": 12.3809175491333}", "{\"n\": 17565, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.76, \"learn_time_ms\": 9860.085, \"total_train_time_s\": 11.280518054962158}", "{\"n\": 17566, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.76, \"learn_time_ms\": 9900.68, \"total_train_time_s\": 11.886431455612183}", "{\"n\": 17567, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.3, \"learn_time_ms\": 9908.422, \"total_train_time_s\": 11.937917947769165}", "{\"n\": 17568, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.5, \"learn_time_ms\": 9893.543, \"total_train_time_s\": 12.143766164779663}", "{\"n\": 17569, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.5, \"learn_time_ms\": 10071.611, \"total_train_time_s\": 12.574674844741821}", "{\"n\": 17570, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.73, \"learn_time_ms\": 10053.691, \"total_train_time_s\": 11.867439270019531}", "{\"n\": 17571, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.17, \"learn_time_ms\": 10041.827, \"total_train_time_s\": 11.508405447006226}", "{\"n\": 17572, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.52, \"learn_time_ms\": 9980.324, \"total_train_time_s\": 11.646698236465454}", "{\"n\": 17573, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.52, \"learn_time_ms\": 10027.182, \"total_train_time_s\": 12.24530029296875}", "{\"n\": 17574, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.99, \"learn_time_ms\": 9878.348, \"total_train_time_s\": 10.883869171142578}", "{\"n\": 17575, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.94, \"learn_time_ms\": 10104.581, \"total_train_time_s\": 13.577077627182007}", "{\"n\": 17576, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.7, \"learn_time_ms\": 10103.287, \"total_train_time_s\": 11.895364046096802}", "{\"n\": 17577, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.09, \"learn_time_ms\": 10099.763, \"total_train_time_s\": 11.850369453430176}", "{\"n\": 17578, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.32, \"learn_time_ms\": 9981.513, \"total_train_time_s\": 10.962697267532349}", "{\"n\": 17579, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.32, \"learn_time_ms\": 9968.193, \"total_train_time_s\": 12.370195150375366}", "{\"n\": 17580, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.97, \"learn_time_ms\": 10079.936, \"total_train_time_s\": 12.895116090774536}", "{\"n\": 17581, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.97, \"learn_time_ms\": 10155.738, \"total_train_time_s\": 12.203340768814087}", "{\"n\": 17582, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.49, \"learn_time_ms\": 10125.334, \"total_train_time_s\": 11.361445903778076}", "{\"n\": 17583, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.49, \"learn_time_ms\": 10208.435, \"total_train_time_s\": 13.094883918762207}", "{\"n\": 17584, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.17, \"learn_time_ms\": 10315.972, \"total_train_time_s\": 11.959842205047607}", "{\"n\": 17585, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.08, \"learn_time_ms\": 10063.817, \"total_train_time_s\": 11.027992248535156}", "{\"n\": 17586, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.71, \"learn_time_ms\": 10083.867, \"total_train_time_s\": 12.069067478179932}", "{\"n\": 17587, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.44, \"learn_time_ms\": 10031.628, \"total_train_time_s\": 11.375561952590942}", "{\"n\": 17588, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.44, \"learn_time_ms\": 10266.354, \"total_train_time_s\": 13.320126295089722}", "{\"n\": 17589, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.04, \"learn_time_ms\": 10129.659, \"total_train_time_s\": 11.025827169418335}", "{\"n\": 17590, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.04, \"learn_time_ms\": 10180.139, \"total_train_time_s\": 13.420548439025879}", "{\"n\": 17591, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.73, \"learn_time_ms\": 10192.132, \"total_train_time_s\": 12.365544080734253}", "{\"n\": 17592, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.53, \"learn_time_ms\": 10299.968, \"total_train_time_s\": 12.419846773147583}", "{\"n\": 17593, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.22, \"learn_time_ms\": 10290.153, \"total_train_time_s\": 13.014595031738281}", "{\"n\": 17594, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.22, \"learn_time_ms\": 10367.02, \"total_train_time_s\": 12.718710899353027}", "{\"n\": 17595, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.71, \"learn_time_ms\": 10466.05, \"total_train_time_s\": 12.013467788696289}", "{\"n\": 17596, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.71, \"learn_time_ms\": 10499.6, \"total_train_time_s\": 12.440335512161255}", "{\"n\": 17597, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.18, \"learn_time_ms\": 10564.285, \"total_train_time_s\": 12.053631782531738}", "{\"n\": 17598, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.2, \"learn_time_ms\": 10420.995, \"total_train_time_s\": 11.8693528175354}", "{\"n\": 17599, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.2, \"learn_time_ms\": 10562.421, \"total_train_time_s\": 12.437299251556396}", "{\"n\": 17600, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.49, \"learn_time_ms\": 10459.293, \"total_train_time_s\": 12.377355337142944}", "{\"n\": 17601, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.2, \"learn_time_ms\": 10481.993, \"total_train_time_s\": 12.607044458389282}", "{\"n\": 17602, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.96, \"learn_time_ms\": 10506.805, \"total_train_time_s\": 12.66945195198059}", "{\"n\": 17603, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.96, \"learn_time_ms\": 10457.427, \"total_train_time_s\": 12.492597579956055}", "{\"n\": 17604, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.75, \"learn_time_ms\": 10400.611, \"total_train_time_s\": 12.156677961349487}", "{\"n\": 17605, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.43, \"learn_time_ms\": 10397.897, \"total_train_time_s\": 11.99642276763916}", "{\"n\": 17606, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.85, \"learn_time_ms\": 10392.513, \"total_train_time_s\": 12.374993085861206}", "{\"n\": 17607, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.38, \"learn_time_ms\": 10396.372, \"total_train_time_s\": 12.073898792266846}", "{\"n\": 17608, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.38, \"learn_time_ms\": 10425.758, \"total_train_time_s\": 12.135276079177856}", "{\"n\": 17609, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.35, \"learn_time_ms\": 10413.56, \"total_train_time_s\": 12.345147132873535}", "{\"n\": 17610, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.35, \"learn_time_ms\": 10341.179, \"total_train_time_s\": 11.655453443527222}", "{\"n\": 17611, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.43, \"learn_time_ms\": 10273.19, \"total_train_time_s\": 11.91662859916687}", "{\"n\": 17612, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.8, \"learn_time_ms\": 10203.119, \"total_train_time_s\": 12.077535629272461}", "{\"n\": 17613, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.43, \"learn_time_ms\": 10148.065, \"total_train_time_s\": 11.946829557418823}", "{\"n\": 17614, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.43, \"learn_time_ms\": 10145.869, \"total_train_time_s\": 12.134005069732666}", "{\"n\": 17615, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.21, \"learn_time_ms\": 10184.418, \"total_train_time_s\": 12.336777925491333}", "{\"n\": 17616, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.91, \"learn_time_ms\": 10063.288, \"total_train_time_s\": 11.150792598724365}", "{\"n\": 17617, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3675.91, \"learn_time_ms\": 10075.945, \"total_train_time_s\": 12.167124509811401}", "{\"n\": 17618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.16, \"learn_time_ms\": 10083.399, \"total_train_time_s\": 12.247650384902954}", "{\"n\": 17619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.16, \"learn_time_ms\": 10113.455, \"total_train_time_s\": 12.611066579818726}", "{\"n\": 17620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.83, \"learn_time_ms\": 10086.556, \"total_train_time_s\": 11.403486013412476}", "{\"n\": 17621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.07, \"learn_time_ms\": 10160.721, \"total_train_time_s\": 12.656835317611694}", "{\"n\": 17622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.07, \"learn_time_ms\": 10177.374, \"total_train_time_s\": 12.160032749176025}", "{\"n\": 17623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.13, \"learn_time_ms\": 10200.626, \"total_train_time_s\": 12.206439971923828}", "{\"n\": 17624, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.59, \"learn_time_ms\": 10297.75, \"total_train_time_s\": 13.100193500518799}", "{\"n\": 17625, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.92, \"learn_time_ms\": 10288.104, \"total_train_time_s\": 12.257676124572754}", "{\"n\": 17626, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.92, \"learn_time_ms\": 10387.881, \"total_train_time_s\": 12.075870752334595}", "{\"n\": 17627, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.68, \"learn_time_ms\": 10391.501, \"total_train_time_s\": 12.239784002304077}", "{\"n\": 17628, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.04, \"learn_time_ms\": 10381.691, \"total_train_time_s\": 12.180896997451782}", "{\"n\": 17629, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.04, \"learn_time_ms\": 10290.022, \"total_train_time_s\": 11.720510244369507}", "{\"n\": 17630, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.04, \"learn_time_ms\": 10340.725, \"total_train_time_s\": 11.914023160934448}", "{\"n\": 17631, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.62, \"learn_time_ms\": 10316.448, \"total_train_time_s\": 12.4298734664917}", "{\"n\": 17632, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.62, \"learn_time_ms\": 10232.297, \"total_train_time_s\": 11.340489387512207}", "{\"n\": 17633, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.62, \"learn_time_ms\": 10335.532, \"total_train_time_s\": 13.238010168075562}", "{\"n\": 17634, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.62, \"learn_time_ms\": 10250.184, \"total_train_time_s\": 12.240841150283813}", "{\"n\": 17635, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 10365.573, \"total_train_time_s\": 13.432952404022217}", "{\"n\": 17636, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 10401.454, \"total_train_time_s\": 12.497919082641602}", "{\"n\": 17637, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.99, \"learn_time_ms\": 10374.207, \"total_train_time_s\": 11.960659503936768}", "{\"n\": 17638, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.05, \"learn_time_ms\": 10357.615, \"total_train_time_s\": 11.962427854537964}", "{\"n\": 17639, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.17, \"learn_time_ms\": 10497.446, \"total_train_time_s\": 13.11277985572815}", "{\"n\": 17640, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.17, \"learn_time_ms\": 10480.286, \"total_train_time_s\": 11.737267255783081}", "{\"n\": 17641, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.17, \"learn_time_ms\": 10434.093, \"total_train_time_s\": 11.948786497116089}", "{\"n\": 17642, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.16, \"learn_time_ms\": 10562.134, \"total_train_time_s\": 12.602163791656494}", "{\"n\": 17643, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.53, \"learn_time_ms\": 10461.532, \"total_train_time_s\": 12.209293603897095}", "{\"n\": 17644, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.53, \"learn_time_ms\": 10374.439, \"total_train_time_s\": 11.397081851959229}", "{\"n\": 17645, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.84, \"learn_time_ms\": 10220.294, \"total_train_time_s\": 11.901596307754517}", "{\"n\": 17646, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.6, \"learn_time_ms\": 10253.196, \"total_train_time_s\": 12.79772162437439}", "{\"n\": 17647, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3681.6, \"learn_time_ms\": 10342.444, \"total_train_time_s\": 12.798722743988037}", "{\"n\": 17648, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.02, \"learn_time_ms\": 10463.672, \"total_train_time_s\": 13.154710054397583}", "{\"n\": 17649, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.9, \"learn_time_ms\": 10457.016, \"total_train_time_s\": 13.060340881347656}", "{\"n\": 17650, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.16, \"learn_time_ms\": 10488.012, \"total_train_time_s\": 12.03622555732727}", "{\"n\": 17651, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.16, \"learn_time_ms\": 10575.98, \"total_train_time_s\": 12.848782300949097}", "{\"n\": 17652, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.59, \"learn_time_ms\": 10643.02, \"total_train_time_s\": 13.277671337127686}", "{\"n\": 17653, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.76, \"learn_time_ms\": 10491.133, \"total_train_time_s\": 10.660035133361816}", "{\"n\": 17654, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.15, \"learn_time_ms\": 10507.427, \"total_train_time_s\": 11.558790445327759}", "{\"n\": 17655, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.15, \"learn_time_ms\": 10556.615, \"total_train_time_s\": 12.375728845596313}", "{\"n\": 17656, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.4, \"learn_time_ms\": 10423.898, \"total_train_time_s\": 11.51081371307373}", "{\"n\": 17657, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.02, \"learn_time_ms\": 10263.648, \"total_train_time_s\": 11.248789310455322}", "{\"n\": 17658, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.5, \"learn_time_ms\": 10152.511, \"total_train_time_s\": 12.068534135818481}", "{\"n\": 17659, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.64, \"learn_time_ms\": 10056.229, \"total_train_time_s\": 12.12253475189209}", "{\"n\": 17660, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.15, \"learn_time_ms\": 10055.658, \"total_train_time_s\": 12.04724669456482}", "{\"n\": 17661, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.27, \"learn_time_ms\": 9975.271, \"total_train_time_s\": 12.042097568511963}", "{\"n\": 17662, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.27, \"learn_time_ms\": 9791.508, \"total_train_time_s\": 11.47516131401062}", "{\"n\": 17663, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.32, \"learn_time_ms\": 9923.968, \"total_train_time_s\": 12.038644790649414}", "{\"n\": 17664, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.32, \"learn_time_ms\": 9966.322, \"total_train_time_s\": 11.977948427200317}", "{\"n\": 17665, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.92, \"learn_time_ms\": 9890.379, \"total_train_time_s\": 11.638720750808716}", "{\"n\": 17666, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.14, \"learn_time_ms\": 10023.141, \"total_train_time_s\": 12.82093334197998}", "{\"n\": 17667, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.16, \"learn_time_ms\": 10073.318, \"total_train_time_s\": 11.750872135162354}", "{\"n\": 17668, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.57, \"learn_time_ms\": 10053.751, \"total_train_time_s\": 11.868784666061401}", "{\"n\": 17669, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.57, \"learn_time_ms\": 10091.916, \"total_train_time_s\": 12.44876766204834}", "{\"n\": 17670, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.61, \"learn_time_ms\": 10099.2, \"total_train_time_s\": 12.105046272277832}", "{\"n\": 17671, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.61, \"learn_time_ms\": 10164.342, \"total_train_time_s\": 12.686972856521606}", "{\"n\": 17672, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.82, \"learn_time_ms\": 10316.532, \"total_train_time_s\": 12.983656406402588}", "{\"n\": 17673, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.53, \"learn_time_ms\": 10309.246, \"total_train_time_s\": 11.981077909469604}", "{\"n\": 17674, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.12, \"learn_time_ms\": 10374.248, \"total_train_time_s\": 12.6182541847229}", "{\"n\": 17675, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.33, \"learn_time_ms\": 10500.219, \"total_train_time_s\": 12.87826681137085}", "{\"n\": 17676, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.89, \"learn_time_ms\": 10519.0, \"total_train_time_s\": 13.011860370635986}", "{\"n\": 17677, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.39, \"learn_time_ms\": 10572.364, \"total_train_time_s\": 12.291097402572632}", "{\"n\": 17678, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.35, \"learn_time_ms\": 10683.05, \"total_train_time_s\": 13.012497425079346}", "{\"n\": 17679, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.35, \"learn_time_ms\": 10680.266, \"total_train_time_s\": 12.481504678726196}", "{\"n\": 17680, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.1, \"learn_time_ms\": 10674.036, \"total_train_time_s\": 12.135252475738525}", "{\"n\": 17681, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.1, \"learn_time_ms\": 10712.732, \"total_train_time_s\": 13.05348825454712}", "{\"n\": 17682, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.1, \"learn_time_ms\": 10728.649, \"total_train_time_s\": 13.142372608184814}", "{\"n\": 17683, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.27, \"learn_time_ms\": 10563.851, \"total_train_time_s\": 10.290962934494019}", "{\"n\": 17684, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.27, \"learn_time_ms\": 10515.641, \"total_train_time_s\": 12.133563756942749}", "{\"n\": 17685, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.27, \"learn_time_ms\": 10416.259, \"total_train_time_s\": 11.890340328216553}", "{\"n\": 17686, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.24, \"learn_time_ms\": 10301.544, \"total_train_time_s\": 11.847879409790039}", "{\"n\": 17687, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.82, \"learn_time_ms\": 10323.88, \"total_train_time_s\": 12.573789119720459}", "{\"n\": 17688, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.82, \"learn_time_ms\": 10203.372, \"total_train_time_s\": 11.760118246078491}", "{\"n\": 17689, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.28, \"learn_time_ms\": 10106.501, \"total_train_time_s\": 11.48874807357788}", "{\"n\": 17690, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.24, \"learn_time_ms\": 9961.695, \"total_train_time_s\": 10.601528882980347}", "{\"n\": 17691, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.24, \"learn_time_ms\": 9892.197, \"total_train_time_s\": 12.380615949630737}", "{\"n\": 17692, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.24, \"learn_time_ms\": 9806.957, \"total_train_time_s\": 12.252419471740723}", "{\"n\": 17693, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.28, \"learn_time_ms\": 9927.461, \"total_train_time_s\": 11.525046110153198}", "{\"n\": 17694, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.64, \"learn_time_ms\": 10039.68, \"total_train_time_s\": 13.256834030151367}", "{\"n\": 17695, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.64, \"learn_time_ms\": 10079.633, \"total_train_time_s\": 12.282975673675537}", "{\"n\": 17696, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.04, \"learn_time_ms\": 10081.359, \"total_train_time_s\": 11.8956139087677}", "{\"n\": 17697, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.1, \"learn_time_ms\": 10001.033, \"total_train_time_s\": 11.684200048446655}", "{\"n\": 17698, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.61, \"learn_time_ms\": 10029.431, \"total_train_time_s\": 12.045616626739502}", "{\"n\": 17699, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.61, \"learn_time_ms\": 10056.767, \"total_train_time_s\": 11.73931097984314}", "{\"n\": 17700, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.83, \"learn_time_ms\": 10231.488, \"total_train_time_s\": 12.382737159729004}", "{\"n\": 17701, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.01, \"learn_time_ms\": 10180.265, \"total_train_time_s\": 11.878480434417725}", "{\"n\": 17702, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.01, \"learn_time_ms\": 10247.09, \"total_train_time_s\": 12.894537687301636}", "{\"n\": 17703, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.45, \"learn_time_ms\": 10387.879, \"total_train_time_s\": 12.901573419570923}", "{\"n\": 17704, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.5, \"learn_time_ms\": 10289.513, \"total_train_time_s\": 12.266845941543579}", "{\"n\": 17705, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.77, \"learn_time_ms\": 10378.448, \"total_train_time_s\": 13.222160577774048}", "{\"n\": 17706, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.72, \"learn_time_ms\": 10432.582, \"total_train_time_s\": 12.458852529525757}", "{\"n\": 17707, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.72, \"learn_time_ms\": 10501.02, \"total_train_time_s\": 12.369532346725464}", "{\"n\": 17708, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.26, \"learn_time_ms\": 10457.115, \"total_train_time_s\": 11.631154298782349}", "{\"n\": 17709, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.14, \"learn_time_ms\": 10482.799, \"total_train_time_s\": 11.995709896087646}", "{\"n\": 17710, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.52, \"learn_time_ms\": 10445.028, \"total_train_time_s\": 11.980756521224976}", "{\"n\": 17711, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.52, \"learn_time_ms\": 10450.263, \"total_train_time_s\": 11.91202449798584}", "{\"n\": 17712, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.11, \"learn_time_ms\": 10290.637, \"total_train_time_s\": 11.349479675292969}", "{\"n\": 17713, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.11, \"learn_time_ms\": 10180.869, \"total_train_time_s\": 11.805257081985474}", "{\"n\": 17714, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.11, \"learn_time_ms\": 10144.74, \"total_train_time_s\": 11.896767616271973}", "{\"n\": 17715, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.11, \"learn_time_ms\": 10027.257, \"total_train_time_s\": 11.969897508621216}", "{\"n\": 17716, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.58, \"learn_time_ms\": 9926.568, \"total_train_time_s\": 11.407140493392944}", "{\"n\": 17717, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.58, \"learn_time_ms\": 10026.135, \"total_train_time_s\": 13.36050796508789}", "{\"n\": 17718, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.58, \"learn_time_ms\": 10056.586, \"total_train_time_s\": 11.936275482177734}", "{\"n\": 17719, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.27, \"learn_time_ms\": 10053.546, \"total_train_time_s\": 11.958808898925781}", "{\"n\": 17720, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.18, \"learn_time_ms\": 10057.862, \"total_train_time_s\": 12.042484521865845}", "{\"n\": 17721, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.18, \"learn_time_ms\": 10125.072, \"total_train_time_s\": 12.608464479446411}", "{\"n\": 17722, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3625.18, \"learn_time_ms\": 10116.46, \"total_train_time_s\": 11.265609502792358}", "{\"n\": 17723, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.27, \"learn_time_ms\": 10057.406, \"total_train_time_s\": 11.240453243255615}", "{\"n\": 17724, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.75, \"learn_time_ms\": 10200.995, \"total_train_time_s\": 13.331421136856079}", "{\"n\": 17725, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.75, \"learn_time_ms\": 10231.217, \"total_train_time_s\": 12.297932863235474}", "{\"n\": 17726, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3619.26, \"learn_time_ms\": 10350.703, \"total_train_time_s\": 12.59026288986206}", "{\"n\": 17727, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.26, \"learn_time_ms\": 10194.014, \"total_train_time_s\": 11.805638790130615}", "{\"n\": 17728, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.51, \"learn_time_ms\": 10225.523, \"total_train_time_s\": 12.261598348617554}", "{\"n\": 17729, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.51, \"learn_time_ms\": 10313.895, \"total_train_time_s\": 12.845624685287476}", "{\"n\": 17730, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.41, \"learn_time_ms\": 10256.4, \"total_train_time_s\": 11.416799068450928}", "{\"n\": 17731, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.32, \"learn_time_ms\": 10304.195, \"total_train_time_s\": 13.061472177505493}", "{\"n\": 17732, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.32, \"learn_time_ms\": 10421.102, \"total_train_time_s\": 12.426666736602783}", "{\"n\": 17733, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.32, \"learn_time_ms\": 10687.962, \"total_train_time_s\": 13.89695930480957}", "{\"n\": 17734, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.22, \"learn_time_ms\": 10549.757, \"total_train_time_s\": 11.992963314056396}", "{\"n\": 17735, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.98, \"learn_time_ms\": 10501.322, \"total_train_time_s\": 11.797483682632446}", "{\"n\": 17736, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.98, \"learn_time_ms\": 10497.253, \"total_train_time_s\": 12.529877424240112}", "{\"n\": 17737, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.98, \"learn_time_ms\": 10610.124, \"total_train_time_s\": 12.908147096633911}", "{\"n\": 17738, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.41, \"learn_time_ms\": 10550.649, \"total_train_time_s\": 11.686814308166504}", "{\"n\": 17739, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.41, \"learn_time_ms\": 10458.966, \"total_train_time_s\": 11.937970638275146}", "{\"n\": 17740, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.41, \"learn_time_ms\": 10517.659, \"total_train_time_s\": 12.006290674209595}", "{\"n\": 17741, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.99, \"learn_time_ms\": 10402.86, \"total_train_time_s\": 11.963596105575562}", "{\"n\": 17742, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.24, \"learn_time_ms\": 10408.328, \"total_train_time_s\": 12.497816801071167}", "{\"n\": 17743, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.24, \"learn_time_ms\": 10291.262, \"total_train_time_s\": 12.736896276473999}", "{\"n\": 17744, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.24, \"learn_time_ms\": 10251.472, \"total_train_time_s\": 11.56856656074524}", "{\"n\": 17745, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.63, \"learn_time_ms\": 10261.372, \"total_train_time_s\": 11.94800090789795}", "{\"n\": 17746, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 10235.638, \"total_train_time_s\": 12.29897952079773}", "{\"n\": 17747, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 10103.461, \"total_train_time_s\": 11.66413688659668}", "{\"n\": 17748, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 10121.467, \"total_train_time_s\": 11.831822633743286}", "{\"n\": 17749, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.5, \"learn_time_ms\": 10094.173, \"total_train_time_s\": 11.654075384140015}", "{\"n\": 17750, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.12, \"learn_time_ms\": 10113.667, \"total_train_time_s\": 12.180521726608276}", "{\"n\": 17751, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.12, \"learn_time_ms\": 10068.405, \"total_train_time_s\": 11.419423341751099}", "{\"n\": 17752, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.28, \"learn_time_ms\": 10091.051, \"total_train_time_s\": 12.712328433990479}", "{\"n\": 17753, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.3, \"learn_time_ms\": 10014.905, \"total_train_time_s\": 11.98597240447998}", "{\"n\": 17754, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.19, \"learn_time_ms\": 10053.17, \"total_train_time_s\": 11.940675258636475}", "{\"n\": 17755, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.62, \"learn_time_ms\": 10086.434, \"total_train_time_s\": 12.213679313659668}", "{\"n\": 17756, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.5, \"learn_time_ms\": 10074.27, \"total_train_time_s\": 12.19738483428955}", "{\"n\": 17757, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.43, \"learn_time_ms\": 10088.327, \"total_train_time_s\": 11.775052785873413}", "{\"n\": 17758, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.24, \"learn_time_ms\": 10121.575, \"total_train_time_s\": 12.136783361434937}", "{\"n\": 17759, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.2, \"learn_time_ms\": 10245.375, \"total_train_time_s\": 12.899023532867432}", "{\"n\": 17760, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.2, \"learn_time_ms\": 10255.66, \"total_train_time_s\": 12.338305473327637}", "{\"n\": 17761, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.57, \"learn_time_ms\": 10297.818, \"total_train_time_s\": 11.910341739654541}", "{\"n\": 17762, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.57, \"learn_time_ms\": 10188.034, \"total_train_time_s\": 11.60289716720581}", "{\"n\": 17763, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.84, \"learn_time_ms\": 10119.196, \"total_train_time_s\": 11.27143144607544}", "{\"n\": 17764, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.84, \"learn_time_ms\": 10187.59, \"total_train_time_s\": 12.624768733978271}", "{\"n\": 17765, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.87, \"learn_time_ms\": 10222.41, \"total_train_time_s\": 12.614138126373291}", "{\"n\": 17766, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.01, \"learn_time_ms\": 10267.556, \"total_train_time_s\": 12.635819911956787}", "{\"n\": 17767, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.9, \"learn_time_ms\": 10226.681, \"total_train_time_s\": 11.335553884506226}", "{\"n\": 17768, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.59, \"learn_time_ms\": 10188.52, \"total_train_time_s\": 11.780664920806885}", "{\"n\": 17769, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.59, \"learn_time_ms\": 10042.343, \"total_train_time_s\": 11.450928211212158}", "{\"n\": 17770, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.59, \"learn_time_ms\": 9988.046, \"total_train_time_s\": 11.787969827651978}", "{\"n\": 17771, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.94, \"learn_time_ms\": 10016.905, \"total_train_time_s\": 12.171963453292847}", "{\"n\": 17772, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.12, \"learn_time_ms\": 10036.621, \"total_train_time_s\": 11.857900857925415}", "{\"n\": 17773, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.12, \"learn_time_ms\": 10147.516, \"total_train_time_s\": 12.423658847808838}", "{\"n\": 17774, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.47, \"learn_time_ms\": 10138.049, \"total_train_time_s\": 12.569679498672485}", "{\"n\": 17775, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.03, \"learn_time_ms\": 10080.732, \"total_train_time_s\": 12.04169774055481}", "{\"n\": 17776, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.54, \"learn_time_ms\": 10152.29, \"total_train_time_s\": 13.3855619430542}", "{\"n\": 17777, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.54, \"learn_time_ms\": 10212.024, \"total_train_time_s\": 11.928436040878296}", "{\"n\": 17778, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.16, \"learn_time_ms\": 10160.946, \"total_train_time_s\": 11.26165223121643}", "{\"n\": 17779, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.34, \"learn_time_ms\": 10237.787, \"total_train_time_s\": 12.233745098114014}", "{\"n\": 17780, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3664.34, \"learn_time_ms\": 10377.935, \"total_train_time_s\": 13.208447694778442}", "{\"n\": 17781, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.94, \"learn_time_ms\": 10280.282, \"total_train_time_s\": 11.217352628707886}", "{\"n\": 17782, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.14, \"learn_time_ms\": 10232.564, \"total_train_time_s\": 11.301751136779785}", "{\"n\": 17783, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.42, \"learn_time_ms\": 10111.521, \"total_train_time_s\": 11.170103311538696}", "{\"n\": 17784, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.23, \"learn_time_ms\": 10092.783, \"total_train_time_s\": 12.350034236907959}", "{\"n\": 17785, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.19, \"learn_time_ms\": 10061.055, \"total_train_time_s\": 11.745029211044312}", "{\"n\": 17786, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.59, \"learn_time_ms\": 9914.356, \"total_train_time_s\": 11.879941701889038}", "{\"n\": 17787, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 10012.886, \"total_train_time_s\": 12.95572304725647}", "{\"n\": 17788, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.41, \"learn_time_ms\": 10096.092, \"total_train_time_s\": 12.108025074005127}", "{\"n\": 17789, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.69, \"learn_time_ms\": 10081.467, \"total_train_time_s\": 12.074665069580078}", "{\"n\": 17790, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.35, \"learn_time_ms\": 10000.453, \"total_train_time_s\": 12.356298446655273}", "{\"n\": 17791, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.65, \"learn_time_ms\": 10165.284, \"total_train_time_s\": 12.859798669815063}", "{\"n\": 17792, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.53, \"learn_time_ms\": 10296.361, \"total_train_time_s\": 12.693842887878418}", "{\"n\": 17793, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.31, \"learn_time_ms\": 10316.74, \"total_train_time_s\": 11.365807056427002}", "{\"n\": 17794, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.13, \"learn_time_ms\": 10302.09, \"total_train_time_s\": 12.164069890975952}", "{\"n\": 17795, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.48, \"learn_time_ms\": 10445.676, \"total_train_time_s\": 13.123831510543823}", "{\"n\": 17796, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.56, \"learn_time_ms\": 10390.679, \"total_train_time_s\": 11.386883020401001}", "{\"n\": 17797, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.49, \"learn_time_ms\": 10249.145, \"total_train_time_s\": 11.55631399154663}", "{\"n\": 17798, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.49, \"learn_time_ms\": 10126.311, \"total_train_time_s\": 10.858830451965332}", "{\"n\": 17799, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.38, \"learn_time_ms\": 10042.765, \"total_train_time_s\": 11.266793012619019}", "{\"n\": 17800, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.38, \"learn_time_ms\": 10063.951, \"total_train_time_s\": 12.590825080871582}", "{\"n\": 17801, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.32, \"learn_time_ms\": 9937.822, \"total_train_time_s\": 11.575767278671265}", "{\"n\": 17802, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.83, \"learn_time_ms\": 9882.637, \"total_train_time_s\": 12.109462261199951}", "{\"n\": 17803, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.25, \"learn_time_ms\": 9989.274, \"total_train_time_s\": 12.438262701034546}", "{\"n\": 17804, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.25, \"learn_time_ms\": 9953.87, \"total_train_time_s\": 11.835241079330444}", "{\"n\": 17805, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.9, \"learn_time_ms\": 9813.173, \"total_train_time_s\": 11.728520154953003}", "{\"n\": 17806, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.71, \"learn_time_ms\": 9977.772, \"total_train_time_s\": 12.96239686012268}", "{\"n\": 17807, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.71, \"learn_time_ms\": 10067.62, \"total_train_time_s\": 12.405417442321777}", "{\"n\": 17808, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3674.01, \"learn_time_ms\": 10112.521, \"total_train_time_s\": 11.327800273895264}", "{\"n\": 17809, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.36, \"learn_time_ms\": 10201.986, \"total_train_time_s\": 12.141260385513306}", "{\"n\": 17810, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.61, \"learn_time_ms\": 10181.398, \"total_train_time_s\": 12.421857595443726}", "{\"n\": 17811, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.61, \"learn_time_ms\": 10331.995, \"total_train_time_s\": 13.111966848373413}", "{\"n\": 17812, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.82, \"learn_time_ms\": 10279.983, \"total_train_time_s\": 11.589907884597778}", "{\"n\": 17813, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.82, \"learn_time_ms\": 10198.76, \"total_train_time_s\": 11.64511752128601}", "{\"n\": 17814, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.82, \"learn_time_ms\": 10218.903, \"total_train_time_s\": 12.056240797042847}", "{\"n\": 17815, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.64, \"learn_time_ms\": 10308.265, \"total_train_time_s\": 12.711220979690552}", "{\"n\": 17816, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10197.147, \"total_train_time_s\": 11.863452911376953}", "{\"n\": 17817, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10091.952, \"total_train_time_s\": 11.375356435775757}", "{\"n\": 17818, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.53, \"learn_time_ms\": 10048.314, \"total_train_time_s\": 10.88388991355896}", "{\"n\": 17819, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.61, \"learn_time_ms\": 10033.467, \"total_train_time_s\": 11.954114437103271}", "{\"n\": 17820, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.47, \"learn_time_ms\": 9992.562, \"total_train_time_s\": 11.985063791275024}", "{\"n\": 17821, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.47, \"learn_time_ms\": 9768.778, \"total_train_time_s\": 10.878601789474487}", "{\"n\": 17822, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.78, \"learn_time_ms\": 9823.325, \"total_train_time_s\": 12.124756336212158}", "{\"n\": 17823, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.22, \"learn_time_ms\": 9840.209, \"total_train_time_s\": 11.790372133255005}", "{\"n\": 17824, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.22, \"learn_time_ms\": 9845.531, \"total_train_time_s\": 12.07554841041565}", "{\"n\": 17825, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.22, \"learn_time_ms\": 9729.847, \"total_train_time_s\": 11.418182134628296}", "{\"n\": 17826, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.22, \"learn_time_ms\": 9924.737, \"total_train_time_s\": 13.847143650054932}", "{\"n\": 17827, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.22, \"learn_time_ms\": 10024.281, \"total_train_time_s\": 12.3792884349823}", "{\"n\": 17828, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3632.22, \"learn_time_ms\": 10151.407, \"total_train_time_s\": 12.157909154891968}", "{\"n\": 17829, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.46, \"learn_time_ms\": 10263.404, \"total_train_time_s\": 13.065114259719849}", "{\"n\": 17830, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.05, \"learn_time_ms\": 10337.042, \"total_train_time_s\": 12.777326345443726}", "{\"n\": 17831, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.05, \"learn_time_ms\": 10401.212, \"total_train_time_s\": 11.48931622505188}", "{\"n\": 17832, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.05, \"learn_time_ms\": 10355.197, \"total_train_time_s\": 11.629262208938599}", "{\"n\": 17833, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.48, \"learn_time_ms\": 10383.944, \"total_train_time_s\": 12.067253589630127}", "{\"n\": 17834, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.24, \"learn_time_ms\": 10395.744, \"total_train_time_s\": 12.222877502441406}", "{\"n\": 17835, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.24, \"learn_time_ms\": 10509.58, \"total_train_time_s\": 12.625711441040039}", "{\"n\": 17836, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.09, \"learn_time_ms\": 10317.717, \"total_train_time_s\": 11.909100770950317}", "{\"n\": 17837, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.17, \"learn_time_ms\": 10310.023, \"total_train_time_s\": 12.277244329452515}", "{\"n\": 17838, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.63, \"learn_time_ms\": 10285.905, \"total_train_time_s\": 11.89564299583435}", "{\"n\": 17839, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.63, \"learn_time_ms\": 10087.183, \"total_train_time_s\": 11.057130813598633}", "{\"n\": 17840, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.96, \"learn_time_ms\": 9979.964, \"total_train_time_s\": 11.63322114944458}", "{\"n\": 17841, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.28, \"learn_time_ms\": 10013.784, \"total_train_time_s\": 11.83054494857788}", "{\"n\": 17842, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3606.58, \"learn_time_ms\": 10100.453, \"total_train_time_s\": 12.495647430419922}", "{\"n\": 17843, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.49, \"learn_time_ms\": 10100.446, \"total_train_time_s\": 12.055196046829224}", "{\"n\": 17844, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.97, \"learn_time_ms\": 10118.706, \"total_train_time_s\": 12.40369462966919}", "{\"n\": 17845, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.05, \"learn_time_ms\": 10089.762, \"total_train_time_s\": 12.338629722595215}", "{\"n\": 17846, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3603.05, \"learn_time_ms\": 10014.867, \"total_train_time_s\": 11.13860821723938}", "{\"n\": 17847, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.44, \"learn_time_ms\": 9890.634, \"total_train_time_s\": 11.09067440032959}", "{\"n\": 17848, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.45, \"learn_time_ms\": 9929.933, \"total_train_time_s\": 12.28669810295105}", "{\"n\": 17849, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.15, \"learn_time_ms\": 10198.519, \"total_train_time_s\": 13.799435138702393}", "{\"n\": 17850, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.8, \"learn_time_ms\": 10181.509, \"total_train_time_s\": 11.485190868377686}", "{\"n\": 17851, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.17, \"learn_time_ms\": 10144.461, \"total_train_time_s\": 11.483232021331787}", "{\"n\": 17852, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 10105.967, \"total_train_time_s\": 12.18209958076477}", "{\"n\": 17853, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 10170.202, \"total_train_time_s\": 12.726459980010986}", "{\"n\": 17854, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.88, \"learn_time_ms\": 10128.907, \"total_train_time_s\": 11.9959397315979}", "{\"n\": 17855, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.88, \"learn_time_ms\": 10076.424, \"total_train_time_s\": 11.799997806549072}", "{\"n\": 17856, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.66, \"learn_time_ms\": 10155.595, \"total_train_time_s\": 11.998462200164795}", "{\"n\": 17857, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.95, \"learn_time_ms\": 10223.246, \"total_train_time_s\": 11.712464094161987}", "{\"n\": 17858, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.34, \"learn_time_ms\": 10286.611, \"total_train_time_s\": 12.961773157119751}", "{\"n\": 17859, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.37, \"learn_time_ms\": 10099.825, \"total_train_time_s\": 11.93780517578125}", "{\"n\": 17860, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.82, \"learn_time_ms\": 10250.739, \"total_train_time_s\": 12.98208999633789}", "{\"n\": 17861, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3594.81, \"learn_time_ms\": 10441.103, \"total_train_time_s\": 13.345600605010986}", "{\"n\": 17862, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.9, \"learn_time_ms\": 10490.191, \"total_train_time_s\": 12.641825199127197}", "{\"n\": 17863, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.9, \"learn_time_ms\": 10524.581, \"total_train_time_s\": 13.1344735622406}", "{\"n\": 17864, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.74, \"learn_time_ms\": 10536.996, \"total_train_time_s\": 12.146701335906982}", "{\"n\": 17865, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.71, \"learn_time_ms\": 10557.498, \"total_train_time_s\": 12.007701635360718}", "{\"n\": 17866, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.71, \"learn_time_ms\": 10624.864, \"total_train_time_s\": 12.60674500465393}", "{\"n\": 17867, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.11, \"learn_time_ms\": 10652.754, \"total_train_time_s\": 11.991456747055054}", "{\"n\": 17868, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.95, \"learn_time_ms\": 10531.708, \"total_train_time_s\": 11.721143960952759}", "{\"n\": 17869, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.99, \"learn_time_ms\": 10581.635, \"total_train_time_s\": 12.439295053482056}", "{\"n\": 17870, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.99, \"learn_time_ms\": 10442.966, \"total_train_time_s\": 11.584015607833862}", "{\"n\": 17871, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.6, \"learn_time_ms\": 10408.175, \"total_train_time_s\": 13.04287052154541}", "{\"n\": 17872, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.64, \"learn_time_ms\": 10346.891, \"total_train_time_s\": 12.07705545425415}", "{\"n\": 17873, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.64, \"learn_time_ms\": 10204.579, \"total_train_time_s\": 11.639383316040039}", "{\"n\": 17874, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.64, \"learn_time_ms\": 10144.735, \"total_train_time_s\": 11.490759134292603}", "{\"n\": 17875, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.86, \"learn_time_ms\": 10109.127, \"total_train_time_s\": 11.635903358459473}", "{\"n\": 17876, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.25, \"learn_time_ms\": 10109.358, \"total_train_time_s\": 12.576269149780273}", "{\"n\": 17877, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.25, \"learn_time_ms\": 10117.919, \"total_train_time_s\": 12.036645889282227}", "{\"n\": 17878, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.17, \"learn_time_ms\": 10076.221, \"total_train_time_s\": 11.381358861923218}", "{\"n\": 17879, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.13, \"learn_time_ms\": 10089.726, \"total_train_time_s\": 12.514690637588501}", "{\"n\": 17880, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.77, \"learn_time_ms\": 10121.236, \"total_train_time_s\": 11.881679773330688}", "{\"n\": 17881, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.43, \"learn_time_ms\": 10060.218, \"total_train_time_s\": 12.404374599456787}", "{\"n\": 17882, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.43, \"learn_time_ms\": 10127.787, \"total_train_time_s\": 12.648035049438477}", "{\"n\": 17883, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.74, \"learn_time_ms\": 10194.96, \"total_train_time_s\": 12.312727689743042}", "{\"n\": 17884, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.74, \"learn_time_ms\": 10248.316, \"total_train_time_s\": 12.033928632736206}", "{\"n\": 17885, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.36, \"learn_time_ms\": 10277.787, \"total_train_time_s\": 11.918171167373657}", "{\"n\": 17886, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3531.17, \"learn_time_ms\": 10273.663, \"total_train_time_s\": 12.567602396011353}", "{\"n\": 17887, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.75, \"learn_time_ms\": 10409.07, \"total_train_time_s\": 13.43076753616333}", "{\"n\": 17888, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.75, \"learn_time_ms\": 10375.556, \"total_train_time_s\": 10.981050729751587}", "{\"n\": 17889, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.35, \"learn_time_ms\": 10487.099, \"total_train_time_s\": 13.706994533538818}", "{\"n\": 17890, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.82, \"learn_time_ms\": 10502.459, \"total_train_time_s\": 12.100954532623291}", "{\"n\": 17891, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.82, \"learn_time_ms\": 10529.718, \"total_train_time_s\": 12.68765115737915}", "{\"n\": 17892, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.04, \"learn_time_ms\": 10492.406, \"total_train_time_s\": 12.338891983032227}", "{\"n\": 17893, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.96, \"learn_time_ms\": 10362.164, \"total_train_time_s\": 11.032938241958618}", "{\"n\": 17894, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.96, \"learn_time_ms\": 10378.049, \"total_train_time_s\": 12.200249910354614}", "{\"n\": 17895, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.96, \"learn_time_ms\": 10406.862, \"total_train_time_s\": 12.22340202331543}", "{\"n\": 17896, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3530.96, \"learn_time_ms\": 10353.605, \"total_train_time_s\": 12.047537088394165}", "{\"n\": 17897, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3523.03, \"learn_time_ms\": 10224.28, \"total_train_time_s\": 12.232651233673096}", "{\"n\": 17898, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3523.03, \"learn_time_ms\": 10271.477, \"total_train_time_s\": 11.462441682815552}", "{\"n\": 17899, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3523.03, \"learn_time_ms\": 10124.736, \"total_train_time_s\": 12.193626165390015}", "{\"n\": 17900, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.85, \"learn_time_ms\": 10026.553, \"total_train_time_s\": 11.049144744873047}", "{\"n\": 17901, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.67, \"learn_time_ms\": 9918.163, \"total_train_time_s\": 11.603443622589111}", "{\"n\": 17902, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.67, \"learn_time_ms\": 9856.697, \"total_train_time_s\": 11.664660453796387}", "{\"n\": 17903, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.6, \"learn_time_ms\": 9861.839, \"total_train_time_s\": 11.061715364456177}", "{\"n\": 17904, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.07, \"learn_time_ms\": 9820.089, \"total_train_time_s\": 11.765531063079834}", "{\"n\": 17905, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 9845.482, \"total_train_time_s\": 12.490640640258789}", "{\"n\": 17906, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 9969.766, \"total_train_time_s\": 13.278088092803955}", "{\"n\": 17907, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.33, \"learn_time_ms\": 10065.061, \"total_train_time_s\": 13.10168194770813}", "{\"n\": 17908, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.11, \"learn_time_ms\": 10131.824, \"total_train_time_s\": 12.078211069107056}", "{\"n\": 17909, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.11, \"learn_time_ms\": 10161.655, \"total_train_time_s\": 12.489541292190552}", "{\"n\": 17910, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.66, \"learn_time_ms\": 10292.953, \"total_train_time_s\": 12.37036681175232}", "{\"n\": 17911, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.26, \"learn_time_ms\": 10179.435, \"total_train_time_s\": 10.468803644180298}", "{\"n\": 17912, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.2, \"learn_time_ms\": 10193.184, \"total_train_time_s\": 11.843717098236084}", "{\"n\": 17913, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.42, \"learn_time_ms\": 10283.423, \"total_train_time_s\": 11.98678207397461}", "{\"n\": 17914, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3533.47, \"learn_time_ms\": 10265.585, \"total_train_time_s\": 11.638898134231567}", "{\"n\": 17915, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.95, \"learn_time_ms\": 10290.183, \"total_train_time_s\": 12.777792930603027}", "{\"n\": 17916, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.95, \"learn_time_ms\": 10150.936, \"total_train_time_s\": 11.882783889770508}", "{\"n\": 17917, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.79, \"learn_time_ms\": 10024.978, \"total_train_time_s\": 11.848576068878174}", "{\"n\": 17918, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.66, \"learn_time_ms\": 10017.518, \"total_train_time_s\": 12.125361919403076}", "{\"n\": 17919, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.45, \"learn_time_ms\": 9923.204, \"total_train_time_s\": 11.558820009231567}", "{\"n\": 17920, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.45, \"learn_time_ms\": 9803.726, \"total_train_time_s\": 11.194096088409424}", "{\"n\": 17921, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.46, \"learn_time_ms\": 9892.608, \"total_train_time_s\": 11.371471643447876}", "{\"n\": 17922, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.57, \"learn_time_ms\": 10013.986, \"total_train_time_s\": 13.048857927322388}", "{\"n\": 17923, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.57, \"learn_time_ms\": 10086.02, \"total_train_time_s\": 12.726058959960938}", "{\"n\": 17924, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.88, \"learn_time_ms\": 10237.174, \"total_train_time_s\": 13.177497148513794}", "{\"n\": 17925, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.41, \"learn_time_ms\": 10206.79, \"total_train_time_s\": 12.430257558822632}", "{\"n\": 17926, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.99, \"learn_time_ms\": 10253.314, \"total_train_time_s\": 12.359559059143066}", "{\"n\": 17927, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.99, \"learn_time_ms\": 10255.617, \"total_train_time_s\": 11.896244764328003}", "{\"n\": 17928, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.55, \"learn_time_ms\": 10288.177, \"total_train_time_s\": 12.383845567703247}", "{\"n\": 17929, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.55, \"learn_time_ms\": 10416.188, \"total_train_time_s\": 12.828615188598633}", "{\"n\": 17930, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.14, \"learn_time_ms\": 10468.075, \"total_train_time_s\": 11.685056447982788}", "{\"n\": 17931, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3543.14, \"learn_time_ms\": 10529.832, \"total_train_time_s\": 11.948781251907349}", "{\"n\": 17932, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 10320.043, \"total_train_time_s\": 10.967642545700073}", "{\"n\": 17933, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 10251.23, \"total_train_time_s\": 12.052978754043579}", "{\"n\": 17934, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.56, \"learn_time_ms\": 10099.829, \"total_train_time_s\": 11.645722150802612}", "{\"n\": 17935, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.7, \"learn_time_ms\": 10160.619, \"total_train_time_s\": 13.007699489593506}", "{\"n\": 17936, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.44, \"learn_time_ms\": 10057.402, \"total_train_time_s\": 11.34384274482727}", "{\"n\": 17937, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.79, \"learn_time_ms\": 10031.924, \"total_train_time_s\": 11.628580570220947}", "{\"n\": 17938, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.79, \"learn_time_ms\": 9998.966, \"total_train_time_s\": 12.005401611328125}", "{\"n\": 17939, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.24, \"learn_time_ms\": 9932.644, \"total_train_time_s\": 12.199347496032715}", "{\"n\": 17940, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.6, \"learn_time_ms\": 9953.379, \"total_train_time_s\": 11.910870790481567}", "{\"n\": 17941, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.78, \"learn_time_ms\": 10053.161, \"total_train_time_s\": 12.997695207595825}", "{\"n\": 17942, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3555.78, \"learn_time_ms\": 10134.519, \"total_train_time_s\": 11.79870867729187}", "{\"n\": 17943, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.06, \"learn_time_ms\": 10093.178, \"total_train_time_s\": 11.605344533920288}", "{\"n\": 17944, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.87, \"learn_time_ms\": 10080.405, \"total_train_time_s\": 11.495975971221924}", "{\"n\": 17945, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.87, \"learn_time_ms\": 9987.383, \"total_train_time_s\": 12.065319538116455}", "{\"n\": 17946, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.74, \"learn_time_ms\": 10078.54, \"total_train_time_s\": 12.255082368850708}", "{\"n\": 17947, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.48, \"learn_time_ms\": 10091.278, \"total_train_time_s\": 11.733675241470337}", "{\"n\": 17948, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.67, \"learn_time_ms\": 10105.548, \"total_train_time_s\": 12.146375894546509}", "{\"n\": 17949, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.67, \"learn_time_ms\": 10047.979, \"total_train_time_s\": 11.585733413696289}", "{\"n\": 17950, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.2, \"learn_time_ms\": 10146.072, \"total_train_time_s\": 12.921913623809814}", "{\"n\": 17951, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3565.14, \"learn_time_ms\": 9974.781, \"total_train_time_s\": 11.302757024765015}", "{\"n\": 17952, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.72, \"learn_time_ms\": 9935.663, \"total_train_time_s\": 11.39884901046753}", "{\"n\": 17953, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.72, \"learn_time_ms\": 9978.52, \"total_train_time_s\": 11.988948822021484}", "{\"n\": 17954, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.45, \"learn_time_ms\": 10114.946, \"total_train_time_s\": 12.857771873474121}", "{\"n\": 17955, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.45, \"learn_time_ms\": 10078.114, \"total_train_time_s\": 11.72944450378418}", "{\"n\": 17956, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.81, \"learn_time_ms\": 10206.476, \"total_train_time_s\": 13.56009292602539}", "{\"n\": 17957, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3603.81, \"learn_time_ms\": 10195.082, \"total_train_time_s\": 11.613308429718018}", "{\"n\": 17958, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.56, \"learn_time_ms\": 10104.776, \"total_train_time_s\": 11.24924612045288}", "{\"n\": 17959, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 10244.21, \"total_train_time_s\": 12.95133113861084}", "{\"n\": 17960, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.98, \"learn_time_ms\": 10145.137, \"total_train_time_s\": 11.924701690673828}", "{\"n\": 17961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3621.98, \"learn_time_ms\": 10266.015, \"total_train_time_s\": 12.460133790969849}", "{\"n\": 17962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.95, \"learn_time_ms\": 10422.416, \"total_train_time_s\": 12.949796915054321}", "{\"n\": 17963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.95, \"learn_time_ms\": 10418.599, \"total_train_time_s\": 11.99548625946045}", "{\"n\": 17964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.04, \"learn_time_ms\": 10486.109, \"total_train_time_s\": 13.543426036834717}", "{\"n\": 17965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.28, \"learn_time_ms\": 10559.61, \"total_train_time_s\": 12.503661632537842}", "{\"n\": 17966, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.88, \"learn_time_ms\": 10338.93, \"total_train_time_s\": 11.295204401016235}", "{\"n\": 17967, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.79, \"learn_time_ms\": 10446.894, \"total_train_time_s\": 12.665470600128174}", "{\"n\": 17968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 10435.771, \"total_train_time_s\": 11.166744709014893}", "{\"n\": 17969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.4, \"learn_time_ms\": 10337.384, \"total_train_time_s\": 12.022758722305298}", "{\"n\": 17970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.4, \"learn_time_ms\": 10376.305, \"total_train_time_s\": 12.274059057235718}", "{\"n\": 17971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.65, \"learn_time_ms\": 10339.47, \"total_train_time_s\": 12.093328714370728}", "{\"n\": 17972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.27, \"learn_time_ms\": 10157.61, \"total_train_time_s\": 11.135082960128784}", "{\"n\": 17973, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.66, \"learn_time_ms\": 10116.427, \"total_train_time_s\": 11.617957353591919}", "{\"n\": 17974, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.99, \"learn_time_ms\": 9988.958, \"total_train_time_s\": 12.261658430099487}", "{\"n\": 17975, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3627.99, \"learn_time_ms\": 9897.83, \"total_train_time_s\": 11.55375361442566}", "{\"n\": 17976, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.53, \"learn_time_ms\": 9952.537, \"total_train_time_s\": 11.899083375930786}", "{\"n\": 17977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.57, \"learn_time_ms\": 10004.122, \"total_train_time_s\": 13.235369682312012}", "{\"n\": 17978, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.57, \"learn_time_ms\": 10132.933, \"total_train_time_s\": 12.43760871887207}", "{\"n\": 17979, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.46, \"learn_time_ms\": 10116.975, \"total_train_time_s\": 11.852886199951172}", "{\"n\": 17980, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.26, \"learn_time_ms\": 9986.876, \"total_train_time_s\": 10.9937744140625}", "{\"n\": 17981, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.52, \"learn_time_ms\": 9962.533, \"total_train_time_s\": 11.854074716567993}", "{\"n\": 17982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.52, \"learn_time_ms\": 10101.436, \"total_train_time_s\": 12.506441354751587}", "{\"n\": 17983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.7, \"learn_time_ms\": 10171.162, \"total_train_time_s\": 12.283297061920166}", "{\"n\": 17984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3636.96, \"learn_time_ms\": 10057.862, \"total_train_time_s\": 11.141655206680298}", "{\"n\": 17985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3645.08, \"learn_time_ms\": 10189.039, \"total_train_time_s\": 12.885642528533936}", "{\"n\": 17986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.07, \"learn_time_ms\": 10251.597, \"total_train_time_s\": 12.532768964767456}", "{\"n\": 17987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.47, \"learn_time_ms\": 10202.551, \"total_train_time_s\": 12.765531778335571}", "{\"n\": 17988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.47, \"learn_time_ms\": 10247.282, \"total_train_time_s\": 12.902586698532104}", "{\"n\": 17989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.45, \"learn_time_ms\": 10326.27, \"total_train_time_s\": 12.657153367996216}", "{\"n\": 17990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.0, \"learn_time_ms\": 10426.323, \"total_train_time_s\": 12.009560108184814}", "{\"n\": 17991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3637.01, \"learn_time_ms\": 10471.782, \"total_train_time_s\": 12.317441940307617}", "{\"n\": 17992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.85, \"learn_time_ms\": 10369.027, \"total_train_time_s\": 11.491449117660522}", "{\"n\": 17993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.85, \"learn_time_ms\": 10368.238, \"total_train_time_s\": 12.243268251419067}", "{\"n\": 17994, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.35, \"learn_time_ms\": 10498.377, \"total_train_time_s\": 12.409833908081055}", "{\"n\": 17995, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10301.609, \"total_train_time_s\": 10.902746200561523}", "{\"n\": 17996, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 10159.983, \"total_train_time_s\": 11.050865888595581}", "{\"n\": 17997, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.35, \"learn_time_ms\": 10069.408, \"total_train_time_s\": 11.790674924850464}", "{\"n\": 17998, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.79, \"learn_time_ms\": 9952.148, \"total_train_time_s\": 11.741758346557617}", "{\"n\": 17999, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.84, \"learn_time_ms\": 9782.647, \"total_train_time_s\": 10.958217859268188}", "{\"n\": 18000, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3633.84, \"learn_time_ms\": 9735.238, \"total_train_time_s\": 11.503186702728271}", "{\"n\": 18001, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.86, \"learn_time_ms\": 9710.716, \"total_train_time_s\": 12.09787368774414}", "{\"n\": 18002, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.86, \"learn_time_ms\": 9746.459, \"total_train_time_s\": 11.825981616973877}", "{\"n\": 18003, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.83, \"learn_time_ms\": 9747.413, \"total_train_time_s\": 12.331177711486816}", "{\"n\": 18004, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.83, \"learn_time_ms\": 9705.183, \"total_train_time_s\": 12.048649072647095}", "{\"n\": 18005, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.95, \"learn_time_ms\": 9853.562, \"total_train_time_s\": 12.456401824951172}", "{\"n\": 18006, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.95, \"learn_time_ms\": 9891.943, \"total_train_time_s\": 11.449604272842407}", "{\"n\": 18007, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.95, \"learn_time_ms\": 9890.232, \"total_train_time_s\": 11.828712940216064}", "{\"n\": 18008, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -0.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.0, \"learn_time_ms\": 9918.874, \"total_train_time_s\": 12.04246211051941}", "{\"n\": 18009, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3662.5, \"learn_time_ms\": 10090.527, \"total_train_time_s\": 12.6991126537323}", "{\"n\": 18010, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -0.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.52, \"learn_time_ms\": 10102.67, \"total_train_time_s\": 11.62805438041687}", "{\"n\": 18011, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.2, \"learn_time_ms\": 10138.949, \"total_train_time_s\": 12.409130334854126}", "{\"n\": 18012, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.65, \"learn_time_ms\": 10047.979, \"total_train_time_s\": 10.993335485458374}", "{\"n\": 18013, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.65, \"learn_time_ms\": 10105.095, \"total_train_time_s\": 12.840254306793213}", "{\"n\": 18014, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.05, \"learn_time_ms\": 10211.722, \"total_train_time_s\": 13.041545629501343}", "{\"n\": 18015, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.05, \"learn_time_ms\": 10119.711, \"total_train_time_s\": 11.447038412094116}", "{\"n\": 18016, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.23, \"learn_time_ms\": 10140.257, \"total_train_time_s\": 11.70361876487732}", "{\"n\": 18017, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.23, \"learn_time_ms\": 10158.622, \"total_train_time_s\": 11.984453916549683}", "{\"n\": 18018, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.69, \"learn_time_ms\": 10192.04, \"total_train_time_s\": 12.338096857070923}", "{\"n\": 18019, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.69, \"learn_time_ms\": 10163.626, \"total_train_time_s\": 12.38226842880249}", "{\"n\": 18020, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.69, \"learn_time_ms\": 10119.319, \"total_train_time_s\": 11.203624248504639}", "{\"n\": 18021, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.75, \"learn_time_ms\": 10015.384, \"total_train_time_s\": 11.382344484329224}", "{\"n\": 18022, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.75, \"learn_time_ms\": 10078.933, \"total_train_time_s\": 11.564005374908447}", "{\"n\": 18023, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.88, \"learn_time_ms\": 9974.481, \"total_train_time_s\": 11.795337200164795}", "{\"n\": 18024, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 9874.312, \"total_train_time_s\": 12.045890808105469}", "{\"n\": 18025, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 10024.691, \"total_train_time_s\": 12.941096305847168}", "{\"n\": 18026, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.91, \"learn_time_ms\": 10080.539, \"total_train_time_s\": 12.207974433898926}", "{\"n\": 18027, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 10077.057, \"total_train_time_s\": 11.951668739318848}", "{\"n\": 18028, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 9940.836, \"total_train_time_s\": 10.993284702301025}", "{\"n\": 18029, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 9832.85, \"total_train_time_s\": 11.319479942321777}", "{\"n\": 18030, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 9880.67, \"total_train_time_s\": 11.664314985275269}", "{\"n\": 18031, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.44, \"learn_time_ms\": 9989.045, \"total_train_time_s\": 12.478611707687378}", "{\"n\": 18032, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.44, \"learn_time_ms\": 10010.856, \"total_train_time_s\": 11.835217475891113}", "{\"n\": 18033, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.44, \"learn_time_ms\": 9974.507, \"total_train_time_s\": 11.423893451690674}", "{\"n\": 18034, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.63, \"learn_time_ms\": 9992.499, \"total_train_time_s\": 12.262107372283936}", "{\"n\": 18035, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.15, \"learn_time_ms\": 9814.738, \"total_train_time_s\": 11.200784683227539}", "{\"n\": 18036, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.15, \"learn_time_ms\": 9750.24, \"total_train_time_s\": 11.578715085983276}", "{\"n\": 18037, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.15, \"learn_time_ms\": 9647.481, \"total_train_time_s\": 10.920841932296753}", "{\"n\": 18038, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.3, \"learn_time_ms\": 9807.918, \"total_train_time_s\": 12.604150295257568}", "{\"n\": 18039, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.67, \"learn_time_ms\": 9966.369, \"total_train_time_s\": 12.883382081985474}", "{\"n\": 18040, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.67, \"learn_time_ms\": 9937.207, \"total_train_time_s\": 11.382261991500854}", "{\"n\": 18041, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.67, \"learn_time_ms\": 9916.377, \"total_train_time_s\": 12.220852136611938}", "{\"n\": 18042, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.29, \"learn_time_ms\": 9965.124, \"total_train_time_s\": 12.25841736793518}", "{\"n\": 18043, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.17, \"learn_time_ms\": 10058.174, \"total_train_time_s\": 12.334264039993286}", "{\"n\": 18044, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.17, \"learn_time_ms\": 9915.476, \"total_train_time_s\": 10.788097858428955}", "{\"n\": 18045, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.17, \"learn_time_ms\": 9949.695, \"total_train_time_s\": 11.555477142333984}", "{\"n\": 18046, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.32, \"learn_time_ms\": 9941.671, \"total_train_time_s\": 11.536981105804443}", "{\"n\": 18047, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.32, \"learn_time_ms\": 10037.656, \"total_train_time_s\": 11.920963525772095}", "{\"n\": 18048, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.32, \"learn_time_ms\": 10032.39, \"total_train_time_s\": 12.576218128204346}", "{\"n\": 18049, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.02, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.41, \"learn_time_ms\": 9970.662, \"total_train_time_s\": 12.25101900100708}", "{\"n\": 18050, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 9967.815, \"total_train_time_s\": 11.39935302734375}", "{\"n\": 18051, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 9918.549, \"total_train_time_s\": 11.771146535873413}", "{\"n\": 18052, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 9827.567, \"total_train_time_s\": 11.41924238204956}", "{\"n\": 18053, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.74, \"learn_time_ms\": 9693.64, \"total_train_time_s\": 11.054770708084106}", "{\"n\": 18054, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.74, \"learn_time_ms\": 9902.526, \"total_train_time_s\": 12.864366054534912}", "{\"n\": 18055, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.74, \"learn_time_ms\": 9978.381, \"total_train_time_s\": 12.27202558517456}", "{\"n\": 18056, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.63, \"learn_time_ms\": 10038.184, \"total_train_time_s\": 12.128895044326782}", "{\"n\": 18057, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.8, \"learn_time_ms\": 9971.551, \"total_train_time_s\": 11.210759162902832}", "{\"n\": 18058, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.8, \"learn_time_ms\": 9922.785, \"total_train_time_s\": 12.061115503311157}", "{\"n\": 18059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 9874.177, \"total_train_time_s\": 11.790541410446167}", "{\"n\": 18060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.04, \"learn_time_ms\": 9954.388, \"total_train_time_s\": 12.154581308364868}", "{\"n\": 18061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.4, \"learn_time_ms\": 10013.377, \"total_train_time_s\": 12.366214036941528}", "{\"n\": 18062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.4, \"learn_time_ms\": 10004.341, \"total_train_time_s\": 11.264923810958862}", "{\"n\": 18063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.01, \"learn_time_ms\": 10077.136, \"total_train_time_s\": 11.754008293151855}", "{\"n\": 18064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.4, \"learn_time_ms\": 9924.621, \"total_train_time_s\": 11.359145164489746}", "{\"n\": 18065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.6, \"learn_time_ms\": 9921.007, \"total_train_time_s\": 12.309560775756836}", "{\"n\": 18066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.41, \"learn_time_ms\": 9920.697, \"total_train_time_s\": 12.067233800888062}", "{\"n\": 18067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.23, \"learn_time_ms\": 9995.205, \"total_train_time_s\": 11.9580078125}", "{\"n\": 18068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.61, \"learn_time_ms\": 10002.026, \"total_train_time_s\": 12.1231689453125}", "{\"n\": 18069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.61, \"learn_time_ms\": 10100.531, \"total_train_time_s\": 12.788127660751343}", "{\"n\": 18070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.11, \"learn_time_ms\": 10148.017, \"total_train_time_s\": 12.651888132095337}", "{\"n\": 18071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.06, \"learn_time_ms\": 10149.278, \"total_train_time_s\": 12.353120565414429}", "{\"n\": 18072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.69, \"learn_time_ms\": 10208.435, \"total_train_time_s\": 11.897443532943726}", "{\"n\": 18073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3653.1, \"learn_time_ms\": 10093.19, \"total_train_time_s\": 10.58208179473877}", "{\"n\": 18074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.36, \"learn_time_ms\": 10249.439, \"total_train_time_s\": 12.94005823135376}", "{\"n\": 18075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.59, \"learn_time_ms\": 10128.784, \"total_train_time_s\": 11.048934698104858}", "{\"n\": 18076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 1.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.16, \"learn_time_ms\": 10194.848, \"total_train_time_s\": 12.741403341293335}", "{\"n\": 18077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.75, \"learn_time_ms\": 10180.21, \"total_train_time_s\": 11.853626728057861}", "{\"n\": 18078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.6, \"learn_time_ms\": 10098.484, \"total_train_time_s\": 11.340683937072754}", "{\"n\": 18079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.6, \"learn_time_ms\": 10006.706, \"total_train_time_s\": 11.845316886901855}", "{\"n\": 18080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.62, \"learn_time_ms\": 10012.415, \"total_train_time_s\": 12.720903396606445}", "{\"n\": 18081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3661.62, \"learn_time_ms\": 9976.94, \"total_train_time_s\": 11.965984344482422}", "{\"n\": 18082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.52, \"learn_time_ms\": 9930.632, \"total_train_time_s\": 11.380098104476929}", "{\"n\": 18083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3663.23, \"learn_time_ms\": 10028.462, \"total_train_time_s\": 11.613184690475464}", "{\"n\": 18084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3660.6, \"learn_time_ms\": 9919.834, \"total_train_time_s\": 11.845670700073242}", "{\"n\": 18085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.05, \"learn_time_ms\": 9976.782, \"total_train_time_s\": 11.658564805984497}", "{\"n\": 18086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.6, \"learn_time_ms\": 9929.527, \"total_train_time_s\": 12.270185947418213}", "{\"n\": 18087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.6, \"learn_time_ms\": 10060.998, \"total_train_time_s\": 13.119358539581299}", "{\"n\": 18088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3643.05, \"learn_time_ms\": 10122.513, \"total_train_time_s\": 11.910276651382446}", "{\"n\": 18089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.3, \"learn_time_ms\": 10277.949, \"total_train_time_s\": 13.403996229171753}", "{\"n\": 18090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.95, \"learn_time_ms\": 10179.778, \"total_train_time_s\": 11.679648876190186}", "{\"n\": 18091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.52, \"learn_time_ms\": 10257.385, \"total_train_time_s\": 12.771320343017578}", "{\"n\": 18092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.17, \"learn_time_ms\": 10234.515, \"total_train_time_s\": 11.206129789352417}", "{\"n\": 18093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.49, \"learn_time_ms\": 10311.65, \"total_train_time_s\": 12.332317590713501}", "{\"n\": 18094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.95, \"learn_time_ms\": 10209.355, \"total_train_time_s\": 10.804346561431885}", "{\"n\": 18095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3655.71, \"learn_time_ms\": 10244.192, \"total_train_time_s\": 11.984191179275513}", "{\"n\": 18096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.07, \"learn_time_ms\": 10186.386, \"total_train_time_s\": 11.722777605056763}", "{\"n\": 18097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.07, \"learn_time_ms\": 10196.979, \"total_train_time_s\": 13.24427604675293}", "{\"n\": 18098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.54, \"learn_time_ms\": 10108.68, \"total_train_time_s\": 11.00534725189209}", "{\"n\": 18099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.37, \"learn_time_ms\": 9946.273, \"total_train_time_s\": 11.781090497970581}", "{\"n\": 18100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.37, \"learn_time_ms\": 10017.332, \"total_train_time_s\": 12.445205211639404}", "{\"n\": 18101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3641.37, \"learn_time_ms\": 10073.465, \"total_train_time_s\": 13.349825143814087}", "{\"n\": 18102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.65, \"learn_time_ms\": 10228.663, \"total_train_time_s\": 12.757631063461304}", "{\"n\": 18103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.58, \"learn_time_ms\": 10208.123, \"total_train_time_s\": 12.120221138000488}", "{\"n\": 18104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.58, \"learn_time_ms\": 10352.548, \"total_train_time_s\": 12.268108606338501}", "{\"n\": 18105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 10230.978, \"total_train_time_s\": 10.7319655418396}", "{\"n\": 18106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.3, \"learn_time_ms\": 10213.612, \"total_train_time_s\": 11.487119436264038}", "{\"n\": 18107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.34, \"learn_time_ms\": 9971.22, \"total_train_time_s\": 10.78040599822998}", "{\"n\": 18108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.92, \"learn_time_ms\": 10074.15, \"total_train_time_s\": 12.075491905212402}", "{\"n\": 18109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.98, \"learn_time_ms\": 10105.797, \"total_train_time_s\": 12.097705364227295}", "{\"n\": 18110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.89, \"learn_time_ms\": 10071.045, \"total_train_time_s\": 12.056661367416382}", "{\"n\": 18111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.04, \"learn_time_ms\": 9901.778, \"total_train_time_s\": 11.662887573242188}", "{\"n\": 18112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.04, \"learn_time_ms\": 9709.428, \"total_train_time_s\": 10.773058891296387}", "{\"n\": 18113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.8, \"learn_time_ms\": 9670.415, \"total_train_time_s\": 11.777384996414185}", "{\"n\": 18114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 9658.221, \"total_train_time_s\": 12.165483713150024}", "{\"n\": 18115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.01, \"learn_time_ms\": 9776.585, \"total_train_time_s\": 11.919311046600342}", "{\"n\": 18116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.01, \"learn_time_ms\": 9813.376, \"total_train_time_s\": 11.891013145446777}", "{\"n\": 18117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.49, \"learn_time_ms\": 9970.515, \"total_train_time_s\": 12.338033199310303}", "{\"n\": 18118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.22, \"learn_time_ms\": 9924.746, \"total_train_time_s\": 11.622626066207886}", "{\"n\": 18119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.75, \"learn_time_ms\": 9954.205, \"total_train_time_s\": 12.427082061767578}", "{\"n\": 18120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.71, \"learn_time_ms\": 9927.82, \"total_train_time_s\": 11.822001695632935}", "{\"n\": 18121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.98, \"learn_time_ms\": 10052.825, \"total_train_time_s\": 12.888519287109375}", "{\"n\": 18122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.39, \"learn_time_ms\": 10217.898, \"total_train_time_s\": 12.437372207641602}", "{\"n\": 18123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.39, \"learn_time_ms\": 10229.486, \"total_train_time_s\": 11.852889060974121}", "{\"n\": 18124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.69, \"learn_time_ms\": 10205.553, \"total_train_time_s\": 11.935300350189209}", "{\"n\": 18125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.6, \"learn_time_ms\": 10181.94, \"total_train_time_s\": 11.736602783203125}", "{\"n\": 18126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.36, \"learn_time_ms\": 10135.142, \"total_train_time_s\": 11.394326448440552}", "{\"n\": 18127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.45, \"learn_time_ms\": 10101.001, \"total_train_time_s\": 12.03380036354065}", "{\"n\": 18128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.12, \"learn_time_ms\": 10206.714, \"total_train_time_s\": 12.723718404769897}", "{\"n\": 18129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.07, \"learn_time_ms\": 10101.034, \"total_train_time_s\": 11.35831356048584}", "{\"n\": 18130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.9, \"learn_time_ms\": 10176.002, \"total_train_time_s\": 12.52450942993164}", "{\"n\": 18131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.51, \"learn_time_ms\": 10090.365, \"total_train_time_s\": 12.050209283828735}", "{\"n\": 18132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3597.59, \"learn_time_ms\": 9980.955, \"total_train_time_s\": 11.355163335800171}", "{\"n\": 18133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.56, \"learn_time_ms\": 9879.894, \"total_train_time_s\": 10.877338886260986}", "{\"n\": 18134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.16, \"learn_time_ms\": 9936.032, \"total_train_time_s\": 12.477200031280518}", "{\"n\": 18135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3580.09, \"learn_time_ms\": 9925.49, \"total_train_time_s\": 11.567881107330322}", "{\"n\": 18136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3580.09, \"learn_time_ms\": 10023.827, \"total_train_time_s\": 12.43742299079895}", "{\"n\": 18137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.88, \"learn_time_ms\": 9935.879, \"total_train_time_s\": 11.180017709732056}", "{\"n\": 18138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.31, \"learn_time_ms\": 9934.662, \"total_train_time_s\": 12.672668218612671}", "{\"n\": 18139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.23, \"learn_time_ms\": 9968.747, \"total_train_time_s\": 11.704886674880981}", "{\"n\": 18140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.23, \"learn_time_ms\": 9953.518, \"total_train_time_s\": 12.433002233505249}", "{\"n\": 18141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.37, \"learn_time_ms\": 10047.341, \"total_train_time_s\": 12.96958589553833}", "{\"n\": 18142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.11, \"learn_time_ms\": 10117.398, \"total_train_time_s\": 12.09675931930542}", "{\"n\": 18143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.11, \"learn_time_ms\": 10310.146, \"total_train_time_s\": 12.813646793365479}", "{\"n\": 18144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.11, \"learn_time_ms\": 10309.571, \"total_train_time_s\": 12.468139171600342}", "{\"n\": 18145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.96, \"learn_time_ms\": 10332.394, \"total_train_time_s\": 11.812020301818848}", "{\"n\": 18146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 10277.839, \"total_train_time_s\": 11.85806393623352}", "{\"n\": 18147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.39, \"learn_time_ms\": 10301.717, \"total_train_time_s\": 11.398309707641602}", "{\"n\": 18148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.38, \"learn_time_ms\": 10290.95, \"total_train_time_s\": 12.546544313430786}", "{\"n\": 18149, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.02, \"learn_time_ms\": 10294.13, \"total_train_time_s\": 11.723535537719727}", "{\"n\": 18150, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 10279.229, \"total_train_time_s\": 12.235099077224731}", "{\"n\": 18151, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 10155.277, \"total_train_time_s\": 11.745169639587402}", "{\"n\": 18152, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 10184.609, \"total_train_time_s\": 12.362358570098877}", "{\"n\": 18153, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.44, \"learn_time_ms\": 10175.364, \"total_train_time_s\": 12.656465768814087}", "{\"n\": 18154, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.44, \"learn_time_ms\": 10096.135, \"total_train_time_s\": 11.64357328414917}", "{\"n\": 18155, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.44, \"learn_time_ms\": 10155.541, \"total_train_time_s\": 12.41249132156372}", "{\"n\": 18156, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.64, \"learn_time_ms\": 10194.093, \"total_train_time_s\": 12.294865608215332}", "{\"n\": 18157, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 10358.992, \"total_train_time_s\": 13.041663646697998}", "{\"n\": 18158, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 10329.13, \"total_train_time_s\": 12.233254671096802}", "{\"n\": 18159, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3594.6, \"learn_time_ms\": 10372.379, \"total_train_time_s\": 12.154208660125732}", "{\"n\": 18160, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.35, \"learn_time_ms\": 10307.12, \"total_train_time_s\": 11.593127250671387}", "{\"n\": 18161, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.57, \"learn_time_ms\": 10327.367, \"total_train_time_s\": 11.964253425598145}", "{\"n\": 18162, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.57, \"learn_time_ms\": 10274.667, \"total_train_time_s\": 11.848340272903442}", "{\"n\": 18163, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.29, \"learn_time_ms\": 10160.407, \"total_train_time_s\": 11.602859735488892}", "{\"n\": 18164, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.97, \"learn_time_ms\": 10269.587, \"total_train_time_s\": 12.765492916107178}", "{\"n\": 18165, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.97, \"learn_time_ms\": 10337.204, \"total_train_time_s\": 13.099684476852417}", "{\"n\": 18166, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.97, \"learn_time_ms\": 10381.37, \"total_train_time_s\": 12.71102786064148}", "{\"n\": 18167, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.49, \"learn_time_ms\": 10216.591, \"total_train_time_s\": 11.413989067077637}", "{\"n\": 18168, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 9918.292, \"total_train_time_s\": 9.270305156707764}", "{\"n\": 18169, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.34, \"learn_time_ms\": 9990.27, \"total_train_time_s\": 12.912472486495972}", "{\"n\": 18170, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.25, \"learn_time_ms\": 10026.863, \"total_train_time_s\": 11.986033916473389}", "{\"n\": 18171, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.27, \"learn_time_ms\": 9995.076, \"total_train_time_s\": 11.689844369888306}", "{\"n\": 18172, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.27, \"learn_time_ms\": 10028.197, \"total_train_time_s\": 12.17808198928833}", "{\"n\": 18173, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.27, \"learn_time_ms\": 10065.554, \"total_train_time_s\": 11.923568487167358}", "{\"n\": 18174, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 10114.324, \"total_train_time_s\": 13.286290407180786}", "{\"n\": 18175, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.64, \"learn_time_ms\": 10005.403, \"total_train_time_s\": 12.050763845443726}", "{\"n\": 18176, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.64, \"learn_time_ms\": 10039.476, \"total_train_time_s\": 13.198848009109497}", "{\"n\": 18177, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.76, \"learn_time_ms\": 10047.328, \"total_train_time_s\": 11.501322746276855}", "{\"n\": 18178, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.73, \"learn_time_ms\": 10332.137, \"total_train_time_s\": 12.101165294647217}", "{\"n\": 18179, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.96, \"learn_time_ms\": 10293.049, \"total_train_time_s\": 12.459627866744995}", "{\"n\": 18180, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3618.96, \"learn_time_ms\": 10337.496, \"total_train_time_s\": 12.426345586776733}", "{\"n\": 18181, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.16, \"learn_time_ms\": 10386.421, \"total_train_time_s\": 12.20714259147644}", "{\"n\": 18182, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.38, \"learn_time_ms\": 10394.999, \"total_train_time_s\": 12.283172130584717}", "{\"n\": 18183, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.81, \"learn_time_ms\": 10404.571, \"total_train_time_s\": 12.040327310562134}", "{\"n\": 18184, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.89, \"learn_time_ms\": 10274.263, \"total_train_time_s\": 11.955975532531738}", "{\"n\": 18185, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.75, \"learn_time_ms\": 10349.481, \"total_train_time_s\": 12.728539228439331}", "{\"n\": 18186, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.42, \"learn_time_ms\": 10336.992, \"total_train_time_s\": 12.855745792388916}", "{\"n\": 18187, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 10224.549, \"total_train_time_s\": 10.358866691589355}", "{\"n\": 18188, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.27, \"learn_time_ms\": 10116.37, \"total_train_time_s\": 11.033905267715454}", "{\"n\": 18189, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.9, \"learn_time_ms\": 10127.759, \"total_train_time_s\": 12.627198457717896}", "{\"n\": 18190, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.13, \"learn_time_ms\": 10128.81, \"total_train_time_s\": 12.43929147720337}", "{\"n\": 18191, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.61, \"learn_time_ms\": 10157.522, \"total_train_time_s\": 12.425304889678955}", "{\"n\": 18192, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.61, \"learn_time_ms\": 10204.743, \"total_train_time_s\": 12.728677034378052}", "{\"n\": 18193, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3601.47, \"learn_time_ms\": 10188.682, \"total_train_time_s\": 11.915030479431152}", "{\"n\": 18194, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.85, \"learn_time_ms\": 10225.288, \"total_train_time_s\": 12.326502561569214}", "{\"n\": 18195, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.6, \"learn_time_ms\": 10139.861, \"total_train_time_s\": 11.862669467926025}", "{\"n\": 18196, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 10123.436, \"total_train_time_s\": 12.72789454460144}", "{\"n\": 18197, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.07, \"learn_time_ms\": 10154.738, \"total_train_time_s\": 10.62748098373413}", "{\"n\": 18198, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.62, \"learn_time_ms\": 10200.584, \"total_train_time_s\": 11.469980478286743}", "{\"n\": 18199, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.73, \"learn_time_ms\": 10127.808, \"total_train_time_s\": 11.881440877914429}", "{\"n\": 18200, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.73, \"learn_time_ms\": 10108.035, \"total_train_time_s\": 12.267147064208984}", "{\"n\": 18201, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.1, \"learn_time_ms\": 10071.172, \"total_train_time_s\": 12.050102710723877}", "{\"n\": 18202, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3598.73, \"learn_time_ms\": 9916.371, \"total_train_time_s\": 11.188003301620483}", "{\"n\": 18203, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.78, \"learn_time_ms\": 10031.749, \"total_train_time_s\": 13.006123781204224}", "{\"n\": 18204, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.78, \"learn_time_ms\": 10103.103, \"total_train_time_s\": 12.982895851135254}", "{\"n\": 18205, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.31, \"learn_time_ms\": 10073.747, \"total_train_time_s\": 11.595538139343262}", "{\"n\": 18206, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 9964.162, \"total_train_time_s\": 11.648369312286377}", "{\"n\": 18207, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 10041.209, \"total_train_time_s\": 11.427785634994507}", "{\"n\": 18208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3596.02, \"learn_time_ms\": 10123.157, \"total_train_time_s\": 12.334232568740845}", "{\"n\": 18209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.9, \"learn_time_ms\": 10114.845, \"total_train_time_s\": 11.80025053024292}", "{\"n\": 18210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.9, \"learn_time_ms\": 10170.521, \"total_train_time_s\": 12.776042461395264}", "{\"n\": 18211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.9, \"learn_time_ms\": 10124.728, \"total_train_time_s\": 11.582501411437988}", "{\"n\": 18212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.33, \"learn_time_ms\": 10164.582, \"total_train_time_s\": 11.559683322906494}", "{\"n\": 18213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.93, \"learn_time_ms\": 10037.469, \"total_train_time_s\": 11.723446607589722}", "{\"n\": 18214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3579.93, \"learn_time_ms\": 9842.615, \"total_train_time_s\": 11.119668006896973}", "{\"n\": 18215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3581.38, \"learn_time_ms\": 9962.371, \"total_train_time_s\": 12.869925260543823}", "{\"n\": 18216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.3, \"learn_time_ms\": 9960.398, \"total_train_time_s\": 11.70438838005066}", "{\"n\": 18217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.82, \"learn_time_ms\": 10105.36, \"total_train_time_s\": 12.90361762046814}", "{\"n\": 18218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.82, \"learn_time_ms\": 9991.854, \"total_train_time_s\": 11.151146173477173}", "{\"n\": 18219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.54, \"learn_time_ms\": 10048.565, \"total_train_time_s\": 12.356172800064087}", "{\"n\": 18220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3602.54, \"learn_time_ms\": 9947.919, \"total_train_time_s\": 11.777625560760498}", "{\"n\": 18221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.25, \"learn_time_ms\": 10066.39, \"total_train_time_s\": 12.77581000328064}", "{\"n\": 18222, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.25, \"learn_time_ms\": 10191.892, \"total_train_time_s\": 12.81308627128601}", "{\"n\": 18223, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.62, \"learn_time_ms\": 10329.068, \"total_train_time_s\": 13.167596578598022}", "{\"n\": 18224, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3608.03, \"learn_time_ms\": 10429.404, \"total_train_time_s\": 12.096773624420166}", "{\"n\": 18225, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3608.03, \"learn_time_ms\": 10357.709, \"total_train_time_s\": 12.111304759979248}", "{\"n\": 18226, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.57, \"learn_time_ms\": 10361.259, \"total_train_time_s\": 11.70628547668457}", "{\"n\": 18227, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.14, \"learn_time_ms\": 10287.704, \"total_train_time_s\": 12.21912431716919}", "{\"n\": 18228, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.9, \"learn_time_ms\": 10528.923, \"total_train_time_s\": 13.535888433456421}", "{\"n\": 18229, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.19, \"learn_time_ms\": 10516.724, \"total_train_time_s\": 12.207739114761353}", "{\"n\": 18230, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.09, \"learn_time_ms\": 10503.839, \"total_train_time_s\": 11.652295351028442}", "{\"n\": 18231, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.09, \"learn_time_ms\": 10363.031, \"total_train_time_s\": 11.349528551101685}", "{\"n\": 18232, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.16, \"learn_time_ms\": 10219.915, \"total_train_time_s\": 11.375564575195312}", "{\"n\": 18233, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.99, \"learn_time_ms\": 10150.336, \"total_train_time_s\": 12.439019918441772}", "{\"n\": 18234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3585.99, \"learn_time_ms\": 10263.143, \"total_train_time_s\": 13.210907459259033}", "{\"n\": 18235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3580.54, \"learn_time_ms\": 10244.264, \"total_train_time_s\": 11.863034725189209}", "{\"n\": 18236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3588.06, \"learn_time_ms\": 10315.943, \"total_train_time_s\": 12.377386569976807}", "{\"n\": 18237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.55, \"learn_time_ms\": 10233.48, \"total_train_time_s\": 11.386927127838135}", "{\"n\": 18238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 10159.414, \"total_train_time_s\": 12.830164432525635}", "{\"n\": 18239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 10102.883, \"total_train_time_s\": 11.592544555664062}", "{\"n\": 18240, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.99, \"learn_time_ms\": 10139.3, \"total_train_time_s\": 12.018151044845581}", "{\"n\": 18241, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.23, \"learn_time_ms\": 10184.753, \"total_train_time_s\": 11.803523063659668}", "{\"n\": 18242, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.23, \"learn_time_ms\": 10218.747, \"total_train_time_s\": 11.722440004348755}", "{\"n\": 18243, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.23, \"learn_time_ms\": 10242.765, \"total_train_time_s\": 12.62563967704773}", "{\"n\": 18244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.97, \"learn_time_ms\": 10160.714, \"total_train_time_s\": 12.418700695037842}", "{\"n\": 18245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.48, \"learn_time_ms\": 10211.256, \"total_train_time_s\": 12.411141633987427}", "{\"n\": 18246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.48, \"learn_time_ms\": 10256.581, \"total_train_time_s\": 12.810331583023071}", "{\"n\": 18247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3606.2, \"learn_time_ms\": 10289.958, \"total_train_time_s\": 11.654629945755005}", "{\"n\": 18248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.73, \"learn_time_ms\": 10200.33, \"total_train_time_s\": 11.926723957061768}", "{\"n\": 18249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.66, \"learn_time_ms\": 10266.734, \"total_train_time_s\": 12.289111614227295}", "{\"n\": 18250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.93, \"learn_time_ms\": 10207.088, \"total_train_time_s\": 11.410102605819702}", "{\"n\": 18251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3603.63, \"learn_time_ms\": 10248.436, \"total_train_time_s\": 12.199629306793213}", "{\"n\": 18252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.61, \"learn_time_ms\": 10321.941, \"total_train_time_s\": 12.472448110580444}", "{\"n\": 18253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3609.61, \"learn_time_ms\": 10330.252, \"total_train_time_s\": 12.806833982467651}", "{\"n\": 18254, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.72, \"learn_time_ms\": 10296.657, \"total_train_time_s\": 12.106844663619995}", "{\"n\": 18255, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3582.53, \"learn_time_ms\": 10184.918, \"total_train_time_s\": 11.314369440078735}", "{\"n\": 18256, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.13, \"learn_time_ms\": 10105.829, \"total_train_time_s\": 12.04428744316101}", "{\"n\": 18257, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3595.13, \"learn_time_ms\": 10211.861, \"total_train_time_s\": 12.72350549697876}", "{\"n\": 18258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.76, \"learn_time_ms\": 10189.076, \"total_train_time_s\": 11.714627504348755}", "{\"n\": 18259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.89, \"learn_time_ms\": 10099.262, \"total_train_time_s\": 11.42034363746643}", "{\"n\": 18260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.27, \"learn_time_ms\": 10067.618, \"total_train_time_s\": 11.121525287628174}", "{\"n\": 18261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3596.43, \"learn_time_ms\": 10003.667, \"total_train_time_s\": 11.58558702468872}", "{\"n\": 18262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.99, \"learn_time_ms\": 9981.188, \"total_train_time_s\": 12.262974262237549}", "{\"n\": 18263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.86, \"learn_time_ms\": 9857.976, \"total_train_time_s\": 11.538057327270508}", "{\"n\": 18264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.86, \"learn_time_ms\": 9869.176, \"total_train_time_s\": 12.181613683700562}", "{\"n\": 18265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3601.24, \"learn_time_ms\": 9909.289, \"total_train_time_s\": 11.699081897735596}", "{\"n\": 18266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.68, \"learn_time_ms\": 9870.204, \"total_train_time_s\": 11.642195701599121}", "{\"n\": 18267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3612.68, \"learn_time_ms\": 9686.812, \"total_train_time_s\": 10.900792360305786}", "{\"n\": 18268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.49, \"learn_time_ms\": 9864.122, \"total_train_time_s\": 13.512892961502075}", "{\"n\": 18269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3599.49, \"learn_time_ms\": 9830.813, \"total_train_time_s\": 11.09600830078125}", "{\"n\": 18270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3608.17, \"learn_time_ms\": 9905.534, \"total_train_time_s\": 11.869110584259033}", "{\"n\": 18271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3622.55, \"learn_time_ms\": 10050.796, \"total_train_time_s\": 13.062033653259277}", "{\"n\": 18272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.5, \"learn_time_ms\": 10116.214, \"total_train_time_s\": 12.907934665679932}", "{\"n\": 18273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3611.5, \"learn_time_ms\": 10184.866, \"total_train_time_s\": 12.196629762649536}", "{\"n\": 18274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.65, \"learn_time_ms\": 10223.03, \"total_train_time_s\": 12.539271831512451}", "{\"n\": 18275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10286.6, \"total_train_time_s\": 12.358220100402832}", "{\"n\": 18276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10385.98, \"total_train_time_s\": 12.651485681533813}", "{\"n\": 18277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.51, \"learn_time_ms\": 10485.009, \"total_train_time_s\": 11.888190269470215}", "{\"n\": 18278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10413.503, \"total_train_time_s\": 12.804425716400146}", "{\"n\": 18279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.83, \"learn_time_ms\": 10597.496, \"total_train_time_s\": 12.924199342727661}", "{\"n\": 18280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3619.83, \"learn_time_ms\": 10517.391, \"total_train_time_s\": 11.050366878509521}", "{\"n\": 18281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3626.56, \"learn_time_ms\": 10493.913, \"total_train_time_s\": 12.779182434082031}", "{\"n\": 18282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.85, \"learn_time_ms\": 10436.54, \"total_train_time_s\": 12.333096504211426}", "{\"n\": 18283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 10390.916, \"total_train_time_s\": 11.74417781829834}", "{\"n\": 18284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 10338.178, \"total_train_time_s\": 12.006322145462036}", "{\"n\": 18285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.54, \"learn_time_ms\": 10312.811, \"total_train_time_s\": 12.08436632156372}", "{\"n\": 18286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.38, \"learn_time_ms\": 10148.752, \"total_train_time_s\": 11.031557083129883}", "{\"n\": 18287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.3, \"learn_time_ms\": 10164.085, \"total_train_time_s\": 12.039148569107056}", "{\"n\": 18288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.3, \"learn_time_ms\": 10109.131, \"total_train_time_s\": 12.248975276947021}", "{\"n\": 18289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.19, \"learn_time_ms\": 10117.35, \"total_train_time_s\": 13.014058351516724}", "{\"n\": 18290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.29, \"learn_time_ms\": 10312.864, \"total_train_time_s\": 13.00609827041626}", "{\"n\": 18291, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.57, \"learn_time_ms\": 10284.245, \"total_train_time_s\": 12.51974105834961}", "{\"n\": 18292, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.54, \"learn_time_ms\": 10323.536, \"total_train_time_s\": 12.709437847137451}", "{\"n\": 18293, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 10457.416, \"total_train_time_s\": 13.062456607818604}", "{\"n\": 18294, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 10562.329, \"total_train_time_s\": 13.073094844818115}", "{\"n\": 18295, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 10547.314, \"total_train_time_s\": 11.924230813980103}", "{\"n\": 18296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3630.52, \"learn_time_ms\": 10679.259, \"total_train_time_s\": 12.34133005142212}", "{\"n\": 18297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.73, \"learn_time_ms\": 10593.564, \"total_train_time_s\": 11.16524600982666}", "{\"n\": 18298, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.79, \"learn_time_ms\": 10507.966, \"total_train_time_s\": 11.332607507705688}", "{\"n\": 18299, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3632.79, \"learn_time_ms\": 10417.54, \"total_train_time_s\": 12.098673582077026}", "{\"n\": 18300, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.89, \"learn_time_ms\": 10305.383, \"total_train_time_s\": 11.882131338119507}", "{\"n\": 18301, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.58, \"learn_time_ms\": 10311.245, \"total_train_time_s\": 12.630329608917236}", "{\"n\": 18302, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 10167.857, \"total_train_time_s\": 11.250478267669678}", "{\"n\": 18303, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 10208.162, \"total_train_time_s\": 13.487840175628662}", "{\"n\": 18304, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.14, \"learn_time_ms\": 10043.47, \"total_train_time_s\": 11.455422163009644}", "{\"n\": 18305, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.67, \"learn_time_ms\": 10023.015, \"total_train_time_s\": 11.72749376296997}", "{\"n\": 18306, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.67, \"learn_time_ms\": 10020.628, \"total_train_time_s\": 12.32242488861084}", "{\"n\": 18307, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.18, \"learn_time_ms\": 10154.976, \"total_train_time_s\": 12.519479990005493}", "{\"n\": 18308, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.18, \"learn_time_ms\": 10163.462, \"total_train_time_s\": 11.444537162780762}", "{\"n\": 18309, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.65, \"learn_time_ms\": 10145.705, \"total_train_time_s\": 11.947460412979126}", "{\"n\": 18310, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.06, \"learn_time_ms\": 10218.7, \"total_train_time_s\": 12.573628425598145}", "{\"n\": 18311, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.06, \"learn_time_ms\": 10252.609, \"total_train_time_s\": 12.888907194137573}", "{\"n\": 18312, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.17, \"learn_time_ms\": 10423.698, \"total_train_time_s\": 12.999988317489624}", "{\"n\": 18313, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.17, \"learn_time_ms\": 10394.569, \"total_train_time_s\": 13.210834741592407}", "{\"n\": 18314, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.71, \"learn_time_ms\": 10405.417, \"total_train_time_s\": 11.52562403678894}", "{\"n\": 18315, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.23, \"learn_time_ms\": 10345.404, \"total_train_time_s\": 11.094605684280396}", "{\"n\": 18316, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.07, \"learn_time_ms\": 10250.762, \"total_train_time_s\": 11.380235195159912}", "{\"n\": 18317, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.07, \"learn_time_ms\": 10187.693, \"total_train_time_s\": 11.890536069869995}", "{\"n\": 18318, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.0, \"learn_time_ms\": 10260.682, \"total_train_time_s\": 12.204766511917114}", "{\"n\": 18319, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.18, \"learn_time_ms\": 10314.915, \"total_train_time_s\": 12.497832775115967}", "{\"n\": 18320, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 10342.994, \"total_train_time_s\": 12.903671503067017}", "{\"n\": 18321, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 10255.767, \"total_train_time_s\": 11.981828927993774}", "{\"n\": 18322, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.42, \"learn_time_ms\": 10103.803, \"total_train_time_s\": 11.529381275177002}", "{\"n\": 18323, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.66, \"learn_time_ms\": 10092.26, \"total_train_time_s\": 13.139359474182129}", "{\"n\": 18324, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.72, \"learn_time_ms\": 10143.341, \"total_train_time_s\": 12.058878660202026}", "{\"n\": 18325, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.72, \"learn_time_ms\": 10286.565, \"total_train_time_s\": 12.548799753189087}", "{\"n\": 18326, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.64, \"learn_time_ms\": 10398.78, \"total_train_time_s\": 12.458423852920532}", "{\"n\": 18327, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.69, \"learn_time_ms\": 10507.652, \"total_train_time_s\": 12.971307277679443}", "{\"n\": 18328, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.69, \"learn_time_ms\": 10511.82, \"total_train_time_s\": 12.243813037872314}", "{\"n\": 18329, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.54, \"learn_time_ms\": 10413.758, \"total_train_time_s\": 11.451964378356934}", "{\"n\": 18330, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3674.84, \"learn_time_ms\": 10359.631, \"total_train_time_s\": 12.322324991226196}", "{\"n\": 18331, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.71, \"learn_time_ms\": 10299.727, \"total_train_time_s\": 11.443637132644653}", "{\"n\": 18332, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3679.71, \"learn_time_ms\": 10282.319, \"total_train_time_s\": 11.282241344451904}", "{\"n\": 18333, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.22, \"learn_time_ms\": 10187.328, \"total_train_time_s\": 12.20558500289917}", "{\"n\": 18334, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.06, \"learn_time_ms\": 10213.018, \"total_train_time_s\": 12.324563026428223}", "{\"n\": 18335, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 10093.904, \"total_train_time_s\": 11.36426305770874}", "{\"n\": 18336, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 9992.862, \"total_train_time_s\": 11.460896730422974}", "{\"n\": 18337, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.21, \"learn_time_ms\": 9841.729, \"total_train_time_s\": 11.45549464225769}", "{\"n\": 18338, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.7, \"learn_time_ms\": 9757.149, \"total_train_time_s\": 11.380678176879883}", "{\"n\": 18339, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.49, \"learn_time_ms\": 9803.271, \"total_train_time_s\": 11.910039901733398}", "{\"n\": 18340, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 9773.494, \"total_train_time_s\": 12.050342321395874}", "{\"n\": 18341, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3680.82, \"learn_time_ms\": 9876.747, \"total_train_time_s\": 12.504857540130615}", "{\"n\": 18342, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3688.37, \"learn_time_ms\": 9878.042, \"total_train_time_s\": 11.301454305648804}", "{\"n\": 18343, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.51, \"learn_time_ms\": 9872.6, \"total_train_time_s\": 12.071616649627686}", "{\"n\": 18344, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.51, \"learn_time_ms\": 9798.67, \"total_train_time_s\": 11.56887698173523}", "{\"n\": 18345, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.72, \"learn_time_ms\": 9870.506, \"total_train_time_s\": 12.081312656402588}", "{\"n\": 18346, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.66, \"learn_time_ms\": 10042.576, \"total_train_time_s\": 13.213883638381958}", "{\"n\": 18347, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.66, \"learn_time_ms\": 10141.684, \"total_train_time_s\": 12.506028175354004}", "{\"n\": 18348, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.61, \"learn_time_ms\": 10191.727, \"total_train_time_s\": 11.899091243743896}", "{\"n\": 18349, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.61, \"learn_time_ms\": 10139.989, \"total_train_time_s\": 11.400514125823975}", "{\"n\": 18350, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.45, \"learn_time_ms\": 10078.521, \"total_train_time_s\": 11.435229063034058}", "{\"n\": 18351, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.45, \"learn_time_ms\": 10063.296, \"total_train_time_s\": 12.345962285995483}", "{\"n\": 18352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.51, \"learn_time_ms\": 10140.401, \"total_train_time_s\": 12.08133864402771}", "{\"n\": 18353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3676.28, \"learn_time_ms\": 10123.283, \"total_train_time_s\": 11.902599334716797}", "{\"n\": 18354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.8, \"learn_time_ms\": 10220.61, \"total_train_time_s\": 12.570486783981323}", "{\"n\": 18355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.27, \"learn_time_ms\": 10195.501, \"total_train_time_s\": 11.827335357666016}", "{\"n\": 18356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.28, \"learn_time_ms\": 10125.478, \"total_train_time_s\": 12.439130783081055}", "{\"n\": 18357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.28, \"learn_time_ms\": 10000.286, \"total_train_time_s\": 11.200977802276611}", "{\"n\": 18358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.61, \"learn_time_ms\": 10143.257, \"total_train_time_s\": 13.331226110458374}", "{\"n\": 18359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.53, \"learn_time_ms\": 10159.139, \"total_train_time_s\": 11.593972206115723}", "{\"n\": 18360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.53, \"learn_time_ms\": 10118.318, \"total_train_time_s\": 10.985671043395996}", "{\"n\": 18361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.78, \"learn_time_ms\": 10165.933, \"total_train_time_s\": 12.848717212677002}", "{\"n\": 18362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.78, \"learn_time_ms\": 10246.059, \"total_train_time_s\": 12.889567375183105}", "{\"n\": 18363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.4, \"learn_time_ms\": 10347.781, \"total_train_time_s\": 12.929261445999146}", "{\"n\": 18364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.35, \"learn_time_ms\": 10236.392, \"total_train_time_s\": 11.419690370559692}", "{\"n\": 18365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.32, \"learn_time_ms\": 10292.247, \"total_train_time_s\": 12.379807233810425}", "{\"n\": 18366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.32, \"learn_time_ms\": 10301.53, \"total_train_time_s\": 12.570274591445923}", "{\"n\": 18367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.49, \"learn_time_ms\": 10344.853, \"total_train_time_s\": 11.647275447845459}", "{\"n\": 18368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.21, \"learn_time_ms\": 10207.085, \"total_train_time_s\": 11.974737405776978}", "{\"n\": 18369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.21, \"learn_time_ms\": 10281.219, \"total_train_time_s\": 12.344035148620605}", "{\"n\": 18370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.21, \"learn_time_ms\": 10471.203, \"total_train_time_s\": 12.905498743057251}", "{\"n\": 18371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.53, \"learn_time_ms\": 10435.973, \"total_train_time_s\": 12.480295181274414}", "{\"n\": 18372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10359.414, \"total_train_time_s\": 12.097814559936523}", "{\"n\": 18373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10263.884, \"total_train_time_s\": 11.939382314682007}", "{\"n\": 18374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.21, \"learn_time_ms\": 10445.672, \"total_train_time_s\": 13.211314916610718}", "{\"n\": 18375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.65, \"learn_time_ms\": 10382.582, \"total_train_time_s\": 11.764977216720581}", "{\"n\": 18376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.44, \"learn_time_ms\": 10331.743, \"total_train_time_s\": 12.086153268814087}", "{\"n\": 18377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.44, \"learn_time_ms\": 10300.258, \"total_train_time_s\": 11.327093362808228}", "{\"n\": 18378, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.54, \"learn_time_ms\": 10279.339, \"total_train_time_s\": 11.721116304397583}", "{\"n\": 18379, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.17, \"learn_time_ms\": 10278.838, \"total_train_time_s\": 12.325829982757568}", "{\"n\": 18380, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.96, \"learn_time_ms\": 10239.917, \"total_train_time_s\": 12.508769035339355}", "{\"n\": 18381, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.96, \"learn_time_ms\": 10218.426, \"total_train_time_s\": 12.21791934967041}", "{\"n\": 18382, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.24, \"learn_time_ms\": 10191.185, \"total_train_time_s\": 11.831503629684448}", "{\"n\": 18383, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.36, \"learn_time_ms\": 10167.383, \"total_train_time_s\": 11.709402322769165}", "{\"n\": 18384, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.36, \"learn_time_ms\": 10027.497, \"total_train_time_s\": 11.803099870681763}", "{\"n\": 18385, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.16, \"learn_time_ms\": 10156.127, \"total_train_time_s\": 13.039576530456543}", "{\"n\": 18386, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.33, \"learn_time_ms\": 10312.245, \"total_train_time_s\": 13.652668476104736}", "{\"n\": 18387, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.39, \"learn_time_ms\": 10324.469, \"total_train_time_s\": 11.45324993133545}", "{\"n\": 18388, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.39, \"learn_time_ms\": 10404.227, \"total_train_time_s\": 12.533915281295776}", "{\"n\": 18389, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.39, \"learn_time_ms\": 10407.631, \"total_train_time_s\": 12.38894248008728}", "{\"n\": 18390, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.67, \"learn_time_ms\": 10268.451, \"total_train_time_s\": 11.186266422271729}", "{\"n\": 18391, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.67, \"learn_time_ms\": 10203.325, \"total_train_time_s\": 11.563213586807251}", "{\"n\": 18392, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.67, \"learn_time_ms\": 10242.866, \"total_train_time_s\": 12.214491844177246}", "{\"n\": 18393, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.54, \"learn_time_ms\": 10292.799, \"total_train_time_s\": 12.217325687408447}", "{\"n\": 18394, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.59, \"learn_time_ms\": 10383.995, \"total_train_time_s\": 12.774547338485718}", "{\"n\": 18395, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.59, \"learn_time_ms\": 10359.82, \"total_train_time_s\": 12.824148893356323}", "{\"n\": 18396, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.55, \"learn_time_ms\": 10252.681, \"total_train_time_s\": 12.528048753738403}", "{\"n\": 18397, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.66, \"learn_time_ms\": 10274.693, \"total_train_time_s\": 11.642025709152222}", "{\"n\": 18398, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.28, \"learn_time_ms\": 10254.895, \"total_train_time_s\": 12.325350046157837}", "{\"n\": 18399, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.28, \"learn_time_ms\": 10272.676, \"total_train_time_s\": 12.544829368591309}", "{\"n\": 18400, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.91, \"learn_time_ms\": 10340.825, \"total_train_time_s\": 11.854479551315308}", "{\"n\": 18401, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.82, \"learn_time_ms\": 10359.699, \"total_train_time_s\": 11.828194379806519}", "{\"n\": 18402, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.82, \"learn_time_ms\": 10384.54, \"total_train_time_s\": 12.50788402557373}", "{\"n\": 18403, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.26, \"learn_time_ms\": 10446.215, \"total_train_time_s\": 12.82064700126648}", "{\"n\": 18404, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.24, \"learn_time_ms\": 10374.363, \"total_train_time_s\": 12.043941736221313}", "{\"n\": 18405, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.69, \"learn_time_ms\": 10249.438, \"total_train_time_s\": 11.554057836532593}", "{\"n\": 18406, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 10215.287, \"total_train_time_s\": 12.217312335968018}", "{\"n\": 18407, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 10290.085, \"total_train_time_s\": 12.407955646514893}", "{\"n\": 18408, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.76, \"learn_time_ms\": 10335.092, \"total_train_time_s\": 12.793352603912354}", "{\"n\": 18409, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.36, \"learn_time_ms\": 10351.491, \"total_train_time_s\": 12.73275899887085}", "{\"n\": 18410, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.91, \"learn_time_ms\": 10382.946, \"total_train_time_s\": 12.13896894454956}", "{\"n\": 18411, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.28, \"learn_time_ms\": 10405.922, \"total_train_time_s\": 12.007290840148926}", "{\"n\": 18412, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.33, \"learn_time_ms\": 10342.952, \"total_train_time_s\": 11.885753154754639}", "{\"n\": 18413, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.23, \"learn_time_ms\": 10261.476, \"total_train_time_s\": 12.044142246246338}", "{\"n\": 18414, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3648.43, \"learn_time_ms\": 10270.077, \"total_train_time_s\": 12.132286787033081}", "{\"n\": 18415, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.93, \"learn_time_ms\": 10233.769, \"total_train_time_s\": 11.221526622772217}", "{\"n\": 18416, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.36, \"learn_time_ms\": 10202.127, \"total_train_time_s\": 11.909743785858154}", "{\"n\": 18417, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.81, \"learn_time_ms\": 10098.785, \"total_train_time_s\": 11.356523036956787}", "{\"n\": 18418, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.72, \"learn_time_ms\": 10027.416, \"total_train_time_s\": 12.027414083480835}", "{\"n\": 18419, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.15, \"learn_time_ms\": 9976.95, \"total_train_time_s\": 12.228613376617432}", "{\"n\": 18420, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.29, \"learn_time_ms\": 9949.694, \"total_train_time_s\": 11.898165464401245}", "{\"n\": 18421, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.29, \"learn_time_ms\": 10001.445, \"total_train_time_s\": 12.475379467010498}", "{\"n\": 18422, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3631.02, \"learn_time_ms\": 10029.61, \"total_train_time_s\": 12.141198635101318}", "{\"n\": 18423, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.55, \"learn_time_ms\": 10085.937, \"total_train_time_s\": 12.603665351867676}", "{\"n\": 18424, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.78, \"learn_time_ms\": 10059.028, \"total_train_time_s\": 11.854605436325073}", "{\"n\": 18425, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.03, \"learn_time_ms\": 10168.143, \"total_train_time_s\": 12.275383472442627}", "{\"n\": 18426, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.08, \"learn_time_ms\": 10253.782, \"total_train_time_s\": 12.753274202346802}", "{\"n\": 18427, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3615.16, \"learn_time_ms\": 10330.589, \"total_train_time_s\": 12.155413150787354}", "{\"n\": 18428, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.88, \"learn_time_ms\": 10284.206, \"total_train_time_s\": 11.636363744735718}", "{\"n\": 18429, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.88, \"learn_time_ms\": 10308.705, \"total_train_time_s\": 12.486533403396606}", "{\"n\": 18430, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.71, \"learn_time_ms\": 10368.149, \"total_train_time_s\": 12.511056900024414}", "{\"n\": 18431, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.88, \"learn_time_ms\": 10432.955, \"total_train_time_s\": 13.186434745788574}", "{\"n\": 18432, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.88, \"learn_time_ms\": 10468.241, \"total_train_time_s\": 12.440724611282349}", "{\"n\": 18433, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.88, \"learn_time_ms\": 10365.581, \"total_train_time_s\": 11.544581651687622}", "{\"n\": 18434, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.28, \"learn_time_ms\": 10393.107, \"total_train_time_s\": 12.119487524032593}", "{\"n\": 18435, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.09, \"learn_time_ms\": 10360.214, \"total_train_time_s\": 11.978078126907349}", "{\"n\": 18436, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.09, \"learn_time_ms\": 10230.94, \"total_train_time_s\": 11.481662511825562}", "{\"n\": 18437, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.65, \"learn_time_ms\": 10287.782, \"total_train_time_s\": 12.706838607788086}", "{\"n\": 18438, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 10273.896, \"total_train_time_s\": 11.482726335525513}", "{\"n\": 18439, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 10225.151, \"total_train_time_s\": 11.984358787536621}", "{\"n\": 18440, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 10050.519, \"total_train_time_s\": 10.703269243240356}", "{\"n\": 18441, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.74, \"learn_time_ms\": 9995.741, \"total_train_time_s\": 12.643304347991943}", "{\"n\": 18442, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.74, \"learn_time_ms\": 9864.087, \"total_train_time_s\": 11.148643493652344}", "{\"n\": 18443, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.74, \"learn_time_ms\": 10025.99, \"total_train_time_s\": 13.155896663665771}", "{\"n\": 18444, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3586.5, \"learn_time_ms\": 10014.84, \"total_train_time_s\": 12.041735887527466}", "{\"n\": 18445, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3586.25, \"learn_time_ms\": 10034.983, \"total_train_time_s\": 12.237370729446411}", "{\"n\": 18446, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3586.25, \"learn_time_ms\": 10154.784, \"total_train_time_s\": 12.653400897979736}", "{\"n\": 18447, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.58, \"learn_time_ms\": 10067.118, \"total_train_time_s\": 11.81168270111084}", "{\"n\": 18448, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.54, \"learn_time_ms\": 10056.518, \"total_train_time_s\": 11.370278596878052}", "{\"n\": 18449, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.54, \"learn_time_ms\": 10071.772, \"total_train_time_s\": 12.07692551612854}", "{\"n\": 18450, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.89, \"learn_time_ms\": 10246.102, \"total_train_time_s\": 12.43518328666687}", "{\"n\": 18451, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.84, \"learn_time_ms\": 10280.651, \"total_train_time_s\": 12.953731536865234}", "{\"n\": 18452, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3571.9, \"learn_time_ms\": 10499.317, \"total_train_time_s\": 13.387060165405273}", "{\"n\": 18453, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3564.74, \"learn_time_ms\": 10388.386, \"total_train_time_s\": 12.080195665359497}", "{\"n\": 18454, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3564.74, \"learn_time_ms\": 10502.412, \"total_train_time_s\": 13.124099969863892}", "{\"n\": 18455, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3574.37, \"learn_time_ms\": 10621.533, \"total_train_time_s\": 13.352216720581055}", "{\"n\": 18456, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3571.96, \"learn_time_ms\": 10471.63, \"total_train_time_s\": 11.178202867507935}", "{\"n\": 18457, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.63, \"learn_time_ms\": 10510.612, \"total_train_time_s\": 12.205421209335327}", "{\"n\": 18458, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.63, \"learn_time_ms\": 10632.954, \"total_train_time_s\": 12.55441951751709}", "{\"n\": 18459, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.83, \"learn_time_ms\": 10532.589, \"total_train_time_s\": 11.131741523742676}", "{\"n\": 18460, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3575.9, \"learn_time_ms\": 10448.494, \"total_train_time_s\": 11.579538106918335}", "{\"n\": 18461, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.07, \"learn_time_ms\": 10359.428, \"total_train_time_s\": 12.134238004684448}", "{\"n\": 18462, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.07, \"learn_time_ms\": 10165.109, \"total_train_time_s\": 11.434007406234741}", "{\"n\": 18463, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3582.15, \"learn_time_ms\": 10136.16, \"total_train_time_s\": 11.805659294128418}", "{\"n\": 18464, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3582.15, \"learn_time_ms\": 10074.279, \"total_train_time_s\": 12.500577688217163}", "{\"n\": 18465, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3589.21, \"learn_time_ms\": 9920.383, \"total_train_time_s\": 11.805640459060669}", "{\"n\": 18466, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.81, \"learn_time_ms\": 9939.615, \"total_train_time_s\": 11.318946361541748}", "{\"n\": 18467, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3580.81, \"learn_time_ms\": 9930.315, \"total_train_time_s\": 12.12336254119873}", "{\"n\": 18468, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.5, \"learn_time_ms\": 9771.051, \"total_train_time_s\": 10.993484497070312}", "{\"n\": 18469, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3586.48, \"learn_time_ms\": 9874.338, \"total_train_time_s\": 12.129305362701416}", "{\"n\": 18470, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.54, \"learn_time_ms\": 9872.179, \"total_train_time_s\": 11.634374856948853}", "{\"n\": 18471, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3597.54, \"learn_time_ms\": 9826.861, \"total_train_time_s\": 11.634816884994507}", "{\"n\": 18472, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.01, \"learn_time_ms\": 10048.986, \"total_train_time_s\": 13.690052032470703}", "{\"n\": 18473, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3590.08, \"learn_time_ms\": 10048.111, \"total_train_time_s\": 11.938515186309814}", "{\"n\": 18474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.03, \"learn_time_ms\": 9967.045, \"total_train_time_s\": 11.72987699508667}", "{\"n\": 18475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3581.03, \"learn_time_ms\": 9932.394, \"total_train_time_s\": 11.471125841140747}", "{\"n\": 18476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.39, \"learn_time_ms\": 10165.365, \"total_train_time_s\": 13.756000995635986}", "{\"n\": 18477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.39, \"learn_time_ms\": 10171.094, \"total_train_time_s\": 12.215933799743652}", "{\"n\": 18478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.37, \"learn_time_ms\": 10283.205, \"total_train_time_s\": 12.08912444114685}", "{\"n\": 18479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.98, \"learn_time_ms\": 10367.888, \"total_train_time_s\": 13.009685516357422}", "{\"n\": 18480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3562.94, \"learn_time_ms\": 10495.299, \"total_train_time_s\": 12.875916719436646}", "{\"n\": 18481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.61, \"learn_time_ms\": 10430.86, \"total_train_time_s\": 10.966707706451416}", "{\"n\": 18482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.1, \"learn_time_ms\": 10250.835, \"total_train_time_s\": 11.862390279769897}", "{\"n\": 18483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3554.9, \"learn_time_ms\": 10258.944, \"total_train_time_s\": 11.905923843383789}", "{\"n\": 18484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3554.9, \"learn_time_ms\": 10237.673, \"total_train_time_s\": 11.55852198600769}", "{\"n\": 18485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.03, \"learn_time_ms\": 10336.961, \"total_train_time_s\": 12.463403224945068}", "{\"n\": 18486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.39, \"learn_time_ms\": 10074.007, \"total_train_time_s\": 11.061345338821411}", "{\"n\": 18487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.2, \"learn_time_ms\": 9936.672, \"total_train_time_s\": 10.84136152267456}", "{\"n\": 18488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.67, \"learn_time_ms\": 9912.276, \"total_train_time_s\": 11.8688645362854}", "{\"n\": 18489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.67, \"learn_time_ms\": 9775.853, \"total_train_time_s\": 11.627093315124512}", "{\"n\": 18490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.97, \"learn_time_ms\": 9730.343, \"total_train_time_s\": 12.43566083908081}", "{\"n\": 18491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3541.01, \"learn_time_ms\": 9926.923, \"total_train_time_s\": 12.949932336807251}", "{\"n\": 18492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3541.01, \"learn_time_ms\": 10057.684, \"total_train_time_s\": 13.142171621322632}", "{\"n\": 18493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3530.81, \"learn_time_ms\": 10094.356, \"total_train_time_s\": 12.197176218032837}", "{\"n\": 18494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3538.43, \"learn_time_ms\": 10128.179, \"total_train_time_s\": 11.854333639144897}", "{\"n\": 18495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.58, \"learn_time_ms\": 9963.965, \"total_train_time_s\": 10.800123691558838}", "{\"n\": 18496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.88, \"learn_time_ms\": 9992.707, \"total_train_time_s\": 11.33184266090393}", "{\"n\": 18497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.11, \"learn_time_ms\": 10109.51, \"total_train_time_s\": 11.980937719345093}", "{\"n\": 18498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.91, \"learn_time_ms\": 10017.324, \"total_train_time_s\": 10.9268159866333}", "{\"n\": 18499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.83, \"learn_time_ms\": 10123.594, \"total_train_time_s\": 12.702733039855957}", "{\"n\": 18500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.83, \"learn_time_ms\": 10037.207, \"total_train_time_s\": 11.567668199539185}", "{\"n\": 18501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.53, \"learn_time_ms\": 9927.463, \"total_train_time_s\": 11.872032880783081}", "{\"n\": 18502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.81, \"learn_time_ms\": 9791.853, \"total_train_time_s\": 11.811142683029175}", "{\"n\": 18503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.32, \"learn_time_ms\": 9798.33, \"total_train_time_s\": 12.295929908752441}", "{\"n\": 18504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.32, \"learn_time_ms\": 9895.51, \"total_train_time_s\": 12.809415340423584}", "{\"n\": 18505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3498.0, \"learn_time_ms\": 10077.706, \"total_train_time_s\": 12.674013614654541}", "{\"n\": 18506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.86, \"learn_time_ms\": 10067.668, \"total_train_time_s\": 11.250349283218384}", "{\"n\": 18507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.86, \"learn_time_ms\": 10097.455, \"total_train_time_s\": 12.282773971557617}", "{\"n\": 18508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.06, \"learn_time_ms\": 10260.747, \"total_train_time_s\": 12.54207968711853}", "{\"n\": 18509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.06, \"learn_time_ms\": 10211.851, \"total_train_time_s\": 12.178152561187744}", "{\"n\": 18510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.65, \"learn_time_ms\": 10215.935, \"total_train_time_s\": 11.603378534317017}", "{\"n\": 18511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.65, \"learn_time_ms\": 10149.842, \"total_train_time_s\": 11.17422103881836}", "{\"n\": 18512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.86, \"learn_time_ms\": 10121.884, \"total_train_time_s\": 11.502583742141724}", "{\"n\": 18513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.89, \"learn_time_ms\": 10081.317, \"total_train_time_s\": 11.854447841644287}", "{\"n\": 18514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.89, \"learn_time_ms\": 10124.506, \"total_train_time_s\": 13.27230978012085}", "{\"n\": 18515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.2, \"learn_time_ms\": 10017.915, \"total_train_time_s\": 11.557666301727295}", "{\"n\": 18516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3537.06, \"learn_time_ms\": 10110.334, \"total_train_time_s\": 12.204308986663818}", "{\"n\": 18517, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3537.06, \"learn_time_ms\": 10218.131, \"total_train_time_s\": 13.38254714012146}", "{\"n\": 18518, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.27, \"learn_time_ms\": 10150.646, \"total_train_time_s\": 11.898886442184448}", "{\"n\": 18519, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.7, \"learn_time_ms\": 10141.517, \"total_train_time_s\": 12.101324558258057}", "{\"n\": 18520, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.92, \"learn_time_ms\": 10091.93, \"total_train_time_s\": 11.102932929992676}", "{\"n\": 18521, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.92, \"learn_time_ms\": 10175.751, \"total_train_time_s\": 12.017163038253784}", "{\"n\": 18522, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.92, \"learn_time_ms\": 10273.232, \"total_train_time_s\": 12.48623538017273}", "{\"n\": 18523, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.46, \"learn_time_ms\": 10355.811, \"total_train_time_s\": 12.718382358551025}", "{\"n\": 18524, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.04, \"learn_time_ms\": 10218.232, \"total_train_time_s\": 11.913905382156372}", "{\"n\": 18525, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.04, \"learn_time_ms\": 10331.781, \"total_train_time_s\": 12.664121627807617}", "{\"n\": 18526, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3525.21, \"learn_time_ms\": 10372.108, \"total_train_time_s\": 12.581408739089966}", "{\"n\": 18527, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.73, \"learn_time_ms\": 10309.69, \"total_train_time_s\": 12.730826139450073}", "{\"n\": 18528, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.73, \"learn_time_ms\": 10275.373, \"total_train_time_s\": 11.528874397277832}", "{\"n\": 18529, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.26, \"learn_time_ms\": 10219.081, \"total_train_time_s\": 11.488779783248901}", "{\"n\": 18530, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.26, \"learn_time_ms\": 10302.832, \"total_train_time_s\": 11.89799976348877}", "{\"n\": 18531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.93, \"learn_time_ms\": 10315.295, \"total_train_time_s\": 12.187121868133545}", "{\"n\": 18532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.68, \"learn_time_ms\": 10410.783, \"total_train_time_s\": 13.44903564453125}", "{\"n\": 18533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.78, \"learn_time_ms\": 10393.443, \"total_train_time_s\": 12.530732870101929}", "{\"n\": 18534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.82, \"learn_time_ms\": 10359.732, \"total_train_time_s\": 11.551050186157227}", "{\"n\": 18535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.82, \"learn_time_ms\": 10244.802, \"total_train_time_s\": 11.505826711654663}", "{\"n\": 18536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.58, \"learn_time_ms\": 10187.993, \"total_train_time_s\": 12.018109798431396}", "{\"n\": 18537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.07, \"learn_time_ms\": 10213.544, \"total_train_time_s\": 13.021611213684082}", "{\"n\": 18538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.07, \"learn_time_ms\": 10266.51, \"total_train_time_s\": 12.075488328933716}", "{\"n\": 18539, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.07, \"learn_time_ms\": 10308.122, \"total_train_time_s\": 11.915881395339966}", "{\"n\": 18540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3544.79, \"learn_time_ms\": 10280.983, \"total_train_time_s\": 11.701149225234985}", "{\"n\": 18541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3554.74, \"learn_time_ms\": 10233.068, \"total_train_time_s\": 11.667704343795776}", "{\"n\": 18542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 5.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3554.74, \"learn_time_ms\": 10020.356, \"total_train_time_s\": 11.321531772613525}", "{\"n\": 18543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3552.03, \"learn_time_ms\": 9961.944, \"total_train_time_s\": 11.979790210723877}", "{\"n\": 18544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3547.75, \"learn_time_ms\": 10051.869, \"total_train_time_s\": 12.439857959747314}", "{\"n\": 18545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3551.65, \"learn_time_ms\": 10116.776, \"total_train_time_s\": 12.184772968292236}", "{\"n\": 18546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3538.58, \"learn_time_ms\": 10172.523, \"total_train_time_s\": 12.560564994812012}", "{\"n\": 18547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3523.62, \"learn_time_ms\": 10033.697, \"total_train_time_s\": 11.613799333572388}", "{\"n\": 18548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3523.62, \"learn_time_ms\": 9971.91, \"total_train_time_s\": 11.42830204963684}", "{\"n\": 18549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3520.57, \"learn_time_ms\": 9955.055, \"total_train_time_s\": 11.80786395072937}", "{\"n\": 18550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3520.57, \"learn_time_ms\": 9983.178, \"total_train_time_s\": 11.919932126998901}", "{\"n\": 18551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3520.99, \"learn_time_ms\": 10030.066, \"total_train_time_s\": 12.112863063812256}", "{\"n\": 18552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3519.05, \"learn_time_ms\": 10230.628, \"total_train_time_s\": 13.329988241195679}", "{\"n\": 18553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3517.3, \"learn_time_ms\": 10216.455, \"total_train_time_s\": 11.777346849441528}", "{\"n\": 18554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3517.3, \"learn_time_ms\": 10111.968, \"total_train_time_s\": 11.369126558303833}", "{\"n\": 18555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3512.83, \"learn_time_ms\": 10006.372, \"total_train_time_s\": 11.135190486907959}", "{\"n\": 18556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3512.83, \"learn_time_ms\": 9944.724, \"total_train_time_s\": 11.949774265289307}", "{\"n\": 18557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3506.3, \"learn_time_ms\": 9987.789, \"total_train_time_s\": 12.028341054916382}", "{\"n\": 18558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3508.89, \"learn_time_ms\": 10007.744, \"total_train_time_s\": 11.661804437637329}", "{\"n\": 18559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3508.53, \"learn_time_ms\": 10192.762, \"total_train_time_s\": 13.64489221572876}", "{\"n\": 18560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3508.53, \"learn_time_ms\": 10235.616, \"total_train_time_s\": 12.352005958557129}", "{\"n\": 18561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3507.54, \"learn_time_ms\": 10187.922, \"total_train_time_s\": 11.679677248001099}", "{\"n\": 18562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3526.25, \"learn_time_ms\": 9974.872, \"total_train_time_s\": 11.203680515289307}", "{\"n\": 18563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 5.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3526.25, \"learn_time_ms\": 9891.068, \"total_train_time_s\": 10.98332142829895}", "{\"n\": 18564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3533.31, \"learn_time_ms\": 9954.142, \"total_train_time_s\": 12.01917314529419}", "{\"n\": 18565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3536.1, \"learn_time_ms\": 10086.978, \"total_train_time_s\": 12.433626174926758}", "{\"n\": 18566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3538.07, \"learn_time_ms\": 10049.575, \"total_train_time_s\": 11.56680941581726}", "{\"n\": 18567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.92, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3545.04, \"learn_time_ms\": 10027.936, \"total_train_time_s\": 11.797317743301392}", "{\"n\": 18568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3535.69, \"learn_time_ms\": 9974.801, \"total_train_time_s\": 11.110269546508789}", "{\"n\": 18569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3535.69, \"learn_time_ms\": 9725.886, \"total_train_time_s\": 11.148688316345215}", "{\"n\": 18570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 9606.068, \"total_train_time_s\": 11.24170184135437}", "{\"n\": 18571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 9803.709, \"total_train_time_s\": 13.71832823753357}", "{\"n\": 18572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3547.02, \"learn_time_ms\": 9933.621, \"total_train_time_s\": 12.581107139587402}", "{\"n\": 18573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3547.02, \"learn_time_ms\": 9979.633, \"total_train_time_s\": 11.422894716262817}", "{\"n\": 18574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3550.08, \"learn_time_ms\": 9980.389, \"total_train_time_s\": 12.039296388626099}", "{\"n\": 18575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3550.08, \"learn_time_ms\": 9988.382, \"total_train_time_s\": 12.561566591262817}", "{\"n\": 18576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3555.5, \"learn_time_ms\": 10002.946, \"total_train_time_s\": 11.714512825012207}", "{\"n\": 18577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3555.5, \"learn_time_ms\": 10046.311, \"total_train_time_s\": 12.258413553237915}", "{\"n\": 18578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3557.46, \"learn_time_ms\": 10126.935, \"total_train_time_s\": 11.955298900604248}", "{\"n\": 18579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.06, \"learn_time_ms\": 10190.556, \"total_train_time_s\": 11.773712873458862}", "{\"n\": 18580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.06, \"learn_time_ms\": 10268.866, \"total_train_time_s\": 11.977747440338135}", "{\"n\": 18581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3566.06, \"learn_time_ms\": 10151.595, \"total_train_time_s\": 12.460224866867065}", "{\"n\": 18582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.68, \"learn_time_ms\": 10067.105, \"total_train_time_s\": 11.634814023971558}", "{\"n\": 18583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.56, \"learn_time_ms\": 10031.217, \"total_train_time_s\": 11.070871829986572}", "{\"n\": 18584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.56, \"learn_time_ms\": 10072.423, \"total_train_time_s\": 12.430315017700195}", "{\"n\": 18585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.91, \"learn_time_ms\": 10109.499, \"total_train_time_s\": 12.897596597671509}", "{\"n\": 18586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.26, \"learn_time_ms\": 10177.955, \"total_train_time_s\": 12.376922130584717}", "{\"n\": 18587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.26, \"learn_time_ms\": 10116.592, \"total_train_time_s\": 11.68050217628479}", "{\"n\": 18588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.98, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3562.26, \"learn_time_ms\": 10226.671, \"total_train_time_s\": 13.052651166915894}", "{\"n\": 18589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.61, \"learn_time_ms\": 10289.81, \"total_train_time_s\": 12.432673454284668}", "{\"n\": 18590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.59, \"learn_time_ms\": 10265.579, \"total_train_time_s\": 11.761281490325928}", "{\"n\": 18591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3570.59, \"learn_time_ms\": 10315.816, \"total_train_time_s\": 12.97577452659607}", "{\"n\": 18592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3566.62, \"learn_time_ms\": 10355.614, \"total_train_time_s\": 12.076673984527588}", "{\"n\": 18593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.39, \"learn_time_ms\": 10496.639, \"total_train_time_s\": 12.473972082138062}", "{\"n\": 18594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.39, \"learn_time_ms\": 10440.922, \"total_train_time_s\": 11.875099420547485}", "{\"n\": 18595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.39, \"learn_time_ms\": 10341.742, \"total_train_time_s\": 11.896809339523315}", "{\"n\": 18596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3556.97, \"learn_time_ms\": 10284.591, \"total_train_time_s\": 11.860779285430908}", "{\"n\": 18597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.36, \"learn_time_ms\": 10346.789, \"total_train_time_s\": 12.27530813217163}", "{\"n\": 18598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.36, \"learn_time_ms\": 10154.854, \"total_train_time_s\": 11.11219573020935}", "{\"n\": 18599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3558.36, \"learn_time_ms\": 10099.726, \"total_train_time_s\": 11.86714220046997}", "{\"n\": 18600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3563.29, \"learn_time_ms\": 10073.661, \"total_train_time_s\": 11.496991157531738}", "{\"n\": 18601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.17, \"learn_time_ms\": 10046.985, \"total_train_time_s\": 12.723304271697998}", "{\"n\": 18602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.17, \"learn_time_ms\": 10042.344, \"total_train_time_s\": 12.015597581863403}", "{\"n\": 18603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3568.17, \"learn_time_ms\": 9903.375, \"total_train_time_s\": 11.083292484283447}", "{\"n\": 18604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3565.82, \"learn_time_ms\": 10084.502, \"total_train_time_s\": 13.66794228553772}", "{\"n\": 18605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3567.72, \"learn_time_ms\": 10128.099, \"total_train_time_s\": 12.340169191360474}", "{\"n\": 18606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3567.72, \"learn_time_ms\": 10165.146, \"total_train_time_s\": 12.200054407119751}", "{\"n\": 18607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.5, \"learn_time_ms\": 10139.008, \"total_train_time_s\": 12.014202356338501}", "{\"n\": 18608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.59, \"learn_time_ms\": 10155.845, \"total_train_time_s\": 11.29765510559082}", "{\"n\": 18609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.59, \"learn_time_ms\": 10205.281, \"total_train_time_s\": 12.39414668083191}", "{\"n\": 18610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.59, \"learn_time_ms\": 10244.327, \"total_train_time_s\": 11.830407619476318}", "{\"n\": 18611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.89, \"learn_time_ms\": 10165.149, \"total_train_time_s\": 11.92116928100586}", "{\"n\": 18612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.31, \"learn_time_ms\": 10205.206, \"total_train_time_s\": 12.412746906280518}", "{\"n\": 18613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.31, \"learn_time_ms\": 10312.309, \"total_train_time_s\": 12.171420812606812}", "{\"n\": 18614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.55, \"learn_time_ms\": 10164.493, \"total_train_time_s\": 12.223563194274902}", "{\"n\": 18615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3584.75, \"learn_time_ms\": 10150.618, \"total_train_time_s\": 12.229895114898682}", "{\"n\": 18616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3574.68, \"learn_time_ms\": 10084.268, \"total_train_time_s\": 11.562570571899414}", "{\"n\": 18617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3569.94, \"learn_time_ms\": 10030.631, \"total_train_time_s\": 11.475401639938354}", "{\"n\": 18618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3565.74, \"learn_time_ms\": 10118.041, \"total_train_time_s\": 12.19416856765747}", "{\"n\": 18619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3577.02, \"learn_time_ms\": 10041.523, \"total_train_time_s\": 11.624361038208008}", "{\"n\": 18620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3578.08, \"learn_time_ms\": 9994.365, \"total_train_time_s\": 11.424370527267456}", "{\"n\": 18621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.48, \"learn_time_ms\": 9991.08, \"total_train_time_s\": 11.88046145439148}", "{\"n\": 18622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.48, \"learn_time_ms\": 9972.244, \"total_train_time_s\": 12.18087649345398}", "{\"n\": 18623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.17, \"learn_time_ms\": 9856.164, \"total_train_time_s\": 11.001542091369629}", "{\"n\": 18624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.96, \"learn_time_ms\": 9800.762, \"total_train_time_s\": 11.696102619171143}", "{\"n\": 18625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.14, \"learn_time_ms\": 9714.607, \"total_train_time_s\": 11.352957010269165}", "{\"n\": 18626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3593.14, \"learn_time_ms\": 9702.192, \"total_train_time_s\": 11.37464714050293}", "{\"n\": 18627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3589.22, \"learn_time_ms\": 9740.26, \"total_train_time_s\": 11.867932558059692}", "{\"n\": 18628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.28, \"learn_time_ms\": 9671.47, \"total_train_time_s\": 11.435326337814331}", "{\"n\": 18629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3585.28, \"learn_time_ms\": 9755.467, \"total_train_time_s\": 12.385515689849854}", "{\"n\": 18630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3592.42, \"learn_time_ms\": 9764.657, \"total_train_time_s\": 11.467292070388794}", "{\"n\": 18631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.31, \"learn_time_ms\": 9716.138, \"total_train_time_s\": 11.413259267807007}", "{\"n\": 18632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.31, \"learn_time_ms\": 9690.087, \"total_train_time_s\": 11.982208490371704}", "{\"n\": 18633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3600.31, \"learn_time_ms\": 9792.672, \"total_train_time_s\": 12.025634288787842}", "{\"n\": 18634, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 9753.453, \"total_train_time_s\": 11.251471757888794}", "{\"n\": 18635, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 9811.692, \"total_train_time_s\": 11.964049577713013}", "{\"n\": 18636, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.77, \"learn_time_ms\": 9863.618, \"total_train_time_s\": 11.925251722335815}", "{\"n\": 18637, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 9899.331, \"total_train_time_s\": 12.166022539138794}", "{\"n\": 18638, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 9911.668, \"total_train_time_s\": 11.622579574584961}", "{\"n\": 18639, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 9773.848, \"total_train_time_s\": 11.073103666305542}", "{\"n\": 18640, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 9940.44, \"total_train_time_s\": 13.135841846466064}", "{\"n\": 18641, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3595.84, \"learn_time_ms\": 9970.051, \"total_train_time_s\": 11.698049068450928}", "{\"n\": 18642, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.72, \"learn_time_ms\": 10026.335, \"total_train_time_s\": 12.524659633636475}", "{\"n\": 18643, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3604.72, \"learn_time_ms\": 10024.868, \"total_train_time_s\": 12.00849175453186}", "{\"n\": 18644, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3590.71, \"learn_time_ms\": 10081.781, \"total_train_time_s\": 11.811723470687866}", "{\"n\": 18645, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.21, \"learn_time_ms\": 10015.02, \"total_train_time_s\": 11.283867359161377}", "{\"n\": 18646, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3591.21, \"learn_time_ms\": 10020.446, \"total_train_time_s\": 11.957713603973389}", "{\"n\": 18647, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3586.08, \"learn_time_ms\": 10113.32, \"total_train_time_s\": 13.16866135597229}", "{\"n\": 18648, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.77, \"learn_time_ms\": 10146.648, \"total_train_time_s\": 11.91807508468628}", "{\"n\": 18649, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.77, \"learn_time_ms\": 10209.042, \"total_train_time_s\": 11.642638444900513}", "{\"n\": 18650, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3582.77, \"learn_time_ms\": 10026.986, \"total_train_time_s\": 11.309906005859375}", "{\"n\": 18651, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.82, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3572.88, \"learn_time_ms\": 10071.279, \"total_train_time_s\": 12.11937952041626}", "{\"n\": 18652, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3563.15, \"learn_time_ms\": 10018.65, \"total_train_time_s\": 11.95404601097107}", "{\"n\": 18653, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3563.15, \"learn_time_ms\": 10125.056, \"total_train_time_s\": 13.065407752990723}", "{\"n\": 18654, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3553.26, \"learn_time_ms\": 10152.305, \"total_train_time_s\": 12.142419576644897}", "{\"n\": 18655, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3553.22, \"learn_time_ms\": 10258.097, \"total_train_time_s\": 12.365819454193115}", "{\"n\": 18656, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3553.22, \"learn_time_ms\": 10337.381, \"total_train_time_s\": 12.824804306030273}", "{\"n\": 18657, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3557.21, \"learn_time_ms\": 10314.942, \"total_train_time_s\": 12.883984804153442}", "{\"n\": 18658, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.28, \"learn_time_ms\": 10319.973, \"total_train_time_s\": 11.954647779464722}", "{\"n\": 18659, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3555.28, \"learn_time_ms\": 10297.287, \"total_train_time_s\": 11.445165872573853}", "{\"n\": 18660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3549.74, \"learn_time_ms\": 10373.603, \"total_train_time_s\": 12.096112489700317}", "{\"n\": 18661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3541.81, \"learn_time_ms\": 10321.572, \"total_train_time_s\": 11.631689310073853}", "{\"n\": 18662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3535.17, \"learn_time_ms\": 10455.681, \"total_train_time_s\": 13.368966579437256}", "{\"n\": 18663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3535.17, \"learn_time_ms\": 10282.57, \"total_train_time_s\": 11.374785423278809}", "{\"n\": 18664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.88, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3526.55, \"learn_time_ms\": 10217.747, \"total_train_time_s\": 11.501017808914185}", "{\"n\": 18665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3524.03, \"learn_time_ms\": 10150.129, \"total_train_time_s\": 11.65141487121582}", "{\"n\": 18666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3519.64, \"learn_time_ms\": 9990.161, \"total_train_time_s\": 11.185694932937622}", "{\"n\": 18667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3519.64, \"learn_time_ms\": 9889.3, \"total_train_time_s\": 11.921833753585815}", "{\"n\": 18668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3520.55, \"learn_time_ms\": 9903.768, \"total_train_time_s\": 12.101990699768066}", "{\"n\": 18669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3527.91, \"learn_time_ms\": 9957.906, \"total_train_time_s\": 12.008673906326294}", "{\"n\": 18670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3527.91, \"learn_time_ms\": 9954.724, \"total_train_time_s\": 12.02454686164856}", "{\"n\": 18671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3536.05, \"learn_time_ms\": 9990.478, \"total_train_time_s\": 11.961279392242432}", "{\"n\": 18672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3535.14, \"learn_time_ms\": 9926.536, \"total_train_time_s\": 12.677882432937622}", "{\"n\": 18673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3526.8, \"learn_time_ms\": 10043.338, \"total_train_time_s\": 12.53835391998291}", "{\"n\": 18674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3530.54, \"learn_time_ms\": 10049.669, \"total_train_time_s\": 11.53186559677124}", "{\"n\": 18675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3530.54, \"learn_time_ms\": 10114.526, \"total_train_time_s\": 12.295982599258423}", "{\"n\": 18676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3531.96, \"learn_time_ms\": 10121.826, \"total_train_time_s\": 11.25615119934082}", "{\"n\": 18677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3545.12, \"learn_time_ms\": 10077.709, \"total_train_time_s\": 11.46256709098816}", "{\"n\": 18678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.75, \"learn_time_ms\": 10001.385, \"total_train_time_s\": 11.34474802017212}", "{\"n\": 18679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.94, \"learn_time_ms\": 10019.139, \"total_train_time_s\": 12.14622688293457}", "{\"n\": 18680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.94, \"learn_time_ms\": 10022.999, \"total_train_time_s\": 12.095669507980347}", "{\"n\": 18681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3557.14, \"learn_time_ms\": 9936.321, \"total_train_time_s\": 11.145459651947021}", "{\"n\": 18682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.46, \"learn_time_ms\": 9883.035, \"total_train_time_s\": 12.11878514289856}", "{\"n\": 18683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.46, \"learn_time_ms\": 9799.721, \"total_train_time_s\": 11.674797058105469}", "{\"n\": 18684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3556.66, \"learn_time_ms\": 9864.901, \"total_train_time_s\": 12.156222105026245}", "{\"n\": 18685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3556.87, \"learn_time_ms\": 9909.67, \"total_train_time_s\": 12.78018569946289}", "{\"n\": 18686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.22, \"learn_time_ms\": 9944.706, \"total_train_time_s\": 11.573608636856079}", "{\"n\": 18687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.22, \"learn_time_ms\": 10026.982, \"total_train_time_s\": 12.262637376785278}", "{\"n\": 18688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.27, \"learn_time_ms\": 10128.103, \"total_train_time_s\": 12.444350481033325}", "{\"n\": 18689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.86, \"learn_time_ms\": 10017.226, \"total_train_time_s\": 11.084979057312012}", "{\"n\": 18690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.86, \"learn_time_ms\": 9952.0, \"total_train_time_s\": 11.420944452285767}", "{\"n\": 18691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.36, \"learn_time_ms\": 10081.843, \"total_train_time_s\": 12.426860332489014}", "{\"n\": 18692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3541.42, \"learn_time_ms\": 10021.413, \"total_train_time_s\": 11.581673383712769}", "{\"n\": 18693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.17, \"learn_time_ms\": 10160.764, \"total_train_time_s\": 13.110631227493286}", "{\"n\": 18694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3538.05, \"learn_time_ms\": 10149.809, \"total_train_time_s\": 12.100775241851807}", "{\"n\": 18695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.4, \"learn_time_ms\": 9975.494, \"total_train_time_s\": 11.018253326416016}", "{\"n\": 18696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.4, \"learn_time_ms\": 10054.759, \"total_train_time_s\": 12.406189441680908}", "{\"n\": 18697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.83, \"learn_time_ms\": 9959.844, \"total_train_time_s\": 11.337221622467041}", "{\"n\": 18698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.58, \"learn_time_ms\": 9858.003, \"total_train_time_s\": 11.36060357093811}", "{\"n\": 18699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3502.73, \"learn_time_ms\": 9996.359, \"total_train_time_s\": 12.437415599822998}", "{\"n\": 18700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.32, \"learn_time_ms\": 10033.469, \"total_train_time_s\": 11.81734013557434}", "{\"n\": 18701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.92, \"learn_time_ms\": 9980.102, \"total_train_time_s\": 11.884968042373657}", "{\"n\": 18702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.08, \"learn_time_ms\": 9985.348, \"total_train_time_s\": 11.61189079284668}", "{\"n\": 18703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.08, \"learn_time_ms\": 9881.129, \"total_train_time_s\": 12.022169589996338}", "{\"n\": 18704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3521.25, \"learn_time_ms\": 9830.958, \"total_train_time_s\": 11.584681272506714}", "{\"n\": 18705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3521.25, \"learn_time_ms\": 9854.569, \"total_train_time_s\": 11.2623929977417}", "{\"n\": 18706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3517.87, \"learn_time_ms\": 9797.019, \"total_train_time_s\": 11.804043769836426}", "{\"n\": 18707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3517.87, \"learn_time_ms\": 9863.056, \"total_train_time_s\": 11.984154224395752}", "{\"n\": 18708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.86, \"learn_time_ms\": 9935.351, \"total_train_time_s\": 12.109455347061157}", "{\"n\": 18709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.86, \"learn_time_ms\": 9829.08, \"total_train_time_s\": 11.385313987731934}", "{\"n\": 18710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3516.0, \"learn_time_ms\": 9799.159, \"total_train_time_s\": 11.522897958755493}", "{\"n\": 18711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3519.17, \"learn_time_ms\": 9783.397, \"total_train_time_s\": 11.7401704788208}", "{\"n\": 18712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.84, \"learn_time_ms\": 9778.766, \"total_train_time_s\": 11.56006908416748}", "{\"n\": 18713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.23, \"learn_time_ms\": 9733.97, \"total_train_time_s\": 11.625328302383423}", "{\"n\": 18714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3529.94, \"learn_time_ms\": 9713.156, \"total_train_time_s\": 11.348715543746948}", "{\"n\": 18715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.69, \"learn_time_ms\": 9905.612, \"total_train_time_s\": 13.126006603240967}", "{\"n\": 18716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.69, \"learn_time_ms\": 9956.059, \"total_train_time_s\": 12.295572280883789}", "{\"n\": 18717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.46, \"learn_time_ms\": 9941.08, \"total_train_time_s\": 11.892991542816162}", "{\"n\": 18718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3519.81, \"learn_time_ms\": 9865.3, \"total_train_time_s\": 11.352780103683472}", "{\"n\": 18719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3519.56, \"learn_time_ms\": 9948.466, \"total_train_time_s\": 12.218272686004639}", "{\"n\": 18720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3516.28, \"learn_time_ms\": 10021.085, \"total_train_time_s\": 12.183236122131348}", "{\"n\": 18721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.05, \"learn_time_ms\": 9983.321, \"total_train_time_s\": 11.295978307723999}", "{\"n\": 18722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.5, \"learn_time_ms\": 10096.582, \"total_train_time_s\": 12.664559602737427}", "{\"n\": 18723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.29, \"learn_time_ms\": 10153.993, \"total_train_time_s\": 12.168835401535034}", "{\"n\": 18724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3516.91, \"learn_time_ms\": 10287.076, \"total_train_time_s\": 12.67809247970581}", "{\"n\": 18725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.72, \"learn_time_ms\": 10178.916, \"total_train_time_s\": 12.06155800819397}", "{\"n\": 18726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.04, \"learn_time_ms\": 10181.544, \"total_train_time_s\": 12.344364404678345}", "{\"n\": 18727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3522.89, \"learn_time_ms\": 10156.438, \"total_train_time_s\": 11.576702117919922}", "{\"n\": 18728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.92, \"learn_time_ms\": 10215.182, \"total_train_time_s\": 11.918864488601685}", "{\"n\": 18729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.92, \"learn_time_ms\": 10195.725, \"total_train_time_s\": 12.029776811599731}", "{\"n\": 18730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3539.31, \"learn_time_ms\": 10145.993, \"total_train_time_s\": 11.751552104949951}", "{\"n\": 18731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3538.15, \"learn_time_ms\": 10289.285, \"total_train_time_s\": 12.763068914413452}", "{\"n\": 18732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.57, \"learn_time_ms\": 10263.1, \"total_train_time_s\": 12.430197715759277}", "{\"n\": 18733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.57, \"learn_time_ms\": 10250.754, \"total_train_time_s\": 12.005618810653687}", "{\"n\": 18734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.59, \"learn_time_ms\": 10183.936, \"total_train_time_s\": 12.035671472549438}", "{\"n\": 18735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3538.38, \"learn_time_ms\": 10290.254, \"total_train_time_s\": 13.136851787567139}", "{\"n\": 18736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.95, \"learn_time_ms\": 10182.242, \"total_train_time_s\": 11.286818027496338}", "{\"n\": 18737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3550.22, \"learn_time_ms\": 10111.225, \"total_train_time_s\": 10.913762092590332}", "{\"n\": 18738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.44, \"learn_time_ms\": 10130.527, \"total_train_time_s\": 12.116738319396973}", "{\"n\": 18739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3556.48, \"learn_time_ms\": 10214.912, \"total_train_time_s\": 12.899216175079346}", "{\"n\": 18740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3556.48, \"learn_time_ms\": 10289.218, \"total_train_time_s\": 12.44957709312439}", "{\"n\": 18741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.52, \"learn_time_ms\": 10218.431, \"total_train_time_s\": 12.045456171035767}", "{\"n\": 18742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.52, \"learn_time_ms\": 10232.572, \"total_train_time_s\": 12.56261157989502}", "{\"n\": 18743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3570.07, \"learn_time_ms\": 10355.444, \"total_train_time_s\": 13.269981622695923}", "{\"n\": 18744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.11, \"learn_time_ms\": 10381.917, \"total_train_time_s\": 12.31241750717163}", "{\"n\": 18745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.42, \"learn_time_ms\": 10169.186, \"total_train_time_s\": 11.034014463424683}", "{\"n\": 18746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.42, \"learn_time_ms\": 10238.083, \"total_train_time_s\": 11.949065685272217}", "{\"n\": 18747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.72, \"learn_time_ms\": 10387.392, \"total_train_time_s\": 12.383670091629028}", "{\"n\": 18748, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.63, \"learn_time_ms\": 10296.111, \"total_train_time_s\": 11.205307960510254}", "{\"n\": 18749, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.63, \"learn_time_ms\": 10162.161, \"total_train_time_s\": 11.554558992385864}", "{\"n\": 18750, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.63, \"learn_time_ms\": 10060.444, \"total_train_time_s\": 11.47654128074646}", "{\"n\": 18751, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.16, \"learn_time_ms\": 9968.994, \"total_train_time_s\": 11.14827036857605}", "{\"n\": 18752, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.05, \"learn_time_ms\": 9852.943, \"total_train_time_s\": 11.453968524932861}", "{\"n\": 18753, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.05, \"learn_time_ms\": 9780.218, \"total_train_time_s\": 12.548278093338013}", "{\"n\": 18754, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.47, \"learn_time_ms\": 9702.809, \"total_train_time_s\": 11.533576726913452}", "{\"n\": 18755, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.47, \"learn_time_ms\": 9710.368, \"total_train_time_s\": 11.085110664367676}", "{\"n\": 18756, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.73, \"learn_time_ms\": 9689.09, \"total_train_time_s\": 11.78208613395691}", "{\"n\": 18757, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.73, \"learn_time_ms\": 9595.523, \"total_train_time_s\": 11.421802282333374}", "{\"n\": 18758, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.69, \"learn_time_ms\": 9661.208, \"total_train_time_s\": 11.85476541519165}", "{\"n\": 18759, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.28, \"learn_time_ms\": 9688.711, \"total_train_time_s\": 11.818771362304688}", "{\"n\": 18760, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.28, \"learn_time_ms\": 9698.431, \"total_train_time_s\": 11.532929420471191}", "{\"n\": 18761, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3562.88, \"learn_time_ms\": 9772.109, \"total_train_time_s\": 11.846680879592896}", "{\"n\": 18762, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3562.88, \"learn_time_ms\": 9813.311, \"total_train_time_s\": 11.81850814819336}", "{\"n\": 18763, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3564.03, \"learn_time_ms\": 9793.423, \"total_train_time_s\": 12.322091579437256}", "{\"n\": 18764, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.78, \"learn_time_ms\": 9972.94, \"total_train_time_s\": 13.313005208969116}", "{\"n\": 18765, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.15, \"learn_time_ms\": 9941.098, \"total_train_time_s\": 10.770533084869385}", "{\"n\": 18766, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.15, \"learn_time_ms\": 9899.118, \"total_train_time_s\": 11.31130838394165}", "{\"n\": 18767, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.91, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3571.77, \"learn_time_ms\": 9954.001, \"total_train_time_s\": 11.961996793746948}", "{\"n\": 18768, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.18, \"learn_time_ms\": 9999.89, \"total_train_time_s\": 12.332205772399902}", "{\"n\": 18769, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.18, \"learn_time_ms\": 9964.875, \"total_train_time_s\": 11.42059874534607}", "{\"n\": 18770, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3551.91, \"learn_time_ms\": 9912.743, \"total_train_time_s\": 11.065272569656372}", "{\"n\": 18771, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3551.41, \"learn_time_ms\": 9903.193, \"total_train_time_s\": 11.791990756988525}", "{\"n\": 18772, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3550.33, \"learn_time_ms\": 9892.216, \"total_train_time_s\": 11.687967300415039}", "{\"n\": 18773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.63, \"learn_time_ms\": 9976.032, \"total_train_time_s\": 13.178477048873901}", "{\"n\": 18774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3547.49, \"learn_time_ms\": 9972.249, \"total_train_time_s\": 13.246626377105713}", "{\"n\": 18775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.84, \"learn_time_ms\": 10104.824, \"total_train_time_s\": 12.09331464767456}", "{\"n\": 18776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.22, \"learn_time_ms\": 10216.557, \"total_train_time_s\": 12.433061122894287}", "{\"n\": 18777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.75, \"learn_time_ms\": 10141.302, \"total_train_time_s\": 11.232190132141113}", "{\"n\": 18778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.75, \"learn_time_ms\": 9992.404, \"total_train_time_s\": 10.841124773025513}", "{\"n\": 18779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3541.1, \"learn_time_ms\": 10077.699, \"total_train_time_s\": 12.307685136795044}", "{\"n\": 18780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.72, \"learn_time_ms\": 10155.668, \"total_train_time_s\": 11.81741738319397}", "{\"n\": 18781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.72, \"learn_time_ms\": 10172.326, \"total_train_time_s\": 11.932689905166626}", "{\"n\": 18782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.72, \"learn_time_ms\": 10129.807, \"total_train_time_s\": 11.248335838317871}", "{\"n\": 18783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.65, \"learn_time_ms\": 9984.682, \"total_train_time_s\": 11.699309825897217}", "{\"n\": 18784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.06, \"learn_time_ms\": 9850.746, \"total_train_time_s\": 11.955258131027222}", "{\"n\": 18785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.06, \"learn_time_ms\": 9775.281, \"total_train_time_s\": 11.340180158615112}", "{\"n\": 18786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.06, \"learn_time_ms\": 9670.475, \"total_train_time_s\": 11.403080701828003}", "{\"n\": 18787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3550.53, \"learn_time_ms\": 9836.917, \"total_train_time_s\": 12.910030126571655}", "{\"n\": 18788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.24, \"learn_time_ms\": 9904.461, \"total_train_time_s\": 11.566153764724731}", "{\"n\": 18789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.24, \"learn_time_ms\": 9893.012, \"total_train_time_s\": 12.206130981445312}", "{\"n\": 18790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3562.02, \"learn_time_ms\": 9931.667, \"total_train_time_s\": 12.248875141143799}", "{\"n\": 18791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3555.36, \"learn_time_ms\": 10028.095, \"total_train_time_s\": 12.92742133140564}", "{\"n\": 18792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.06, \"learn_time_ms\": 10163.374, \"total_train_time_s\": 12.616184949874878}", "{\"n\": 18793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.29, \"learn_time_ms\": 10173.903, \"total_train_time_s\": 11.85858941078186}", "{\"n\": 18794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3567.08, \"learn_time_ms\": 10125.633, \"total_train_time_s\": 11.483886241912842}", "{\"n\": 18795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3564.61, \"learn_time_ms\": 10154.314, \"total_train_time_s\": 11.596034526824951}", "{\"n\": 18796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.26, \"learn_time_ms\": 10152.565, \"total_train_time_s\": 11.379868507385254}", "{\"n\": 18797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3563.26, \"learn_time_ms\": 10019.185, \"total_train_time_s\": 11.569643497467041}", "{\"n\": 18798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3543.99, \"learn_time_ms\": 10078.671, \"total_train_time_s\": 12.094598293304443}", "{\"n\": 18799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 9963.298, \"total_train_time_s\": 11.065462827682495}", "{\"n\": 18800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 9933.469, \"total_train_time_s\": 11.902530670166016}", "{\"n\": 18801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3538.07, \"learn_time_ms\": 9972.181, \"total_train_time_s\": 13.307566165924072}", "{\"n\": 18802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.71, \"learn_time_ms\": 9982.034, \"total_train_time_s\": 12.721824645996094}", "{\"n\": 18803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3523.39, \"learn_time_ms\": 10074.175, \"total_train_time_s\": 12.78126859664917}", "{\"n\": 18804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3523.39, \"learn_time_ms\": 10045.801, \"total_train_time_s\": 11.193068504333496}", "{\"n\": 18805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.42, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3529.84, \"learn_time_ms\": 10045.406, \"total_train_time_s\": 11.62161135673523}", "{\"n\": 18806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.89, \"learn_time_ms\": 10173.604, \"total_train_time_s\": 12.650304555892944}", "{\"n\": 18807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.43, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.37, \"learn_time_ms\": 10208.514, \"total_train_time_s\": 11.969732761383057}", "{\"n\": 18808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.43, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.37, \"learn_time_ms\": 10152.167, \"total_train_time_s\": 11.558269262313843}", "{\"n\": 18809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.69, \"learn_time_ms\": 10213.906, \"total_train_time_s\": 11.648885726928711}", "{\"n\": 18810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.18, \"learn_time_ms\": 10242.344, \"total_train_time_s\": 12.150208950042725}", "{\"n\": 18811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 4.49, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.18, \"learn_time_ms\": 10131.181, \"total_train_time_s\": 12.182947397232056}", "{\"n\": 18812, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3549.86, \"learn_time_ms\": 9975.344, \"total_train_time_s\": 11.188388109207153}", "{\"n\": 18813, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3555.29, \"learn_time_ms\": 9989.844, \"total_train_time_s\": 12.91720700263977}", "{\"n\": 18814, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.81, \"learn_time_ms\": 10013.171, \"total_train_time_s\": 11.37716293334961}", "{\"n\": 18815, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.81, \"learn_time_ms\": 9973.116, \"total_train_time_s\": 11.233618021011353}", "{\"n\": 18816, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3543.31, \"learn_time_ms\": 9915.301, \"total_train_time_s\": 12.099576950073242}", "{\"n\": 18817, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.82, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.47, \"learn_time_ms\": 9849.754, \"total_train_time_s\": 11.227627277374268}", "{\"n\": 18818, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.82, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.47, \"learn_time_ms\": 9929.448, \"total_train_time_s\": 12.325516939163208}", "{\"n\": 18819, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 9977.319, \"total_train_time_s\": 12.126293182373047}", "{\"n\": 18820, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.86, \"learn_time_ms\": 9950.37, \"total_train_time_s\": 11.911479234695435}", "{\"n\": 18821, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.86, \"learn_time_ms\": 10035.979, \"total_train_time_s\": 13.04476523399353}", "{\"n\": 18822, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.58, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3532.97, \"learn_time_ms\": 10175.901, \"total_train_time_s\": 12.53871750831604}", "{\"n\": 18823, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.65, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.32, \"learn_time_ms\": 10121.0, \"total_train_time_s\": 12.360882997512817}", "{\"n\": 18824, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.65, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.32, \"learn_time_ms\": 10053.705, \"total_train_time_s\": 10.764249563217163}", "{\"n\": 18825, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.58, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3510.29, \"learn_time_ms\": 10143.272, \"total_train_time_s\": 12.113337755203247}", "{\"n\": 18826, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.44, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3516.01, \"learn_time_ms\": 10219.9, \"total_train_time_s\": 12.83424687385559}", "{\"n\": 18827, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.29, \"learn_time_ms\": 10318.045, \"total_train_time_s\": 12.254404067993164}", "{\"n\": 18828, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.34, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.29, \"learn_time_ms\": 10247.024, \"total_train_time_s\": 11.608430624008179}", "{\"n\": 18829, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.5, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3515.43, \"learn_time_ms\": 10237.908, \"total_train_time_s\": 12.029546737670898}", "{\"n\": 18830, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3513.05, \"learn_time_ms\": 10336.028, \"total_train_time_s\": 12.948372602462769}", "{\"n\": 18831, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3513.05, \"learn_time_ms\": 10181.308, \"total_train_time_s\": 11.526047229766846}", "{\"n\": 18832, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.47, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3508.85, \"learn_time_ms\": 10113.684, \"total_train_time_s\": 11.859947443008423}", "{\"n\": 18833, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.68, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3507.81, \"learn_time_ms\": 10115.564, \"total_train_time_s\": 12.359038352966309}", "{\"n\": 18834, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3508.7, \"learn_time_ms\": 10288.325, \"total_train_time_s\": 12.481729984283447}", "{\"n\": 18835, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3508.7, \"learn_time_ms\": 10198.903, \"total_train_time_s\": 11.27189040184021}", "{\"n\": 18836, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.64, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3512.33, \"learn_time_ms\": 10079.254, \"total_train_time_s\": 11.680184364318848}", "{\"n\": 18837, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.57, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3516.43, \"learn_time_ms\": 10037.096, \"total_train_time_s\": 11.816008567810059}", "{\"n\": 18838, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3513.4, \"learn_time_ms\": 10125.097, \"total_train_time_s\": 12.474929332733154}", "{\"n\": 18839, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3513.4, \"learn_time_ms\": 10121.929, \"total_train_time_s\": 11.959936618804932}", "{\"n\": 18840, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.41, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3519.69, \"learn_time_ms\": 9979.117, \"total_train_time_s\": 11.469775676727295}", "{\"n\": 18841, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3529.6, \"learn_time_ms\": 10105.008, \"total_train_time_s\": 12.77704381942749}", "{\"n\": 18842, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.26, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3531.6, \"learn_time_ms\": 10180.444, \"total_train_time_s\": 12.633054971694946}", "{\"n\": 18843, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.19, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.53, \"learn_time_ms\": 10102.758, \"total_train_time_s\": 11.550995826721191}", "{\"n\": 18844, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.16, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.75, \"learn_time_ms\": 10025.783, \"total_train_time_s\": 11.698416948318481}", "{\"n\": 18845, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.85, \"learn_time_ms\": 10071.491, \"total_train_time_s\": 11.68239140510559}", "{\"n\": 18846, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3548.85, \"learn_time_ms\": 10168.238, \"total_train_time_s\": 12.638980388641357}", "{\"n\": 18847, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.99, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3549.36, \"learn_time_ms\": 10213.821, \"total_train_time_s\": 12.30327844619751}", "{\"n\": 18848, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3542.53, \"learn_time_ms\": 10140.408, \"total_train_time_s\": 11.743301391601562}", "{\"n\": 18849, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.92, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.32, \"learn_time_ms\": 10152.046, \"total_train_time_s\": 12.162097215652466}", "{\"n\": 18850, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3540.38, \"learn_time_ms\": 10081.992, \"total_train_time_s\": 10.772244215011597}", "{\"n\": 18851, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3535.97, \"learn_time_ms\": 10042.54, \"total_train_time_s\": 12.370948076248169}", "{\"n\": 18852, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3532.34, \"learn_time_ms\": 9920.592, \"total_train_time_s\": 11.469381093978882}", "{\"n\": 18853, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3525.45, \"learn_time_ms\": 10097.856, \"total_train_time_s\": 13.329044580459595}", "{\"n\": 18854, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3525.45, \"learn_time_ms\": 10181.295, \"total_train_time_s\": 12.53580617904663}", "{\"n\": 18855, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.18, \"learn_time_ms\": 10163.113, \"total_train_time_s\": 11.533206462860107}", "{\"n\": 18856, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3527.03, \"learn_time_ms\": 10019.74, \"total_train_time_s\": 11.160511255264282}", "{\"n\": 18857, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3536.4, \"learn_time_ms\": 10004.319, \"total_train_time_s\": 12.113400936126709}", "{\"n\": 18858, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3529.72, \"learn_time_ms\": 10087.418, \"total_train_time_s\": 12.57355284690857}", "{\"n\": 18859, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3527.69, \"learn_time_ms\": 10053.598, \"total_train_time_s\": 11.799731969833374}", "{\"n\": 18860, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3532.12, \"learn_time_ms\": 10121.296, \"total_train_time_s\": 11.42948865890503}", "{\"n\": 18861, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3536.36, \"learn_time_ms\": 10068.977, \"total_train_time_s\": 11.820312023162842}", "{\"n\": 18862, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3545.17, \"learn_time_ms\": 10131.371, \"total_train_time_s\": 12.066693782806396}", "{\"n\": 18863, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3545.79, \"learn_time_ms\": 9970.933, \"total_train_time_s\": 11.754778146743774}", "{\"n\": 18864, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3543.93, \"learn_time_ms\": 9932.003, \"total_train_time_s\": 12.174495935440063}", "{\"n\": 18865, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3543.93, \"learn_time_ms\": 10032.913, \"total_train_time_s\": 12.496000528335571}", "{\"n\": 18866, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3546.77, \"learn_time_ms\": 10162.296, \"total_train_time_s\": 12.4719557762146}", "{\"n\": 18867, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3535.46, \"learn_time_ms\": 10182.73, \"total_train_time_s\": 12.33575439453125}", "{\"n\": 18868, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.54, \"learn_time_ms\": 10226.337, \"total_train_time_s\": 13.0566086769104}", "{\"n\": 18869, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.54, \"learn_time_ms\": 10344.487, \"total_train_time_s\": 12.993090629577637}", "{\"n\": 18870, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.3, \"learn_time_ms\": 10353.389, \"total_train_time_s\": 11.582311153411865}", "{\"n\": 18871, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.49, \"learn_time_ms\": 10379.898, \"total_train_time_s\": 12.104872465133667}", "{\"n\": 18872, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3544.49, \"learn_time_ms\": 10373.295, \"total_train_time_s\": 12.004482746124268}", "{\"n\": 18873, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3545.36, \"learn_time_ms\": 10403.848, \"total_train_time_s\": 12.047781705856323}", "{\"n\": 18874, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3536.66, \"learn_time_ms\": 10277.985, \"total_train_time_s\": 10.848716735839844}", "{\"n\": 18875, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3531.63, \"learn_time_ms\": 10193.591, \"total_train_time_s\": 11.695400476455688}", "{\"n\": 18876, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.68, \"learn_time_ms\": 10059.1, \"total_train_time_s\": 11.103490591049194}", "{\"n\": 18877, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3510.32, \"learn_time_ms\": 10076.984, \"total_train_time_s\": 12.49130392074585}", "{\"n\": 18878, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3508.34, \"learn_time_ms\": 10051.067, \"total_train_time_s\": 12.72657823562622}", "{\"n\": 18879, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3510.88, \"learn_time_ms\": 10011.806, \"total_train_time_s\": 12.565435647964478}", "{\"n\": 18880, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3508.53, \"learn_time_ms\": 10081.936, \"total_train_time_s\": 12.23211407661438}", "{\"n\": 18881, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3512.31, \"learn_time_ms\": 10175.141, \"total_train_time_s\": 13.07340931892395}", "{\"n\": 18882, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3523.96, \"learn_time_ms\": 10217.615, \"total_train_time_s\": 12.442800045013428}", "{\"n\": 18883, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3518.7, \"learn_time_ms\": 10226.763, \"total_train_time_s\": 12.138272285461426}", "{\"n\": 18884, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3525.03, \"learn_time_ms\": 10235.778, \"total_train_time_s\": 11.001811742782593}", "{\"n\": 18885, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3537.36, \"learn_time_ms\": 10182.387, \"total_train_time_s\": 11.12616777420044}", "{\"n\": 18886, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3541.79, \"learn_time_ms\": 10305.173, \"total_train_time_s\": 12.363786935806274}", "{\"n\": 18887, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.86, \"learn_time_ms\": 10231.041, \"total_train_time_s\": 11.786356210708618}", "{\"n\": 18888, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3538.54, \"learn_time_ms\": 10196.692, \"total_train_time_s\": 12.415836572647095}", "{\"n\": 18889, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3534.49, \"learn_time_ms\": 10275.854, \"total_train_time_s\": 13.358835935592651}", "{\"n\": 18890, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3530.99, \"learn_time_ms\": 10406.904, \"total_train_time_s\": 13.517756462097168}", "{\"n\": 18891, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.38, \"learn_time_ms\": 10385.084, \"total_train_time_s\": 12.846160888671875}", "{\"n\": 18892, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3537.05, \"learn_time_ms\": 10272.66, \"total_train_time_s\": 11.270605564117432}", "{\"n\": 18893, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3537.05, \"learn_time_ms\": 10314.971, \"total_train_time_s\": 12.567228317260742}", "{\"n\": 18894, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.34, \"learn_time_ms\": 10448.414, \"total_train_time_s\": 12.330727100372314}", "{\"n\": 18895, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.52, \"learn_time_ms\": 10567.134, \"total_train_time_s\": 12.391195297241211}", "{\"n\": 18896, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3534.4, \"learn_time_ms\": 10520.785, \"total_train_time_s\": 11.939498662948608}", "{\"n\": 18897, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.73, \"learn_time_ms\": 10525.427, \"total_train_time_s\": 11.837509870529175}", "{\"n\": 18898, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3536.44, \"learn_time_ms\": 10404.026, \"total_train_time_s\": 11.245768070220947}", "{\"n\": 18899, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.51, \"learn_time_ms\": 10215.826, \"total_train_time_s\": 11.473991632461548}", "{\"n\": 18900, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.51, \"learn_time_ms\": 10027.276, \"total_train_time_s\": 11.663852214813232}", "{\"n\": 18901, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.57, \"learn_time_ms\": 9970.075, \"total_train_time_s\": 12.236472606658936}", "{\"n\": 18902, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.07, \"learn_time_ms\": 9953.191, \"total_train_time_s\": 11.10518479347229}", "{\"n\": 18903, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3537.15, \"learn_time_ms\": 9881.364, \"total_train_time_s\": 11.881027221679688}", "{\"n\": 18904, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3537.15, \"learn_time_ms\": 9813.625, \"total_train_time_s\": 11.60151982307434}", "{\"n\": 18905, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.76, \"learn_time_ms\": 9751.39, \"total_train_time_s\": 11.694224119186401}", "{\"n\": 18906, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.74, \"learn_time_ms\": 9782.468, \"total_train_time_s\": 12.243666172027588}", "{\"n\": 18907, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.74, \"learn_time_ms\": 9821.85, \"total_train_time_s\": 12.203788757324219}", "{\"n\": 18908, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.6, \"learn_time_ms\": 9939.636, \"total_train_time_s\": 12.393569469451904}", "{\"n\": 18909, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.79, \"learn_time_ms\": 10023.106, \"total_train_time_s\": 12.324238777160645}", "{\"n\": 18910, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.4, \"learn_time_ms\": 10071.21, \"total_train_time_s\": 12.150080680847168}", "{\"n\": 18911, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.4, \"learn_time_ms\": 10059.595, \"total_train_time_s\": 12.11426830291748}", "{\"n\": 18912, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.21, \"learn_time_ms\": 10102.238, \"total_train_time_s\": 11.564845085144043}", "{\"n\": 18913, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.21, \"learn_time_ms\": 10157.645, \"total_train_time_s\": 12.434730768203735}", "{\"n\": 18914, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.61, \"learn_time_ms\": 10253.433, \"total_train_time_s\": 12.57761549949646}", "{\"n\": 18915, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3583.61, \"learn_time_ms\": 10163.486, \"total_train_time_s\": 10.802781343460083}", "{\"n\": 18916, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.16, \"learn_time_ms\": 10174.673, \"total_train_time_s\": 12.421698093414307}", "{\"n\": 18917, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.3, \"learn_time_ms\": 10145.457, \"total_train_time_s\": 11.907925605773926}", "{\"n\": 18918, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3586.2, \"learn_time_ms\": 10281.823, \"total_train_time_s\": 13.733386754989624}", "{\"n\": 18919, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.2, \"learn_time_ms\": 10300.749, \"total_train_time_s\": 12.505350828170776}", "{\"n\": 18920, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.2, \"learn_time_ms\": 10302.544, \"total_train_time_s\": 12.184827327728271}", "{\"n\": 18921, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 10226.474, \"total_train_time_s\": 11.370338916778564}", "{\"n\": 18922, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 10197.808, \"total_train_time_s\": 11.255425453186035}", "{\"n\": 18923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.23, \"learn_time_ms\": 10176.254, \"total_train_time_s\": 12.216361045837402}", "{\"n\": 18924, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.09, \"learn_time_ms\": 10170.54, \"total_train_time_s\": 12.537083387374878}", "{\"n\": 18925, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.58, \"learn_time_ms\": 10379.164, \"total_train_time_s\": 12.872179508209229}", "{\"n\": 18926, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.58, \"learn_time_ms\": 10304.678, \"total_train_time_s\": 11.547458410263062}", "{\"n\": 18927, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.6, \"learn_time_ms\": 10265.625, \"total_train_time_s\": 11.532102346420288}", "{\"n\": 18928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.66, \"learn_time_ms\": 10203.235, \"total_train_time_s\": 13.139031887054443}", "{\"n\": 18929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.07, \"learn_time_ms\": 10152.718, \"total_train_time_s\": 11.984379053115845}", "{\"n\": 18930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3612.07, \"learn_time_ms\": 10130.407, \"total_train_time_s\": 11.938283205032349}", "{\"n\": 18931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.87, \"learn_time_ms\": 10209.844, \"total_train_time_s\": 12.149645328521729}", "{\"n\": 18932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.87, \"learn_time_ms\": 10190.005, \"total_train_time_s\": 11.048345565795898}", "{\"n\": 18933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.7, \"learn_time_ms\": 10123.606, \"total_train_time_s\": 11.540092945098877}", "{\"n\": 18934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.94, \"learn_time_ms\": 10120.53, \"total_train_time_s\": 12.463098764419556}", "{\"n\": 18935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.35, \"learn_time_ms\": 10026.992, \"total_train_time_s\": 11.937785863876343}", "{\"n\": 18936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.35, \"learn_time_ms\": 10044.57, \"total_train_time_s\": 11.764117240905762}", "{\"n\": 18937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3593.42, \"learn_time_ms\": 10074.159, \"total_train_time_s\": 11.788402557373047}", "{\"n\": 18938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.44, \"learn_time_ms\": 9998.46, \"total_train_time_s\": 12.356796503067017}", "{\"n\": 18939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.44, \"learn_time_ms\": 9978.234, \"total_train_time_s\": 11.787771940231323}", "{\"n\": 18940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.01, \"learn_time_ms\": 9919.911, \"total_train_time_s\": 11.340230464935303}", "{\"n\": 18941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.25, \"learn_time_ms\": 9991.816, \"total_train_time_s\": 12.882463693618774}", "{\"n\": 18942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.06, \"learn_time_ms\": 10089.419, \"total_train_time_s\": 12.053531885147095}", "{\"n\": 18943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.06, \"learn_time_ms\": 10142.383, \"total_train_time_s\": 12.044925451278687}", "{\"n\": 18944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3609.33, \"learn_time_ms\": 10154.198, \"total_train_time_s\": 12.624438047409058}", "{\"n\": 18945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.28, \"learn_time_ms\": 10094.933, \"total_train_time_s\": 11.358958005905151}", "{\"n\": 18946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.28, \"learn_time_ms\": 10117.578, \"total_train_time_s\": 12.012349128723145}", "{\"n\": 18947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.48, \"learn_time_ms\": 10117.691, \"total_train_time_s\": 11.837868690490723}", "{\"n\": 18948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.78, \"learn_time_ms\": 10037.694, \"total_train_time_s\": 11.593185901641846}", "{\"n\": 18949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.51, \"learn_time_ms\": 10074.496, \"total_train_time_s\": 12.131626844406128}", "{\"n\": 18950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.46, \"learn_time_ms\": 10088.888, \"total_train_time_s\": 11.518733501434326}", "{\"n\": 18951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.88, \"learn_time_ms\": 10026.102, \"total_train_time_s\": 12.295843124389648}", "{\"n\": 18952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.88, \"learn_time_ms\": 10076.874, \"total_train_time_s\": 12.554248332977295}", "{\"n\": 18953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.82, \"learn_time_ms\": 10063.246, \"total_train_time_s\": 11.924723625183105}", "{\"n\": 18954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.6, \"learn_time_ms\": 9996.15, \"total_train_time_s\": 11.94969630241394}", "{\"n\": 18955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.86, \"learn_time_ms\": 10110.023, \"total_train_time_s\": 12.492776155471802}", "{\"n\": 18956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.86, \"learn_time_ms\": 10060.601, \"total_train_time_s\": 11.4485502243042}", "{\"n\": 18957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.63, \"learn_time_ms\": 10028.005, \"total_train_time_s\": 11.479466438293457}", "{\"n\": 18958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.7, \"learn_time_ms\": 10075.311, \"total_train_time_s\": 12.068711519241333}", "{\"n\": 18959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.7, \"learn_time_ms\": 10062.666, \"total_train_time_s\": 12.05936598777771}", "{\"n\": 18960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.52, \"learn_time_ms\": 10069.891, \"total_train_time_s\": 11.588186740875244}", "{\"n\": 18961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.28, \"learn_time_ms\": 10054.722, \"total_train_time_s\": 12.12592363357544}", "{\"n\": 18962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.17, \"learn_time_ms\": 9993.41, \"total_train_time_s\": 11.949684858322144}", "{\"n\": 18963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.17, \"learn_time_ms\": 9952.632, \"total_train_time_s\": 11.560089826583862}", "{\"n\": 18964, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.15, \"learn_time_ms\": 9885.41, \"total_train_time_s\": 11.278883695602417}", "{\"n\": 18965, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.59, \"learn_time_ms\": 9747.898, \"total_train_time_s\": 11.175554990768433}", "{\"n\": 18966, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.14, \"learn_time_ms\": 9938.498, \"total_train_time_s\": 13.403634786605835}", "{\"n\": 18967, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.14, \"learn_time_ms\": 10057.98, \"total_train_time_s\": 12.69318699836731}", "{\"n\": 18968, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3580.14, \"learn_time_ms\": 9992.599, \"total_train_time_s\": 11.387522220611572}", "{\"n\": 18969, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.54, \"learn_time_ms\": 9980.741, \"total_train_time_s\": 11.889316320419312}", "{\"n\": 18970, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.85, \"learn_time_ms\": 9967.533, \"total_train_time_s\": 11.43004560470581}", "{\"n\": 18971, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3582.92, \"learn_time_ms\": 10003.149, \"total_train_time_s\": 12.46054720878601}", "{\"n\": 18972, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.42, \"learn_time_ms\": 10034.037, \"total_train_time_s\": 12.241734266281128}", "{\"n\": 18973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.34, \"learn_time_ms\": 10098.526, \"total_train_time_s\": 12.223002433776855}", "{\"n\": 18974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.6, \"learn_time_ms\": 10125.707, \"total_train_time_s\": 11.54835295677185}", "{\"n\": 18975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.19, \"learn_time_ms\": 10172.34, \"total_train_time_s\": 11.565643548965454}", "{\"n\": 18976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.19, \"learn_time_ms\": 10037.163, \"total_train_time_s\": 12.018067359924316}", "{\"n\": 18977, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.16, \"learn_time_ms\": 9892.532, \"total_train_time_s\": 11.246737480163574}", "{\"n\": 18978, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.45, \"learn_time_ms\": 10015.984, \"total_train_time_s\": 12.642361402511597}", "{\"n\": 18979, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.58, \"learn_time_ms\": 10018.42, \"total_train_time_s\": 11.983238220214844}", "{\"n\": 18980, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.58, \"learn_time_ms\": 10090.572, \"total_train_time_s\": 12.176100015640259}", "{\"n\": 18981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.58, \"learn_time_ms\": 10036.45, \"total_train_time_s\": 11.898298978805542}", "{\"n\": 18982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.69, \"learn_time_ms\": 9908.357, \"total_train_time_s\": 10.984127283096313}", "{\"n\": 18983, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.69, \"learn_time_ms\": 9894.118, \"total_train_time_s\": 12.01156497001648}", "{\"n\": 18984, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.69, \"learn_time_ms\": 9897.509, \"total_train_time_s\": 11.586952924728394}", "{\"n\": 18985, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3623.86, \"learn_time_ms\": 9914.146, \"total_train_time_s\": 11.758100271224976}", "{\"n\": 18986, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.89, \"learn_time_ms\": 9864.533, \"total_train_time_s\": 11.533388376235962}", "{\"n\": 18987, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.89, \"learn_time_ms\": 9919.062, \"total_train_time_s\": 11.77655553817749}", "{\"n\": 18988, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3626.89, \"learn_time_ms\": 9898.765, \"total_train_time_s\": 12.443697929382324}", "{\"n\": 18989, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.6, \"learn_time_ms\": 9870.932, \"total_train_time_s\": 11.668202877044678}", "{\"n\": 18990, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.6, \"learn_time_ms\": 9930.318, \"total_train_time_s\": 12.74423623085022}", "{\"n\": 18991, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.6, \"learn_time_ms\": 9978.733, \"total_train_time_s\": 12.39543628692627}", "{\"n\": 18992, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3641.17, \"learn_time_ms\": 10047.344, \"total_train_time_s\": 11.639595031738281}", "{\"n\": 18993, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.58, \"learn_time_ms\": 10118.584, \"total_train_time_s\": 12.755473852157593}", "{\"n\": 18994, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.58, \"learn_time_ms\": 10186.021, \"total_train_time_s\": 12.228572845458984}", "{\"n\": 18995, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.58, \"learn_time_ms\": 10214.8, \"total_train_time_s\": 12.04017949104309}", "{\"n\": 18996, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3635.0, \"learn_time_ms\": 10341.803, \"total_train_time_s\": 12.844013452529907}", "{\"n\": 18997, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.06, \"learn_time_ms\": 10350.114, \"total_train_time_s\": 11.90507459640503}", "{\"n\": 18998, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.06, \"learn_time_ms\": 10353.728, \"total_train_time_s\": 12.501347780227661}", "{\"n\": 18999, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3637.06, \"learn_time_ms\": 10434.966, \"total_train_time_s\": 12.461179256439209}", "{\"n\": 19000, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3642.49, \"learn_time_ms\": 10222.276, \"total_train_time_s\": 10.591187715530396}", "{\"n\": 19001, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.47, \"learn_time_ms\": 10208.551, \"total_train_time_s\": 12.28075647354126}", "{\"n\": 19002, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.47, \"learn_time_ms\": 10180.867, \"total_train_time_s\": 11.338960886001587}", "{\"n\": 19003, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.29, \"learn_time_ms\": 10036.09, \"total_train_time_s\": 11.289674758911133}", "{\"n\": 19004, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.31, \"learn_time_ms\": 10007.55, \"total_train_time_s\": 11.97335433959961}", "{\"n\": 19005, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.26, \"learn_time_ms\": 9967.379, \"total_train_time_s\": 11.652242183685303}", "{\"n\": 19006, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.26, \"learn_time_ms\": 9957.417, \"total_train_time_s\": 12.650254964828491}", "{\"n\": 19007, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.35, \"learn_time_ms\": 9985.643, \"total_train_time_s\": 12.20819640159607}", "{\"n\": 19008, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.35, \"learn_time_ms\": 9973.859, \"total_train_time_s\": 12.333367824554443}", "{\"n\": 19009, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.4, \"learn_time_ms\": 10040.7, \"total_train_time_s\": 13.163604497909546}", "{\"n\": 19010, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.63, \"learn_time_ms\": 10187.342, \"total_train_time_s\": 12.083057880401611}", "{\"n\": 19011, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.6, \"learn_time_ms\": 10296.373, \"total_train_time_s\": 13.351229190826416}", "{\"n\": 19012, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.6, \"learn_time_ms\": 10444.953, \"total_train_time_s\": 12.834354400634766}", "{\"n\": 19013, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.5, \"learn_time_ms\": 10573.98, \"total_train_time_s\": 12.605086088180542}", "{\"n\": 19014, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.77, \"learn_time_ms\": 10570.638, \"total_train_time_s\": 11.941385984420776}", "{\"n\": 19015, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.77, \"learn_time_ms\": 10590.873, \"total_train_time_s\": 11.845515012741089}", "{\"n\": 19016, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.77, \"learn_time_ms\": 10543.564, \"total_train_time_s\": 12.232750177383423}", "{\"n\": 19017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.97, \"learn_time_ms\": 10502.99, \"total_train_time_s\": 11.733884811401367}", "{\"n\": 19018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.94, \"learn_time_ms\": 10412.432, \"total_train_time_s\": 11.366694688796997}", "{\"n\": 19019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.94, \"learn_time_ms\": 10339.193, \"total_train_time_s\": 12.411135911941528}", "{\"n\": 19020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.95, \"learn_time_ms\": 10273.209, \"total_train_time_s\": 11.414745330810547}", "{\"n\": 19021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.33, \"learn_time_ms\": 10137.896, \"total_train_time_s\": 12.008219003677368}", "{\"n\": 19022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3630.33, \"learn_time_ms\": 10045.03, \"total_train_time_s\": 11.941808938980103}", "{\"n\": 19023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.37, \"learn_time_ms\": 10019.511, \"total_train_time_s\": 12.365557432174683}", "{\"n\": 19024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.03, \"learn_time_ms\": 10096.595, \"total_train_time_s\": 12.779022693634033}", "{\"n\": 19025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.03, \"learn_time_ms\": 10060.118, \"total_train_time_s\": 11.493937969207764}", "{\"n\": 19026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.46, \"learn_time_ms\": 9972.294, \"total_train_time_s\": 11.361464023590088}", "{\"n\": 19027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.39, \"learn_time_ms\": 9989.522, \"total_train_time_s\": 11.932727575302124}", "{\"n\": 19028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.01, \"learn_time_ms\": 10031.497, \"total_train_time_s\": 11.840805530548096}", "{\"n\": 19029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.01, \"learn_time_ms\": 10053.977, \"total_train_time_s\": 12.614547491073608}", "{\"n\": 19030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.14, \"learn_time_ms\": 10200.404, \"total_train_time_s\": 12.885716676712036}", "{\"n\": 19031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.34, \"learn_time_ms\": 10159.944, \"total_train_time_s\": 11.628989458084106}", "{\"n\": 19032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.34, \"learn_time_ms\": 10212.104, \"total_train_time_s\": 12.454190731048584}", "{\"n\": 19033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3612.55, \"learn_time_ms\": 10167.362, \"total_train_time_s\": 11.899556636810303}", "{\"n\": 19034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3598.96, \"learn_time_ms\": 10207.37, \"total_train_time_s\": 13.14033579826355}", "{\"n\": 19035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.48, \"learn_time_ms\": 10289.281, \"total_train_time_s\": 12.328664779663086}", "{\"n\": 19036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.48, \"learn_time_ms\": 10331.928, \"total_train_time_s\": 11.798648118972778}", "{\"n\": 19037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3607.89, \"learn_time_ms\": 10409.699, \"total_train_time_s\": 12.71083664894104}", "{\"n\": 19038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3607.89, \"learn_time_ms\": 10404.535, \"total_train_time_s\": 11.815126895904541}", "{\"n\": 19039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.45, \"learn_time_ms\": 10340.202, \"total_train_time_s\": 12.016810178756714}", "{\"n\": 19040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.2, \"learn_time_ms\": 10245.945, \"total_train_time_s\": 11.925263166427612}", "{\"n\": 19041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3617.32, \"learn_time_ms\": 10348.723, \"total_train_time_s\": 12.627958297729492}", "{\"n\": 19042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.8, \"learn_time_ms\": 10267.571, \"total_train_time_s\": 11.659193754196167}", "{\"n\": 19043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.8, \"learn_time_ms\": 10317.03, \"total_train_time_s\": 12.344308137893677}", "{\"n\": 19044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.62, \"learn_time_ms\": 10202.629, \"total_train_time_s\": 11.959779977798462}", "{\"n\": 19045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.62, \"learn_time_ms\": 10175.315, \"total_train_time_s\": 11.999640703201294}", "{\"n\": 19046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.94, \"learn_time_ms\": 10314.427, \"total_train_time_s\": 13.18000054359436}", "{\"n\": 19047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3632.72, \"learn_time_ms\": 10232.501, \"total_train_time_s\": 11.917553186416626}", "{\"n\": 19048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.06, \"learn_time_ms\": 10261.262, \"total_train_time_s\": 12.074167490005493}", "{\"n\": 19049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3626.06, \"learn_time_ms\": 10282.365, \"total_train_time_s\": 12.188771963119507}", "{\"n\": 19050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.45, \"learn_time_ms\": 10241.965, \"total_train_time_s\": 11.546325206756592}", "{\"n\": 19051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.24, \"learn_time_ms\": 10173.832, \"total_train_time_s\": 11.913030624389648}", "{\"n\": 19052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.59, \"learn_time_ms\": 10209.936, \"total_train_time_s\": 12.019514560699463}", "{\"n\": 19053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.09, \"learn_time_ms\": 10189.55, \"total_train_time_s\": 12.13943362236023}", "{\"n\": 19054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.29, \"learn_time_ms\": 10197.251, \"total_train_time_s\": 12.01905870437622}", "{\"n\": 19055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3632.46, \"learn_time_ms\": 10252.356, \"total_train_time_s\": 12.54293155670166}", "{\"n\": 19056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3620.89, \"learn_time_ms\": 10138.756, \"total_train_time_s\": 12.07006287574768}", "{\"n\": 19057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.84, \"learn_time_ms\": 10095.733, \"total_train_time_s\": 11.468335151672363}", "{\"n\": 19058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.22, \"learn_time_ms\": 10243.756, \"total_train_time_s\": 13.601384401321411}", "{\"n\": 19059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.22, \"learn_time_ms\": 10154.129, \"total_train_time_s\": 11.277765989303589}", "{\"n\": 19060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.62, \"learn_time_ms\": 10227.449, \"total_train_time_s\": 12.341277837753296}", "{\"n\": 19061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3604.65, \"learn_time_ms\": 10186.194, \"total_train_time_s\": 11.541441440582275}", "{\"n\": 19062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.82, \"learn_time_ms\": 10175.758, \"total_train_time_s\": 11.87323808670044}", "{\"n\": 19063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.75, \"learn_time_ms\": 10145.728, \"total_train_time_s\": 11.892058372497559}", "{\"n\": 19064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.17, \"learn_time_ms\": 10118.447, \"total_train_time_s\": 11.776192665100098}", "{\"n\": 19065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.58, \"learn_time_ms\": 10112.017, \"total_train_time_s\": 12.520638704299927}", "{\"n\": 19066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3572.58, \"learn_time_ms\": 10161.651, \"total_train_time_s\": 12.515266418457031}", "{\"n\": 19067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3564.36, \"learn_time_ms\": 10045.144, \"total_train_time_s\": 10.249618291854858}", "{\"n\": 19068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.13, \"learn_time_ms\": 9816.364, \"total_train_time_s\": 11.28628158569336}", "{\"n\": 19069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.13, \"learn_time_ms\": 9766.106, \"total_train_time_s\": 10.849638938903809}", "{\"n\": 19070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3560.13, \"learn_time_ms\": 9749.865, \"total_train_time_s\": 12.139039993286133}", "{\"n\": 19071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.22, \"learn_time_ms\": 9892.961, \"total_train_time_s\": 12.96379542350769}", "{\"n\": 19072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 9915.771, \"total_train_time_s\": 12.121273279190063}", "{\"n\": 19073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 9915.074, \"total_train_time_s\": 11.815388917922974}", "{\"n\": 19074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3536.8, \"learn_time_ms\": 9891.271, \"total_train_time_s\": 11.528743982315063}", "{\"n\": 19075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.7, \"learn_time_ms\": 9843.771, \"total_train_time_s\": 12.052852869033813}", "{\"n\": 19076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.7, \"learn_time_ms\": 9845.078, \"total_train_time_s\": 12.535930156707764}", "{\"n\": 19077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.7, \"learn_time_ms\": 10099.851, \"total_train_time_s\": 12.815055131912231}", "{\"n\": 19078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.56, \"learn_time_ms\": 10224.337, \"total_train_time_s\": 12.55531096458435}", "{\"n\": 19079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.12, \"learn_time_ms\": 10387.446, \"total_train_time_s\": 12.471123933792114}", "{\"n\": 19080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3527.12, \"learn_time_ms\": 10360.492, \"total_train_time_s\": 11.841088056564331}", "{\"n\": 19081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.81, \"learn_time_ms\": 10186.265, \"total_train_time_s\": 11.220325946807861}", "{\"n\": 19082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.99, \"learn_time_ms\": 10153.941, \"total_train_time_s\": 11.833035469055176}", "{\"n\": 19083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.99, \"learn_time_ms\": 10230.42, \"total_train_time_s\": 12.661006450653076}", "{\"n\": 19084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.49, \"learn_time_ms\": 10249.225, \"total_train_time_s\": 11.716370820999146}", "{\"n\": 19085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.23, \"learn_time_ms\": 10169.815, \"total_train_time_s\": 11.273770809173584}", "{\"n\": 19086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.23, \"learn_time_ms\": 10167.292, \"total_train_time_s\": 12.50553297996521}", "{\"n\": 19087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3489.12, \"learn_time_ms\": 9999.101, \"total_train_time_s\": 11.129666090011597}", "{\"n\": 19088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3489.12, \"learn_time_ms\": 9994.551, \"total_train_time_s\": 12.47499394416809}", "{\"n\": 19089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3479.44, \"learn_time_ms\": 10046.067, \"total_train_time_s\": 13.007381677627563}", "{\"n\": 19090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3479.44, \"learn_time_ms\": 10125.264, \"total_train_time_s\": 12.685011148452759}", "{\"n\": 19091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3472.59, \"learn_time_ms\": 10219.798, \"total_train_time_s\": 12.132153272628784}", "{\"n\": 19092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3466.92, \"learn_time_ms\": 10370.198, \"total_train_time_s\": 13.308950424194336}", "{\"n\": 19093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3466.92, \"learn_time_ms\": 10329.666, \"total_train_time_s\": 12.202376127243042}", "{\"n\": 19094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.22, \"learn_time_ms\": 10343.353, \"total_train_time_s\": 11.866285562515259}", "{\"n\": 19095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3458.65, \"learn_time_ms\": 10386.749, \"total_train_time_s\": 11.699393510818481}", "{\"n\": 19096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.83, \"learn_time_ms\": 10334.031, \"total_train_time_s\": 12.000446081161499}", "{\"n\": 19097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3451.66, \"learn_time_ms\": 10495.642, \"total_train_time_s\": 12.755043983459473}", "{\"n\": 19098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3436.43, \"learn_time_ms\": 10455.604, \"total_train_time_s\": 12.0556800365448}", "{\"n\": 19099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3436.43, \"learn_time_ms\": 10395.686, \"total_train_time_s\": 12.379725933074951}", "{\"n\": 19100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3446.66, \"learn_time_ms\": 10336.628, \"total_train_time_s\": 12.060334205627441}", "{\"n\": 19101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.76, \"learn_time_ms\": 10263.569, \"total_train_time_s\": 11.434345483779907}", "{\"n\": 19102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.76, \"learn_time_ms\": 10193.318, \"total_train_time_s\": 12.649693250656128}", "{\"n\": 19103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.76, \"learn_time_ms\": 10301.059, \"total_train_time_s\": 13.287766456604004}", "{\"n\": 19104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3447.67, \"learn_time_ms\": 10305.137, \"total_train_time_s\": 11.875750541687012}", "{\"n\": 19105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.07, \"learn_time_ms\": 10340.132, \"total_train_time_s\": 12.03093695640564}", "{\"n\": 19106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.07, \"learn_time_ms\": 10328.644, \"total_train_time_s\": 11.874588251113892}", "{\"n\": 19107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.07, \"learn_time_ms\": 10237.71, \"total_train_time_s\": 11.839733600616455}", "{\"n\": 19108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.92, \"learn_time_ms\": 10208.335, \"total_train_time_s\": 11.77294397354126}", "{\"n\": 19109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.76, \"learn_time_ms\": 10054.391, \"total_train_time_s\": 10.843584537506104}", "{\"n\": 19110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.76, \"learn_time_ms\": 9996.324, \"total_train_time_s\": 11.480625629425049}", "{\"n\": 19111, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3478.43, \"learn_time_ms\": 10012.224, \"total_train_time_s\": 11.634306907653809}", "{\"n\": 19112, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3486.96, \"learn_time_ms\": 10076.813, \"total_train_time_s\": 13.279850721359253}", "{\"n\": 19113, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3486.96, \"learn_time_ms\": 10012.271, \"total_train_time_s\": 12.660820245742798}", "{\"n\": 19114, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3488.73, \"learn_time_ms\": 9957.731, \"total_train_time_s\": 11.31230878829956}", "{\"n\": 19115, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.52, \"learn_time_ms\": 10053.691, \"total_train_time_s\": 12.980820178985596}", "{\"n\": 19116, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.52, \"learn_time_ms\": 10080.955, \"total_train_time_s\": 12.140085697174072}", "{\"n\": 19117, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.52, \"learn_time_ms\": 10140.639, \"total_train_time_s\": 12.409746408462524}", "{\"n\": 19118, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.44, \"learn_time_ms\": 10230.151, \"total_train_time_s\": 12.70798921585083}", "{\"n\": 19119, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.54, \"learn_time_ms\": 10276.654, \"total_train_time_s\": 11.298309326171875}", "{\"n\": 19120, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.54, \"learn_time_ms\": 10464.524, \"total_train_time_s\": 13.31419038772583}", "{\"n\": 19121, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.0, \"learn_time_ms\": 10482.756, \"total_train_time_s\": 11.783970594406128}", "{\"n\": 19122, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.56, \"learn_time_ms\": 10443.05, \"total_train_time_s\": 12.911864280700684}", "{\"n\": 19123, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.56, \"learn_time_ms\": 10262.358, \"total_train_time_s\": 10.80409288406372}", "{\"n\": 19124, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.56, \"learn_time_ms\": 10333.497, \"total_train_time_s\": 12.060099840164185}", "{\"n\": 19125, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3488.32, \"learn_time_ms\": 10341.589, \"total_train_time_s\": 13.10060167312622}", "{\"n\": 19126, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3485.54, \"learn_time_ms\": 10340.633, \"total_train_time_s\": 12.112637281417847}", "{\"n\": 19127, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3485.54, \"learn_time_ms\": 10293.306, \"total_train_time_s\": 11.963081121444702}", "{\"n\": 19128, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.79, \"learn_time_ms\": 10286.337, \"total_train_time_s\": 12.61841893196106}", "{\"n\": 19129, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3484.18, \"learn_time_ms\": 10316.037, \"total_train_time_s\": 11.567397832870483}", "{\"n\": 19130, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3484.18, \"learn_time_ms\": 10096.326, \"total_train_time_s\": 11.129616975784302}", "{\"n\": 19131, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3474.4, \"learn_time_ms\": 10154.091, \"total_train_time_s\": 12.315072059631348}", "{\"n\": 19132, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3463.8, \"learn_time_ms\": 10012.213, \"total_train_time_s\": 11.465105295181274}", "{\"n\": 19133, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3474.32, \"learn_time_ms\": 10087.43, \"total_train_time_s\": 11.617828130722046}", "{\"n\": 19134, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3474.32, \"learn_time_ms\": 10009.516, \"total_train_time_s\": 11.280584573745728}", "{\"n\": 19135, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3472.43, \"learn_time_ms\": 10071.811, \"total_train_time_s\": 13.703263998031616}", "{\"n\": 19136, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3483.33, \"learn_time_ms\": 10010.164, \"total_train_time_s\": 11.532127618789673}", "{\"n\": 19137, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3489.19, \"learn_time_ms\": 10041.964, \"total_train_time_s\": 12.27585220336914}", "{\"n\": 19138, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3492.86, \"learn_time_ms\": 9911.602, \"total_train_time_s\": 11.307698965072632}", "{\"n\": 19139, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3492.86, \"learn_time_ms\": 10057.454, \"total_train_time_s\": 13.036913394927979}", "{\"n\": 19140, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.97, \"learn_time_ms\": 10223.85, \"total_train_time_s\": 12.820457696914673}", "{\"n\": 19141, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.97, \"learn_time_ms\": 10232.329, \"total_train_time_s\": 12.410117626190186}", "{\"n\": 19142, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.77, \"learn_time_ms\": 10323.676, \"total_train_time_s\": 12.352938652038574}", "{\"n\": 19143, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3507.25, \"learn_time_ms\": 10360.401, \"total_train_time_s\": 11.97002649307251}", "{\"n\": 19144, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3512.44, \"learn_time_ms\": 10526.84, \"total_train_time_s\": 12.951668977737427}", "{\"n\": 19145, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3515.11, \"learn_time_ms\": 10409.048, \"total_train_time_s\": 12.535522937774658}", "{\"n\": 19146, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.75, \"learn_time_ms\": 10515.75, \"total_train_time_s\": 12.580796003341675}", "{\"n\": 19147, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.76, \"learn_time_ms\": 10541.753, \"total_train_time_s\": 12.546415567398071}", "{\"n\": 19148, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.76, \"learn_time_ms\": 10672.133, \"total_train_time_s\": 12.584452629089355}", "{\"n\": 19149, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3509.43, \"learn_time_ms\": 10570.374, \"total_train_time_s\": 12.043127536773682}", "{\"n\": 19150, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3517.03, \"learn_time_ms\": 10540.05, \"total_train_time_s\": 12.5123291015625}", "{\"n\": 19151, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3521.93, \"learn_time_ms\": 10532.522, \"total_train_time_s\": 12.342135190963745}", "{\"n\": 19152, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.17, \"learn_time_ms\": 10455.441, \"total_train_time_s\": 11.613601446151733}", "{\"n\": 19153, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.17, \"learn_time_ms\": 10472.058, \"total_train_time_s\": 12.088452339172363}", "{\"n\": 19154, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.47, \"learn_time_ms\": 10408.552, \"total_train_time_s\": 12.308047533035278}", "{\"n\": 19155, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.3, \"learn_time_ms\": 10390.92, \"total_train_time_s\": 12.333369016647339}", "{\"n\": 19156, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.81, \"learn_time_ms\": 10296.946, \"total_train_time_s\": 11.689656496047974}", "{\"n\": 19157, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3518.81, \"learn_time_ms\": 10370.911, \"total_train_time_s\": 13.304653406143188}", "{\"n\": 19158, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.73, \"learn_time_ms\": 10303.999, \"total_train_time_s\": 11.954116821289062}", "{\"n\": 19159, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.73, \"learn_time_ms\": 10380.828, \"total_train_time_s\": 12.755255699157715}", "{\"n\": 19160, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.41, \"learn_time_ms\": 10385.015, \"total_train_time_s\": 12.550464630126953}", "{\"n\": 19161, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 1.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.41, \"learn_time_ms\": 10399.033, \"total_train_time_s\": 12.494059801101685}", "{\"n\": 19162, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.53, \"learn_time_ms\": 10501.638, \"total_train_time_s\": 12.642879247665405}", "{\"n\": 19163, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3532.53, \"learn_time_ms\": 10568.414, \"total_train_time_s\": 12.808836936950684}", "{\"n\": 19164, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.76, \"learn_time_ms\": 10636.034, \"total_train_time_s\": 12.98233962059021}", "{\"n\": 19165, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3533.84, \"learn_time_ms\": 10703.177, \"total_train_time_s\": 13.014423847198486}", "{\"n\": 19166, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3534.11, \"learn_time_ms\": 10724.372, \"total_train_time_s\": 11.840911149978638}", "{\"n\": 19167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.71, \"learn_time_ms\": 10564.847, \"total_train_time_s\": 11.674322843551636}", "{\"n\": 19168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3542.71, \"learn_time_ms\": 10629.032, \"total_train_time_s\": 12.583553552627563}", "{\"n\": 19169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.75, \"learn_time_ms\": 10637.867, \"total_train_time_s\": 12.907262563705444}", "{\"n\": 19170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3548.75, \"learn_time_ms\": 10537.363, \"total_train_time_s\": 11.542562007904053}", "{\"n\": 19171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.46, \"learn_time_ms\": 10480.881, \"total_train_time_s\": 11.924219131469727}", "{\"n\": 19172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3544.46, \"learn_time_ms\": 10456.556, \"total_train_time_s\": 12.406467199325562}", "{\"n\": 19173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.28, \"learn_time_ms\": 10588.018, \"total_train_time_s\": 14.158290147781372}", "{\"n\": 19174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.16, \"learn_time_ms\": 10539.061, \"total_train_time_s\": 12.537588119506836}", "{\"n\": 19175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3557.8, \"learn_time_ms\": 10495.935, \"total_train_time_s\": 12.573791742324829}", "{\"n\": 19176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.32, \"learn_time_ms\": 10414.525, \"total_train_time_s\": 11.012213706970215}", "{\"n\": 19177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3568.32, \"learn_time_ms\": 10487.01, \"total_train_time_s\": 12.412535905838013}", "{\"n\": 19178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.98, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3559.74, \"learn_time_ms\": 10373.512, \"total_train_time_s\": 11.448239088058472}", "{\"n\": 19179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3566.64, \"learn_time_ms\": 10354.941, \"total_train_time_s\": 12.6890709400177}", "{\"n\": 19180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.14, \"learn_time_ms\": 10340.456, \"total_train_time_s\": 11.440664291381836}", "{\"n\": 19181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3573.56, \"learn_time_ms\": 10333.682, \"total_train_time_s\": 11.91332459449768}", "{\"n\": 19182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.18, \"learn_time_ms\": 10327.682, \"total_train_time_s\": 12.283641338348389}", "{\"n\": 19183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.09, \"learn_time_ms\": 10125.074, \"total_train_time_s\": 12.08539867401123}", "{\"n\": 19184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.27, \"learn_time_ms\": 10056.261, \"total_train_time_s\": 11.830658674240112}", "{\"n\": 19185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3587.07, \"learn_time_ms\": 10082.753, \"total_train_time_s\": 12.91622805595398}", "{\"n\": 19186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3583.96, \"learn_time_ms\": 10194.916, \"total_train_time_s\": 12.172968864440918}", "{\"n\": 19187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3584.74, \"learn_time_ms\": 10177.076, \"total_train_time_s\": 12.198303461074829}", "{\"n\": 19188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.65, \"learn_time_ms\": 10166.523, \"total_train_time_s\": 11.347886800765991}", "{\"n\": 19189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.16, \"learn_time_ms\": 10144.379, \"total_train_time_s\": 12.504918098449707}", "{\"n\": 19190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.41, \"learn_time_ms\": 10226.751, \"total_train_time_s\": 12.254026174545288}", "{\"n\": 19191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.14, \"learn_time_ms\": 10357.736, \"total_train_time_s\": 13.213796615600586}", "{\"n\": 19192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.19, \"learn_time_ms\": 10391.854, \"total_train_time_s\": 12.684212446212769}", "{\"n\": 19193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.22, \"learn_time_ms\": 10255.583, \"total_train_time_s\": 10.719466209411621}", "{\"n\": 19194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.22, \"learn_time_ms\": 10240.882, \"total_train_time_s\": 11.657761335372925}", "{\"n\": 19195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.95, \"learn_time_ms\": 10136.05, \"total_train_time_s\": 11.78651738166809}", "{\"n\": 19196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.0, \"learn_time_ms\": 10074.029, \"total_train_time_s\": 11.573501110076904}", "{\"n\": 19197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.53, \"learn_time_ms\": 10121.361, \"total_train_time_s\": 12.704809665679932}", "{\"n\": 19198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.53, \"learn_time_ms\": 10177.625, \"total_train_time_s\": 11.892881631851196}", "{\"n\": 19199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.09, \"learn_time_ms\": 10141.064, \"total_train_time_s\": 12.092862844467163}", "{\"n\": 19200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.88, \"learn_time_ms\": 10155.899, \"total_train_time_s\": 12.394451379776001}", "{\"n\": 19201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.25, \"learn_time_ms\": 10074.998, \"total_train_time_s\": 12.38068175315857}", "{\"n\": 19202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.25, \"learn_time_ms\": 9962.434, \"total_train_time_s\": 11.517783403396606}", "{\"n\": 19203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.61, \"learn_time_ms\": 10120.912, \"total_train_time_s\": 12.30308985710144}", "{\"n\": 19204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.37, \"learn_time_ms\": 10104.988, \"total_train_time_s\": 11.48058557510376}", "{\"n\": 19205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3577.23, \"learn_time_ms\": 10089.11, \"total_train_time_s\": 11.661384344100952}", "{\"n\": 19206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.14, \"learn_time_ms\": 10170.496, \"total_train_time_s\": 12.36550760269165}", "{\"n\": 19207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.14, \"learn_time_ms\": 10141.281, \"total_train_time_s\": 12.390141010284424}", "{\"n\": 19208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.87, \"learn_time_ms\": 10150.613, \"total_train_time_s\": 12.001680374145508}", "{\"n\": 19209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.87, \"learn_time_ms\": 10027.746, \"total_train_time_s\": 10.9038565158844}", "{\"n\": 19210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.71, \"learn_time_ms\": 9934.065, \"total_train_time_s\": 11.421967267990112}", "{\"n\": 19211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3591.8, \"learn_time_ms\": 9937.882, \"total_train_time_s\": 12.404921054840088}", "{\"n\": 19212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.62, \"learn_time_ms\": 9974.789, \"total_train_time_s\": 11.913070678710938}", "{\"n\": 19213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.4, \"learn_time_ms\": 10038.929, \"total_train_time_s\": 12.94724726676941}", "{\"n\": 19214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3585.4, \"learn_time_ms\": 10058.06, \"total_train_time_s\": 11.654804468154907}", "{\"n\": 19215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.87, \"learn_time_ms\": 10172.847, \"total_train_time_s\": 12.833924055099487}", "{\"n\": 19216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.86, \"learn_time_ms\": 10195.443, \"total_train_time_s\": 12.613183498382568}", "{\"n\": 19217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3599.84, \"learn_time_ms\": 10046.307, \"total_train_time_s\": 10.98186707496643}", "{\"n\": 19218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3600.46, \"learn_time_ms\": 10068.353, \"total_train_time_s\": 12.206263542175293}", "{\"n\": 19219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3601.12, \"learn_time_ms\": 10161.453, \"total_train_time_s\": 11.796546697616577}", "{\"n\": 19220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3606.8, \"learn_time_ms\": 10233.598, \"total_train_time_s\": 12.133399963378906}", "{\"n\": 19221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3620.82, \"learn_time_ms\": 10210.111, \"total_train_time_s\": 12.167547702789307}", "{\"n\": 19222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.09, \"learn_time_ms\": 10179.936, \"total_train_time_s\": 11.594193935394287}", "{\"n\": 19223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.88, \"learn_time_ms\": 10194.878, \"total_train_time_s\": 13.132287979125977}", "{\"n\": 19224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3627.88, \"learn_time_ms\": 10211.844, \"total_train_time_s\": 11.930622100830078}", "{\"n\": 19225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3624.32, \"learn_time_ms\": 10146.437, \"total_train_time_s\": 12.170586109161377}", "{\"n\": 19226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.7, \"learn_time_ms\": 10050.611, \"total_train_time_s\": 11.648853540420532}", "{\"n\": 19227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.7, \"learn_time_ms\": 10228.087, \"total_train_time_s\": 12.716499328613281}", "{\"n\": 19228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3607.7, \"learn_time_ms\": 10074.883, \"total_train_time_s\": 10.689303636550903}", "{\"n\": 19229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3614.29, \"learn_time_ms\": 10099.144, \"total_train_time_s\": 12.033185720443726}", "{\"n\": 19230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.6, \"learn_time_ms\": 10011.225, \"total_train_time_s\": 11.249510526657104}", "{\"n\": 19231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3608.6, \"learn_time_ms\": 10064.268, \"total_train_time_s\": 12.732425451278687}", "{\"n\": 19232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3602.9, \"learn_time_ms\": 10069.904, \"total_train_time_s\": 11.625604629516602}", "{\"n\": 19233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 9946.909, \"total_train_time_s\": 11.907927751541138}", "{\"n\": 19234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 10020.326, \"total_train_time_s\": 12.566278457641602}", "{\"n\": 19235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3604.5, \"learn_time_ms\": 9923.282, \"total_train_time_s\": 11.15467882156372}", "{\"n\": 19236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.57, \"learn_time_ms\": 9959.401, \"total_train_time_s\": 12.045242071151733}", "{\"n\": 19237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.93, \"learn_time_ms\": 9785.523, \"total_train_time_s\": 10.990233421325684}", "{\"n\": 19238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3616.93, \"learn_time_ms\": 9880.163, \"total_train_time_s\": 11.611714124679565}", "{\"n\": 19239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3615.89, \"learn_time_ms\": 9822.264, \"total_train_time_s\": 11.451347589492798}", "{\"n\": 19240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.98, \"learn_time_ms\": 9883.593, \"total_train_time_s\": 11.898313045501709}", "{\"n\": 19241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.98, \"learn_time_ms\": 9888.699, \"total_train_time_s\": 12.703014850616455}", "{\"n\": 19242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3607.98, \"learn_time_ms\": 9905.088, \"total_train_time_s\": 11.829748153686523}", "{\"n\": 19243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3610.05, \"learn_time_ms\": 9851.04, \"total_train_time_s\": 11.354526281356812}", "{\"n\": 19244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3614.35, \"learn_time_ms\": 9865.175, \"total_train_time_s\": 12.722195386886597}", "{\"n\": 19245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.98, \"learn_time_ms\": 9847.144, \"total_train_time_s\": 10.99025011062622}", "{\"n\": 19246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3612.98, \"learn_time_ms\": 9962.411, \"total_train_time_s\": 13.152708292007446}", "{\"n\": 19247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3625.88, \"learn_time_ms\": 10020.923, \"total_train_time_s\": 11.530392408370972}", "{\"n\": 19248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3628.22, \"learn_time_ms\": 10073.517, \"total_train_time_s\": 12.156733751296997}", "{\"n\": 19249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.14, \"learn_time_ms\": 10149.119, \"total_train_time_s\": 12.20119595527649}", "{\"n\": 19250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.14, \"learn_time_ms\": 10133.391, \"total_train_time_s\": 11.75294828414917}", "{\"n\": 19251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3634.48, \"learn_time_ms\": 10072.606, \"total_train_time_s\": 12.162729978561401}", "{\"n\": 19252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.03, \"learn_time_ms\": 10221.047, \"total_train_time_s\": 13.28330135345459}", "{\"n\": 19253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3647.02, \"learn_time_ms\": 10257.681, \"total_train_time_s\": 11.675189018249512}", "{\"n\": 19254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.85, \"learn_time_ms\": 10195.756, \"total_train_time_s\": 12.10326361656189}", "{\"n\": 19255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3652.72, \"learn_time_ms\": 10228.64, \"total_train_time_s\": 11.32445764541626}", "{\"n\": 19256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.94, \"learn_time_ms\": 10115.878, \"total_train_time_s\": 12.02803897857666}", "{\"n\": 19257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.94, \"learn_time_ms\": 10173.256, \"total_train_time_s\": 12.134360551834106}", "{\"n\": 19258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.9, \"learn_time_ms\": 10230.079, \"total_train_time_s\": 12.738579273223877}", "{\"n\": 19259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.55, \"learn_time_ms\": 10198.127, \"total_train_time_s\": 11.907963991165161}", "{\"n\": 19260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.52, \"learn_time_ms\": 10267.787, \"total_train_time_s\": 12.467272758483887}", "{\"n\": 19261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3635.52, \"learn_time_ms\": 10263.172, \"total_train_time_s\": 12.111216306686401}", "{\"n\": 19262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.58, \"learn_time_ms\": 10040.288, \"total_train_time_s\": 11.119127988815308}", "{\"n\": 19263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.55, \"learn_time_ms\": 10034.697, \"total_train_time_s\": 11.665193557739258}", "{\"n\": 19264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.55, \"learn_time_ms\": 10089.236, \"total_train_time_s\": 12.720234155654907}", "{\"n\": 19265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.55, \"learn_time_ms\": 10036.153, \"total_train_time_s\": 10.757618188858032}", "{\"n\": 19266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.53, \"learn_time_ms\": 10142.157, \"total_train_time_s\": 13.074299573898315}", "{\"n\": 19267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.36, \"learn_time_ms\": 10135.785, \"total_train_time_s\": 12.07841157913208}", "{\"n\": 19268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.36, \"learn_time_ms\": 10099.873, \"total_train_time_s\": 12.358697891235352}", "{\"n\": 19269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.36, \"learn_time_ms\": 10250.859, \"total_train_time_s\": 13.393506526947021}", "{\"n\": 19270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.01, \"learn_time_ms\": 10103.051, \"total_train_time_s\": 10.96028733253479}", "{\"n\": 19271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.75, \"learn_time_ms\": 10122.899, \"total_train_time_s\": 12.341964721679688}", "{\"n\": 19272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.75, \"learn_time_ms\": 10335.8, \"total_train_time_s\": 13.196255683898926}", "{\"n\": 19273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.75, \"learn_time_ms\": 10415.748, \"total_train_time_s\": 12.457905292510986}", "{\"n\": 19274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.7, \"learn_time_ms\": 10439.259, \"total_train_time_s\": 12.927714109420776}", "{\"n\": 19275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.16, \"learn_time_ms\": 10488.111, \"total_train_time_s\": 11.259071826934814}", "{\"n\": 19276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.16, \"learn_time_ms\": 10442.877, \"total_train_time_s\": 12.627321243286133}", "{\"n\": 19277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.16, \"learn_time_ms\": 10529.618, \"total_train_time_s\": 12.9149489402771}", "{\"n\": 19278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.86, \"learn_time_ms\": 10501.604, \"total_train_time_s\": 12.08427095413208}", "{\"n\": 19279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.29, \"learn_time_ms\": 10532.766, \"total_train_time_s\": 13.73408055305481}", "{\"n\": 19280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.29, \"learn_time_ms\": 10640.199, \"total_train_time_s\": 12.025842666625977}", "{\"n\": 19281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3681.61, \"learn_time_ms\": 10616.777, \"total_train_time_s\": 12.09708023071289}", "{\"n\": 19282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.97, \"learn_time_ms\": 10499.168, \"total_train_time_s\": 12.02599310874939}", "{\"n\": 19283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.57, \"learn_time_ms\": 10393.468, \"total_train_time_s\": 11.381757974624634}", "{\"n\": 19284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.57, \"learn_time_ms\": 10329.588, \"total_train_time_s\": 12.293971300125122}", "{\"n\": 19285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 2.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.39, \"learn_time_ms\": 10365.798, \"total_train_time_s\": 11.63042688369751}", "{\"n\": 19286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.64, \"learn_time_ms\": 10182.612, \"total_train_time_s\": 10.837646722793579}", "{\"n\": 19287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.64, \"learn_time_ms\": 10149.436, \"total_train_time_s\": 12.60055422782898}", "{\"n\": 19288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.92, \"learn_time_ms\": 10231.044, \"total_train_time_s\": 12.940969228744507}", "{\"n\": 19289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.84, \"learn_time_ms\": 10068.806, \"total_train_time_s\": 12.144899129867554}", "{\"n\": 19290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.36, \"learn_time_ms\": 9989.152, \"total_train_time_s\": 11.20589280128479}", "{\"n\": 19291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.36, \"learn_time_ms\": 10041.974, \"total_train_time_s\": 12.590167999267578}", "{\"n\": 19292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": 1.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.36, \"learn_time_ms\": 10115.993, \"total_train_time_s\": 12.751368522644043}", "{\"n\": 19293, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.24, \"learn_time_ms\": 10145.823, \"total_train_time_s\": 11.65654182434082}", "{\"n\": 19294, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.24, \"learn_time_ms\": 10156.538, \"total_train_time_s\": 12.363194942474365}", "{\"n\": 19295, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.24, \"learn_time_ms\": 10181.439, \"total_train_time_s\": 11.894243955612183}", "{\"n\": 19296, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.28, \"learn_time_ms\": 10294.426, \"total_train_time_s\": 11.958093881607056}", "{\"n\": 19297, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.41, \"learn_time_ms\": 10181.29, \"total_train_time_s\": 11.467119216918945}", "{\"n\": 19298, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.41, \"learn_time_ms\": 10140.948, \"total_train_time_s\": 12.538763284683228}", "{\"n\": 19299, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.03, \"learn_time_ms\": 10130.038, \"total_train_time_s\": 11.9763503074646}", "{\"n\": 19300, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.55, \"learn_time_ms\": 10244.306, \"total_train_time_s\": 12.42595362663269}", "{\"n\": 19301, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.01, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3707.55, \"learn_time_ms\": 10163.966, \"total_train_time_s\": 11.818122386932373}", "{\"n\": 19302, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3712.55, \"learn_time_ms\": 10078.745, \"total_train_time_s\": 11.904768705368042}", "{\"n\": 19303, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.58, \"learn_time_ms\": 10201.456, \"total_train_time_s\": 12.958537340164185}", "{\"n\": 19304, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.99, \"learn_time_ms\": 10201.028, \"total_train_time_s\": 12.396815061569214}", "{\"n\": 19305, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.99, \"learn_time_ms\": 10216.381, \"total_train_time_s\": 12.054934740066528}", "{\"n\": 19306, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.01, \"learn_time_ms\": 10273.293, \"total_train_time_s\": 12.493432760238647}", "{\"n\": 19307, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.76, \"learn_time_ms\": 10289.193, \"total_train_time_s\": 11.68355941772461}", "{\"n\": 19308, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.76, \"learn_time_ms\": 10262.335, \"total_train_time_s\": 12.249047994613647}", "{\"n\": 19309, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.0, \"learn_time_ms\": 10138.77, \"total_train_time_s\": 10.753452777862549}", "{\"n\": 19310, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3700.45, \"learn_time_ms\": 10093.679, \"total_train_time_s\": 11.926532745361328}", "{\"n\": 19311, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.2, \"learn_time_ms\": 10135.176, \"total_train_time_s\": 12.248201131820679}", "{\"n\": 19312, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.2, \"learn_time_ms\": 10080.721, \"total_train_time_s\": 11.357512474060059}", "{\"n\": 19313, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.12, \"learn_time_ms\": 9938.764, \"total_train_time_s\": 11.50183653831482}", "{\"n\": 19314, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.21, \"learn_time_ms\": 9843.18, \"total_train_time_s\": 11.404848098754883}", "{\"n\": 19315, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.21, \"learn_time_ms\": 9883.151, \"total_train_time_s\": 12.389456748962402}", "{\"n\": 19316, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.21, \"learn_time_ms\": 9780.281, \"total_train_time_s\": 11.446043014526367}", "{\"n\": 19317, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.12, \"learn_time_ms\": 9881.533, \"total_train_time_s\": 12.629185676574707}", "{\"n\": 19318, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.03, \"learn_time_ms\": 9770.413, \"total_train_time_s\": 11.128113508224487}", "{\"n\": 19319, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.03, \"learn_time_ms\": 9883.234, \"total_train_time_s\": 11.91601037979126}", "{\"n\": 19320, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.03, \"learn_time_ms\": 9962.947, \"total_train_time_s\": 12.740309000015259}", "{\"n\": 19321, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.05, \"learn_time_ms\": 9988.363, \"total_train_time_s\": 12.491710424423218}", "{\"n\": 19322, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.44, \"learn_time_ms\": 9970.956, \"total_train_time_s\": 11.202470064163208}", "{\"n\": 19323, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.44, \"learn_time_ms\": 9980.467, \"total_train_time_s\": 11.58174467086792}", "{\"n\": 19324, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.01, \"learn_time_ms\": 10068.827, \"total_train_time_s\": 12.347707271575928}", "{\"n\": 19325, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.79, \"learn_time_ms\": 9984.786, \"total_train_time_s\": 11.60680079460144}", "{\"n\": 19326, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.79, \"learn_time_ms\": 10138.285, \"total_train_time_s\": 13.017329216003418}", "{\"n\": 19327, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.79, \"learn_time_ms\": 10081.865, \"total_train_time_s\": 12.069300651550293}", "{\"n\": 19328, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.71, \"learn_time_ms\": 10037.552, \"total_train_time_s\": 10.673576831817627}", "{\"n\": 19329, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.85, \"learn_time_ms\": 10017.2, \"total_train_time_s\": 11.687004327774048}", "{\"n\": 19330, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.85, \"learn_time_ms\": 10058.853, \"total_train_time_s\": 13.147385835647583}", "{\"n\": 19331, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.37, \"learn_time_ms\": 10040.121, \"total_train_time_s\": 12.241472244262695}", "{\"n\": 19332, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.7, \"learn_time_ms\": 10102.006, \"total_train_time_s\": 11.807435512542725}", "{\"n\": 19333, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.36, \"learn_time_ms\": 10179.929, \"total_train_time_s\": 12.394453287124634}", "{\"n\": 19334, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.36, \"learn_time_ms\": 10258.572, \"total_train_time_s\": 13.051101207733154}", "{\"n\": 19335, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 0.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.61, \"learn_time_ms\": 10254.925, \"total_train_time_s\": 11.537272453308105}", "{\"n\": 19336, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.68, \"learn_time_ms\": 10197.08, \"total_train_time_s\": 12.430447578430176}", "{\"n\": 19337, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.68, \"learn_time_ms\": 10258.273, \"total_train_time_s\": 12.680267333984375}", "{\"n\": 19338, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.68, \"learn_time_ms\": 10426.018, \"total_train_time_s\": 12.364423990249634}", "{\"n\": 19339, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.91, \"learn_time_ms\": 10378.567, \"total_train_time_s\": 11.175564289093018}", "{\"n\": 19340, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 10284.72, \"total_train_time_s\": 12.207035303115845}", "{\"n\": 19341, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 10302.142, \"total_train_time_s\": 12.425907373428345}", "{\"n\": 19342, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.39, \"learn_time_ms\": 10356.345, \"total_train_time_s\": 12.330627918243408}", "{\"n\": 19343, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.14, \"learn_time_ms\": 10308.105, \"total_train_time_s\": 11.922686338424683}", "{\"n\": 19344, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3676.58, \"learn_time_ms\": 10189.509, \"total_train_time_s\": 11.88918685913086}", "{\"n\": 19345, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3676.58, \"learn_time_ms\": 10232.065, \"total_train_time_s\": 11.968439817428589}", "{\"n\": 19346, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.19, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3665.37, \"learn_time_ms\": 10216.809, \"total_train_time_s\": 12.276274681091309}", "{\"n\": 19347, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3666.08, \"learn_time_ms\": 10108.574, \"total_train_time_s\": 11.603225231170654}", "{\"n\": 19348, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.21, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3666.08, \"learn_time_ms\": 10121.593, \"total_train_time_s\": 12.484208822250366}", "{\"n\": 19349, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3654.57, \"learn_time_ms\": 10195.283, \"total_train_time_s\": 11.958085536956787}", "{\"n\": 19350, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3654.57, \"learn_time_ms\": 10157.348, \"total_train_time_s\": 11.877511978149414}", "{\"n\": 19351, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3662.98, \"learn_time_ms\": 10146.913, \"total_train_time_s\": 12.362224578857422}", "{\"n\": 19352, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.66, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3663.85, \"learn_time_ms\": 10032.943, \"total_train_time_s\": 11.21068811416626}", "{\"n\": 19353, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3659.31, \"learn_time_ms\": 10116.492, \"total_train_time_s\": 12.696754932403564}", "{\"n\": 19354, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3659.31, \"learn_time_ms\": 10132.296, \"total_train_time_s\": 12.044751167297363}", "{\"n\": 19355, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3660.27, \"learn_time_ms\": 10167.549, \"total_train_time_s\": 12.341959953308105}", "{\"n\": 19356, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.58, \"learn_time_ms\": 10178.0, \"total_train_time_s\": 12.395548105239868}", "{\"n\": 19357, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.58, \"learn_time_ms\": 10172.673, \"total_train_time_s\": 11.534831047058105}", "{\"n\": 19358, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 1.92, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3647.58, \"learn_time_ms\": 10039.518, \"total_train_time_s\": 11.145227909088135}", "{\"n\": 19359, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3644.63, \"learn_time_ms\": 10100.092, \"total_train_time_s\": 12.55879545211792}", "{\"n\": 19360, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3644.63, \"learn_time_ms\": 10140.821, \"total_train_time_s\": 12.27223515510559}", "{\"n\": 19361, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3644.63, \"learn_time_ms\": 10122.504, \"total_train_time_s\": 12.156996488571167}", "{\"n\": 19362, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3631.27, \"learn_time_ms\": 10225.494, \"total_train_time_s\": 12.217138528823853}", "{\"n\": 19363, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3627.88, \"learn_time_ms\": 10114.468, \"total_train_time_s\": 11.633788824081421}", "{\"n\": 19364, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3627.88, \"learn_time_ms\": 10113.543, \"total_train_time_s\": 12.067046165466309}", "{\"n\": 19365, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3621.66, \"learn_time_ms\": 10031.436, \"total_train_time_s\": 11.524190664291382}", "{\"n\": 19366, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 10055.389, \"total_train_time_s\": 12.652865409851074}", "{\"n\": 19367, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 10082.704, \"total_train_time_s\": 11.810067176818848}", "{\"n\": 19368, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.97, \"learn_time_ms\": 10241.369, \"total_train_time_s\": 12.765308618545532}", "{\"n\": 19369, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.53, \"learn_time_ms\": 10124.495, \"total_train_time_s\": 11.36706829071045}", "{\"n\": 19370, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.9, \"learn_time_ms\": 10105.901, \"total_train_time_s\": 12.176949262619019}", "{\"n\": 19371, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.31, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.61, \"learn_time_ms\": 10215.317, \"total_train_time_s\": 13.249667406082153}", "{\"n\": 19372, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.39, \"learn_time_ms\": 10090.541, \"total_train_time_s\": 10.95397424697876}", "{\"n\": 19373, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.92, \"learn_time_ms\": 10074.418, \"total_train_time_s\": 11.442903280258179}", "{\"n\": 19374, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3611.17, \"learn_time_ms\": 10034.787, \"total_train_time_s\": 11.708192110061646}", "{\"n\": 19375, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.83, \"learn_time_ms\": 10057.155, \"total_train_time_s\": 11.72967791557312}", "{\"n\": 19376, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.04, \"learn_time_ms\": 10007.811, \"total_train_time_s\": 12.11110258102417}", "{\"n\": 19377, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.12, \"learn_time_ms\": 10051.159, \"total_train_time_s\": 12.250942707061768}", "{\"n\": 19378, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3616.09, \"learn_time_ms\": 9886.155, \"total_train_time_s\": 11.159523010253906}", "{\"n\": 19379, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3613.29, \"learn_time_ms\": 9912.86, \"total_train_time_s\": 11.664647579193115}", "{\"n\": 19380, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3603.84, \"learn_time_ms\": 9850.687, \"total_train_time_s\": 11.42104721069336}", "{\"n\": 19381, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.91, \"learn_time_ms\": 9679.52, \"total_train_time_s\": 11.554487466812134}", "{\"n\": 19382, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3608.94, \"learn_time_ms\": 9768.461, \"total_train_time_s\": 11.82103681564331}", "{\"n\": 19383, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.87, \"learn_time_ms\": 9859.48, \"total_train_time_s\": 12.345587253570557}", "{\"n\": 19384, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.06, \"learn_time_ms\": 9929.181, \"total_train_time_s\": 12.365803956985474}", "{\"n\": 19385, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.06, \"learn_time_ms\": 9937.369, \"total_train_time_s\": 11.801685571670532}", "{\"n\": 19386, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3605.18, \"learn_time_ms\": 9844.029, \"total_train_time_s\": 11.19193959236145}", "{\"n\": 19387, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.13, \"learn_time_ms\": 9912.234, \"total_train_time_s\": 12.939900636672974}", "{\"n\": 19388, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.75, \"learn_time_ms\": 9881.917, \"total_train_time_s\": 10.79433536529541}", "{\"n\": 19389, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.23, \"learn_time_ms\": 10013.443, \"total_train_time_s\": 12.983567237854004}", "{\"n\": 19390, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.04, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3602.23, \"learn_time_ms\": 10050.939, \"total_train_time_s\": 11.784128189086914}", "{\"n\": 19391, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.01, \"learn_time_ms\": 10147.344, \"total_train_time_s\": 12.539314031600952}", "{\"n\": 19392, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3607.01, \"learn_time_ms\": 10160.311, \"total_train_time_s\": 12.006561040878296}", "{\"n\": 19393, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3606.92, \"learn_time_ms\": 10086.39, \"total_train_time_s\": 11.620062351226807}", "{\"n\": 19394, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3610.05, \"learn_time_ms\": 10244.848, \"total_train_time_s\": 13.94021725654602}", "{\"n\": 19395, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.8, \"learn_time_ms\": 10201.785, \"total_train_time_s\": 11.400227308273315}", "{\"n\": 19396, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.2, \"learn_time_ms\": 10325.571, \"total_train_time_s\": 12.40744400024414}", "{\"n\": 19397, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3614.2, \"learn_time_ms\": 10316.433, \"total_train_time_s\": 12.822489738464355}", "{\"n\": 19398, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.96, \"learn_time_ms\": 10461.335, \"total_train_time_s\": 12.28041958808899}", "{\"n\": 19399, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.38, \"learn_time_ms\": 10341.455, \"total_train_time_s\": 11.791974782943726}", "{\"n\": 19400, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3609.6, \"learn_time_ms\": 10447.638, \"total_train_time_s\": 12.91038203239441}", "{\"n\": 19401, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3612.18, \"learn_time_ms\": 10308.762, \"total_train_time_s\": 11.139862537384033}", "{\"n\": 19402, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.74, \"learn_time_ms\": 10328.919, \"total_train_time_s\": 12.212299585342407}", "{\"n\": 19403, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3619.74, \"learn_time_ms\": 10367.306, \"total_train_time_s\": 11.929510831832886}", "{\"n\": 19404, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.38, \"learn_time_ms\": 10215.723, \"total_train_time_s\": 12.42049503326416}", "{\"n\": 19405, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3617.38, \"learn_time_ms\": 10409.579, \"total_train_time_s\": 13.385630130767822}", "{\"n\": 19406, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 10389.129, \"total_train_time_s\": 12.222016334533691}", "{\"n\": 19407, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 10257.643, \"total_train_time_s\": 11.508097648620605}", "{\"n\": 19408, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3623.62, \"learn_time_ms\": 10292.482, \"total_train_time_s\": 12.57902979850769}", "{\"n\": 19409, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.78, \"learn_time_ms\": 10396.941, \"total_train_time_s\": 12.839109659194946}", "{\"n\": 19410, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3639.26, \"learn_time_ms\": 10247.513, \"total_train_time_s\": 11.388627290725708}", "{\"n\": 19411, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3639.06, \"learn_time_ms\": 10271.168, \"total_train_time_s\": 11.337777376174927}", "{\"n\": 19412, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.28, \"learn_time_ms\": 10230.92, \"total_train_time_s\": 11.778639793395996}", "{\"n\": 19413, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.35, \"learn_time_ms\": 10391.041, \"total_train_time_s\": 13.600425481796265}", "{\"n\": 19414, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.18, \"learn_time_ms\": 10391.945, \"total_train_time_s\": 12.397881269454956}", "{\"n\": 19415, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.58, \"learn_time_ms\": 10214.546, \"total_train_time_s\": 11.53577733039856}", "{\"n\": 19416, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3626.58, \"learn_time_ms\": 10204.051, \"total_train_time_s\": 12.117342948913574}", "{\"n\": 19417, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 10146.342, \"total_train_time_s\": 10.96798849105835}", "{\"n\": 19418, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3643.26, \"learn_time_ms\": 10096.886, \"total_train_time_s\": 12.075373411178589}", "{\"n\": 19419, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3643.77, \"learn_time_ms\": 10051.905, \"total_train_time_s\": 12.33823037147522}", "{\"n\": 19420, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3638.98, \"learn_time_ms\": 10147.714, \"total_train_time_s\": 12.295344829559326}", "{\"n\": 19421, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3642.14, \"learn_time_ms\": 10082.06, \"total_train_time_s\": 10.67781114578247}", "{\"n\": 19422, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3646.05, \"learn_time_ms\": 9967.732, \"total_train_time_s\": 10.673012495040894}", "{\"n\": 19423, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3649.38, \"learn_time_ms\": 9748.099, \"total_train_time_s\": 11.408133506774902}", "{\"n\": 19424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3637.36, \"learn_time_ms\": 9779.063, \"total_train_time_s\": 12.717976570129395}", "{\"n\": 19425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3646.16, \"learn_time_ms\": 9860.338, \"total_train_time_s\": 12.320731163024902}", "{\"n\": 19426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3648.27, \"learn_time_ms\": 9873.248, \"total_train_time_s\": 12.264547109603882}", "{\"n\": 19427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3641.02, \"learn_time_ms\": 9964.295, \"total_train_time_s\": 11.851459264755249}", "{\"n\": 19428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3642.69, \"learn_time_ms\": 9948.526, \"total_train_time_s\": 11.970853328704834}", "{\"n\": 19429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.92, \"learn_time_ms\": 9921.89, \"total_train_time_s\": 12.121844291687012}", "{\"n\": 19430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3632.05, \"learn_time_ms\": 9885.149, \"total_train_time_s\": 11.966219663619995}", "{\"n\": 19431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3634.39, \"learn_time_ms\": 10068.108, \"total_train_time_s\": 12.505463361740112}", "{\"n\": 19432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3631.19, \"learn_time_ms\": 10244.456, \"total_train_time_s\": 12.443210363388062}", "{\"n\": 19433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3638.83, \"learn_time_ms\": 10296.212, \"total_train_time_s\": 11.934274435043335}", "{\"n\": 19434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3629.97, \"learn_time_ms\": 10253.43, \"total_train_time_s\": 12.317373037338257}", "{\"n\": 19435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.84, \"learn_time_ms\": 10281.294, \"total_train_time_s\": 12.633392095565796}", "{\"n\": 19436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3639.06, \"learn_time_ms\": 10336.479, \"total_train_time_s\": 12.834962606430054}", "{\"n\": 19437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3636.33, \"learn_time_ms\": 10315.449, \"total_train_time_s\": 11.627450227737427}", "{\"n\": 19438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3633.03, \"learn_time_ms\": 10298.493, \"total_train_time_s\": 11.826547384262085}", "{\"n\": 19439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3634.62, \"learn_time_ms\": 10244.27, \"total_train_time_s\": 11.558533430099487}", "{\"n\": 19440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.0, \"learn_time_ms\": 10259.014, \"total_train_time_s\": 12.067708015441895}", "{\"n\": 19441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.29, \"learn_time_ms\": 10204.483, \"total_train_time_s\": 11.957757234573364}", "{\"n\": 19442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.31, \"learn_time_ms\": 10262.151, \"total_train_time_s\": 13.001147747039795}", "{\"n\": 19443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 10211.223, \"total_train_time_s\": 11.416628122329712}", "{\"n\": 19444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 10167.309, \"total_train_time_s\": 11.816841840744019}", "{\"n\": 19445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.99, \"learn_time_ms\": 10054.85, \"total_train_time_s\": 11.543891668319702}", "{\"n\": 19446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.99, \"learn_time_ms\": 9958.492, \"total_train_time_s\": 11.839271068572998}", "{\"n\": 19447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.59, \"learn_time_ms\": 10100.012, \"total_train_time_s\": 13.07679295539856}", "{\"n\": 19448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.49, \"learn_time_ms\": 10164.258, \"total_train_time_s\": 12.416525840759277}", "{\"n\": 19449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.36, \"learn_time_ms\": 10245.526, \"total_train_time_s\": 12.372449398040771}", "{\"n\": 19450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.72, \"learn_time_ms\": 10230.62, \"total_train_time_s\": 11.952149391174316}", "{\"n\": 19451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.72, \"learn_time_ms\": 10246.148, \"total_train_time_s\": 12.119074821472168}", "{\"n\": 19452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.01, \"learn_time_ms\": 10060.844, \"total_train_time_s\": 11.136290311813354}", "{\"n\": 19453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.77, \"learn_time_ms\": 10088.99, \"total_train_time_s\": 11.716277360916138}", "{\"n\": 19454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.77, \"learn_time_ms\": 10074.631, \"total_train_time_s\": 11.703711986541748}", "{\"n\": 19455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 10122.357, \"total_train_time_s\": 12.03303337097168}", "{\"n\": 19456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 10140.835, \"total_train_time_s\": 12.028674125671387}", "{\"n\": 19457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.47, \"learn_time_ms\": 10007.188, \"total_train_time_s\": 11.743423700332642}", "{\"n\": 19458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.47, \"learn_time_ms\": 10106.822, \"total_train_time_s\": 13.383259773254395}", "{\"n\": 19459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.35, \"learn_time_ms\": 9971.586, \"total_train_time_s\": 10.979075193405151}", "{\"n\": 19460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.13, \"learn_time_ms\": 10001.088, \"total_train_time_s\": 12.222233057022095}", "{\"n\": 19461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3653.13, \"learn_time_ms\": 9948.625, \"total_train_time_s\": 11.61036205291748}", "{\"n\": 19462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.83, \"learn_time_ms\": 9951.561, \"total_train_time_s\": 11.153734683990479}", "{\"n\": 19463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.41, \"learn_time_ms\": 9902.292, \"total_train_time_s\": 11.204642295837402}", "{\"n\": 19464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.1, \"learn_time_ms\": 9923.546, \"total_train_time_s\": 11.933470726013184}", "{\"n\": 19465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.1, \"learn_time_ms\": 9939.686, \"total_train_time_s\": 12.186728954315186}", "{\"n\": 19466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.78, \"learn_time_ms\": 9927.707, \"total_train_time_s\": 11.941457271575928}", "{\"n\": 19467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3669.11, \"learn_time_ms\": 9979.066, \"total_train_time_s\": 12.278368711471558}", "{\"n\": 19468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.38, \"learn_time_ms\": 9818.238, \"total_train_time_s\": 11.799110889434814}", "{\"n\": 19469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.28, \"learn_time_ms\": 10039.102, \"total_train_time_s\": 13.235485553741455}", "{\"n\": 19470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3682.43, \"learn_time_ms\": 10069.048, \"total_train_time_s\": 12.58103346824646}", "{\"n\": 19471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.63, \"learn_time_ms\": 10153.113, \"total_train_time_s\": 12.453899145126343}", "{\"n\": 19472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.63, \"learn_time_ms\": 10203.813, \"total_train_time_s\": 11.70151948928833}", "{\"n\": 19473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.79, \"learn_time_ms\": 10277.757, \"total_train_time_s\": 11.921519041061401}", "{\"n\": 19474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.79, \"learn_time_ms\": 10318.671, \"total_train_time_s\": 12.365723371505737}", "{\"n\": 19475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.92, \"learn_time_ms\": 10241.247, \"total_train_time_s\": 11.409061908721924}", "{\"n\": 19476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.92, \"learn_time_ms\": 10319.397, \"total_train_time_s\": 12.660259008407593}", "{\"n\": 19477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.45, \"learn_time_ms\": 10390.589, \"total_train_time_s\": 12.955261707305908}", "{\"n\": 19478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.6, \"learn_time_ms\": 10330.323, \"total_train_time_s\": 11.178253650665283}", "{\"n\": 19479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.6, \"learn_time_ms\": 10215.292, \"total_train_time_s\": 12.05634069442749}", "{\"n\": 19480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.24, \"learn_time_ms\": 10155.915, \"total_train_time_s\": 11.979526281356812}", "{\"n\": 19481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.96, \"learn_time_ms\": 10157.183, \"total_train_time_s\": 12.444446325302124}", "{\"n\": 19482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.34, \"learn_time_ms\": 10134.696, \"total_train_time_s\": 11.43070650100708}", "{\"n\": 19483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.34, \"learn_time_ms\": 10176.424, \"total_train_time_s\": 12.365582704544067}", "{\"n\": 19484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.35, \"learn_time_ms\": 10191.295, \"total_train_time_s\": 12.464169025421143}", "{\"n\": 19485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.73, \"learn_time_ms\": 10335.079, \"total_train_time_s\": 12.84436297416687}", "{\"n\": 19486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.51, \"learn_time_ms\": 10238.908, \"total_train_time_s\": 11.730088472366333}", "{\"n\": 19487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.51, \"learn_time_ms\": 10163.367, \"total_train_time_s\": 12.195713758468628}", "{\"n\": 19488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3693.28, \"learn_time_ms\": 10196.324, \"total_train_time_s\": 11.510474920272827}", "{\"n\": 19489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.07, \"learn_time_ms\": 10172.292, \"total_train_time_s\": 11.832411050796509}", "{\"n\": 19490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.01, \"learn_time_ms\": 10174.024, \"total_train_time_s\": 11.976622581481934}", "{\"n\": 19491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.01, \"learn_time_ms\": 10005.607, \"total_train_time_s\": 10.790522575378418}", "{\"n\": 19492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.26, \"learn_time_ms\": 10091.322, \"total_train_time_s\": 12.30247950553894}", "{\"n\": 19493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.26, \"learn_time_ms\": 10027.782, \"total_train_time_s\": 11.744360208511353}", "{\"n\": 19494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.83, \"learn_time_ms\": 10032.517, \"total_train_time_s\": 12.54785680770874}", "{\"n\": 19495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.24, \"learn_time_ms\": 10014.788, \"total_train_time_s\": 12.639765977859497}", "{\"n\": 19496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.88, \"learn_time_ms\": 9979.742, \"total_train_time_s\": 11.318840026855469}", "{\"n\": 19497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3719.08, \"learn_time_ms\": 9930.349, \"total_train_time_s\": 11.691081285476685}", "{\"n\": 19498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.66, \"learn_time_ms\": 9919.866, \"total_train_time_s\": 11.36766505241394}", "{\"n\": 19499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3732.4, \"learn_time_ms\": 9916.678, \"total_train_time_s\": 11.798478364944458}", "{\"n\": 19500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3727.52, \"learn_time_ms\": 9871.641, \"total_train_time_s\": 11.532115459442139}", "{\"n\": 19501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.72, \"learn_time_ms\": 10089.526, \"total_train_time_s\": 13.021238565444946}", "{\"n\": 19502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.72, \"learn_time_ms\": 10091.839, \"total_train_time_s\": 12.351093530654907}", "{\"n\": 19503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.46, \"learn_time_ms\": 10148.393, \"total_train_time_s\": 12.276691675186157}", "{\"n\": 19504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.4, \"learn_time_ms\": 10129.813, \"total_train_time_s\": 12.341912031173706}", "{\"n\": 19505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.63, \"learn_time_ms\": 10152.718, \"total_train_time_s\": 12.883584260940552}", "{\"n\": 19506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.63, \"learn_time_ms\": 10229.477, \"total_train_time_s\": 12.169801473617554}", "{\"n\": 19507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.83, \"learn_time_ms\": 10187.542, \"total_train_time_s\": 11.317784786224365}", "{\"n\": 19508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3717.8, \"learn_time_ms\": 10305.509, \"total_train_time_s\": 12.594903945922852}", "{\"n\": 19509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.88, \"learn_time_ms\": 10343.083, \"total_train_time_s\": 12.208179473876953}", "{\"n\": 19510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.88, \"learn_time_ms\": 10491.318, \"total_train_time_s\": 12.981113910675049}", "{\"n\": 19511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.93, \"learn_time_ms\": 10426.889, \"total_train_time_s\": 12.323553800582886}", "{\"n\": 19512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.03, \"learn_time_ms\": 10370.154, \"total_train_time_s\": 11.760609865188599}", "{\"n\": 19513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.42, \"learn_time_ms\": 10309.709, \"total_train_time_s\": 11.699127197265625}", "{\"n\": 19514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.0, \"learn_time_ms\": 10335.008, \"total_train_time_s\": 12.577779531478882}", "{\"n\": 19515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.9, \"learn_time_ms\": 10283.367, \"total_train_time_s\": 12.372487783432007}", "{\"n\": 19516, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.23, \"learn_time_ms\": 10360.087, \"total_train_time_s\": 12.894347429275513}", "{\"n\": 19517, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.23, \"learn_time_ms\": 10479.073, \"total_train_time_s\": 12.497474431991577}", "{\"n\": 19518, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3704.79, \"learn_time_ms\": 10442.011, \"total_train_time_s\": 12.256323337554932}", "{\"n\": 19519, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.03, \"learn_time_ms\": 10547.667, \"total_train_time_s\": 13.195008039474487}", "{\"n\": 19520, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3703.65, \"learn_time_ms\": 10370.522, \"total_train_time_s\": 11.271075010299683}", "{\"n\": 19521, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3706.38, \"learn_time_ms\": 10249.5, \"total_train_time_s\": 11.106056213378906}", "{\"n\": 19522, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3715.98, \"learn_time_ms\": 10258.126, \"total_train_time_s\": 11.897943496704102}", "{\"n\": 19523, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3716.03, \"learn_time_ms\": 10275.661, \"total_train_time_s\": 11.847091674804688}", "{\"n\": 19524, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3716.03, \"learn_time_ms\": 10324.572, \"total_train_time_s\": 13.070078372955322}", "{\"n\": 19525, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3713.86, \"learn_time_ms\": 10299.928, \"total_train_time_s\": 12.089789628982544}", "{\"n\": 19526, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3719.37, \"learn_time_ms\": 10157.769, \"total_train_time_s\": 11.497629165649414}", "{\"n\": 19527, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3715.86, \"learn_time_ms\": 10192.422, \"total_train_time_s\": 12.794885158538818}", "{\"n\": 19528, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3715.78, \"learn_time_ms\": 10125.938, \"total_train_time_s\": 11.602341413497925}", "{\"n\": 19529, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3720.72, \"learn_time_ms\": 9984.056, \"total_train_time_s\": 11.838840961456299}", "{\"n\": 19530, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3718.91, \"learn_time_ms\": 10062.25, \"total_train_time_s\": 12.01650071144104}", "{\"n\": 19531, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3710.02, \"learn_time_ms\": 10163.165, \"total_train_time_s\": 12.113295555114746}", "{\"n\": 19532, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3710.02, \"learn_time_ms\": 10181.37, \"total_train_time_s\": 12.00395679473877}", "{\"n\": 19533, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.85, \"learn_time_ms\": 10198.784, \"total_train_time_s\": 12.017431259155273}", "{\"n\": 19534, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.85, \"learn_time_ms\": 10102.238, \"total_train_time_s\": 12.10685658454895}", "{\"n\": 19535, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3696.81, \"learn_time_ms\": 10107.589, \"total_train_time_s\": 12.178499937057495}", "{\"n\": 19536, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3687.94, \"learn_time_ms\": 10166.348, \"total_train_time_s\": 12.096869707107544}", "{\"n\": 19537, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3695.88, \"learn_time_ms\": 9978.035, \"total_train_time_s\": 10.969289064407349}", "{\"n\": 19538, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3697.09, \"learn_time_ms\": 10058.071, \"total_train_time_s\": 12.372238636016846}", "{\"n\": 19539, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3697.09, \"learn_time_ms\": 10000.268, \"total_train_time_s\": 11.253925323486328}", "{\"n\": 19540, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3699.83, \"learn_time_ms\": 10062.347, \"total_train_time_s\": 12.651724576950073}", "{\"n\": 19541, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.76, \"learn_time_ms\": 10088.625, \"total_train_time_s\": 12.360811710357666}", "{\"n\": 19542, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.24, \"learn_time_ms\": 10136.299, \"total_train_time_s\": 12.513447046279907}", "{\"n\": 19543, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3702.24, \"learn_time_ms\": 10209.57, \"total_train_time_s\": 12.738553762435913}", "{\"n\": 19544, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3715.55, \"learn_time_ms\": 10161.628, \"total_train_time_s\": 11.648572206497192}", "{\"n\": 19545, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3719.09, \"learn_time_ms\": 10169.285, \"total_train_time_s\": 12.275171518325806}", "{\"n\": 19546, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3719.09, \"learn_time_ms\": 10264.471, \"total_train_time_s\": 13.060212850570679}", "{\"n\": 19547, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3712.6, \"learn_time_ms\": 10454.135, \"total_train_time_s\": 12.88408350944519}", "{\"n\": 19548, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3715.68, \"learn_time_ms\": 10550.589, \"total_train_time_s\": 13.341510772705078}", "{\"n\": 19549, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3718.6, \"learn_time_ms\": 10653.646, \"total_train_time_s\": 12.272563695907593}", "{\"n\": 19550, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3718.6, \"learn_time_ms\": 10598.303, \"total_train_time_s\": 12.088417530059814}", "{\"n\": 19551, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3723.06, \"learn_time_ms\": 10482.73, \"total_train_time_s\": 11.183005094528198}", "{\"n\": 19552, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3729.06, \"learn_time_ms\": 10293.435, \"total_train_time_s\": 10.610587358474731}", "{\"n\": 19553, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3731.67, \"learn_time_ms\": 10336.911, \"total_train_time_s\": 13.164828062057495}", "{\"n\": 19554, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3731.67, \"learn_time_ms\": 10386.68, \"total_train_time_s\": 12.14227032661438}", "{\"n\": 19555, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3731.46, \"learn_time_ms\": 10376.45, \"total_train_time_s\": 12.147242069244385}", "{\"n\": 19556, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3735.26, \"learn_time_ms\": 10302.614, \"total_train_time_s\": 12.298838376998901}", "{\"n\": 19557, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.46, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3737.23, \"learn_time_ms\": 10137.171, \"total_train_time_s\": 11.158661842346191}", "{\"n\": 19558, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3730.21, \"learn_time_ms\": 9996.902, \"total_train_time_s\": 11.899084091186523}", "{\"n\": 19559, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3724.33, \"learn_time_ms\": 9894.438, \"total_train_time_s\": 11.20565938949585}", "{\"n\": 19560, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3725.11, \"learn_time_ms\": 9878.117, \"total_train_time_s\": 11.906054973602295}", "{\"n\": 19561, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3725.11, \"learn_time_ms\": 9895.484, \"total_train_time_s\": 11.37293028831482}", "{\"n\": 19562, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3710.95, \"learn_time_ms\": 10120.808, \"total_train_time_s\": 12.879281282424927}", "{\"n\": 19563, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3710.95, \"learn_time_ms\": 10008.798, \"total_train_time_s\": 12.0754873752594}", "{\"n\": 19564, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3707.8, \"learn_time_ms\": 9931.926, \"total_train_time_s\": 11.373097896575928}", "{\"n\": 19565, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3710.67, \"learn_time_ms\": 9848.928, \"total_train_time_s\": 11.30302119255066}", "{\"n\": 19566, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3711.81, \"learn_time_ms\": 9867.645, \"total_train_time_s\": 12.47577452659607}", "{\"n\": 19567, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3711.81, \"learn_time_ms\": 9916.05, \"total_train_time_s\": 11.671742916107178}", "{\"n\": 19568, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 3.93, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3716.99, \"learn_time_ms\": 9970.135, \"total_train_time_s\": 12.45872187614441}", "{\"n\": 19569, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.09, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3700.44, \"learn_time_ms\": 10079.768, \"total_train_time_s\": 12.460349559783936}", "{\"n\": 19570, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3701.7, \"learn_time_ms\": 10027.114, \"total_train_time_s\": 11.38837480545044}", "{\"n\": 19571, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3692.92, \"learn_time_ms\": 10046.803, \"total_train_time_s\": 11.56815791130066}", "{\"n\": 19572, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3684.87, \"learn_time_ms\": 9975.178, \"total_train_time_s\": 12.118799924850464}", "{\"n\": 19573, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.06, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3688.37, \"learn_time_ms\": 9957.149, \"total_train_time_s\": 11.91145396232605}", "{\"n\": 19574, \"episode_reward_min\": -6.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3690.16, \"learn_time_ms\": 10068.447, \"total_train_time_s\": 12.493287801742554}", "{\"n\": 19575, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3687.37, \"learn_time_ms\": 10132.011, \"total_train_time_s\": 11.940912008285522}", "{\"n\": 19576, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3692.82, \"learn_time_ms\": 10017.029, \"total_train_time_s\": 11.311509609222412}", "{\"n\": 19577, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.66, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3692.82, \"learn_time_ms\": 9929.615, \"total_train_time_s\": 10.779470443725586}", "{\"n\": 19578, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3698.35, \"learn_time_ms\": 9751.381, \"total_train_time_s\": 10.630971670150757}", "{\"n\": 19579, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3687.24, \"learn_time_ms\": 9690.708, \"total_train_time_s\": 11.705033540725708}", "{\"n\": 19580, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3695.63, \"learn_time_ms\": 9718.636, \"total_train_time_s\": 11.677928447723389}", "{\"n\": 19581, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.68, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3695.63, \"learn_time_ms\": 9818.206, \"total_train_time_s\": 12.654483795166016}", "{\"n\": 19582, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3694.47, \"learn_time_ms\": 9842.58, \"total_train_time_s\": 12.442076444625854}", "{\"n\": 19583, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.8, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3685.81, \"learn_time_ms\": 9919.565, \"total_train_time_s\": 12.69314455986023}", "{\"n\": 19584, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 9939.468, \"total_train_time_s\": 12.683120965957642}", "{\"n\": 19585, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 9943.809, \"total_train_time_s\": 12.009339332580566}", "{\"n\": 19586, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3687.42, \"learn_time_ms\": 10063.709, \"total_train_time_s\": 12.533336162567139}", "{\"n\": 19587, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3705.64, \"learn_time_ms\": 10122.363, \"total_train_time_s\": 11.41266655921936}", "{\"n\": 19588, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3705.64, \"learn_time_ms\": 10254.267, \"total_train_time_s\": 12.057239055633545}", "{\"n\": 19589, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3706.13, \"learn_time_ms\": 10308.688, \"total_train_time_s\": 12.246819972991943}", "{\"n\": 19590, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.7, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3699.07, \"learn_time_ms\": 10463.468, \"total_train_time_s\": 13.198740482330322}", "{\"n\": 19591, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3696.04, \"learn_time_ms\": 10379.497, \"total_train_time_s\": 11.737885475158691}", "{\"n\": 19592, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.84, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3696.04, \"learn_time_ms\": 10312.471, \"total_train_time_s\": 11.743909358978271}", "{\"n\": 19593, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.79, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3697.79, \"learn_time_ms\": 10306.818, \"total_train_time_s\": 12.665255784988403}", "{\"n\": 19594, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.81, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3698.79, \"learn_time_ms\": 10191.573, \"total_train_time_s\": 11.529494285583496}", "{\"n\": 19595, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3692.93, \"learn_time_ms\": 10193.747, \"total_train_time_s\": 12.022722721099854}", "{\"n\": 19596, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.83, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3692.93, \"learn_time_ms\": 10155.376, \"total_train_time_s\": 12.128304243087769}", "{\"n\": 19597, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.87, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3687.99, \"learn_time_ms\": 10153.985, \"total_train_time_s\": 11.395496845245361}", "{\"n\": 19598, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3684.72, \"learn_time_ms\": 10147.997, \"total_train_time_s\": 11.920806169509888}", "{\"n\": 19599, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.95, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3684.72, \"learn_time_ms\": 10163.774, \"total_train_time_s\": 12.458420276641846}", "{\"n\": 19600, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.02, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3683.56, \"learn_time_ms\": 10112.735, \"total_train_time_s\": 12.773905038833618}", "{\"n\": 19601, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3677.76, \"learn_time_ms\": 10224.87, \"total_train_time_s\": 12.844831228256226}", "{\"n\": 19602, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3677.76, \"learn_time_ms\": 10253.163, \"total_train_time_s\": 12.012343406677246}", "{\"n\": 19603, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.1, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3677.76, \"learn_time_ms\": 10243.602, \"total_train_time_s\": 12.466929912567139}", "{\"n\": 19604, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.05, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3670.62, \"learn_time_ms\": 10365.708, \"total_train_time_s\": 12.754228353500366}", "{\"n\": 19605, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3662.1, \"learn_time_ms\": 10294.17, \"total_train_time_s\": 11.26774549484253}", "{\"n\": 19606, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3662.1, \"learn_time_ms\": 10247.156, \"total_train_time_s\": 11.653335094451904}", "{\"n\": 19607, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3657.54, \"learn_time_ms\": 10302.138, \"total_train_time_s\": 11.907069444656372}", "{\"n\": 19608, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 19.0, \"episode_len_mean\": 3653.8, \"learn_time_ms\": 10220.461, \"total_train_time_s\": 11.122954607009888}", "{\"n\": 19609, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.27, \"learn_time_ms\": 10193.297, \"total_train_time_s\": 12.128119468688965}", "{\"n\": 19610, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.27, \"learn_time_ms\": 10134.861, \"total_train_time_s\": 12.126508235931396}", "{\"n\": 19611, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.3, \"learn_time_ms\": 10038.415, \"total_train_time_s\": 11.897244215011597}", "{\"n\": 19612, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.13, \"learn_time_ms\": 10090.578, \"total_train_time_s\": 12.505953550338745}", "{\"n\": 19613, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.13, \"learn_time_ms\": 10030.971, \"total_train_time_s\": 11.889652729034424}", "{\"n\": 19614, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3659.96, \"learn_time_ms\": 9896.948, \"total_train_time_s\": 11.380311250686646}", "{\"n\": 19615, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.45, \"learn_time_ms\": 9963.339, \"total_train_time_s\": 12.027160167694092}", "{\"n\": 19616, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.45, \"learn_time_ms\": 9901.642, \"total_train_time_s\": 11.056567907333374}", "{\"n\": 19617, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 3.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.45, \"learn_time_ms\": 9838.142, \"total_train_time_s\": 11.251846075057983}", "{\"n\": 19618, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.61, \"learn_time_ms\": 9867.606, \"total_train_time_s\": 11.423411130905151}", "{\"n\": 19619, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.05, \"learn_time_ms\": 9852.837, \"total_train_time_s\": 12.062453985214233}", "{\"n\": 19620, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.05, \"learn_time_ms\": 9767.996, \"total_train_time_s\": 11.281978607177734}", "{\"n\": 19621, \"episode_reward_min\": -7.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.61, \"learn_time_ms\": 9825.744, \"total_train_time_s\": 12.460464239120483}", "{\"n\": 19622, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.0, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.19, \"learn_time_ms\": 9835.737, \"total_train_time_s\": 12.637961387634277}", "{\"n\": 19623, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.01, \"learn_time_ms\": 9964.781, \"total_train_time_s\": 13.240561485290527}", "{\"n\": 19624, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.01, \"learn_time_ms\": 10062.023, \"total_train_time_s\": 12.437959909439087}", "{\"n\": 19625, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.97, \"learn_time_ms\": 10048.787, \"total_train_time_s\": 11.870762348175049}", "{\"n\": 19626, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.97, \"learn_time_ms\": 10145.613, \"total_train_time_s\": 12.00078558921814}", "{\"n\": 19627, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.71, \"learn_time_ms\": 10251.152, \"total_train_time_s\": 12.329214572906494}", "{\"n\": 19628, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.63, \"learn_time_ms\": 10312.313, \"total_train_time_s\": 12.017369985580444}", "{\"n\": 19629, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.0, \"learn_time_ms\": 10316.021, \"total_train_time_s\": 12.06621241569519}", "{\"n\": 19630, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.18, \"learn_time_ms\": 10444.239, \"total_train_time_s\": 12.557358980178833}", "{\"n\": 19631, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3653.17, \"learn_time_ms\": 10352.335, \"total_train_time_s\": 11.58706283569336}", "{\"n\": 19632, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3653.17, \"learn_time_ms\": 10322.466, \"total_train_time_s\": 12.327461242675781}", "{\"n\": 19633, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.87, \"learn_time_ms\": 10208.211, \"total_train_time_s\": 12.05574083328247}", "{\"n\": 19634, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.48, \"learn_time_ms\": 10127.164, \"total_train_time_s\": 11.568131685256958}", "{\"n\": 19635, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.18, \"learn_time_ms\": 10204.747, \"total_train_time_s\": 12.61068320274353}", "{\"n\": 19636, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.18, \"learn_time_ms\": 10277.643, \"total_train_time_s\": 12.727648258209229}", "{\"n\": 19637, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3639.67, \"learn_time_ms\": 10185.733, \"total_train_time_s\": 11.405415534973145}", "{\"n\": 19638, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.67, \"learn_time_ms\": 10216.344, \"total_train_time_s\": 12.36955976486206}", "{\"n\": 19639, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3653.35, \"learn_time_ms\": 10237.671, \"total_train_time_s\": 12.271799802780151}", "{\"n\": 19640, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.94, \"learn_time_ms\": 10252.394, \"total_train_time_s\": 12.739563703536987}", "{\"n\": 19641, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3654.88, \"learn_time_ms\": 10379.867, \"total_train_time_s\": 12.869152784347534}", "{\"n\": 19642, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.27, \"learn_time_ms\": 10321.863, \"total_train_time_s\": 11.761786937713623}", "{\"n\": 19643, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.0, \"learn_time_ms\": 10299.564, \"total_train_time_s\": 11.878302097320557}", "{\"n\": 19644, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.0, \"learn_time_ms\": 10415.042, \"total_train_time_s\": 12.757743835449219}", "{\"n\": 19645, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.42, \"learn_time_ms\": 10362.138, \"total_train_time_s\": 12.075383424758911}", "{\"n\": 19646, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.08, \"learn_time_ms\": 10244.094, \"total_train_time_s\": 11.572185039520264}", "{\"n\": 19647, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.24, \"learn_time_ms\": 10280.895, \"total_train_time_s\": 11.818561315536499}", "{\"n\": 19648, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.24, \"learn_time_ms\": 10144.621, \"total_train_time_s\": 10.994236469268799}", "{\"n\": 19649, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.75, \"learn_time_ms\": 10021.024, \"total_train_time_s\": 11.009801149368286}", "{\"n\": 19650, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.87, \"learn_time_ms\": 9922.94, \"total_train_time_s\": 11.723088026046753}", "{\"n\": 19651, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.0, \"learn_time_ms\": 9820.364, \"total_train_time_s\": 11.792076587677002}", "{\"n\": 19652, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.0, \"learn_time_ms\": 9749.608, \"total_train_time_s\": 11.10550856590271}", "{\"n\": 19653, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3627.09, \"learn_time_ms\": 9698.59, \"total_train_time_s\": 11.33055830001831}", "{\"n\": 19654, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3632.3, \"learn_time_ms\": 9579.223, \"total_train_time_s\": 11.538437604904175}", "{\"n\": 19655, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.15, \"learn_time_ms\": 9585.402, \"total_train_time_s\": 12.144338846206665}", "{\"n\": 19656, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.01, \"learn_time_ms\": 9604.127, \"total_train_time_s\": 11.783592224121094}", "{\"n\": 19657, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.51, \"learn_time_ms\": 9577.24, \"total_train_time_s\": 11.530384302139282}", "{\"n\": 19658, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.3, \"learn_time_ms\": 9754.768, \"total_train_time_s\": 12.763313055038452}", "{\"n\": 19659, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 4.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.3, \"learn_time_ms\": 9862.958, \"total_train_time_s\": 12.127596855163574}", "{\"n\": 19660, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.88, \"learn_time_ms\": 9868.465, \"total_train_time_s\": 11.774612188339233}", "{\"n\": 19661, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3637.33, \"learn_time_ms\": 9874.461, \"total_train_time_s\": 11.871652841567993}", "{\"n\": 19662, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.58, \"learn_time_ms\": 9896.761, \"total_train_time_s\": 11.300690650939941}", "{\"n\": 19663, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.49, \"learn_time_ms\": 9944.518, \"total_train_time_s\": 11.864305019378662}", "{\"n\": 19664, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.73, \"learn_time_ms\": 9925.915, \"total_train_time_s\": 11.363011598587036}", "{\"n\": 19665, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3647.73, \"learn_time_ms\": 9888.686, \"total_train_time_s\": 11.798097372055054}", "{\"n\": 19666, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3653.19, \"learn_time_ms\": 9947.851, \"total_train_time_s\": 12.345063924789429}", "{\"n\": 19667, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.64, \"learn_time_ms\": 9981.792, \"total_train_time_s\": 11.856196880340576}", "{\"n\": 19668, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3651.06, \"learn_time_ms\": 9946.386, \"total_train_time_s\": 12.424387693405151}", "{\"n\": 19669, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.91, \"learn_time_ms\": 9910.907, \"total_train_time_s\": 11.73465085029602}", "{\"n\": 19670, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 4.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3657.91, \"learn_time_ms\": 9812.101, \"total_train_time_s\": 10.782484531402588}", "{\"n\": 19671, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.14, \"learn_time_ms\": 9792.1, \"total_train_time_s\": 11.679708003997803}", "{\"n\": 19672, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.08, \"learn_time_ms\": 9748.139, \"total_train_time_s\": 10.856933116912842}", "{\"n\": 19673, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.08, \"learn_time_ms\": 9709.843, \"total_train_time_s\": 11.442800045013428}", "{\"n\": 19674, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.08, \"learn_time_ms\": 9879.233, \"total_train_time_s\": 13.050301551818848}", "{\"n\": 19675, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.31, \"learn_time_ms\": 9917.248, \"total_train_time_s\": 12.167900085449219}", "{\"n\": 19676, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.24, \"learn_time_ms\": 10040.734, \"total_train_time_s\": 13.631349086761475}", "{\"n\": 19677, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.24, \"learn_time_ms\": 10203.302, \"total_train_time_s\": 13.491844415664673}", "{\"n\": 19678, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.24, \"learn_time_ms\": 10207.57, \"total_train_time_s\": 12.428139209747314}", "{\"n\": 19679, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.57, \"learn_time_ms\": 10304.646, \"total_train_time_s\": 12.758699655532837}", "{\"n\": 19680, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.0, \"learn_time_ms\": 10429.148, \"total_train_time_s\": 12.035672903060913}", "{\"n\": 19681, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.0, \"learn_time_ms\": 10519.731, \"total_train_time_s\": 12.561951637268066}", "{\"n\": 19682, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.0, \"learn_time_ms\": 10631.846, \"total_train_time_s\": 11.967318296432495}", "{\"n\": 19683, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10659.302, \"total_train_time_s\": 11.701556921005249}", "{\"n\": 19684, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10509.787, \"total_train_time_s\": 11.534040927886963}", "{\"n\": 19685, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.85, \"learn_time_ms\": 10540.123, \"total_train_time_s\": 12.445174932479858}", "{\"n\": 19686, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 4.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3646.1, \"learn_time_ms\": 10301.189, \"total_train_time_s\": 11.211349964141846}", "{\"n\": 19687, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.26, \"learn_time_ms\": 10284.621, \"total_train_time_s\": 13.338611364364624}", "{\"n\": 19688, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.26, \"learn_time_ms\": 10228.249, \"total_train_time_s\": 11.901022911071777}", "{\"n\": 19689, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.26, \"learn_time_ms\": 10037.639, \"total_train_time_s\": 10.802027702331543}", "{\"n\": 19690, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.13, \"learn_time_ms\": 10079.8, \"total_train_time_s\": 12.419404983520508}", "{\"n\": 19691, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3668.08, \"learn_time_ms\": 9952.647, \"total_train_time_s\": 11.311617851257324}", "{\"n\": 19692, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3668.08, \"learn_time_ms\": 9966.064, \"total_train_time_s\": 12.157375574111938}", "{\"n\": 19693, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3667.04, \"learn_time_ms\": 10008.605, \"total_train_time_s\": 12.168383598327637}", "{\"n\": 19694, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.03, \"learn_time_ms\": 10048.677, \"total_train_time_s\": 11.962062120437622}", "{\"n\": 19695, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.37, \"learn_time_ms\": 10017.122, \"total_train_time_s\": 12.151612758636475}", "{\"n\": 19696, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.37, \"learn_time_ms\": 10026.956, \"total_train_time_s\": 11.29269289970398}", "{\"n\": 19697, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3682.29, \"learn_time_ms\": 9991.314, \"total_train_time_s\": 12.96828031539917}", "{\"n\": 19698, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.19, \"learn_time_ms\": 10134.951, \"total_train_time_s\": 13.353023767471313}", "{\"n\": 19699, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3680.32, \"learn_time_ms\": 10260.385, \"total_train_time_s\": 12.101279735565186}", "{\"n\": 19700, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.71, \"learn_time_ms\": 10189.303, \"total_train_time_s\": 11.771814584732056}", "{\"n\": 19701, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.71, \"learn_time_ms\": 10197.766, \"total_train_time_s\": 11.380170345306396}", "{\"n\": 19702, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3683.34, \"learn_time_ms\": 10224.284, \"total_train_time_s\": 12.35847806930542}", "{\"n\": 19703, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3675.36, \"learn_time_ms\": 10212.584, \"total_train_time_s\": 12.009443759918213}", "{\"n\": 19704, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.91, \"learn_time_ms\": 10187.799, \"total_train_time_s\": 11.723429918289185}", "{\"n\": 19705, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.55, \"learn_time_ms\": 10086.055, \"total_train_time_s\": 11.149183511734009}", "{\"n\": 19706, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.55, \"learn_time_ms\": 10141.563, \"total_train_time_s\": 11.908346176147461}", "{\"n\": 19707, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.55, \"learn_time_ms\": 10014.943, \"total_train_time_s\": 11.71364712715149}", "{\"n\": 19708, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.6, \"learn_time_ms\": 9862.977, \"total_train_time_s\": 11.774112701416016}", "{\"n\": 19709, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.45, \"learn_time_ms\": 9857.137, \"total_train_time_s\": 12.045419216156006}", "{\"n\": 19710, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3677.45, \"learn_time_ms\": 9942.775, \"total_train_time_s\": 12.607105493545532}", "{\"n\": 19711, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3681.77, \"learn_time_ms\": 9993.735, \"total_train_time_s\": 11.910583734512329}", "{\"n\": 19712, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3686.0, \"learn_time_ms\": 10084.929, \"total_train_time_s\": 13.272073984146118}", "{\"n\": 19713, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.98, \"learn_time_ms\": 10082.508, \"total_train_time_s\": 11.97655701637268}", "{\"n\": 19714, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.98, \"learn_time_ms\": 10091.327, \"total_train_time_s\": 11.769713878631592}", "{\"n\": 19715, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.48, \"learn_time_ms\": 10203.438, \"total_train_time_s\": 12.237746715545654}", "{\"n\": 19716, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3690.17, \"learn_time_ms\": 10276.733, \"total_train_time_s\": 12.575077056884766}", "{\"n\": 19717, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3699.44, \"learn_time_ms\": 10489.828, \"total_train_time_s\": 13.842320680618286}", "{\"n\": 19718, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3699.44, \"learn_time_ms\": 10556.723, \"total_train_time_s\": 12.447836637496948}", "{\"n\": 19719, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3698.3, \"learn_time_ms\": 10639.031, \"total_train_time_s\": 12.814825534820557}", "{\"n\": 19720, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3698.48, \"learn_time_ms\": 10614.793, \"total_train_time_s\": 12.36409616470337}", "{\"n\": 19721, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3704.43, \"learn_time_ms\": 10607.754, \"total_train_time_s\": 11.873921394348145}", "{\"n\": 19722, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3704.43, \"learn_time_ms\": 10475.562, \"total_train_time_s\": 11.999250888824463}", "{\"n\": 19723, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3690.03, \"learn_time_ms\": 10448.519, \"total_train_time_s\": 11.71784520149231}", "{\"n\": 19724, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3691.32, \"learn_time_ms\": 10556.176, \"total_train_time_s\": 12.868443489074707}", "{\"n\": 19725, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3691.32, \"learn_time_ms\": 10513.622, \"total_train_time_s\": 11.808529138565063}", "{\"n\": 19726, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3697.85, \"learn_time_ms\": 10429.219, \"total_train_time_s\": 11.737041473388672}", "{\"n\": 19727, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10312.255, \"total_train_time_s\": 12.662991285324097}", "{\"n\": 19728, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10187.241, \"total_train_time_s\": 11.17069387435913}", "{\"n\": 19729, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.46, \"learn_time_ms\": 10043.553, \"total_train_time_s\": 11.37890625}", "{\"n\": 19730, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.72, \"learn_time_ms\": 10081.075, \"total_train_time_s\": 12.734633445739746}", "{\"n\": 19731, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.11, \"learn_time_ms\": 10159.217, \"total_train_time_s\": 12.616512537002563}", "{\"n\": 19732, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.11, \"learn_time_ms\": 10157.534, \"total_train_time_s\": 11.936676025390625}", "{\"n\": 19733, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.11, \"learn_time_ms\": 10133.895, \"total_train_time_s\": 11.51622223854065}", "{\"n\": 19734, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3677.81, \"learn_time_ms\": 9947.335, \"total_train_time_s\": 10.998708963394165}", "{\"n\": 19735, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.55, \"learn_time_ms\": 10026.45, \"total_train_time_s\": 12.58010983467102}", "{\"n\": 19736, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.55, \"learn_time_ms\": 10104.092, \"total_train_time_s\": 12.484786033630371}", "{\"n\": 19737, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.26, \"learn_time_ms\": 10067.886, \"total_train_time_s\": 12.31479549407959}", "{\"n\": 19738, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.53, \"learn_time_ms\": 10105.418, \"total_train_time_s\": 11.577199697494507}", "{\"n\": 19739, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3701.53, \"learn_time_ms\": 10191.464, \"total_train_time_s\": 12.264091968536377}", "{\"n\": 19740, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3696.24, \"learn_time_ms\": 10157.35, \"total_train_time_s\": 12.361969709396362}", "{\"n\": 19741, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.08, \"learn_time_ms\": 10063.791, \"total_train_time_s\": 11.690659284591675}", "{\"n\": 19742, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.57, \"learn_time_ms\": 10087.557, \"total_train_time_s\": 12.200223922729492}", "{\"n\": 19743, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.57, \"learn_time_ms\": 10197.412, \"total_train_time_s\": 12.595900774002075}", "{\"n\": 19744, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.13, \"learn_time_ms\": 10357.483, \"total_train_time_s\": 12.606447696685791}", "{\"n\": 19745, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.79, \"learn_time_ms\": 10368.215, \"total_train_time_s\": 12.739086627960205}", "{\"n\": 19746, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.79, \"learn_time_ms\": 10305.209, \"total_train_time_s\": 11.896262407302856}", "{\"n\": 19747, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.51, \"learn_time_ms\": 10151.028, \"total_train_time_s\": 10.750426054000854}", "{\"n\": 19748, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.91, \"learn_time_ms\": 10143.639, \"total_train_time_s\": 11.514214277267456}", "{\"n\": 19749, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.19, \"learn_time_ms\": 10097.814, \"total_train_time_s\": 11.800225496292114}", "{\"n\": 19750, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.19, \"learn_time_ms\": 9997.352, \"total_train_time_s\": 11.42219591140747}", "{\"n\": 19751, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.69, \"learn_time_ms\": 10179.428, \"total_train_time_s\": 13.492098331451416}", "{\"n\": 19752, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.86, \"learn_time_ms\": 10111.608, \"total_train_time_s\": 11.473413467407227}", "{\"n\": 19753, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3702.2, \"learn_time_ms\": 10118.664, \"total_train_time_s\": 12.65137243270874}", "{\"n\": 19754, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.42, \"learn_time_ms\": 9967.906, \"total_train_time_s\": 11.085091829299927}", "{\"n\": 19755, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.42, \"learn_time_ms\": 9857.913, \"total_train_time_s\": 11.611441850662231}", "{\"n\": 19756, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.26, \"learn_time_ms\": 9939.695, \"total_train_time_s\": 12.721410512924194}", "{\"n\": 19757, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.02, \"learn_time_ms\": 10016.296, \"total_train_time_s\": 11.504857063293457}", "{\"n\": 19758, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.39, \"learn_time_ms\": 10063.683, \"total_train_time_s\": 12.008754968643188}", "{\"n\": 19759, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3704.39, \"learn_time_ms\": 10076.898, \"total_train_time_s\": 11.899943351745605}", "{\"n\": 19760, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.27, \"learn_time_ms\": 10179.14, \"total_train_time_s\": 12.409316062927246}", "{\"n\": 19761, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.27, \"learn_time_ms\": 10073.556, \"total_train_time_s\": 12.422156810760498}", "{\"n\": 19762, \"episode_reward_min\": -10.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.4, \"learn_time_ms\": 10160.574, \"total_train_time_s\": 12.343018293380737}", "{\"n\": 19763, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3713.0, \"learn_time_ms\": 10110.619, \"total_train_time_s\": 12.162264585494995}", "{\"n\": 19764, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.12, \"learn_time_ms\": 10253.158, \"total_train_time_s\": 12.522686958312988}", "{\"n\": 19765, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.75, \"learn_time_ms\": 10315.385, \"total_train_time_s\": 12.25623106956482}", "{\"n\": 19766, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.75, \"learn_time_ms\": 10306.231, \"total_train_time_s\": 12.63082242012024}", "{\"n\": 19767, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.82, \"learn_time_ms\": 10370.49, \"total_train_time_s\": 12.186745643615723}", "{\"n\": 19768, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.21, \"learn_time_ms\": 10418.492, \"total_train_time_s\": 12.516894102096558}", "{\"n\": 19769, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.09, \"learn_time_ms\": 10445.486, \"total_train_time_s\": 12.223328351974487}", "{\"n\": 19770, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.09, \"learn_time_ms\": 10452.58, \"total_train_time_s\": 12.483929872512817}", "{\"n\": 19771, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.92, \"learn_time_ms\": 10462.347, \"total_train_time_s\": 12.561213254928589}", "{\"n\": 19772, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.29, \"learn_time_ms\": 10445.879, \"total_train_time_s\": 12.156177282333374}", "{\"n\": 19773, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3722.84, \"learn_time_ms\": 10346.51, \"total_train_time_s\": 11.149492502212524}", "{\"n\": 19774, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3726.3, \"learn_time_ms\": 10179.015, \"total_train_time_s\": 10.848016023635864}", "{\"n\": 19775, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3725.0, \"learn_time_ms\": 10115.803, \"total_train_time_s\": 11.604722023010254}", "{\"n\": 19776, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.93, \"learn_time_ms\": 10000.931, \"total_train_time_s\": 11.450922966003418}", "{\"n\": 19777, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.93, \"learn_time_ms\": 9846.761, \"total_train_time_s\": 10.634527444839478}", "{\"n\": 19778, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.26, \"learn_time_ms\": 9822.475, \"total_train_time_s\": 12.267107725143433}", "{\"n\": 19779, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.16, \"learn_time_ms\": 9764.927, \"total_train_time_s\": 11.632739782333374}", "{\"n\": 19780, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.33, \"learn_time_ms\": 9683.914, \"total_train_time_s\": 11.655881881713867}", "{\"n\": 19781, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.22, \"learn_time_ms\": 9747.315, \"total_train_time_s\": 13.147387266159058}", "{\"n\": 19782, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.03, \"learn_time_ms\": 9810.169, \"total_train_time_s\": 12.816843032836914}", "{\"n\": 19783, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.01, \"learn_time_ms\": 9864.387, \"total_train_time_s\": 11.731449365615845}", "{\"n\": 19784, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.01, \"learn_time_ms\": 9995.454, \"total_train_time_s\": 12.192230701446533}", "{\"n\": 19785, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.27, \"learn_time_ms\": 10091.739, \"total_train_time_s\": 12.603413105010986}", "{\"n\": 19786, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3690.97, \"learn_time_ms\": 10176.162, \"total_train_time_s\": 12.265353918075562}", "{\"n\": 19787, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3685.62, \"learn_time_ms\": 10356.912, \"total_train_time_s\": 12.438745021820068}", "{\"n\": 19788, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3687.88, \"learn_time_ms\": 10406.913, \"total_train_time_s\": 12.732654571533203}", "{\"n\": 19789, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.1, \"learn_time_ms\": 10548.626, \"total_train_time_s\": 13.085811376571655}", "{\"n\": 19790, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.36, \"learn_time_ms\": 10585.519, \"total_train_time_s\": 12.05589747428894}", "{\"n\": 19791, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.36, \"learn_time_ms\": 10531.123, \"total_train_time_s\": 12.615206718444824}", "{\"n\": 19792, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3701.03, \"learn_time_ms\": 10474.227, \"total_train_time_s\": 12.233206033706665}", "{\"n\": 19793, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3695.48, \"learn_time_ms\": 10542.212, \"total_train_time_s\": 12.391952991485596}", "{\"n\": 19794, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.77, \"learn_time_ms\": 10536.537, \"total_train_time_s\": 12.122804403305054}", "{\"n\": 19795, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.08, \"learn_time_ms\": 10455.848, \"total_train_time_s\": 11.746403932571411}", "{\"n\": 19796, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.08, \"learn_time_ms\": 10400.101, \"total_train_time_s\": 11.754748582839966}", "{\"n\": 19797, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.8, \"learn_time_ms\": 10436.197, \"total_train_time_s\": 12.806972980499268}", "{\"n\": 19798, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.63, \"learn_time_ms\": 10355.257, \"total_train_time_s\": 11.895105123519897}", "{\"n\": 19799, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.16, \"learn_time_ms\": 10216.953, \"total_train_time_s\": 11.687381267547607}", "{\"n\": 19800, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.16, \"learn_time_ms\": 10299.604, \"total_train_time_s\": 12.86225152015686}", "{\"n\": 19801, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.99, \"learn_time_ms\": 10234.299, \"total_train_time_s\": 11.98940134048462}", "{\"n\": 19802, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.99, \"learn_time_ms\": 10096.3, \"total_train_time_s\": 10.868157386779785}", "{\"n\": 19803, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3713.27, \"learn_time_ms\": 10023.225, \"total_train_time_s\": 11.617495059967041}", "{\"n\": 19804, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.39, \"learn_time_ms\": 10022.211, \"total_train_time_s\": 12.108394145965576}", "{\"n\": 19805, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.94, \"learn_time_ms\": 10095.948, \"total_train_time_s\": 12.512056827545166}", "{\"n\": 19806, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.05, \"learn_time_ms\": 10193.679, \"total_train_time_s\": 12.724481344223022}", "{\"n\": 19807, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3718.05, \"learn_time_ms\": 10060.412, \"total_train_time_s\": 11.442409992218018}", "{\"n\": 19808, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3710.8, \"learn_time_ms\": 9947.559, \"total_train_time_s\": 10.802300453186035}", "{\"n\": 19809, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.53, \"learn_time_ms\": 10011.593, \"total_train_time_s\": 12.311468601226807}", "{\"n\": 19810, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.02, \"learn_time_ms\": 9982.984, \"total_train_time_s\": 12.604859113693237}", "{\"n\": 19811, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.02, \"learn_time_ms\": 10006.905, \"total_train_time_s\": 12.217707395553589}", "{\"n\": 19812, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.39, \"learn_time_ms\": 10126.935, \"total_train_time_s\": 12.07190203666687}", "{\"n\": 19813, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.66, \"learn_time_ms\": 10217.118, \"total_train_time_s\": 12.520234823226929}", "{\"n\": 19814, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3699.95, \"learn_time_ms\": 10021.241, \"total_train_time_s\": 10.154482364654541}", "{\"n\": 19815, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.06, \"learn_time_ms\": 9914.341, \"total_train_time_s\": 11.408432722091675}", "{\"n\": 19816, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.54, \"learn_time_ms\": 9842.865, \"total_train_time_s\": 12.01235032081604}", "{\"n\": 19817, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3704.54, \"learn_time_ms\": 9904.763, \"total_train_time_s\": 12.068656921386719}", "{\"n\": 19818, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.18, \"learn_time_ms\": 10070.889, \"total_train_time_s\": 12.449561834335327}", "{\"n\": 19819, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.8, \"learn_time_ms\": 9979.13, \"total_train_time_s\": 11.362801790237427}", "{\"n\": 19820, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.31, \"learn_time_ms\": 9938.603, \"total_train_time_s\": 12.157381057739258}", "{\"n\": 19821, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.31, \"learn_time_ms\": 9837.993, \"total_train_time_s\": 11.193482875823975}", "{\"n\": 19822, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3702.82, \"learn_time_ms\": 9815.755, \"total_train_time_s\": 11.842862129211426}", "{\"n\": 19823, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.69, \"learn_time_ms\": 9714.825, \"total_train_time_s\": 11.551635265350342}", "{\"n\": 19824, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.69, \"learn_time_ms\": 9962.313, \"total_train_time_s\": 12.617629051208496}", "{\"n\": 19825, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.69, \"learn_time_ms\": 9997.766, \"total_train_time_s\": 11.774906873703003}", "{\"n\": 19826, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.85, \"learn_time_ms\": 9842.971, \"total_train_time_s\": 10.465152978897095}", "{\"n\": 19827, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.74, \"learn_time_ms\": 9747.53, \"total_train_time_s\": 11.147887706756592}", "{\"n\": 19828, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.74, \"learn_time_ms\": 9802.978, \"total_train_time_s\": 12.990986347198486}", "{\"n\": 19829, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3696.95, \"learn_time_ms\": 9952.187, \"total_train_time_s\": 12.88468074798584}", "{\"n\": 19830, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3697.0, \"learn_time_ms\": 9982.431, \"total_train_time_s\": 12.494014501571655}", "{\"n\": 19831, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.65, \"learn_time_ms\": 10079.308, \"total_train_time_s\": 12.165063619613647}", "{\"n\": 19832, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3700.65, \"learn_time_ms\": 10229.949, \"total_train_time_s\": 13.370602369308472}", "{\"n\": 19833, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3698.65, \"learn_time_ms\": 10230.951, \"total_train_time_s\": 11.53132677078247}", "{\"n\": 19834, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.8, \"learn_time_ms\": 10153.887, \"total_train_time_s\": 11.810736417770386}", "{\"n\": 19835, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.8, \"learn_time_ms\": 10210.852, \"total_train_time_s\": 12.333800554275513}", "{\"n\": 19836, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.8, \"learn_time_ms\": 10429.617, \"total_train_time_s\": 12.647916078567505}", "{\"n\": 19837, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3711.92, \"learn_time_ms\": 10516.705, \"total_train_time_s\": 12.010102987289429}", "{\"n\": 19838, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.75, \"learn_time_ms\": 10381.734, \"total_train_time_s\": 11.653406858444214}", "{\"n\": 19839, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3712.75, \"learn_time_ms\": 10437.133, \"total_train_time_s\": 13.376627922058105}", "{\"n\": 19840, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.81, \"learn_time_ms\": 10370.442, \"total_train_time_s\": 11.832134246826172}", "{\"n\": 19841, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3723.21, \"learn_time_ms\": 10400.115, \"total_train_time_s\": 12.459383487701416}", "{\"n\": 19842, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3720.84, \"learn_time_ms\": 10216.187, \"total_train_time_s\": 11.557929992675781}", "{\"n\": 19843, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3720.84, \"learn_time_ms\": 10252.94, \"total_train_time_s\": 11.883089542388916}", "{\"n\": 19844, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.99, \"learn_time_ms\": 10298.518, \"total_train_time_s\": 12.252457618713379}", "{\"n\": 19845, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 10412.596, \"total_train_time_s\": 13.469175100326538}", "{\"n\": 19846, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 10528.571, \"total_train_time_s\": 13.856413841247559}", "{\"n\": 19847, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 10662.122, \"total_train_time_s\": 13.33054780960083}", "{\"n\": 19848, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3683.76, \"learn_time_ms\": 10726.897, \"total_train_time_s\": 12.259430646896362}", "{\"n\": 19849, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.69, \"learn_time_ms\": 10521.832, \"total_train_time_s\": 11.378407001495361}", "{\"n\": 19850, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.69, \"learn_time_ms\": 10579.371, \"total_train_time_s\": 12.378905296325684}", "{\"n\": 19851, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3694.15, \"learn_time_ms\": 10561.203, \"total_train_time_s\": 12.276642084121704}", "{\"n\": 19852, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.15, \"learn_time_ms\": 10596.677, \"total_train_time_s\": 11.882015228271484}", "{\"n\": 19853, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.15, \"learn_time_ms\": 10554.643, \"total_train_time_s\": 11.467090606689453}", "{\"n\": 19854, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3689.15, \"learn_time_ms\": 10634.668, \"total_train_time_s\": 13.06217908859253}", "{\"n\": 19855, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3678.17, \"learn_time_ms\": 10516.251, \"total_train_time_s\": 12.31565237045288}", "{\"n\": 19856, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.65, \"learn_time_ms\": 10364.052, \"total_train_time_s\": 12.342193603515625}", "{\"n\": 19857, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3672.65, \"learn_time_ms\": 10323.783, \"total_train_time_s\": 12.88606309890747}", "{\"n\": 19858, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.18, \"learn_time_ms\": 10287.329, \"total_train_time_s\": 11.94132685661316}", "{\"n\": 19859, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.19, \"learn_time_ms\": 10353.348, \"total_train_time_s\": 12.081300020217896}", "{\"n\": 19860, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.07, \"learn_time_ms\": 10345.254, \"total_train_time_s\": 12.349509239196777}", "{\"n\": 19861, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.32, \"learn_time_ms\": 10211.878, \"total_train_time_s\": 10.978537797927856}", "{\"n\": 19862, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.61, \"learn_time_ms\": 10086.8, \"total_train_time_s\": 10.643706560134888}", "{\"n\": 19863, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.47, \"learn_time_ms\": 10105.263, \"total_train_time_s\": 11.677503108978271}", "{\"n\": 19864, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.71, \"learn_time_ms\": 9932.092, \"total_train_time_s\": 11.364381074905396}", "{\"n\": 19865, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.58, \"learn_time_ms\": 9833.316, \"total_train_time_s\": 11.319570302963257}", "{\"n\": 19866, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.0, \"learn_time_ms\": 9761.152, \"total_train_time_s\": 11.585386514663696}", "{\"n\": 19867, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.93, \"learn_time_ms\": 9742.548, \"total_train_time_s\": 12.749151229858398}", "{\"n\": 19868, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.06, \"learn_time_ms\": 9562.478, \"total_train_time_s\": 10.103586673736572}", "{\"n\": 19869, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3646.06, \"learn_time_ms\": 9589.377, \"total_train_time_s\": 12.293944597244263}", "{\"n\": 19870, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 3.09, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.71, \"learn_time_ms\": 9583.882, \"total_train_time_s\": 12.244178295135498}", "{\"n\": 19871, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.11, \"learn_time_ms\": 9762.078, \"total_train_time_s\": 12.772153615951538}", "{\"n\": 19872, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 9856.221, \"total_train_time_s\": 11.582541465759277}", "{\"n\": 19873, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.92, \"learn_time_ms\": 9808.092, \"total_train_time_s\": 11.230536699295044}", "{\"n\": 19874, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.21, \"learn_time_ms\": 9840.874, \"total_train_time_s\": 11.708952903747559}", "{\"n\": 19875, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.7, \"learn_time_ms\": 9951.159, \"total_train_time_s\": 12.402616262435913}", "{\"n\": 19876, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.7, \"learn_time_ms\": 9877.859, \"total_train_time_s\": 10.8439359664917}", "{\"n\": 19877, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.56, \"learn_time_ms\": 9725.965, \"total_train_time_s\": 11.275884866714478}", "{\"n\": 19878, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.1, \"learn_time_ms\": 9958.166, \"total_train_time_s\": 12.463533639907837}", "{\"n\": 19879, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.26, \"learn_time_ms\": 9976.626, \"total_train_time_s\": 12.526196479797363}", "{\"n\": 19880, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3667.26, \"learn_time_ms\": 9969.037, \"total_train_time_s\": 12.154899597167969}", "{\"n\": 19881, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.24, \"learn_time_ms\": 9886.981, \"total_train_time_s\": 11.914483308792114}", "{\"n\": 19882, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 10006.115, \"total_train_time_s\": 12.759936094284058}", "{\"n\": 19883, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 10068.492, \"total_train_time_s\": 11.825413465499878}", "{\"n\": 19884, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3662.51, \"learn_time_ms\": 10083.837, \"total_train_time_s\": 11.85229754447937}", "{\"n\": 19885, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.11, \"learn_time_ms\": 9994.535, \"total_train_time_s\": 11.54221796989441}", "{\"n\": 19886, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.05, \"learn_time_ms\": 10134.203, \"total_train_time_s\": 12.222365856170654}", "{\"n\": 19887, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.05, \"learn_time_ms\": 10225.431, \"total_train_time_s\": 12.179589986801147}", "{\"n\": 19888, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 10114.86, \"total_train_time_s\": 11.369587898254395}", "{\"n\": 19889, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3655.96, \"learn_time_ms\": 9954.99, \"total_train_time_s\": 10.917622327804565}", "{\"n\": 19890, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.71, \"learn_time_ms\": 10047.253, \"total_train_time_s\": 13.102769613265991}", "{\"n\": 19891, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.71, \"learn_time_ms\": 10031.987, \"total_train_time_s\": 11.73415470123291}", "{\"n\": 19892, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3661.78, \"learn_time_ms\": 9897.521, \"total_train_time_s\": 11.452883958816528}", "{\"n\": 19893, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.05, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.92, \"learn_time_ms\": 9875.242, \"total_train_time_s\": 11.595043659210205}", "{\"n\": 19894, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.63, \"learn_time_ms\": 10017.074, \"total_train_time_s\": 13.257910966873169}", "{\"n\": 19895, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3673.55, \"learn_time_ms\": 10107.837, \"total_train_time_s\": 12.468008518218994}", "{\"n\": 19896, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.76, \"learn_time_ms\": 10027.33, \"total_train_time_s\": 11.439183950424194}", "{\"n\": 19897, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.76, \"learn_time_ms\": 10036.633, \"total_train_time_s\": 12.197919130325317}", "{\"n\": 19898, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3668.7, \"learn_time_ms\": 10087.965, \"total_train_time_s\": 11.833357572555542}", "{\"n\": 19899, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.26, \"learn_time_ms\": 10313.787, \"total_train_time_s\": 13.154602527618408}", "{\"n\": 19900, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3671.26, \"learn_time_ms\": 10218.155, \"total_train_time_s\": 12.136180400848389}", "{\"n\": 19901, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3666.51, \"learn_time_ms\": 10318.112, \"total_train_time_s\": 12.771151781082153}", "{\"n\": 19902, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3664.82, \"learn_time_ms\": 10415.419, \"total_train_time_s\": 12.352982521057129}", "{\"n\": 19903, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3660.27, \"learn_time_ms\": 10442.306, \"total_train_time_s\": 11.835580825805664}", "{\"n\": 19904, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.03, \"learn_time_ms\": 10310.635, \"total_train_time_s\": 11.945289611816406}", "{\"n\": 19905, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.49, \"learn_time_ms\": 10291.465, \"total_train_time_s\": 12.30234408378601}", "{\"n\": 19906, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.23, \"learn_time_ms\": 10358.585, \"total_train_time_s\": 12.112455129623413}", "{\"n\": 19907, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.23, \"learn_time_ms\": 10290.766, \"total_train_time_s\": 11.571242809295654}", "{\"n\": 19908, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.03, \"learn_time_ms\": 10302.551, \"total_train_time_s\": 12.063899278640747}", "{\"n\": 19909, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.55, \"learn_time_ms\": 10208.095, \"total_train_time_s\": 12.191230058670044}", "{\"n\": 19910, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.38, \"learn_time_ms\": 10212.848, \"total_train_time_s\": 12.242240190505981}", "{\"n\": 19911, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.94, \"learn_time_ms\": 10115.8, \"total_train_time_s\": 11.804153203964233}", "{\"n\": 19912, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3650.94, \"learn_time_ms\": 10180.587, \"total_train_time_s\": 13.056993246078491}", "{\"n\": 19913, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3654.09, \"learn_time_ms\": 10225.654, \"total_train_time_s\": 12.34311056137085}", "{\"n\": 19914, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.31, \"learn_time_ms\": 10208.282, \"total_train_time_s\": 11.812561750411987}", "{\"n\": 19915, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 10203.848, \"total_train_time_s\": 12.212095022201538}", "{\"n\": 19916, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.65, \"learn_time_ms\": 10172.766, \"total_train_time_s\": 11.769916296005249}", "{\"n\": 19917, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.37, \"learn_time_ms\": 10204.236, \"total_train_time_s\": 11.852529287338257}", "{\"n\": 19918, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3651.77, \"learn_time_ms\": 10301.14, \"total_train_time_s\": 12.928655862808228}", "{\"n\": 19919, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.66, \"learn_time_ms\": 10290.008, \"total_train_time_s\": 12.114001035690308}", "{\"n\": 19920, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3670.54, \"learn_time_ms\": 10193.058, \"total_train_time_s\": 11.238040447235107}", "{\"n\": 19921, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.53, \"learn_time_ms\": 10225.618, \"total_train_time_s\": 12.107762575149536}", "{\"n\": 19922, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.53, \"learn_time_ms\": 10148.333, \"total_train_time_s\": 12.225014925003052}", "{\"n\": 19923, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3665.68, \"learn_time_ms\": 10034.518, \"total_train_time_s\": 11.201375007629395}", "{\"n\": 19924, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.22, \"learn_time_ms\": 10094.777, \"total_train_time_s\": 12.390579223632812}", "{\"n\": 19925, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3663.22, \"learn_time_ms\": 9995.686, \"total_train_time_s\": 11.214608669281006}", "{\"n\": 19926, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3657.39, \"learn_time_ms\": 9966.797, \"total_train_time_s\": 11.502199649810791}", "{\"n\": 19927, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3658.04, \"learn_time_ms\": 9978.395, \"total_train_time_s\": 11.975350379943848}", "{\"n\": 19928, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 9930.814, \"total_train_time_s\": 12.483172178268433}", "{\"n\": 19929, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 9980.164, \"total_train_time_s\": 12.607727527618408}", "{\"n\": 19930, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3652.59, \"learn_time_ms\": 10021.472, \"total_train_time_s\": 11.602956771850586}", "{\"n\": 19931, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3644.96, \"learn_time_ms\": 10018.451, \"total_train_time_s\": 12.101152420043945}", "{\"n\": 19932, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 9984.742, \"total_train_time_s\": 11.961765050888062}", "{\"n\": 19933, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.46, \"learn_time_ms\": 10158.627, \"total_train_time_s\": 12.933834791183472}", "{\"n\": 19934, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3645.46, \"learn_time_ms\": 10051.351, \"total_train_time_s\": 11.241706371307373}", "{\"n\": 19935, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 10123.68, \"total_train_time_s\": 11.931472539901733}", "{\"n\": 19936, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3643.31, \"learn_time_ms\": 10133.972, \"total_train_time_s\": 11.575636386871338}", "{\"n\": 19937, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.77, \"learn_time_ms\": 10141.131, \"total_train_time_s\": 12.070415019989014}", "{\"n\": 19938, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3640.77, \"learn_time_ms\": 9916.637, \"total_train_time_s\": 10.225404024124146}", "{\"n\": 19939, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3628.54, \"learn_time_ms\": 9784.584, \"total_train_time_s\": 11.277529954910278}", "{\"n\": 19940, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3615.9, \"learn_time_ms\": 9767.286, \"total_train_time_s\": 11.463403224945068}", "{\"n\": 19941, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.04, \"learn_time_ms\": 9745.23, \"total_train_time_s\": 11.870421648025513}", "{\"n\": 19942, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3613.04, \"learn_time_ms\": 9848.185, \"total_train_time_s\": 12.989247798919678}", "{\"n\": 19943, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3627.58, \"learn_time_ms\": 9660.685, \"total_train_time_s\": 11.061497449874878}", "{\"n\": 19944, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.78, \"learn_time_ms\": 9725.668, \"total_train_time_s\": 11.946640968322754}", "{\"n\": 19945, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3632.78, \"learn_time_ms\": 9836.584, \"total_train_time_s\": 13.002861976623535}", "{\"n\": 19946, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3640.63, \"learn_time_ms\": 9841.371, \"total_train_time_s\": 11.649638652801514}", "{\"n\": 19947, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3643.42, \"learn_time_ms\": 9712.942, \"total_train_time_s\": 10.770411491394043}", "{\"n\": 19948, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.62, \"learn_time_ms\": 9934.514, \"total_train_time_s\": 12.457005262374878}", "{\"n\": 19949, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3642.62, \"learn_time_ms\": 9970.292, \"total_train_time_s\": 11.628425598144531}", "{\"n\": 19950, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3634.59, \"learn_time_ms\": 10000.748, \"total_train_time_s\": 11.7456796169281}", "{\"n\": 19951, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3630.53, \"learn_time_ms\": 10104.548, \"total_train_time_s\": 12.889057636260986}", "{\"n\": 19952, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 9936.216, \"total_train_time_s\": 11.256176948547363}", "{\"n\": 19953, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 9974.687, \"total_train_time_s\": 11.38435435295105}", "{\"n\": 19954, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3649.28, \"learn_time_ms\": 9952.329, \"total_train_time_s\": 11.767030477523804}", "{\"n\": 19955, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3649.22, \"learn_time_ms\": 9831.275, \"total_train_time_s\": 11.826405048370361}", "{\"n\": 19956, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3659.02, \"learn_time_ms\": 9793.629, \"total_train_time_s\": 11.261946678161621}", "{\"n\": 19957, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 9913.088, \"total_train_time_s\": 11.958373785018921}", "{\"n\": 19958, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.21, \"learn_time_ms\": 9792.661, \"total_train_time_s\": 11.241065740585327}", "{\"n\": 19959, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.21, \"learn_time_ms\": 9860.991, \"total_train_time_s\": 12.29255199432373}", "{\"n\": 19960, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3679.5, \"learn_time_ms\": 9872.531, \"total_train_time_s\": 11.858246088027954}", "{\"n\": 19961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3675.98, \"learn_time_ms\": 9725.641, \"total_train_time_s\": 11.441475868225098}", "{\"n\": 19962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.69, \"learn_time_ms\": 9805.186, \"total_train_time_s\": 12.102046728134155}", "{\"n\": 19963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.69, \"learn_time_ms\": 9961.785, \"total_train_time_s\": 13.05519413948059}", "{\"n\": 19964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3685.96, \"learn_time_ms\": 9948.392, \"total_train_time_s\": 11.599329710006714}", "{\"n\": 19965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3679.6, \"learn_time_ms\": 9886.389, \"total_train_time_s\": 11.249541282653809}", "{\"n\": 19966, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3687.16, \"learn_time_ms\": 9889.449, \"total_train_time_s\": 11.30381178855896}", "{\"n\": 19967, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3687.16, \"learn_time_ms\": 9866.956, \"total_train_time_s\": 11.780670642852783}", "{\"n\": 19968, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3690.16, \"learn_time_ms\": 9961.345, \"total_train_time_s\": 12.234572887420654}", "{\"n\": 19969, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3690.16, \"learn_time_ms\": 9973.596, \"total_train_time_s\": 12.448779582977295}", "{\"n\": 19970, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3701.22, \"learn_time_ms\": 10012.589, \"total_train_time_s\": 12.31578278541565}", "{\"n\": 19971, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.06, \"learn_time_ms\": 10104.071, \"total_train_time_s\": 12.336441993713379}", "{\"n\": 19972, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.06, \"learn_time_ms\": 10187.122, \"total_train_time_s\": 12.899549007415771}", "{\"n\": 19973, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.06, \"learn_time_ms\": 10113.632, \"total_train_time_s\": 12.241668462753296}", "{\"n\": 19974, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3698.71, \"learn_time_ms\": 10044.082, \"total_train_time_s\": 10.908502578735352}", "{\"n\": 19975, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3692.39, \"learn_time_ms\": 10243.718, \"total_train_time_s\": 13.201696634292603}", "{\"n\": 19976, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3692.39, \"learn_time_ms\": 10238.728, \"total_train_time_s\": 11.243983030319214}", "{\"n\": 19977, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.29, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3692.39, \"learn_time_ms\": 10225.502, \"total_train_time_s\": 11.60158085823059}", "{\"n\": 19978, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3691.54, \"learn_time_ms\": 10197.015, \"total_train_time_s\": 11.88649296760559}", "{\"n\": 19979, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3703.67, \"learn_time_ms\": 10240.242, \"total_train_time_s\": 12.887972593307495}", "{\"n\": 19980, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3703.67, \"learn_time_ms\": 10201.942, \"total_train_time_s\": 11.871230363845825}", "{\"n\": 19981, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3703.67, \"learn_time_ms\": 10268.797, \"total_train_time_s\": 13.051419258117676}", "{\"n\": 19982, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3710.74, \"learn_time_ms\": 10202.769, \"total_train_time_s\": 12.241361141204834}", "{\"n\": 19983, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3711.66, \"learn_time_ms\": 10204.558, \"total_train_time_s\": 12.268369913101196}", "{\"n\": 19984, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3711.66, \"learn_time_ms\": 10353.203, \"total_train_time_s\": 12.368499994277954}", "{\"n\": 19985, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3716.71, \"learn_time_ms\": 10234.937, \"total_train_time_s\": 12.03816533088684}", "{\"n\": 19986, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3711.41, \"learn_time_ms\": 10360.937, \"total_train_time_s\": 12.532319068908691}", "{\"n\": 19987, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3711.41, \"learn_time_ms\": 10526.183, \"total_train_time_s\": 13.24608302116394}", "{\"n\": 19988, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3701.57, \"learn_time_ms\": 10577.878, \"total_train_time_s\": 12.417667150497437}", "{\"n\": 19989, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3703.49, \"learn_time_ms\": 10521.912, \"total_train_time_s\": 12.349501371383667}", "{\"n\": 19990, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3698.33, \"learn_time_ms\": 10612.548, \"total_train_time_s\": 12.785506248474121}", "{\"n\": 19991, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3698.33, \"learn_time_ms\": 10497.286, \"total_train_time_s\": 11.859585046768188}", "{\"n\": 19992, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3699.47, \"learn_time_ms\": 10519.043, \"total_train_time_s\": 12.439323663711548}", "{\"n\": 19993, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3689.05, \"learn_time_ms\": 10524.342, \"total_train_time_s\": 12.355297088623047}", "{\"n\": 19994, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.41, \"learn_time_ms\": 10409.763, \"total_train_time_s\": 11.23725700378418}", "{\"n\": 19995, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.76, \"learn_time_ms\": 10383.96, \"total_train_time_s\": 11.743821859359741}", "{\"n\": 19996, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3694.52, \"learn_time_ms\": 10377.944, \"total_train_time_s\": 12.48402214050293}", "{\"n\": 19997, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3702.04, \"learn_time_ms\": 10367.317, \"total_train_time_s\": 13.202460289001465}", "{\"n\": 19998, \"episode_reward_min\": -9.0, \"episode_reward_mean\": 2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3702.04, \"learn_time_ms\": 10288.852, \"total_train_time_s\": 11.684943914413452}", "{\"n\": 19999, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3694.08, \"learn_time_ms\": 10207.391, \"total_train_time_s\": 11.514504432678223}", "{\"n\": 20000, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3688.85, \"learn_time_ms\": 10291.019, \"total_train_time_s\": 13.640405654907227}", "{\"n\": 20001, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3687.17, \"learn_time_ms\": 10339.629, \"total_train_time_s\": 12.363178730010986}", "{\"n\": 20002, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3687.17, \"learn_time_ms\": 10330.725, \"total_train_time_s\": 12.354488134384155}", "{\"n\": 20003, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 2.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.53, \"learn_time_ms\": 10319.261, \"total_train_time_s\": 12.254430055618286}", "{\"n\": 20004, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.43, \"learn_time_ms\": 10407.075, \"total_train_time_s\": 12.106426000595093}", "{\"n\": 20005, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.43, \"learn_time_ms\": 10501.259, \"total_train_time_s\": 12.710477828979492}", "{\"n\": 20006, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3693.43, \"learn_time_ms\": 10533.551, \"total_train_time_s\": 12.757956743240356}", "{\"n\": 20007, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3697.39, \"learn_time_ms\": 10470.107, \"total_train_time_s\": 12.560960292816162}", "{\"n\": 20008, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3695.46, \"learn_time_ms\": 10472.206, \"total_train_time_s\": 11.659836053848267}", "{\"n\": 20009, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3695.46, \"learn_time_ms\": 10544.513, \"total_train_time_s\": 12.241673469543457}", "{\"n\": 20010, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3686.8, \"learn_time_ms\": 10379.514, \"total_train_time_s\": 12.004695653915405}", "{\"n\": 20011, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.8, \"learn_time_ms\": 10485.394, \"total_train_time_s\": 13.404802560806274}", "{\"n\": 20012, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.8, \"learn_time_ms\": 10575.11, \"total_train_time_s\": 13.25985836982727}", "{\"n\": 20013, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3680.8, \"learn_time_ms\": 10522.571, \"total_train_time_s\": 11.674466133117676}", "{\"n\": 20014, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.76, \"learn_time_ms\": 10487.684, \"total_train_time_s\": 11.760167598724365}", "{\"n\": 20015, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3668.77, \"learn_time_ms\": 10437.25, \"total_train_time_s\": 12.227367162704468}", "{\"n\": 20016, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3668.77, \"learn_time_ms\": 10403.48, \"total_train_time_s\": 12.437540292739868}", "{\"n\": 20017, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3683.09, \"learn_time_ms\": 10380.303, \"total_train_time_s\": 12.302785873413086}", "{\"n\": 20018, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 10460.691, \"total_train_time_s\": 12.442564487457275}", "{\"n\": 20019, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 10463.074, \"total_train_time_s\": 12.221579313278198}", "{\"n\": 20020, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 10465.583, \"total_train_time_s\": 12.004162549972534}", "{\"n\": 20021, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.27, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3670.08, \"learn_time_ms\": 10243.539, \"total_train_time_s\": 11.177250385284424}", "{\"n\": 20022, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.6, \"learn_time_ms\": 10118.818, \"total_train_time_s\": 11.995876550674438}", "{\"n\": 20023, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3674.6, \"learn_time_ms\": 10209.93, \"total_train_time_s\": 12.641481161117554}", "{\"n\": 20024, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3670.79, \"learn_time_ms\": 10235.05, \"total_train_time_s\": 12.051335096359253}", "{\"n\": 20025, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3675.25, \"learn_time_ms\": 10121.575, \"total_train_time_s\": 11.09265422821045}", "{\"n\": 20026, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3673.69, \"learn_time_ms\": 10067.662, \"total_train_time_s\": 11.906038999557495}", "{\"n\": 20027, \"episode_reward_min\": -11.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3673.69, \"learn_time_ms\": 10030.075, \"total_train_time_s\": 11.901402711868286}", "{\"n\": 20028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3665.67, \"learn_time_ms\": 9978.154, \"total_train_time_s\": 11.9804048538208}", "{\"n\": 20029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3684.95, \"learn_time_ms\": 10109.363, \"total_train_time_s\": 13.60113000869751}", "{\"n\": 20030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3684.95, \"learn_time_ms\": 10145.053, \"total_train_time_s\": 12.3572256565094}", "{\"n\": 20031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3684.95, \"learn_time_ms\": 10270.092, \"total_train_time_s\": 12.441069602966309}", "{\"n\": 20032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.13, \"learn_time_ms\": 10251.427, \"total_train_time_s\": 11.831163167953491}", "{\"n\": 20033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 10183.283, \"total_train_time_s\": 11.934139490127563}", "{\"n\": 20034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 10216.42, \"total_train_time_s\": 12.346078634262085}", "{\"n\": 20035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.91, \"learn_time_ms\": 10402.399, \"total_train_time_s\": 12.900128364562988}", "{\"n\": 20036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.13, \"learn_time_ms\": 10416.581, \"total_train_time_s\": 12.070229053497314}", "{\"n\": 20037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.2, \"learn_time_ms\": 10397.174, \"total_train_time_s\": 11.72398853302002}", "{\"n\": 20038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3692.2, \"learn_time_ms\": 10450.433, \"total_train_time_s\": 12.459015369415283}", "{\"n\": 20039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.39, \"learn_time_ms\": 10452.652, \"total_train_time_s\": 13.606623888015747}", "{\"n\": 20040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3686.39, \"learn_time_ms\": 10493.934, \"total_train_time_s\": 12.777586698532104}", "{\"n\": 20041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.44, \"learn_time_ms\": 10496.769, \"total_train_time_s\": 12.507923364639282}", "{\"n\": 20042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.1, \"learn_time_ms\": 10479.454, \"total_train_time_s\": 11.659064054489136}", "{\"n\": 20043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.72, \"learn_time_ms\": 10562.765, \"total_train_time_s\": 12.785279989242554}", "{\"n\": 20044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.72, \"learn_time_ms\": 10512.958, \"total_train_time_s\": 11.825699806213379}", "{\"n\": 20045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.72, \"learn_time_ms\": 10484.702, \"total_train_time_s\": 12.647489547729492}", "{\"n\": 20046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3668.18, \"learn_time_ms\": 10549.112, \"total_train_time_s\": 12.702174663543701}", "{\"n\": 20047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.35, \"learn_time_ms\": 10632.769, \"total_train_time_s\": 12.602575302124023}", "{\"n\": 20048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.35, \"learn_time_ms\": 10718.329, \"total_train_time_s\": 13.348525524139404}", "{\"n\": 20049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.73, \"learn_time_ms\": 10585.509, \"total_train_time_s\": 12.222955226898193}", "{\"n\": 20050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.47, \"learn_time_ms\": 10542.661, \"total_train_time_s\": 12.376023292541504}", "{\"n\": 20051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3641.0, \"learn_time_ms\": 10580.724, \"total_train_time_s\": 12.888773679733276}", "{\"n\": 20052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.82, \"learn_time_ms\": 10626.962, \"total_train_time_s\": 12.109355211257935}", "{\"n\": 20053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.47, \"learn_time_ms\": 10546.998, \"total_train_time_s\": 11.954853534698486}", "{\"n\": 20054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 10597.624, \"total_train_time_s\": 12.364761590957642}", "{\"n\": 20055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.69, \"learn_time_ms\": 10487.445, \"total_train_time_s\": 11.55814266204834}", "{\"n\": 20056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.0, \"learn_time_ms\": 10420.633, \"total_train_time_s\": 11.996233463287354}", "{\"n\": 20057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.54, \"learn_time_ms\": 10342.143, \"total_train_time_s\": 11.760066509246826}", "{\"n\": 20058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.98, \"learn_time_ms\": 10168.964, \"total_train_time_s\": 11.599236965179443}", "{\"n\": 20059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3621.34, \"learn_time_ms\": 10185.301, \"total_train_time_s\": 12.460310697555542}", "{\"n\": 20060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": 3.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.13, \"learn_time_ms\": 10210.929, \"total_train_time_s\": 12.618551254272461}", "{\"n\": 20061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3610.37, \"learn_time_ms\": 10288.575, \"total_train_time_s\": 13.623161554336548}", "{\"n\": 20062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.45, \"learn_time_ms\": 10314.875, \"total_train_time_s\": 12.344792127609253}", "{\"n\": 20063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.45, \"learn_time_ms\": 10343.999, \"total_train_time_s\": 12.252235412597656}", "{\"n\": 20064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.56, \"learn_time_ms\": 10342.197, \"total_train_time_s\": 12.314528703689575}", "{\"n\": 20065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3606.89, \"learn_time_ms\": 10310.565, \"total_train_time_s\": 11.200748920440674}", "{\"n\": 20066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.44, \"learn_time_ms\": 10344.358, \"total_train_time_s\": 12.504012823104858}", "{\"n\": 20067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.44, \"learn_time_ms\": 10415.154, \"total_train_time_s\": 12.521688222885132}", "{\"n\": 20068, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.43, \"learn_time_ms\": 10557.089, \"total_train_time_s\": 13.07247281074524}", "{\"n\": 20069, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3592.43, \"learn_time_ms\": 10521.875, \"total_train_time_s\": 12.042272090911865}", "{\"n\": 20070, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3595.04, \"learn_time_ms\": 10513.218, \"total_train_time_s\": 12.532079696655273}", "{\"n\": 20071, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 10308.805, \"total_train_time_s\": 11.657000303268433}", "{\"n\": 20072, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 10276.742, \"total_train_time_s\": 12.073068380355835}", "{\"n\": 20073, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 10253.463, \"total_train_time_s\": 12.001267910003662}", "{\"n\": 20074, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3576.4, \"learn_time_ms\": 10226.682, \"total_train_time_s\": 12.056625127792358}", "{\"n\": 20075, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.09, \"learn_time_ms\": 10370.935, \"total_train_time_s\": 12.680300235748291}", "{\"n\": 20076, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3546.09, \"learn_time_ms\": 10310.565, \"total_train_time_s\": 11.735223531723022}", "{\"n\": 20077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 10213.566, \"total_train_time_s\": 11.542855978012085}", "{\"n\": 20078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 10079.786, \"total_train_time_s\": 11.68380618095398}", "{\"n\": 20079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.5, \"learn_time_ms\": 10112.373, \"total_train_time_s\": 12.401057481765747}", "{\"n\": 20080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.5, \"learn_time_ms\": 10030.676, \"total_train_time_s\": 11.773140907287598}", "{\"n\": 20081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.1, \"learn_time_ms\": 10069.797, \"total_train_time_s\": 11.997363090515137}", "{\"n\": 20082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3569.1, \"learn_time_ms\": 10008.089, \"total_train_time_s\": 11.41675853729248}", "{\"n\": 20083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3591.3, \"learn_time_ms\": 10155.118, \"total_train_time_s\": 13.513338327407837}", "{\"n\": 20084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.87, \"learn_time_ms\": 10080.959, \"total_train_time_s\": 11.347793102264404}", "{\"n\": 20085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.87, \"learn_time_ms\": 9939.024, \"total_train_time_s\": 11.2509446144104}", "{\"n\": 20086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3593.87, \"learn_time_ms\": 9974.43, \"total_train_time_s\": 12.101938247680664}", "{\"n\": 20087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3600.33, \"learn_time_ms\": 9990.006, \"total_train_time_s\": 11.686086177825928}", "{\"n\": 20088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.18, \"learn_time_ms\": 10004.134, \"total_train_time_s\": 11.801005363464355}", "{\"n\": 20089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3608.18, \"learn_time_ms\": 10028.595, \"total_train_time_s\": 12.617897272109985}", "{\"n\": 20090, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3602.36, \"learn_time_ms\": 10044.569, \"total_train_time_s\": 11.842061042785645}", "{\"n\": 20091, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.06, \"learn_time_ms\": 10021.214, \"total_train_time_s\": 11.742653846740723}", "{\"n\": 20092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.41, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3623.26, \"learn_time_ms\": 10095.718, \"total_train_time_s\": 12.212322473526001}", "{\"n\": 20093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.5, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3615.1, \"learn_time_ms\": 9971.24, \"total_train_time_s\": 12.250170230865479}", "{\"n\": 20094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.76, \"learn_time_ms\": 10109.92, \"total_train_time_s\": 12.701318740844727}", "{\"n\": 20095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3618.76, \"learn_time_ms\": 10144.65, \"total_train_time_s\": 11.556763648986816}", "{\"n\": 20096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3613.15, \"learn_time_ms\": 10171.751, \"total_train_time_s\": 12.40766954421997}", "{\"n\": 20097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3607.36, \"learn_time_ms\": 10211.538, \"total_train_time_s\": 12.059935331344604}", "{\"n\": 20098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.48, \"learn_time_ms\": 10285.403, \"total_train_time_s\": 12.581276178359985}", "{\"n\": 20099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3605.48, \"learn_time_ms\": 10165.473, \"total_train_time_s\": 11.435259103775024}", "{\"n\": 20100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.17, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.4, \"learn_time_ms\": 10108.32, \"total_train_time_s\": 11.28611946105957}", "{\"n\": 20101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.61, \"learn_time_ms\": 10103.979, \"total_train_time_s\": 11.719204187393188}", "{\"n\": 20102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.17, \"learn_time_ms\": 10123.111, \"total_train_time_s\": 12.356664180755615}", "{\"n\": 20103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3619.48, \"learn_time_ms\": 10191.547, \"total_train_time_s\": 12.915186882019043}", "{\"n\": 20104, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.99, \"learn_time_ms\": 10124.714, \"total_train_time_s\": 12.044115543365479}", "{\"n\": 20105, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3625.52, \"learn_time_ms\": 10256.713, \"total_train_time_s\": 12.944365739822388}", "{\"n\": 20106, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10204.289, \"total_train_time_s\": 11.841285467147827}", "{\"n\": 20107, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 10241.749, \"total_train_time_s\": 12.436704874038696}", "{\"n\": 20108, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 2.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3624.35, \"learn_time_ms\": 10204.669, \"total_train_time_s\": 12.205844163894653}", "{\"n\": 20109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.32, \"learn_time_ms\": 10298.437, \"total_train_time_s\": 12.39202618598938}", "{\"n\": 20110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.12, \"learn_time_ms\": 10406.92, \"total_train_time_s\": 12.375203609466553}", "{\"n\": 20111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.92, \"learn_time_ms\": 10348.562, \"total_train_time_s\": 11.127545356750488}", "{\"n\": 20112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.2, \"learn_time_ms\": 10287.095, \"total_train_time_s\": 11.721183776855469}", "{\"n\": 20113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.21, \"learn_time_ms\": 10254.897, \"total_train_time_s\": 12.592341899871826}", "{\"n\": 20114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.21, \"learn_time_ms\": 10298.488, \"total_train_time_s\": 12.501238584518433}", "{\"n\": 20115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.95, \"learn_time_ms\": 10173.367, \"total_train_time_s\": 11.673449993133545}", "{\"n\": 20116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.06, \"learn_time_ms\": 10160.676, \"total_train_time_s\": 11.73331332206726}", "{\"n\": 20117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3629.06, \"learn_time_ms\": 10112.588, \"total_train_time_s\": 11.91026520729065}", "{\"n\": 20118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.29, \"learn_time_ms\": 10030.288, \"total_train_time_s\": 11.407684564590454}", "{\"n\": 20119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.31, \"learn_time_ms\": 10035.772, \"total_train_time_s\": 12.406915187835693}", "{\"n\": 20120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.92, \"learn_time_ms\": 10015.111, \"total_train_time_s\": 12.227010011672974}", "{\"n\": 20121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.62, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.92, \"learn_time_ms\": 10192.845, \"total_train_time_s\": 12.911651849746704}", "{\"n\": 20122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3637.33, \"learn_time_ms\": 10167.469, \"total_train_time_s\": 11.488702774047852}", "{\"n\": 20123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.95, \"learn_time_ms\": 10104.952, \"total_train_time_s\": 11.932312726974487}", "{\"n\": 20124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.73, \"learn_time_ms\": 10014.532, \"total_train_time_s\": 11.56188440322876}", "{\"n\": 20125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3630.33, \"learn_time_ms\": 10081.997, \"total_train_time_s\": 12.323598146438599}", "{\"n\": 20126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.83, \"learn_time_ms\": 10133.188, \"total_train_time_s\": 12.226002216339111}", "{\"n\": 20127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.83, \"learn_time_ms\": 10115.197, \"total_train_time_s\": 11.788959264755249}", "{\"n\": 20128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.2, \"learn_time_ms\": 10176.334, \"total_train_time_s\": 11.99419617652893}", "{\"n\": 20129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3633.29, \"learn_time_ms\": 10204.118, \"total_train_time_s\": 12.740018129348755}", "{\"n\": 20130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3638.69, \"learn_time_ms\": 10232.762, \"total_train_time_s\": 12.444416046142578}", "{\"n\": 20131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.55, \"learn_time_ms\": 10127.128, \"total_train_time_s\": 11.817200183868408}", "{\"n\": 20132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.55, \"learn_time_ms\": 10116.542, \"total_train_time_s\": 11.424216747283936}", "{\"n\": 20133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.97, \"learn_time_ms\": 10256.746, \"total_train_time_s\": 13.371702194213867}", "{\"n\": 20134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 1.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3645.0, \"learn_time_ms\": 10246.093, \"total_train_time_s\": 11.442537784576416}", "{\"n\": 20135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.99, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.09, \"learn_time_ms\": 10232.699, \"total_train_time_s\": 12.22217321395874}", "{\"n\": 20136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.58, \"learn_time_ms\": 10231.952, \"total_train_time_s\": 12.217467069625854}", "{\"n\": 20137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.58, \"learn_time_ms\": 10245.581, \"total_train_time_s\": 11.899173736572266}", "{\"n\": 20138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3665.73, \"learn_time_ms\": 10408.094, \"total_train_time_s\": 13.56699514389038}", "{\"n\": 20139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.63, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3679.1, \"learn_time_ms\": 10291.868, \"total_train_time_s\": 11.528126239776611}", "{\"n\": 20140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3683.18, \"learn_time_ms\": 10317.121, \"total_train_time_s\": 12.691416501998901}", "{\"n\": 20141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3683.18, \"learn_time_ms\": 10453.873, \"total_train_time_s\": 13.17784333229065}", "{\"n\": 20142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3677.56, \"learn_time_ms\": 10538.357, \"total_train_time_s\": 12.262485980987549}", "{\"n\": 20143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.42, \"learn_time_ms\": 10322.619, \"total_train_time_s\": 11.24179220199585}", "{\"n\": 20144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.23, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3682.42, \"learn_time_ms\": 10378.116, \"total_train_time_s\": 12.044806957244873}", "{\"n\": 20145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.26, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3680.76, \"learn_time_ms\": 10340.433, \"total_train_time_s\": 11.79261064529419}", "{\"n\": 20146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.36, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3688.72, \"learn_time_ms\": 10221.756, \"total_train_time_s\": 11.01376223564148}", "{\"n\": 20147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3690.72, \"learn_time_ms\": 10184.851, \"total_train_time_s\": 11.60287070274353}", "{\"n\": 20148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3690.72, \"learn_time_ms\": 10059.107, \"total_train_time_s\": 12.360069036483765}", "{\"n\": 20149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.37, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3691.01, \"learn_time_ms\": 10087.9, \"total_train_time_s\": 11.843173503875732}", "{\"n\": 20150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.47, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3694.89, \"learn_time_ms\": 9999.23, \"total_train_time_s\": 11.828969478607178}", "{\"n\": 20151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": 0.49, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3693.21, \"learn_time_ms\": 9749.22, \"total_train_time_s\": 10.713143587112427}"]