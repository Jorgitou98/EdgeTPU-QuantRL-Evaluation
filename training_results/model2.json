["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1014.0, \"learn_time_ms\": 13357.605, \"total_train_time_s\": 21.339139699935913}"]["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9615.894, \"total_train_time_s\": 11.062198400497437}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9203.384, \"total_train_time_s\": 10.20088815689087}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1063.25, \"learn_time_ms\": 8835.854, \"total_train_time_s\": 9.491028785705566}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1051.0, \"learn_time_ms\": 8941.82, \"total_train_time_s\": 10.691755533218384}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.916666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.6666666666667, \"learn_time_ms\": 9017.036, \"total_train_time_s\": 10.734109163284302}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.375, \"learn_time_ms\": 8889.638, \"total_train_time_s\": 9.67796015739441}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1046.55, \"learn_time_ms\": 8817.176, \"total_train_time_s\": 9.802162170410156}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.916666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.5416666666667, \"learn_time_ms\": 8746.172, \"total_train_time_s\": 9.699617862701416}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.928571428571427, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.4642857142858, \"learn_time_ms\": 8672.745, \"total_train_time_s\": 9.53090238571167}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.59375, \"learn_time_ms\": 8760.241, \"total_train_time_s\": 10.959949493408203}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.944444444444443, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.861111111111, \"learn_time_ms\": 8655.491, \"total_train_time_s\": 9.985091209411621}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.95, \"learn_time_ms\": 8607.209, \"total_train_time_s\": 9.714620590209961}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.931818181818183, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.75, \"learn_time_ms\": 8663.06, \"total_train_time_s\": 10.074326038360596}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.7083333333333, \"learn_time_ms\": 8771.206, \"total_train_time_s\": 11.784829139709473}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.923076923076923, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1045.6923076923076, \"learn_time_ms\": 8786.873, \"total_train_time_s\": 10.92637825012207}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.928571428571427, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1049.8214285714287, \"learn_time_ms\": 8842.674, \"total_train_time_s\": 10.212623834609985}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1052.4166666666667, \"learn_time_ms\": 8874.024, \"total_train_time_s\": 10.123228549957275}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88888888888889, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.142857142857, \"learn_time_ms\": 8915.384, \"total_train_time_s\": 10.096349000930786}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.865671641791046, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1062.2835820895523, \"learn_time_ms\": 9139.054, \"total_train_time_s\": 11.739838600158691}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.830985915492956, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1068.7605633802816, \"learn_time_ms\": 9103.959, \"total_train_time_s\": 10.596150398254395}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.835616438356166, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1068.5753424657535, \"learn_time_ms\": 9176.161, \"total_train_time_s\": 10.659833431243896}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.844155844155843, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1069.1948051948052, \"learn_time_ms\": 9280.987, \"total_train_time_s\": 10.785494804382324}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.825, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1071.85, \"learn_time_ms\": 9340.368, \"total_train_time_s\": 10.656044483184814}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.80952380952381, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1074.7261904761904, \"learn_time_ms\": 9195.054, \"total_train_time_s\": 10.323535919189453}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.795454545454547, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1077.2613636363637, \"learn_time_ms\": 9145.402, \"total_train_time_s\": 10.39880919456482}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75824175824176, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1081.032967032967, \"learn_time_ms\": 9267.601, \"total_train_time_s\": 11.461259841918945}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.757894736842104, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1081.7473684210527, \"learn_time_ms\": 9246.149, \"total_train_time_s\": 9.875133752822876}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.757575757575758, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1083.040404040404, \"learn_time_ms\": 9262.151, \"total_train_time_s\": 10.235421657562256}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1085.5, \"learn_time_ms\": 9084.815, \"total_train_time_s\": 9.94255542755127}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1086.82, \"learn_time_ms\": 9054.238, \"total_train_time_s\": 10.271198272705078}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1094.69, \"learn_time_ms\": 8922.888, \"total_train_time_s\": 9.390625476837158}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1099.79, \"learn_time_ms\": 8829.339, \"total_train_time_s\": 9.842269659042358}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1101.34, \"learn_time_ms\": 8730.897, \"total_train_time_s\": 9.672549724578857}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1107.81, \"learn_time_ms\": 8775.465, \"total_train_time_s\": 10.756279706954956}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1115.74, \"learn_time_ms\": 8835.079, \"total_train_time_s\": 11.032842874526978}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1119.86, \"learn_time_ms\": 8754.833, \"total_train_time_s\": 10.628437042236328}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1125.91, \"learn_time_ms\": 8775.123, \"total_train_time_s\": 10.077414512634277}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1135.42, \"learn_time_ms\": 8788.778, \"total_train_time_s\": 10.41731882095337}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1141.82, \"learn_time_ms\": 8815.424, \"total_train_time_s\": 10.239599227905273}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1145.19, \"learn_time_ms\": 8736.798, \"total_train_time_s\": 9.538888454437256}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1153.02, \"learn_time_ms\": 8822.329, \"total_train_time_s\": 10.24901533126831}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1159.56, \"learn_time_ms\": 8816.787, \"total_train_time_s\": 9.76688027381897}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1165.3, \"learn_time_ms\": 8901.811, \"total_train_time_s\": 10.522914409637451}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1168.62, \"learn_time_ms\": 8720.649, \"total_train_time_s\": 8.95499563217163}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.18, \"learn_time_ms\": 8531.084, \"total_train_time_s\": 9.12677264213562}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1187.42, \"learn_time_ms\": 8266.694, \"total_train_time_s\": 8.008679866790771}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1195.16, \"learn_time_ms\": 8396.186, \"total_train_time_s\": 11.384235382080078}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1199.44, \"learn_time_ms\": 8341.809, \"total_train_time_s\": 9.816418886184692}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1207.38, \"learn_time_ms\": 8424.625, \"total_train_time_s\": 11.091372728347778}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1213.64, \"learn_time_ms\": 8463.606, \"total_train_time_s\": 9.914642333984375}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1221.42, \"learn_time_ms\": 8469.347, \"total_train_time_s\": 10.289707660675049}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1230.36, \"learn_time_ms\": 8399.459, \"total_train_time_s\": 9.10080862045288}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1239.92, \"learn_time_ms\": 8466.962, \"total_train_time_s\": 11.222980976104736}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1243.16, \"learn_time_ms\": 8585.973, \"total_train_time_s\": 10.143706560134888}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1250.12, \"learn_time_ms\": 8638.595, \"total_train_time_s\": 9.62562084197998}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1265.24, \"learn_time_ms\": 8794.798, \"total_train_time_s\": 9.60226583480835}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1270.3, \"learn_time_ms\": 8646.026, \"total_train_time_s\": 9.984140396118164}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1275.31, \"learn_time_ms\": 8666.508, \"total_train_time_s\": 10.234221458435059}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1286.39, \"learn_time_ms\": 8521.989, \"total_train_time_s\": 9.614725351333618}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1300.54, \"learn_time_ms\": 8576.372, \"total_train_time_s\": 10.477270603179932}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1308.08, \"learn_time_ms\": 8681.2, \"total_train_time_s\": 11.401500701904297}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1310.59, \"learn_time_ms\": 8840.872, \"total_train_time_s\": 10.686240911483765}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1324.83, \"learn_time_ms\": 8657.284, \"total_train_time_s\": 9.438463926315308}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1333.49, \"learn_time_ms\": 8589.928, \"total_train_time_s\": 9.479151725769043}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1337.44, \"learn_time_ms\": 8473.428, \"total_train_time_s\": 8.436504125595093}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.71, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1350.41, \"learn_time_ms\": 8614.334, \"total_train_time_s\": 10.983285665512085}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.71, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1355.4, \"learn_time_ms\": 8753.944, \"total_train_time_s\": 11.343558311462402}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1361.09, \"learn_time_ms\": 8957.128, \"total_train_time_s\": 12.102725744247437}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.64, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1371.81, \"learn_time_ms\": 9024.196, \"total_train_time_s\": 10.287246465682983}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.62, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1381.61, \"learn_time_ms\": 9092.961, \"total_train_time_s\": 11.173010349273682}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1388.34, \"learn_time_ms\": 9148.397, \"total_train_time_s\": 11.88224458694458}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1395.54, \"learn_time_ms\": 9034.735, \"total_train_time_s\": 9.51280927658081}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.59, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1399.73, \"learn_time_ms\": 9250.627, \"total_train_time_s\": 11.532767057418823}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.57, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1413.92, \"learn_time_ms\": 9275.978, \"total_train_time_s\": 9.731904983520508}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.55, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1424.28, \"learn_time_ms\": 9401.938, \"total_train_time_s\": 9.765358209609985}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1427.15, \"learn_time_ms\": 9474.413, \"total_train_time_s\": 11.695810317993164}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.47, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1437.25, \"learn_time_ms\": 9279.376, \"total_train_time_s\": 9.37448263168335}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1442.37, \"learn_time_ms\": 8979.416, \"total_train_time_s\": 9.129225730895996}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1463.35, \"learn_time_ms\": 8948.492, \"total_train_time_s\": 10.015999555587769}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1463.35, \"learn_time_ms\": 8747.322, \"total_train_time_s\": 9.140080213546753}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1490.54, \"learn_time_ms\": 8658.49, \"total_train_time_s\": 11.076548337936401}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1490.82, \"learn_time_ms\": 8735.28, \"total_train_time_s\": 10.311846494674683}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1501.3, \"learn_time_ms\": 8703.286, \"total_train_time_s\": 11.230748891830444}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1500.42, \"learn_time_ms\": 8932.414, \"total_train_time_s\": 11.969377279281616}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1515.28, \"learn_time_ms\": 8922.833, \"total_train_time_s\": 9.587809324264526}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1526.75, \"learn_time_ms\": 8802.397, \"total_train_time_s\": 10.528203010559082}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1537.3, \"learn_time_ms\": 8728.981, \"total_train_time_s\": 8.647318124771118}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1546.16, \"learn_time_ms\": 8817.369, \"total_train_time_s\": 9.970035314559937}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1562.47, \"learn_time_ms\": 8785.121, \"total_train_time_s\": 9.656615734100342}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1565.75, \"learn_time_ms\": 8973.218, \"total_train_time_s\": 11.00252652168274}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1573.94, \"learn_time_ms\": 8722.293, \"total_train_time_s\": 8.512942790985107}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1575.59, \"learn_time_ms\": 8598.706, \"total_train_time_s\": 9.091569662094116}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1588.47, \"learn_time_ms\": 8322.072, \"total_train_time_s\": 8.43615984916687}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1598.08, \"learn_time_ms\": 8260.48, \"total_train_time_s\": 11.396887302398682}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1603.13, \"learn_time_ms\": 8180.345, \"total_train_time_s\": 8.810351133346558}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1618.23, \"learn_time_ms\": 8205.011, \"total_train_time_s\": 10.793248891830444}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1618.23, \"learn_time_ms\": 8409.742, \"total_train_time_s\": 10.6767258644104}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1627.12, \"learn_time_ms\": 8512.462, \"total_train_time_s\": 10.977409601211548}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1630.33, \"learn_time_ms\": 8516.428, \"total_train_time_s\": 9.678713083267212}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1642.3, \"learn_time_ms\": 8491.899, \"total_train_time_s\": 10.826189041137695}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1643.71, \"learn_time_ms\": 8583.554, \"total_train_time_s\": 9.432428121566772}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1654.58, \"learn_time_ms\": 8794.789, \"total_train_time_s\": 11.204749345779419}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1665.55, \"learn_time_ms\": 8845.983, \"total_train_time_s\": 8.967071533203125}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1672.05, \"learn_time_ms\": 8737.787, \"total_train_time_s\": 10.312571287155151}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1686.04, \"learn_time_ms\": 9051.825, \"total_train_time_s\": 11.981802940368652}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1694.69, \"learn_time_ms\": 9008.55, \"total_train_time_s\": 10.316394090652466}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1699.18, \"learn_time_ms\": 8965.42, \"total_train_time_s\": 10.221606254577637}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1706.4, \"learn_time_ms\": 8977.681, \"total_train_time_s\": 11.128597021102905}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1711.9, \"learn_time_ms\": 9037.079, \"total_train_time_s\": 10.298625469207764}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1729.44, \"learn_time_ms\": 8970.337, \"total_train_time_s\": 10.09485411643982}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1729.44, \"learn_time_ms\": 9033.556, \"total_train_time_s\": 10.079300880432129}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1731.85, \"learn_time_ms\": 8924.073, \"total_train_time_s\": 10.119781255722046}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.01, \"learn_time_ms\": 9093.094, \"total_train_time_s\": 10.625283002853394}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1748.61, \"learn_time_ms\": 9077.679, \"total_train_time_s\": 10.140137910842896}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1776.35, \"learn_time_ms\": 8938.264, \"total_train_time_s\": 10.59441328048706}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1782.67, \"learn_time_ms\": 8906.392, \"total_train_time_s\": 9.995731830596924}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1784.28, \"learn_time_ms\": 8885.444, \"total_train_time_s\": 10.035049200057983}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1787.74, \"learn_time_ms\": 8891.347, \"total_train_time_s\": 11.184879779815674}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1798.02, \"learn_time_ms\": 8965.912, \"total_train_time_s\": 11.051520109176636}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1795.64, \"learn_time_ms\": 9100.752, \"total_train_time_s\": 11.454110860824585}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1812.08, \"learn_time_ms\": 9173.368, \"total_train_time_s\": 10.788259029388428}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1822.57, \"learn_time_ms\": 9163.721, \"total_train_time_s\": 10.039831399917603}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1835.25, \"learn_time_ms\": 9084.408, \"total_train_time_s\": 9.865629434585571}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1839.35, \"learn_time_ms\": 9033.986, \"total_train_time_s\": 9.618756294250488}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1839.56, \"learn_time_ms\": 9048.254, \"total_train_time_s\": 10.707411289215088}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1840.76, \"learn_time_ms\": 9197.847, \"total_train_time_s\": 11.523972749710083}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1845.07, \"learn_time_ms\": 9226.52, \"total_train_time_s\": 10.355146169662476}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1855.14, \"learn_time_ms\": 9121.918, \"total_train_time_s\": 10.068434715270996}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1863.09, \"learn_time_ms\": 9038.275, \"total_train_time_s\": 10.19369626045227}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1865.5, \"learn_time_ms\": 8848.513, \"total_train_time_s\": 9.535200595855713}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1873.56, \"learn_time_ms\": 8706.79, \"total_train_time_s\": 9.397501230239868}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1871.99, \"learn_time_ms\": 8661.561, \"total_train_time_s\": 9.582831621170044}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1876.24, \"learn_time_ms\": 8601.352, \"total_train_time_s\": 9.28087830543518}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1878.48, \"learn_time_ms\": 8662.357, \"total_train_time_s\": 10.268784046173096}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1883.71, \"learn_time_ms\": 8577.269, \"total_train_time_s\": 9.831957340240479}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.88, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1891.39, \"learn_time_ms\": 8430.671, \"total_train_time_s\": 9.99759840965271}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1890.92, \"learn_time_ms\": 8578.439, \"total_train_time_s\": 11.803013801574707}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1890.92, \"learn_time_ms\": 8700.372, \"total_train_time_s\": 11.328784704208374}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1900.94, \"learn_time_ms\": 8874.398, \"total_train_time_s\": 11.943284749984741}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1917.58, \"learn_time_ms\": 9011.795, \"total_train_time_s\": 10.944406032562256}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1929.53, \"learn_time_ms\": 9125.511, \"total_train_time_s\": 10.475663900375366}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1946.73, \"learn_time_ms\": 9108.744, \"total_train_time_s\": 9.40831732749939}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1949.79, \"learn_time_ms\": 9081.677, \"total_train_time_s\": 8.983395099639893}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1947.13, \"learn_time_ms\": 9074.707, \"total_train_time_s\": 10.115816831588745}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1949.56, \"learn_time_ms\": 9145.457, \"total_train_time_s\": 10.557332754135132}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1965.63, \"learn_time_ms\": 9221.101, \"total_train_time_s\": 10.77674412727356}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1966.91, \"learn_time_ms\": 9092.421, \"total_train_time_s\": 10.502290964126587}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1975.87, \"learn_time_ms\": 8942.101, \"total_train_time_s\": 9.835930347442627}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1984.56, \"learn_time_ms\": 8674.419, \"total_train_time_s\": 9.269206285476685}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.37, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1986.28, \"learn_time_ms\": 8529.516, \"total_train_time_s\": 9.477879524230957}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.37, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1987.16, \"learn_time_ms\": 8521.527, \"total_train_time_s\": 10.430192232131958}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1995.81, \"learn_time_ms\": 8586.391, \"total_train_time_s\": 10.038880825042725}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1998.28, \"learn_time_ms\": 8689.258, \"total_train_time_s\": 10.046202421188354}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2011.17, \"learn_time_ms\": 8704.241, \"total_train_time_s\": 10.355642318725586}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2009.67, \"learn_time_ms\": 8598.195, \"total_train_time_s\": 9.518332958221436}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2014.58, \"learn_time_ms\": 8460.979, \"total_train_time_s\": 9.426166772842407}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2019.0, \"learn_time_ms\": 8375.959, \"total_train_time_s\": 9.63677716255188}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2021.06, \"learn_time_ms\": 8362.383, \"total_train_time_s\": 9.709708452224731}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2028.65, \"learn_time_ms\": 8492.773, \"total_train_time_s\": 10.577938795089722}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2031.81, \"learn_time_ms\": 8473.178, \"total_train_time_s\": 9.290109395980835}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2039.04, \"learn_time_ms\": 8601.384, \"total_train_time_s\": 11.66926884651184}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2039.93, \"learn_time_ms\": 8652.275, \"total_train_time_s\": 10.598918199539185}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2047.11, \"learn_time_ms\": 8686.717, \"total_train_time_s\": 10.343037605285645}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2042.48, \"learn_time_ms\": 8657.105, \"total_train_time_s\": 10.045801162719727}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2043.19, \"learn_time_ms\": 8682.086, \"total_train_time_s\": 9.775198698043823}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2040.96, \"learn_time_ms\": 8882.055, \"total_train_time_s\": 11.464182376861572}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2037.99, \"learn_time_ms\": 8849.351, \"total_train_time_s\": 9.303860187530518}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2060.57, \"learn_time_ms\": 8844.497, \"total_train_time_s\": 9.651551723480225}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2060.57, \"learn_time_ms\": 8899.437, \"total_train_time_s\": 11.112058639526367}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2063.72, \"learn_time_ms\": 9085.512, \"total_train_time_s\": 11.218470573425293}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2071.82, \"learn_time_ms\": 8991.684, \"total_train_time_s\": 10.765187978744507}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2075.77, \"learn_time_ms\": 8880.341, \"total_train_time_s\": 9.404783487319946}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2090.53, \"learn_time_ms\": 8739.796, \"total_train_time_s\": 8.969010591506958}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2090.53, \"learn_time_ms\": 8859.606, \"total_train_time_s\": 11.21376085281372}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.3, \"learn_time_ms\": 8798.229, \"total_train_time_s\": 9.264734506607056}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.3, \"learn_time_ms\": 8640.64, \"total_train_time_s\": 9.783931255340576}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2096.93, \"learn_time_ms\": 8726.365, \"total_train_time_s\": 10.189156770706177}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2096.93, \"learn_time_ms\": 8812.027, \"total_train_time_s\": 10.501123666763306}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2099.71, \"learn_time_ms\": 8731.877, \"total_train_time_s\": 10.312469244003296}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.7, \"learn_time_ms\": 8554.296, \"total_train_time_s\": 9.332084655761719}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2099.99, \"learn_time_ms\": 8512.887, \"total_train_time_s\": 10.351513862609863}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2100.52, \"learn_time_ms\": 8614.915, \"total_train_time_s\": 10.435672760009766}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2103.92, \"learn_time_ms\": 8834.91, \"total_train_time_s\": 11.153793096542358}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.87, \"learn_time_ms\": 8716.779, \"total_train_time_s\": 10.039926290512085}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.09, \"learn_time_ms\": 8868.37, \"total_train_time_s\": 10.669574975967407}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2106.75, \"learn_time_ms\": 8856.938, \"total_train_time_s\": 9.745509386062622}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.54, \"learn_time_ms\": 8860.715, \"total_train_time_s\": 10.259137868881226}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.52, \"learn_time_ms\": 8751.861, \"total_train_time_s\": 9.45689058303833}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2121.57, \"learn_time_ms\": 8714.522, \"total_train_time_s\": 10.002363920211792}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.05, \"learn_time_ms\": 8815.173, \"total_train_time_s\": 10.390508651733398}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2133.21, \"learn_time_ms\": 8737.236, \"total_train_time_s\": 9.615661144256592}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2130.59, \"learn_time_ms\": 8792.172, \"total_train_time_s\": 10.994089365005493}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2129.52, \"learn_time_ms\": 8604.031, \"total_train_time_s\": 9.296704769134521}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2121.43, \"learn_time_ms\": 8547.62, \"total_train_time_s\": 9.489986419677734}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2127.69, \"learn_time_ms\": 8612.964, \"total_train_time_s\": 11.309449434280396}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2127.69, \"learn_time_ms\": 8619.355, \"total_train_time_s\": 9.796676874160767}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.12, \"learn_time_ms\": 8660.859, \"total_train_time_s\": 10.62895679473877}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2137.07, \"learn_time_ms\": 8694.091, \"total_train_time_s\": 9.794697999954224}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2138.73, \"learn_time_ms\": 8756.152, \"total_train_time_s\": 10.572062015533447}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.39, \"learn_time_ms\": 8878.892, \"total_train_time_s\": 11.599116325378418}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.62, \"learn_time_ms\": 8950.835, \"total_train_time_s\": 10.341567516326904}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2141.78, \"learn_time_ms\": 8909.998, \"total_train_time_s\": 10.5619797706604}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2148.64, \"learn_time_ms\": 8979.908, \"total_train_time_s\": 9.98594045639038}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2153.42, \"learn_time_ms\": 9008.584, \"total_train_time_s\": 9.74792742729187}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2153.48, \"learn_time_ms\": 8891.549, \"total_train_time_s\": 10.121598482131958}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2165.67, \"learn_time_ms\": 8879.046, \"total_train_time_s\": 9.634204387664795}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2165.67, \"learn_time_ms\": 8835.812, \"total_train_time_s\": 10.195793390274048}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.37, \"learn_time_ms\": 8793.896, \"total_train_time_s\": 9.305760622024536}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2172.7, \"learn_time_ms\": 8780.727, \"total_train_time_s\": 10.409624814987183}", "{\"n\": 210, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2172.03, \"learn_time_ms\": 8728.911, \"total_train_time_s\": 11.116273880004883}", "{\"n\": 211, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2181.61, \"learn_time_ms\": 8740.735, \"total_train_time_s\": 10.41818618774414}", "{\"n\": 212, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2184.56, \"learn_time_ms\": 8666.977, \"total_train_time_s\": 9.845089197158813}", "{\"n\": 213, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2190.75, \"learn_time_ms\": 8657.326, \"total_train_time_s\": 9.915249347686768}", "{\"n\": 214, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2200.59, \"learn_time_ms\": 8693.295, \"total_train_time_s\": 10.157139301300049}", "{\"n\": 215, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2214.92, \"learn_time_ms\": 8742.91, \"total_train_time_s\": 10.62916374206543}", "{\"n\": 216, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2219.14, \"learn_time_ms\": 8761.183, \"total_train_time_s\": 9.793489933013916}", "{\"n\": 217, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2218.08, \"learn_time_ms\": 8773.613, \"total_train_time_s\": 10.302534103393555}", "{\"n\": 218, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.65, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2228.0, \"learn_time_ms\": 8829.774, \"total_train_time_s\": 9.847877502441406}", "{\"n\": 219, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2240.63, \"learn_time_ms\": 8839.82, \"total_train_time_s\": 10.507747411727905}", "{\"n\": 220, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2240.63, \"learn_time_ms\": 8664.538, \"total_train_time_s\": 9.345368385314941}", "{\"n\": 221, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2260.54, \"learn_time_ms\": 8718.302, \"total_train_time_s\": 10.977946043014526}", "{\"n\": 222, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2260.54, \"learn_time_ms\": 8845.899, \"total_train_time_s\": 11.120060205459595}", "{\"n\": 223, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.0, \"learn_time_ms\": 8882.978, \"total_train_time_s\": 10.28115963935852}", "{\"n\": 224, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2279.08, \"learn_time_ms\": 8997.641, \"total_train_time_s\": 11.309540271759033}", "{\"n\": 225, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2279.08, \"learn_time_ms\": 9005.7, \"total_train_time_s\": 10.717978954315186}", "{\"n\": 226, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2287.56, \"learn_time_ms\": 9092.673, \"total_train_time_s\": 10.705936908721924}", "{\"n\": 227, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2289.87, \"learn_time_ms\": 8914.478, \"total_train_time_s\": 8.569786548614502}", "{\"n\": 228, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2293.65, \"learn_time_ms\": 8872.463, \"total_train_time_s\": 9.472582817077637}", "{\"n\": 229, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2299.46, \"learn_time_ms\": 8762.087, \"total_train_time_s\": 9.475402593612671}", "{\"n\": 230, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2294.04, \"learn_time_ms\": 8808.276, \"total_train_time_s\": 9.81467342376709}", "{\"n\": 231, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.29, \"learn_time_ms\": 8599.247, \"total_train_time_s\": 8.886993169784546}", "{\"n\": 232, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.29, \"learn_time_ms\": 8543.968, \"total_train_time_s\": 10.57002592086792}", "{\"n\": 233, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2312.06, \"learn_time_ms\": 8535.08, \"total_train_time_s\": 10.134389638900757}", "{\"n\": 234, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2315.65, \"learn_time_ms\": 8435.679, \"total_train_time_s\": 10.44667673110962}", "{\"n\": 235, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2317.75, \"learn_time_ms\": 8549.246, \"total_train_time_s\": 11.836146354675293}", "{\"n\": 236, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.67, \"learn_time_ms\": 8589.921, \"total_train_time_s\": 11.121886014938354}", "{\"n\": 237, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.67, \"learn_time_ms\": 8831.456, \"total_train_time_s\": 10.965444803237915}", "{\"n\": 238, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.07, \"learn_time_ms\": 8938.668, \"total_train_time_s\": 10.523709297180176}", "{\"n\": 239, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.84, \"learn_time_ms\": 8948.297, \"total_train_time_s\": 9.531698226928711}", "{\"n\": 240, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.2, \"learn_time_ms\": 9085.342, \"total_train_time_s\": 11.169800996780396}", "{\"n\": 241, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.99, \"learn_time_ms\": 9211.431, \"total_train_time_s\": 10.128016948699951}", "{\"n\": 242, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2372.38, \"learn_time_ms\": 9106.862, \"total_train_time_s\": 9.529266834259033}", "{\"n\": 243, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2388.25, \"learn_time_ms\": 9145.31, \"total_train_time_s\": 10.607776403427124}", "{\"n\": 244, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.38, \"learn_time_ms\": 9194.008, \"total_train_time_s\": 10.774778842926025}", "{\"n\": 245, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2388.46, \"learn_time_ms\": 8920.061, \"total_train_time_s\": 9.116978168487549}", "{\"n\": 246, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2407.17, \"learn_time_ms\": 8768.856, \"total_train_time_s\": 9.63323712348938}", "{\"n\": 247, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2411.56, \"learn_time_ms\": 8683.154, \"total_train_time_s\": 10.094624519348145}", "{\"n\": 248, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2411.56, \"learn_time_ms\": 8848.285, \"total_train_time_s\": 12.19551968574524}", "{\"n\": 249, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.95, \"learn_time_ms\": 9171.245, \"total_train_time_s\": 12.764298915863037}", "{\"n\": 250, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.02, \"learn_time_ms\": 9066.405, \"total_train_time_s\": 10.092993021011353}", "{\"n\": 251, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2422.52, \"learn_time_ms\": 9036.136, \"total_train_time_s\": 9.787730693817139}", "{\"n\": 252, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2430.53, \"learn_time_ms\": 9260.084, \"total_train_time_s\": 11.735072612762451}", "{\"n\": 253, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2439.0, \"learn_time_ms\": 9212.899, \"total_train_time_s\": 10.083702325820923}", "{\"n\": 254, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2441.59, \"learn_time_ms\": 9037.012, \"total_train_time_s\": 9.004971742630005}", "{\"n\": 255, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2444.96, \"learn_time_ms\": 9058.316, \"total_train_time_s\": 9.303470611572266}", "{\"n\": 256, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2450.88, \"learn_time_ms\": 9096.329, \"total_train_time_s\": 9.93054723739624}", "{\"n\": 257, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2454.8, \"learn_time_ms\": 9109.85, \"total_train_time_s\": 10.261473655700684}", "{\"n\": 258, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2456.72, \"learn_time_ms\": 9083.948, \"total_train_time_s\": 11.937558650970459}", "{\"n\": 259, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2463.77, \"learn_time_ms\": 8911.672, \"total_train_time_s\": 10.994415044784546}", "{\"n\": 260, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2473.72, \"learn_time_ms\": 9057.032, \"total_train_time_s\": 11.571372032165527}", "{\"n\": 261, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2489.23, \"learn_time_ms\": 9074.979, \"total_train_time_s\": 10.036186933517456}", "{\"n\": 262, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2489.23, \"learn_time_ms\": 8948.763, \"total_train_time_s\": 10.53997802734375}", "{\"n\": 263, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2498.06, \"learn_time_ms\": 8971.397, \"total_train_time_s\": 10.298712730407715}", "{\"n\": 264, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2495.9, \"learn_time_ms\": 9247.215, \"total_train_time_s\": 11.80620789527893}", "{\"n\": 265, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2495.18, \"learn_time_ms\": 9233.688, \"total_train_time_s\": 9.148488759994507}", "{\"n\": 266, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2508.31, \"learn_time_ms\": 9302.814, \"total_train_time_s\": 10.717316389083862}", "{\"n\": 267, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2508.31, \"learn_time_ms\": 9258.594, \"total_train_time_s\": 9.786901950836182}", "{\"n\": 268, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2519.67, \"learn_time_ms\": 8987.917, \"total_train_time_s\": 9.228150367736816}", "{\"n\": 269, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2520.48, \"learn_time_ms\": 8934.601, \"total_train_time_s\": 10.50350832939148}", "{\"n\": 270, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2520.48, \"learn_time_ms\": 8817.789, \"total_train_time_s\": 10.422443151473999}", "{\"n\": 271, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2534.34, \"learn_time_ms\": 8895.114, \"total_train_time_s\": 10.771717309951782}", "{\"n\": 272, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2534.34, \"learn_time_ms\": 8853.029, \"total_train_time_s\": 10.05480670928955}", "{\"n\": 273, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2538.62, \"learn_time_ms\": 8914.174, \"total_train_time_s\": 10.87763524055481}", "{\"n\": 274, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2548.05, \"learn_time_ms\": 8743.785, \"total_train_time_s\": 10.086690664291382}", "{\"n\": 275, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2546.73, \"learn_time_ms\": 8921.403, \"total_train_time_s\": 10.94710087776184}", "{\"n\": 276, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2548.13, \"learn_time_ms\": 8970.804, \"total_train_time_s\": 11.176507711410522}", "{\"n\": 277, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2558.06, \"learn_time_ms\": 9080.027, \"total_train_time_s\": 10.910896301269531}", "{\"n\": 278, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2552.97, \"learn_time_ms\": 9231.898, \"total_train_time_s\": 10.739728927612305}", "{\"n\": 279, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2560.31, \"learn_time_ms\": 9205.286, \"total_train_time_s\": 10.248814344406128}", "{\"n\": 280, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2563.63, \"learn_time_ms\": 9201.348, \"total_train_time_s\": 10.370925426483154}", "{\"n\": 281, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2563.33, \"learn_time_ms\": 9298.182, \"total_train_time_s\": 11.72912073135376}", "{\"n\": 282, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2570.57, \"learn_time_ms\": 9288.948, \"total_train_time_s\": 10.006722450256348}", "{\"n\": 283, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2570.57, \"learn_time_ms\": 9275.367, \"total_train_time_s\": 10.756044387817383}", "{\"n\": 284, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2569.7, \"learn_time_ms\": 9366.803, \"total_train_time_s\": 10.988568305969238}", "{\"n\": 285, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2573.14, \"learn_time_ms\": 9253.471, \"total_train_time_s\": 9.803945541381836}", "{\"n\": 286, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2573.14, \"learn_time_ms\": 9194.046, \"total_train_time_s\": 10.585050582885742}", "{\"n\": 287, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2582.49, \"learn_time_ms\": 9067.543, \"total_train_time_s\": 9.678919076919556}", "{\"n\": 288, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2590.33, \"learn_time_ms\": 8935.02, \"total_train_time_s\": 9.408998250961304}", "{\"n\": 289, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2590.33, \"learn_time_ms\": 8963.548, \"total_train_time_s\": 10.55105972290039}", "{\"n\": 290, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2596.03, \"learn_time_ms\": 9028.164, \"total_train_time_s\": 11.042009115219116}", "{\"n\": 291, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2596.42, \"learn_time_ms\": 8642.911, \"total_train_time_s\": 7.853309154510498}", "{\"n\": 292, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2596.42, \"learn_time_ms\": 8735.909, \"total_train_time_s\": 10.948187589645386}", "{\"n\": 293, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2618.52, \"learn_time_ms\": 8752.786, \"total_train_time_s\": 10.942943572998047}", "{\"n\": 294, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2618.52, \"learn_time_ms\": 8564.735, \"total_train_time_s\": 9.151854753494263}", "{\"n\": 295, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2612.76, \"learn_time_ms\": 8626.264, \"total_train_time_s\": 10.49519658088684}", "{\"n\": 296, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2626.85, \"learn_time_ms\": 8553.208, \"total_train_time_s\": 9.819750308990479}", "{\"n\": 297, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2637.25, \"learn_time_ms\": 8558.632, \"total_train_time_s\": 9.680573463439941}", "{\"n\": 298, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2635.84, \"learn_time_ms\": 8472.216, \"total_train_time_s\": 8.568904638290405}", "{\"n\": 299, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2639.43, \"learn_time_ms\": 8260.337, \"total_train_time_s\": 8.40606689453125}", "{\"n\": 300, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2641.81, \"learn_time_ms\": 8180.41, \"total_train_time_s\": 10.250046253204346}", "{\"n\": 301, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2650.71, \"learn_time_ms\": 8456.549, \"total_train_time_s\": 10.681716918945312}", "{\"n\": 302, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2647.71, \"learn_time_ms\": 8394.768, \"total_train_time_s\": 10.322989225387573}", "{\"n\": 303, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2642.97, \"learn_time_ms\": 8346.517, \"total_train_time_s\": 10.454258441925049}", "{\"n\": 304, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2652.72, \"learn_time_ms\": 8457.748, \"total_train_time_s\": 10.242702722549438}", "{\"n\": 305, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2655.3, \"learn_time_ms\": 8332.156, \"total_train_time_s\": 9.264191389083862}", "{\"n\": 306, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2652.15, \"learn_time_ms\": 8365.292, \"total_train_time_s\": 10.156524896621704}", "{\"n\": 307, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2657.84, \"learn_time_ms\": 8380.718, \"total_train_time_s\": 9.874309539794922}", "{\"n\": 308, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2653.24, \"learn_time_ms\": 8583.731, \"total_train_time_s\": 10.55078935623169}", "{\"n\": 309, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2653.24, \"learn_time_ms\": 8831.433, \"total_train_time_s\": 10.850806951522827}", "{\"n\": 310, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2663.48, \"learn_time_ms\": 8868.961, \"total_train_time_s\": 10.60343050956726}", "{\"n\": 311, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2663.48, \"learn_time_ms\": 8982.402, \"total_train_time_s\": 11.782905101776123}", "{\"n\": 312, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2663.48, \"learn_time_ms\": 8956.045, \"total_train_time_s\": 10.027427911758423}", "{\"n\": 313, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2677.51, \"learn_time_ms\": 8894.3, \"total_train_time_s\": 9.88948678970337}", "{\"n\": 314, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2677.51, \"learn_time_ms\": 8967.915, \"total_train_time_s\": 10.986461639404297}", "{\"n\": 315, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2684.72, \"learn_time_ms\": 9129.39, \"total_train_time_s\": 10.78426194190979}", "{\"n\": 316, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2704.22, \"learn_time_ms\": 9189.732, \"total_train_time_s\": 10.794628620147705}", "{\"n\": 317, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2704.22, \"learn_time_ms\": 9257.93, \"total_train_time_s\": 10.481147289276123}", "{\"n\": 318, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2703.8, \"learn_time_ms\": 9126.24, \"total_train_time_s\": 9.245732545852661}", "{\"n\": 319, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2707.61, \"learn_time_ms\": 9096.33, \"total_train_time_s\": 10.586799621582031}", "{\"n\": 320, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2707.61, \"learn_time_ms\": 9067.518, \"total_train_time_s\": 10.271280765533447}", "{\"n\": 321, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2722.0, \"learn_time_ms\": 9028.139, \"total_train_time_s\": 11.414536476135254}", "{\"n\": 322, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2725.75, \"learn_time_ms\": 9069.542, \"total_train_time_s\": 10.433921813964844}", "{\"n\": 323, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2727.93, \"learn_time_ms\": 9108.637, \"total_train_time_s\": 10.215041875839233}", "{\"n\": 324, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2722.71, \"learn_time_ms\": 9025.775, \"total_train_time_s\": 10.114604949951172}", "{\"n\": 325, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2725.06, \"learn_time_ms\": 8804.644, \"total_train_time_s\": 8.589466333389282}", "{\"n\": 326, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2719.69, \"learn_time_ms\": 8654.273, \"total_train_time_s\": 9.296679496765137}", "{\"n\": 327, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2725.06, \"learn_time_ms\": 8546.019, \"total_train_time_s\": 9.42688798904419}", "{\"n\": 328, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2730.02, \"learn_time_ms\": 8742.598, \"total_train_time_s\": 11.24661636352539}", "{\"n\": 329, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2731.04, \"learn_time_ms\": 8652.2, \"total_train_time_s\": 9.664109706878662}", "{\"n\": 330, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2743.87, \"learn_time_ms\": 8703.116, \"total_train_time_s\": 10.777072668075562}", "{\"n\": 331, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2743.87, \"learn_time_ms\": 8603.527, \"total_train_time_s\": 10.385079860687256}", "{\"n\": 332, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2743.87, \"learn_time_ms\": 8485.451, \"total_train_time_s\": 9.27521014213562}", "{\"n\": 333, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2774.29, \"learn_time_ms\": 8477.239, \"total_train_time_s\": 10.166171550750732}", "{\"n\": 334, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2774.29, \"learn_time_ms\": 8622.637, \"total_train_time_s\": 11.555346488952637}", "{\"n\": 335, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.88, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2773.94, \"learn_time_ms\": 8800.398, \"total_train_time_s\": 10.389662981033325}", "{\"n\": 336, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2779.2, \"learn_time_ms\": 8821.112, \"total_train_time_s\": 9.493017435073853}", "{\"n\": 337, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2779.2, \"learn_time_ms\": 8816.666, \"total_train_time_s\": 9.361047983169556}", "{\"n\": 338, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2780.14, \"learn_time_ms\": 8720.691, \"total_train_time_s\": 10.244502544403076}", "{\"n\": 339, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2800.65, \"learn_time_ms\": 8760.95, \"total_train_time_s\": 10.08950424194336}", "{\"n\": 340, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2800.65, \"learn_time_ms\": 8706.903, \"total_train_time_s\": 10.280595541000366}", "{\"n\": 341, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2806.19, \"learn_time_ms\": 8698.794, \"total_train_time_s\": 10.372824430465698}", "{\"n\": 342, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2809.36, \"learn_time_ms\": 8820.262, \"total_train_time_s\": 10.50745177268982}", "{\"n\": 343, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2809.36, \"learn_time_ms\": 8889.912, \"total_train_time_s\": 10.795904159545898}", "{\"n\": 344, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2812.24, \"learn_time_ms\": 8761.947, \"total_train_time_s\": 10.2856605052948}", "{\"n\": 345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2818.88, \"learn_time_ms\": 8627.461, \"total_train_time_s\": 9.004685401916504}", "{\"n\": 346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2818.88, \"learn_time_ms\": 8622.066, \"total_train_time_s\": 9.432294845581055}", "{\"n\": 347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.77, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2817.38, \"learn_time_ms\": 8670.465, \"total_train_time_s\": 9.903595209121704}", "{\"n\": 348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2827.05, \"learn_time_ms\": 8643.427, \"total_train_time_s\": 10.025699138641357}", "{\"n\": 349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2827.05, \"learn_time_ms\": 8505.573, \"total_train_time_s\": 8.66325068473816}", "{\"n\": 350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2831.82, \"learn_time_ms\": 8413.204, \"total_train_time_s\": 9.35382604598999}", "{\"n\": 351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2839.71, \"learn_time_ms\": 8435.473, \"total_train_time_s\": 10.566668033599854}", "{\"n\": 352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2839.71, \"learn_time_ms\": 8444.626, \"total_train_time_s\": 10.577830076217651}", "{\"n\": 353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2839.75, \"learn_time_ms\": 8542.673, \"total_train_time_s\": 11.822914361953735}", "{\"n\": 354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2845.81, \"learn_time_ms\": 8565.505, \"total_train_time_s\": 10.517377853393555}", "{\"n\": 355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2845.81, \"learn_time_ms\": 8512.595, \"total_train_time_s\": 8.487596273422241}", "{\"n\": 356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2849.82, \"learn_time_ms\": 8763.293, \"total_train_time_s\": 11.944846868515015}", "{\"n\": 357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2853.76, \"learn_time_ms\": 8749.681, \"total_train_time_s\": 9.741985082626343}", "{\"n\": 358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2853.76, \"learn_time_ms\": 8697.583, \"total_train_time_s\": 9.49522614479065}", "{\"n\": 359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2858.29, \"learn_time_ms\": 8943.294, \"total_train_time_s\": 11.173150062561035}", "{\"n\": 360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2865.04, \"learn_time_ms\": 9048.404, \"total_train_time_s\": 10.369179010391235}", "{\"n\": 361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2863.59, \"learn_time_ms\": 9018.291, \"total_train_time_s\": 10.238824129104614}", "{\"n\": 362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2868.17, \"learn_time_ms\": 9071.558, \"total_train_time_s\": 11.083296060562134}", "{\"n\": 363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2872.34, \"learn_time_ms\": 8993.207, \"total_train_time_s\": 11.006517171859741}", "{\"n\": 364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2868.03, \"learn_time_ms\": 9080.913, \"total_train_time_s\": 11.373389959335327}", "{\"n\": 365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2857.76, \"learn_time_ms\": 9336.638, \"total_train_time_s\": 11.04782509803772}", "{\"n\": 366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2860.3, \"learn_time_ms\": 9152.407, \"total_train_time_s\": 10.073364019393921}", "{\"n\": 367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2861.58, \"learn_time_ms\": 9311.728, \"total_train_time_s\": 11.32646656036377}", "{\"n\": 368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2869.1, \"learn_time_ms\": 9417.831, \"total_train_time_s\": 10.555325269699097}", "{\"n\": 369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2876.98, \"learn_time_ms\": 9356.078, \"total_train_time_s\": 10.528924465179443}", "{\"n\": 370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2878.53, \"learn_time_ms\": 9448.267, \"total_train_time_s\": 11.339518547058105}", "{\"n\": 371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2876.83, \"learn_time_ms\": 9443.954, \"total_train_time_s\": 10.201295137405396}", "{\"n\": 372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2883.69, \"learn_time_ms\": 9505.426, \"total_train_time_s\": 11.714085102081299}", "{\"n\": 373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2883.69, \"learn_time_ms\": 9489.501, \"total_train_time_s\": 10.865482807159424}", "{\"n\": 374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2894.48, \"learn_time_ms\": 9383.568, \"total_train_time_s\": 10.346240282058716}", "{\"n\": 375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2894.48, \"learn_time_ms\": 9299.156, \"total_train_time_s\": 10.22433614730835}", "{\"n\": 376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2900.28, \"learn_time_ms\": 9417.006, \"total_train_time_s\": 11.258628129959106}", "{\"n\": 377, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2907.39, \"learn_time_ms\": 9361.624, \"total_train_time_s\": 10.814278364181519}", "{\"n\": 378, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2907.39, \"learn_time_ms\": 9417.343, \"total_train_time_s\": 11.117035388946533}", "{\"n\": 379, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2910.23, \"learn_time_ms\": 9310.248, \"total_train_time_s\": 9.468657493591309}", "{\"n\": 380, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2930.84, \"learn_time_ms\": 9050.923, \"total_train_time_s\": 8.721460819244385}", "{\"n\": 381, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2930.84, \"learn_time_ms\": 8897.626, \"total_train_time_s\": 8.703763484954834}", "{\"n\": 382, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2932.92, \"learn_time_ms\": 8699.142, \"total_train_time_s\": 9.735393762588501}", "{\"n\": 383, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2938.16, \"learn_time_ms\": 8571.193, \"total_train_time_s\": 9.603385925292969}", "{\"n\": 384, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2938.16, \"learn_time_ms\": 8443.002, \"total_train_time_s\": 9.010416030883789}", "{\"n\": 385, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2933.41, \"learn_time_ms\": 8483.108, \"total_train_time_s\": 10.621946096420288}", "{\"n\": 386, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.56, \"learn_time_ms\": 8359.751, \"total_train_time_s\": 10.029939651489258}", "{\"n\": 387, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.56, \"learn_time_ms\": 8263.689, \"total_train_time_s\": 9.850499391555786}", "{\"n\": 388, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2920.88, \"learn_time_ms\": 8307.495, \"total_train_time_s\": 11.57956838607788}", "{\"n\": 389, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2915.07, \"learn_time_ms\": 8449.731, \"total_train_time_s\": 10.922389268875122}", "{\"n\": 390, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2915.07, \"learn_time_ms\": 8585.455, \"total_train_time_s\": 10.040564060211182}", "{\"n\": 391, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2926.95, \"learn_time_ms\": 8793.761, \"total_train_time_s\": 10.775946855545044}", "{\"n\": 392, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2937.18, \"learn_time_ms\": 8827.74, \"total_train_time_s\": 10.065102815628052}", "{\"n\": 393, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2937.18, \"learn_time_ms\": 8984.263, \"total_train_time_s\": 11.20922064781189}", "{\"n\": 394, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2934.65, \"learn_time_ms\": 9114.237, \"total_train_time_s\": 10.390340805053711}", "{\"n\": 395, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2925.04, \"learn_time_ms\": 9078.749, \"total_train_time_s\": 10.260012149810791}", "{\"n\": 396, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2927.04, \"learn_time_ms\": 9074.893, \"total_train_time_s\": 9.99065899848938}", "{\"n\": 397, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2942.65, \"learn_time_ms\": 9206.408, \"total_train_time_s\": 11.142563819885254}", "{\"n\": 398, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2951.69, \"learn_time_ms\": 8997.429, \"total_train_time_s\": 9.452594757080078}", "{\"n\": 399, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.99, \"learn_time_ms\": 8916.192, \"total_train_time_s\": 10.053626537322998}", "{\"n\": 400, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2964.89, \"learn_time_ms\": 8970.813, \"total_train_time_s\": 10.689886331558228}", "{\"n\": 401, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.26, \"learn_time_ms\": 8829.595, \"total_train_time_s\": 9.297251462936401}", "{\"n\": 402, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2969.89, \"learn_time_ms\": 8728.579, \"total_train_time_s\": 9.0934476852417}", "{\"n\": 403, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2968.95, \"learn_time_ms\": 8572.112, \"total_train_time_s\": 9.591229438781738}", "{\"n\": 404, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.97, \"learn_time_ms\": 8511.403, \"total_train_time_s\": 9.762785196304321}", "{\"n\": 405, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2975.76, \"learn_time_ms\": 8556.443, \"total_train_time_s\": 10.742740392684937}", "{\"n\": 406, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.85, \"learn_time_ms\": 8559.833, \"total_train_time_s\": 10.03213119506836}", "{\"n\": 407, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2973.27, \"learn_time_ms\": 8396.897, \"total_train_time_s\": 9.535268545150757}", "{\"n\": 408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2970.08, \"learn_time_ms\": 8616.023, \"total_train_time_s\": 11.69356083869934}", "{\"n\": 409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.82, \"learn_time_ms\": 8544.148, \"total_train_time_s\": 9.395933628082275}", "{\"n\": 410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2973.35, \"learn_time_ms\": 8612.33, \"total_train_time_s\": 11.341918468475342}", "{\"n\": 411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.9, \"learn_time_ms\": 8775.188, \"total_train_time_s\": 11.016857385635376}", "{\"n\": 412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2969.97, \"learn_time_ms\": 8802.952, \"total_train_time_s\": 9.362654685974121}", "{\"n\": 413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.2, \"learn_time_ms\": 8640.84, \"total_train_time_s\": 7.999900579452515}", "{\"n\": 414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2961.1, \"learn_time_ms\": 8732.053, \"total_train_time_s\": 10.640429735183716}", "{\"n\": 415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2959.26, \"learn_time_ms\": 8650.953, \"total_train_time_s\": 9.899129390716553}", "{\"n\": 416, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.78, \"learn_time_ms\": 8597.043, \"total_train_time_s\": 9.529063940048218}", "{\"n\": 417, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2956.58, \"learn_time_ms\": 8721.578, \"total_train_time_s\": 10.763368606567383}", "{\"n\": 418, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.88, \"learn_time_ms\": 8560.993, \"total_train_time_s\": 10.041373014450073}", "{\"n\": 419, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.29, \"learn_time_ms\": 8742.218, \"total_train_time_s\": 11.184214115142822}", "{\"n\": 420, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2959.57, \"learn_time_ms\": 8558.408, \"total_train_time_s\": 9.509429454803467}", "{\"n\": 421, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2952.01, \"learn_time_ms\": 8443.541, \"total_train_time_s\": 9.842983722686768}", "{\"n\": 422, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2952.01, \"learn_time_ms\": 8578.749, \"total_train_time_s\": 10.69752311706543}", "{\"n\": 423, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.82, \"learn_time_ms\": 8686.692, \"total_train_time_s\": 9.065476417541504}", "{\"n\": 424, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.87, \"learn_time_ms\": 8788.229, \"total_train_time_s\": 11.69672966003418}", "{\"n\": 425, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.87, \"learn_time_ms\": 8851.669, \"total_train_time_s\": 10.529600620269775}", "{\"n\": 426, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.66, \"learn_time_ms\": 8999.987, \"total_train_time_s\": 10.931057214736938}", "{\"n\": 427, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2944.63, \"learn_time_ms\": 8896.368, \"total_train_time_s\": 9.729286432266235}", "{\"n\": 428, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2944.63, \"learn_time_ms\": 8906.064, \"total_train_time_s\": 10.19008207321167}", "{\"n\": 429, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.21, \"learn_time_ms\": 8841.387, \"total_train_time_s\": 10.529658555984497}", "{\"n\": 430, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.98, \"learn_time_ms\": 8887.107, \"total_train_time_s\": 9.9258713722229}", "{\"n\": 431, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.98, \"learn_time_ms\": 8820.038, \"total_train_time_s\": 9.122659683227539}", "{\"n\": 432, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.23, \"learn_time_ms\": 8837.969, \"total_train_time_s\": 10.880604028701782}", "{\"n\": 433, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.1, \"learn_time_ms\": 8998.66, \"total_train_time_s\": 10.725123167037964}", "{\"n\": 434, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.38, \"learn_time_ms\": 8798.403, \"total_train_time_s\": 9.68131709098816}", "{\"n\": 435, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.08, \"learn_time_ms\": 8822.2, \"total_train_time_s\": 10.773524761199951}", "{\"n\": 436, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.01, \"learn_time_ms\": 8808.48, \"total_train_time_s\": 10.869867324829102}", "{\"n\": 437, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.38, \"learn_time_ms\": 8833.266, \"total_train_time_s\": 9.949867725372314}", "{\"n\": 438, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.14, \"learn_time_ms\": 8887.167, \"total_train_time_s\": 10.689875841140747}", "{\"n\": 439, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.69, \"learn_time_ms\": 8845.114, \"total_train_time_s\": 10.064282417297363}", "{\"n\": 440, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2958.76, \"learn_time_ms\": 8734.576, \"total_train_time_s\": 8.806810140609741}", "{\"n\": 441, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.7, \"learn_time_ms\": 8849.962, \"total_train_time_s\": 10.314533948898315}", "{\"n\": 442, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.6, \"learn_time_ms\": 8865.228, \"total_train_time_s\": 10.995612621307373}", "{\"n\": 443, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2946.05, \"learn_time_ms\": 8721.139, \"total_train_time_s\": 9.29293704032898}", "{\"n\": 444, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.09, \"learn_time_ms\": 8773.705, \"total_train_time_s\": 10.222519397735596}", "{\"n\": 445, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2938.24, \"learn_time_ms\": 8768.16, \"total_train_time_s\": 10.73322319984436}", "{\"n\": 446, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2935.05, \"learn_time_ms\": 8673.61, \"total_train_time_s\": 9.90236783027649}", "{\"n\": 447, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2937.56, \"learn_time_ms\": 8593.219, \"total_train_time_s\": 9.179765462875366}", "{\"n\": 448, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2940.87, \"learn_time_ms\": 8463.257, \"total_train_time_s\": 9.371801137924194}", "{\"n\": 449, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.89, \"learn_time_ms\": 8695.445, \"total_train_time_s\": 12.397674322128296}", "{\"n\": 450, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.42, \"learn_time_ms\": 8854.72, \"total_train_time_s\": 10.389237642288208}", "{\"n\": 451, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2958.5, \"learn_time_ms\": 8816.361, \"total_train_time_s\": 9.906988859176636}", "{\"n\": 452, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.3, \"learn_time_ms\": 8597.78, \"total_train_time_s\": 8.833122968673706}", "{\"n\": 453, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.63, \"learn_time_ms\": 8783.02, \"total_train_time_s\": 11.064937114715576}", "{\"n\": 454, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2952.21, \"learn_time_ms\": 8746.476, \"total_train_time_s\": 9.819987297058105}", "{\"n\": 455, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.07, \"learn_time_ms\": 8657.39, \"total_train_time_s\": 9.832785367965698}", "{\"n\": 456, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.36, \"learn_time_ms\": 8635.328, \"total_train_time_s\": 9.642305850982666}", "{\"n\": 457, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.98, \"learn_time_ms\": 8765.267, \"total_train_time_s\": 10.466631650924683}", "{\"n\": 458, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.67, \"learn_time_ms\": 8908.866, \"total_train_time_s\": 10.793697118759155}", "{\"n\": 459, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2964.34, \"learn_time_ms\": 8785.006, \"total_train_time_s\": 11.207127571105957}", "{\"n\": 460, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2958.09, \"learn_time_ms\": 8743.26, \"total_train_time_s\": 10.01428484916687}", "{\"n\": 461, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.52, \"learn_time_ms\": 8878.406, \"total_train_time_s\": 11.247262716293335}", "{\"n\": 462, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2958.35, \"learn_time_ms\": 9090.463, \"total_train_time_s\": 10.960693597793579}", "{\"n\": 463, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.13, \"learn_time_ms\": 9061.916, \"total_train_time_s\": 10.818835735321045}", "{\"n\": 464, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.4, \"learn_time_ms\": 9042.349, \"total_train_time_s\": 9.67648720741272}", "{\"n\": 465, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2961.73, \"learn_time_ms\": 8947.289, \"total_train_time_s\": 8.852413177490234}", "{\"n\": 466, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2959.79, \"learn_time_ms\": 8962.975, \"total_train_time_s\": 9.836965560913086}", "{\"n\": 467, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2961.03, \"learn_time_ms\": 9002.193, \"total_train_time_s\": 10.797698259353638}", "{\"n\": 468, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2959.37, \"learn_time_ms\": 8909.858, \"total_train_time_s\": 9.866827011108398}", "{\"n\": 469, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.56, \"learn_time_ms\": 8856.351, \"total_train_time_s\": 10.63628625869751}", "{\"n\": 470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.14, \"learn_time_ms\": 8790.869, \"total_train_time_s\": 9.346816539764404}", "{\"n\": 471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.49, \"learn_time_ms\": 8618.67, \"total_train_time_s\": 9.563621282577515}", "{\"n\": 472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.41, \"learn_time_ms\": 8465.435, \"total_train_time_s\": 9.439958572387695}", "{\"n\": 473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.44, \"learn_time_ms\": 8360.46, \"total_train_time_s\": 9.779521942138672}", "{\"n\": 474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.6, \"learn_time_ms\": 8454.106, \"total_train_time_s\": 10.621692657470703}", "{\"n\": 475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2946.61, \"learn_time_ms\": 8494.09, \"total_train_time_s\": 9.306624174118042}", "{\"n\": 476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2956.25, \"learn_time_ms\": 8434.746, \"total_train_time_s\": 9.24116039276123}", "{\"n\": 477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.86, \"learn_time_ms\": 8438.221, \"total_train_time_s\": 10.856417417526245}", "{\"n\": 478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2952.46, \"learn_time_ms\": 8466.833, \"total_train_time_s\": 10.219919443130493}", "{\"n\": 479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2961.14, \"learn_time_ms\": 8513.475, \"total_train_time_s\": 11.150748014450073}", "{\"n\": 480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2961.14, \"learn_time_ms\": 8507.595, \"total_train_time_s\": 9.357637643814087}", "{\"n\": 481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2967.26, \"learn_time_ms\": 8495.961, \"total_train_time_s\": 9.399423837661743}", "{\"n\": 482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2969.83, \"learn_time_ms\": 8598.028, \"total_train_time_s\": 10.447803735733032}", "{\"n\": 483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.68, \"learn_time_ms\": 8666.926, \"total_train_time_s\": 10.431625843048096}", "{\"n\": 484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2967.45, \"learn_time_ms\": 8667.096, \"total_train_time_s\": 10.624121904373169}", "{\"n\": 485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.88, \"learn_time_ms\": 8715.336, \"total_train_time_s\": 9.819843053817749}", "{\"n\": 486, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2970.26, \"learn_time_ms\": 8839.154, \"total_train_time_s\": 10.497354745864868}", "{\"n\": 487, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2973.53, \"learn_time_ms\": 8701.077, \"total_train_time_s\": 9.455785751342773}", "{\"n\": 488, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2973.71, \"learn_time_ms\": 8728.675, \"total_train_time_s\": 10.439682722091675}", "{\"n\": 489, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2976.68, \"learn_time_ms\": 8561.042, \"total_train_time_s\": 9.465259552001953}", "{\"n\": 490, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2984.38, \"learn_time_ms\": 8557.287, \"total_train_time_s\": 9.192667245864868}", "{\"n\": 491, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2985.92, \"learn_time_ms\": 8576.154, \"total_train_time_s\": 9.620870590209961}", "{\"n\": 492, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2986.32, \"learn_time_ms\": 8473.291, \"total_train_time_s\": 9.41144585609436}", "{\"n\": 493, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2986.05, \"learn_time_ms\": 8599.971, \"total_train_time_s\": 11.717763900756836}", "{\"n\": 494, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2987.51, \"learn_time_ms\": 8427.894, \"total_train_time_s\": 8.833938837051392}", "{\"n\": 495, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2992.61, \"learn_time_ms\": 8492.74, \"total_train_time_s\": 10.426993370056152}", "{\"n\": 496, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.2, \"learn_time_ms\": 8436.28, \"total_train_time_s\": 9.913286685943604}", "{\"n\": 497, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2989.45, \"learn_time_ms\": 8423.141, \"total_train_time_s\": 9.402132511138916}", "{\"n\": 498, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.96, \"learn_time_ms\": 8462.184, \"total_train_time_s\": 10.827944040298462}", "{\"n\": 499, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.59, \"learn_time_ms\": 8413.385, \"total_train_time_s\": 8.907208919525146}", "{\"n\": 500, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.59, \"learn_time_ms\": 8515.953, \"total_train_time_s\": 10.27824354171753}", "{\"n\": 501, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3000.26, \"learn_time_ms\": 8522.898, \"total_train_time_s\": 9.731724262237549}", "{\"n\": 502, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2998.36, \"learn_time_ms\": 8567.805, \"total_train_time_s\": 9.892024517059326}", "{\"n\": 503, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2998.36, \"learn_time_ms\": 8531.896, \"total_train_time_s\": 11.335131168365479}", "{\"n\": 504, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3001.27, \"learn_time_ms\": 8715.661, \"total_train_time_s\": 10.746299028396606}", "{\"n\": 505, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2995.93, \"learn_time_ms\": 8571.087, \"total_train_time_s\": 8.941025018692017}", "{\"n\": 506, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2996.43, \"learn_time_ms\": 8659.372, \"total_train_time_s\": 10.838314771652222}", "{\"n\": 507, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2992.4, \"learn_time_ms\": 8787.25, \"total_train_time_s\": 10.711374759674072}", "{\"n\": 508, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2992.4, \"learn_time_ms\": 8858.079, \"total_train_time_s\": 11.515588998794556}", "{\"n\": 509, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2983.73, \"learn_time_ms\": 9091.615, \"total_train_time_s\": 11.256683588027954}", "{\"n\": 510, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2989.59, \"learn_time_ms\": 9089.465, \"total_train_time_s\": 10.23862361907959}", "{\"n\": 511, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2989.59, \"learn_time_ms\": 9151.737, \"total_train_time_s\": 10.302258968353271}", "{\"n\": 512, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2995.66, \"learn_time_ms\": 9146.212, \"total_train_time_s\": 9.861682653427124}", "{\"n\": 513, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2989.86, \"learn_time_ms\": 8902.213, \"total_train_time_s\": 8.923608779907227}", "{\"n\": 514, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2989.86, \"learn_time_ms\": 8862.722, \"total_train_time_s\": 10.339510679244995}", "{\"n\": 515, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2988.2, \"learn_time_ms\": 9064.054, \"total_train_time_s\": 10.956207513809204}", "{\"n\": 516, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.91, \"learn_time_ms\": 9074.12, \"total_train_time_s\": 10.893195629119873}", "{\"n\": 517, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.91, \"learn_time_ms\": 8913.169, \"total_train_time_s\": 9.028883934020996}", "{\"n\": 518, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.91, \"learn_time_ms\": 8846.956, \"total_train_time_s\": 10.880359411239624}", "{\"n\": 519, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.51, \"learn_time_ms\": 8658.252, \"total_train_time_s\": 9.418389081954956}", "{\"n\": 520, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.51, \"learn_time_ms\": 8625.598, \"total_train_time_s\": 9.864971160888672}", "{\"n\": 521, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.51, \"learn_time_ms\": 8711.551, \"total_train_time_s\": 11.184608221054077}", "{\"n\": 522, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3003.64, \"learn_time_ms\": 8749.668, \"total_train_time_s\": 10.19045877456665}", "{\"n\": 523, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3003.64, \"learn_time_ms\": 8990.634, \"total_train_time_s\": 11.314483404159546}", "{\"n\": 524, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3003.64, \"learn_time_ms\": 8966.075, \"total_train_time_s\": 10.107037782669067}", "{\"n\": 525, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3004.57, \"learn_time_ms\": 8950.373, \"total_train_time_s\": 10.822267055511475}", "{\"n\": 526, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3004.57, \"learn_time_ms\": 8867.449, \"total_train_time_s\": 10.061295747756958}", "{\"n\": 527, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3004.57, \"learn_time_ms\": 9038.976, \"total_train_time_s\": 10.767220497131348}", "{\"n\": 528, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3003.19, \"learn_time_ms\": 8873.343, \"total_train_time_s\": 9.202660322189331}", "{\"n\": 529, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3005.89, \"learn_time_ms\": 8880.424, \"total_train_time_s\": 9.465858459472656}", "{\"n\": 530, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3005.89, \"learn_time_ms\": 8926.717, \"total_train_time_s\": 10.381490707397461}", "{\"n\": 531, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3002.94, \"learn_time_ms\": 8734.704, \"total_train_time_s\": 9.267206192016602}", "{\"n\": 532, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3007.52, \"learn_time_ms\": 8883.454, \"total_train_time_s\": 11.694686889648438}", "{\"n\": 533, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3007.52, \"learn_time_ms\": 8745.693, \"total_train_time_s\": 9.937914371490479}", "{\"n\": 534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3012.74, \"learn_time_ms\": 8711.384, \"total_train_time_s\": 9.738376379013062}", "{\"n\": 535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3011.38, \"learn_time_ms\": 8641.021, \"total_train_time_s\": 10.132060527801514}", "{\"n\": 536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3011.38, \"learn_time_ms\": 8685.533, \"total_train_time_s\": 10.49057650566101}", "{\"n\": 537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3011.24, \"learn_time_ms\": 8735.686, \"total_train_time_s\": 11.267575025558472}", "{\"n\": 538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3018.1, \"learn_time_ms\": 8854.027, \"total_train_time_s\": 10.43504810333252}", "{\"n\": 539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3018.1, \"learn_time_ms\": 8827.045, \"total_train_time_s\": 9.197993040084839}", "{\"n\": 540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3016.59, \"learn_time_ms\": 8890.856, \"total_train_time_s\": 10.99793028831482}", "{\"n\": 541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3030.53, \"learn_time_ms\": 8975.988, \"total_train_time_s\": 10.116329193115234}", "{\"n\": 542, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3031.5, \"learn_time_ms\": 8740.428, \"total_train_time_s\": 9.296037197113037}", "{\"n\": 543, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3031.5, \"learn_time_ms\": 8816.588, \"total_train_time_s\": 10.702537298202515}", "{\"n\": 544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.64, \"learn_time_ms\": 8845.607, \"total_train_time_s\": 10.035585641860962}", "{\"n\": 545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.43, \"learn_time_ms\": 8774.569, \"total_train_time_s\": 9.411097764968872}", "{\"n\": 546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.43, \"learn_time_ms\": 8920.783, \"total_train_time_s\": 11.947492599487305}", "{\"n\": 547, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.45, \"learn_time_ms\": 8836.169, \"total_train_time_s\": 10.44603443145752}", "{\"n\": 548, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.09, \"learn_time_ms\": 8716.549, \"total_train_time_s\": 9.207586288452148}", "{\"n\": 549, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3035.99, \"learn_time_ms\": 8895.518, \"total_train_time_s\": 10.996746301651001}", "{\"n\": 550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3039.07, \"learn_time_ms\": 8848.961, \"total_train_time_s\": 10.548802375793457}", "{\"n\": 551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.6, \"learn_time_ms\": 8810.058, \"total_train_time_s\": 9.724297046661377}", "{\"n\": 552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3038.43, \"learn_time_ms\": 9005.693, \"total_train_time_s\": 11.287961483001709}", "{\"n\": 553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3037.76, \"learn_time_ms\": 8960.422, \"total_train_time_s\": 10.231460571289062}", "{\"n\": 554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3036.89, \"learn_time_ms\": 8959.763, \"total_train_time_s\": 9.994549751281738}", "{\"n\": 555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3031.54, \"learn_time_ms\": 9071.683, \"total_train_time_s\": 10.519031763076782}", "{\"n\": 556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3029.06, \"learn_time_ms\": 8919.49, \"total_train_time_s\": 10.421492576599121}", "{\"n\": 557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3031.61, \"learn_time_ms\": 9001.075, \"total_train_time_s\": 11.221231698989868}", "{\"n\": 558, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3034.14, \"learn_time_ms\": 9212.758, \"total_train_time_s\": 11.332375764846802}", "{\"n\": 559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3029.19, \"learn_time_ms\": 9149.685, \"total_train_time_s\": 10.350245237350464}", "{\"n\": 560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3040.63, \"learn_time_ms\": 9060.293, \"total_train_time_s\": 9.61620020866394}", "{\"n\": 561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3043.15, \"learn_time_ms\": 9207.493, \"total_train_time_s\": 11.189006567001343}", "{\"n\": 562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3047.7, \"learn_time_ms\": 9157.193, \"total_train_time_s\": 10.781716346740723}", "{\"n\": 563, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3046.92, \"learn_time_ms\": 9071.391, \"total_train_time_s\": 9.400184392929077}", "{\"n\": 564, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3048.8, \"learn_time_ms\": 9062.06, \"total_train_time_s\": 9.887190341949463}", "{\"n\": 565, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3049.82, \"learn_time_ms\": 8959.104, \"total_train_time_s\": 9.503160953521729}", "{\"n\": 566, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3058.54, \"learn_time_ms\": 8926.915, \"total_train_time_s\": 10.182846784591675}", "{\"n\": 567, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3056.24, \"learn_time_ms\": 8705.254, \"total_train_time_s\": 9.034027338027954}", "{\"n\": 568, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3058.48, \"learn_time_ms\": 8543.492, \"total_train_time_s\": 9.785167455673218}", "{\"n\": 569, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3054.96, \"learn_time_ms\": 8522.469, \"total_train_time_s\": 10.12751293182373}", "{\"n\": 570, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3057.69, \"learn_time_ms\": 8737.462, \"total_train_time_s\": 11.853088140487671}", "{\"n\": 571, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3055.46, \"learn_time_ms\": 8657.934, \"total_train_time_s\": 10.430837154388428}", "{\"n\": 572, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3059.58, \"learn_time_ms\": 8534.322, \"total_train_time_s\": 9.582964658737183}", "{\"n\": 573, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3067.17, \"learn_time_ms\": 8528.039, \"total_train_time_s\": 9.316635370254517}", "{\"n\": 574, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3060.48, \"learn_time_ms\": 8704.657, \"total_train_time_s\": 11.668322801589966}", "{\"n\": 575, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3060.48, \"learn_time_ms\": 8876.134, \"total_train_time_s\": 11.175546884536743}", "{\"n\": 576, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3057.81, \"learn_time_ms\": 8836.826, \"total_train_time_s\": 9.753947734832764}", "{\"n\": 577, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3065.17, \"learn_time_ms\": 9043.429, \"total_train_time_s\": 11.093931913375854}", "{\"n\": 578, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3062.06, \"learn_time_ms\": 9118.856, \"total_train_time_s\": 10.461613893508911}", "{\"n\": 579, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3066.4, \"learn_time_ms\": 9207.839, \"total_train_time_s\": 11.042276382446289}", "{\"n\": 580, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3073.0, \"learn_time_ms\": 9054.375, \"total_train_time_s\": 10.275879144668579}", "{\"n\": 581, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3070.24, \"learn_time_ms\": 9247.01, \"total_train_time_s\": 12.271681547164917}", "{\"n\": 582, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3075.2, \"learn_time_ms\": 9235.078, \"total_train_time_s\": 9.456571578979492}", "{\"n\": 583, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3075.55, \"learn_time_ms\": 9264.45, \"total_train_time_s\": 9.587444305419922}", "{\"n\": 584, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3082.83, \"learn_time_ms\": 9131.032, \"total_train_time_s\": 10.360476016998291}", "{\"n\": 585, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3078.79, \"learn_time_ms\": 9008.172, \"total_train_time_s\": 9.986767768859863}", "{\"n\": 586, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3086.37, \"learn_time_ms\": 9036.292, \"total_train_time_s\": 10.04775857925415}", "{\"n\": 587, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3084.44, \"learn_time_ms\": 9150.421, \"total_train_time_s\": 12.203564643859863}", "{\"n\": 588, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3087.39, \"learn_time_ms\": 9141.578, \"total_train_time_s\": 10.373898029327393}", "{\"n\": 589, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3086.83, \"learn_time_ms\": 9117.985, \"total_train_time_s\": 10.826833724975586}", "{\"n\": 590, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3095.14, \"learn_time_ms\": 9153.191, \"total_train_time_s\": 10.644205570220947}", "{\"n\": 591, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3094.11, \"learn_time_ms\": 8913.483, \"total_train_time_s\": 9.912230730056763}", "{\"n\": 592, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3096.02, \"learn_time_ms\": 8859.198, \"total_train_time_s\": 8.869301080703735}", "{\"n\": 593, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3102.2, \"learn_time_ms\": 8978.196, \"total_train_time_s\": 10.838114738464355}", "{\"n\": 594, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3102.2, \"learn_time_ms\": 8802.205, \"total_train_time_s\": 8.635889530181885}", "{\"n\": 595, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3105.34, \"learn_time_ms\": 8718.991, \"total_train_time_s\": 9.159253120422363}", "{\"n\": 596, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3097.05, \"learn_time_ms\": 8767.906, \"total_train_time_s\": 10.45339059829712}", "{\"n\": 597, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3097.05, \"learn_time_ms\": 8682.446, \"total_train_time_s\": 11.352500677108765}", "{\"n\": 598, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3095.15, \"learn_time_ms\": 8669.89, \"total_train_time_s\": 10.238150596618652}", "{\"n\": 599, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3092.08, \"learn_time_ms\": 8630.128, \"total_train_time_s\": 10.444094896316528}", "{\"n\": 600, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3092.08, \"learn_time_ms\": 8542.911, \"total_train_time_s\": 9.763999462127686}", "{\"n\": 601, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3080.88, \"learn_time_ms\": 8659.767, \"total_train_time_s\": 11.104137659072876}", "{\"n\": 602, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3081.87, \"learn_time_ms\": 8832.528, \"total_train_time_s\": 10.584006309509277}", "{\"n\": 603, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3091.29, \"learn_time_ms\": 8885.3, \"total_train_time_s\": 11.367990255355835}", "{\"n\": 604, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3088.71, \"learn_time_ms\": 9019.787, \"total_train_time_s\": 9.922584533691406}", "{\"n\": 605, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3085.95, \"learn_time_ms\": 9121.671, \"total_train_time_s\": 10.150754928588867}", "{\"n\": 606, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3094.22, \"learn_time_ms\": 9017.978, \"total_train_time_s\": 9.510130167007446}", "{\"n\": 607, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3094.11, \"learn_time_ms\": 8961.729, \"total_train_time_s\": 10.799198389053345}", "{\"n\": 608, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3096.18, \"learn_time_ms\": 9028.139, \"total_train_time_s\": 10.939064025878906}", "{\"n\": 609, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3100.31, \"learn_time_ms\": 8977.566, \"total_train_time_s\": 9.921655654907227}", "{\"n\": 610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3098.7, \"learn_time_ms\": 9038.032, \"total_train_time_s\": 10.381199836730957}", "{\"n\": 611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3096.27, \"learn_time_ms\": 8884.397, \"total_train_time_s\": 9.502492904663086}", "{\"n\": 612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3088.57, \"learn_time_ms\": 8791.61, \"total_train_time_s\": 9.714098691940308}", "{\"n\": 613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.31, \"learn_time_ms\": 8759.673, \"total_train_time_s\": 10.975162029266357}", "{\"n\": 614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3103.06, \"learn_time_ms\": 8755.5, \"total_train_time_s\": 9.898958444595337}", "{\"n\": 615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3106.37, \"learn_time_ms\": 8769.238, \"total_train_time_s\": 10.34177827835083}", "{\"n\": 616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3100.21, \"learn_time_ms\": 8851.473, \"total_train_time_s\": 10.25272512435913}", "{\"n\": 617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3100.21, \"learn_time_ms\": 8764.306, \"total_train_time_s\": 9.913201332092285}", "{\"n\": 618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3098.75, \"learn_time_ms\": 8656.116, \"total_train_time_s\": 9.838293075561523}", "{\"n\": 619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3094.68, \"learn_time_ms\": 8693.095, \"total_train_time_s\": 10.278625011444092}", "{\"n\": 620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3094.68, \"learn_time_ms\": 8643.893, \"total_train_time_s\": 9.848579168319702}", "{\"n\": 621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3089.73, \"learn_time_ms\": 8758.483, \"total_train_time_s\": 10.684171676635742}", "{\"n\": 622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3092.37, \"learn_time_ms\": 8687.953, \"total_train_time_s\": 8.966012954711914}", "{\"n\": 623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3092.37, \"learn_time_ms\": 8527.064, \"total_train_time_s\": 9.39082384109497}", "{\"n\": 624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3092.37, \"learn_time_ms\": 8547.063, \"total_train_time_s\": 10.123103141784668}", "{\"n\": 625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.24, \"learn_time_ms\": 8463.81, \"total_train_time_s\": 9.472382307052612}", "{\"n\": 626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.24, \"learn_time_ms\": 8475.566, \"total_train_time_s\": 10.401453256607056}", "{\"n\": 627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.24, \"learn_time_ms\": 8555.287, \"total_train_time_s\": 10.71861481666565}", "{\"n\": 628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.22, \"learn_time_ms\": 8548.899, \"total_train_time_s\": 9.792427778244019}", "{\"n\": 629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.22, \"learn_time_ms\": 8550.936, \"total_train_time_s\": 10.291813611984253}", "{\"n\": 630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.22, \"learn_time_ms\": 8536.237, \"total_train_time_s\": 9.71970248222351}", "{\"n\": 631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.68, \"learn_time_ms\": 8556.924, \"total_train_time_s\": 10.884644031524658}", "{\"n\": 632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.68, \"learn_time_ms\": 8527.299, \"total_train_time_s\": 8.644423007965088}", "{\"n\": 633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3090.68, \"learn_time_ms\": 8545.364, \"total_train_time_s\": 9.534534692764282}", "{\"n\": 634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3085.75, \"learn_time_ms\": 8537.006, \"total_train_time_s\": 10.045172214508057}", "{\"n\": 635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3087.56, \"learn_time_ms\": 8604.632, \"total_train_time_s\": 10.146039485931396}", "{\"n\": 636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3073.75, \"learn_time_ms\": 8685.237, \"total_train_time_s\": 11.281340599060059}", "{\"n\": 637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3073.31, \"learn_time_ms\": 8720.49, \"total_train_time_s\": 11.083586931228638}", "{\"n\": 638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3074.43, \"learn_time_ms\": 8781.137, \"total_train_time_s\": 10.390778064727783}", "{\"n\": 639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3071.39, \"learn_time_ms\": 8772.027, \"total_train_time_s\": 10.169718503952026}", "{\"n\": 640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3068.29, \"learn_time_ms\": 8791.026, \"total_train_time_s\": 9.94151520729065}", "{\"n\": 641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3066.3, \"learn_time_ms\": 8764.757, \"total_train_time_s\": 10.679330825805664}", "{\"n\": 642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3066.3, \"learn_time_ms\": 8732.212, \"total_train_time_s\": 8.359419584274292}", "{\"n\": 643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3062.25, \"learn_time_ms\": 8822.762, \"total_train_time_s\": 10.511454343795776}", "{\"n\": 644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3070.79, \"learn_time_ms\": 8805.754, \"total_train_time_s\": 9.822357177734375}", "{\"n\": 645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3070.79, \"learn_time_ms\": 8789.972, \"total_train_time_s\": 10.001514673233032}", "{\"n\": 646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3073.11, \"learn_time_ms\": 8624.827, \"total_train_time_s\": 9.640699625015259}", "{\"n\": 647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3076.82, \"learn_time_ms\": 8348.882, \"total_train_time_s\": 8.299639225006104}", "{\"n\": 648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.78, \"learn_time_ms\": 8396.556, \"total_train_time_s\": 10.837525367736816}", "{\"n\": 649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3078.49, \"learn_time_ms\": 8273.185, \"total_train_time_s\": 9.016846418380737}", "{\"n\": 650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3072.83, \"learn_time_ms\": 8316.388, \"total_train_time_s\": 10.320765733718872}", "{\"n\": 651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3079.61, \"learn_time_ms\": 8292.033, \"total_train_time_s\": 10.398633241653442}", "{\"n\": 652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.41, \"learn_time_ms\": 8477.557, \"total_train_time_s\": 10.21113133430481}", "{\"n\": 653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.89, \"learn_time_ms\": 8532.665, \"total_train_time_s\": 11.046019554138184}", "{\"n\": 654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3086.54, \"learn_time_ms\": 8510.343, \"total_train_time_s\": 9.614189863204956}", "{\"n\": 655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3088.41, \"learn_time_ms\": 8543.644, \"total_train_time_s\": 10.319485425949097}", "{\"n\": 656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3085.11, \"learn_time_ms\": 8562.548, \"total_train_time_s\": 9.72252082824707}", "{\"n\": 657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3086.43, \"learn_time_ms\": 8807.365, \"total_train_time_s\": 10.77727222442627}", "{\"n\": 658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3089.2, \"learn_time_ms\": 9002.567, \"total_train_time_s\": 12.775301218032837}", "{\"n\": 659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3093.3, \"learn_time_ms\": 9127.048, \"total_train_time_s\": 10.179250240325928}", "{\"n\": 660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3093.03, \"learn_time_ms\": 9156.441, \"total_train_time_s\": 10.660303354263306}", "{\"n\": 661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3093.03, \"learn_time_ms\": 9099.744, \"total_train_time_s\": 9.851319551467896}", "{\"n\": 662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3097.49, \"learn_time_ms\": 9084.167, \"total_train_time_s\": 10.035254716873169}", "{\"n\": 663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3095.72, \"learn_time_ms\": 8981.922, \"total_train_time_s\": 10.003304958343506}", "{\"n\": 664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3095.72, \"learn_time_ms\": 9090.3, \"total_train_time_s\": 10.721898794174194}", "{\"n\": 665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3100.52, \"learn_time_ms\": 9058.729, \"total_train_time_s\": 10.059165239334106}", "{\"n\": 666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.11, \"learn_time_ms\": 9016.698, \"total_train_time_s\": 9.357230186462402}", "{\"n\": 667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.11, \"learn_time_ms\": 8934.749, \"total_train_time_s\": 9.937615156173706}", "{\"n\": 668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.09, \"learn_time_ms\": 8633.207, \"total_train_time_s\": 9.826038837432861}", "{\"n\": 669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.67, \"learn_time_ms\": 8708.977, \"total_train_time_s\": 11.026423692703247}", "{\"n\": 670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.67, \"learn_time_ms\": 8745.375, \"total_train_time_s\": 11.038553953170776}", "{\"n\": 671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3103.41, \"learn_time_ms\": 8777.113, \"total_train_time_s\": 10.138277769088745}", "{\"n\": 672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3107.61, \"learn_time_ms\": 8809.508, \"total_train_time_s\": 10.435241937637329}", "{\"n\": 673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3107.61, \"learn_time_ms\": 8905.819, \"total_train_time_s\": 11.015322923660278}", "{\"n\": 674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3113.38, \"learn_time_ms\": 8772.653, \"total_train_time_s\": 9.317255973815918}", "{\"n\": 675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3111.78, \"learn_time_ms\": 8750.183, \"total_train_time_s\": 9.759716272354126}", "{\"n\": 676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3112.31, \"learn_time_ms\": 8819.856, \"total_train_time_s\": 10.000613451004028}", "{\"n\": 677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3112.76, \"learn_time_ms\": 8954.108, \"total_train_time_s\": 11.227214813232422}", "{\"n\": 678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.83, \"learn_time_ms\": 8926.204, \"total_train_time_s\": 9.511547803878784}", "{\"n\": 679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.52, \"learn_time_ms\": 8798.963, \"total_train_time_s\": 9.70949649810791}", "{\"n\": 680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3112.26, \"learn_time_ms\": 8785.89, \"total_train_time_s\": 10.84684681892395}", "{\"n\": 681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3115.18, \"learn_time_ms\": 8792.199, \"total_train_time_s\": 10.210374116897583}", "{\"n\": 682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3119.27, \"learn_time_ms\": 8794.804, \"total_train_time_s\": 10.43231987953186}", "{\"n\": 683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3116.69, \"learn_time_ms\": 8758.317, \"total_train_time_s\": 10.621462106704712}", "{\"n\": 684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.46, \"learn_time_ms\": 8994.41, \"total_train_time_s\": 11.762066125869751}", "{\"n\": 685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.46, \"learn_time_ms\": 9131.299, \"total_train_time_s\": 11.130284547805786}", "{\"n\": 686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3109.15, \"learn_time_ms\": 9237.54, \"total_train_time_s\": 11.08816409111023}", "{\"n\": 687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3104.63, \"learn_time_ms\": 9091.109, \"total_train_time_s\": 9.843160629272461}", "{\"n\": 688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3113.05, \"learn_time_ms\": 9101.76, \"total_train_time_s\": 9.61734676361084}", "{\"n\": 689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3123.54, \"learn_time_ms\": 9245.588, \"total_train_time_s\": 11.143361568450928}", "{\"n\": 690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.38, \"learn_time_ms\": 9147.215, \"total_train_time_s\": 9.874648332595825}", "{\"n\": 691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.33, \"learn_time_ms\": 9264.129, \"total_train_time_s\": 11.403626203536987}", "{\"n\": 692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3120.34, \"learn_time_ms\": 9230.306, \"total_train_time_s\": 10.05420184135437}", "{\"n\": 693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3122.86, \"learn_time_ms\": 9220.665, \"total_train_time_s\": 10.561887979507446}", "{\"n\": 694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3122.86, \"learn_time_ms\": 8988.71, \"total_train_time_s\": 9.427350997924805}", "{\"n\": 695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3114.97, \"learn_time_ms\": 8877.754, \"total_train_time_s\": 10.066877841949463}", "{\"n\": 696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3112.68, \"learn_time_ms\": 8792.247, \"total_train_time_s\": 10.226995468139648}", "{\"n\": 697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3115.35, \"learn_time_ms\": 8850.329, \"total_train_time_s\": 10.371376276016235}", "{\"n\": 698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.53, \"learn_time_ms\": 8994.95, \"total_train_time_s\": 11.055191040039062}", "{\"n\": 699, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3116.29, \"learn_time_ms\": 8918.624, \"total_train_time_s\": 10.401088953018188}", "{\"n\": 700, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3121.4, \"learn_time_ms\": 9132.589, \"total_train_time_s\": 12.036342144012451}", "{\"n\": 701, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.41, \"learn_time_ms\": 8948.145, \"total_train_time_s\": 9.534111976623535}", "{\"n\": 702, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3127.67, \"learn_time_ms\": 8964.159, \"total_train_time_s\": 10.249111652374268}", "{\"n\": 703, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3129.67, \"learn_time_ms\": 8961.382, \"total_train_time_s\": 10.514882564544678}", "{\"n\": 704, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3132.77, \"learn_time_ms\": 9171.288, \"total_train_time_s\": 11.485389471054077}", "{\"n\": 705, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3136.01, \"learn_time_ms\": 9188.428, \"total_train_time_s\": 10.236988544464111}", "{\"n\": 706, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3129.39, \"learn_time_ms\": 9148.158, \"total_train_time_s\": 9.856690168380737}", "{\"n\": 707, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3124.47, \"learn_time_ms\": 9161.76, \"total_train_time_s\": 10.521102666854858}", "{\"n\": 708, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3118.09, \"learn_time_ms\": 9013.465, \"total_train_time_s\": 9.610832691192627}", "{\"n\": 709, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3119.93, \"learn_time_ms\": 8991.511, \"total_train_time_s\": 10.14588713645935}", "{\"n\": 710, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3117.68, \"learn_time_ms\": 8692.257, \"total_train_time_s\": 9.08095383644104}", "{\"n\": 711, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3122.36, \"learn_time_ms\": 8790.257, \"total_train_time_s\": 10.496291160583496}", "{\"n\": 712, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3125.12, \"learn_time_ms\": 8689.965, \"total_train_time_s\": 9.241013765335083}", "{\"n\": 713, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3125.4, \"learn_time_ms\": 8670.116, \"total_train_time_s\": 10.28471851348877}", "{\"n\": 714, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3125.4, \"learn_time_ms\": 8484.758, \"total_train_time_s\": 9.60831332206726}", "{\"n\": 715, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3140.49, \"learn_time_ms\": 8505.966, \"total_train_time_s\": 10.502050876617432}", "{\"n\": 716, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3140.49, \"learn_time_ms\": 8398.429, \"total_train_time_s\": 8.778812408447266}", "{\"n\": 717, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3138.61, \"learn_time_ms\": 8323.1, \"total_train_time_s\": 9.817800760269165}", "{\"n\": 718, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3143.94, \"learn_time_ms\": 8474.289, \"total_train_time_s\": 11.121764421463013}", "{\"n\": 719, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3143.94, \"learn_time_ms\": 8434.889, \"total_train_time_s\": 9.741854906082153}", "{\"n\": 720, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3152.1, \"learn_time_ms\": 8513.5, \"total_train_time_s\": 9.822422742843628}", "{\"n\": 721, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.74, \"learn_time_ms\": 8636.484, \"total_train_time_s\": 11.779279470443726}", "{\"n\": 722, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.74, \"learn_time_ms\": 8760.756, \"total_train_time_s\": 10.452256679534912}", "{\"n\": 723, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.42, \"learn_time_ms\": 8843.618, \"total_train_time_s\": 11.101918697357178}", "{\"n\": 724, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3142.55, \"learn_time_ms\": 8799.097, \"total_train_time_s\": 9.185305833816528}", "{\"n\": 725, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.62, \"learn_time_ms\": 8724.381, \"total_train_time_s\": 9.668261289596558}", "{\"n\": 726, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.13, \"learn_time_ms\": 8935.879, \"total_train_time_s\": 10.88304853439331}", "{\"n\": 727, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.48, \"learn_time_ms\": 8926.437, \"total_train_time_s\": 9.71406078338623}", "{\"n\": 728, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.48, \"learn_time_ms\": 8954.55, \"total_train_time_s\": 11.37346625328064}", "{\"n\": 729, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3139.22, \"learn_time_ms\": 9006.826, \"total_train_time_s\": 10.262733697891235}", "{\"n\": 730, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3137.91, \"learn_time_ms\": 9113.407, \"total_train_time_s\": 10.925897598266602}", "{\"n\": 731, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3137.91, \"learn_time_ms\": 8961.698, \"total_train_time_s\": 10.18921446800232}", "{\"n\": 732, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.27, \"learn_time_ms\": 8999.325, \"total_train_time_s\": 10.895281314849854}", "{\"n\": 733, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.51, \"learn_time_ms\": 9086.075, \"total_train_time_s\": 12.014598608016968}", "{\"n\": 734, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.33, \"learn_time_ms\": 9351.367, \"total_train_time_s\": 11.862529754638672}", "{\"n\": 735, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.33, \"learn_time_ms\": 9272.829, \"total_train_time_s\": 8.893703937530518}", "{\"n\": 736, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3129.92, \"learn_time_ms\": 9313.69, \"total_train_time_s\": 11.285589456558228}", "{\"n\": 737, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3129.92, \"learn_time_ms\": 9447.963, \"total_train_time_s\": 11.058862447738647}", "{\"n\": 738, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3129.92, \"learn_time_ms\": 9384.259, \"total_train_time_s\": 10.748309850692749}", "{\"n\": 739, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.21, \"learn_time_ms\": 9248.236, \"total_train_time_s\": 8.983426094055176}", "{\"n\": 740, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.16, \"learn_time_ms\": 9274.186, \"total_train_time_s\": 11.186528444290161}", "{\"n\": 741, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.16, \"learn_time_ms\": 9195.522, \"total_train_time_s\": 9.411989688873291}", "{\"n\": 742, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.7, \"learn_time_ms\": 9102.515, \"total_train_time_s\": 9.932257413864136}", "{\"n\": 743, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.22, \"learn_time_ms\": 8996.533, \"total_train_time_s\": 10.898513078689575}", "{\"n\": 744, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.22, \"learn_time_ms\": 8893.065, \"total_train_time_s\": 10.795848846435547}", "{\"n\": 745, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.55, \"learn_time_ms\": 9111.873, \"total_train_time_s\": 11.095150470733643}", "{\"n\": 746, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.4, \"learn_time_ms\": 8899.786, \"total_train_time_s\": 9.14163613319397}", "{\"n\": 747, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.4, \"learn_time_ms\": 8813.452, \"total_train_time_s\": 10.1503746509552}", "{\"n\": 748, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.97, \"learn_time_ms\": 8826.212, \"total_train_time_s\": 10.873703002929688}", "{\"n\": 749, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.76, \"learn_time_ms\": 8994.569, \"total_train_time_s\": 10.629480361938477}", "{\"n\": 750, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.76, \"learn_time_ms\": 8945.906, \"total_train_time_s\": 10.645295143127441}", "{\"n\": 751, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.74, \"learn_time_ms\": 9005.138, \"total_train_time_s\": 10.002996444702148}", "{\"n\": 752, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.1, \"learn_time_ms\": 8988.012, \"total_train_time_s\": 9.750497817993164}", "{\"n\": 753, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.51, \"learn_time_ms\": 8931.158, \"total_train_time_s\": 10.366730451583862}", "{\"n\": 754, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.61, \"learn_time_ms\": 8985.77, \"total_train_time_s\": 11.35178518295288}", "{\"n\": 755, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.66, \"learn_time_ms\": 9043.769, \"total_train_time_s\": 11.700324296951294}", "{\"n\": 756, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.81, \"learn_time_ms\": 9137.798, \"total_train_time_s\": 10.088620901107788}", "{\"n\": 757, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.32, \"learn_time_ms\": 9127.86, \"total_train_time_s\": 10.04991865158081}", "{\"n\": 758, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.87, \"learn_time_ms\": 8924.185, \"total_train_time_s\": 8.878482341766357}", "{\"n\": 759, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.04, \"learn_time_ms\": 8736.685, \"total_train_time_s\": 8.72776484489441}", "{\"n\": 760, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.04, \"learn_time_ms\": 8770.401, \"total_train_time_s\": 11.008213758468628}", "{\"n\": 761, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3127.29, \"learn_time_ms\": 8779.316, \"total_train_time_s\": 10.107983589172363}", "{\"n\": 762, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.49, \"learn_time_ms\": 8688.726, \"total_train_time_s\": 8.833167791366577}", "{\"n\": 763, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3127.01, \"learn_time_ms\": 8765.708, \"total_train_time_s\": 11.179563522338867}", "{\"n\": 764, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.08, \"learn_time_ms\": 8764.205, \"total_train_time_s\": 11.368533849716187}", "{\"n\": 765, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3127.81, \"learn_time_ms\": 8551.352, \"total_train_time_s\": 9.530655860900879}", "{\"n\": 766, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.92, \"learn_time_ms\": 8718.825, \"total_train_time_s\": 11.788989782333374}", "{\"n\": 767, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.71, \"learn_time_ms\": 8751.858, \"total_train_time_s\": 10.377875328063965}", "{\"n\": 768, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.08, \"learn_time_ms\": 8884.665, \"total_train_time_s\": 10.203130722045898}", "{\"n\": 769, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.9, \"learn_time_ms\": 9158.862, \"total_train_time_s\": 11.531074047088623}", "{\"n\": 770, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.9, \"learn_time_ms\": 9091.556, \"total_train_time_s\": 10.322254657745361}", "{\"n\": 771, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.21, \"learn_time_ms\": 9015.603, \"total_train_time_s\": 9.347064733505249}", "{\"n\": 772, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.85, \"learn_time_ms\": 9245.612, \"total_train_time_s\": 11.157654285430908}", "{\"n\": 773, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.4, \"learn_time_ms\": 9380.531, \"total_train_time_s\": 12.4918692111969}", "{\"n\": 774, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.35, \"learn_time_ms\": 9285.793, \"total_train_time_s\": 10.393818616867065}", "{\"n\": 775, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.1, \"learn_time_ms\": 9504.48, \"total_train_time_s\": 11.766226053237915}", "{\"n\": 776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.38, \"learn_time_ms\": 9388.038, \"total_train_time_s\": 10.602727890014648}", "{\"n\": 777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.44, \"learn_time_ms\": 9505.187, \"total_train_time_s\": 11.571452140808105}", "{\"n\": 778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.56, \"learn_time_ms\": 9588.98, \"total_train_time_s\": 10.995754957199097}", "{\"n\": 779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.62, \"learn_time_ms\": 9505.57, \"total_train_time_s\": 10.57723617553711}", "{\"n\": 780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.19, \"learn_time_ms\": 9433.094, \"total_train_time_s\": 9.58418607711792}", "{\"n\": 781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.52, \"learn_time_ms\": 9477.38, \"total_train_time_s\": 9.7872896194458}", "{\"n\": 782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.52, \"learn_time_ms\": 9380.279, \"total_train_time_s\": 10.219955921173096}", "{\"n\": 783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3122.17, \"learn_time_ms\": 9246.045, \"total_train_time_s\": 11.14254117012024}", "{\"n\": 784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.25, \"learn_time_ms\": 9128.791, \"total_train_time_s\": 9.271495819091797}", "{\"n\": 785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.82, \"learn_time_ms\": 9245.908, \"total_train_time_s\": 12.90104341506958}", "{\"n\": 786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.88, \"learn_time_ms\": 9244.271, \"total_train_time_s\": 10.594509601593018}", "{\"n\": 787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.09, \"learn_time_ms\": 9103.234, \"total_train_time_s\": 10.171738624572754}", "{\"n\": 788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.86, \"learn_time_ms\": 8919.77, \"total_train_time_s\": 9.142725944519043}", "{\"n\": 789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.86, \"learn_time_ms\": 8869.548, \"total_train_time_s\": 10.132865905761719}", "{\"n\": 790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.21, \"learn_time_ms\": 8943.94, \"total_train_time_s\": 10.317270278930664}", "{\"n\": 791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.21, \"learn_time_ms\": 9030.997, \"total_train_time_s\": 10.681004285812378}", "{\"n\": 792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3108.37, \"learn_time_ms\": 9068.724, \"total_train_time_s\": 10.55132269859314}", "{\"n\": 793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3110.58, \"learn_time_ms\": 8941.937, \"total_train_time_s\": 9.929819107055664}", "{\"n\": 794, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.68, \"learn_time_ms\": 9120.092, \"total_train_time_s\": 11.075061798095703}", "{\"n\": 795, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3110.87, \"learn_time_ms\": 8923.269, \"total_train_time_s\": 10.930067300796509}", "{\"n\": 796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3108.54, \"learn_time_ms\": 8835.982, \"total_train_time_s\": 9.678609371185303}", "{\"n\": 797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3106.48, \"learn_time_ms\": 8866.4, \"total_train_time_s\": 10.43168020248413}", "{\"n\": 798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3102.94, \"learn_time_ms\": 8961.809, \"total_train_time_s\": 10.130127429962158}", "{\"n\": 799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.01, \"learn_time_ms\": 9121.243, \"total_train_time_s\": 11.750755548477173}", "{\"n\": 800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3107.84, \"learn_time_ms\": 9218.066, \"total_train_time_s\": 11.310362577438354}", "{\"n\": 801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3111.52, \"learn_time_ms\": 9125.265, \"total_train_time_s\": 9.770265817642212}", "{\"n\": 802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3111.72, \"learn_time_ms\": 9144.291, \"total_train_time_s\": 10.71714448928833}", "{\"n\": 803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3110.11, \"learn_time_ms\": 8968.21, \"total_train_time_s\": 8.102354288101196}", "{\"n\": 804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3113.04, \"learn_time_ms\": 8940.288, \"total_train_time_s\": 10.757488250732422}", "{\"n\": 805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3113.43, \"learn_time_ms\": 8796.625, \"total_train_time_s\": 9.488755702972412}", "{\"n\": 806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3113.53, \"learn_time_ms\": 8924.802, \"total_train_time_s\": 11.043936491012573}", "{\"n\": 807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.78, \"learn_time_ms\": 8938.539, \"total_train_time_s\": 10.666836738586426}", "{\"n\": 808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.24, \"learn_time_ms\": 8942.813, \"total_train_time_s\": 10.161087036132812}", "{\"n\": 809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.97, \"learn_time_ms\": 8884.89, \"total_train_time_s\": 11.146920204162598}", "{\"n\": 810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.53, \"learn_time_ms\": 8828.664, \"total_train_time_s\": 10.71705150604248}", "{\"n\": 811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3107.26, \"learn_time_ms\": 8861.476, \"total_train_time_s\": 10.10774540901184}", "{\"n\": 812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3107.26, \"learn_time_ms\": 8934.709, \"total_train_time_s\": 11.463462829589844}", "{\"n\": 813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3102.56, \"learn_time_ms\": 9023.266, \"total_train_time_s\": 8.985177278518677}", "{\"n\": 814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.81, \"learn_time_ms\": 8960.851, \"total_train_time_s\": 10.109598159790039}", "{\"n\": 815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3099.27, \"learn_time_ms\": 9046.187, \"total_train_time_s\": 10.369418382644653}", "{\"n\": 816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3099.78, \"learn_time_ms\": 9130.247, \"total_train_time_s\": 11.893075942993164}", "{\"n\": 817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3094.62, \"learn_time_ms\": 9146.944, \"total_train_time_s\": 10.738597393035889}", "{\"n\": 818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3095.51, \"learn_time_ms\": 9048.874, \"total_train_time_s\": 9.146660804748535}", "{\"n\": 819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3096.7, \"learn_time_ms\": 8974.169, \"total_train_time_s\": 10.380294799804688}", "{\"n\": 820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3094.9, \"learn_time_ms\": 8919.223, \"total_train_time_s\": 10.186427116394043}", "{\"n\": 821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3097.16, \"learn_time_ms\": 9006.937, \"total_train_time_s\": 10.978371143341064}", "{\"n\": 822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3097.16, \"learn_time_ms\": 8756.433, \"total_train_time_s\": 8.978563070297241}", "{\"n\": 823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3097.74, \"learn_time_ms\": 8857.28, \"total_train_time_s\": 10.047938823699951}", "{\"n\": 824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3102.54, \"learn_time_ms\": 8838.092, \"total_train_time_s\": 9.965456485748291}", "{\"n\": 825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3102.54, \"learn_time_ms\": 8726.118, \"total_train_time_s\": 9.201200246810913}", "{\"n\": 826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3103.24, \"learn_time_ms\": 8642.437, \"total_train_time_s\": 11.048917531967163}", "{\"n\": 827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.82, \"learn_time_ms\": 8662.592, \"total_train_time_s\": 11.013948440551758}", "{\"n\": 828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3101.96, \"learn_time_ms\": 8775.933, \"total_train_time_s\": 10.337911367416382}", "{\"n\": 829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.26, \"learn_time_ms\": 8754.195, \"total_train_time_s\": 10.192016839981079}", "{\"n\": 830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.02, \"learn_time_ms\": 8718.723, \"total_train_time_s\": 9.817549467086792}", "{\"n\": 831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3098.27, \"learn_time_ms\": 8623.324, \"total_train_time_s\": 10.005962133407593}", "{\"n\": 832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3098.11, \"learn_time_ms\": 8876.662, \"total_train_time_s\": 11.498031377792358}", "{\"n\": 833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3088.52, \"learn_time_ms\": 8937.206, \"total_train_time_s\": 10.606832027435303}", "{\"n\": 834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3095.36, \"learn_time_ms\": 8892.297, \"total_train_time_s\": 9.465174198150635}", "{\"n\": 835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3095.36, \"learn_time_ms\": 9032.223, \"total_train_time_s\": 10.584598779678345}", "{\"n\": 836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3098.06, \"learn_time_ms\": 8965.505, \"total_train_time_s\": 10.350963592529297}", "{\"n\": 837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.18, \"learn_time_ms\": 8938.645, \"total_train_time_s\": 10.716487884521484}", "{\"n\": 838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.18, \"learn_time_ms\": 8889.533, \"total_train_time_s\": 9.843768835067749}", "{\"n\": 839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.18, \"learn_time_ms\": 8835.714, \"total_train_time_s\": 9.679007291793823}", "{\"n\": 840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.24, \"learn_time_ms\": 8896.448, \"total_train_time_s\": 10.450834274291992}", "{\"n\": 841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.24, \"learn_time_ms\": 8903.738, \"total_train_time_s\": 10.076110601425171}", "{\"n\": 842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.24, \"learn_time_ms\": 8767.71, \"total_train_time_s\": 10.115152359008789}", "{\"n\": 843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.34, \"learn_time_ms\": 8840.713, \"total_train_time_s\": 11.350303888320923}", "{\"n\": 844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.34, \"learn_time_ms\": 8970.987, \"total_train_time_s\": 10.721256732940674}", "{\"n\": 845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.34, \"learn_time_ms\": 8952.144, \"total_train_time_s\": 10.4677734375}", "{\"n\": 846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3080.56, \"learn_time_ms\": 9009.144, \"total_train_time_s\": 10.952388048171997}", "{\"n\": 847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3080.56, \"learn_time_ms\": 9111.599, \"total_train_time_s\": 11.721739768981934}", "{\"n\": 848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3080.56, \"learn_time_ms\": 9271.173, \"total_train_time_s\": 11.442219972610474}", "{\"n\": 849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3077.81, \"learn_time_ms\": 9255.906, \"total_train_time_s\": 9.49524974822998}", "{\"n\": 850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.18, \"learn_time_ms\": 9354.974, \"total_train_time_s\": 11.432848930358887}", "{\"n\": 851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.18, \"learn_time_ms\": 9286.306, \"total_train_time_s\": 9.379024267196655}", "{\"n\": 852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3072.67, \"learn_time_ms\": 9261.141, \"total_train_time_s\": 9.869113206863403}", "{\"n\": 853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3070.97, \"learn_time_ms\": 9110.387, \"total_train_time_s\": 9.78846788406372}", "{\"n\": 854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3070.97, \"learn_time_ms\": 9063.888, \"total_train_time_s\": 10.308254957199097}", "{\"n\": 855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3076.77, \"learn_time_ms\": 8971.264, \"total_train_time_s\": 9.504559993743896}", "{\"n\": 856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3075.95, \"learn_time_ms\": 8797.485, \"total_train_time_s\": 9.141781568527222}", "{\"n\": 857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3075.95, \"learn_time_ms\": 8585.92, \"total_train_time_s\": 9.614169597625732}", "{\"n\": 858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.03, \"learn_time_ms\": 8404.085, \"total_train_time_s\": 9.613296270370483}", "{\"n\": 859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3078.45, \"learn_time_ms\": 8570.083, \"total_train_time_s\": 11.132639169692993}", "{\"n\": 860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3078.45, \"learn_time_ms\": 8450.752, \"total_train_time_s\": 10.303449630737305}", "{\"n\": 861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3079.7, \"learn_time_ms\": 8502.887, \"total_train_time_s\": 9.897914409637451}", "{\"n\": 862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3078.05, \"learn_time_ms\": 8592.524, \"total_train_time_s\": 10.770046710968018}", "{\"n\": 863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3078.05, \"learn_time_ms\": 8688.941, \"total_train_time_s\": 10.791648387908936}", "{\"n\": 864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.83, \"learn_time_ms\": 8821.688, \"total_train_time_s\": 11.633866548538208}", "{\"n\": 865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3076.84, \"learn_time_ms\": 8763.69, \"total_train_time_s\": 8.929033517837524}", "{\"n\": 866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3076.84, \"learn_time_ms\": 8767.316, \"total_train_time_s\": 9.175314664840698}", "{\"n\": 867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3082.13, \"learn_time_ms\": 8682.771, \"total_train_time_s\": 8.778648138046265}", "{\"n\": 868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3086.78, \"learn_time_ms\": 8626.28, \"total_train_time_s\": 9.079370021820068}", "{\"n\": 869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3086.78, \"learn_time_ms\": 8606.59, \"total_train_time_s\": 10.972570657730103}", "{\"n\": 870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3081.02, \"learn_time_ms\": 8563.533, \"total_train_time_s\": 9.843975305557251}", "{\"n\": 871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3081.36, \"learn_time_ms\": 8640.928, \"total_train_time_s\": 10.722702026367188}", "{\"n\": 872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3081.36, \"learn_time_ms\": 8620.0, \"total_train_time_s\": 10.60970139503479}", "{\"n\": 873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3085.23, \"learn_time_ms\": 8618.905, \"total_train_time_s\": 10.77796459197998}", "{\"n\": 874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3085.46, \"learn_time_ms\": 8480.527, \"total_train_time_s\": 10.303954839706421}", "{\"n\": 875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3085.46, \"learn_time_ms\": 8625.315, \"total_train_time_s\": 10.329393148422241}", "{\"n\": 876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3076.14, \"learn_time_ms\": 8880.581, \"total_train_time_s\": 11.730036973953247}", "{\"n\": 877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.21, \"learn_time_ms\": 9048.755, \"total_train_time_s\": 10.43599009513855}", "{\"n\": 878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.0, \"learn_time_ms\": 9135.093, \"total_train_time_s\": 9.883375883102417}", "{\"n\": 879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3069.76, \"learn_time_ms\": 8990.063, \"total_train_time_s\": 9.497482061386108}", "{\"n\": 880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3066.23, \"learn_time_ms\": 9087.223, \"total_train_time_s\": 10.769944906234741}", "{\"n\": 881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.04, \"learn_time_ms\": 9038.79, \"total_train_time_s\": 10.177244186401367}", "{\"n\": 882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3064.31, \"learn_time_ms\": 9087.42, \"total_train_time_s\": 11.072372913360596}", "{\"n\": 883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3060.79, \"learn_time_ms\": 8961.557, \"total_train_time_s\": 9.57079291343689}", "{\"n\": 884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3066.94, \"learn_time_ms\": 8937.302, \"total_train_time_s\": 10.016940355300903}", "{\"n\": 885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.17, \"learn_time_ms\": 8897.583, \"total_train_time_s\": 9.986298322677612}", "{\"n\": 886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3066.89, \"learn_time_ms\": 8767.273, \"total_train_time_s\": 10.47624945640564}", "{\"n\": 887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.18, \"learn_time_ms\": 8529.963, \"total_train_time_s\": 8.025010108947754}", "{\"n\": 888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3065.18, \"learn_time_ms\": 8355.074, \"total_train_time_s\": 8.141180992126465}", "{\"n\": 889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.22, \"learn_time_ms\": 8523.142, \"total_train_time_s\": 11.186529874801636}", "{\"n\": 890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.71, \"learn_time_ms\": 8495.697, \"total_train_time_s\": 10.522992849349976}", "{\"n\": 891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3076.68, \"learn_time_ms\": 8396.003, \"total_train_time_s\": 9.201074361801147}", "{\"n\": 892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3076.68, \"learn_time_ms\": 8379.531, \"total_train_time_s\": 10.86077332496643}", "{\"n\": 893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.14, \"learn_time_ms\": 8503.529, \"total_train_time_s\": 10.762643098831177}", "{\"n\": 894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3071.6, \"learn_time_ms\": 8508.087, \"total_train_time_s\": 10.069449186325073}", "{\"n\": 895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3071.6, \"learn_time_ms\": 8507.678, \"total_train_time_s\": 9.958548307418823}", "{\"n\": 896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.75, \"learn_time_ms\": 8533.244, \"total_train_time_s\": 10.739668369293213}", "{\"n\": 897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.45, \"learn_time_ms\": 8910.196, \"total_train_time_s\": 11.879892826080322}", "{\"n\": 898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3071.83, \"learn_time_ms\": 9258.697, \"total_train_time_s\": 11.659923791885376}", "{\"n\": 899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.6, \"learn_time_ms\": 9231.333, \"total_train_time_s\": 10.94872760772705}", "{\"n\": 900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3068.71, \"learn_time_ms\": 9387.743, \"total_train_time_s\": 12.07388162612915}", "{\"n\": 901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.78, \"learn_time_ms\": 9500.659, \"total_train_time_s\": 10.306376695632935}", "{\"n\": 902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3058.61, \"learn_time_ms\": 9384.694, \"total_train_time_s\": 9.739097595214844}", "{\"n\": 903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3056.65, \"learn_time_ms\": 9189.475, \"total_train_time_s\": 8.831236124038696}", "{\"n\": 904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3059.54, \"learn_time_ms\": 9222.964, \"total_train_time_s\": 10.358422756195068}", "{\"n\": 905, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.31, \"learn_time_ms\": 9271.204, \"total_train_time_s\": 10.443207502365112}", "{\"n\": 906, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3067.31, \"learn_time_ms\": 9180.718, \"total_train_time_s\": 9.74852180480957}", "{\"n\": 907, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3063.17, \"learn_time_ms\": 9047.688, \"total_train_time_s\": 10.527111768722534}", "{\"n\": 908, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3069.53, \"learn_time_ms\": 8782.686, \"total_train_time_s\": 8.98033881187439}", "{\"n\": 909, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3069.53, \"learn_time_ms\": 8707.715, \"total_train_time_s\": 10.192829608917236}", "{\"n\": 910, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3069.15, \"learn_time_ms\": 8457.864, \"total_train_time_s\": 9.582430362701416}", "{\"n\": 911, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3072.86, \"learn_time_ms\": 8418.051, \"total_train_time_s\": 9.949697732925415}", "{\"n\": 912, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3072.86, \"learn_time_ms\": 8371.653, \"total_train_time_s\": 9.320816278457642}", "{\"n\": 913, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3075.64, \"learn_time_ms\": 8493.119, \"total_train_time_s\": 10.027355432510376}", "{\"n\": 914, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.96, \"learn_time_ms\": 8317.834, \"total_train_time_s\": 8.64929461479187}", "{\"n\": 915, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.36, \"learn_time_ms\": 8391.997, \"total_train_time_s\": 11.226984977722168}", "{\"n\": 916, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3089.93, \"learn_time_ms\": 8462.665, \"total_train_time_s\": 10.537771940231323}", "{\"n\": 917, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.06, \"learn_time_ms\": 8463.815, \"total_train_time_s\": 10.571293592453003}", "{\"n\": 918, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.53, \"learn_time_ms\": 8559.135, \"total_train_time_s\": 9.935751914978027}", "{\"n\": 919, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.53, \"learn_time_ms\": 8592.999, \"total_train_time_s\": 10.557543992996216}", "{\"n\": 920, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3097.65, \"learn_time_ms\": 8765.233, \"total_train_time_s\": 11.30057430267334}", "{\"n\": 921, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3097.97, \"learn_time_ms\": 8927.799, \"total_train_time_s\": 11.53479266166687}", "{\"n\": 922, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3097.97, \"learn_time_ms\": 9028.554, \"total_train_time_s\": 10.245292663574219}", "{\"n\": 923, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3095.27, \"learn_time_ms\": 8990.133, \"total_train_time_s\": 9.679049015045166}", "{\"n\": 924, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.97, \"learn_time_ms\": 9126.138, \"total_train_time_s\": 10.01577639579773}", "{\"n\": 925, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.97, \"learn_time_ms\": 9015.39, \"total_train_time_s\": 10.038722038269043}", "{\"n\": 926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.23, \"learn_time_ms\": 9051.989, \"total_train_time_s\": 10.902944326400757}", "{\"n\": 927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.45, \"learn_time_ms\": 9050.98, \"total_train_time_s\": 10.536810398101807}", "{\"n\": 928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.45, \"learn_time_ms\": 9058.198, \"total_train_time_s\": 9.956137895584106}", "{\"n\": 929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3098.86, \"learn_time_ms\": 9071.336, \"total_train_time_s\": 10.651811122894287}", "{\"n\": 930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.53, \"learn_time_ms\": 9017.687, \"total_train_time_s\": 10.762653589248657}", "{\"n\": 931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.53, \"learn_time_ms\": 8896.965, \"total_train_time_s\": 10.345902919769287}", "{\"n\": 932, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3093.26, \"learn_time_ms\": 8828.79, \"total_train_time_s\": 9.612918615341187}", "{\"n\": 933, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.23, \"learn_time_ms\": 8879.847, \"total_train_time_s\": 10.169857025146484}", "{\"n\": 934, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.68, \"learn_time_ms\": 8862.127, \"total_train_time_s\": 9.838713884353638}", "{\"n\": 935, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3080.9, \"learn_time_ms\": 8809.701, \"total_train_time_s\": 9.546918392181396}", "{\"n\": 936, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3080.56, \"learn_time_ms\": 8747.328, \"total_train_time_s\": 10.221128463745117}", "{\"n\": 937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.37, \"learn_time_ms\": 8556.99, \"total_train_time_s\": 8.597288131713867}", "{\"n\": 938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.13, \"learn_time_ms\": 8503.77, \"total_train_time_s\": 9.468651294708252}", "{\"n\": 939, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.13, \"learn_time_ms\": 8406.845, \"total_train_time_s\": 9.658143758773804}", "{\"n\": 940, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.96, \"learn_time_ms\": 8410.038, \"total_train_time_s\": 10.795864343643188}", "{\"n\": 941, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.99, \"learn_time_ms\": 8289.523, \"total_train_time_s\": 9.139465570449829}", "{\"n\": 942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.21, \"learn_time_ms\": 8296.006, \"total_train_time_s\": 9.733300685882568}", "{\"n\": 943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.63, \"learn_time_ms\": 8186.251, \"total_train_time_s\": 9.056978702545166}", "{\"n\": 944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3072.34, \"learn_time_ms\": 8209.493, \"total_train_time_s\": 10.109837055206299}", "{\"n\": 945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.19, \"learn_time_ms\": 8099.823, \"total_train_time_s\": 8.565208911895752}", "{\"n\": 946, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.19, \"learn_time_ms\": 8077.388, \"total_train_time_s\": 10.043675184249878}", "{\"n\": 947, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3071.85, \"learn_time_ms\": 8243.747, \"total_train_time_s\": 10.282833576202393}", "{\"n\": 948, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3071.85, \"learn_time_ms\": 8460.171, \"total_train_time_s\": 11.620218992233276}", "{\"n\": 949, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3071.85, \"learn_time_ms\": 8579.437, \"total_train_time_s\": 10.8562331199646}", "{\"n\": 950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.59, \"learn_time_ms\": 8510.565, \"total_train_time_s\": 10.13594365119934}", "{\"n\": 951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3070.21, \"learn_time_ms\": 8491.396, \"total_train_time_s\": 8.97609829902649}", "{\"n\": 952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3070.21, \"learn_time_ms\": 8580.286, \"total_train_time_s\": 10.556193590164185}", "{\"n\": 953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3076.71, \"learn_time_ms\": 8816.311, \"total_train_time_s\": 11.402745008468628}", "{\"n\": 954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.92, \"learn_time_ms\": 8833.823, \"total_train_time_s\": 10.254018306732178}", "{\"n\": 955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.92, \"learn_time_ms\": 9103.11, \"total_train_time_s\": 11.125122547149658}", "{\"n\": 956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.9, \"learn_time_ms\": 9149.885, \"total_train_time_s\": 10.518149614334106}", "{\"n\": 957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.04, \"learn_time_ms\": 9236.107, \"total_train_time_s\": 11.135358810424805}", "{\"n\": 958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.04, \"learn_time_ms\": 8940.685, \"total_train_time_s\": 8.693394899368286}", "{\"n\": 959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3088.54, \"learn_time_ms\": 8768.099, \"total_train_time_s\": 9.10312032699585}", "{\"n\": 960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3086.03, \"learn_time_ms\": 8816.893, \"total_train_time_s\": 10.608772277832031}", "{\"n\": 961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3086.03, \"learn_time_ms\": 9105.711, \"total_train_time_s\": 11.829871892929077}", "{\"n\": 962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.14, \"learn_time_ms\": 9124.832, \"total_train_time_s\": 10.704323530197144}", "{\"n\": 963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3091.72, \"learn_time_ms\": 9127.826, \"total_train_time_s\": 11.48829960823059}", "{\"n\": 964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3091.72, \"learn_time_ms\": 9149.561, \"total_train_time_s\": 10.421542882919312}", "{\"n\": 965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3088.22, \"learn_time_ms\": 9035.872, \"total_train_time_s\": 10.016671895980835}", "{\"n\": 966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3088.22, \"learn_time_ms\": 9049.36, \"total_train_time_s\": 10.639727115631104}", "{\"n\": 967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3088.22, \"learn_time_ms\": 8956.813, \"total_train_time_s\": 10.164209604263306}", "{\"n\": 968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3080.09, \"learn_time_ms\": 9097.019, \"total_train_time_s\": 10.093059778213501}", "{\"n\": 969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3076.93, \"learn_time_ms\": 9212.225, \"total_train_time_s\": 10.268452167510986}", "{\"n\": 970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3076.93, \"learn_time_ms\": 8953.277, \"total_train_time_s\": 7.9955666065216064}", "{\"n\": 971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.3, \"learn_time_ms\": 8680.724, \"total_train_time_s\": 9.112861633300781}", "{\"n\": 972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.3, \"learn_time_ms\": 8645.777, \"total_train_time_s\": 10.355632543563843}", "{\"n\": 973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3069.87, \"learn_time_ms\": 8542.268, \"total_train_time_s\": 10.412148237228394}", "{\"n\": 974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.74, \"learn_time_ms\": 8519.051, \"total_train_time_s\": 10.23506212234497}", "{\"n\": 975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.74, \"learn_time_ms\": 8584.599, \"total_train_time_s\": 10.645816564559937}", "{\"n\": 976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3047.87, \"learn_time_ms\": 8537.153, \"total_train_time_s\": 10.150930643081665}", "{\"n\": 977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.97, \"learn_time_ms\": 8569.004, \"total_train_time_s\": 10.539666175842285}", "{\"n\": 978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3047.82, \"learn_time_ms\": 8578.367, \"total_train_time_s\": 10.163376092910767}", "{\"n\": 979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3040.29, \"learn_time_ms\": 8597.3, \"total_train_time_s\": 10.450395584106445}", "{\"n\": 980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.17, \"learn_time_ms\": 8884.735, \"total_train_time_s\": 10.863083839416504}", "{\"n\": 981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.39, \"learn_time_ms\": 9099.459, \"total_train_time_s\": 11.242209911346436}", "{\"n\": 982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.03, \"learn_time_ms\": 9197.786, \"total_train_time_s\": 11.419757604598999}", "{\"n\": 983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3039.71, \"learn_time_ms\": 9231.825, \"total_train_time_s\": 10.77094578742981}", "{\"n\": 984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.82, \"learn_time_ms\": 9266.149, \"total_train_time_s\": 10.530981540679932}", "{\"n\": 985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3036.5, \"learn_time_ms\": 9208.846, \"total_train_time_s\": 10.071744203567505}", "{\"n\": 986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.55, \"learn_time_ms\": 9155.402, \"total_train_time_s\": 9.646658897399902}", "{\"n\": 987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.95, \"learn_time_ms\": 9167.452, \"total_train_time_s\": 10.673017263412476}", "{\"n\": 988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.02, \"learn_time_ms\": 9253.216, \"total_train_time_s\": 11.068451404571533}", "{\"n\": 989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.64, \"learn_time_ms\": 9356.492, \"total_train_time_s\": 11.517368793487549}", "{\"n\": 990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.48, \"learn_time_ms\": 9332.276, \"total_train_time_s\": 10.665922403335571}", "{\"n\": 991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3027.85, \"learn_time_ms\": 9183.39, \"total_train_time_s\": 9.738031387329102}", "{\"n\": 992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3021.51, \"learn_time_ms\": 9116.75, \"total_train_time_s\": 10.707173585891724}", "{\"n\": 993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3021.51, \"learn_time_ms\": 8982.797, \"total_train_time_s\": 9.354697942733765}", "{\"n\": 994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3021.51, \"learn_time_ms\": 9024.967, \"total_train_time_s\": 10.938920497894287}", "{\"n\": 995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3015.02, \"learn_time_ms\": 8961.088, \"total_train_time_s\": 9.499102115631104}", "{\"n\": 996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3012.74, \"learn_time_ms\": 8923.729, \"total_train_time_s\": 9.249094724655151}", "{\"n\": 997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3012.74, \"learn_time_ms\": 8921.442, \"total_train_time_s\": 10.632622480392456}", "{\"n\": 998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3015.85, \"learn_time_ms\": 8756.167, \"total_train_time_s\": 9.399174451828003}", "{\"n\": 999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.3, \"learn_time_ms\": 8630.694, \"total_train_time_s\": 10.262802124023438}", "{\"n\": 1000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.3, \"learn_time_ms\": 8589.068, \"total_train_time_s\": 10.176202535629272}", "{\"n\": 1001, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.86, \"learn_time_ms\": 8583.398, \"total_train_time_s\": 9.703379154205322}", "{\"n\": 1002, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.1, \"learn_time_ms\": 8485.324, \"total_train_time_s\": 9.681633472442627}", "{\"n\": 1003, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.1, \"learn_time_ms\": 8575.327, \"total_train_time_s\": 10.315990924835205}", "{\"n\": 1004, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3017.97, \"learn_time_ms\": 8531.297, \"total_train_time_s\": 10.59026288986206}", "{\"n\": 1005, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.5, \"learn_time_ms\": 8540.42, \"total_train_time_s\": 9.570916652679443}", "{\"n\": 1006, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.5, \"learn_time_ms\": 8645.933, \"total_train_time_s\": 10.359134674072266}", "{\"n\": 1007, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3020.45, \"learn_time_ms\": 8509.54, \"total_train_time_s\": 9.311378002166748}", "{\"n\": 1008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.41, \"learn_time_ms\": 8399.591, \"total_train_time_s\": 8.322732925415039}", "{\"n\": 1009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.41, \"learn_time_ms\": 8274.015, \"total_train_time_s\": 8.973405122756958}", "{\"n\": 1010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.24, \"learn_time_ms\": 8287.065, \"total_train_time_s\": 10.325160264968872}", "{\"n\": 1011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.88, \"learn_time_ms\": 8408.95, \"total_train_time_s\": 10.887386798858643}", "{\"n\": 1012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.22, \"learn_time_ms\": 8493.424, \"total_train_time_s\": 10.59471344947815}", "{\"n\": 1013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.47, \"learn_time_ms\": 8371.354, \"total_train_time_s\": 9.0582435131073}", "{\"n\": 1014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.73, \"learn_time_ms\": 8337.647, \"total_train_time_s\": 10.20160460472107}", "{\"n\": 1015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3036.68, \"learn_time_ms\": 8500.932, \"total_train_time_s\": 11.166561841964722}", "{\"n\": 1016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3031.55, \"learn_time_ms\": 8321.618, \"total_train_time_s\": 8.478322267532349}", "{\"n\": 1017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.34, \"learn_time_ms\": 8458.038, \"total_train_time_s\": 10.62976336479187}", "{\"n\": 1018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.19, \"learn_time_ms\": 8828.265, \"total_train_time_s\": 11.983350038528442}", "{\"n\": 1019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.27, \"learn_time_ms\": 8868.026, \"total_train_time_s\": 9.42326283454895}", "{\"n\": 1020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3040.3, \"learn_time_ms\": 8888.934, \"total_train_time_s\": 10.63406491279602}", "{\"n\": 1021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3036.32, \"learn_time_ms\": 8711.176, \"total_train_time_s\": 9.151636838912964}", "{\"n\": 1022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.21, \"learn_time_ms\": 8781.551, \"total_train_time_s\": 11.303049325942993}", "{\"n\": 1023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.21, \"learn_time_ms\": 8847.988, \"total_train_time_s\": 9.745156288146973}", "{\"n\": 1024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.94, \"learn_time_ms\": 8833.874, \"total_train_time_s\": 10.042541265487671}", "{\"n\": 1025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.23, \"learn_time_ms\": 8719.227, \"total_train_time_s\": 10.027525663375854}", "{\"n\": 1026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.71, \"learn_time_ms\": 8819.875, \"total_train_time_s\": 9.569450378417969}", "{\"n\": 1027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.71, \"learn_time_ms\": 8936.69, \"total_train_time_s\": 11.753541946411133}", "{\"n\": 1028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3027.82, \"learn_time_ms\": 8783.397, \"total_train_time_s\": 10.50284194946289}", "{\"n\": 1029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.46, \"learn_time_ms\": 8898.674, \"total_train_time_s\": 10.56951093673706}", "{\"n\": 1030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3020.83, \"learn_time_ms\": 8850.962, \"total_train_time_s\": 10.067114114761353}", "{\"n\": 1031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3020.83, \"learn_time_ms\": 8928.974, \"total_train_time_s\": 9.887426137924194}", "{\"n\": 1032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3026.73, \"learn_time_ms\": 8855.501, \"total_train_time_s\": 10.553318738937378}", "{\"n\": 1033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3037.63, \"learn_time_ms\": 8853.304, \"total_train_time_s\": 9.735635757446289}", "{\"n\": 1034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3038.0, \"learn_time_ms\": 8745.673, \"total_train_time_s\": 8.975082874298096}", "{\"n\": 1035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3040.71, \"learn_time_ms\": 8688.763, \"total_train_time_s\": 9.439879417419434}", "{\"n\": 1036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3049.34, \"learn_time_ms\": 8803.023, \"total_train_time_s\": 10.681622505187988}", "{\"n\": 1037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3048.52, \"learn_time_ms\": 8666.355, \"total_train_time_s\": 10.42204475402832}", "{\"n\": 1038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3053.57, \"learn_time_ms\": 8688.966, \"total_train_time_s\": 10.681785106658936}", "{\"n\": 1039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3053.5, \"learn_time_ms\": 8787.754, \"total_train_time_s\": 11.535939693450928}", "{\"n\": 1040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3053.5, \"learn_time_ms\": 8701.52, \"total_train_time_s\": 9.17784070968628}", "{\"n\": 1041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3049.03, \"learn_time_ms\": 8778.775, \"total_train_time_s\": 10.699325561523438}", "{\"n\": 1042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3049.01, \"learn_time_ms\": 8713.787, \"total_train_time_s\": 9.92239785194397}", "{\"n\": 1043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3048.3, \"learn_time_ms\": 8866.019, \"total_train_time_s\": 11.26869535446167}", "{\"n\": 1044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3064.59, \"learn_time_ms\": 9181.394, \"total_train_time_s\": 12.109026908874512}", "{\"n\": 1045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3065.21, \"learn_time_ms\": 9420.968, \"total_train_time_s\": 11.868087530136108}", "{\"n\": 1046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3072.93, \"learn_time_ms\": 9297.566, \"total_train_time_s\": 9.388104677200317}", "{\"n\": 1047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3067.27, \"learn_time_ms\": 9359.908, \"total_train_time_s\": 11.057933330535889}", "{\"n\": 1048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3068.73, \"learn_time_ms\": 9255.529, \"total_train_time_s\": 9.59561824798584}", "{\"n\": 1049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3068.73, \"learn_time_ms\": 9039.936, \"total_train_time_s\": 9.36960220336914}", "{\"n\": 1050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.9, \"learn_time_ms\": 9106.76, \"total_train_time_s\": 9.871184587478638}", "{\"n\": 1051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3084.71, \"learn_time_ms\": 9081.846, \"total_train_time_s\": 10.477646112442017}", "{\"n\": 1052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3088.52, \"learn_time_ms\": 9266.124, \"total_train_time_s\": 11.720335721969604}", "{\"n\": 1053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3094.1, \"learn_time_ms\": 9152.477, \"total_train_time_s\": 10.118557691574097}", "{\"n\": 1054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3093.98, \"learn_time_ms\": 8792.776, \"total_train_time_s\": 8.546279430389404}", "{\"n\": 1055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3090.94, \"learn_time_ms\": 8673.564, \"total_train_time_s\": 10.710806608200073}", "{\"n\": 1056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.19, \"learn_time_ms\": 8729.826, \"total_train_time_s\": 9.961055517196655}", "{\"n\": 1057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.19, \"learn_time_ms\": 8710.757, \"total_train_time_s\": 10.893070936203003}", "{\"n\": 1058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.19, \"learn_time_ms\": 8758.542, \"total_train_time_s\": 10.124282360076904}", "{\"n\": 1059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.42, \"learn_time_ms\": 8851.833, \"total_train_time_s\": 10.319967031478882}", "{\"n\": 1060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3091.58, \"learn_time_ms\": 8950.275, \"total_train_time_s\": 10.871329545974731}", "{\"n\": 1061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3087.78, \"learn_time_ms\": 8991.404, \"total_train_time_s\": 10.871525526046753}", "{\"n\": 1062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.27, \"learn_time_ms\": 9015.024, \"total_train_time_s\": 11.945359468460083}", "{\"n\": 1063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3090.6, \"learn_time_ms\": 8929.372, \"total_train_time_s\": 9.26431155204773}", "{\"n\": 1064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.79, \"learn_time_ms\": 9002.169, \"total_train_time_s\": 9.294838428497314}", "{\"n\": 1065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3094.69, \"learn_time_ms\": 8971.383, \"total_train_time_s\": 10.440481424331665}", "{\"n\": 1066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3101.43, \"learn_time_ms\": 8956.338, \"total_train_time_s\": 9.868400812149048}", "{\"n\": 1067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3104.11, \"learn_time_ms\": 8973.215, \"total_train_time_s\": 11.050249338150024}", "{\"n\": 1068, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3093.73, \"learn_time_ms\": 9106.333, \"total_train_time_s\": 11.42340636253357}", "{\"n\": 1069, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3099.12, \"learn_time_ms\": 9080.37, \"total_train_time_s\": 10.043830394744873}", "{\"n\": 1070, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3105.8, \"learn_time_ms\": 8948.743, \"total_train_time_s\": 9.552612781524658}", "{\"n\": 1071, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3111.07, \"learn_time_ms\": 8929.415, \"total_train_time_s\": 10.685412168502808}", "{\"n\": 1072, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3108.8, \"learn_time_ms\": 8758.18, \"total_train_time_s\": 10.281078338623047}", "{\"n\": 1073, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3114.87, \"learn_time_ms\": 8867.795, \"total_train_time_s\": 10.368929386138916}", "{\"n\": 1074, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3116.33, \"learn_time_ms\": 8963.596, \"total_train_time_s\": 10.205780267715454}", "{\"n\": 1075, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3110.33, \"learn_time_ms\": 8986.948, \"total_train_time_s\": 10.596510887145996}", "{\"n\": 1076, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3108.45, \"learn_time_ms\": 8945.294, \"total_train_time_s\": 9.455353736877441}", "{\"n\": 1077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3111.25, \"learn_time_ms\": 8840.52, \"total_train_time_s\": 9.99819302558899}", "{\"n\": 1078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.78, \"learn_time_ms\": 8736.255, \"total_train_time_s\": 10.437491655349731}", "{\"n\": 1079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3096.98, \"learn_time_ms\": 8883.43, \"total_train_time_s\": 11.547681331634521}", "{\"n\": 1080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3101.15, \"learn_time_ms\": 9036.41, \"total_train_time_s\": 11.086406469345093}", "{\"n\": 1081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.97, \"learn_time_ms\": 8869.528, \"total_train_time_s\": 9.01951551437378}", "{\"n\": 1082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.92, \"learn_time_ms\": 8702.333, \"total_train_time_s\": 8.574052810668945}", "{\"n\": 1083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.56, \"learn_time_ms\": 8649.078, \"total_train_time_s\": 9.848500490188599}", "{\"n\": 1084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3097.49, \"learn_time_ms\": 8801.554, \"total_train_time_s\": 11.760698080062866}", "{\"n\": 1085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.33, \"learn_time_ms\": 8779.685, \"total_train_time_s\": 10.400067567825317}", "{\"n\": 1086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3094.79, \"learn_time_ms\": 8792.553, \"total_train_time_s\": 9.553969860076904}", "{\"n\": 1087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3087.86, \"learn_time_ms\": 8827.323, \"total_train_time_s\": 10.359380006790161}", "{\"n\": 1088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.21, \"learn_time_ms\": 8842.291, \"total_train_time_s\": 10.532115936279297}", "{\"n\": 1089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3085.8, \"learn_time_ms\": 8679.122, \"total_train_time_s\": 9.866383790969849}", "{\"n\": 1090, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3084.49, \"learn_time_ms\": 8567.942, \"total_train_time_s\": 9.975508689880371}", "{\"n\": 1091, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3087.15, \"learn_time_ms\": 8765.075, \"total_train_time_s\": 10.999680042266846}", "{\"n\": 1092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3085.89, \"learn_time_ms\": 8858.672, \"total_train_time_s\": 9.54750394821167}", "{\"n\": 1093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3090.2, \"learn_time_ms\": 8901.401, \"total_train_time_s\": 10.321615934371948}", "{\"n\": 1094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3093.57, \"learn_time_ms\": 8854.45, \"total_train_time_s\": 11.269856214523315}", "{\"n\": 1095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.92, \"learn_time_ms\": 8787.39, \"total_train_time_s\": 9.737705707550049}", "{\"n\": 1096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3091.08, \"learn_time_ms\": 8728.124, \"total_train_time_s\": 8.944270372390747}", "{\"n\": 1097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.77, \"learn_time_ms\": 8621.772, \"total_train_time_s\": 9.254111289978027}", "{\"n\": 1098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3094.82, \"learn_time_ms\": 8571.66, \"total_train_time_s\": 10.014923572540283}", "{\"n\": 1099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3083.31, \"learn_time_ms\": 8691.223, \"total_train_time_s\": 11.100507020950317}", "{\"n\": 1100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3083.31, \"learn_time_ms\": 8604.199, \"total_train_time_s\": 9.123375654220581}", "{\"n\": 1101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3081.48, \"learn_time_ms\": 8583.536, \"total_train_time_s\": 10.786405563354492}", "{\"n\": 1102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.07, \"learn_time_ms\": 8604.102, \"total_train_time_s\": 9.731337547302246}", "{\"n\": 1103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.85, \"learn_time_ms\": 8567.393, \"total_train_time_s\": 9.900243759155273}", "{\"n\": 1104, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3099.05, \"learn_time_ms\": 8521.091, \"total_train_time_s\": 10.799642086029053}", "{\"n\": 1105, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3099.15, \"learn_time_ms\": 8659.509, \"total_train_time_s\": 11.10795521736145}", "{\"n\": 1106, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.01, \"learn_time_ms\": 8851.215, \"total_train_time_s\": 10.84022331237793}", "{\"n\": 1107, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.01, \"learn_time_ms\": 8963.562, \"total_train_time_s\": 10.457473993301392}", "{\"n\": 1108, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3104.18, \"learn_time_ms\": 8994.318, \"total_train_time_s\": 10.337367057800293}", "{\"n\": 1109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3107.89, \"learn_time_ms\": 8967.221, \"total_train_time_s\": 10.868104696273804}", "{\"n\": 1110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3097.85, \"learn_time_ms\": 9173.176, \"total_train_time_s\": 11.175285816192627}", "{\"n\": 1111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3096.51, \"learn_time_ms\": 9061.013, \"total_train_time_s\": 9.649582862854004}", "{\"n\": 1112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.54, \"learn_time_ms\": 9165.917, \"total_train_time_s\": 10.781848430633545}", "{\"n\": 1113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.95, \"learn_time_ms\": 9306.031, \"total_train_time_s\": 11.257117748260498}", "{\"n\": 1114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3086.94, \"learn_time_ms\": 9280.599, \"total_train_time_s\": 10.560508251190186}", "{\"n\": 1115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3086.94, \"learn_time_ms\": 9361.198, \"total_train_time_s\": 11.92048978805542}", "{\"n\": 1116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3080.49, \"learn_time_ms\": 9250.021, \"total_train_time_s\": 9.780076503753662}", "{\"n\": 1117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.21, \"learn_time_ms\": 9280.309, \"total_train_time_s\": 10.666377067565918}", "{\"n\": 1118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3089.21, \"learn_time_ms\": 9295.631, \"total_train_time_s\": 10.502886295318604}", "{\"n\": 1119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3093.03, \"learn_time_ms\": 9170.793, \"total_train_time_s\": 9.54557728767395}", "{\"n\": 1120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3100.2, \"learn_time_ms\": 9029.258, \"total_train_time_s\": 9.720054388046265}", "{\"n\": 1121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.13, \"learn_time_ms\": 9141.632, \"total_train_time_s\": 10.777039051055908}", "{\"n\": 1122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3104.99, \"learn_time_ms\": 9151.861, \"total_train_time_s\": 10.90084719657898}", "{\"n\": 1123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3097.48, \"learn_time_ms\": 8923.706, \"total_train_time_s\": 9.043765783309937}", "{\"n\": 1124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3099.44, \"learn_time_ms\": 8806.017, \"total_train_time_s\": 9.4014413356781}", "{\"n\": 1125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.63, \"learn_time_ms\": 8699.13, \"total_train_time_s\": 10.794328689575195}", "{\"n\": 1126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.1, \"learn_time_ms\": 8717.28, \"total_train_time_s\": 9.987272500991821}", "{\"n\": 1127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3098.69, \"learn_time_ms\": 8696.993, \"total_train_time_s\": 10.531500577926636}", "{\"n\": 1128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3101.48, \"learn_time_ms\": 8724.408, \"total_train_time_s\": 10.768429279327393}", "{\"n\": 1129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3105.24, \"learn_time_ms\": 8806.948, \"total_train_time_s\": 10.393836975097656}", "{\"n\": 1130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3107.26, \"learn_time_ms\": 8771.94, \"total_train_time_s\": 9.389386653900146}", "{\"n\": 1131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3108.18, \"learn_time_ms\": 8806.478, \"total_train_time_s\": 11.107447862625122}", "{\"n\": 1132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3112.92, \"learn_time_ms\": 8622.799, \"total_train_time_s\": 9.034310579299927}", "{\"n\": 1133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.79, \"learn_time_ms\": 8775.401, \"total_train_time_s\": 10.576359272003174}", "{\"n\": 1134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.79, \"learn_time_ms\": 8728.914, \"total_train_time_s\": 8.91795039176941}", "{\"n\": 1135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.79, \"learn_time_ms\": 8694.282, \"total_train_time_s\": 10.49614405632019}", "{\"n\": 1136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3127.84, \"learn_time_ms\": 8632.514, \"total_train_time_s\": 9.338520765304565}", "{\"n\": 1137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3124.66, \"learn_time_ms\": 8547.475, \"total_train_time_s\": 9.71412992477417}", "{\"n\": 1138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3127.88, \"learn_time_ms\": 8416.857, \"total_train_time_s\": 9.473862409591675}", "{\"n\": 1139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3127.73, \"learn_time_ms\": 8473.453, \"total_train_time_s\": 10.935272932052612}", "{\"n\": 1140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3130.92, \"learn_time_ms\": 8483.582, \"total_train_time_s\": 9.496357679367065}", "{\"n\": 1141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.44, \"learn_time_ms\": 8419.261, \"total_train_time_s\": 10.507758855819702}", "{\"n\": 1142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.44, \"learn_time_ms\": 8430.331, \"total_train_time_s\": 9.165442705154419}", "{\"n\": 1143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3129.91, \"learn_time_ms\": 8372.279, \"total_train_time_s\": 9.970643043518066}", "{\"n\": 1144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.34, \"learn_time_ms\": 8582.724, \"total_train_time_s\": 11.038384437561035}", "{\"n\": 1145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.34, \"learn_time_ms\": 8579.472, \"total_train_time_s\": 10.426608324050903}", "{\"n\": 1146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3127.17, \"learn_time_ms\": 8666.094, \"total_train_time_s\": 10.183865070343018}", "{\"n\": 1147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3121.02, \"learn_time_ms\": 8656.623, \"total_train_time_s\": 9.552682638168335}", "{\"n\": 1148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3121.02, \"learn_time_ms\": 8771.575, \"total_train_time_s\": 10.650760173797607}", "{\"n\": 1149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3115.52, \"learn_time_ms\": 8717.197, \"total_train_time_s\": 10.422493934631348}", "{\"n\": 1150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3115.52, \"learn_time_ms\": 8824.04, \"total_train_time_s\": 10.544056415557861}", "{\"n\": 1151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3115.79, \"learn_time_ms\": 8746.531, \"total_train_time_s\": 9.697598457336426}", "{\"n\": 1152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3114.09, \"learn_time_ms\": 8779.328, \"total_train_time_s\": 9.483028411865234}", "{\"n\": 1153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3118.06, \"learn_time_ms\": 8814.65, \"total_train_time_s\": 10.296876430511475}", "{\"n\": 1154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3118.06, \"learn_time_ms\": 8669.489, \"total_train_time_s\": 9.561659812927246}", "{\"n\": 1155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3117.39, \"learn_time_ms\": 8690.447, \"total_train_time_s\": 10.669761180877686}", "{\"n\": 1156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3117.39, \"learn_time_ms\": 8617.322, \"total_train_time_s\": 9.441871643066406}", "{\"n\": 1157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3120.4, \"learn_time_ms\": 8700.584, \"total_train_time_s\": 10.390222787857056}", "{\"n\": 1158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3130.03, \"learn_time_ms\": 8742.641, \"total_train_time_s\": 11.062724351882935}", "{\"n\": 1159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3130.03, \"learn_time_ms\": 8712.016, \"total_train_time_s\": 10.050946950912476}", "{\"n\": 1160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.38, \"learn_time_ms\": 8667.315, \"total_train_time_s\": 10.107513904571533}", "{\"n\": 1161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.29, \"learn_time_ms\": 8706.783, \"total_train_time_s\": 10.08382511138916}", "{\"n\": 1162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.59, \"learn_time_ms\": 8842.232, \"total_train_time_s\": 10.870935440063477}", "{\"n\": 1163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.59, \"learn_time_ms\": 8795.091, \"total_train_time_s\": 9.851195812225342}", "{\"n\": 1164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3143.64, \"learn_time_ms\": 8782.644, \"total_train_time_s\": 9.503718376159668}", "{\"n\": 1165, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3140.64, \"learn_time_ms\": 8678.595, \"total_train_time_s\": 9.603655815124512}", "{\"n\": 1166, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3140.64, \"learn_time_ms\": 8774.573, \"total_train_time_s\": 10.405184030532837}", "{\"n\": 1167, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.85, \"learn_time_ms\": 8698.414, \"total_train_time_s\": 9.642322540283203}", "{\"n\": 1168, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.85, \"learn_time_ms\": 8562.633, \"total_train_time_s\": 9.695107221603394}", "{\"n\": 1169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.78, \"learn_time_ms\": 8536.577, \"total_train_time_s\": 9.85506010055542}", "{\"n\": 1170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3140.23, \"learn_time_ms\": 8550.134, \"total_train_time_s\": 10.274867296218872}", "{\"n\": 1171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.05, \"learn_time_ms\": 8717.257, \"total_train_time_s\": 11.81861400604248}", "{\"n\": 1172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.05, \"learn_time_ms\": 8730.752, \"total_train_time_s\": 10.96991753578186}", "{\"n\": 1173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.05, \"learn_time_ms\": 8678.651, \"total_train_time_s\": 9.300691843032837}", "{\"n\": 1174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.04, \"learn_time_ms\": 8606.769, \"total_train_time_s\": 8.744588375091553}", "{\"n\": 1175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.04, \"learn_time_ms\": 8704.548, \"total_train_time_s\": 10.638410091400146}", "{\"n\": 1176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.42, \"learn_time_ms\": 8760.353, \"total_train_time_s\": 11.012075662612915}", "{\"n\": 1177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3153.74, \"learn_time_ms\": 8764.039, \"total_train_time_s\": 9.649242877960205}", "{\"n\": 1178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.12, \"learn_time_ms\": 8841.307, \"total_train_time_s\": 10.48031497001648}", "{\"n\": 1179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3150.34, \"learn_time_ms\": 8804.146, \"total_train_time_s\": 9.482951879501343}", "{\"n\": 1180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3141.68, \"learn_time_ms\": 8970.004, \"total_train_time_s\": 11.966911792755127}", "{\"n\": 1181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.33, \"learn_time_ms\": 8848.472, \"total_train_time_s\": 10.539931774139404}", "{\"n\": 1182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.48, \"learn_time_ms\": 8738.976, \"total_train_time_s\": 9.889078617095947}", "{\"n\": 1183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.66, \"learn_time_ms\": 8956.01, \"total_train_time_s\": 11.469280004501343}", "{\"n\": 1184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.66, \"learn_time_ms\": 9086.476, \"total_train_time_s\": 10.054136276245117}", "{\"n\": 1185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.52, \"learn_time_ms\": 9044.197, \"total_train_time_s\": 10.166390419006348}", "{\"n\": 1186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3143.65, \"learn_time_ms\": 9013.86, \"total_train_time_s\": 10.678472518920898}", "{\"n\": 1187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3133.58, \"learn_time_ms\": 9031.686, \"total_train_time_s\": 9.831610441207886}", "{\"n\": 1188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3130.14, \"learn_time_ms\": 9124.912, \"total_train_time_s\": 11.4269540309906}", "{\"n\": 1189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.39, \"learn_time_ms\": 9086.653, \"total_train_time_s\": 9.06821060180664}", "{\"n\": 1190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.39, \"learn_time_ms\": 8907.228, \"total_train_time_s\": 10.093989610671997}", "{\"n\": 1191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3118.88, \"learn_time_ms\": 8883.615, \"total_train_time_s\": 10.272631883621216}", "{\"n\": 1192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3126.79, \"learn_time_ms\": 9075.55, \"total_train_time_s\": 11.801288843154907}", "{\"n\": 1193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3126.79, \"learn_time_ms\": 8893.36, \"total_train_time_s\": 9.6692476272583}", "{\"n\": 1194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.87, \"learn_time_ms\": 9008.667, \"total_train_time_s\": 11.207908868789673}", "{\"n\": 1195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.91, \"learn_time_ms\": 8994.187, \"total_train_time_s\": 10.043862342834473}", "{\"n\": 1196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.91, \"learn_time_ms\": 9000.218, \"total_train_time_s\": 10.740670442581177}", "{\"n\": 1197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3116.84, \"learn_time_ms\": 9166.288, \"total_train_time_s\": 11.540416240692139}", "{\"n\": 1198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3116.5, \"learn_time_ms\": 8879.626, \"total_train_time_s\": 8.509590148925781}", "{\"n\": 1199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3116.5, \"learn_time_ms\": 8918.882, \"total_train_time_s\": 9.446497201919556}", "{\"n\": 1200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.36, \"learn_time_ms\": 8974.857, \"total_train_time_s\": 10.727007150650024}", "{\"n\": 1201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.36, \"learn_time_ms\": 9015.714, \"total_train_time_s\": 10.761473178863525}", "{\"n\": 1202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.36, \"learn_time_ms\": 8787.88, \"total_train_time_s\": 9.527689695358276}", "{\"n\": 1203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3100.3, \"learn_time_ms\": 8995.85, \"total_train_time_s\": 11.758089065551758}", "{\"n\": 1204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.38, \"learn_time_ms\": 8882.902, \"total_train_time_s\": 10.054877281188965}", "{\"n\": 1205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.38, \"learn_time_ms\": 8838.681, \"total_train_time_s\": 9.610509395599365}", "{\"n\": 1206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3095.54, \"learn_time_ms\": 8852.13, \"total_train_time_s\": 10.853131771087646}", "{\"n\": 1207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.34, \"learn_time_ms\": 8778.009, \"total_train_time_s\": 10.74834156036377}", "{\"n\": 1208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.34, \"learn_time_ms\": 9025.762, \"total_train_time_s\": 10.99460744857788}", "{\"n\": 1209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3085.89, \"learn_time_ms\": 9256.02, \"total_train_time_s\": 11.7829749584198}", "{\"n\": 1210, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3089.92, \"learn_time_ms\": 9226.133, \"total_train_time_s\": 10.394775152206421}", "{\"n\": 1211, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3089.92, \"learn_time_ms\": 9238.289, \"total_train_time_s\": 10.818380117416382}", "{\"n\": 1212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3086.43, \"learn_time_ms\": 9377.41, \"total_train_time_s\": 10.88698673248291}", "{\"n\": 1213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.9, \"learn_time_ms\": 9230.419, \"total_train_time_s\": 10.282979011535645}", "{\"n\": 1214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.9, \"learn_time_ms\": 9296.74, \"total_train_time_s\": 10.713370561599731}", "{\"n\": 1215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3078.73, \"learn_time_ms\": 9247.2, \"total_train_time_s\": 9.051573514938354}", "{\"n\": 1216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.21, \"learn_time_ms\": 9066.876, \"total_train_time_s\": 9.09721064567566}", "{\"n\": 1217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.21, \"learn_time_ms\": 9083.754, \"total_train_time_s\": 10.951304912567139}", "{\"n\": 1218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3084.45, \"learn_time_ms\": 9014.441, \"total_train_time_s\": 10.290530681610107}", "{\"n\": 1219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3080.46, \"learn_time_ms\": 8897.659, \"total_train_time_s\": 10.626155614852905}", "{\"n\": 1220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.23, \"learn_time_ms\": 8827.897, \"total_train_time_s\": 9.716292142868042}", "{\"n\": 1221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3086.74, \"learn_time_ms\": 8606.259, \"total_train_time_s\": 8.62332534790039}", "{\"n\": 1222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.38, \"learn_time_ms\": 8544.312, \"total_train_time_s\": 10.320688486099243}", "{\"n\": 1223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.11, \"learn_time_ms\": 8577.858, \"total_train_time_s\": 10.60326337814331}", "{\"n\": 1224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3092.24, \"learn_time_ms\": 8422.364, \"total_train_time_s\": 9.148319721221924}", "{\"n\": 1225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3092.24, \"learn_time_ms\": 8553.313, \"total_train_time_s\": 10.350847721099854}", "{\"n\": 1226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.68, \"learn_time_ms\": 8717.261, \"total_train_time_s\": 10.746241569519043}", "{\"n\": 1227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.68, \"learn_time_ms\": 8655.531, \"total_train_time_s\": 10.319307088851929}", "{\"n\": 1228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.68, \"learn_time_ms\": 8682.61, \"total_train_time_s\": 10.571108341217041}", "{\"n\": 1229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.66, \"learn_time_ms\": 8647.877, \"total_train_time_s\": 10.269284963607788}", "{\"n\": 1230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.66, \"learn_time_ms\": 8668.162, \"total_train_time_s\": 9.897329092025757}", "{\"n\": 1231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3097.37, \"learn_time_ms\": 8792.003, \"total_train_time_s\": 9.83808445930481}", "{\"n\": 1232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.41, \"learn_time_ms\": 8689.09, \"total_train_time_s\": 9.252346992492676}", "{\"n\": 1233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3102.62, \"learn_time_ms\": 8732.092, \"total_train_time_s\": 11.040733098983765}", "{\"n\": 1234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.07, \"learn_time_ms\": 8809.303, \"total_train_time_s\": 9.939266920089722}", "{\"n\": 1235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3104.12, \"learn_time_ms\": 8928.776, \"total_train_time_s\": 11.602312564849854}", "{\"n\": 1236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3104.44, \"learn_time_ms\": 8826.46, \"total_train_time_s\": 9.681896924972534}", "{\"n\": 1237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3098.16, \"learn_time_ms\": 8799.34, \"total_train_time_s\": 10.005656719207764}", "{\"n\": 1238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3098.16, \"learn_time_ms\": 8755.25, \"total_train_time_s\": 10.136512756347656}", "{\"n\": 1239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3102.11, \"learn_time_ms\": 8727.602, \"total_train_time_s\": 9.98769235610962}", "{\"n\": 1240, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.99, \"learn_time_ms\": 8765.011, \"total_train_time_s\": 10.267931938171387}", "{\"n\": 1241, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3102.75, \"learn_time_ms\": 8670.488, \"total_train_time_s\": 8.905565023422241}", "{\"n\": 1242, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.45, \"learn_time_ms\": 8929.103, \"total_train_time_s\": 11.839239358901978}", "{\"n\": 1243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.45, \"learn_time_ms\": 8781.079, \"total_train_time_s\": 9.549964904785156}", "{\"n\": 1244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.52, \"learn_time_ms\": 8908.412, \"total_train_time_s\": 11.22230339050293}", "{\"n\": 1245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.89, \"learn_time_ms\": 8730.38, \"total_train_time_s\": 9.828323364257812}", "{\"n\": 1246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.11, \"learn_time_ms\": 8869.837, \"total_train_time_s\": 11.066262483596802}", "{\"n\": 1247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.37, \"learn_time_ms\": 8856.569, \"total_train_time_s\": 9.875126600265503}", "{\"n\": 1248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.37, \"learn_time_ms\": 8919.009, \"total_train_time_s\": 10.768095016479492}", "{\"n\": 1249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.9, \"learn_time_ms\": 9024.323, \"total_train_time_s\": 11.036984920501709}", "{\"n\": 1250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.51, \"learn_time_ms\": 8996.831, \"total_train_time_s\": 10.025310754776001}", "{\"n\": 1251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.51, \"learn_time_ms\": 8978.211, \"total_train_time_s\": 8.755978345870972}", "{\"n\": 1252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.96, \"learn_time_ms\": 8695.33, \"total_train_time_s\": 9.095394372940063}", "{\"n\": 1253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.96, \"learn_time_ms\": 8713.507, \"total_train_time_s\": 9.738940238952637}", "{\"n\": 1254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.88, \"learn_time_ms\": 8591.746, \"total_train_time_s\": 10.02189826965332}", "{\"n\": 1255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.14, \"learn_time_ms\": 8632.997, \"total_train_time_s\": 10.208283185958862}", "{\"n\": 1256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.93, \"learn_time_ms\": 8602.166, \"total_train_time_s\": 10.778496980667114}", "{\"n\": 1257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.29, \"learn_time_ms\": 8709.268, \"total_train_time_s\": 10.945838212966919}", "{\"n\": 1258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.06, \"learn_time_ms\": 8496.51, \"total_train_time_s\": 8.664467573165894}", "{\"n\": 1259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3137.59, \"learn_time_ms\": 8232.276, \"total_train_time_s\": 8.434969902038574}", "{\"n\": 1260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.46, \"learn_time_ms\": 8256.247, \"total_train_time_s\": 10.19106936454773}", "{\"n\": 1261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.05, \"learn_time_ms\": 8451.722, \"total_train_time_s\": 10.693464994430542}", "{\"n\": 1262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.18, \"learn_time_ms\": 8583.091, \"total_train_time_s\": 10.355870485305786}", "{\"n\": 1263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.59, \"learn_time_ms\": 8549.342, \"total_train_time_s\": 9.376052618026733}", "{\"n\": 1264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.1, \"learn_time_ms\": 8733.597, \"total_train_time_s\": 11.796701192855835}", "{\"n\": 1265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3137.57, \"learn_time_ms\": 8698.768, \"total_train_time_s\": 9.872775793075562}", "{\"n\": 1266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3137.57, \"learn_time_ms\": 8619.437, \"total_train_time_s\": 9.94165563583374}", "{\"n\": 1267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.1, \"learn_time_ms\": 8518.42, \"total_train_time_s\": 9.998092651367188}", "{\"n\": 1268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.99, \"learn_time_ms\": 8838.632, \"total_train_time_s\": 11.840038776397705}", "{\"n\": 1269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.99, \"learn_time_ms\": 9105.602, \"total_train_time_s\": 11.06289267539978}", "{\"n\": 1270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.47, \"learn_time_ms\": 9204.459, \"total_train_time_s\": 11.206460237503052}", "{\"n\": 1271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.6, \"learn_time_ms\": 9137.255, \"total_train_time_s\": 10.028228998184204}", "{\"n\": 1272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.71, \"learn_time_ms\": 9168.748, \"total_train_time_s\": 10.638425588607788}", "{\"n\": 1273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.11, \"learn_time_ms\": 9251.556, \"total_train_time_s\": 10.234357118606567}", "{\"n\": 1274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.67, \"learn_time_ms\": 9095.374, \"total_train_time_s\": 10.289273977279663}", "{\"n\": 1275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.67, \"learn_time_ms\": 9316.241, \"total_train_time_s\": 12.077231168746948}", "{\"n\": 1276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.63, \"learn_time_ms\": 9432.091, \"total_train_time_s\": 11.152930498123169}", "{\"n\": 1277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.57, \"learn_time_ms\": 9387.064, \"total_train_time_s\": 9.507382154464722}", "{\"n\": 1278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.57, \"learn_time_ms\": 9158.607, \"total_train_time_s\": 9.572883129119873}", "{\"n\": 1279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.11, \"learn_time_ms\": 9044.695, \"total_train_time_s\": 9.917019605636597}", "{\"n\": 1280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.62, \"learn_time_ms\": 9003.101, \"total_train_time_s\": 10.836646556854248}", "{\"n\": 1281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.62, \"learn_time_ms\": 9121.419, \"total_train_time_s\": 11.137211799621582}", "{\"n\": 1282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.04, \"learn_time_ms\": 9101.07, \"total_train_time_s\": 10.39216661453247}", "{\"n\": 1283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.32, \"learn_time_ms\": 9110.039, \"total_train_time_s\": 10.315819025039673}", "{\"n\": 1284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.32, \"learn_time_ms\": 9087.58, \"total_train_time_s\": 10.099853038787842}", "{\"n\": 1285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.7, \"learn_time_ms\": 8952.808, \"total_train_time_s\": 10.735957145690918}", "{\"n\": 1286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.39, \"learn_time_ms\": 8831.49, \"total_train_time_s\": 9.871794939041138}", "{\"n\": 1287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.39, \"learn_time_ms\": 8838.941, \"total_train_time_s\": 9.546277046203613}", "{\"n\": 1288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.21, \"learn_time_ms\": 8842.774, \"total_train_time_s\": 9.597119808197021}", "{\"n\": 1289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.21, \"learn_time_ms\": 8880.272, \"total_train_time_s\": 10.32934308052063}", "{\"n\": 1290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.56, \"learn_time_ms\": 8775.423, \"total_train_time_s\": 9.757947206497192}", "{\"n\": 1291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.56, \"learn_time_ms\": 8662.747, \"total_train_time_s\": 10.070852518081665}", "{\"n\": 1292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.93, \"learn_time_ms\": 8627.636, \"total_train_time_s\": 10.087857007980347}", "{\"n\": 1293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.65, \"learn_time_ms\": 8733.168, \"total_train_time_s\": 11.40217900276184}", "{\"n\": 1294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.29, \"learn_time_ms\": 8727.868, \"total_train_time_s\": 9.991128921508789}", "{\"n\": 1295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.58, \"learn_time_ms\": 8711.75, \"total_train_time_s\": 10.58825421333313}", "{\"n\": 1296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.37, \"learn_time_ms\": 8700.98, \"total_train_time_s\": 9.843238592147827}", "{\"n\": 1297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.16, \"learn_time_ms\": 8667.754, \"total_train_time_s\": 9.293664932250977}", "{\"n\": 1298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.52, \"learn_time_ms\": 8732.927, \"total_train_time_s\": 10.26514458656311}", "{\"n\": 1299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.94, \"learn_time_ms\": 8685.588, \"total_train_time_s\": 9.828391075134277}", "{\"n\": 1300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.94, \"learn_time_ms\": 8724.331, \"total_train_time_s\": 10.129371643066406}", "{\"n\": 1301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.54, \"learn_time_ms\": 8814.61, \"total_train_time_s\": 10.999639987945557}", "{\"n\": 1302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.98, \"learn_time_ms\": 8882.966, \"total_train_time_s\": 10.738403081893921}", "{\"n\": 1303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.98, \"learn_time_ms\": 8778.818, \"total_train_time_s\": 10.325253963470459}", "{\"n\": 1304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.74, \"learn_time_ms\": 8785.593, \"total_train_time_s\": 10.051282167434692}", "{\"n\": 1305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.58, \"learn_time_ms\": 8692.161, \"total_train_time_s\": 9.64352011680603}", "{\"n\": 1306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.58, \"learn_time_ms\": 8731.448, \"total_train_time_s\": 10.213046789169312}", "{\"n\": 1307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.16, \"learn_time_ms\": 8878.685, \"total_train_time_s\": 10.729759693145752}", "{\"n\": 1308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.4, \"learn_time_ms\": 8832.414, \"total_train_time_s\": 9.820770263671875}", "{\"n\": 1309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.4, \"learn_time_ms\": 8968.502, \"total_train_time_s\": 11.216300249099731}", "{\"n\": 1310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.31, \"learn_time_ms\": 8837.582, \"total_train_time_s\": 8.862756490707397}", "{\"n\": 1311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.62, \"learn_time_ms\": 8856.458, \"total_train_time_s\": 11.175899267196655}", "{\"n\": 1312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.24, \"learn_time_ms\": 8814.018, \"total_train_time_s\": 10.328829288482666}", "{\"n\": 1313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.64, \"learn_time_ms\": 8772.481, \"total_train_time_s\": 9.923543214797974}", "{\"n\": 1314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.38, \"learn_time_ms\": 8773.07, \"total_train_time_s\": 10.074954509735107}", "{\"n\": 1315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.38, \"learn_time_ms\": 8762.51, \"total_train_time_s\": 9.549140214920044}", "{\"n\": 1316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.63, \"learn_time_ms\": 8794.558, \"total_train_time_s\": 10.55312728881836}", "{\"n\": 1317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.53, \"learn_time_ms\": 8725.168, \"total_train_time_s\": 10.046512126922607}", "{\"n\": 1318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.26, \"learn_time_ms\": 8727.962, \"total_train_time_s\": 9.833476305007935}", "{\"n\": 1319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.24, \"learn_time_ms\": 8554.411, \"total_train_time_s\": 9.466699838638306}", "{\"n\": 1320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.73, \"learn_time_ms\": 8768.159, \"total_train_time_s\": 10.9671630859375}", "{\"n\": 1321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.71, \"learn_time_ms\": 8661.642, \"total_train_time_s\": 10.086243629455566}", "{\"n\": 1322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.46, \"learn_time_ms\": 8536.448, \"total_train_time_s\": 9.166340589523315}", "{\"n\": 1323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.46, \"learn_time_ms\": 8671.103, \"total_train_time_s\": 11.27163028717041}", "{\"n\": 1324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.46, \"learn_time_ms\": 8922.806, \"total_train_time_s\": 12.586971282958984}", "{\"n\": 1325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.27, \"learn_time_ms\": 9003.165, \"total_train_time_s\": 10.342747688293457}", "{\"n\": 1326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.5, \"learn_time_ms\": 8955.97, \"total_train_time_s\": 10.044320583343506}", "{\"n\": 1327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.21, \"learn_time_ms\": 8983.6, \"total_train_time_s\": 10.269008159637451}", "{\"n\": 1328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.75, \"learn_time_ms\": 8957.456, \"total_train_time_s\": 9.569703340530396}", "{\"n\": 1329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.26, \"learn_time_ms\": 9074.554, \"total_train_time_s\": 10.627978801727295}", "{\"n\": 1330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.27, \"learn_time_ms\": 9058.953, \"total_train_time_s\": 10.797359466552734}", "{\"n\": 1331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.86, \"learn_time_ms\": 8966.652, \"total_train_time_s\": 9.224371194839478}", "{\"n\": 1332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.73, \"learn_time_ms\": 9144.407, \"total_train_time_s\": 10.921555995941162}", "{\"n\": 1333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.73, \"learn_time_ms\": 8987.367, \"total_train_time_s\": 9.706272602081299}", "{\"n\": 1334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.9, \"learn_time_ms\": 8792.438, \"total_train_time_s\": 10.625621795654297}", "{\"n\": 1335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.66, \"learn_time_ms\": 8621.784, \"total_train_time_s\": 8.670542240142822}", "{\"n\": 1336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.66, \"learn_time_ms\": 8626.751, \"total_train_time_s\": 10.167251825332642}", "{\"n\": 1337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.15, \"learn_time_ms\": 8627.966, \"total_train_time_s\": 10.41596269607544}", "{\"n\": 1338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.74, \"learn_time_ms\": 8652.3, \"total_train_time_s\": 9.851883172988892}", "{\"n\": 1339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.74, \"learn_time_ms\": 8565.566, \"total_train_time_s\": 9.758216857910156}", "{\"n\": 1340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.54, \"learn_time_ms\": 8445.874, \"total_train_time_s\": 9.611158847808838}", "{\"n\": 1341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3140.51, \"learn_time_ms\": 8697.772, \"total_train_time_s\": 11.707563638687134}", "{\"n\": 1342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3140.51, \"learn_time_ms\": 8709.45, \"total_train_time_s\": 10.987952709197998}", "{\"n\": 1343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.31, \"learn_time_ms\": 8784.111, \"total_train_time_s\": 10.431403875350952}", "{\"n\": 1344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.72, \"learn_time_ms\": 8735.392, \"total_train_time_s\": 10.177536010742188}", "{\"n\": 1345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.72, \"learn_time_ms\": 8837.295, \"total_train_time_s\": 9.628754377365112}", "{\"n\": 1346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.72, \"learn_time_ms\": 8717.852, \"total_train_time_s\": 8.92180848121643}", "{\"n\": 1347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.3, \"learn_time_ms\": 8782.876, \"total_train_time_s\": 10.96979570388794}", "{\"n\": 1348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.75, \"learn_time_ms\": 8903.193, \"total_train_time_s\": 10.98318362236023}", "{\"n\": 1349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.63, \"learn_time_ms\": 8821.73, \"total_train_time_s\": 8.936535596847534}", "{\"n\": 1350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.63, \"learn_time_ms\": 8870.964, \"total_train_time_s\": 10.153820991516113}", "{\"n\": 1351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.43, \"learn_time_ms\": 8766.649, \"total_train_time_s\": 10.685451745986938}", "{\"n\": 1352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3140.07, \"learn_time_ms\": 8633.158, \"total_train_time_s\": 9.683828592300415}", "{\"n\": 1353, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.56, \"learn_time_ms\": 8660.612, \"total_train_time_s\": 10.724620580673218}", "{\"n\": 1354, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3138.05, \"learn_time_ms\": 8654.984, \"total_train_time_s\": 10.115732669830322}", "{\"n\": 1355, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3137.31, \"learn_time_ms\": 8477.038, \"total_train_time_s\": 7.856727123260498}", "{\"n\": 1356, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3123.17, \"learn_time_ms\": 8639.369, \"total_train_time_s\": 10.571373224258423}", "{\"n\": 1357, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.94, \"learn_time_ms\": 8505.764, \"total_train_time_s\": 9.634716272354126}", "{\"n\": 1358, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.02, \"learn_time_ms\": 8260.031, \"total_train_time_s\": 8.524414539337158}", "{\"n\": 1359, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.47, \"learn_time_ms\": 8488.398, \"total_train_time_s\": 11.228895425796509}", "{\"n\": 1360, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.96, \"learn_time_ms\": 8527.094, \"total_train_time_s\": 10.450732469558716}", "{\"n\": 1361, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.54, \"learn_time_ms\": 8453.219, \"total_train_time_s\": 9.908160209655762}", "{\"n\": 1362, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.6, \"learn_time_ms\": 8433.355, \"total_train_time_s\": 9.437331199645996}", "{\"n\": 1363, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3123.19, \"learn_time_ms\": 8310.079, \"total_train_time_s\": 9.472941160202026}", "{\"n\": 1364, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.54, \"learn_time_ms\": 8260.603, \"total_train_time_s\": 9.61081600189209}", "{\"n\": 1365, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.73, \"learn_time_ms\": 8619.244, \"total_train_time_s\": 11.482863903045654}", "{\"n\": 1366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.47, \"learn_time_ms\": 8697.236, \"total_train_time_s\": 11.275342226028442}", "{\"n\": 1367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.23, \"learn_time_ms\": 8835.367, \"total_train_time_s\": 11.023226499557495}", "{\"n\": 1368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.23, \"learn_time_ms\": 8885.461, \"total_train_time_s\": 9.020402669906616}", "{\"n\": 1369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.56, \"learn_time_ms\": 8854.814, \"total_train_time_s\": 10.921823024749756}", "{\"n\": 1370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.93, \"learn_time_ms\": 8801.486, \"total_train_time_s\": 9.962966680526733}", "{\"n\": 1371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.93, \"learn_time_ms\": 8847.475, \"total_train_time_s\": 10.420867443084717}", "{\"n\": 1372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.77, \"learn_time_ms\": 8841.431, \"total_train_time_s\": 9.410791158676147}", "{\"n\": 1373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.5, \"learn_time_ms\": 9007.115, \"total_train_time_s\": 11.171411037445068}", "{\"n\": 1374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.32, \"learn_time_ms\": 9247.395, \"total_train_time_s\": 12.027277946472168}", "{\"n\": 1375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.5, \"learn_time_ms\": 9301.263, \"total_train_time_s\": 12.045838117599487}", "{\"n\": 1376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.99, \"learn_time_ms\": 9181.583, \"total_train_time_s\": 10.131591796875}", "{\"n\": 1377, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.77, \"learn_time_ms\": 9212.053, \"total_train_time_s\": 11.29082179069519}", "{\"n\": 1378, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.83, \"learn_time_ms\": 9280.923, \"total_train_time_s\": 9.726091623306274}", "{\"n\": 1379, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.18, \"learn_time_ms\": 9375.397, \"total_train_time_s\": 11.922882795333862}", "{\"n\": 1380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.08, \"learn_time_ms\": 9443.332, \"total_train_time_s\": 10.638681173324585}", "{\"n\": 1381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.49, \"learn_time_ms\": 9500.579, \"total_train_time_s\": 10.921691656112671}", "{\"n\": 1382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.71, \"learn_time_ms\": 9596.465, \"total_train_time_s\": 10.36931300163269}", "{\"n\": 1383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.34, \"learn_time_ms\": 9651.856, \"total_train_time_s\": 11.709536075592041}", "{\"n\": 1384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.47, \"learn_time_ms\": 9504.549, \"total_train_time_s\": 10.532534122467041}", "{\"n\": 1385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.62, \"learn_time_ms\": 9444.594, \"total_train_time_s\": 11.385135412216187}", "{\"n\": 1386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.92, \"learn_time_ms\": 9470.861, \"total_train_time_s\": 10.399184465408325}", "{\"n\": 1387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.13, \"learn_time_ms\": 9395.552, \"total_train_time_s\": 10.583254337310791}", "{\"n\": 1388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.18, \"learn_time_ms\": 9668.823, \"total_train_time_s\": 12.479831457138062}", "{\"n\": 1389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.38, \"learn_time_ms\": 9467.817, \"total_train_time_s\": 9.851947784423828}", "{\"n\": 1390, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.33, \"learn_time_ms\": 9505.915, \"total_train_time_s\": 10.993338584899902}", "{\"n\": 1391, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.07, \"learn_time_ms\": 9416.141, \"total_train_time_s\": 10.036172866821289}", "{\"n\": 1392, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.19, \"learn_time_ms\": 9444.014, \"total_train_time_s\": 10.64172911643982}", "{\"n\": 1393, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.1, \"learn_time_ms\": 9365.922, \"total_train_time_s\": 10.893078088760376}", "{\"n\": 1394, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.36, \"learn_time_ms\": 9383.402, \"total_train_time_s\": 10.725131273269653}", "{\"n\": 1395, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.95, \"learn_time_ms\": 9323.068, \"total_train_time_s\": 10.85730528831482}", "{\"n\": 1396, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.5, \"learn_time_ms\": 9376.081, \"total_train_time_s\": 10.921672582626343}", "{\"n\": 1397, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.42, \"learn_time_ms\": 9249.775, \"total_train_time_s\": 9.350188255310059}", "{\"n\": 1398, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3117.27, \"learn_time_ms\": 9111.083, \"total_train_time_s\": 11.064340829849243}", "{\"n\": 1399, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.18, \"learn_time_ms\": 9065.5, \"total_train_time_s\": 9.413772583007812}", "{\"n\": 1400, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.48, \"learn_time_ms\": 8962.128, \"total_train_time_s\": 9.987353563308716}", "{\"n\": 1401, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.48, \"learn_time_ms\": 9126.365, \"total_train_time_s\": 11.702160120010376}", "{\"n\": 1402, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.63, \"learn_time_ms\": 8996.61, \"total_train_time_s\": 9.3441002368927}", "{\"n\": 1403, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.34, \"learn_time_ms\": 8945.777, \"total_train_time_s\": 10.357511758804321}", "{\"n\": 1404, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.34, \"learn_time_ms\": 8904.806, \"total_train_time_s\": 10.268498182296753}", "{\"n\": 1405, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.57, \"learn_time_ms\": 8892.413, \"total_train_time_s\": 10.629380702972412}", "{\"n\": 1406, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.49, \"learn_time_ms\": 8823.413, \"total_train_time_s\": 10.238286972045898}", "{\"n\": 1407, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.0, \"learn_time_ms\": 8843.878, \"total_train_time_s\": 9.488863945007324}", "{\"n\": 1408, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3138.8, \"learn_time_ms\": 8949.921, \"total_train_time_s\": 12.180562973022461}", "{\"n\": 1409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.42, \"learn_time_ms\": 9016.117, \"total_train_time_s\": 10.078832864761353}", "{\"n\": 1410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.42, \"learn_time_ms\": 8846.801, \"total_train_time_s\": 8.311003923416138}", "{\"n\": 1411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.76, \"learn_time_ms\": 8797.758, \"total_train_time_s\": 11.209305047988892}", "{\"n\": 1412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.62, \"learn_time_ms\": 8892.824, \"total_train_time_s\": 10.284921169281006}", "{\"n\": 1413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.86, \"learn_time_ms\": 8920.177, \"total_train_time_s\": 10.690478086471558}", "{\"n\": 1414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.46, \"learn_time_ms\": 8885.495, \"total_train_time_s\": 9.971459150314331}", "{\"n\": 1415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.31, \"learn_time_ms\": 8827.988, \"total_train_time_s\": 10.073306560516357}", "{\"n\": 1416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.84, \"learn_time_ms\": 8951.059, \"total_train_time_s\": 11.436795711517334}", "{\"n\": 1417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.97, \"learn_time_ms\": 9088.069, \"total_train_time_s\": 10.934406995773315}", "{\"n\": 1418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.05, \"learn_time_ms\": 8896.476, \"total_train_time_s\": 10.232659339904785}", "{\"n\": 1419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.13, \"learn_time_ms\": 9065.31, \"total_train_time_s\": 11.744148969650269}", "{\"n\": 1420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.81, \"learn_time_ms\": 9242.493, \"total_train_time_s\": 10.069164752960205}", "{\"n\": 1421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.81, \"learn_time_ms\": 9219.13, \"total_train_time_s\": 10.929397821426392}", "{\"n\": 1422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.6, \"learn_time_ms\": 9048.439, \"total_train_time_s\": 8.596040964126587}", "{\"n\": 1423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.64, \"learn_time_ms\": 9153.92, \"total_train_time_s\": 11.738887548446655}", "{\"n\": 1424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.64, \"learn_time_ms\": 9427.286, \"total_train_time_s\": 12.73949909210205}", "{\"n\": 1425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.71, \"learn_time_ms\": 9544.879, \"total_train_time_s\": 11.325023889541626}", "{\"n\": 1426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.71, \"learn_time_ms\": 9415.284, \"total_train_time_s\": 10.168193578720093}", "{\"n\": 1427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.53, \"learn_time_ms\": 9399.177, \"total_train_time_s\": 10.686476230621338}", "{\"n\": 1428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.56, \"learn_time_ms\": 9425.25, \"total_train_time_s\": 10.45805287361145}", "{\"n\": 1429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.77, \"learn_time_ms\": 9332.071, \"total_train_time_s\": 10.797369718551636}", "{\"n\": 1430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.67, \"learn_time_ms\": 9369.187, \"total_train_time_s\": 10.450276374816895}", "{\"n\": 1431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.33, \"learn_time_ms\": 9272.747, \"total_train_time_s\": 10.01186490058899}", "{\"n\": 1432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.22, \"learn_time_ms\": 9460.474, \"total_train_time_s\": 10.520040512084961}", "{\"n\": 1433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.22, \"learn_time_ms\": 9357.809, \"total_train_time_s\": 10.68286919593811}", "{\"n\": 1434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.26, \"learn_time_ms\": 9062.19, \"total_train_time_s\": 9.744424819946289}", "{\"n\": 1435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.21, \"learn_time_ms\": 9062.608, \"total_train_time_s\": 11.330814361572266}", "{\"n\": 1436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.21, \"learn_time_ms\": 9054.426, \"total_train_time_s\": 10.052385091781616}", "{\"n\": 1437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.43, \"learn_time_ms\": 8914.461, \"total_train_time_s\": 9.325997352600098}", "{\"n\": 1438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.82, \"learn_time_ms\": 8964.744, \"total_train_time_s\": 10.928656816482544}", "{\"n\": 1439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.82, \"learn_time_ms\": 8784.637, \"total_train_time_s\": 9.072741508483887}", "{\"n\": 1440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.39, \"learn_time_ms\": 8847.718, \"total_train_time_s\": 11.087714433670044}", "{\"n\": 1441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.39, \"learn_time_ms\": 8771.349, \"total_train_time_s\": 9.201081275939941}", "{\"n\": 1442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.39, \"learn_time_ms\": 8681.206, \"total_train_time_s\": 9.525394439697266}", "{\"n\": 1443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.75, \"learn_time_ms\": 8816.092, \"total_train_time_s\": 12.052985191345215}", "{\"n\": 1444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.65, \"learn_time_ms\": 8865.895, \"total_train_time_s\": 10.183704376220703}", "{\"n\": 1445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.65, \"learn_time_ms\": 8744.493, \"total_train_time_s\": 10.087300300598145}", "{\"n\": 1446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.67, \"learn_time_ms\": 8835.612, \"total_train_time_s\": 11.020866394042969}", "{\"n\": 1447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.08, \"learn_time_ms\": 8860.164, \"total_train_time_s\": 9.576237440109253}", "{\"n\": 1448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.08, \"learn_time_ms\": 8756.989, \"total_train_time_s\": 9.977152585983276}", "{\"n\": 1449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.22, \"learn_time_ms\": 8800.642, \"total_train_time_s\": 9.458988666534424}", "{\"n\": 1450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.73, \"learn_time_ms\": 8668.553, \"total_train_time_s\": 9.747278690338135}", "{\"n\": 1451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.73, \"learn_time_ms\": 8763.335, \"total_train_time_s\": 10.186655759811401}", "{\"n\": 1452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.08, \"learn_time_ms\": 8881.71, \"total_train_time_s\": 10.726586818695068}", "{\"n\": 1453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 8597.041, \"total_train_time_s\": 9.232568502426147}", "{\"n\": 1454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 8704.609, \"total_train_time_s\": 11.321027278900146}", "{\"n\": 1455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.13, \"learn_time_ms\": 8797.241, \"total_train_time_s\": 10.988601207733154}", "{\"n\": 1456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.21, \"learn_time_ms\": 8619.482, \"total_train_time_s\": 9.246752262115479}", "{\"n\": 1457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.21, \"learn_time_ms\": 8516.668, \"total_train_time_s\": 8.527080297470093}", "{\"n\": 1458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.36, \"learn_time_ms\": 8638.455, \"total_train_time_s\": 11.165680170059204}", "{\"n\": 1459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.42, \"learn_time_ms\": 8710.732, \"total_train_time_s\": 10.183587074279785}", "{\"n\": 1460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.22, \"learn_time_ms\": 8819.456, \"total_train_time_s\": 10.875483751296997}", "{\"n\": 1461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.25, \"learn_time_ms\": 8954.133, \"total_train_time_s\": 11.538155555725098}", "{\"n\": 1462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.52, \"learn_time_ms\": 8808.645, \"total_train_time_s\": 9.25241756439209}", "{\"n\": 1463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.2, \"learn_time_ms\": 8713.935, \"total_train_time_s\": 8.243796586990356}", "{\"n\": 1464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.2, \"learn_time_ms\": 8609.935, \"total_train_time_s\": 10.278137683868408}", "{\"n\": 1465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.24, \"learn_time_ms\": 8672.806, \"total_train_time_s\": 11.630876779556274}", "{\"n\": 1466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.42, \"learn_time_ms\": 8750.374, \"total_train_time_s\": 10.029225826263428}", "{\"n\": 1467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.42, \"learn_time_ms\": 8859.13, \"total_train_time_s\": 9.664480209350586}", "{\"n\": 1468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.47, \"learn_time_ms\": 8788.816, \"total_train_time_s\": 10.463386535644531}", "{\"n\": 1469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.05, \"learn_time_ms\": 8884.557, \"total_train_time_s\": 11.182811737060547}", "{\"n\": 1470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.76, \"learn_time_ms\": 8730.775, \"total_train_time_s\": 9.311590671539307}", "{\"n\": 1471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.96, \"learn_time_ms\": 8485.524, \"total_train_time_s\": 9.115771055221558}", "{\"n\": 1472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.12, \"learn_time_ms\": 8535.055, \"total_train_time_s\": 9.781881093978882}", "{\"n\": 1473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.75, \"learn_time_ms\": 8766.403, \"total_train_time_s\": 10.59355902671814}", "{\"n\": 1474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.75, \"learn_time_ms\": 8779.683, \"total_train_time_s\": 10.387943267822266}", "{\"n\": 1475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.83, \"learn_time_ms\": 8643.307, \"total_train_time_s\": 10.25017237663269}", "{\"n\": 1476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.07, \"learn_time_ms\": 8700.588, \"total_train_time_s\": 10.569774866104126}", "{\"n\": 1477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.07, \"learn_time_ms\": 8884.22, \"total_train_time_s\": 11.465198993682861}", "{\"n\": 1478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.9, \"learn_time_ms\": 9121.307, \"total_train_time_s\": 12.840658187866211}", "{\"n\": 1479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.06, \"learn_time_ms\": 9129.211, \"total_train_time_s\": 11.223378419876099}", "{\"n\": 1480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.55, \"learn_time_ms\": 9364.835, \"total_train_time_s\": 11.652820825576782}", "{\"n\": 1481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.55, \"learn_time_ms\": 9458.391, \"total_train_time_s\": 10.014036178588867}", "{\"n\": 1482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.41, \"learn_time_ms\": 9581.668, \"total_train_time_s\": 11.016993761062622}", "{\"n\": 1483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.41, \"learn_time_ms\": 9609.893, \"total_train_time_s\": 10.860985040664673}", "{\"n\": 1484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.17, \"learn_time_ms\": 9578.172, \"total_train_time_s\": 10.066781759262085}", "{\"n\": 1485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.64, \"learn_time_ms\": 9463.785, \"total_train_time_s\": 9.11254620552063}", "{\"n\": 1486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.64, \"learn_time_ms\": 9406.026, \"total_train_time_s\": 9.959315061569214}", "{\"n\": 1487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.36, \"learn_time_ms\": 9139.686, \"total_train_time_s\": 8.783833742141724}", "{\"n\": 1488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3174.79, \"learn_time_ms\": 8996.175, \"total_train_time_s\": 11.424989223480225}", "{\"n\": 1489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.16, \"learn_time_ms\": 8796.209, \"total_train_time_s\": 9.218593120574951}", "{\"n\": 1490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.35, \"learn_time_ms\": 8651.115, \"total_train_time_s\": 10.21118712425232}", "{\"n\": 1491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.55, \"learn_time_ms\": 8654.501, \"total_train_time_s\": 10.046879053115845}", "{\"n\": 1492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.17, \"learn_time_ms\": 8668.886, \"total_train_time_s\": 11.122581243515015}", "{\"n\": 1493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.68, \"learn_time_ms\": 8535.668, \"total_train_time_s\": 9.505213022232056}", "{\"n\": 1494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.64, \"learn_time_ms\": 8463.742, \"total_train_time_s\": 9.340222835540771}", "{\"n\": 1495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.1, \"learn_time_ms\": 8658.243, \"total_train_time_s\": 11.071350812911987}", "{\"n\": 1496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.72, \"learn_time_ms\": 8691.946, \"total_train_time_s\": 10.33704161643982}", "{\"n\": 1497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.09, \"learn_time_ms\": 8917.401, \"total_train_time_s\": 11.047547340393066}", "{\"n\": 1498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.79, \"learn_time_ms\": 8794.3, \"total_train_time_s\": 10.157521486282349}", "{\"n\": 1499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.71, \"learn_time_ms\": 8958.393, \"total_train_time_s\": 10.88609004020691}", "{\"n\": 1500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3174.19, \"learn_time_ms\": 8929.376, \"total_train_time_s\": 9.904850721359253}", "{\"n\": 1501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.05, \"learn_time_ms\": 8921.565, \"total_train_time_s\": 9.973479986190796}", "{\"n\": 1502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.83, \"learn_time_ms\": 8895.382, \"total_train_time_s\": 10.928539514541626}", "{\"n\": 1503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.19, \"learn_time_ms\": 9047.454, \"total_train_time_s\": 11.068278551101685}", "{\"n\": 1504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.73, \"learn_time_ms\": 9177.221, \"total_train_time_s\": 10.6379075050354}", "{\"n\": 1505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.73, \"learn_time_ms\": 9062.42, \"total_train_time_s\": 9.91391134262085}", "{\"n\": 1506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.02, \"learn_time_ms\": 9008.204, \"total_train_time_s\": 9.749950647354126}", "{\"n\": 1507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.28, \"learn_time_ms\": 8885.742, \"total_train_time_s\": 9.844996452331543}", "{\"n\": 1508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.0, \"learn_time_ms\": 9071.154, \"total_train_time_s\": 12.029130697250366}", "{\"n\": 1509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.42, \"learn_time_ms\": 9049.425, \"total_train_time_s\": 10.610785245895386}", "{\"n\": 1510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.87, \"learn_time_ms\": 9067.687, \"total_train_time_s\": 10.0839684009552}", "{\"n\": 1511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.4, \"learn_time_ms\": 9156.886, \"total_train_time_s\": 10.85935926437378}", "{\"n\": 1512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.06, \"learn_time_ms\": 8990.19, \"total_train_time_s\": 9.278583526611328}", "{\"n\": 1513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.17, \"learn_time_ms\": 8921.853, \"total_train_time_s\": 10.400919675827026}", "{\"n\": 1514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.85, \"learn_time_ms\": 8933.428, \"total_train_time_s\": 10.75401759147644}", "{\"n\": 1515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.85, \"learn_time_ms\": 8906.754, \"total_train_time_s\": 9.666660785675049}", "{\"n\": 1516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.8, \"learn_time_ms\": 8972.763, \"total_train_time_s\": 10.469244241714478}", "{\"n\": 1517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.8, \"learn_time_ms\": 9036.378, \"total_train_time_s\": 10.44883418083191}", "{\"n\": 1518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.07, \"learn_time_ms\": 8943.614, \"total_train_time_s\": 11.145974397659302}", "{\"n\": 1519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.98, \"learn_time_ms\": 8900.537, \"total_train_time_s\": 10.249897480010986}", "{\"n\": 1520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.98, \"learn_time_ms\": 8832.774, \"total_train_time_s\": 9.405098676681519}", "{\"n\": 1521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.48, \"learn_time_ms\": 8727.688, \"total_train_time_s\": 9.834874153137207}", "{\"n\": 1522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.2, \"learn_time_ms\": 8947.35, \"total_train_time_s\": 11.370202541351318}", "{\"n\": 1523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.2, \"learn_time_ms\": 8946.851, \"total_train_time_s\": 10.320262670516968}", "{\"n\": 1524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.57, \"learn_time_ms\": 8962.68, \"total_train_time_s\": 10.982633352279663}", "{\"n\": 1525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.05, \"learn_time_ms\": 8970.56, \"total_train_time_s\": 9.720557451248169}", "{\"n\": 1526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.68, \"learn_time_ms\": 8995.331, \"total_train_time_s\": 10.659294366836548}", "{\"n\": 1527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.17, \"learn_time_ms\": 9010.695, \"total_train_time_s\": 10.629709243774414}", "{\"n\": 1528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.06, \"learn_time_ms\": 8790.011, \"total_train_time_s\": 8.89193344116211}", "{\"n\": 1529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.07, \"learn_time_ms\": 8806.238, \"total_train_time_s\": 10.38157868385315}", "{\"n\": 1530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.4, \"learn_time_ms\": 8708.003, \"total_train_time_s\": 8.445662021636963}", "{\"n\": 1531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.61, \"learn_time_ms\": 8654.232, \"total_train_time_s\": 9.301356792449951}", "{\"n\": 1532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.84, \"learn_time_ms\": 8432.964, \"total_train_time_s\": 9.205013036727905}", "{\"n\": 1533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.09, \"learn_time_ms\": 8436.442, \"total_train_time_s\": 10.388369798660278}", "{\"n\": 1534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.51, \"learn_time_ms\": 8425.115, \"total_train_time_s\": 10.828531265258789}", "{\"n\": 1535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.03, \"learn_time_ms\": 8467.201, \"total_train_time_s\": 10.178164720535278}", "{\"n\": 1536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.18, \"learn_time_ms\": 8362.521, \"total_train_time_s\": 9.6707022190094}", "{\"n\": 1537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.18, \"learn_time_ms\": 8235.391, \"total_train_time_s\": 9.378949880599976}", "{\"n\": 1538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.27, \"learn_time_ms\": 8390.022, \"total_train_time_s\": 10.426496982574463}", "{\"n\": 1539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.2, \"learn_time_ms\": 8302.724, \"total_train_time_s\": 9.489075899124146}", "{\"n\": 1540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.2, \"learn_time_ms\": 8449.363, \"total_train_time_s\": 9.901624917984009}", "{\"n\": 1541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.78, \"learn_time_ms\": 8441.47, \"total_train_time_s\": 9.175798177719116}", "{\"n\": 1542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.78, \"learn_time_ms\": 8551.137, \"total_train_time_s\": 10.285690069198608}", "{\"n\": 1543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.76, \"learn_time_ms\": 8382.445, \"total_train_time_s\": 8.688318967819214}", "{\"n\": 1544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.85, \"learn_time_ms\": 8328.932, \"total_train_time_s\": 10.32329249382019}", "{\"n\": 1545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.85, \"learn_time_ms\": 8409.781, \"total_train_time_s\": 10.948642253875732}", "{\"n\": 1546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.33, \"learn_time_ms\": 8546.815, \"total_train_time_s\": 11.050284385681152}", "{\"n\": 1547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.65, \"learn_time_ms\": 8621.188, \"total_train_time_s\": 10.143126249313354}", "{\"n\": 1548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.65, \"learn_time_ms\": 8464.139, \"total_train_time_s\": 8.944197177886963}", "{\"n\": 1549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.24, \"learn_time_ms\": 8436.067, \"total_train_time_s\": 9.263318300247192}", "{\"n\": 1550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.32, \"learn_time_ms\": 8474.652, \"total_train_time_s\": 10.297717094421387}", "{\"n\": 1551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.32, \"learn_time_ms\": 8640.197, \"total_train_time_s\": 10.849820137023926}", "{\"n\": 1552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.32, \"learn_time_ms\": 8648.125, \"total_train_time_s\": 10.365541458129883}", "{\"n\": 1553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3160.19, \"learn_time_ms\": 8883.83, \"total_train_time_s\": 11.113739967346191}", "{\"n\": 1554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.17, \"learn_time_ms\": 8892.606, \"total_train_time_s\": 10.419233083724976}", "{\"n\": 1555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.17, \"learn_time_ms\": 8791.334, \"total_train_time_s\": 9.940080404281616}", "{\"n\": 1556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.54, \"learn_time_ms\": 8750.146, \"total_train_time_s\": 10.582800149917603}", "{\"n\": 1557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.55, \"learn_time_ms\": 8699.826, \"total_train_time_s\": 9.575875759124756}", "{\"n\": 1558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.55, \"learn_time_ms\": 8869.402, \"total_train_time_s\": 10.56205940246582}", "{\"n\": 1559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.31, \"learn_time_ms\": 9001.667, \"total_train_time_s\": 10.55059814453125}", "{\"n\": 1560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.56, \"learn_time_ms\": 9004.28, \"total_train_time_s\": 10.289825439453125}", "{\"n\": 1561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.56, \"learn_time_ms\": 8844.976, \"total_train_time_s\": 9.33462381362915}", "{\"n\": 1562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.07, \"learn_time_ms\": 8858.773, \"total_train_time_s\": 10.545793771743774}", "{\"n\": 1563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.35, \"learn_time_ms\": 8823.348, \"total_train_time_s\": 10.72782301902771}", "{\"n\": 1564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.35, \"learn_time_ms\": 8682.352, \"total_train_time_s\": 8.931641101837158}", "{\"n\": 1565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.31, \"learn_time_ms\": 8676.681, \"total_train_time_s\": 9.881782531738281}", "{\"n\": 1566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.85, \"learn_time_ms\": 8718.613, \"total_train_time_s\": 10.982597589492798}", "{\"n\": 1567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.85, \"learn_time_ms\": 8674.063, \"total_train_time_s\": 9.162237882614136}", "{\"n\": 1568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.68, \"learn_time_ms\": 8833.833, \"total_train_time_s\": 12.167104482650757}", "{\"n\": 1569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.59, \"learn_time_ms\": 8688.951, \"total_train_time_s\": 9.104278564453125}", "{\"n\": 1570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.59, \"learn_time_ms\": 8707.011, \"total_train_time_s\": 10.540674209594727}", "{\"n\": 1571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.68, \"learn_time_ms\": 8869.674, \"total_train_time_s\": 10.890729427337646}", "{\"n\": 1572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.06, \"learn_time_ms\": 8796.066, \"total_train_time_s\": 9.787829160690308}", "{\"n\": 1573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.06, \"learn_time_ms\": 8807.852, \"total_train_time_s\": 10.786664962768555}", "{\"n\": 1574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.56, \"learn_time_ms\": 9038.888, \"total_train_time_s\": 11.228036403656006}", "{\"n\": 1575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.38, \"learn_time_ms\": 9115.221, \"total_train_time_s\": 10.653498411178589}", "{\"n\": 1576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.18, \"learn_time_ms\": 9070.294, \"total_train_time_s\": 10.564996004104614}", "{\"n\": 1577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.18, \"learn_time_ms\": 9183.795, \"total_train_time_s\": 10.254786729812622}", "{\"n\": 1578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.46, \"learn_time_ms\": 8982.784, \"total_train_time_s\": 10.18209433555603}", "{\"n\": 1579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.06, \"learn_time_ms\": 9029.547, \"total_train_time_s\": 9.56967806816101}", "{\"n\": 1580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.06, \"learn_time_ms\": 9014.089, \"total_train_time_s\": 10.346121311187744}", "{\"n\": 1581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.88, \"learn_time_ms\": 8863.799, \"total_train_time_s\": 9.404759407043457}", "{\"n\": 1582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.31, \"learn_time_ms\": 8917.625, \"total_train_time_s\": 10.300908088684082}", "{\"n\": 1583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.31, \"learn_time_ms\": 8814.216, \"total_train_time_s\": 9.790164232254028}", "{\"n\": 1584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.78, \"learn_time_ms\": 8587.539, \"total_train_time_s\": 9.028301239013672}", "{\"n\": 1585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.39, \"learn_time_ms\": 8613.018, \"total_train_time_s\": 10.932146549224854}", "{\"n\": 1586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.53, \"learn_time_ms\": 8731.604, \"total_train_time_s\": 11.751195669174194}", "{\"n\": 1587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.07, \"learn_time_ms\": 8737.455, \"total_train_time_s\": 10.332072496414185}", "{\"n\": 1588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.89, \"learn_time_ms\": 8712.062, \"total_train_time_s\": 9.935157299041748}", "{\"n\": 1589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.33, \"learn_time_ms\": 8783.489, \"total_train_time_s\": 10.287871360778809}", "{\"n\": 1590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.96, \"learn_time_ms\": 8847.344, \"total_train_time_s\": 10.991379499435425}", "{\"n\": 1591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.29, \"learn_time_ms\": 8967.113, \"total_train_time_s\": 10.567994356155396}", "{\"n\": 1592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.3, \"learn_time_ms\": 9056.057, \"total_train_time_s\": 11.257854223251343}", "{\"n\": 1593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.19, \"learn_time_ms\": 9040.402, \"total_train_time_s\": 9.61259651184082}", "{\"n\": 1594, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.36, \"learn_time_ms\": 9110.188, \"total_train_time_s\": 9.686616659164429}", "{\"n\": 1595, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.64, \"learn_time_ms\": 9048.86, \"total_train_time_s\": 10.27479362487793}", "{\"n\": 1596, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.64, \"learn_time_ms\": 8974.879, \"total_train_time_s\": 11.003179788589478}", "{\"n\": 1597, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.18, \"learn_time_ms\": 9053.802, \"total_train_time_s\": 11.168466806411743}", "{\"n\": 1598, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.73, \"learn_time_ms\": 9036.866, \"total_train_time_s\": 9.760718584060669}", "{\"n\": 1599, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.73, \"learn_time_ms\": 8996.404, \"total_train_time_s\": 9.883593320846558}", "{\"n\": 1600, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.69, \"learn_time_ms\": 8840.987, \"total_train_time_s\": 9.449684619903564}", "{\"n\": 1601, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.23, \"learn_time_ms\": 8868.976, \"total_train_time_s\": 10.879888772964478}", "{\"n\": 1602, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.35, \"learn_time_ms\": 8675.727, \"total_train_time_s\": 9.285676002502441}", "{\"n\": 1603, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.35, \"learn_time_ms\": 8781.042, \"total_train_time_s\": 10.688845157623291}", "{\"n\": 1604, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.61, \"learn_time_ms\": 8858.5, \"total_train_time_s\": 10.464229345321655}", "{\"n\": 1605, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.4, \"learn_time_ms\": 8876.335, \"total_train_time_s\": 10.469297647476196}", "{\"n\": 1606, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.57, \"learn_time_ms\": 8820.375, \"total_train_time_s\": 10.4478600025177}", "{\"n\": 1607, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.57, \"learn_time_ms\": 8775.735, \"total_train_time_s\": 10.693511724472046}", "{\"n\": 1608, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.4, \"learn_time_ms\": 8791.35, \"total_train_time_s\": 9.88862681388855}", "{\"n\": 1609, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.9, \"learn_time_ms\": 8832.447, \"total_train_time_s\": 10.267191648483276}", "{\"n\": 1610, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.9, \"learn_time_ms\": 9000.635, \"total_train_time_s\": 11.09701681137085}", "{\"n\": 1611, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.75, \"learn_time_ms\": 8938.264, \"total_train_time_s\": 10.249217748641968}", "{\"n\": 1612, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.6, \"learn_time_ms\": 8944.142, \"total_train_time_s\": 9.352783918380737}", "{\"n\": 1613, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.6, \"learn_time_ms\": 8727.578, \"total_train_time_s\": 8.483977556228638}", "{\"n\": 1614, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.83, \"learn_time_ms\": 8765.35, \"total_train_time_s\": 10.848093509674072}", "{\"n\": 1615, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.92, \"learn_time_ms\": 8773.742, \"total_train_time_s\": 10.56696367263794}", "{\"n\": 1616, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.92, \"learn_time_ms\": 8615.411, \"total_train_time_s\": 8.86508822441101}", "{\"n\": 1617, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.25, \"learn_time_ms\": 8392.229, \"total_train_time_s\": 8.444113969802856}", "{\"n\": 1618, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.87, \"learn_time_ms\": 8442.497, \"total_train_time_s\": 10.381012201309204}", "{\"n\": 1619, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.87, \"learn_time_ms\": 8355.87, \"total_train_time_s\": 9.410486936569214}", "{\"n\": 1620, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.66, \"learn_time_ms\": 8334.635, \"total_train_time_s\": 10.902243852615356}", "{\"n\": 1621, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.69, \"learn_time_ms\": 8391.326, \"total_train_time_s\": 10.776865720748901}", "{\"n\": 1622, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.88, \"learn_time_ms\": 8526.999, \"total_train_time_s\": 10.681652545928955}", "{\"n\": 1623, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.4, \"learn_time_ms\": 8741.356, \"total_train_time_s\": 10.647314310073853}", "{\"n\": 1624, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.31, \"learn_time_ms\": 8713.915, \"total_train_time_s\": 10.527412414550781}", "{\"n\": 1625, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.58, \"learn_time_ms\": 8590.233, \"total_train_time_s\": 9.29608941078186}", "{\"n\": 1626, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.91, \"learn_time_ms\": 8623.066, \"total_train_time_s\": 9.224212408065796}", "{\"n\": 1627, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3161.25, \"learn_time_ms\": 8858.053, \"total_train_time_s\": 10.802210807800293}", "{\"n\": 1628, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.76, \"learn_time_ms\": 8899.644, \"total_train_time_s\": 10.82069730758667}", "{\"n\": 1629, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.76, \"learn_time_ms\": 8947.028, \"total_train_time_s\": 9.888953447341919}", "{\"n\": 1630, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.62, \"learn_time_ms\": 8680.486, \"total_train_time_s\": 8.224430084228516}", "{\"n\": 1631, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.22, \"learn_time_ms\": 8635.959, \"total_train_time_s\": 10.34376573562622}", "{\"n\": 1632, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.22, \"learn_time_ms\": 8663.55, \"total_train_time_s\": 10.957181453704834}", "{\"n\": 1633, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.79, \"learn_time_ms\": 8656.496, \"total_train_time_s\": 10.644559621810913}", "{\"n\": 1634, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.53, \"learn_time_ms\": 8569.349, \"total_train_time_s\": 9.677720069885254}", "{\"n\": 1635, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.53, \"learn_time_ms\": 8671.784, \"total_train_time_s\": 10.366169691085815}", "{\"n\": 1636, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.0, \"learn_time_ms\": 8753.235, \"total_train_time_s\": 10.056520700454712}", "{\"n\": 1637, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.94, \"learn_time_ms\": 8564.578, \"total_train_time_s\": 8.897448539733887}", "{\"n\": 1638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.98, \"learn_time_ms\": 8500.902, \"total_train_time_s\": 10.196213722229004}", "{\"n\": 1639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.93, \"learn_time_ms\": 8561.826, \"total_train_time_s\": 10.478082418441772}", "{\"n\": 1640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.41, \"learn_time_ms\": 8794.238, \"total_train_time_s\": 10.582931995391846}", "{\"n\": 1641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.17, \"learn_time_ms\": 8927.88, \"total_train_time_s\": 11.755949258804321}", "{\"n\": 1642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.94, \"learn_time_ms\": 8936.865, \"total_train_time_s\": 11.092700481414795}", "{\"n\": 1643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.68, \"learn_time_ms\": 8815.176, \"total_train_time_s\": 9.393246173858643}", "{\"n\": 1644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.68, \"learn_time_ms\": 8820.202, \"total_train_time_s\": 9.790869951248169}", "{\"n\": 1645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3147.3, \"learn_time_ms\": 8776.222, \"total_train_time_s\": 9.872825622558594}", "{\"n\": 1646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.11, \"learn_time_ms\": 8816.548, \"total_train_time_s\": 10.433648109436035}", "{\"n\": 1647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.11, \"learn_time_ms\": 8953.238, \"total_train_time_s\": 10.27073049545288}", "{\"n\": 1648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.79, \"learn_time_ms\": 8849.348, \"total_train_time_s\": 9.118630409240723}", "{\"n\": 1649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3147.86, \"learn_time_ms\": 8952.881, \"total_train_time_s\": 11.595967292785645}", "{\"n\": 1650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.03, \"learn_time_ms\": 8874.006, \"total_train_time_s\": 9.773599863052368}", "{\"n\": 1651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.47, \"learn_time_ms\": 8594.464, \"total_train_time_s\": 8.87593936920166}", "{\"n\": 1652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.4, \"learn_time_ms\": 8426.924, \"total_train_time_s\": 9.38775634765625}", "{\"n\": 1653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.76, \"learn_time_ms\": 8558.304, \"total_train_time_s\": 10.690948247909546}", "{\"n\": 1654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.76, \"learn_time_ms\": 8708.409, \"total_train_time_s\": 11.214895248413086}", "{\"n\": 1655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.85, \"learn_time_ms\": 8648.208, \"total_train_time_s\": 9.347000122070312}", "{\"n\": 1656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.13, \"learn_time_ms\": 8545.621, \"total_train_time_s\": 9.415690422058105}", "{\"n\": 1657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.13, \"learn_time_ms\": 8514.805, \"total_train_time_s\": 9.94968295097351}", "{\"n\": 1658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.65, \"learn_time_ms\": 8556.152, \"total_train_time_s\": 9.538711547851562}", "{\"n\": 1659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.08, \"learn_time_ms\": 8501.771, \"total_train_time_s\": 11.004327774047852}", "{\"n\": 1660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.08, \"learn_time_ms\": 8512.271, \"total_train_time_s\": 9.911772012710571}", "{\"n\": 1661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.48, \"learn_time_ms\": 8713.202, \"total_train_time_s\": 10.916942596435547}", "{\"n\": 1662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.88, \"learn_time_ms\": 8675.024, \"total_train_time_s\": 9.033712148666382}", "{\"n\": 1663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.88, \"learn_time_ms\": 8598.857, \"total_train_time_s\": 9.908411502838135}", "{\"n\": 1664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.85, \"learn_time_ms\": 8417.535, \"total_train_time_s\": 9.4518723487854}", "{\"n\": 1665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.41, \"learn_time_ms\": 8550.492, \"total_train_time_s\": 10.63864803314209}", "{\"n\": 1666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.41, \"learn_time_ms\": 8670.314, \"total_train_time_s\": 10.570077657699585}", "{\"n\": 1667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3140.37, \"learn_time_ms\": 8860.559, \"total_train_time_s\": 11.927570104598999}", "{\"n\": 1668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.45, \"learn_time_ms\": 8756.919, \"total_train_time_s\": 8.512025117874146}", "{\"n\": 1669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.45, \"learn_time_ms\": 8598.326, \"total_train_time_s\": 9.47086787223816}", "{\"n\": 1670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.94, \"learn_time_ms\": 8598.243, \"total_train_time_s\": 9.844610929489136}", "{\"n\": 1671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.36, \"learn_time_ms\": 8494.857, \"total_train_time_s\": 9.878920078277588}", "{\"n\": 1672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.29, \"learn_time_ms\": 8640.82, \"total_train_time_s\": 10.483294248580933}", "{\"n\": 1673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.72, \"learn_time_ms\": 8760.526, \"total_train_time_s\": 11.14504075050354}", "{\"n\": 1674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.29, \"learn_time_ms\": 8770.006, \"total_train_time_s\": 9.573866128921509}", "{\"n\": 1675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.7, \"learn_time_ms\": 8717.755, \"total_train_time_s\": 10.139629125595093}", "{\"n\": 1676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.25, \"learn_time_ms\": 8699.563, \"total_train_time_s\": 10.405203104019165}", "{\"n\": 1677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.58, \"learn_time_ms\": 8517.696, \"total_train_time_s\": 10.027990102767944}", "{\"n\": 1678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.24, \"learn_time_ms\": 8704.663, \"total_train_time_s\": 10.360527515411377}", "{\"n\": 1679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.99, \"learn_time_ms\": 8705.305, \"total_train_time_s\": 9.407994508743286}", "{\"n\": 1680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.68, \"learn_time_ms\": 8746.745, \"total_train_time_s\": 10.280057907104492}", "{\"n\": 1681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.92, \"learn_time_ms\": 8808.816, \"total_train_time_s\": 10.477357864379883}", "{\"n\": 1682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.12, \"learn_time_ms\": 8833.577, \"total_train_time_s\": 10.71175479888916}", "{\"n\": 1683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.7, \"learn_time_ms\": 8696.427, \"total_train_time_s\": 9.793805837631226}", "{\"n\": 1684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.59, \"learn_time_ms\": 8678.192, \"total_train_time_s\": 9.380120754241943}", "{\"n\": 1685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.89, \"learn_time_ms\": 8783.738, \"total_train_time_s\": 11.171254634857178}", "{\"n\": 1686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.26, \"learn_time_ms\": 8811.173, \"total_train_time_s\": 10.690754175186157}", "{\"n\": 1687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.52, \"learn_time_ms\": 8655.487, \"total_train_time_s\": 8.531822204589844}", "{\"n\": 1688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.06, \"learn_time_ms\": 8766.758, \"total_train_time_s\": 11.538203239440918}", "{\"n\": 1689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.65, \"learn_time_ms\": 8786.136, \"total_train_time_s\": 9.578451156616211}", "{\"n\": 1690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.09, \"learn_time_ms\": 8714.254, \"total_train_time_s\": 9.552989721298218}", "{\"n\": 1691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.9, \"learn_time_ms\": 8600.211, \"total_train_time_s\": 9.320560932159424}", "{\"n\": 1692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.9, \"learn_time_ms\": 8547.154, \"total_train_time_s\": 10.238446712493896}", "{\"n\": 1693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.83, \"learn_time_ms\": 8535.167, \"total_train_time_s\": 9.609901189804077}", "{\"n\": 1694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.31, \"learn_time_ms\": 8670.359, \"total_train_time_s\": 10.675302982330322}", "{\"n\": 1695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.31, \"learn_time_ms\": 8669.079, \"total_train_time_s\": 11.269964218139648}", "{\"n\": 1696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.59, \"learn_time_ms\": 8526.518, \"total_train_time_s\": 9.229390144348145}", "{\"n\": 1697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.59, \"learn_time_ms\": 8646.166, \"total_train_time_s\": 9.701042175292969}", "{\"n\": 1698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.18, \"learn_time_ms\": 8588.428, \"total_train_time_s\": 10.878284931182861}", "{\"n\": 1699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.34, \"learn_time_ms\": 8759.445, \"total_train_time_s\": 11.291606903076172}", "{\"n\": 1700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.34, \"learn_time_ms\": 8747.787, \"total_train_time_s\": 9.488940238952637}", "{\"n\": 1701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.73, \"learn_time_ms\": 8842.285, \"total_train_time_s\": 10.35078501701355}", "{\"n\": 1702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.63, \"learn_time_ms\": 8728.77, \"total_train_time_s\": 9.051946640014648}", "{\"n\": 1703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.85, \"learn_time_ms\": 8695.425, \"total_train_time_s\": 9.28165578842163}", "{\"n\": 1704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.26, \"learn_time_ms\": 8657.478, \"total_train_time_s\": 10.320911407470703}", "{\"n\": 1705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.26, \"learn_time_ms\": 8571.183, \"total_train_time_s\": 10.30737853050232}", "{\"n\": 1706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.56, \"learn_time_ms\": 8729.3, \"total_train_time_s\": 10.798115253448486}", "{\"n\": 1707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.87, \"learn_time_ms\": 8740.446, \"total_train_time_s\": 9.837374448776245}", "{\"n\": 1708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.87, \"learn_time_ms\": 8611.692, \"total_train_time_s\": 9.613037109375}", "{\"n\": 1709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.48, \"learn_time_ms\": 8565.902, \"total_train_time_s\": 10.838021516799927}", "{\"n\": 1710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.72, \"learn_time_ms\": 8801.108, \"total_train_time_s\": 11.798023462295532}", "{\"n\": 1711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.72, \"learn_time_ms\": 8745.532, \"total_train_time_s\": 9.711337804794312}", "{\"n\": 1712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.54, \"learn_time_ms\": 8982.303, \"total_train_time_s\": 11.428215265274048}", "{\"n\": 1713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.54, \"learn_time_ms\": 9042.282, \"total_train_time_s\": 9.916263341903687}", "{\"n\": 1714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.76, \"learn_time_ms\": 8970.604, \"total_train_time_s\": 9.650937795639038}", "{\"n\": 1715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.3, \"learn_time_ms\": 9009.396, \"total_train_time_s\": 10.666154146194458}", "{\"n\": 1716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.9, \"learn_time_ms\": 8848.002, \"total_train_time_s\": 9.225947618484497}", "{\"n\": 1717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.34, \"learn_time_ms\": 8857.528, \"total_train_time_s\": 9.943473100662231}", "{\"n\": 1718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.61, \"learn_time_ms\": 8913.867, \"total_train_time_s\": 10.202036142349243}", "{\"n\": 1719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.18, \"learn_time_ms\": 8738.579, \"total_train_time_s\": 9.129679918289185}", "{\"n\": 1720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.5, \"learn_time_ms\": 8514.659, \"total_train_time_s\": 9.578722476959229}", "{\"n\": 1721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.26, \"learn_time_ms\": 8535.682, \"total_train_time_s\": 10.00670599937439}", "{\"n\": 1722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.26, \"learn_time_ms\": 8356.362, \"total_train_time_s\": 9.625308513641357}", "{\"n\": 1723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.63, \"learn_time_ms\": 8295.626, \"total_train_time_s\": 9.26995325088501}", "{\"n\": 1724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.52, \"learn_time_ms\": 8307.338, \"total_train_time_s\": 9.759661436080933}", "{\"n\": 1725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.52, \"learn_time_ms\": 8351.654, \"total_train_time_s\": 11.098961353302002}", "{\"n\": 1726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.6, \"learn_time_ms\": 8397.911, \"total_train_time_s\": 9.678673028945923}", "{\"n\": 1727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.61, \"learn_time_ms\": 8406.224, \"total_train_time_s\": 10.017520904541016}", "{\"n\": 1728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.61, \"learn_time_ms\": 8443.562, \"total_train_time_s\": 10.620391607284546}", "{\"n\": 1729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.16, \"learn_time_ms\": 8462.595, \"total_train_time_s\": 9.295137882232666}", "{\"n\": 1730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.08, \"learn_time_ms\": 8495.853, \"total_train_time_s\": 9.921164274215698}", "{\"n\": 1731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.08, \"learn_time_ms\": 8637.163, \"total_train_time_s\": 11.36984896659851}", "{\"n\": 1732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.76, \"learn_time_ms\": 8603.008, \"total_train_time_s\": 9.25791072845459}", "{\"n\": 1733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.36, \"learn_time_ms\": 8608.764, \"total_train_time_s\": 9.327308654785156}", "{\"n\": 1734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.26, \"learn_time_ms\": 8663.094, \"total_train_time_s\": 10.309226512908936}", "{\"n\": 1735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.63, \"learn_time_ms\": 8569.614, \"total_train_time_s\": 10.235690832138062}", "{\"n\": 1736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.0, \"learn_time_ms\": 8540.954, \"total_train_time_s\": 9.375855207443237}", "{\"n\": 1737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.0, \"learn_time_ms\": 8675.963, \"total_train_time_s\": 11.29265308380127}", "{\"n\": 1738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.0, \"learn_time_ms\": 8602.534, \"total_train_time_s\": 9.845933437347412}", "{\"n\": 1739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.49, \"learn_time_ms\": 8631.827, \"total_train_time_s\": 9.612915754318237}", "{\"n\": 1740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.94, \"learn_time_ms\": 8401.822, \"total_train_time_s\": 7.6347434520721436}", "{\"n\": 1741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.94, \"learn_time_ms\": 8357.588, \"total_train_time_s\": 10.940661430358887}", "{\"n\": 1742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.62, \"learn_time_ms\": 8382.663, \"total_train_time_s\": 9.577173471450806}", "{\"n\": 1743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.66, \"learn_time_ms\": 8591.43, \"total_train_time_s\": 11.45928692817688}", "{\"n\": 1744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.66, \"learn_time_ms\": 8666.18, \"total_train_time_s\": 11.03370213508606}", "{\"n\": 1745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.75, \"learn_time_ms\": 8614.676, \"total_train_time_s\": 9.631346940994263}", "{\"n\": 1746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.84, \"learn_time_ms\": 8879.512, \"total_train_time_s\": 12.051458835601807}", "{\"n\": 1747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.84, \"learn_time_ms\": 8747.868, \"total_train_time_s\": 10.006025791168213}", "{\"n\": 1748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.37, \"learn_time_ms\": 8812.505, \"total_train_time_s\": 10.504071474075317}", "{\"n\": 1749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.87, \"learn_time_ms\": 8889.294, \"total_train_time_s\": 10.393086433410645}", "{\"n\": 1750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.87, \"learn_time_ms\": 9033.616, \"total_train_time_s\": 9.051846981048584}", "{\"n\": 1751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.72, \"learn_time_ms\": 9053.643, \"total_train_time_s\": 11.139213800430298}", "{\"n\": 1752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.59, \"learn_time_ms\": 9250.778, \"total_train_time_s\": 11.475838899612427}", "{\"n\": 1753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.59, \"learn_time_ms\": 9201.041, \"total_train_time_s\": 10.934128284454346}", "{\"n\": 1754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.11, \"learn_time_ms\": 9039.678, \"total_train_time_s\": 9.416666984558105}", "{\"n\": 1755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.82, \"learn_time_ms\": 9108.098, \"total_train_time_s\": 10.436479091644287}", "{\"n\": 1756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.82, \"learn_time_ms\": 9084.585, \"total_train_time_s\": 11.812237739562988}", "{\"n\": 1757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.14, \"learn_time_ms\": 9246.047, \"total_train_time_s\": 11.61307692527771}", "{\"n\": 1758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.5, \"learn_time_ms\": 9199.988, \"total_train_time_s\": 9.985619306564331}", "{\"n\": 1759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.5, \"learn_time_ms\": 9166.476, \"total_train_time_s\": 10.009265184402466}", "{\"n\": 1760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.5, \"learn_time_ms\": 9285.81, \"total_train_time_s\": 10.207797288894653}", "{\"n\": 1761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.96, \"learn_time_ms\": 9195.5, \"total_train_time_s\": 10.221536636352539}", "{\"n\": 1762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.96, \"learn_time_ms\": 8928.153, \"total_train_time_s\": 8.817074060440063}", "{\"n\": 1763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.12, \"learn_time_ms\": 8855.239, \"total_train_time_s\": 10.240051507949829}", "{\"n\": 1764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.74, \"learn_time_ms\": 9040.502, \"total_train_time_s\": 11.261740922927856}", "{\"n\": 1765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.74, \"learn_time_ms\": 8961.545, \"total_train_time_s\": 9.506767511367798}", "{\"n\": 1766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.74, \"learn_time_ms\": 8845.125, \"total_train_time_s\": 10.717000961303711}", "{\"n\": 1767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.44, \"learn_time_ms\": 8699.389, \"total_train_time_s\": 10.20564079284668}", "{\"n\": 1768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.07, \"learn_time_ms\": 8571.931, \"total_train_time_s\": 8.728541851043701}", "{\"n\": 1769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.07, \"learn_time_ms\": 8659.851, \"total_train_time_s\": 10.875118732452393}", "{\"n\": 1770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.61, \"learn_time_ms\": 8658.528, \"total_train_time_s\": 10.191494226455688}", "{\"n\": 1771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.51, \"learn_time_ms\": 8700.693, \"total_train_time_s\": 10.657742261886597}", "{\"n\": 1772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.51, \"learn_time_ms\": 8798.583, \"total_train_time_s\": 9.804938554763794}", "{\"n\": 1773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.89, \"learn_time_ms\": 8793.22, \"total_train_time_s\": 10.16129207611084}", "{\"n\": 1774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.48, \"learn_time_ms\": 8699.318, \"total_train_time_s\": 10.30336880683899}", "{\"n\": 1775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.48, \"learn_time_ms\": 8778.545, \"total_train_time_s\": 10.350924015045166}", "{\"n\": 1776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.77, \"learn_time_ms\": 8656.755, \"total_train_time_s\": 9.476064682006836}", "{\"n\": 1777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.42, \"learn_time_ms\": 8503.278, \"total_train_time_s\": 8.662343978881836}", "{\"n\": 1778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.42, \"learn_time_ms\": 8660.591, \"total_train_time_s\": 10.314651727676392}", "{\"n\": 1779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.49, \"learn_time_ms\": 8632.883, \"total_train_time_s\": 10.661121129989624}", "{\"n\": 1780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.84, \"learn_time_ms\": 8824.147, \"total_train_time_s\": 12.159907102584839}", "{\"n\": 1781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.84, \"learn_time_ms\": 8634.154, \"total_train_time_s\": 8.75152587890625}", "{\"n\": 1782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.03, \"learn_time_ms\": 8654.259, \"total_train_time_s\": 10.051666021347046}", "{\"n\": 1783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.69, \"learn_time_ms\": 8533.349, \"total_train_time_s\": 9.01488971710205}", "{\"n\": 1784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.66, \"learn_time_ms\": 8662.459, \"total_train_time_s\": 11.655774593353271}", "{\"n\": 1785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.66, \"learn_time_ms\": 8579.552, \"total_train_time_s\": 9.568583488464355}", "{\"n\": 1786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.17, \"learn_time_ms\": 8589.943, \"total_train_time_s\": 9.532845973968506}", "{\"n\": 1787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.73, \"learn_time_ms\": 8784.136, \"total_train_time_s\": 10.619117021560669}", "{\"n\": 1788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.73, \"learn_time_ms\": 8793.786, \"total_train_time_s\": 10.420596361160278}", "{\"n\": 1789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3155.9, \"learn_time_ms\": 8821.517, \"total_train_time_s\": 10.851128816604614}", "{\"n\": 1790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.51, \"learn_time_ms\": 8748.706, \"total_train_time_s\": 11.451381921768188}", "{\"n\": 1791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.51, \"learn_time_ms\": 8812.418, \"total_train_time_s\": 9.393702983856201}", "{\"n\": 1792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.77, \"learn_time_ms\": 8852.598, \"total_train_time_s\": 10.445760488510132}", "{\"n\": 1793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.81, \"learn_time_ms\": 9092.442, \"total_train_time_s\": 11.372284173965454}", "{\"n\": 1794, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3143.81, \"learn_time_ms\": 8867.067, \"total_train_time_s\": 9.33772325515747}", "{\"n\": 1795, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.93, \"learn_time_ms\": 8546.48, \"total_train_time_s\": 6.352383613586426}", "{\"n\": 1796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.63, \"learn_time_ms\": 8228.44, \"total_train_time_s\": 6.491154193878174}", "{\"n\": 1797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.63, \"learn_time_ms\": 8081.052, \"total_train_time_s\": 9.292529821395874}", "{\"n\": 1798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.63, \"learn_time_ms\": 8026.097, \"total_train_time_s\": 9.866997957229614}", "{\"n\": 1799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.17, \"learn_time_ms\": 7883.595, \"total_train_time_s\": 9.54513931274414}", "{\"n\": 1800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.17, \"learn_time_ms\": 7781.486, \"total_train_time_s\": 10.391277313232422}", "{\"n\": 1801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.17, \"learn_time_ms\": 7905.325, \"total_train_time_s\": 10.619470119476318}", "{\"n\": 1802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.48, \"learn_time_ms\": 7834.555, \"total_train_time_s\": 9.760910749435425}", "{\"n\": 1803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.48, \"learn_time_ms\": 7778.284, \"total_train_time_s\": 10.801830530166626}", "{\"n\": 1804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.48, \"learn_time_ms\": 7662.754, \"total_train_time_s\": 8.181886196136475}", "{\"n\": 1805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.76, \"learn_time_ms\": 8205.133, \"total_train_time_s\": 11.752973794937134}", "{\"n\": 1806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.88, \"learn_time_ms\": 8582.639, \"total_train_time_s\": 10.112833976745605}", "{\"n\": 1807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.88, \"learn_time_ms\": 8762.699, \"total_train_time_s\": 10.912471055984497}", "{\"n\": 1808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3162.76, \"learn_time_ms\": 8760.293, \"total_train_time_s\": 9.837661743164062}", "{\"n\": 1809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.19, \"learn_time_ms\": 8745.265, \"total_train_time_s\": 9.339290857315063}", "{\"n\": 1810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.19, \"learn_time_ms\": 8756.062, \"total_train_time_s\": 10.499505996704102}", "{\"n\": 1811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3164.38, \"learn_time_ms\": 8683.24, \"total_train_time_s\": 9.915322542190552}", "{\"n\": 1812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3163.46, \"learn_time_ms\": 8778.157, \"total_train_time_s\": 10.668691158294678}", "{\"n\": 1813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.26, \"learn_time_ms\": 8580.001, \"total_train_time_s\": 8.7886803150177}", "{\"n\": 1814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.78, \"learn_time_ms\": 8662.579, \"total_train_time_s\": 9.01460862159729}", "{\"n\": 1815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.78, \"learn_time_ms\": 8430.647, \"total_train_time_s\": 9.410152196884155}", "{\"n\": 1816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.13, \"learn_time_ms\": 8458.941, \"total_train_time_s\": 10.423786401748657}", "{\"n\": 1817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.13, \"learn_time_ms\": 8337.349, \"total_train_time_s\": 9.674824237823486}", "{\"n\": 1818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3173.5, \"learn_time_ms\": 8324.644, \"total_train_time_s\": 9.664762496948242}", "{\"n\": 1819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.17, \"learn_time_ms\": 8526.751, \"total_train_time_s\": 11.38425064086914}", "{\"n\": 1820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.17, \"learn_time_ms\": 8404.323, \"total_train_time_s\": 9.26478385925293}", "{\"n\": 1821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.73, \"learn_time_ms\": 8388.528, \"total_train_time_s\": 9.730215311050415}", "{\"n\": 1822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.3, \"learn_time_ms\": 8367.411, \"total_train_time_s\": 10.447372674942017}", "{\"n\": 1823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.3, \"learn_time_ms\": 8583.772, \"total_train_time_s\": 10.954122543334961}", "{\"n\": 1824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.52, \"learn_time_ms\": 8745.074, \"total_train_time_s\": 10.620457172393799}", "{\"n\": 1825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.17, \"learn_time_ms\": 8729.984, \"total_train_time_s\": 9.22673511505127}", "{\"n\": 1826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.17, \"learn_time_ms\": 8796.236, \"total_train_time_s\": 11.045287370681763}", "{\"n\": 1827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.16, \"learn_time_ms\": 8695.311, \"total_train_time_s\": 8.643103122711182}", "{\"n\": 1828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.67, \"learn_time_ms\": 8873.124, \"total_train_time_s\": 11.455620527267456}", "{\"n\": 1829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.67, \"learn_time_ms\": 8857.554, \"total_train_time_s\": 11.191483497619629}", "{\"n\": 1830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.82, \"learn_time_ms\": 8834.955, \"total_train_time_s\": 9.03612208366394}", "{\"n\": 1831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.96, \"learn_time_ms\": 9057.003, \"total_train_time_s\": 11.958707809448242}", "{\"n\": 1832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.96, \"learn_time_ms\": 9165.484, \"total_train_time_s\": 11.524928569793701}", "{\"n\": 1833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.71, \"learn_time_ms\": 9170.316, \"total_train_time_s\": 10.989834785461426}", "{\"n\": 1834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.93, \"learn_time_ms\": 9108.993, \"total_train_time_s\": 10.019404649734497}", "{\"n\": 1835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.93, \"learn_time_ms\": 9274.216, \"total_train_time_s\": 10.928101539611816}", "{\"n\": 1836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.78, \"learn_time_ms\": 9176.901, \"total_train_time_s\": 10.103416442871094}", "{\"n\": 1837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.27, \"learn_time_ms\": 9381.301, \"total_train_time_s\": 10.748291730880737}", "{\"n\": 1838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.07, \"learn_time_ms\": 9124.239, \"total_train_time_s\": 8.894615888595581}", "{\"n\": 1839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.07, \"learn_time_ms\": 8887.514, \"total_train_time_s\": 8.785099506378174}", "{\"n\": 1840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.87, \"learn_time_ms\": 8893.03, \"total_train_time_s\": 9.107911109924316}", "{\"n\": 1841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.74, \"learn_time_ms\": 8742.255, \"total_train_time_s\": 10.479134321212769}", "{\"n\": 1842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.74, \"learn_time_ms\": 8557.265, \"total_train_time_s\": 9.62804365158081}", "{\"n\": 1843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.32, \"learn_time_ms\": 8583.367, \"total_train_time_s\": 11.271897077560425}", "{\"n\": 1844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.74, \"learn_time_ms\": 8708.325, \"total_train_time_s\": 11.295129537582397}", "{\"n\": 1845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.74, \"learn_time_ms\": 8609.713, \"total_train_time_s\": 9.929583549499512}", "{\"n\": 1846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.69, \"learn_time_ms\": 8757.155, \"total_train_time_s\": 11.618999004364014}", "{\"n\": 1847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.56, \"learn_time_ms\": 8774.204, \"total_train_time_s\": 10.923190116882324}", "{\"n\": 1848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.56, \"learn_time_ms\": 8996.744, \"total_train_time_s\": 11.169343948364258}", "{\"n\": 1849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.56, \"learn_time_ms\": 9110.334, \"total_train_time_s\": 9.990115404129028}", "{\"n\": 1850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 9161.16, \"total_train_time_s\": 9.660253524780273}", "{\"n\": 1851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 9152.751, \"total_train_time_s\": 10.400382041931152}", "{\"n\": 1852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 9274.169, \"total_train_time_s\": 10.887793779373169}", "{\"n\": 1853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.7, \"learn_time_ms\": 9178.496, \"total_train_time_s\": 10.323298454284668}", "{\"n\": 1854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.7, \"learn_time_ms\": 8991.394, \"total_train_time_s\": 9.35310435295105}", "{\"n\": 1855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.7, \"learn_time_ms\": 8993.118, \"total_train_time_s\": 9.94136118888855}", "{\"n\": 1856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.01, \"learn_time_ms\": 8839.503, \"total_train_time_s\": 10.068432569503784}", "{\"n\": 1857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.55, \"learn_time_ms\": 8701.562, \"total_train_time_s\": 9.50029993057251}", "{\"n\": 1858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.55, \"learn_time_ms\": 8735.273, \"total_train_time_s\": 11.44761037826538}", "{\"n\": 1859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.81, \"learn_time_ms\": 8690.787, \"total_train_time_s\": 9.487138748168945}", "{\"n\": 1860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.39, \"learn_time_ms\": 8749.55, \"total_train_time_s\": 10.167314052581787}", "{\"n\": 1861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.39, \"learn_time_ms\": 8798.322, \"total_train_time_s\": 10.8467378616333}", "{\"n\": 1862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.75, \"learn_time_ms\": 8860.005, \"total_train_time_s\": 11.579920291900635}", "{\"n\": 1863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.24, \"learn_time_ms\": 8832.08, \"total_train_time_s\": 10.087995529174805}", "{\"n\": 1864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.24, \"learn_time_ms\": 9006.66, \"total_train_time_s\": 11.15015983581543}", "{\"n\": 1865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.09, \"learn_time_ms\": 8968.762, \"total_train_time_s\": 9.616824626922607}", "{\"n\": 1866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.09, \"learn_time_ms\": 9018.618, \"total_train_time_s\": 10.554498672485352}", "{\"n\": 1867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.17, \"learn_time_ms\": 9092.661, \"total_train_time_s\": 10.24817967414856}", "{\"n\": 1868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.06, \"learn_time_ms\": 8894.302, \"total_train_time_s\": 9.5095853805542}", "{\"n\": 1869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.63, \"learn_time_ms\": 8975.626, \"total_train_time_s\": 10.341548204421997}", "{\"n\": 1870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.69, \"learn_time_ms\": 9023.11, \"total_train_time_s\": 10.628029346466064}", "{\"n\": 1871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.3, \"learn_time_ms\": 8933.023, \"total_train_time_s\": 9.91498064994812}", "{\"n\": 1872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.57, \"learn_time_ms\": 8849.644, \"total_train_time_s\": 10.648037910461426}", "{\"n\": 1873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.91, \"learn_time_ms\": 8836.749, \"total_train_time_s\": 9.914050340652466}", "{\"n\": 1874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.96, \"learn_time_ms\": 8840.396, \"total_train_time_s\": 11.172992944717407}", "{\"n\": 1875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.49, \"learn_time_ms\": 8959.35, \"total_train_time_s\": 10.79505205154419}", "{\"n\": 1876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.93, \"learn_time_ms\": 8959.709, \"total_train_time_s\": 10.569762468338013}", "{\"n\": 1877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.93, \"learn_time_ms\": 8861.26, \"total_train_time_s\": 9.267566680908203}", "{\"n\": 1878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.84, \"learn_time_ms\": 8937.091, \"total_train_time_s\": 10.240333080291748}", "{\"n\": 1879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.59, \"learn_time_ms\": 8999.426, \"total_train_time_s\": 10.966056108474731}", "{\"n\": 1880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.59, \"learn_time_ms\": 9010.261, \"total_train_time_s\": 10.76649785041809}", "{\"n\": 1881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.14, \"learn_time_ms\": 9150.251, \"total_train_time_s\": 11.369930505752563}", "{\"n\": 1882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.97, \"learn_time_ms\": 9070.659, \"total_train_time_s\": 9.87561845779419}", "{\"n\": 1883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.97, \"learn_time_ms\": 9109.073, \"total_train_time_s\": 10.301954746246338}", "{\"n\": 1884, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.22, \"learn_time_ms\": 9062.387, \"total_train_time_s\": 10.722025394439697}", "{\"n\": 1885, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.61, \"learn_time_ms\": 9106.402, \"total_train_time_s\": 11.203909635543823}", "{\"n\": 1886, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.61, \"learn_time_ms\": 9110.363, \"total_train_time_s\": 10.612851619720459}", "{\"n\": 1887, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.64, \"learn_time_ms\": 9240.167, \"total_train_time_s\": 10.612749338150024}", "{\"n\": 1888, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.89, \"learn_time_ms\": 9192.989, \"total_train_time_s\": 9.80573296546936}", "{\"n\": 1889, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.89, \"learn_time_ms\": 9119.002, \"total_train_time_s\": 10.198871612548828}", "{\"n\": 1890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.5, \"learn_time_ms\": 8974.527, \"total_train_time_s\": 9.328906536102295}", "{\"n\": 1891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.73, \"learn_time_ms\": 8872.546, \"total_train_time_s\": 10.34161925315857}", "{\"n\": 1892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.73, \"learn_time_ms\": 8959.295, \"total_train_time_s\": 10.737333059310913}", "{\"n\": 1893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.42, \"learn_time_ms\": 8893.423, \"total_train_time_s\": 9.606411933898926}", "{\"n\": 1894, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.33, \"learn_time_ms\": 8828.371, \"total_train_time_s\": 10.032321691513062}", "{\"n\": 1895, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.33, \"learn_time_ms\": 8638.254, \"total_train_time_s\": 9.281105995178223}", "{\"n\": 1896, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.32, \"learn_time_ms\": 8543.335, \"total_train_time_s\": 9.614187240600586}", "{\"n\": 1897, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.23, \"learn_time_ms\": 8408.957, \"total_train_time_s\": 9.211745023727417}", "{\"n\": 1898, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.23, \"learn_time_ms\": 8540.386, \"total_train_time_s\": 11.09140658378601}", "{\"n\": 1899, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.23, \"learn_time_ms\": 8688.23, \"total_train_time_s\": 11.680943965911865}", "{\"n\": 1900, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3153.47, \"learn_time_ms\": 8794.658, \"total_train_time_s\": 10.412958860397339}", "{\"n\": 1901, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3151.79, \"learn_time_ms\": 8808.242, \"total_train_time_s\": 10.474145412445068}", "{\"n\": 1902, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3151.79, \"learn_time_ms\": 8830.926, \"total_train_time_s\": 10.986029386520386}", "{\"n\": 1903, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3150.38, \"learn_time_ms\": 8722.517, \"total_train_time_s\": 8.580126523971558}", "{\"n\": 1904, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3150.38, \"learn_time_ms\": 8634.726, \"total_train_time_s\": 9.203029155731201}", "{\"n\": 1905, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3150.38, \"learn_time_ms\": 8638.936, \"total_train_time_s\": 9.322639465332031}", "{\"n\": 1906, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.43, \"learn_time_ms\": 8719.016, \"total_train_time_s\": 10.411964178085327}", "{\"n\": 1907, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3152.66, \"learn_time_ms\": 8724.591, \"total_train_time_s\": 9.299694299697876}", "{\"n\": 1908, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3152.66, \"learn_time_ms\": 8649.855, \"total_train_time_s\": 10.33573579788208}", "{\"n\": 1909, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3152.59, \"learn_time_ms\": 8565.016, \"total_train_time_s\": 10.876430034637451}", "{\"n\": 1910, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3153.41, \"learn_time_ms\": 8548.545, \"total_train_time_s\": 10.261752367019653}", "{\"n\": 1911, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3153.41, \"learn_time_ms\": 8569.231, \"total_train_time_s\": 10.657746315002441}", "{\"n\": 1912, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3153.99, \"learn_time_ms\": 8546.814, \"total_train_time_s\": 10.750105381011963}", "{\"n\": 1913, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3156.98, \"learn_time_ms\": 8640.186, \"total_train_time_s\": 9.469434976577759}", "{\"n\": 1914, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3156.98, \"learn_time_ms\": 8744.364, \"total_train_time_s\": 10.238177299499512}", "{\"n\": 1915, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3156.69, \"learn_time_ms\": 8910.766, \"total_train_time_s\": 11.051647424697876}", "{\"n\": 1916, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.89, \"learn_time_ms\": 8931.141, \"total_train_time_s\": 10.653613805770874}", "{\"n\": 1917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.89, \"learn_time_ms\": 9017.359, \"total_train_time_s\": 10.179999589920044}", "{\"n\": 1918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.27, \"learn_time_ms\": 8997.078, \"total_train_time_s\": 10.205893754959106}", "{\"n\": 1919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3145.93, \"learn_time_ms\": 8786.792, \"total_train_time_s\": 8.709503412246704}", "{\"n\": 1920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3145.93, \"learn_time_ms\": 8842.912, \"total_train_time_s\": 10.781478643417358}", "{\"n\": 1921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3141.52, \"learn_time_ms\": 8774.739, \"total_train_time_s\": 10.017014980316162}", "{\"n\": 1922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3144.95, \"learn_time_ms\": 8751.946, \"total_train_time_s\": 10.569839715957642}", "{\"n\": 1923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3144.95, \"learn_time_ms\": 8895.176, \"total_train_time_s\": 10.895141363143921}", "{\"n\": 1924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3137.38, \"learn_time_ms\": 8816.108, \"total_train_time_s\": 9.40829086303711}", "{\"n\": 1925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3131.05, \"learn_time_ms\": 8696.36, \"total_train_time_s\": 9.80392861366272}", "{\"n\": 1926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3133.03, \"learn_time_ms\": 8684.145, \"total_train_time_s\": 10.517146825790405}", "{\"n\": 1927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3132.23, \"learn_time_ms\": 8623.509, \"total_train_time_s\": 9.539458274841309}", "{\"n\": 1928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3135.29, \"learn_time_ms\": 8694.465, \"total_train_time_s\": 10.892210245132446}", "{\"n\": 1929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.56, \"learn_time_ms\": 8658.383, \"total_train_time_s\": 8.371541976928711}", "{\"n\": 1930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.58, \"learn_time_ms\": 8475.749, \"total_train_time_s\": 8.95488429069519}", "{\"n\": 1931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.09, \"learn_time_ms\": 8574.991, \"total_train_time_s\": 11.039165019989014}", "{\"n\": 1932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3142.97, \"learn_time_ms\": 8619.349, \"total_train_time_s\": 10.940107345581055}", "{\"n\": 1933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3142.97, \"learn_time_ms\": 8625.173, \"total_train_time_s\": 10.954443216323853}", "{\"n\": 1934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.09, \"learn_time_ms\": 8709.595, \"total_train_time_s\": 10.327038526535034}", "{\"n\": 1935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.85, \"learn_time_ms\": 8690.185, \"total_train_time_s\": 9.627163887023926}", "{\"n\": 1936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.85, \"learn_time_ms\": 8641.825, \"total_train_time_s\": 10.018818378448486}", "{\"n\": 1937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3140.36, \"learn_time_ms\": 8611.72, \"total_train_time_s\": 9.253128051757812}", "{\"n\": 1938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3143.33, \"learn_time_ms\": 8476.572, \"total_train_time_s\": 9.527844190597534}", "{\"n\": 1939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3142.77, \"learn_time_ms\": 8709.12, \"total_train_time_s\": 10.69843053817749}", "{\"n\": 1940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3142.81, \"learn_time_ms\": 8799.97, \"total_train_time_s\": 9.888203144073486}", "{\"n\": 1941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3141.31, \"learn_time_ms\": 8776.651, \"total_train_time_s\": 10.73443055152893}", "{\"n\": 1942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3136.54, \"learn_time_ms\": 8752.518, \"total_train_time_s\": 10.729485511779785}", "{\"n\": 1943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3137.49, \"learn_time_ms\": 8740.918, \"total_train_time_s\": 10.866854429244995}", "{\"n\": 1944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3133.62, \"learn_time_ms\": 8856.921, \"total_train_time_s\": 11.445991516113281}", "{\"n\": 1945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3136.95, \"learn_time_ms\": 8993.736, \"total_train_time_s\": 11.01824140548706}", "{\"n\": 1946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3132.4, \"learn_time_ms\": 9090.799, \"total_train_time_s\": 11.036604881286621}", "{\"n\": 1947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3134.44, \"learn_time_ms\": 9164.561, \"total_train_time_s\": 10.006714820861816}", "{\"n\": 1948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3131.76, \"learn_time_ms\": 9166.431, \"total_train_time_s\": 9.537250518798828}", "{\"n\": 1949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3136.61, \"learn_time_ms\": 9183.635, \"total_train_time_s\": 10.930235624313354}", "{\"n\": 1950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3136.61, \"learn_time_ms\": 9291.367, \"total_train_time_s\": 10.943547010421753}", "{\"n\": 1951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3130.18, \"learn_time_ms\": 9270.668, \"total_train_time_s\": 10.606521606445312}", "{\"n\": 1952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3133.33, \"learn_time_ms\": 9132.313, \"total_train_time_s\": 9.370554685592651}", "{\"n\": 1953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3133.33, \"learn_time_ms\": 9123.279, \"total_train_time_s\": 10.733764886856079}", "{\"n\": 1954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3134.38, \"learn_time_ms\": 9035.869, \"total_train_time_s\": 10.57494592666626}", "{\"n\": 1955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3134.38, \"learn_time_ms\": 8933.917, \"total_train_time_s\": 10.014058351516724}", "{\"n\": 1956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.08, \"learn_time_ms\": 8864.501, \"total_train_time_s\": 10.299111366271973}", "{\"n\": 1957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3141.99, \"learn_time_ms\": 8904.242, \"total_train_time_s\": 10.348533868789673}", "{\"n\": 1958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3141.99, \"learn_time_ms\": 8956.667, \"total_train_time_s\": 10.000749826431274}", "{\"n\": 1959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3150.92, \"learn_time_ms\": 8911.435, \"total_train_time_s\": 10.40282130241394}", "{\"n\": 1960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.93, \"learn_time_ms\": 8912.646, \"total_train_time_s\": 10.96636176109314}", "{\"n\": 1961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3157.96, \"learn_time_ms\": 8866.36, \"total_train_time_s\": 10.108636379241943}", "{\"n\": 1962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3163.33, \"learn_time_ms\": 9006.169, \"total_train_time_s\": 10.758899688720703}", "{\"n\": 1963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3163.33, \"learn_time_ms\": 9068.998, \"total_train_time_s\": 11.444093227386475}", "{\"n\": 1964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3164.78, \"learn_time_ms\": 9148.637, \"total_train_time_s\": 11.377906560897827}", "{\"n\": 1965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.46, \"learn_time_ms\": 9120.037, \"total_train_time_s\": 9.668891906738281}", "{\"n\": 1966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3171.13, \"learn_time_ms\": 9176.318, \"total_train_time_s\": 10.844989538192749}", "{\"n\": 1967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.23, \"learn_time_ms\": 9170.354, \"total_train_time_s\": 10.324946880340576}", "{\"n\": 1968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.87, \"learn_time_ms\": 9197.742, \"total_train_time_s\": 10.329422235488892}", "{\"n\": 1969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.25, \"learn_time_ms\": 9175.028, \"total_train_time_s\": 10.195649147033691}", "{\"n\": 1970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.79, \"learn_time_ms\": 9249.307, \"total_train_time_s\": 11.693727970123291}", "{\"n\": 1971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3173.67, \"learn_time_ms\": 9394.538, \"total_train_time_s\": 11.536639928817749}", "{\"n\": 1972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.89, \"learn_time_ms\": 9286.97, \"total_train_time_s\": 9.64418625831604}", "{\"n\": 1973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.63, \"learn_time_ms\": 9225.082, \"total_train_time_s\": 10.83249306678772}", "{\"n\": 1974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.48, \"learn_time_ms\": 9165.528, \"total_train_time_s\": 10.764199018478394}", "{\"n\": 1975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.24, \"learn_time_ms\": 9252.093, \"total_train_time_s\": 10.520750761032104}", "{\"n\": 1976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.24, \"learn_time_ms\": 9150.396, \"total_train_time_s\": 9.837390184402466}", "{\"n\": 1977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3174.28, \"learn_time_ms\": 9137.329, \"total_train_time_s\": 10.136792659759521}", "{\"n\": 1978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.31, \"learn_time_ms\": 9188.45, \"total_train_time_s\": 10.88083028793335}", "{\"n\": 1979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.31, \"learn_time_ms\": 9180.825, \"total_train_time_s\": 10.125226259231567}", "{\"n\": 1980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.69, \"learn_time_ms\": 8986.512, \"total_train_time_s\": 9.772729396820068}", "{\"n\": 1981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.05, \"learn_time_ms\": 8858.921, \"total_train_time_s\": 10.223580598831177}", "{\"n\": 1982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.99, \"learn_time_ms\": 8705.357, \"total_train_time_s\": 8.15738558769226}", "{\"n\": 1983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.99, \"learn_time_ms\": 8641.124, \"total_train_time_s\": 10.167968988418579}", "{\"n\": 1984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.82, \"learn_time_ms\": 8528.088, \"total_train_time_s\": 9.676348447799683}", "{\"n\": 1985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.62, \"learn_time_ms\": 8471.325, \"total_train_time_s\": 9.96541690826416}", "{\"n\": 1986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.62, \"learn_time_ms\": 8446.549, \"total_train_time_s\": 9.596367120742798}", "{\"n\": 1987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.39, \"learn_time_ms\": 8563.143, \"total_train_time_s\": 11.379064559936523}", "{\"n\": 1988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.06, \"learn_time_ms\": 8462.471, \"total_train_time_s\": 9.826281309127808}", "{\"n\": 1989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.48, \"learn_time_ms\": 8390.655, \"total_train_time_s\": 9.42100977897644}", "{\"n\": 1990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.71, \"learn_time_ms\": 8503.212, \"total_train_time_s\": 10.859664678573608}", "{\"n\": 1991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.02, \"learn_time_ms\": 8429.362, \"total_train_time_s\": 9.513924837112427}", "{\"n\": 1992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.18, \"learn_time_ms\": 8630.682, \"total_train_time_s\": 10.098822116851807}", "{\"n\": 1993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.18, \"learn_time_ms\": 8541.042, \"total_train_time_s\": 9.220980882644653}", "{\"n\": 1994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.69, \"learn_time_ms\": 8564.14, \"total_train_time_s\": 9.908738136291504}", "{\"n\": 1995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.31, \"learn_time_ms\": 8663.346, \"total_train_time_s\": 11.009068489074707}", "{\"n\": 1996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.91, \"learn_time_ms\": 8615.726, \"total_train_time_s\": 9.143325090408325}", "{\"n\": 1997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.44, \"learn_time_ms\": 8534.247, \"total_train_time_s\": 10.530429363250732}", "{\"n\": 1998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.12, \"learn_time_ms\": 8610.362, \"total_train_time_s\": 10.590782165527344}", "{\"n\": 1999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.48, \"learn_time_ms\": 8658.322, \"total_train_time_s\": 9.92582631111145}", "{\"n\": 2000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.48, \"learn_time_ms\": 8416.581, \"total_train_time_s\": 8.440491914749146}", "{\"n\": 2001, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.65, \"learn_time_ms\": 8552.942, \"total_train_time_s\": 10.878226041793823}", "{\"n\": 2002, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.66, \"learn_time_ms\": 8472.483, \"total_train_time_s\": 9.320387601852417}", "{\"n\": 2003, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.74, \"learn_time_ms\": 8534.366, \"total_train_time_s\": 9.87977647781372}", "{\"n\": 2004, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.23, \"learn_time_ms\": 8619.035, \"total_train_time_s\": 10.72743535041809}", "{\"n\": 2005, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.23, \"learn_time_ms\": 8520.624, \"total_train_time_s\": 9.964307308197021}", "{\"n\": 2006, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.04, \"learn_time_ms\": 8550.832, \"total_train_time_s\": 9.446285486221313}", "{\"n\": 2007, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.97, \"learn_time_ms\": 8585.802, \"total_train_time_s\": 10.899426460266113}", "{\"n\": 2008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.97, \"learn_time_ms\": 8531.362, \"total_train_time_s\": 10.072868585586548}", "{\"n\": 2009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.67, \"learn_time_ms\": 8662.573, \"total_train_time_s\": 11.195734024047852}", "{\"n\": 2010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.26, \"learn_time_ms\": 8753.401, \"total_train_time_s\": 9.390687227249146}", "{\"n\": 2011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.26, \"learn_time_ms\": 8656.008, \"total_train_time_s\": 9.88111925125122}", "{\"n\": 2012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.02, \"learn_time_ms\": 8857.669, \"total_train_time_s\": 11.399647235870361}", "{\"n\": 2013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.14, \"learn_time_ms\": 8894.178, \"total_train_time_s\": 10.215248107910156}", "{\"n\": 2014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.14, \"learn_time_ms\": 8942.217, \"total_train_time_s\": 11.144435167312622}", "{\"n\": 2015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.77, \"learn_time_ms\": 8930.017, \"total_train_time_s\": 9.841729640960693}", "{\"n\": 2016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.83, \"learn_time_ms\": 9153.404, \"total_train_time_s\": 11.637325763702393}", "{\"n\": 2017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.83, \"learn_time_ms\": 9023.042, \"total_train_time_s\": 9.572211265563965}", "{\"n\": 2018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.83, \"learn_time_ms\": 8903.502, \"total_train_time_s\": 8.809669017791748}", "{\"n\": 2019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.43, \"learn_time_ms\": 8749.487, \"total_train_time_s\": 9.653027772903442}", "{\"n\": 2020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.43, \"learn_time_ms\": 8873.849, \"total_train_time_s\": 10.63282060623169}", "{\"n\": 2021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.43, \"learn_time_ms\": 9021.004, \"total_train_time_s\": 11.357104778289795}", "{\"n\": 2022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.0, \"learn_time_ms\": 8846.195, \"total_train_time_s\": 9.642244815826416}", "{\"n\": 2023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.0, \"learn_time_ms\": 8609.782, \"total_train_time_s\": 7.8436033725738525}", "{\"n\": 2024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.0, \"learn_time_ms\": 8494.294, \"total_train_time_s\": 9.993750095367432}", "{\"n\": 2025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.43, \"learn_time_ms\": 8664.505, \"total_train_time_s\": 11.566644191741943}", "{\"n\": 2026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.7, \"learn_time_ms\": 8558.774, \"total_train_time_s\": 10.59725570678711}", "{\"n\": 2027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.7, \"learn_time_ms\": 8597.495, \"total_train_time_s\": 9.961512327194214}", "{\"n\": 2028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.39, \"learn_time_ms\": 8790.139, \"total_train_time_s\": 10.822885751724243}", "{\"n\": 2029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.67, \"learn_time_ms\": 8728.656, \"total_train_time_s\": 9.003166437149048}", "{\"n\": 2030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.67, \"learn_time_ms\": 8653.892, \"total_train_time_s\": 9.864441156387329}", "{\"n\": 2031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.16, \"learn_time_ms\": 8626.018, \"total_train_time_s\": 11.126888513565063}", "{\"n\": 2032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.74, \"learn_time_ms\": 8590.869, \"total_train_time_s\": 9.28299593925476}", "{\"n\": 2033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.74, \"learn_time_ms\": 8731.976, \"total_train_time_s\": 9.276788234710693}", "{\"n\": 2034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.74, \"learn_time_ms\": 8856.965, \"total_train_time_s\": 11.306141376495361}", "{\"n\": 2035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.18, \"learn_time_ms\": 8838.333, \"total_train_time_s\": 11.414137125015259}", "{\"n\": 2036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.18, \"learn_time_ms\": 8835.399, \"total_train_time_s\": 10.540306329727173}", "{\"n\": 2037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.18, \"learn_time_ms\": 8781.181, \"total_train_time_s\": 9.37109661102295}", "{\"n\": 2038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.43, \"learn_time_ms\": 8726.503, \"total_train_time_s\": 10.19039535522461}", "{\"n\": 2039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.97, \"learn_time_ms\": 8788.914, \"total_train_time_s\": 9.65708041191101}", "{\"n\": 2040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.97, \"learn_time_ms\": 8760.702, \"total_train_time_s\": 9.572797536849976}", "{\"n\": 2041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.5, \"learn_time_ms\": 8624.519, \"total_train_time_s\": 9.72447419166565}", "{\"n\": 2042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.5, \"learn_time_ms\": 8571.114, \"total_train_time_s\": 8.738861560821533}", "{\"n\": 2043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.5, \"learn_time_ms\": 8517.074, \"total_train_time_s\": 8.745327711105347}", "{\"n\": 2044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.66, \"learn_time_ms\": 8411.868, \"total_train_time_s\": 10.244304418563843}", "{\"n\": 2045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.67, \"learn_time_ms\": 8275.757, \"total_train_time_s\": 10.029919385910034}", "{\"n\": 2046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.67, \"learn_time_ms\": 8160.478, \"total_train_time_s\": 9.414083242416382}", "{\"n\": 2047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.71, \"learn_time_ms\": 8123.997, \"total_train_time_s\": 9.042531728744507}", "{\"n\": 2048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.65, \"learn_time_ms\": 8009.453, \"total_train_time_s\": 9.071177959442139}", "{\"n\": 2049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.65, \"learn_time_ms\": 8064.927, \"total_train_time_s\": 10.229491233825684}", "{\"n\": 2050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.68, \"learn_time_ms\": 8158.995, \"total_train_time_s\": 10.549937009811401}", "{\"n\": 2051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.6, \"learn_time_ms\": 8390.999, \"total_train_time_s\": 12.091819286346436}", "{\"n\": 2052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.6, \"learn_time_ms\": 8526.285, \"total_train_time_s\": 10.07092022895813}", "{\"n\": 2053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.32, \"learn_time_ms\": 8690.784, \"total_train_time_s\": 10.343631267547607}", "{\"n\": 2054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.63, \"learn_time_ms\": 8590.361, \"total_train_time_s\": 9.237665891647339}", "{\"n\": 2055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.63, \"learn_time_ms\": 8508.408, \"total_train_time_s\": 9.172149658203125}", "{\"n\": 2056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.2, \"learn_time_ms\": 8709.507, \"total_train_time_s\": 11.483013391494751}", "{\"n\": 2057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.5, \"learn_time_ms\": 8896.446, \"total_train_time_s\": 10.932358264923096}", "{\"n\": 2058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.23, \"learn_time_ms\": 9086.107, \"total_train_time_s\": 10.972887754440308}", "{\"n\": 2059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.26, \"learn_time_ms\": 8904.01, \"total_train_time_s\": 8.401715517044067}", "{\"n\": 2060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.69, \"learn_time_ms\": 9008.876, \"total_train_time_s\": 11.607676267623901}", "{\"n\": 2061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.54, \"learn_time_ms\": 8927.998, \"total_train_time_s\": 11.301122903823853}", "{\"n\": 2062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.61, \"learn_time_ms\": 8930.26, \"total_train_time_s\": 10.182864427566528}", "{\"n\": 2063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.61, \"learn_time_ms\": 8894.653, \"total_train_time_s\": 10.02032995223999}", "{\"n\": 2064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.57, \"learn_time_ms\": 8953.57, \"total_train_time_s\": 9.847178220748901}", "{\"n\": 2065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.32, \"learn_time_ms\": 8988.522, \"total_train_time_s\": 9.592337131500244}", "{\"n\": 2066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.32, \"learn_time_ms\": 8794.806, \"total_train_time_s\": 9.48627257347107}", "{\"n\": 2067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.14, \"learn_time_ms\": 8630.635, \"total_train_time_s\": 9.254133224487305}", "{\"n\": 2068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.58, \"learn_time_ms\": 8597.431, \"total_train_time_s\": 10.648248434066772}", "{\"n\": 2069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.58, \"learn_time_ms\": 8733.523, \"total_train_time_s\": 9.7535400390625}", "{\"n\": 2070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3149.96, \"learn_time_ms\": 8580.57, \"total_train_time_s\": 10.080338716506958}", "{\"n\": 2071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.75, \"learn_time_ms\": 8391.115, \"total_train_time_s\": 9.399225950241089}", "{\"n\": 2072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.75, \"learn_time_ms\": 8450.377, \"total_train_time_s\": 10.670959234237671}", "{\"n\": 2073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.67, \"learn_time_ms\": 8405.429, \"total_train_time_s\": 9.597762823104858}", "{\"n\": 2074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.62, \"learn_time_ms\": 8482.603, \"total_train_time_s\": 10.602588653564453}", "{\"n\": 2075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.03, \"learn_time_ms\": 8633.405, \"total_train_time_s\": 11.008121252059937}", "{\"n\": 2076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.99, \"learn_time_ms\": 8585.676, \"total_train_time_s\": 9.026963233947754}", "{\"n\": 2077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.99, \"learn_time_ms\": 8613.679, \"total_train_time_s\": 9.50783634185791}", "{\"n\": 2078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.48, \"learn_time_ms\": 8549.465, \"total_train_time_s\": 10.01116681098938}", "{\"n\": 2079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.89, \"learn_time_ms\": 8706.533, \"total_train_time_s\": 11.370015382766724}", "{\"n\": 2080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.69, \"learn_time_ms\": 8684.229, \"total_train_time_s\": 9.842891931533813}", "{\"n\": 2081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.39, \"learn_time_ms\": 8694.386, \"total_train_time_s\": 9.465185403823853}", "{\"n\": 2082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.18, \"learn_time_ms\": 8551.569, \"total_train_time_s\": 9.269909381866455}", "{\"n\": 2083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.61, \"learn_time_ms\": 8617.163, \"total_train_time_s\": 10.231184005737305}", "{\"n\": 2084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.61, \"learn_time_ms\": 8618.087, \"total_train_time_s\": 10.602478981018066}", "{\"n\": 2085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.39, \"learn_time_ms\": 8592.172, \"total_train_time_s\": 10.831701278686523}", "{\"n\": 2086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.62, \"learn_time_ms\": 8902.479, \"total_train_time_s\": 12.15993881225586}", "{\"n\": 2087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.62, \"learn_time_ms\": 8857.379, \"total_train_time_s\": 9.122737884521484}", "{\"n\": 2088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.68, \"learn_time_ms\": 8868.569, \"total_train_time_s\": 10.096663475036621}", "{\"n\": 2089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.67, \"learn_time_ms\": 8720.651, \"total_train_time_s\": 9.89596152305603}", "{\"n\": 2090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.67, \"learn_time_ms\": 8768.961, \"total_train_time_s\": 10.30271577835083}", "{\"n\": 2091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.87, \"learn_time_ms\": 8895.844, \"total_train_time_s\": 10.759212493896484}", "{\"n\": 2092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.9, \"learn_time_ms\": 8956.299, \"total_train_time_s\": 9.863878726959229}", "{\"n\": 2093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.9, \"learn_time_ms\": 8953.959, \"total_train_time_s\": 10.2083101272583}", "{\"n\": 2094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.2, \"learn_time_ms\": 8884.981, \"total_train_time_s\": 9.91665506362915}", "{\"n\": 2095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3172.2, \"learn_time_ms\": 8864.66, \"total_train_time_s\": 10.578244686126709}", "{\"n\": 2096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.62, \"learn_time_ms\": 8568.781, \"total_train_time_s\": 9.205767154693604}", "{\"n\": 2097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.69, \"learn_time_ms\": 8638.702, \"total_train_time_s\": 9.828592300415039}", "{\"n\": 2098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.56, \"learn_time_ms\": 8600.927, \"total_train_time_s\": 9.74065351486206}", "{\"n\": 2099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.26, \"learn_time_ms\": 8706.679, \"total_train_time_s\": 10.93184494972229}", "{\"n\": 2100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.1, \"learn_time_ms\": 8831.518, \"total_train_time_s\": 11.571420907974243}", "{\"n\": 2101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.1, \"learn_time_ms\": 8661.957, \"total_train_time_s\": 9.027327537536621}", "{\"n\": 2102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.58, \"learn_time_ms\": 8689.107, \"total_train_time_s\": 10.156357526779175}", "{\"n\": 2103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.87, \"learn_time_ms\": 8515.808, \"total_train_time_s\": 8.460201740264893}", "{\"n\": 2104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.87, \"learn_time_ms\": 8353.146, \"total_train_time_s\": 8.2541663646698}", "{\"n\": 2105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.73, \"learn_time_ms\": 8363.291, \"total_train_time_s\": 10.692398309707642}", "{\"n\": 2106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.82, \"learn_time_ms\": 8587.237, \"total_train_time_s\": 11.38772702217102}", "{\"n\": 2107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.82, \"learn_time_ms\": 8623.85, \"total_train_time_s\": 10.16676926612854}", "{\"n\": 2108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.32, \"learn_time_ms\": 8650.416, \"total_train_time_s\": 10.025844812393188}", "{\"n\": 2109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.22, \"learn_time_ms\": 8693.561, \"total_train_time_s\": 11.332685470581055}", "{\"n\": 2110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.22, \"learn_time_ms\": 8544.815, \"total_train_time_s\": 10.060322046279907}", "{\"n\": 2111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.28, \"learn_time_ms\": 8792.541, \"total_train_time_s\": 11.504738807678223}", "{\"n\": 2112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.91, \"learn_time_ms\": 8857.179, \"total_train_time_s\": 10.79601001739502}", "{\"n\": 2113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.81, \"learn_time_ms\": 8813.04, \"total_train_time_s\": 8.047014474868774}", "{\"n\": 2114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.48, \"learn_time_ms\": 9084.098, \"total_train_time_s\": 11.021196842193604}", "{\"n\": 2115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.3, \"learn_time_ms\": 8980.27, \"total_train_time_s\": 9.643271923065186}", "{\"n\": 2116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.31, \"learn_time_ms\": 8840.245, \"total_train_time_s\": 9.962451457977295}", "{\"n\": 2117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.78, \"learn_time_ms\": 8871.941, \"total_train_time_s\": 10.50436520576477}", "{\"n\": 2118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.67, \"learn_time_ms\": 8775.155, \"total_train_time_s\": 9.0353422164917}", "{\"n\": 2119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3156.03, \"learn_time_ms\": 8806.439, \"total_train_time_s\": 11.639483213424683}", "{\"n\": 2120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.01, \"learn_time_ms\": 8869.744, \"total_train_time_s\": 10.694830179214478}", "{\"n\": 2121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.33, \"learn_time_ms\": 8646.965, \"total_train_time_s\": 9.360767364501953}", "{\"n\": 2122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3157.44, \"learn_time_ms\": 8645.887, \"total_train_time_s\": 10.815269708633423}", "{\"n\": 2123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3153.21, \"learn_time_ms\": 8920.998, \"total_train_time_s\": 10.787256956100464}", "{\"n\": 2124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.62, \"learn_time_ms\": 8789.435, \"total_train_time_s\": 9.707766056060791}", "{\"n\": 2125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.62, \"learn_time_ms\": 8948.282, \"total_train_time_s\": 11.236594676971436}", "{\"n\": 2126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.15, \"learn_time_ms\": 9004.794, \"total_train_time_s\": 10.579680919647217}", "{\"n\": 2127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.02, \"learn_time_ms\": 8953.803, \"total_train_time_s\": 9.990369081497192}", "{\"n\": 2128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3153.8, \"learn_time_ms\": 9119.403, \"total_train_time_s\": 10.718057632446289}", "{\"n\": 2129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3153.8, \"learn_time_ms\": 8917.178, \"total_train_time_s\": 9.630512475967407}", "{\"n\": 2130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.08, \"learn_time_ms\": 8841.819, \"total_train_time_s\": 9.98714303970337}", "{\"n\": 2131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.08, \"learn_time_ms\": 8912.81, \"total_train_time_s\": 10.010663986206055}", "{\"n\": 2132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3149.86, \"learn_time_ms\": 8868.941, \"total_train_time_s\": 10.31749153137207}", "{\"n\": 2133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.14, \"learn_time_ms\": 8845.486, \"total_train_time_s\": 10.579761266708374}", "{\"n\": 2134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.14, \"learn_time_ms\": 8827.0, \"total_train_time_s\": 9.509337425231934}", "{\"n\": 2135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.53, \"learn_time_ms\": 8693.527, \"total_train_time_s\": 9.935933351516724}", "{\"n\": 2136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3140.44, \"learn_time_ms\": 8551.545, \"total_train_time_s\": 9.134202718734741}", "{\"n\": 2137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3143.33, \"learn_time_ms\": 8627.486, \"total_train_time_s\": 10.750537395477295}", "{\"n\": 2138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.68, \"learn_time_ms\": 8725.666, \"total_train_time_s\": 11.679068326950073}", "{\"n\": 2139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3137.21, \"learn_time_ms\": 8924.571, \"total_train_time_s\": 11.662415266036987}", "{\"n\": 2140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.35, \"learn_time_ms\": 8825.955, \"total_train_time_s\": 8.963595628738403}", "{\"n\": 2141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.35, \"learn_time_ms\": 8801.906, \"total_train_time_s\": 9.759812116622925}", "{\"n\": 2142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.34, \"learn_time_ms\": 8844.791, \"total_train_time_s\": 10.782019853591919}", "{\"n\": 2143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.34, \"learn_time_ms\": 8960.625, \"total_train_time_s\": 11.748435258865356}", "{\"n\": 2144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.89, \"learn_time_ms\": 9051.65, \"total_train_time_s\": 10.439536333084106}", "{\"n\": 2145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.79, \"learn_time_ms\": 9128.548, \"total_train_time_s\": 10.689916849136353}", "{\"n\": 2146, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.95, \"learn_time_ms\": 9331.657, \"total_train_time_s\": 11.137627601623535}", "{\"n\": 2147, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.47, \"learn_time_ms\": 9242.595, \"total_train_time_s\": 9.903799295425415}", "{\"n\": 2148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.69, \"learn_time_ms\": 9118.564, \"total_train_time_s\": 10.461067199707031}", "{\"n\": 2149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.04, \"learn_time_ms\": 8871.487, \"total_train_time_s\": 9.15247392654419}", "{\"n\": 2150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.94, \"learn_time_ms\": 8963.134, \"total_train_time_s\": 9.86433219909668}", "{\"n\": 2151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.73, \"learn_time_ms\": 8901.094, \"total_train_time_s\": 9.101706743240356}", "{\"n\": 2152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.25, \"learn_time_ms\": 8922.412, \"total_train_time_s\": 10.935986995697021}", "{\"n\": 2153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.75, \"learn_time_ms\": 8674.003, \"total_train_time_s\": 9.169902324676514}", "{\"n\": 2154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.76, \"learn_time_ms\": 8730.815, \"total_train_time_s\": 10.962113380432129}", "{\"n\": 2155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.21, \"learn_time_ms\": 8695.859, \"total_train_time_s\": 10.357803344726562}", "{\"n\": 2156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.21, \"learn_time_ms\": 8667.99, \"total_train_time_s\": 10.899160385131836}", "{\"n\": 2157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.55, \"learn_time_ms\": 8666.715, \"total_train_time_s\": 9.85190200805664}", "{\"n\": 2158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.3, \"learn_time_ms\": 8613.384, \"total_train_time_s\": 9.883437633514404}", "{\"n\": 2159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.3, \"learn_time_ms\": 8713.197, \"total_train_time_s\": 10.13791012763977}", "{\"n\": 2160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.67, \"learn_time_ms\": 8832.569, \"total_train_time_s\": 11.073073148727417}", "{\"n\": 2161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.17, \"learn_time_ms\": 9009.242, \"total_train_time_s\": 10.868342638015747}", "{\"n\": 2162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.17, \"learn_time_ms\": 8840.883, \"total_train_time_s\": 9.254621028900146}", "{\"n\": 2163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.17, \"learn_time_ms\": 9064.359, \"total_train_time_s\": 11.426031351089478}", "{\"n\": 2164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.58, \"learn_time_ms\": 9027.104, \"total_train_time_s\": 10.635048389434814}", "{\"n\": 2165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.58, \"learn_time_ms\": 9059.721, \"total_train_time_s\": 10.682897806167603}", "{\"n\": 2166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.53, \"learn_time_ms\": 9054.225, \"total_train_time_s\": 10.983091831207275}", "{\"n\": 2167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.69, \"learn_time_ms\": 9209.306, \"total_train_time_s\": 11.383722066879272}", "{\"n\": 2168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.69, \"learn_time_ms\": 9279.493, \"total_train_time_s\": 10.624413251876831}", "{\"n\": 2169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.36, \"learn_time_ms\": 9333.506, \"total_train_time_s\": 10.662013530731201}", "{\"n\": 2170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.84, \"learn_time_ms\": 9288.222, \"total_train_time_s\": 10.60961127281189}", "{\"n\": 2171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.84, \"learn_time_ms\": 9426.356, \"total_train_time_s\": 12.273987293243408}", "{\"n\": 2172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.84, \"learn_time_ms\": 9519.323, \"total_train_time_s\": 10.24258828163147}", "{\"n\": 2173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.2, \"learn_time_ms\": 9490.795, \"total_train_time_s\": 11.193809270858765}", "{\"n\": 2174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.2, \"learn_time_ms\": 9520.368, \"total_train_time_s\": 10.948224067687988}", "{\"n\": 2175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.2, \"learn_time_ms\": 9521.44, \"total_train_time_s\": 10.667672634124756}", "{\"n\": 2176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.6, \"learn_time_ms\": 9474.52, \"total_train_time_s\": 10.372800588607788}", "{\"n\": 2177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.6, \"learn_time_ms\": 9272.364, \"total_train_time_s\": 9.326692819595337}", "{\"n\": 2178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.6, \"learn_time_ms\": 9308.716, \"total_train_time_s\": 10.974098205566406}", "{\"n\": 2179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.42, \"learn_time_ms\": 9275.888, \"total_train_time_s\": 10.37936782836914}", "{\"n\": 2180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.42, \"learn_time_ms\": 9184.567, \"total_train_time_s\": 9.75156307220459}", "{\"n\": 2181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.42, \"learn_time_ms\": 8874.973, \"total_train_time_s\": 9.217484712600708}", "{\"n\": 2182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.13, \"learn_time_ms\": 8990.031, \"total_train_time_s\": 11.352243661880493}", "{\"n\": 2183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.23, \"learn_time_ms\": 8790.756, \"total_train_time_s\": 9.203046321868896}", "{\"n\": 2184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.23, \"learn_time_ms\": 8725.711, \"total_train_time_s\": 10.252830505371094}", "{\"n\": 2185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.41, \"learn_time_ms\": 8811.445, \"total_train_time_s\": 11.571160554885864}", "{\"n\": 2186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.68, \"learn_time_ms\": 8842.73, \"total_train_time_s\": 10.70407485961914}", "{\"n\": 2187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.68, \"learn_time_ms\": 8997.558, \"total_train_time_s\": 10.927111625671387}", "{\"n\": 2188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.33, \"learn_time_ms\": 8834.796, \"total_train_time_s\": 9.35727596282959}", "{\"n\": 2189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.18, \"learn_time_ms\": 8873.457, \"total_train_time_s\": 10.750303268432617}", "{\"n\": 2190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.18, \"learn_time_ms\": 8947.042, \"total_train_time_s\": 10.478079557418823}", "{\"n\": 2191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.26, \"learn_time_ms\": 9026.709, \"total_train_time_s\": 9.984918355941772}", "{\"n\": 2192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.42, \"learn_time_ms\": 8942.289, \"total_train_time_s\": 10.515827178955078}", "{\"n\": 2193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.42, \"learn_time_ms\": 8836.72, \"total_train_time_s\": 8.105716466903687}", "{\"n\": 2194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.07, \"learn_time_ms\": 8947.922, \"total_train_time_s\": 11.331949949264526}", "{\"n\": 2195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3147.98, \"learn_time_ms\": 8789.271, \"total_train_time_s\": 9.949666738510132}", "{\"n\": 2196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3147.98, \"learn_time_ms\": 8817.39, \"total_train_time_s\": 11.012006282806396}", "{\"n\": 2197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.66, \"learn_time_ms\": 8796.965, \"total_train_time_s\": 10.805417537689209}", "{\"n\": 2198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.48, \"learn_time_ms\": 8974.95, \"total_train_time_s\": 11.13228154182434}", "{\"n\": 2199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.48, \"learn_time_ms\": 8974.584, \"total_train_time_s\": 10.759262561798096}", "{\"n\": 2200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3137.28, \"learn_time_ms\": 9099.476, \"total_train_time_s\": 11.705142736434937}", "{\"n\": 2201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.35, \"learn_time_ms\": 9162.924, \"total_train_time_s\": 10.607535600662231}", "{\"n\": 2202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3138.21, \"learn_time_ms\": 9191.765, \"total_train_time_s\": 10.801634788513184}", "{\"n\": 2203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.81, \"learn_time_ms\": 9374.028, \"total_train_time_s\": 9.928004264831543}", "{\"n\": 2204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3138.09, \"learn_time_ms\": 9170.701, \"total_train_time_s\": 9.35784649848938}", "{\"n\": 2205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.0, \"learn_time_ms\": 9358.856, \"total_train_time_s\": 11.841856718063354}", "{\"n\": 2206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.0, \"learn_time_ms\": 9182.012, \"total_train_time_s\": 9.19291090965271}", "{\"n\": 2207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.51, \"learn_time_ms\": 9125.966, \"total_train_time_s\": 10.179662942886353}", "{\"n\": 2208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.06, \"learn_time_ms\": 8966.303, \"total_train_time_s\": 9.562589645385742}", "{\"n\": 2209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.06, \"learn_time_ms\": 8918.554, \"total_train_time_s\": 10.226961374282837}", "{\"n\": 2210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.47, \"learn_time_ms\": 8812.225, \"total_train_time_s\": 10.634161949157715}", "{\"n\": 2211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.1, \"learn_time_ms\": 8676.208, \"total_train_time_s\": 9.240814208984375}", "{\"n\": 2212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.1, \"learn_time_ms\": 8574.916, \"total_train_time_s\": 9.742900848388672}", "{\"n\": 2213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.14, \"learn_time_ms\": 8691.268, \"total_train_time_s\": 11.093073606491089}", "{\"n\": 2214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.83, \"learn_time_ms\": 8868.52, \"total_train_time_s\": 11.1337411403656}", "{\"n\": 2215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.29, \"learn_time_ms\": 8878.55, \"total_train_time_s\": 11.8967866897583}", "{\"n\": 2216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.53, \"learn_time_ms\": 8995.799, \"total_train_time_s\": 10.349055290222168}", "{\"n\": 2217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.53, \"learn_time_ms\": 9034.651, \"total_train_time_s\": 10.521875619888306}", "{\"n\": 2218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.24, \"learn_time_ms\": 9038.753, \"total_train_time_s\": 9.562564849853516}", "{\"n\": 2219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.45, \"learn_time_ms\": 9097.546, \"total_train_time_s\": 10.84009075164795}", "{\"n\": 2220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.6, \"learn_time_ms\": 8956.48, \"total_train_time_s\": 9.214036703109741}", "{\"n\": 2221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.37, \"learn_time_ms\": 9119.648, \"total_train_time_s\": 10.859850406646729}", "{\"n\": 2222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.56, \"learn_time_ms\": 9340.997, \"total_train_time_s\": 12.018136978149414}", "{\"n\": 2223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.03, \"learn_time_ms\": 9270.747, \"total_train_time_s\": 10.419440984725952}", "{\"n\": 2224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.72, \"learn_time_ms\": 9277.2, \"total_train_time_s\": 11.176179885864258}", "{\"n\": 2225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3150.71, \"learn_time_ms\": 9039.676, \"total_train_time_s\": 9.53031039237976}", "{\"n\": 2226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.79, \"learn_time_ms\": 9120.07, \"total_train_time_s\": 11.18173360824585}", "{\"n\": 2227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3148.79, \"learn_time_ms\": 9140.472, \"total_train_time_s\": 10.737029314041138}", "{\"n\": 2228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3154.17, \"learn_time_ms\": 9314.269, \"total_train_time_s\": 11.301714181900024}", "{\"n\": 2229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3157.36, \"learn_time_ms\": 9335.762, \"total_train_time_s\": 11.095365047454834}", "{\"n\": 2230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3157.36, \"learn_time_ms\": 9468.287, \"total_train_time_s\": 10.552916765213013}", "{\"n\": 2231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3158.66, \"learn_time_ms\": 9295.587, \"total_train_time_s\": 9.156957387924194}", "{\"n\": 2232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3153.68, \"learn_time_ms\": 8972.999, \"total_train_time_s\": 8.840023756027222}", "{\"n\": 2233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3157.84, \"learn_time_ms\": 8932.236, \"total_train_time_s\": 10.064584970474243}", "{\"n\": 2234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3160.32, \"learn_time_ms\": 8749.758, \"total_train_time_s\": 9.310857057571411}", "{\"n\": 2235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3165.27, \"learn_time_ms\": 8852.716, \"total_train_time_s\": 10.577234268188477}", "{\"n\": 2236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3162.77, \"learn_time_ms\": 8776.123, \"total_train_time_s\": 10.45384669303894}", "{\"n\": 2237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3162.77, \"learn_time_ms\": 8882.645, \"total_train_time_s\": 11.777227401733398}", "{\"n\": 2238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3166.87, \"learn_time_ms\": 8805.982, \"total_train_time_s\": 10.541183471679688}", "{\"n\": 2239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.49, \"learn_time_ms\": 8721.211, \"total_train_time_s\": 10.231033086776733}", "{\"n\": 2240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.49, \"learn_time_ms\": 8689.414, \"total_train_time_s\": 10.237135648727417}", "{\"n\": 2241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.77, \"learn_time_ms\": 8694.363, \"total_train_time_s\": 9.148072719573975}", "{\"n\": 2242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.92, \"learn_time_ms\": 8889.221, \"total_train_time_s\": 10.736658334732056}", "{\"n\": 2243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.92, \"learn_time_ms\": 9007.423, \"total_train_time_s\": 11.152812242507935}", "{\"n\": 2244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.02, \"learn_time_ms\": 9134.743, \"total_train_time_s\": 10.665064573287964}", "{\"n\": 2245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.35, \"learn_time_ms\": 9133.631, \"total_train_time_s\": 10.605969667434692}", "{\"n\": 2246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.0, \"learn_time_ms\": 9031.857, \"total_train_time_s\": 9.435147762298584}", "{\"n\": 2247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.0, \"learn_time_ms\": 8893.034, \"total_train_time_s\": 10.424226760864258}", "{\"n\": 2248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.1, \"learn_time_ms\": 8962.23, \"total_train_time_s\": 11.25338339805603}", "{\"n\": 2249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.61, \"learn_time_ms\": 8952.516, \"total_train_time_s\": 10.159169435501099}", "{\"n\": 2250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.61, \"learn_time_ms\": 8858.032, \"total_train_time_s\": 9.309300661087036}", "{\"n\": 2251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.67, \"learn_time_ms\": 8953.703, \"total_train_time_s\": 10.207755327224731}", "{\"n\": 2252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.66, \"learn_time_ms\": 9051.261, \"total_train_time_s\": 11.732519388198853}", "{\"n\": 2253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.66, \"learn_time_ms\": 8863.512, \"total_train_time_s\": 9.345505237579346}", "{\"n\": 2254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.37, \"learn_time_ms\": 8927.073, \"total_train_time_s\": 11.29435658454895}", "{\"n\": 2255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.33, \"learn_time_ms\": 8776.954, \"total_train_time_s\": 9.071856021881104}", "{\"n\": 2256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.44, \"learn_time_ms\": 8875.911, \"total_train_time_s\": 10.423681735992432}", "{\"n\": 2257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.42, \"learn_time_ms\": 8885.917, \"total_train_time_s\": 10.525562524795532}", "{\"n\": 2258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.61, \"learn_time_ms\": 8657.798, \"total_train_time_s\": 8.938844203948975}", "{\"n\": 2259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.35, \"learn_time_ms\": 8737.133, \"total_train_time_s\": 10.938010692596436}", "{\"n\": 2260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.06, \"learn_time_ms\": 8794.836, \"total_train_time_s\": 9.904798984527588}", "{\"n\": 2261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.04, \"learn_time_ms\": 8835.506, \"total_train_time_s\": 10.602166175842285}", "{\"n\": 2262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.48, \"learn_time_ms\": 8664.951, \"total_train_time_s\": 9.999253511428833}", "{\"n\": 2263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.66, \"learn_time_ms\": 8645.237, \"total_train_time_s\": 9.086811304092407}", "{\"n\": 2264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.49, \"learn_time_ms\": 8574.679, \"total_train_time_s\": 10.551874160766602}", "{\"n\": 2265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.75, \"learn_time_ms\": 8698.097, \"total_train_time_s\": 10.321821928024292}", "{\"n\": 2266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.91, \"learn_time_ms\": 8742.466, \"total_train_time_s\": 10.842675924301147}", "{\"n\": 2267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.62, \"learn_time_ms\": 8802.811, \"total_train_time_s\": 11.160276412963867}", "{\"n\": 2268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.33, \"learn_time_ms\": 9069.001, \"total_train_time_s\": 11.641607522964478}", "{\"n\": 2269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.83, \"learn_time_ms\": 9110.875, \"total_train_time_s\": 11.326639890670776}", "{\"n\": 2270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.38, \"learn_time_ms\": 9120.324, \"total_train_time_s\": 9.952874660491943}", "{\"n\": 2271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.38, \"learn_time_ms\": 9071.745, \"total_train_time_s\": 10.058119297027588}", "{\"n\": 2272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.47, \"learn_time_ms\": 9066.585, \"total_train_time_s\": 9.979120016098022}", "{\"n\": 2273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.78, \"learn_time_ms\": 9138.918, \"total_train_time_s\": 9.87317967414856}", "{\"n\": 2274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.78, \"learn_time_ms\": 9021.78, \"total_train_time_s\": 9.423425436019897}", "{\"n\": 2275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.56, \"learn_time_ms\": 8950.82, \"total_train_time_s\": 9.56926417350769}", "{\"n\": 2276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.09, \"learn_time_ms\": 8923.557, \"total_train_time_s\": 10.533719301223755}", "{\"n\": 2277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.04, \"learn_time_ms\": 8708.484, \"total_train_time_s\": 8.966212272644043}", "{\"n\": 2278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.04, \"learn_time_ms\": 8404.023, \"total_train_time_s\": 8.529980182647705}", "{\"n\": 2279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.05, \"learn_time_ms\": 8197.824, \"total_train_time_s\": 9.26439356803894}", "{\"n\": 2280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.05, \"learn_time_ms\": 8281.354, \"total_train_time_s\": 10.847455263137817}", "{\"n\": 2281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.94, \"learn_time_ms\": 8378.274, \"total_train_time_s\": 11.108741283416748}", "{\"n\": 2282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.3, \"learn_time_ms\": 8372.862, \"total_train_time_s\": 9.931293725967407}", "{\"n\": 2283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.2, \"learn_time_ms\": 8446.976, \"total_train_time_s\": 10.615633010864258}", "{\"n\": 2284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.23, \"learn_time_ms\": 8462.822, \"total_train_time_s\": 9.568106651306152}", "{\"n\": 2285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.09, \"learn_time_ms\": 8482.46, \"total_train_time_s\": 9.866405725479126}", "{\"n\": 2286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.29, \"learn_time_ms\": 8516.583, \"total_train_time_s\": 10.932430505752563}", "{\"n\": 2287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.29, \"learn_time_ms\": 8839.043, \"total_train_time_s\": 12.210965394973755}", "{\"n\": 2288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.22, \"learn_time_ms\": 9067.843, \"total_train_time_s\": 10.874136686325073}", "{\"n\": 2289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.32, \"learn_time_ms\": 9175.421, \"total_train_time_s\": 10.388271808624268}", "{\"n\": 2290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.8, \"learn_time_ms\": 9053.297, \"total_train_time_s\": 9.59126353263855}", "{\"n\": 2291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.6, \"learn_time_ms\": 8841.14, \"total_train_time_s\": 8.928324460983276}", "{\"n\": 2292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.26, \"learn_time_ms\": 8710.132, \"total_train_time_s\": 8.609108209609985}", "{\"n\": 2293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.26, \"learn_time_ms\": 8506.918, \"total_train_time_s\": 8.522230863571167}", "{\"n\": 2294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.8, \"learn_time_ms\": 8578.376, \"total_train_time_s\": 10.263264894485474}", "{\"n\": 2295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 8637.839, \"total_train_time_s\": 10.426654815673828}", "{\"n\": 2296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 8567.299, \"total_train_time_s\": 10.161073684692383}", "{\"n\": 2297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.9, \"learn_time_ms\": 8426.498, \"total_train_time_s\": 10.767953872680664}", "{\"n\": 2298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.96, \"learn_time_ms\": 8318.792, \"total_train_time_s\": 9.800107717514038}", "{\"n\": 2299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.5, \"learn_time_ms\": 8169.922, \"total_train_time_s\": 8.851441144943237}", "{\"n\": 2300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.5, \"learn_time_ms\": 8329.152, \"total_train_time_s\": 11.181605100631714}", "{\"n\": 2301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.43, \"learn_time_ms\": 8368.485, \"total_train_time_s\": 9.352559089660645}", "{\"n\": 2302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.13, \"learn_time_ms\": 8531.734, \"total_train_time_s\": 10.219623327255249}", "{\"n\": 2303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.13, \"learn_time_ms\": 8761.928, \"total_train_time_s\": 10.873000144958496}", "{\"n\": 2304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.75, \"learn_time_ms\": 8781.328, \"total_train_time_s\": 10.481423139572144}", "{\"n\": 2305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.35, \"learn_time_ms\": 8769.022, \"total_train_time_s\": 10.266823291778564}", "{\"n\": 2306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.35, \"learn_time_ms\": 8814.093, \"total_train_time_s\": 10.643193006515503}", "{\"n\": 2307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.28, \"learn_time_ms\": 8820.265, \"total_train_time_s\": 10.954825639724731}", "{\"n\": 2308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.75, \"learn_time_ms\": 8780.069, \"total_train_time_s\": 9.401875019073486}", "{\"n\": 2309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.75, \"learn_time_ms\": 9024.692, \"total_train_time_s\": 11.304454326629639}", "{\"n\": 2310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.84, \"learn_time_ms\": 9038.953, \"total_train_time_s\": 11.327105045318604}", "{\"n\": 2311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.84, \"learn_time_ms\": 9117.787, \"total_train_time_s\": 10.164077043533325}", "{\"n\": 2312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.64, \"learn_time_ms\": 9066.594, \"total_train_time_s\": 9.741116046905518}", "{\"n\": 2313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.18, \"learn_time_ms\": 8911.009, \"total_train_time_s\": 9.26746129989624}", "{\"n\": 2314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.18, \"learn_time_ms\": 8923.425, \"total_train_time_s\": 10.551630973815918}", "{\"n\": 2315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.55, \"learn_time_ms\": 9101.037, \"total_train_time_s\": 12.063976526260376}", "{\"n\": 2316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.2, \"learn_time_ms\": 9014.762, \"total_train_time_s\": 9.827274799346924}", "{\"n\": 2317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.2, \"learn_time_ms\": 8946.925, \"total_train_time_s\": 10.209345579147339}", "{\"n\": 2318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.0, \"learn_time_ms\": 8991.09, \"total_train_time_s\": 9.824207782745361}", "{\"n\": 2319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.94, \"learn_time_ms\": 8806.997, \"total_train_time_s\": 9.434652090072632}", "{\"n\": 2320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.5, \"learn_time_ms\": 8695.305, \"total_train_time_s\": 10.153738975524902}", "{\"n\": 2321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.72, \"learn_time_ms\": 8771.41, \"total_train_time_s\": 10.868004083633423}", "{\"n\": 2322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.72, \"learn_time_ms\": 8840.668, \"total_train_time_s\": 10.412245273590088}", "{\"n\": 2323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.67, \"learn_time_ms\": 8886.239, \"total_train_time_s\": 9.747378826141357}", "{\"n\": 2324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3157.53, \"learn_time_ms\": 8770.0, \"total_train_time_s\": 9.44594120979309}", "{\"n\": 2325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3157.53, \"learn_time_ms\": 8609.25, \"total_train_time_s\": 10.37494945526123}", "{\"n\": 2326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.31, \"learn_time_ms\": 8746.778, \"total_train_time_s\": 11.175765752792358}", "{\"n\": 2327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.57, \"learn_time_ms\": 8824.715, \"total_train_time_s\": 10.983270168304443}", "{\"n\": 2328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3157.04, \"learn_time_ms\": 8859.54, \"total_train_time_s\": 10.199400663375854}", "{\"n\": 2329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.92, \"learn_time_ms\": 8823.023, \"total_train_time_s\": 9.106329917907715}", "{\"n\": 2330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.92, \"learn_time_ms\": 8923.352, \"total_train_time_s\": 11.191974878311157}", "{\"n\": 2331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.48, \"learn_time_ms\": 8877.639, \"total_train_time_s\": 10.388090133666992}", "{\"n\": 2332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3156.79, \"learn_time_ms\": 8736.233, \"total_train_time_s\": 8.976906776428223}", "{\"n\": 2333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.35, \"learn_time_ms\": 8712.124, \"total_train_time_s\": 9.497202396392822}", "{\"n\": 2334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.14, \"learn_time_ms\": 8714.521, \"total_train_time_s\": 9.445962190628052}", "{\"n\": 2335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.76, \"learn_time_ms\": 8654.927, \"total_train_time_s\": 9.835496664047241}", "{\"n\": 2336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.2, \"learn_time_ms\": 8499.555, \"total_train_time_s\": 9.645885705947876}", "{\"n\": 2337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.11, \"learn_time_ms\": 8535.945, \"total_train_time_s\": 11.370716571807861}", "{\"n\": 2338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.47, \"learn_time_ms\": 8647.901, \"total_train_time_s\": 11.258648157119751}", "{\"n\": 2339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.91, \"learn_time_ms\": 8774.703, \"total_train_time_s\": 10.33006739616394}", "{\"n\": 2340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.22, \"learn_time_ms\": 8566.645, \"total_train_time_s\": 9.127478122711182}", "{\"n\": 2341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.42, \"learn_time_ms\": 8650.768, \"total_train_time_s\": 11.304938077926636}", "{\"n\": 2342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.42, \"learn_time_ms\": 8677.255, \"total_train_time_s\": 9.23328971862793}", "{\"n\": 2343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.72, \"learn_time_ms\": 8718.868, \"total_train_time_s\": 9.927125453948975}", "{\"n\": 2344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.06, \"learn_time_ms\": 8705.385, \"total_train_time_s\": 9.303506135940552}", "{\"n\": 2345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.01, \"learn_time_ms\": 8725.505, \"total_train_time_s\": 10.007391214370728}", "{\"n\": 2346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.84, \"learn_time_ms\": 8669.859, \"total_train_time_s\": 9.068198204040527}", "{\"n\": 2347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.1, \"learn_time_ms\": 8585.784, \"total_train_time_s\": 10.51804256439209}", "{\"n\": 2348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.1, \"learn_time_ms\": 8412.227, \"total_train_time_s\": 9.546406745910645}", "{\"n\": 2349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.99, \"learn_time_ms\": 8421.374, \"total_train_time_s\": 10.50465703010559}", "{\"n\": 2350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.37, \"learn_time_ms\": 8478.332, \"total_train_time_s\": 9.716835498809814}", "{\"n\": 2351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.37, \"learn_time_ms\": 8428.312, \"total_train_time_s\": 10.761207103729248}", "{\"n\": 2352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3150.61, \"learn_time_ms\": 8460.976, \"total_train_time_s\": 9.559454202651978}", "{\"n\": 2353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.18, \"learn_time_ms\": 8615.059, \"total_train_time_s\": 11.445723533630371}", "{\"n\": 2354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3148.35, \"learn_time_ms\": 8761.444, \"total_train_time_s\": 10.767901182174683}", "{\"n\": 2355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.88, \"learn_time_ms\": 8794.399, \"total_train_time_s\": 10.365012884140015}", "{\"n\": 2356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3152.68, \"learn_time_ms\": 8913.582, \"total_train_time_s\": 10.2431960105896}", "{\"n\": 2357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.08, \"learn_time_ms\": 8954.794, \"total_train_time_s\": 10.897487163543701}", "{\"n\": 2358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.56, \"learn_time_ms\": 8954.421, \"total_train_time_s\": 9.56945538520813}", "{\"n\": 2359, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.45, \"learn_time_ms\": 8942.288, \"total_train_time_s\": 10.399300575256348}", "{\"n\": 2360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.45, \"learn_time_ms\": 8976.479, \"total_train_time_s\": 10.00515627861023}", "{\"n\": 2361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.72, \"learn_time_ms\": 8996.348, \"total_train_time_s\": 10.987552404403687}", "{\"n\": 2362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.03, \"learn_time_ms\": 9055.812, \"total_train_time_s\": 10.163639068603516}", "{\"n\": 2363, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.49, \"learn_time_ms\": 8921.25, \"total_train_time_s\": 10.137197971343994}", "{\"n\": 2364, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.46, \"learn_time_ms\": 8890.168, \"total_train_time_s\": 10.430397033691406}", "{\"n\": 2365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.46, \"learn_time_ms\": 8912.869, \"total_train_time_s\": 10.611946821212769}", "{\"n\": 2366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.72, \"learn_time_ms\": 8971.681, \"total_train_time_s\": 10.844369173049927}", "{\"n\": 2367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.72, \"learn_time_ms\": 9003.572, \"total_train_time_s\": 11.17139220237732}", "{\"n\": 2368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.34, \"learn_time_ms\": 9068.971, \"total_train_time_s\": 10.204901218414307}", "{\"n\": 2369, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.17, \"learn_time_ms\": 9054.235, \"total_train_time_s\": 10.190943479537964}", "{\"n\": 2370, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.17, \"learn_time_ms\": 8956.121, \"total_train_time_s\": 9.009549617767334}", "{\"n\": 2371, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.54, \"learn_time_ms\": 8922.049, \"total_train_time_s\": 10.606508731842041}", "{\"n\": 2372, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3174.31, \"learn_time_ms\": 8847.621, \"total_train_time_s\": 9.39607858657837}", "{\"n\": 2373, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.99, \"learn_time_ms\": 9036.646, \"total_train_time_s\": 12.006606101989746}", "{\"n\": 2374, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.94, \"learn_time_ms\": 9063.717, \"total_train_time_s\": 10.720235109329224}", "{\"n\": 2375, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.94, \"learn_time_ms\": 9128.839, \"total_train_time_s\": 11.234234094619751}", "{\"n\": 2376, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.29, \"learn_time_ms\": 9196.571, \"total_train_time_s\": 11.491520166397095}", "{\"n\": 2377, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.21, \"learn_time_ms\": 8931.6, \"total_train_time_s\": 8.559231758117676}", "{\"n\": 2378, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.21, \"learn_time_ms\": 8965.58, \"total_train_time_s\": 10.547230958938599}", "{\"n\": 2379, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.46, \"learn_time_ms\": 8782.868, \"total_train_time_s\": 8.382031917572021}", "{\"n\": 2380, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.95, \"learn_time_ms\": 9133.568, \"total_train_time_s\": 12.545644760131836}", "{\"n\": 2381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.95, \"learn_time_ms\": 8985.403, \"total_train_time_s\": 9.154433488845825}", "{\"n\": 2382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.08, \"learn_time_ms\": 9140.232, \"total_train_time_s\": 10.978636503219604}", "{\"n\": 2383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.79, \"learn_time_ms\": 9039.479, \"total_train_time_s\": 10.974066734313965}", "{\"n\": 2384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.85, \"learn_time_ms\": 9141.148, \"total_train_time_s\": 11.735503911972046}", "{\"n\": 2385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.85, \"learn_time_ms\": 8948.977, \"total_train_time_s\": 9.341529369354248}", "{\"n\": 2386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.31, \"learn_time_ms\": 8788.195, \"total_train_time_s\": 9.934878826141357}", "{\"n\": 2387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.53, \"learn_time_ms\": 9052.399, \"total_train_time_s\": 11.23977017402649}", "{\"n\": 2388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.53, \"learn_time_ms\": 9037.208, \"total_train_time_s\": 10.37825870513916}", "{\"n\": 2389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.06, \"learn_time_ms\": 9261.605, \"total_train_time_s\": 10.597682476043701}", "{\"n\": 2390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.5, \"learn_time_ms\": 9051.977, \"total_train_time_s\": 10.498147010803223}", "{\"n\": 2391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.5, \"learn_time_ms\": 9056.088, \"total_train_time_s\": 9.20422649383545}", "{\"n\": 2392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.97, \"learn_time_ms\": 9001.597, \"total_train_time_s\": 10.454955339431763}", "{\"n\": 2393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.63, \"learn_time_ms\": 8914.974, \"total_train_time_s\": 10.22014307975769}", "{\"n\": 2394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.63, \"learn_time_ms\": 8758.347, \"total_train_time_s\": 10.15779161453247}", "{\"n\": 2395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.63, \"learn_time_ms\": 8833.58, \"total_train_time_s\": 10.019546747207642}", "{\"n\": 2396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.27, \"learn_time_ms\": 8579.249, \"total_train_time_s\": 7.3384690284729}", "{\"n\": 2397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.27, \"learn_time_ms\": 8567.825, \"total_train_time_s\": 11.078575134277344}", "{\"n\": 2398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.27, \"learn_time_ms\": 8544.656, \"total_train_time_s\": 10.157336711883545}", "{\"n\": 2399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.91, \"learn_time_ms\": 8540.795, \"total_train_time_s\": 10.554940700531006}", "{\"n\": 2400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.74, \"learn_time_ms\": 8515.085, \"total_train_time_s\": 10.186250448226929}", "{\"n\": 2401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.74, \"learn_time_ms\": 8446.567, \"total_train_time_s\": 8.4849534034729}", "{\"n\": 2402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.8, \"learn_time_ms\": 8435.388, \"total_train_time_s\": 10.353380918502808}", "{\"n\": 2403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.87, \"learn_time_ms\": 8426.224, \"total_train_time_s\": 10.077024698257446}", "{\"n\": 2404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.87, \"learn_time_ms\": 8394.583, \"total_train_time_s\": 9.879410028457642}", "{\"n\": 2405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.78, \"learn_time_ms\": 8504.786, \"total_train_time_s\": 11.174960136413574}", "{\"n\": 2406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.5, \"learn_time_ms\": 8688.358, \"total_train_time_s\": 9.148926496505737}", "{\"n\": 2407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.65, \"learn_time_ms\": 8539.277, \"total_train_time_s\": 9.606011390686035}", "{\"n\": 2408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.49, \"learn_time_ms\": 8485.735, \"total_train_time_s\": 9.640459537506104}", "{\"n\": 2409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.57, \"learn_time_ms\": 8337.427, \"total_train_time_s\": 9.073801517486572}", "{\"n\": 2410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.42, \"learn_time_ms\": 8488.619, \"total_train_time_s\": 11.708347797393799}", "{\"n\": 2411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.11, \"learn_time_ms\": 8587.914, \"total_train_time_s\": 9.469098091125488}", "{\"n\": 2412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.41, \"learn_time_ms\": 8715.621, \"total_train_time_s\": 11.600386142730713}", "{\"n\": 2413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.33, \"learn_time_ms\": 8765.232, \"total_train_time_s\": 10.5402512550354}", "{\"n\": 2414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.78, \"learn_time_ms\": 8689.03, \"total_train_time_s\": 9.071808338165283}", "{\"n\": 2415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.22, \"learn_time_ms\": 8477.926, \"total_train_time_s\": 9.087484359741211}", "{\"n\": 2416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.68, \"learn_time_ms\": 8349.461, \"total_train_time_s\": 7.894402742385864}", "{\"n\": 2417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.68, \"learn_time_ms\": 8386.289, \"total_train_time_s\": 9.965494632720947}", "{\"n\": 2418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.58, \"learn_time_ms\": 8381.304, \"total_train_time_s\": 9.57740330696106}", "{\"n\": 2419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.49, \"learn_time_ms\": 8453.366, \"total_train_time_s\": 9.801960945129395}", "{\"n\": 2420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.49, \"learn_time_ms\": 8385.873, \"total_train_time_s\": 11.005934238433838}", "{\"n\": 2421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.54, \"learn_time_ms\": 8540.493, \"total_train_time_s\": 11.034924507141113}", "{\"n\": 2422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.18, \"learn_time_ms\": 8413.181, \"total_train_time_s\": 10.322144031524658}", "{\"n\": 2423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.47, \"learn_time_ms\": 8255.945, \"total_train_time_s\": 9.002167224884033}", "{\"n\": 2424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.65, \"learn_time_ms\": 8382.149, \"total_train_time_s\": 10.359484195709229}", "{\"n\": 2425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.42, \"learn_time_ms\": 8509.729, \"total_train_time_s\": 10.39811086654663}", "{\"n\": 2426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.42, \"learn_time_ms\": 8741.726, \"total_train_time_s\": 10.248238563537598}", "{\"n\": 2427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.09, \"learn_time_ms\": 8895.246, \"total_train_time_s\": 11.510646104812622}", "{\"n\": 2428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 8973.959, \"total_train_time_s\": 10.363751411437988}", "{\"n\": 2429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 8929.17, \"total_train_time_s\": 9.40065598487854}", "{\"n\": 2430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.67, \"learn_time_ms\": 8801.697, \"total_train_time_s\": 9.750839948654175}", "{\"n\": 2431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.43, \"learn_time_ms\": 8782.233, \"total_train_time_s\": 10.842933654785156}", "{\"n\": 2432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.71, \"learn_time_ms\": 8782.525, \"total_train_time_s\": 10.317973136901855}", "{\"n\": 2433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.17, \"learn_time_ms\": 8860.98, \"total_train_time_s\": 9.75931978225708}", "{\"n\": 2434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.59, \"learn_time_ms\": 8859.432, \"total_train_time_s\": 10.38235330581665}", "{\"n\": 2435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.97, \"learn_time_ms\": 8711.058, \"total_train_time_s\": 8.847333908081055}", "{\"n\": 2436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.97, \"learn_time_ms\": 8696.355, \"total_train_time_s\": 10.094589948654175}", "{\"n\": 2437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.74, \"learn_time_ms\": 8613.768, \"total_train_time_s\": 10.72812032699585}", "{\"n\": 2438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.87, \"learn_time_ms\": 8565.876, \"total_train_time_s\": 9.87884259223938}", "{\"n\": 2439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.87, \"learn_time_ms\": 8511.564, \"total_train_time_s\": 8.816142797470093}", "{\"n\": 2440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.0, \"learn_time_ms\": 8462.028, \"total_train_time_s\": 9.23519492149353}", "{\"n\": 2441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.74, \"learn_time_ms\": 8306.186, \"total_train_time_s\": 9.246039390563965}", "{\"n\": 2442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.96, \"learn_time_ms\": 8176.802, \"total_train_time_s\": 9.017496585845947}", "{\"n\": 2443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.36, \"learn_time_ms\": 8270.535, \"total_train_time_s\": 10.694326400756836}", "{\"n\": 2444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.75, \"learn_time_ms\": 8218.567, \"total_train_time_s\": 9.802342414855957}", "{\"n\": 2445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.91, \"learn_time_ms\": 8461.046, \"total_train_time_s\": 11.272419214248657}", "{\"n\": 2446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.78, \"learn_time_ms\": 8387.03, \"total_train_time_s\": 9.338370323181152}", "{\"n\": 2447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.75, \"learn_time_ms\": 8197.59, \"total_train_time_s\": 8.787081003189087}", "{\"n\": 2448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.28, \"learn_time_ms\": 8274.831, \"total_train_time_s\": 10.686184883117676}", "{\"n\": 2449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.78, \"learn_time_ms\": 8454.904, \"total_train_time_s\": 10.605918169021606}", "{\"n\": 2450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.51, \"learn_time_ms\": 8459.762, \"total_train_time_s\": 9.304954528808594}", "{\"n\": 2451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.93, \"learn_time_ms\": 8484.19, \"total_train_time_s\": 9.521369934082031}", "{\"n\": 2452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.2, \"learn_time_ms\": 8533.231, \"total_train_time_s\": 9.546586990356445}", "{\"n\": 2453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.61, \"learn_time_ms\": 8491.451, \"total_train_time_s\": 10.225263595581055}", "{\"n\": 2454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.82, \"learn_time_ms\": 8407.207, \"total_train_time_s\": 8.983774900436401}", "{\"n\": 2455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.82, \"learn_time_ms\": 8258.78, \"total_train_time_s\": 9.790160417556763}", "{\"n\": 2456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.42, \"learn_time_ms\": 8479.691, \"total_train_time_s\": 11.497850179672241}", "{\"n\": 2457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.73, \"learn_time_ms\": 8647.131, \"total_train_time_s\": 10.451283931732178}", "{\"n\": 2458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.88, \"learn_time_ms\": 8697.351, \"total_train_time_s\": 11.162221193313599}", "{\"n\": 2459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.01, \"learn_time_ms\": 8727.748, \"total_train_time_s\": 11.078903198242188}", "{\"n\": 2460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.81, \"learn_time_ms\": 8854.17, \"total_train_time_s\": 10.56760287284851}", "{\"n\": 2461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.29, \"learn_time_ms\": 8793.097, \"total_train_time_s\": 8.938734292984009}", "{\"n\": 2462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.89, \"learn_time_ms\": 8746.292, \"total_train_time_s\": 9.067168474197388}", "{\"n\": 2463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.62, \"learn_time_ms\": 8789.343, \"total_train_time_s\": 10.68256402015686}", "{\"n\": 2464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.67, \"learn_time_ms\": 8911.807, \"total_train_time_s\": 10.207202434539795}", "{\"n\": 2465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.9, \"learn_time_ms\": 8946.762, \"total_train_time_s\": 10.10345458984375}", "{\"n\": 2466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.51, \"learn_time_ms\": 8831.099, \"total_train_time_s\": 10.3461012840271}", "{\"n\": 2467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.87, \"learn_time_ms\": 8904.15, \"total_train_time_s\": 11.135679721832275}", "{\"n\": 2468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.14, \"learn_time_ms\": 8882.516, \"total_train_time_s\": 10.931974649429321}", "{\"n\": 2469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.6, \"learn_time_ms\": 8877.136, \"total_train_time_s\": 10.88526725769043}", "{\"n\": 2470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.36, \"learn_time_ms\": 8861.688, \"total_train_time_s\": 10.41620922088623}", "{\"n\": 2471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.8, \"learn_time_ms\": 8952.887, \"total_train_time_s\": 9.856595516204834}", "{\"n\": 2472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.27, \"learn_time_ms\": 9205.985, \"total_train_time_s\": 11.58734655380249}", "{\"n\": 2473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.27, \"learn_time_ms\": 9125.647, \"total_train_time_s\": 9.881295919418335}", "{\"n\": 2474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.7, \"learn_time_ms\": 9139.912, \"total_train_time_s\": 10.357604503631592}", "{\"n\": 2475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.94, \"learn_time_ms\": 9165.56, \"total_train_time_s\": 10.399851322174072}", "{\"n\": 2476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.94, \"learn_time_ms\": 9108.929, \"total_train_time_s\": 9.789944648742676}", "{\"n\": 2477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.05, \"learn_time_ms\": 9063.814, \"total_train_time_s\": 10.743057012557983}", "{\"n\": 2478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.71, \"learn_time_ms\": 9004.01, \"total_train_time_s\": 10.363777160644531}", "{\"n\": 2479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.71, \"learn_time_ms\": 8901.401, \"total_train_time_s\": 9.840568542480469}", "{\"n\": 2480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.39, \"learn_time_ms\": 8720.273, \"total_train_time_s\": 8.587680339813232}", "{\"n\": 2481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.12, \"learn_time_ms\": 8650.145, \"total_train_time_s\": 9.1251699924469}", "{\"n\": 2482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.42, \"learn_time_ms\": 8469.931, \"total_train_time_s\": 9.778124332427979}", "{\"n\": 2483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.67, \"learn_time_ms\": 8543.402, \"total_train_time_s\": 10.628267288208008}", "{\"n\": 2484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.17, \"learn_time_ms\": 8504.315, \"total_train_time_s\": 9.927053928375244}", "{\"n\": 2485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.27, \"learn_time_ms\": 8416.082, \"total_train_time_s\": 9.535450458526611}", "{\"n\": 2486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.11, \"learn_time_ms\": 8391.759, \"total_train_time_s\": 9.592000246047974}", "{\"n\": 2487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.5, \"learn_time_ms\": 8411.949, \"total_train_time_s\": 10.948719501495361}", "{\"n\": 2488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.41, \"learn_time_ms\": 8444.043, \"total_train_time_s\": 10.635732650756836}", "{\"n\": 2489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.41, \"learn_time_ms\": 8461.442, \"total_train_time_s\": 10.001209259033203}", "{\"n\": 2490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.36, \"learn_time_ms\": 8800.451, \"total_train_time_s\": 12.019863367080688}", "{\"n\": 2491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3182.65, \"learn_time_ms\": 8900.106, \"total_train_time_s\": 10.126510381698608}", "{\"n\": 2492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3182.65, \"learn_time_ms\": 9089.782, \"total_train_time_s\": 11.690715074539185}", "{\"n\": 2493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3184.56, \"learn_time_ms\": 9144.35, \"total_train_time_s\": 11.166068077087402}", "{\"n\": 2494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3186.77, \"learn_time_ms\": 9197.243, \"total_train_time_s\": 10.483850479125977}", "{\"n\": 2495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3181.55, \"learn_time_ms\": 9217.639, \"total_train_time_s\": 9.707972764968872}", "{\"n\": 2496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3181.55, \"learn_time_ms\": 9360.12, \"total_train_time_s\": 11.01258659362793}", "{\"n\": 2497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.71, \"learn_time_ms\": 9152.498, \"total_train_time_s\": 8.87474513053894}", "{\"n\": 2498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.75, \"learn_time_ms\": 9149.824, \"total_train_time_s\": 10.651177167892456}", "{\"n\": 2499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.75, \"learn_time_ms\": 9134.582, \"total_train_time_s\": 9.837671041488647}", "{\"n\": 2500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3170.23, \"learn_time_ms\": 8923.655, \"total_train_time_s\": 9.874756813049316}", "{\"n\": 2501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.33, \"learn_time_ms\": 9043.018, \"total_train_time_s\": 11.317769527435303}", "{\"n\": 2502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.33, \"learn_time_ms\": 8919.035, \"total_train_time_s\": 10.44711971282959}", "{\"n\": 2503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.1, \"learn_time_ms\": 8888.673, \"total_train_time_s\": 10.845200061798096}", "{\"n\": 2504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.41, \"learn_time_ms\": 8925.663, \"total_train_time_s\": 10.837396621704102}", "{\"n\": 2505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.98, \"learn_time_ms\": 8918.543, \"total_train_time_s\": 9.655809164047241}", "{\"n\": 2506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3170.31, \"learn_time_ms\": 8642.473, \"total_train_time_s\": 8.216759204864502}", "{\"n\": 2507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.05, \"learn_time_ms\": 8851.154, \"total_train_time_s\": 10.978646516799927}", "{\"n\": 2508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.05, \"learn_time_ms\": 8865.722, \"total_train_time_s\": 10.778892040252686}", "{\"n\": 2509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.5, \"learn_time_ms\": 8935.781, \"total_train_time_s\": 10.596839189529419}", "{\"n\": 2510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.24, \"learn_time_ms\": 8956.528, \"total_train_time_s\": 10.108675479888916}", "{\"n\": 2511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.31, \"learn_time_ms\": 8927.26, \"total_train_time_s\": 11.034099102020264}", "{\"n\": 2512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.82, \"learn_time_ms\": 8959.207, \"total_train_time_s\": 10.751288414001465}", "{\"n\": 2513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3173.96, \"learn_time_ms\": 8945.476, \"total_train_time_s\": 10.719208478927612}", "{\"n\": 2514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.28, \"learn_time_ms\": 8939.309, \"total_train_time_s\": 10.793747186660767}", "{\"n\": 2515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.28, \"learn_time_ms\": 9132.058, \"total_train_time_s\": 11.573821306228638}", "{\"n\": 2516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.98, \"learn_time_ms\": 9285.142, \"total_train_time_s\": 9.78488540649414}", "{\"n\": 2517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.13, \"learn_time_ms\": 9184.174, \"total_train_time_s\": 10.025602340698242}", "{\"n\": 2518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.13, \"learn_time_ms\": 9170.825, \"total_train_time_s\": 10.677857160568237}", "{\"n\": 2519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.02, \"learn_time_ms\": 9153.334, \"total_train_time_s\": 10.371949434280396}", "{\"n\": 2520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.37, \"learn_time_ms\": 9160.34, \"total_train_time_s\": 10.149029731750488}", "{\"n\": 2521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.37, \"learn_time_ms\": 9108.676, \"total_train_time_s\": 10.48003339767456}", "{\"n\": 2522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.34, \"learn_time_ms\": 8942.659, \"total_train_time_s\": 9.121717691421509}", "{\"n\": 2523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3174.46, \"learn_time_ms\": 8981.836, \"total_train_time_s\": 11.120957374572754}", "{\"n\": 2524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3172.75, \"learn_time_ms\": 8882.008, \"total_train_time_s\": 9.761660814285278}", "{\"n\": 2525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.04, \"learn_time_ms\": 8848.954, \"total_train_time_s\": 11.22380805015564}", "{\"n\": 2526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.65, \"learn_time_ms\": 8869.29, \"total_train_time_s\": 10.010790348052979}", "{\"n\": 2527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.8, \"learn_time_ms\": 8916.284, \"total_train_time_s\": 10.434033393859863}", "{\"n\": 2528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.33, \"learn_time_ms\": 8963.473, \"total_train_time_s\": 11.13815450668335}", "{\"n\": 2529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.0, \"learn_time_ms\": 9091.821, \"total_train_time_s\": 11.684865474700928}", "{\"n\": 2530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3185.09, \"learn_time_ms\": 9122.381, \"total_train_time_s\": 10.476921081542969}", "{\"n\": 2531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3181.76, \"learn_time_ms\": 9015.452, \"total_train_time_s\": 9.38709568977356}", "{\"n\": 2532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.99, \"learn_time_ms\": 9118.179, \"total_train_time_s\": 10.13986587524414}", "{\"n\": 2533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.58, \"learn_time_ms\": 8970.456, \"total_train_time_s\": 9.654387950897217}", "{\"n\": 2534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.58, \"learn_time_ms\": 8979.309, \"total_train_time_s\": 9.896856546401978}", "{\"n\": 2535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.34, \"learn_time_ms\": 8907.624, \"total_train_time_s\": 10.549059391021729}", "{\"n\": 2536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.9, \"learn_time_ms\": 8985.82, \"total_train_time_s\": 10.749970436096191}", "{\"n\": 2537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3182.34, \"learn_time_ms\": 8934.796, \"total_train_time_s\": 9.8971529006958}", "{\"n\": 2538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.8, \"learn_time_ms\": 8850.996, \"total_train_time_s\": 10.267627000808716}", "{\"n\": 2539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.37, \"learn_time_ms\": 8742.197, \"total_train_time_s\": 10.543122053146362}", "{\"n\": 2540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.39, \"learn_time_ms\": 8643.126, \"total_train_time_s\": 9.463922500610352}", "{\"n\": 2541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.47, \"learn_time_ms\": 8669.966, \"total_train_time_s\": 9.681797504425049}", "{\"n\": 2542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.08, \"learn_time_ms\": 8537.913, \"total_train_time_s\": 8.808314561843872}", "{\"n\": 2543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.6, \"learn_time_ms\": 8595.204, \"total_train_time_s\": 10.200846672058105}", "{\"n\": 2544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.1, \"learn_time_ms\": 8621.494, \"total_train_time_s\": 10.163022518157959}", "{\"n\": 2545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.55, \"learn_time_ms\": 8543.398, \"total_train_time_s\": 9.761399507522583}", "{\"n\": 2546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.01, \"learn_time_ms\": 8584.691, \"total_train_time_s\": 11.14166259765625}", "{\"n\": 2547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.48, \"learn_time_ms\": 8555.553, \"total_train_time_s\": 9.631432056427002}", "{\"n\": 2548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.26, \"learn_time_ms\": 8537.724, \"total_train_time_s\": 10.097679138183594}", "{\"n\": 2549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.3, \"learn_time_ms\": 8580.626, \"total_train_time_s\": 10.962599754333496}", "{\"n\": 2550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.16, \"learn_time_ms\": 8797.029, \"total_train_time_s\": 11.649212121963501}", "{\"n\": 2551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.56, \"learn_time_ms\": 8887.21, \"total_train_time_s\": 10.617713451385498}", "{\"n\": 2552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.56, \"learn_time_ms\": 9035.309, \"total_train_time_s\": 10.276968240737915}", "{\"n\": 2553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.55, \"learn_time_ms\": 8990.305, \"total_train_time_s\": 9.77356243133545}", "{\"n\": 2554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.4, \"learn_time_ms\": 8935.474, \"total_train_time_s\": 9.61612343788147}", "{\"n\": 2555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.4, \"learn_time_ms\": 8958.392, \"total_train_time_s\": 9.981429815292358}", "{\"n\": 2556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.31, \"learn_time_ms\": 8916.448, \"total_train_time_s\": 10.759309768676758}", "{\"n\": 2557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.07, \"learn_time_ms\": 9213.568, \"total_train_time_s\": 12.585094451904297}", "{\"n\": 2558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.42, \"learn_time_ms\": 9259.38, \"total_train_time_s\": 10.581031322479248}", "{\"n\": 2559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.07, \"learn_time_ms\": 9014.075, \"total_train_time_s\": 8.579516649246216}", "{\"n\": 2560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.99, \"learn_time_ms\": 8868.541, \"total_train_time_s\": 10.262978315353394}", "{\"n\": 2561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.23, \"learn_time_ms\": 8848.092, \"total_train_time_s\": 10.401700735092163}", "{\"n\": 2562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.36, \"learn_time_ms\": 8721.228, \"total_train_time_s\": 9.03476619720459}", "{\"n\": 2563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 8663.988, \"total_train_time_s\": 9.199379444122314}", "{\"n\": 2564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 8787.071, \"total_train_time_s\": 10.784115314483643}", "{\"n\": 2565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.08, \"learn_time_ms\": 8809.166, \"total_train_time_s\": 10.202961921691895}", "{\"n\": 2566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.05, \"learn_time_ms\": 8781.531, \"total_train_time_s\": 10.490240573883057}", "{\"n\": 2567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.05, \"learn_time_ms\": 8518.91, \"total_train_time_s\": 9.981090068817139}", "{\"n\": 2568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.42, \"learn_time_ms\": 8382.786, \"total_train_time_s\": 9.217998504638672}", "{\"n\": 2569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.67, \"learn_time_ms\": 8635.848, \"total_train_time_s\": 11.074954986572266}", "{\"n\": 2570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.67, \"learn_time_ms\": 8665.111, \"total_train_time_s\": 10.488981008529663}", "{\"n\": 2571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.67, \"learn_time_ms\": 8678.309, \"total_train_time_s\": 10.523297309875488}", "{\"n\": 2572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.53, \"learn_time_ms\": 8859.02, \"total_train_time_s\": 10.813636302947998}", "{\"n\": 2573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.53, \"learn_time_ms\": 8894.418, \"total_train_time_s\": 9.535710573196411}", "{\"n\": 2574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.03, \"learn_time_ms\": 8822.737, \"total_train_time_s\": 10.14280891418457}", "{\"n\": 2575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.16, \"learn_time_ms\": 8855.658, \"total_train_time_s\": 10.560413599014282}", "{\"n\": 2576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.16, \"learn_time_ms\": 8868.29, \"total_train_time_s\": 10.599255800247192}", "{\"n\": 2577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.16, \"learn_time_ms\": 8946.017, \"total_train_time_s\": 10.715097665786743}", "{\"n\": 2578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 9120.881, \"total_train_time_s\": 10.976027727127075}", "{\"n\": 2579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 9049.335, \"total_train_time_s\": 10.358706951141357}", "{\"n\": 2580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 8962.999, \"total_train_time_s\": 9.65668272972107}", "{\"n\": 2581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.93, \"learn_time_ms\": 8910.231, \"total_train_time_s\": 9.995898246765137}", "{\"n\": 2582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.93, \"learn_time_ms\": 8937.336, \"total_train_time_s\": 11.131388425827026}", "{\"n\": 2583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.93, \"learn_time_ms\": 9058.643, \"total_train_time_s\": 10.78674864768982}", "{\"n\": 2584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.0, \"learn_time_ms\": 9086.991, \"total_train_time_s\": 10.437628746032715}", "{\"n\": 2585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.57, \"learn_time_ms\": 9062.407, \"total_train_time_s\": 10.293628692626953}", "{\"n\": 2586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.57, \"learn_time_ms\": 9005.611, \"total_train_time_s\": 10.067707300186157}", "{\"n\": 2587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.25, \"learn_time_ms\": 8842.272, \"total_train_time_s\": 9.095854043960571}", "{\"n\": 2588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.85, \"learn_time_ms\": 8828.182, \"total_train_time_s\": 10.858086347579956}", "{\"n\": 2589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.85, \"learn_time_ms\": 8856.138, \"total_train_time_s\": 10.641843557357788}", "{\"n\": 2590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.14, \"learn_time_ms\": 8961.753, \"total_train_time_s\": 10.660643339157104}", "{\"n\": 2591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.23, \"learn_time_ms\": 9019.907, \"total_train_time_s\": 10.613404989242554}", "{\"n\": 2592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.28, \"learn_time_ms\": 8923.706, \"total_train_time_s\": 10.127317905426025}", "{\"n\": 2593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.69, \"learn_time_ms\": 8801.304, \"total_train_time_s\": 9.550167322158813}", "{\"n\": 2594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.5, \"learn_time_ms\": 8833.413, \"total_train_time_s\": 10.711256504058838}", "{\"n\": 2595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.48, \"learn_time_ms\": 8726.331, \"total_train_time_s\": 9.20784854888916}", "{\"n\": 2596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.22, \"learn_time_ms\": 8672.02, \"total_train_time_s\": 9.488207340240479}", "{\"n\": 2597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.55, \"learn_time_ms\": 8956.762, \"total_train_time_s\": 11.937758207321167}", "{\"n\": 2598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.37, \"learn_time_ms\": 8857.639, \"total_train_time_s\": 9.791927576065063}", "{\"n\": 2599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.9, \"learn_time_ms\": 8798.606, \"total_train_time_s\": 10.032161712646484}", "{\"n\": 2600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.02, \"learn_time_ms\": 8592.552, \"total_train_time_s\": 8.642932653427124}", "{\"n\": 2601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.52, \"learn_time_ms\": 8647.739, \"total_train_time_s\": 11.116753101348877}", "{\"n\": 2602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.52, \"learn_time_ms\": 8718.585, \"total_train_time_s\": 10.805583715438843}", "{\"n\": 2603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.79, \"learn_time_ms\": 8846.977, \"total_train_time_s\": 10.838051795959473}", "{\"n\": 2604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.43, \"learn_time_ms\": 8906.182, \"total_train_time_s\": 11.297469854354858}", "{\"n\": 2605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.59, \"learn_time_ms\": 9010.933, \"total_train_time_s\": 10.247677564620972}", "{\"n\": 2606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.59, \"learn_time_ms\": 9204.526, \"total_train_time_s\": 11.437450170516968}", "{\"n\": 2607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.35, \"learn_time_ms\": 9124.033, \"total_train_time_s\": 11.146607637405396}", "{\"n\": 2608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.37, \"learn_time_ms\": 9115.19, \"total_train_time_s\": 9.720512628555298}", "{\"n\": 2609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.37, \"learn_time_ms\": 9085.585, \"total_train_time_s\": 9.772804975509644}", "{\"n\": 2610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.75, \"learn_time_ms\": 9357.626, \"total_train_time_s\": 11.367759227752686}", "{\"n\": 2611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.88, \"learn_time_ms\": 9253.958, \"total_train_time_s\": 10.121202230453491}", "{\"n\": 2612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.88, \"learn_time_ms\": 9283.461, \"total_train_time_s\": 11.129421472549438}", "{\"n\": 2613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.85, \"learn_time_ms\": 9088.642, \"total_train_time_s\": 8.89148998260498}", "{\"n\": 2614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.45, \"learn_time_ms\": 8838.635, \"total_train_time_s\": 8.726009130477905}", "{\"n\": 2615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.45, \"learn_time_ms\": 8884.108, \"total_train_time_s\": 10.713237047195435}", "{\"n\": 2616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.38, \"learn_time_ms\": 8871.396, \"total_train_time_s\": 11.34095287322998}", "{\"n\": 2617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.58, \"learn_time_ms\": 8707.121, \"total_train_time_s\": 9.477882623672485}", "{\"n\": 2618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.58, \"learn_time_ms\": 8719.613, \"total_train_time_s\": 9.858796119689941}", "{\"n\": 2619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.13, \"learn_time_ms\": 8941.742, \"total_train_time_s\": 11.990100145339966}", "{\"n\": 2620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.11, \"learn_time_ms\": 8775.115, \"total_train_time_s\": 9.657102346420288}", "{\"n\": 2621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.26, \"learn_time_ms\": 8768.313, \"total_train_time_s\": 9.990831136703491}", "{\"n\": 2622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.28, \"learn_time_ms\": 8559.572, \"total_train_time_s\": 9.070229291915894}", "{\"n\": 2623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.77, \"learn_time_ms\": 8708.117, \"total_train_time_s\": 10.389467477798462}", "{\"n\": 2624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.77, \"learn_time_ms\": 8783.582, \"total_train_time_s\": 9.59629511833191}", "{\"n\": 2625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.42, \"learn_time_ms\": 8641.328, \"total_train_time_s\": 9.290682792663574}", "{\"n\": 2626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.62, \"learn_time_ms\": 8604.825, \"total_train_time_s\": 10.920503854751587}", "{\"n\": 2627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.62, \"learn_time_ms\": 8729.406, \"total_train_time_s\": 10.736533164978027}", "{\"n\": 2628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.59, \"learn_time_ms\": 8830.528, \"total_train_time_s\": 10.892798900604248}", "{\"n\": 2629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.8, \"learn_time_ms\": 8507.571, \"total_train_time_s\": 8.770291328430176}", "{\"n\": 2630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.14, \"learn_time_ms\": 8479.441, \"total_train_time_s\": 9.404043436050415}", "{\"n\": 2631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.54, \"learn_time_ms\": 8455.529, \"total_train_time_s\": 9.846893548965454}", "{\"n\": 2632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.55, \"learn_time_ms\": 8610.196, \"total_train_time_s\": 10.601023197174072}", "{\"n\": 2633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.65, \"learn_time_ms\": 8593.325, \"total_train_time_s\": 10.150527238845825}", "{\"n\": 2634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.02, \"learn_time_ms\": 8698.977, \"total_train_time_s\": 10.740290641784668}", "{\"n\": 2635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.39, \"learn_time_ms\": 8734.837, \"total_train_time_s\": 9.660691738128662}", "{\"n\": 2636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.08, \"learn_time_ms\": 8706.112, \"total_train_time_s\": 10.65430498123169}", "{\"n\": 2637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.76, \"learn_time_ms\": 8672.591, \"total_train_time_s\": 10.434021234512329}", "{\"n\": 2638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.76, \"learn_time_ms\": 8555.239, \"total_train_time_s\": 9.677592277526855}", "{\"n\": 2639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.76, \"learn_time_ms\": 8713.044, \"total_train_time_s\": 10.31122875213623}", "{\"n\": 2640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.55, \"learn_time_ms\": 8807.953, \"total_train_time_s\": 10.33760118484497}", "{\"n\": 2641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.91, \"learn_time_ms\": 8795.518, \"total_train_time_s\": 9.653728723526001}", "{\"n\": 2642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.04, \"learn_time_ms\": 8668.711, \"total_train_time_s\": 9.352388620376587}", "{\"n\": 2643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.36, \"learn_time_ms\": 8731.607, \"total_train_time_s\": 10.841496467590332}", "{\"n\": 2644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.85, \"learn_time_ms\": 8687.895, \"total_train_time_s\": 10.15829849243164}", "{\"n\": 2645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.25, \"learn_time_ms\": 8810.34, \"total_train_time_s\": 10.878550291061401}", "{\"n\": 2646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.96, \"learn_time_ms\": 8794.836, \"total_train_time_s\": 10.563992977142334}", "{\"n\": 2647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.82, \"learn_time_ms\": 8805.897, \"total_train_time_s\": 10.55262017250061}", "{\"n\": 2648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.04, \"learn_time_ms\": 8844.649, \"total_train_time_s\": 10.118603706359863}", "{\"n\": 2649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.04, \"learn_time_ms\": 8929.271, \"total_train_time_s\": 11.205983877182007}", "{\"n\": 2650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.06, \"learn_time_ms\": 8924.64, \"total_train_time_s\": 10.306198120117188}", "{\"n\": 2651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.39, \"learn_time_ms\": 8993.012, \"total_train_time_s\": 10.333805799484253}", "{\"n\": 2652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.42, \"learn_time_ms\": 8994.297, \"total_train_time_s\": 9.331150770187378}", "{\"n\": 2653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.41, \"learn_time_ms\": 9104.345, \"total_train_time_s\": 11.932614803314209}", "{\"n\": 2654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.98, \"learn_time_ms\": 9131.502, \"total_train_time_s\": 10.455248594284058}", "{\"n\": 2655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.68, \"learn_time_ms\": 9070.274, \"total_train_time_s\": 10.242921590805054}", "{\"n\": 2656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.32, \"learn_time_ms\": 9161.527, \"total_train_time_s\": 11.403420448303223}", "{\"n\": 2657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.89, \"learn_time_ms\": 9081.079, \"total_train_time_s\": 9.702168703079224}", "{\"n\": 2658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.89, \"learn_time_ms\": 9171.747, \"total_train_time_s\": 10.967336893081665}", "{\"n\": 2659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.08, \"learn_time_ms\": 9125.61, \"total_train_time_s\": 10.74956226348877}", "{\"n\": 2660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.08, \"learn_time_ms\": 9073.76, \"total_train_time_s\": 9.746428489685059}", "{\"n\": 2661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.73, \"learn_time_ms\": 9200.709, \"total_train_time_s\": 11.599690914154053}", "{\"n\": 2662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.05, \"learn_time_ms\": 9337.724, \"total_train_time_s\": 10.761176824569702}", "{\"n\": 2663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.96, \"learn_time_ms\": 9216.235, \"total_train_time_s\": 10.744097471237183}", "{\"n\": 2664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.27, \"learn_time_ms\": 9288.624, \"total_train_time_s\": 11.163820505142212}", "{\"n\": 2665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.27, \"learn_time_ms\": 9401.184, \"total_train_time_s\": 11.379358053207397}", "{\"n\": 2666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.81, \"learn_time_ms\": 9249.386, \"total_train_time_s\": 9.89389967918396}", "{\"n\": 2667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.64, \"learn_time_ms\": 9224.5, \"total_train_time_s\": 9.463934659957886}", "{\"n\": 2668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.2, \"learn_time_ms\": 9190.349, \"total_train_time_s\": 10.618181943893433}", "{\"n\": 2669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.85, \"learn_time_ms\": 9099.351, \"total_train_time_s\": 9.823485374450684}", "{\"n\": 2670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.61, \"learn_time_ms\": 9097.991, \"total_train_time_s\": 9.75394344329834}", "{\"n\": 2671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.48, \"learn_time_ms\": 8924.08, \"total_train_time_s\": 9.892341375350952}", "{\"n\": 2672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.41, \"learn_time_ms\": 8896.558, \"total_train_time_s\": 10.484374046325684}", "{\"n\": 2673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.05, \"learn_time_ms\": 8864.034, \"total_train_time_s\": 10.376808404922485}", "{\"n\": 2674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.88, \"learn_time_ms\": 8772.507, \"total_train_time_s\": 10.233541011810303}", "{\"n\": 2675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 8659.168, \"total_train_time_s\": 10.257645845413208}", "{\"n\": 2676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.14, \"learn_time_ms\": 8711.27, \"total_train_time_s\": 10.386543989181519}", "{\"n\": 2677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.16, \"learn_time_ms\": 8963.109, \"total_train_time_s\": 11.990061283111572}", "{\"n\": 2678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.31, \"learn_time_ms\": 9008.429, \"total_train_time_s\": 11.045001029968262}", "{\"n\": 2679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.77, \"learn_time_ms\": 9035.688, \"total_train_time_s\": 10.06546688079834}", "{\"n\": 2680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.16, \"learn_time_ms\": 8876.978, \"total_train_time_s\": 8.14730191230774}", "{\"n\": 2681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.94, \"learn_time_ms\": 8867.415, \"total_train_time_s\": 9.839710235595703}", "{\"n\": 2682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.13, \"learn_time_ms\": 8954.068, \"total_train_time_s\": 11.349747896194458}", "{\"n\": 2683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.13, \"learn_time_ms\": 8935.808, \"total_train_time_s\": 10.18373155593872}", "{\"n\": 2684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.22, \"learn_time_ms\": 8970.663, \"total_train_time_s\": 10.588590145111084}", "{\"n\": 2685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.33, \"learn_time_ms\": 8887.003, \"total_train_time_s\": 9.450715780258179}", "{\"n\": 2686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.64, \"learn_time_ms\": 8785.382, \"total_train_time_s\": 9.411946773529053}", "{\"n\": 2687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.16, \"learn_time_ms\": 8471.719, \"total_train_time_s\": 8.898610591888428}", "{\"n\": 2688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.83, \"learn_time_ms\": 8358.782, \"total_train_time_s\": 9.931326627731323}", "{\"n\": 2689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.1, \"learn_time_ms\": 8319.678, \"total_train_time_s\": 9.680389642715454}", "{\"n\": 2690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.49, \"learn_time_ms\": 8565.558, \"total_train_time_s\": 10.611775398254395}", "{\"n\": 2691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.91, \"learn_time_ms\": 8686.887, \"total_train_time_s\": 10.986530780792236}", "{\"n\": 2692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.96, \"learn_time_ms\": 8538.239, \"total_train_time_s\": 9.993692636489868}", "{\"n\": 2693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.0, \"learn_time_ms\": 8560.706, \"total_train_time_s\": 10.430310010910034}", "{\"n\": 2694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.46, \"learn_time_ms\": 8542.685, \"total_train_time_s\": 10.455878257751465}", "{\"n\": 2695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.97, \"learn_time_ms\": 8590.346, \"total_train_time_s\": 9.877437829971313}", "{\"n\": 2696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.34, \"learn_time_ms\": 8845.436, \"total_train_time_s\": 11.94292402267456}", "{\"n\": 2697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.16, \"learn_time_ms\": 9096.872, \"total_train_time_s\": 11.38698148727417}", "{\"n\": 2698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.64, \"learn_time_ms\": 9001.977, \"total_train_time_s\": 9.08086371421814}", "{\"n\": 2699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.64, \"learn_time_ms\": 9108.819, \"total_train_time_s\": 10.810166120529175}", "{\"n\": 2700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.35, \"learn_time_ms\": 8914.146, \"total_train_time_s\": 8.701318264007568}", "{\"n\": 2701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.97, \"learn_time_ms\": 8940.184, \"total_train_time_s\": 11.273193597793579}", "{\"n\": 2702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.02, \"learn_time_ms\": 9009.816, \"total_train_time_s\": 10.507293939590454}", "{\"n\": 2703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.54, \"learn_time_ms\": 8986.879, \"total_train_time_s\": 10.186567306518555}", "{\"n\": 2704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.59, \"learn_time_ms\": 8914.098, \"total_train_time_s\": 9.729941844940186}", "{\"n\": 2705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.68, \"learn_time_ms\": 8981.342, \"total_train_time_s\": 10.589169979095459}", "{\"n\": 2706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.66, \"learn_time_ms\": 8820.7, \"total_train_time_s\": 10.352596282958984}", "{\"n\": 2707, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.17, \"learn_time_ms\": 8763.333, \"total_train_time_s\": 10.793461084365845}", "{\"n\": 2708, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.97, \"learn_time_ms\": 9033.621, \"total_train_time_s\": 11.77867841720581}", "{\"n\": 2709, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.97, \"learn_time_ms\": 8986.832, \"total_train_time_s\": 10.271379947662354}", "{\"n\": 2710, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.08, \"learn_time_ms\": 9295.868, \"total_train_time_s\": 11.807326793670654}", "{\"n\": 2711, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.49, \"learn_time_ms\": 9157.778, \"total_train_time_s\": 9.895029544830322}", "{\"n\": 2712, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.49, \"learn_time_ms\": 9255.724, \"total_train_time_s\": 11.505345821380615}", "{\"n\": 2713, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3197.56, \"learn_time_ms\": 9256.984, \"total_train_time_s\": 10.174274921417236}", "{\"n\": 2714, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3202.07, \"learn_time_ms\": 9238.914, \"total_train_time_s\": 9.48400330543518}", "{\"n\": 2715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3202.07, \"learn_time_ms\": 9282.452, \"total_train_time_s\": 10.95673155784607}", "{\"n\": 2716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3200.98, \"learn_time_ms\": 9170.755, \"total_train_time_s\": 9.201971054077148}", "{\"n\": 2717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.43, \"learn_time_ms\": 9121.119, \"total_train_time_s\": 10.289365768432617}", "{\"n\": 2718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.43, \"learn_time_ms\": 9106.884, \"total_train_time_s\": 11.565649509429932}", "{\"n\": 2719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3200.24, \"learn_time_ms\": 9131.067, \"total_train_time_s\": 10.545046091079712}", "{\"n\": 2720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3195.53, \"learn_time_ms\": 8950.195, \"total_train_time_s\": 10.041227579116821}", "{\"n\": 2721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3195.39, \"learn_time_ms\": 8868.436, \"total_train_time_s\": 9.033299684524536}", "{\"n\": 2722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.95, \"learn_time_ms\": 8757.723, \"total_train_time_s\": 10.421178579330444}", "{\"n\": 2723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.31, \"learn_time_ms\": 8707.746, \"total_train_time_s\": 9.715108394622803}", "{\"n\": 2724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3199.23, \"learn_time_ms\": 8782.265, \"total_train_time_s\": 10.263394355773926}", "{\"n\": 2725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3199.58, \"learn_time_ms\": 8652.89, \"total_train_time_s\": 9.73180866241455}", "{\"n\": 2726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3199.25, \"learn_time_ms\": 8711.381, \"total_train_time_s\": 9.819345712661743}", "{\"n\": 2727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3198.26, \"learn_time_ms\": 8716.225, \"total_train_time_s\": 10.328482151031494}", "{\"n\": 2728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3195.68, \"learn_time_ms\": 8543.463, \"total_train_time_s\": 9.849263668060303}", "{\"n\": 2729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3187.48, \"learn_time_ms\": 8573.527, \"total_train_time_s\": 10.839016199111938}", "{\"n\": 2730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3187.0, \"learn_time_ms\": 8679.289, \"total_train_time_s\": 11.028825521469116}", "{\"n\": 2731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3185.77, \"learn_time_ms\": 8868.12, \"total_train_time_s\": 10.9212646484375}", "{\"n\": 2732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3185.77, \"learn_time_ms\": 8877.945, \"total_train_time_s\": 10.529840469360352}", "{\"n\": 2733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3187.7, \"learn_time_ms\": 8963.089, \"total_train_time_s\": 10.566079378128052}", "{\"n\": 2734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3184.9, \"learn_time_ms\": 8904.539, \"total_train_time_s\": 9.64393925666809}", "{\"n\": 2735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3184.9, \"learn_time_ms\": 9061.404, \"total_train_time_s\": 11.24710750579834}", "{\"n\": 2736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 9188.535, \"total_train_time_s\": 11.034645557403564}", "{\"n\": 2737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3187.27, \"learn_time_ms\": 9229.756, \"total_train_time_s\": 10.740558624267578}", "{\"n\": 2738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3189.37, \"learn_time_ms\": 9261.342, \"total_train_time_s\": 10.174172639846802}", "{\"n\": 2739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3191.68, \"learn_time_ms\": 9182.328, \"total_train_time_s\": 10.049799680709839}", "{\"n\": 2740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3196.32, \"learn_time_ms\": 9088.699, \"total_train_time_s\": 10.05631422996521}", "{\"n\": 2741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3194.26, \"learn_time_ms\": 8997.809, \"total_train_time_s\": 10.012928247451782}", "{\"n\": 2742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3190.57, \"learn_time_ms\": 8953.619, \"total_train_time_s\": 10.051000833511353}", "{\"n\": 2743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3194.52, \"learn_time_ms\": 8889.464, \"total_train_time_s\": 9.9461350440979}", "{\"n\": 2744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3193.7, \"learn_time_ms\": 8870.691, \"total_train_time_s\": 9.49947714805603}", "{\"n\": 2745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3193.59, \"learn_time_ms\": 8917.102, \"total_train_time_s\": 11.756910562515259}", "{\"n\": 2746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3198.23, \"learn_time_ms\": 9028.143, \"total_train_time_s\": 12.260862350463867}", "{\"n\": 2747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.26, \"learn_time_ms\": 8982.095, \"total_train_time_s\": 10.29951810836792}", "{\"n\": 2748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.28, \"learn_time_ms\": 8985.029, \"total_train_time_s\": 10.216350793838501}", "{\"n\": 2749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.05, \"learn_time_ms\": 9155.877, \"total_train_time_s\": 11.736773014068604}", "{\"n\": 2750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.05, \"learn_time_ms\": 9114.945, \"total_train_time_s\": 9.677169799804688}", "{\"n\": 2751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3212.04, \"learn_time_ms\": 9090.417, \"total_train_time_s\": 9.755279541015625}", "{\"n\": 2752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.08, \"learn_time_ms\": 9027.829, \"total_train_time_s\": 9.46366834640503}", "{\"n\": 2753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.08, \"learn_time_ms\": 9006.028, \"total_train_time_s\": 9.669774055480957}", "{\"n\": 2754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3209.57, \"learn_time_ms\": 9202.364, \"total_train_time_s\": 11.468371152877808}", "{\"n\": 2755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3208.16, \"learn_time_ms\": 8998.192, \"total_train_time_s\": 9.689774751663208}", "{\"n\": 2756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3208.16, \"learn_time_ms\": 8877.89, \"total_train_time_s\": 10.96862268447876}", "{\"n\": 2757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3207.2, \"learn_time_ms\": 8881.266, \"total_train_time_s\": 10.301674127578735}", "{\"n\": 2758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.64, \"learn_time_ms\": 9023.237, \"total_train_time_s\": 11.597684860229492}", "{\"n\": 2759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 8762.31, \"total_train_time_s\": 9.179187774658203}", "{\"n\": 2760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3211.64, \"learn_time_ms\": 8884.489, \"total_train_time_s\": 10.90585470199585}", "{\"n\": 2761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3215.4, \"learn_time_ms\": 8814.027, \"total_train_time_s\": 9.093648910522461}", "{\"n\": 2762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3219.9, \"learn_time_ms\": 8938.573, \"total_train_time_s\": 10.609442234039307}", "{\"n\": 2763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3225.18, \"learn_time_ms\": 8980.161, \"total_train_time_s\": 10.146094799041748}", "{\"n\": 2764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3234.0, \"learn_time_ms\": 8810.322, \"total_train_time_s\": 9.770528793334961}", "{\"n\": 2765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.5, \"learn_time_ms\": 8797.536, \"total_train_time_s\": 9.54178237915039}", "{\"n\": 2766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.5, \"learn_time_ms\": 8859.841, \"total_train_time_s\": 11.61863112449646}", "{\"n\": 2767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.95, \"learn_time_ms\": 8751.805, \"total_train_time_s\": 9.2812819480896}", "{\"n\": 2768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.47, \"learn_time_ms\": 8664.469, \"total_train_time_s\": 10.728178262710571}", "{\"n\": 2769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.47, \"learn_time_ms\": 8882.59, \"total_train_time_s\": 11.303202867507935}", "{\"n\": 2770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3228.95, \"learn_time_ms\": 8934.666, \"total_train_time_s\": 11.389811992645264}", "{\"n\": 2771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3234.87, \"learn_time_ms\": 8945.031, \"total_train_time_s\": 9.20523190498352}", "{\"n\": 2772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3234.87, \"learn_time_ms\": 8930.236, \"total_train_time_s\": 10.52876353263855}", "{\"n\": 2773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3234.73, \"learn_time_ms\": 8824.252, \"total_train_time_s\": 9.139055967330933}", "{\"n\": 2774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3241.74, \"learn_time_ms\": 8886.558, \"total_train_time_s\": 10.462865352630615}", "{\"n\": 2775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3246.44, \"learn_time_ms\": 8954.415, \"total_train_time_s\": 10.31080961227417}", "{\"n\": 2776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3242.92, \"learn_time_ms\": 8747.488, \"total_train_time_s\": 9.56680965423584}", "{\"n\": 2777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3243.54, \"learn_time_ms\": 8862.245, \"total_train_time_s\": 10.411938905715942}", "{\"n\": 2778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.04, \"learn_time_ms\": 8852.066, \"total_train_time_s\": 10.609618902206421}", "{\"n\": 2779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.14, \"learn_time_ms\": 8785.661, \"total_train_time_s\": 10.656415700912476}", "{\"n\": 2780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3232.13, \"learn_time_ms\": 8721.392, \"total_train_time_s\": 10.785524606704712}", "{\"n\": 2781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.96, \"learn_time_ms\": 8736.028, \"total_train_time_s\": 9.366492509841919}", "{\"n\": 2782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.96, \"learn_time_ms\": 8589.672, \"total_train_time_s\": 9.045576810836792}", "{\"n\": 2783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.3, \"learn_time_ms\": 8713.38, \"total_train_time_s\": 10.270922422409058}", "{\"n\": 2784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.3, \"learn_time_ms\": 8648.336, \"total_train_time_s\": 9.768778800964355}", "{\"n\": 2785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3233.88, \"learn_time_ms\": 8625.572, \"total_train_time_s\": 10.02394437789917}", "{\"n\": 2786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 8705.103, \"total_train_time_s\": 10.345617771148682}", "{\"n\": 2787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3241.18, \"learn_time_ms\": 8725.851, \"total_train_time_s\": 10.597480535507202}", "{\"n\": 2788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3245.02, \"learn_time_ms\": 8641.812, \"total_train_time_s\": 9.793813943862915}", "{\"n\": 2789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3241.46, \"learn_time_ms\": 8687.005, \"total_train_time_s\": 11.130624771118164}", "{\"n\": 2790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3244.62, \"learn_time_ms\": 8588.719, \"total_train_time_s\": 9.819252967834473}", "{\"n\": 2791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3239.34, \"learn_time_ms\": 8544.537, \"total_train_time_s\": 8.899170637130737}", "{\"n\": 2792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3240.35, \"learn_time_ms\": 8736.576, \"total_train_time_s\": 10.94787859916687}", "{\"n\": 2793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.56, \"learn_time_ms\": 8772.368, \"total_train_time_s\": 10.666501760482788}", "{\"n\": 2794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.94, \"learn_time_ms\": 8713.402, \"total_train_time_s\": 9.13938856124878}", "{\"n\": 2795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.69, \"learn_time_ms\": 8739.111, \"total_train_time_s\": 10.254801511764526}", "{\"n\": 2796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.63, \"learn_time_ms\": 8654.195, \"total_train_time_s\": 9.483699560165405}", "{\"n\": 2797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.5, \"learn_time_ms\": 8687.563, \"total_train_time_s\": 10.918972492218018}", "{\"n\": 2798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.5, \"learn_time_ms\": 8654.429, \"total_train_time_s\": 9.44149899482727}", "{\"n\": 2799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.92, \"learn_time_ms\": 8652.38, \"total_train_time_s\": 11.119773626327515}", "{\"n\": 2800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.64, \"learn_time_ms\": 8666.548, \"total_train_time_s\": 9.979065895080566}", "{\"n\": 2801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.38, \"learn_time_ms\": 8875.228, \"total_train_time_s\": 11.049025297164917}", "{\"n\": 2802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.38, \"learn_time_ms\": 8856.841, \"total_train_time_s\": 10.778971433639526}", "{\"n\": 2803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.06, \"learn_time_ms\": 8776.69, \"total_train_time_s\": 9.886077880859375}", "{\"n\": 2804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.14, \"learn_time_ms\": 8944.486, \"total_train_time_s\": 10.874025106430054}", "{\"n\": 2805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.14, \"learn_time_ms\": 8961.031, \"total_train_time_s\": 10.438754081726074}", "{\"n\": 2806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.37, \"learn_time_ms\": 8992.979, \"total_train_time_s\": 9.809022188186646}", "{\"n\": 2807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.35, \"learn_time_ms\": 9067.612, \"total_train_time_s\": 11.688451766967773}", "{\"n\": 2808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.35, \"learn_time_ms\": 9004.418, \"total_train_time_s\": 8.811790704727173}", "{\"n\": 2809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.82, \"learn_time_ms\": 8844.583, \"total_train_time_s\": 9.502963066101074}", "{\"n\": 2810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.62, \"learn_time_ms\": 8876.806, \"total_train_time_s\": 10.289844274520874}", "{\"n\": 2811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.74, \"learn_time_ms\": 8854.596, \"total_train_time_s\": 10.77715277671814}", "{\"n\": 2812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.43, \"learn_time_ms\": 8678.119, \"total_train_time_s\": 9.061322450637817}", "{\"n\": 2813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.82, \"learn_time_ms\": 8706.774, \"total_train_time_s\": 10.153988122940063}", "{\"n\": 2814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.6, \"learn_time_ms\": 8707.384, \"total_train_time_s\": 10.794096231460571}", "{\"n\": 2815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.44, \"learn_time_ms\": 8652.319, \"total_train_time_s\": 9.895511865615845}", "{\"n\": 2816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.37, \"learn_time_ms\": 8712.708, \"total_train_time_s\": 10.401933908462524}", "{\"n\": 2817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.83, \"learn_time_ms\": 8557.132, \"total_train_time_s\": 10.15210485458374}", "{\"n\": 2818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.11, \"learn_time_ms\": 8753.791, \"total_train_time_s\": 10.830284357070923}", "{\"n\": 2819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.11, \"learn_time_ms\": 9010.694, \"total_train_time_s\": 12.085296392440796}", "{\"n\": 2820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.81, \"learn_time_ms\": 9220.246, \"total_train_time_s\": 12.37761664390564}", "{\"n\": 2821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.81, \"learn_time_ms\": 9298.655, \"total_train_time_s\": 11.509843587875366}", "{\"n\": 2822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.15, \"learn_time_ms\": 9502.256, \"total_train_time_s\": 11.105865001678467}", "{\"n\": 2823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.48, \"learn_time_ms\": 9569.5, \"total_train_time_s\": 10.831592321395874}", "{\"n\": 2824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.81, \"learn_time_ms\": 9557.174, \"total_train_time_s\": 10.726867437362671}", "{\"n\": 2825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.11, \"learn_time_ms\": 9607.886, \"total_train_time_s\": 10.38879656791687}", "{\"n\": 2826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.48, \"learn_time_ms\": 9624.138, \"total_train_time_s\": 10.571308612823486}", "{\"n\": 2827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.67, \"learn_time_ms\": 9693.342, \"total_train_time_s\": 10.843157768249512}", "{\"n\": 2828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.86, \"learn_time_ms\": 9686.225, \"total_train_time_s\": 10.705580949783325}", "{\"n\": 2829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.43, \"learn_time_ms\": 9553.949, \"total_train_time_s\": 10.757846117019653}", "{\"n\": 2830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.61, \"learn_time_ms\": 9283.29, \"total_train_time_s\": 9.639670610427856}", "{\"n\": 2831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.61, \"learn_time_ms\": 9162.583, \"total_train_time_s\": 10.384426355361938}", "{\"n\": 2832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.27, \"learn_time_ms\": 9078.432, \"total_train_time_s\": 10.264965295791626}", "{\"n\": 2833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.01, \"learn_time_ms\": 8984.016, \"total_train_time_s\": 9.874109506607056}", "{\"n\": 2834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.01, \"learn_time_ms\": 8786.04, \"total_train_time_s\": 8.685543298721313}", "{\"n\": 2835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.91, \"learn_time_ms\": 8736.127, \"total_train_time_s\": 9.914273738861084}", "{\"n\": 2836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.03, \"learn_time_ms\": 8626.369, \"total_train_time_s\": 9.448662042617798}", "{\"n\": 2837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.85, \"learn_time_ms\": 8446.119, \"total_train_time_s\": 9.029379606246948}", "{\"n\": 2838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.48, \"learn_time_ms\": 8576.219, \"total_train_time_s\": 12.020503997802734}", "{\"n\": 2839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.82, \"learn_time_ms\": 8496.304, \"total_train_time_s\": 9.929082870483398}", "{\"n\": 2840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.47, \"learn_time_ms\": 8647.396, \"total_train_time_s\": 11.15051794052124}", "{\"n\": 2841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.44, \"learn_time_ms\": 8536.335, \"total_train_time_s\": 9.23521614074707}", "{\"n\": 2842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.96, \"learn_time_ms\": 8459.52, \"total_train_time_s\": 9.432723999023438}", "{\"n\": 2843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.69, \"learn_time_ms\": 8422.419, \"total_train_time_s\": 9.487301349639893}", "{\"n\": 2844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.69, \"learn_time_ms\": 8560.343, \"total_train_time_s\": 10.099584817886353}", "{\"n\": 2845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.33, \"learn_time_ms\": 8706.422, \"total_train_time_s\": 11.34801459312439}", "{\"n\": 2846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 8735.65, \"total_train_time_s\": 9.803669691085815}", "{\"n\": 2847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.38, \"learn_time_ms\": 8936.615, \"total_train_time_s\": 11.027737855911255}", "{\"n\": 2848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.93, \"learn_time_ms\": 8800.216, \"total_train_time_s\": 10.682446241378784}", "{\"n\": 2849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.45, \"learn_time_ms\": 8803.77, \"total_train_time_s\": 10.02278447151184}", "{\"n\": 2850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.47, \"learn_time_ms\": 8715.466, \"total_train_time_s\": 10.253308773040771}", "{\"n\": 2851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.98, \"learn_time_ms\": 8985.197, \"total_train_time_s\": 11.92435884475708}", "{\"n\": 2852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.82, \"learn_time_ms\": 9020.989, \"total_train_time_s\": 9.801419973373413}", "{\"n\": 2853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.15, \"learn_time_ms\": 9088.609, \"total_train_time_s\": 10.097631216049194}", "{\"n\": 2854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.33, \"learn_time_ms\": 9057.141, \"total_train_time_s\": 9.76155948638916}", "{\"n\": 2855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.8, \"learn_time_ms\": 8871.578, \"total_train_time_s\": 9.474475860595703}", "{\"n\": 2856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.43, \"learn_time_ms\": 8931.5, \"total_train_time_s\": 10.374969005584717}", "{\"n\": 2857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.43, \"learn_time_ms\": 8826.028, \"total_train_time_s\": 9.998450994491577}", "{\"n\": 2858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.32, \"learn_time_ms\": 8636.683, \"total_train_time_s\": 8.79554271697998}", "{\"n\": 2859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.5, \"learn_time_ms\": 8759.411, \"total_train_time_s\": 11.21364712715149}", "{\"n\": 2860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.5, \"learn_time_ms\": 8697.526, \"total_train_time_s\": 9.661606311798096}", "{\"n\": 2861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.87, \"learn_time_ms\": 8574.502, \"total_train_time_s\": 10.706907987594604}", "{\"n\": 2862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.17, \"learn_time_ms\": 8660.6, \"total_train_time_s\": 10.684554815292358}", "{\"n\": 2863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.17, \"learn_time_ms\": 8708.538, \"total_train_time_s\": 10.669428825378418}", "{\"n\": 2864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3234.56, \"learn_time_ms\": 8758.974, \"total_train_time_s\": 10.305169343948364}", "{\"n\": 2865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.44, \"learn_time_ms\": 8850.127, \"total_train_time_s\": 10.426930904388428}", "{\"n\": 2866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.44, \"learn_time_ms\": 8920.323, \"total_train_time_s\": 11.058297157287598}", "{\"n\": 2867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.81, \"learn_time_ms\": 9085.603, \"total_train_time_s\": 11.620505809783936}", "{\"n\": 2868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.71, \"learn_time_ms\": 9176.908, \"total_train_time_s\": 9.686633110046387}", "{\"n\": 2869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.57, \"learn_time_ms\": 8995.242, \"total_train_time_s\": 9.407772302627563}", "{\"n\": 2870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.56, \"learn_time_ms\": 9026.974, \"total_train_time_s\": 9.96275520324707}", "{\"n\": 2871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.56, \"learn_time_ms\": 8980.948, \"total_train_time_s\": 10.229140996932983}", "{\"n\": 2872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.21, \"learn_time_ms\": 8868.737, \"total_train_time_s\": 9.567081928253174}", "{\"n\": 2873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.33, \"learn_time_ms\": 8937.672, \"total_train_time_s\": 11.342802286148071}", "{\"n\": 2874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.33, \"learn_time_ms\": 8890.421, \"total_train_time_s\": 9.852249383926392}", "{\"n\": 2875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.13, \"learn_time_ms\": 8838.022, \"total_train_time_s\": 9.915015459060669}", "{\"n\": 2876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.13, \"learn_time_ms\": 8862.712, \"total_train_time_s\": 11.326445579528809}", "{\"n\": 2877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.04, \"learn_time_ms\": 8714.689, \"total_train_time_s\": 10.14798378944397}", "{\"n\": 2878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.2, \"learn_time_ms\": 8637.201, \"total_train_time_s\": 8.874724626541138}", "{\"n\": 2879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.68, \"learn_time_ms\": 8753.929, \"total_train_time_s\": 10.542286396026611}", "{\"n\": 2880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.92, \"learn_time_ms\": 8751.895, \"total_train_time_s\": 9.979734897613525}", "{\"n\": 2881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.14, \"learn_time_ms\": 8790.095, \"total_train_time_s\": 10.628696918487549}", "{\"n\": 2882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.17, \"learn_time_ms\": 8779.899, \"total_train_time_s\": 9.446527242660522}", "{\"n\": 2883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.5, \"learn_time_ms\": 8655.842, \"total_train_time_s\": 10.07563328742981}", "{\"n\": 2884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.5, \"learn_time_ms\": 8693.953, \"total_train_time_s\": 10.207139492034912}", "{\"n\": 2885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.38, \"learn_time_ms\": 8843.124, \"total_train_time_s\": 11.396628141403198}", "{\"n\": 2886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.41, \"learn_time_ms\": 8646.85, \"total_train_time_s\": 9.35094928741455}", "{\"n\": 2887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.33, \"learn_time_ms\": 8792.475, \"total_train_time_s\": 11.614071607589722}", "{\"n\": 2888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.59, \"learn_time_ms\": 8939.888, \"total_train_time_s\": 10.362722396850586}", "{\"n\": 2889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.79, \"learn_time_ms\": 8966.97, \"total_train_time_s\": 10.81396770477295}", "{\"n\": 2890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.86, \"learn_time_ms\": 9100.764, \"total_train_time_s\": 11.260615110397339}", "{\"n\": 2891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.83, \"learn_time_ms\": 8906.302, \"total_train_time_s\": 8.642871379852295}", "{\"n\": 2892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.59, \"learn_time_ms\": 8990.735, \"total_train_time_s\": 10.300654649734497}", "{\"n\": 2893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.59, \"learn_time_ms\": 9079.888, \"total_train_time_s\": 11.022649765014648}", "{\"n\": 2894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.16, \"learn_time_ms\": 9076.695, \"total_train_time_s\": 10.164700508117676}", "{\"n\": 2895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.41, \"learn_time_ms\": 9051.432, \"total_train_time_s\": 11.176780700683594}", "{\"n\": 2896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.41, \"learn_time_ms\": 9165.764, \"total_train_time_s\": 10.479681730270386}", "{\"n\": 2897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.08, \"learn_time_ms\": 9124.904, \"total_train_time_s\": 11.212266445159912}", "{\"n\": 2898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.4, \"learn_time_ms\": 9132.503, \"total_train_time_s\": 10.456160545349121}", "{\"n\": 2899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.4, \"learn_time_ms\": 8926.329, \"total_train_time_s\": 8.762290239334106}", "{\"n\": 2900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.15, \"learn_time_ms\": 8788.291, \"total_train_time_s\": 9.914057731628418}", "{\"n\": 2901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.4, \"learn_time_ms\": 8832.028, \"total_train_time_s\": 9.124340772628784}", "{\"n\": 2902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.4, \"learn_time_ms\": 8909.982, \"total_train_time_s\": 11.093249559402466}", "{\"n\": 2903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.27, \"learn_time_ms\": 8856.156, \"total_train_time_s\": 10.465468883514404}", "{\"n\": 2904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.99, \"learn_time_ms\": 8820.653, \"total_train_time_s\": 9.839166402816772}", "{\"n\": 2905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.35, \"learn_time_ms\": 8632.959, \"total_train_time_s\": 9.258498191833496}", "{\"n\": 2906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.38, \"learn_time_ms\": 8553.523, \"total_train_time_s\": 9.75944972038269}", "{\"n\": 2907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.69, \"learn_time_ms\": 8508.69, \"total_train_time_s\": 10.764172554016113}", "{\"n\": 2908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.33, \"learn_time_ms\": 8646.738, \"total_train_time_s\": 11.83484935760498}", "{\"n\": 2909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.33, \"learn_time_ms\": 8743.251, \"total_train_time_s\": 9.697770357131958}", "{\"n\": 2910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.14, \"learn_time_ms\": 8619.136, \"total_train_time_s\": 8.712845087051392}", "{\"n\": 2911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.97, \"learn_time_ms\": 8788.972, \"total_train_time_s\": 10.860027313232422}", "{\"n\": 2912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.97, \"learn_time_ms\": 8743.608, \"total_train_time_s\": 10.620347023010254}", "{\"n\": 2913, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.5, \"learn_time_ms\": 8886.446, \"total_train_time_s\": 11.88387155532837}", "{\"n\": 2914, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.5, \"learn_time_ms\": 8861.907, \"total_train_time_s\": 9.539497375488281}", "{\"n\": 2915, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.46, \"learn_time_ms\": 9039.292, \"total_train_time_s\": 11.022833347320557}", "{\"n\": 2916, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.64, \"learn_time_ms\": 9056.432, \"total_train_time_s\": 9.889030694961548}", "{\"n\": 2917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.48, \"learn_time_ms\": 9012.634, \"total_train_time_s\": 10.309275150299072}", "{\"n\": 2918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.28, \"learn_time_ms\": 8827.77, \"total_train_time_s\": 9.977080583572388}", "{\"n\": 2919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.7, \"learn_time_ms\": 8695.814, \"total_train_time_s\": 8.393074989318848}", "{\"n\": 2920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.71, \"learn_time_ms\": 8849.593, \"total_train_time_s\": 10.19305157661438}", "{\"n\": 2921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.49, \"learn_time_ms\": 8685.155, \"total_train_time_s\": 9.152589559555054}", "{\"n\": 2922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.79, \"learn_time_ms\": 8601.073, \"total_train_time_s\": 9.816564798355103}", "{\"n\": 2923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.7, \"learn_time_ms\": 8473.791, \"total_train_time_s\": 10.621771097183228}", "{\"n\": 2924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.22, \"learn_time_ms\": 8546.33, \"total_train_time_s\": 10.318687438964844}", "{\"n\": 2925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.39, \"learn_time_ms\": 8597.692, \"total_train_time_s\": 11.66173005104065}", "{\"n\": 2926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.04, \"learn_time_ms\": 8574.875, \"total_train_time_s\": 9.660473585128784}", "{\"n\": 2927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.5, \"learn_time_ms\": 8533.961, \"total_train_time_s\": 9.91228985786438}", "{\"n\": 2928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.5, \"learn_time_ms\": 8349.572, \"total_train_time_s\": 8.163203239440918}", "{\"n\": 2929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.29, \"learn_time_ms\": 8566.724, \"total_train_time_s\": 10.585635662078857}", "{\"n\": 2930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.23, \"learn_time_ms\": 8701.946, \"total_train_time_s\": 11.530731916427612}", "{\"n\": 2931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.79, \"learn_time_ms\": 9002.836, \"total_train_time_s\": 12.143073797225952}", "{\"n\": 2932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.39, \"learn_time_ms\": 9181.038, \"total_train_time_s\": 11.590083837509155}", "{\"n\": 2933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.39, \"learn_time_ms\": 9214.349, \"total_train_time_s\": 10.94474172592163}", "{\"n\": 2934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.11, \"learn_time_ms\": 9128.456, \"total_train_time_s\": 9.468535423278809}", "{\"n\": 2935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.14, \"learn_time_ms\": 9069.158, \"total_train_time_s\": 10.941039562225342}", "{\"n\": 2936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.14, \"learn_time_ms\": 9163.191, \"total_train_time_s\": 10.596677303314209}", "{\"n\": 2937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.12, \"learn_time_ms\": 9142.286, \"total_train_time_s\": 9.68186330795288}", "{\"n\": 2938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.22, \"learn_time_ms\": 9329.305, \"total_train_time_s\": 9.982758283615112}", "{\"n\": 2939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.22, \"learn_time_ms\": 9351.117, \"total_train_time_s\": 10.799223184585571}", "{\"n\": 2940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.79, \"learn_time_ms\": 9075.329, \"total_train_time_s\": 8.787471532821655}", "{\"n\": 2941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.0, \"learn_time_ms\": 8913.312, \"total_train_time_s\": 10.561839818954468}", "{\"n\": 2942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.6, \"learn_time_ms\": 8720.764, \"total_train_time_s\": 9.631516933441162}", "{\"n\": 2943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.35, \"learn_time_ms\": 8626.326, \"total_train_time_s\": 10.029855012893677}", "{\"n\": 2944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.79, \"learn_time_ms\": 8679.898, \"total_train_time_s\": 9.953293085098267}", "{\"n\": 2945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.79, \"learn_time_ms\": 8575.31, \"total_train_time_s\": 9.892569065093994}", "{\"n\": 2946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.22, \"learn_time_ms\": 8643.976, \"total_train_time_s\": 11.268275022506714}", "{\"n\": 2947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.22, \"learn_time_ms\": 8637.661, \"total_train_time_s\": 9.622032165527344}", "{\"n\": 2948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.3, \"learn_time_ms\": 8635.716, \"total_train_time_s\": 9.98014521598816}", "{\"n\": 2949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.53, \"learn_time_ms\": 8552.381, \"total_train_time_s\": 9.960464477539062}", "{\"n\": 2950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.31, \"learn_time_ms\": 8825.781, \"total_train_time_s\": 11.524649381637573}", "{\"n\": 2951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.31, \"learn_time_ms\": 8801.866, \"total_train_time_s\": 10.275794982910156}", "{\"n\": 2952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.57, \"learn_time_ms\": 8925.109, \"total_train_time_s\": 10.874098777770996}", "{\"n\": 2953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.94, \"learn_time_ms\": 8917.088, \"total_train_time_s\": 9.867492914199829}", "{\"n\": 2954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.19, \"learn_time_ms\": 9014.286, \"total_train_time_s\": 10.932935237884521}", "{\"n\": 2955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.7, \"learn_time_ms\": 9153.257, \"total_train_time_s\": 11.293880224227905}", "{\"n\": 2956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.11, \"learn_time_ms\": 9088.287, \"total_train_time_s\": 10.603717565536499}", "{\"n\": 2957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.75, \"learn_time_ms\": 8990.648, \"total_train_time_s\": 8.689223766326904}", "{\"n\": 2958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.75, \"learn_time_ms\": 9040.185, \"total_train_time_s\": 10.477417945861816}", "{\"n\": 2959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.27, \"learn_time_ms\": 9100.297, \"total_train_time_s\": 10.595829486846924}", "{\"n\": 2960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.45, \"learn_time_ms\": 8888.066, \"total_train_time_s\": 9.417044878005981}", "{\"n\": 2961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.45, \"learn_time_ms\": 8993.475, \"total_train_time_s\": 11.362746715545654}", "{\"n\": 2962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.99, \"learn_time_ms\": 8793.634, \"total_train_time_s\": 8.857686042785645}", "{\"n\": 2963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.31, \"learn_time_ms\": 8757.624, \"total_train_time_s\": 9.557378053665161}", "{\"n\": 2964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.31, \"learn_time_ms\": 8700.775, \"total_train_time_s\": 10.32449722290039}", "{\"n\": 2965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.77, \"learn_time_ms\": 8498.805, \"total_train_time_s\": 9.29422926902771}", "{\"n\": 2966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.92, \"learn_time_ms\": 8441.753, \"total_train_time_s\": 10.040233135223389}", "{\"n\": 2967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.92, \"learn_time_ms\": 8701.153, \"total_train_time_s\": 11.236038208007812}", "{\"n\": 2968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.75, \"learn_time_ms\": 8735.528, \"total_train_time_s\": 10.863228797912598}", "{\"n\": 2969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.04, \"learn_time_ms\": 8588.534, \"total_train_time_s\": 9.104421854019165}", "{\"n\": 2970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.48, \"learn_time_ms\": 8691.856, \"total_train_time_s\": 10.423058032989502}", "{\"n\": 2971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.18, \"learn_time_ms\": 8603.984, \"total_train_time_s\": 10.493144035339355}", "{\"n\": 2972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.44, \"learn_time_ms\": 8928.634, \"total_train_time_s\": 12.107093572616577}", "{\"n\": 2973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.3, \"learn_time_ms\": 8874.838, \"total_train_time_s\": 9.013414144515991}", "{\"n\": 2974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.3, \"learn_time_ms\": 8769.99, \"total_train_time_s\": 9.342432737350464}", "{\"n\": 2975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.53, \"learn_time_ms\": 9005.045, \"total_train_time_s\": 11.643538236618042}", "{\"n\": 2976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.1, \"learn_time_ms\": 9110.598, \"total_train_time_s\": 11.15141773223877}", "{\"n\": 2977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.49, \"learn_time_ms\": 9057.836, \"total_train_time_s\": 10.736055374145508}", "{\"n\": 2978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.49, \"learn_time_ms\": 9025.151, \"total_train_time_s\": 10.504111051559448}", "{\"n\": 2979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.7, \"learn_time_ms\": 9170.409, \"total_train_time_s\": 10.546461820602417}", "{\"n\": 2980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.31, \"learn_time_ms\": 9023.698, \"total_train_time_s\": 8.978223323822021}", "{\"n\": 2981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.31, \"learn_time_ms\": 9008.401, \"total_train_time_s\": 10.345210790634155}", "{\"n\": 2982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.39, \"learn_time_ms\": 8730.507, \"total_train_time_s\": 9.376921653747559}", "{\"n\": 2983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.83, \"learn_time_ms\": 8983.093, \"total_train_time_s\": 11.569006204605103}", "{\"n\": 2984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.83, \"learn_time_ms\": 8982.305, \"total_train_time_s\": 9.29206109046936}", "{\"n\": 2985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.93, \"learn_time_ms\": 8887.239, \"total_train_time_s\": 10.688965082168579}", "{\"n\": 2986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.96, \"learn_time_ms\": 8932.416, \"total_train_time_s\": 11.574854373931885}", "{\"n\": 2987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.96, \"learn_time_ms\": 8847.451, \"total_train_time_s\": 9.854682207107544}", "{\"n\": 2988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.98, \"learn_time_ms\": 8872.839, \"total_train_time_s\": 10.76284670829773}", "{\"n\": 2989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.09, \"learn_time_ms\": 8738.014, \"total_train_time_s\": 9.209814310073853}", "{\"n\": 2990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.54, \"learn_time_ms\": 8862.903, \"total_train_time_s\": 10.262389183044434}", "{\"n\": 2991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.54, \"learn_time_ms\": 8844.718, \"total_train_time_s\": 10.175270318984985}", "{\"n\": 2992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.73, \"learn_time_ms\": 9014.106, \"total_train_time_s\": 11.049931526184082}", "{\"n\": 2993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.43, \"learn_time_ms\": 8824.342, \"total_train_time_s\": 9.66759705543518}", "{\"n\": 2994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.43, \"learn_time_ms\": 8969.805, \"total_train_time_s\": 10.8099684715271}", "{\"n\": 2995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.34, \"learn_time_ms\": 8889.598, \"total_train_time_s\": 9.895904779434204}", "{\"n\": 2996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.34, \"learn_time_ms\": 8748.35, \"total_train_time_s\": 10.15002965927124}", "{\"n\": 2997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.52, \"learn_time_ms\": 8701.531, \"total_train_time_s\": 9.377967357635498}", "{\"n\": 2998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.32, \"learn_time_ms\": 8627.989, \"total_train_time_s\": 10.020960569381714}", "{\"n\": 2999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.32, \"learn_time_ms\": 8641.631, \"total_train_time_s\": 9.298208951950073}", "{\"n\": 3000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.92, \"learn_time_ms\": 8578.879, \"total_train_time_s\": 9.623754978179932}", "{\"n\": 3001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.38, \"learn_time_ms\": 8610.972, \"total_train_time_s\": 10.52503514289856}", "{\"n\": 3002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.38, \"learn_time_ms\": 8393.25, \"total_train_time_s\": 8.881615400314331}", "{\"n\": 3003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.26, \"learn_time_ms\": 8426.738, \"total_train_time_s\": 9.967185020446777}", "{\"n\": 3004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.16, \"learn_time_ms\": 8289.439, \"total_train_time_s\": 9.411158323287964}", "{\"n\": 3005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.94, \"learn_time_ms\": 8237.065, \"total_train_time_s\": 9.295814990997314}", "{\"n\": 3006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.94, \"learn_time_ms\": 8051.305, \"total_train_time_s\": 8.268677711486816}", "{\"n\": 3007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.13, \"learn_time_ms\": 8279.655, \"total_train_time_s\": 11.680545330047607}", "{\"n\": 3008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.56, \"learn_time_ms\": 8282.074, \"total_train_time_s\": 10.087018489837646}", "{\"n\": 3009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.56, \"learn_time_ms\": 8334.351, \"total_train_time_s\": 9.85755467414856}", "{\"n\": 3010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.08, \"learn_time_ms\": 8376.63, \"total_train_time_s\": 10.00602674484253}", "{\"n\": 3011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.94, \"learn_time_ms\": 8402.086, \"total_train_time_s\": 10.716478109359741}", "{\"n\": 3012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.03, \"learn_time_ms\": 8463.839, \"total_train_time_s\": 9.465498447418213}", "{\"n\": 3013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.03, \"learn_time_ms\": 8457.503, \"total_train_time_s\": 9.883235216140747}", "{\"n\": 3014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.32, \"learn_time_ms\": 8432.36, \"total_train_time_s\": 9.143181085586548}", "{\"n\": 3015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.84, \"learn_time_ms\": 8614.769, \"total_train_time_s\": 11.174636602401733}", "{\"n\": 3016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.84, \"learn_time_ms\": 8834.463, \"total_train_time_s\": 10.470423698425293}", "{\"n\": 3017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.18, \"learn_time_ms\": 8782.531, \"total_train_time_s\": 11.172561168670654}", "{\"n\": 3018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.58, \"learn_time_ms\": 8791.645, \"total_train_time_s\": 10.147372722625732}", "{\"n\": 3019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.05, \"learn_time_ms\": 8806.635, \"total_train_time_s\": 10.045124053955078}", "{\"n\": 3020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.76, \"learn_time_ms\": 8715.784, \"total_train_time_s\": 9.104989767074585}", "{\"n\": 3021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.36, \"learn_time_ms\": 8662.189, \"total_train_time_s\": 10.186272621154785}", "{\"n\": 3022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.36, \"learn_time_ms\": 8777.22, \"total_train_time_s\": 10.576091051101685}", "{\"n\": 3023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.78, \"learn_time_ms\": 8793.034, \"total_train_time_s\": 10.019785642623901}", "{\"n\": 3024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.0, \"learn_time_ms\": 8817.521, \"total_train_time_s\": 9.351613998413086}", "{\"n\": 3025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.0, \"learn_time_ms\": 8722.809, \"total_train_time_s\": 10.232856750488281}", "{\"n\": 3026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.82, \"learn_time_ms\": 8536.66, \"total_train_time_s\": 8.636279821395874}", "{\"n\": 3027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.2, \"learn_time_ms\": 8321.202, \"total_train_time_s\": 8.999184131622314}", "{\"n\": 3028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.47, \"learn_time_ms\": 8279.273, \"total_train_time_s\": 9.709512948989868}", "{\"n\": 3029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.98, \"learn_time_ms\": 8316.403, \"total_train_time_s\": 10.375370264053345}", "{\"n\": 3030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.92, \"learn_time_ms\": 8221.057, \"total_train_time_s\": 8.140361785888672}", "{\"n\": 3031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.81, \"learn_time_ms\": 8248.262, \"total_train_time_s\": 10.45530891418457}", "{\"n\": 3032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.98, \"learn_time_ms\": 8226.736, \"total_train_time_s\": 10.453955888748169}", "{\"n\": 3033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.79, \"learn_time_ms\": 8407.195, \"total_train_time_s\": 11.881596088409424}", "{\"n\": 3034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.63, \"learn_time_ms\": 8529.567, \"total_train_time_s\": 10.666935205459595}", "{\"n\": 3035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.19, \"learn_time_ms\": 8524.548, \"total_train_time_s\": 10.150084257125854}", "{\"n\": 3036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.19, \"learn_time_ms\": 8619.737, \"total_train_time_s\": 9.559671878814697}", "{\"n\": 3037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.88, \"learn_time_ms\": 8774.519, \"total_train_time_s\": 10.548696994781494}", "{\"n\": 3038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.23, \"learn_time_ms\": 8860.726, \"total_train_time_s\": 10.600624084472656}", "{\"n\": 3039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.23, \"learn_time_ms\": 8682.736, \"total_train_time_s\": 8.603158473968506}", "{\"n\": 3040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.54, \"learn_time_ms\": 8870.413, \"total_train_time_s\": 10.052908182144165}", "{\"n\": 3041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.21, \"learn_time_ms\": 8859.399, \"total_train_time_s\": 10.439700841903687}", "{\"n\": 3042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.21, \"learn_time_ms\": 8856.013, \"total_train_time_s\": 10.392737627029419}", "{\"n\": 3043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.47, \"learn_time_ms\": 8629.23, \"total_train_time_s\": 9.781259059906006}", "{\"n\": 3044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.47, \"learn_time_ms\": 8576.216, \"total_train_time_s\": 10.1226327419281}", "{\"n\": 3045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.1, \"learn_time_ms\": 8474.3, \"total_train_time_s\": 9.14386796951294}", "{\"n\": 3046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.42, \"learn_time_ms\": 8585.723, \"total_train_time_s\": 10.694575786590576}", "{\"n\": 3047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.67, \"learn_time_ms\": 8624.318, \"total_train_time_s\": 10.919169187545776}", "{\"n\": 3048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.54, \"learn_time_ms\": 8697.525, \"total_train_time_s\": 11.31781554222107}", "{\"n\": 3049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.23, \"learn_time_ms\": 8857.727, \"total_train_time_s\": 10.193747520446777}", "{\"n\": 3050, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.25, \"learn_time_ms\": 8787.274, \"total_train_time_s\": 9.316673755645752}", "{\"n\": 3051, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.21, \"learn_time_ms\": 8801.721, \"total_train_time_s\": 10.497315883636475}", "{\"n\": 3052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.28, \"learn_time_ms\": 8730.949, \"total_train_time_s\": 9.654301643371582}", "{\"n\": 3053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.57, \"learn_time_ms\": 8847.666, \"total_train_time_s\": 10.807515382766724}", "{\"n\": 3054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.36, \"learn_time_ms\": 8766.93, \"total_train_time_s\": 9.278027772903442}", "{\"n\": 3055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.88, \"learn_time_ms\": 8919.377, \"total_train_time_s\": 10.691850423812866}", "{\"n\": 3056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.42, \"learn_time_ms\": 8809.424, \"total_train_time_s\": 9.637187004089355}", "{\"n\": 3057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.42, \"learn_time_ms\": 8626.114, \"total_train_time_s\": 9.079243659973145}", "{\"n\": 3058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.97, \"learn_time_ms\": 8540.49, \"total_train_time_s\": 10.438160419464111}", "{\"n\": 3059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.29, \"learn_time_ms\": 8627.209, \"total_train_time_s\": 11.112951755523682}", "{\"n\": 3060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.48, \"learn_time_ms\": 8733.805, \"total_train_time_s\": 10.421940326690674}", "{\"n\": 3061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.48, \"learn_time_ms\": 8715.548, \"total_train_time_s\": 10.284614324569702}", "{\"n\": 3062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.5, \"learn_time_ms\": 8805.094, \"total_train_time_s\": 10.557467699050903}", "{\"n\": 3063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.98, \"learn_time_ms\": 8840.508, \"total_train_time_s\": 11.163841247558594}", "{\"n\": 3064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.17, \"learn_time_ms\": 9025.839, \"total_train_time_s\": 11.111478805541992}", "{\"n\": 3065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.67, \"learn_time_ms\": 9081.917, \"total_train_time_s\": 11.257479190826416}", "{\"n\": 3066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.48, \"learn_time_ms\": 9054.429, \"total_train_time_s\": 9.314498901367188}", "{\"n\": 3067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.48, \"learn_time_ms\": 9162.285, \"total_train_time_s\": 10.176188468933105}", "{\"n\": 3068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.26, \"learn_time_ms\": 8969.496, \"total_train_time_s\": 8.564353704452515}", "{\"n\": 3069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.46, \"learn_time_ms\": 8872.787, \"total_train_time_s\": 10.07457184791565}", "{\"n\": 3070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.63, \"learn_time_ms\": 8976.452, \"total_train_time_s\": 11.422993421554565}", "{\"n\": 3071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.07, \"learn_time_ms\": 8915.442, \"total_train_time_s\": 9.727566480636597}", "{\"n\": 3072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.07, \"learn_time_ms\": 8939.333, \"total_train_time_s\": 10.797797679901123}", "{\"n\": 3073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.3, \"learn_time_ms\": 8996.46, \"total_train_time_s\": 11.703588724136353}", "{\"n\": 3074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.5, \"learn_time_ms\": 8976.152, \"total_train_time_s\": 10.955065727233887}", "{\"n\": 3075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.97, \"learn_time_ms\": 8996.686, \"total_train_time_s\": 11.499110221862793}", "{\"n\": 3076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.61, \"learn_time_ms\": 8994.795, \"total_train_time_s\": 9.283761501312256}", "{\"n\": 3077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.61, \"learn_time_ms\": 8961.661, \"total_train_time_s\": 9.86911153793335}", "{\"n\": 3078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.39, \"learn_time_ms\": 9182.059, \"total_train_time_s\": 10.752148389816284}", "{\"n\": 3079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.19, \"learn_time_ms\": 9140.735, \"total_train_time_s\": 9.678700685501099}", "{\"n\": 3080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.19, \"learn_time_ms\": 8991.446, \"total_train_time_s\": 9.942954301834106}", "{\"n\": 3081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.77, \"learn_time_ms\": 8812.973, \"total_train_time_s\": 7.947923898696899}", "{\"n\": 3082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.04, \"learn_time_ms\": 8644.355, \"total_train_time_s\": 9.107555866241455}", "{\"n\": 3083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.04, \"learn_time_ms\": 8509.834, \"total_train_time_s\": 10.390998840332031}", "{\"n\": 3084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.7, \"learn_time_ms\": 8557.413, \"total_train_time_s\": 11.466185331344604}", "{\"n\": 3085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.7, \"learn_time_ms\": 8555.552, \"total_train_time_s\": 11.430545330047607}", "{\"n\": 3086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.39, \"learn_time_ms\": 8805.779, \"total_train_time_s\": 11.793579578399658}", "{\"n\": 3087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.66, \"learn_time_ms\": 8926.468, \"total_train_time_s\": 11.04205870628357}", "{\"n\": 3088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.91, \"learn_time_ms\": 8794.182, \"total_train_time_s\": 9.414115190505981}", "{\"n\": 3089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.1, \"learn_time_ms\": 8774.782, \"total_train_time_s\": 9.46824336051941}", "{\"n\": 3090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.1, \"learn_time_ms\": 8761.444, \"total_train_time_s\": 9.76013469696045}", "{\"n\": 3091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.08, \"learn_time_ms\": 9127.005, \"total_train_time_s\": 11.579385757446289}", "{\"n\": 3092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.73, \"learn_time_ms\": 9300.008, \"total_train_time_s\": 10.820458889007568}", "{\"n\": 3093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.73, \"learn_time_ms\": 9406.155, \"total_train_time_s\": 11.394957542419434}", "{\"n\": 3094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.94, \"learn_time_ms\": 9282.595, \"total_train_time_s\": 10.161847352981567}", "{\"n\": 3095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.81, \"learn_time_ms\": 9371.975, \"total_train_time_s\": 12.309363603591919}", "{\"n\": 3096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.81, \"learn_time_ms\": 9108.722, \"total_train_time_s\": 9.144874095916748}", "{\"n\": 3097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 9075.632, \"total_train_time_s\": 10.789051294326782}", "{\"n\": 3098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.02, \"learn_time_ms\": 9177.645, \"total_train_time_s\": 10.512893438339233}", "{\"n\": 3099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.02, \"learn_time_ms\": 9195.804, \"total_train_time_s\": 9.663235902786255}", "{\"n\": 3100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.58, \"learn_time_ms\": 9337.632, \"total_train_time_s\": 11.183237791061401}", "{\"n\": 3101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.92, \"learn_time_ms\": 9155.156, \"total_train_time_s\": 9.757160425186157}", "{\"n\": 3102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.97, \"learn_time_ms\": 9211.525, \"total_train_time_s\": 11.377806663513184}", "{\"n\": 3103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.97, \"learn_time_ms\": 8921.524, \"total_train_time_s\": 8.493775844573975}", "{\"n\": 3104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.21, \"learn_time_ms\": 8835.252, \"total_train_time_s\": 9.28283143043518}", "{\"n\": 3105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.46, \"learn_time_ms\": 8610.541, \"total_train_time_s\": 10.104148149490356}", "{\"n\": 3106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.46, \"learn_time_ms\": 8608.331, \"total_train_time_s\": 9.146978616714478}", "{\"n\": 3107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.04, \"learn_time_ms\": 8483.452, \"total_train_time_s\": 9.533007383346558}", "{\"n\": 3108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.36, \"learn_time_ms\": 8418.424, \"total_train_time_s\": 9.784276247024536}", "{\"n\": 3109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.36, \"learn_time_ms\": 8531.026, \"total_train_time_s\": 10.788750648498535}", "{\"n\": 3110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.7, \"learn_time_ms\": 8468.144, \"total_train_time_s\": 10.590728044509888}", "{\"n\": 3111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.16, \"learn_time_ms\": 8621.401, \"total_train_time_s\": 11.264886379241943}", "{\"n\": 3112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.51, \"learn_time_ms\": 8510.235, \"total_train_time_s\": 10.30379605293274}", "{\"n\": 3113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.83, \"learn_time_ms\": 8677.443, \"total_train_time_s\": 10.19923734664917}", "{\"n\": 3114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.17, \"learn_time_ms\": 8676.352, \"total_train_time_s\": 9.265536546707153}", "{\"n\": 3115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.53, \"learn_time_ms\": 8605.825, \"total_train_time_s\": 9.367051839828491}", "{\"n\": 3116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.86, \"learn_time_ms\": 8767.247, \"total_train_time_s\": 10.80051326751709}", "{\"n\": 3117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.08, \"learn_time_ms\": 8768.837, \"total_train_time_s\": 9.529723644256592}", "{\"n\": 3118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.87, \"learn_time_ms\": 8791.598, \"total_train_time_s\": 10.03853726387024}", "{\"n\": 3119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.87, \"learn_time_ms\": 8677.556, \"total_train_time_s\": 9.644315719604492}", "{\"n\": 3120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.48, \"learn_time_ms\": 8619.96, \"total_train_time_s\": 10.048353672027588}", "{\"n\": 3121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.27, \"learn_time_ms\": 8584.045, \"total_train_time_s\": 10.936649560928345}", "{\"n\": 3122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.26, \"learn_time_ms\": 8566.119, \"total_train_time_s\": 10.093012809753418}", "{\"n\": 3123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.26, \"learn_time_ms\": 8615.447, \"total_train_time_s\": 10.681789875030518}", "{\"n\": 3124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.86, \"learn_time_ms\": 8730.838, \"total_train_time_s\": 10.496509552001953}", "{\"n\": 3125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.43, \"learn_time_ms\": 8891.576, \"total_train_time_s\": 10.97945785522461}", "{\"n\": 3126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.22, \"learn_time_ms\": 8894.611, \"total_train_time_s\": 10.781290054321289}", "{\"n\": 3127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.32, \"learn_time_ms\": 8901.435, \"total_train_time_s\": 9.566067934036255}", "{\"n\": 3128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.28, \"learn_time_ms\": 8911.166, \"total_train_time_s\": 10.094454288482666}", "{\"n\": 3129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.93, \"learn_time_ms\": 8978.17, \"total_train_time_s\": 10.35128664970398}", "{\"n\": 3130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.08, \"learn_time_ms\": 9013.651, \"total_train_time_s\": 10.421309471130371}", "{\"n\": 3131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.41, \"learn_time_ms\": 8924.37, \"total_train_time_s\": 10.03915286064148}", "{\"n\": 3132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.71, \"learn_time_ms\": 9149.967, \"total_train_time_s\": 12.398900985717773}", "{\"n\": 3133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.87, \"learn_time_ms\": 9118.653, \"total_train_time_s\": 10.333380460739136}", "{\"n\": 3134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.14, \"learn_time_ms\": 9133.576, \"total_train_time_s\": 10.544751167297363}", "{\"n\": 3135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.61, \"learn_time_ms\": 9112.497, \"total_train_time_s\": 10.760903358459473}", "{\"n\": 3136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.61, \"learn_time_ms\": 9082.498, \"total_train_time_s\": 10.478822231292725}", "{\"n\": 3137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.07, \"learn_time_ms\": 9150.885, \"total_train_time_s\": 10.252935409545898}", "{\"n\": 3138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.86, \"learn_time_ms\": 9101.931, \"total_train_time_s\": 9.636898279190063}", "{\"n\": 3139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.48, \"learn_time_ms\": 9038.191, \"total_train_time_s\": 9.652957439422607}", "{\"n\": 3140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.34, \"learn_time_ms\": 9052.52, \"total_train_time_s\": 10.509998798370361}", "{\"n\": 3141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.92, \"learn_time_ms\": 9052.181, \"total_train_time_s\": 10.017328977584839}", "{\"n\": 3142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.55, \"learn_time_ms\": 8774.323, \"total_train_time_s\": 9.58799695968628}", "{\"n\": 3143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.35, \"learn_time_ms\": 8733.496, \"total_train_time_s\": 9.96622085571289}", "{\"n\": 3144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.07, \"learn_time_ms\": 8795.869, \"total_train_time_s\": 11.228178262710571}", "{\"n\": 3145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.52, \"learn_time_ms\": 8676.272, \"total_train_time_s\": 9.55246901512146}", "{\"n\": 3146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.52, \"learn_time_ms\": 8610.535, \"total_train_time_s\": 9.810434341430664}", "{\"n\": 3147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.07, \"learn_time_ms\": 8569.224, \"total_train_time_s\": 9.835845470428467}", "{\"n\": 3148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.07, \"learn_time_ms\": 8548.655, \"total_train_time_s\": 9.417092084884644}", "{\"n\": 3149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.45, \"learn_time_ms\": 8610.885, \"total_train_time_s\": 10.322279453277588}", "{\"n\": 3150, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.53, \"learn_time_ms\": 8621.31, \"total_train_time_s\": 10.662959337234497}", "{\"n\": 3151, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.43, \"learn_time_ms\": 8620.244, \"total_train_time_s\": 9.994691133499146}", "{\"n\": 3152, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.04, \"learn_time_ms\": 8569.304, \"total_train_time_s\": 9.060807466506958}", "{\"n\": 3153, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.51, \"learn_time_ms\": 8575.334, \"total_train_time_s\": 10.020349264144897}", "{\"n\": 3154, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.38, \"learn_time_ms\": 8469.901, \"total_train_time_s\": 10.175525903701782}", "{\"n\": 3155, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.77, \"learn_time_ms\": 8472.781, \"total_train_time_s\": 9.608116626739502}", "{\"n\": 3156, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.46, \"learn_time_ms\": 8498.446, \"total_train_time_s\": 10.129509687423706}", "{\"n\": 3157, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.44, \"learn_time_ms\": 8522.986, \"total_train_time_s\": 10.128215312957764}", "{\"n\": 3158, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.44, \"learn_time_ms\": 8599.509, \"total_train_time_s\": 10.128074169158936}", "{\"n\": 3159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.14, \"learn_time_ms\": 8558.929, \"total_train_time_s\": 9.912710666656494}", "{\"n\": 3160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.33, \"learn_time_ms\": 8537.576, \"total_train_time_s\": 10.405076742172241}", "{\"n\": 3161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.33, \"learn_time_ms\": 8570.892, \"total_train_time_s\": 10.326693058013916}", "{\"n\": 3162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.74, \"learn_time_ms\": 8659.295, \"total_train_time_s\": 9.960878133773804}", "{\"n\": 3163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.11, \"learn_time_ms\": 8741.464, \"total_train_time_s\": 10.831224918365479}", "{\"n\": 3164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.11, \"learn_time_ms\": 8731.405, \"total_train_time_s\": 10.063912630081177}", "{\"n\": 3165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.19, \"learn_time_ms\": 8897.09, \"total_train_time_s\": 11.279855966567993}", "{\"n\": 3166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.95, \"learn_time_ms\": 8830.915, \"total_train_time_s\": 9.446852684020996}", "{\"n\": 3167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.52, \"learn_time_ms\": 8844.564, \"total_train_time_s\": 10.230258703231812}", "{\"n\": 3168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.13, \"learn_time_ms\": 8905.658, \"total_train_time_s\": 10.788804054260254}", "{\"n\": 3169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.39, \"learn_time_ms\": 8947.216, \"total_train_time_s\": 10.376853704452515}", "{\"n\": 3170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.03, \"learn_time_ms\": 9055.774, \"total_train_time_s\": 11.477992057800293}", "{\"n\": 3171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.03, \"learn_time_ms\": 9153.942, \"total_train_time_s\": 11.34861445426941}", "{\"n\": 3172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.05, \"learn_time_ms\": 9346.359, \"total_train_time_s\": 11.947889804840088}", "{\"n\": 3173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.7, \"learn_time_ms\": 9321.098, \"total_train_time_s\": 10.58375358581543}", "{\"n\": 3174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.7, \"learn_time_ms\": 9413.016, \"total_train_time_s\": 10.952301502227783}", "{\"n\": 3175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.59, \"learn_time_ms\": 9344.035, \"total_train_time_s\": 10.53673267364502}", "{\"n\": 3176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.93, \"learn_time_ms\": 9544.839, \"total_train_time_s\": 11.424076795578003}", "{\"n\": 3177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.93, \"learn_time_ms\": 9582.809, \"total_train_time_s\": 10.558094024658203}", "{\"n\": 3178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.38, \"learn_time_ms\": 9520.732, \"total_train_time_s\": 10.18030595779419}", "{\"n\": 3179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.86, \"learn_time_ms\": 9562.881, \"total_train_time_s\": 10.761091947555542}", "{\"n\": 3180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.86, \"learn_time_ms\": 9540.886, \"total_train_time_s\": 11.323764324188232}", "{\"n\": 3181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.59, \"learn_time_ms\": 9442.633, \"total_train_time_s\": 10.37403655052185}", "{\"n\": 3182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.7, \"learn_time_ms\": 9218.39, \"total_train_time_s\": 9.62119460105896}", "{\"n\": 3183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.7, \"learn_time_ms\": 9223.84, \"total_train_time_s\": 10.672955989837646}", "{\"n\": 3184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.52, \"learn_time_ms\": 9169.164, \"total_train_time_s\": 10.446478366851807}", "{\"n\": 3185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.54, \"learn_time_ms\": 9167.446, \"total_train_time_s\": 10.53827452659607}", "{\"n\": 3186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.54, \"learn_time_ms\": 9116.113, \"total_train_time_s\": 10.892812728881836}", "{\"n\": 3187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.54, \"learn_time_ms\": 9088.324, \"total_train_time_s\": 10.304608345031738}", "{\"n\": 3188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.2, \"learn_time_ms\": 9077.341, \"total_train_time_s\": 10.086986780166626}", "{\"n\": 3189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.09, \"learn_time_ms\": 8903.603, \"total_train_time_s\": 9.0170738697052}", "{\"n\": 3190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.09, \"learn_time_ms\": 8765.41, \"total_train_time_s\": 9.852572917938232}", "{\"n\": 3191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.02, \"learn_time_ms\": 8723.948, \"total_train_time_s\": 9.916540622711182}", "{\"n\": 3192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.69, \"learn_time_ms\": 8868.838, \"total_train_time_s\": 11.097115993499756}", "{\"n\": 3193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.88, \"learn_time_ms\": 8836.64, \"total_train_time_s\": 10.317541122436523}", "{\"n\": 3194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.69, \"learn_time_ms\": 8728.762, \"total_train_time_s\": 9.361598014831543}", "{\"n\": 3195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.2, \"learn_time_ms\": 8650.521, \"total_train_time_s\": 9.771103382110596}", "{\"n\": 3196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.7, \"learn_time_ms\": 8547.807, \"total_train_time_s\": 9.931798696517944}", "{\"n\": 3197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.91, \"learn_time_ms\": 8648.067, \"total_train_time_s\": 11.382223129272461}", "{\"n\": 3198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 8695.202, \"total_train_time_s\": 10.574548959732056}", "{\"n\": 3199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.61, \"learn_time_ms\": 8686.635, \"total_train_time_s\": 8.946019649505615}", "{\"n\": 3200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.02, \"learn_time_ms\": 8666.888, \"total_train_time_s\": 9.712749481201172}", "{\"n\": 3201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.06, \"learn_time_ms\": 8712.657, \"total_train_time_s\": 10.401734590530396}", "{\"n\": 3202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.02, \"learn_time_ms\": 8714.195, \"total_train_time_s\": 11.130339622497559}", "{\"n\": 3203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.61, \"learn_time_ms\": 8657.589, \"total_train_time_s\": 9.779541492462158}", "{\"n\": 3204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.23, \"learn_time_ms\": 8818.008, \"total_train_time_s\": 10.938347339630127}", "{\"n\": 3205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.72, \"learn_time_ms\": 8805.169, \"total_train_time_s\": 9.65045976638794}", "{\"n\": 3206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.37, \"learn_time_ms\": 8871.011, \"total_train_time_s\": 10.545826435089111}", "{\"n\": 3207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.37, \"learn_time_ms\": 8805.912, \"total_train_time_s\": 10.630598068237305}", "{\"n\": 3208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.38, \"learn_time_ms\": 8820.884, \"total_train_time_s\": 10.673706769943237}", "{\"n\": 3209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.38, \"learn_time_ms\": 8997.411, \"total_train_time_s\": 10.672630071640015}", "{\"n\": 3210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.59, \"learn_time_ms\": 9195.309, \"total_train_time_s\": 11.721771001815796}", "{\"n\": 3211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.95, \"learn_time_ms\": 9132.023, \"total_train_time_s\": 9.789627313613892}", "{\"n\": 3212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.95, \"learn_time_ms\": 8929.555, \"total_train_time_s\": 9.093641996383667}", "{\"n\": 3213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.73, \"learn_time_ms\": 8931.064, \"total_train_time_s\": 9.788899421691895}", "{\"n\": 3214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.27, \"learn_time_ms\": 8777.339, \"total_train_time_s\": 9.427815675735474}", "{\"n\": 3215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.27, \"learn_time_ms\": 8853.258, \"total_train_time_s\": 10.414250612258911}", "{\"n\": 3216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.96, \"learn_time_ms\": 8849.191, \"total_train_time_s\": 10.474047660827637}", "{\"n\": 3217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.59, \"learn_time_ms\": 8902.362, \"total_train_time_s\": 11.24146056175232}", "{\"n\": 3218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.69, \"learn_time_ms\": 8892.136, \"total_train_time_s\": 10.601705074310303}", "{\"n\": 3219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.16, \"learn_time_ms\": 8976.509, \"total_train_time_s\": 11.562885522842407}", "{\"n\": 3220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.16, \"learn_time_ms\": 8938.345, \"total_train_time_s\": 11.31345248222351}", "{\"n\": 3221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.98, \"learn_time_ms\": 9012.808, \"total_train_time_s\": 10.51145339012146}", "{\"n\": 3222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.25, \"learn_time_ms\": 9237.738, \"total_train_time_s\": 11.340033769607544}", "{\"n\": 3223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.25, \"learn_time_ms\": 9105.986, \"total_train_time_s\": 8.468068838119507}", "{\"n\": 3224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.05, \"learn_time_ms\": 9302.725, \"total_train_time_s\": 11.387457370758057}", "{\"n\": 3225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.09, \"learn_time_ms\": 9168.293, \"total_train_time_s\": 9.087071895599365}", "{\"n\": 3226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.64, \"learn_time_ms\": 9091.573, \"total_train_time_s\": 9.788220167160034}", "{\"n\": 3227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.74, \"learn_time_ms\": 8996.843, \"total_train_time_s\": 10.261092185974121}", "{\"n\": 3228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.54, \"learn_time_ms\": 8995.942, \"total_train_time_s\": 10.56094741821289}", "{\"n\": 3229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.81, \"learn_time_ms\": 8835.844, \"total_train_time_s\": 9.914231300354004}", "{\"n\": 3230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.41, \"learn_time_ms\": 8757.274, \"total_train_time_s\": 10.498498678207397}", "{\"n\": 3231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.01, \"learn_time_ms\": 8724.209, \"total_train_time_s\": 10.189252853393555}", "{\"n\": 3232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.0, \"learn_time_ms\": 8641.694, \"total_train_time_s\": 10.517908096313477}", "{\"n\": 3233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.44, \"learn_time_ms\": 8739.08, \"total_train_time_s\": 9.427643299102783}", "{\"n\": 3234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.28, \"learn_time_ms\": 8513.255, \"total_train_time_s\": 9.131454706192017}", "{\"n\": 3235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.82, \"learn_time_ms\": 8700.369, \"total_train_time_s\": 10.934889316558838}", "{\"n\": 3236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.82, \"learn_time_ms\": 8757.955, \"total_train_time_s\": 10.402138710021973}", "{\"n\": 3237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.63, \"learn_time_ms\": 8721.079, \"total_train_time_s\": 9.92054796218872}", "{\"n\": 3238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.63, \"learn_time_ms\": 8678.859, \"total_train_time_s\": 10.15855097770691}", "{\"n\": 3239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.76, \"learn_time_ms\": 8750.249, \"total_train_time_s\": 10.640300750732422}", "{\"n\": 3240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.79, \"learn_time_ms\": 8758.408, \"total_train_time_s\": 10.581956624984741}", "{\"n\": 3241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.38, \"learn_time_ms\": 8832.181, \"total_train_time_s\": 10.954121589660645}", "{\"n\": 3242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.38, \"learn_time_ms\": 8799.537, \"total_train_time_s\": 10.218550443649292}", "{\"n\": 3243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.98, \"learn_time_ms\": 8873.174, \"total_train_time_s\": 10.176145076751709}", "{\"n\": 3244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.11, \"learn_time_ms\": 8981.204, \"total_train_time_s\": 10.215687274932861}", "{\"n\": 3245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.11, \"learn_time_ms\": 8750.021, \"total_train_time_s\": 8.60764765739441}", "{\"n\": 3246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.08, \"learn_time_ms\": 8759.784, \"total_train_time_s\": 10.397137880325317}", "{\"n\": 3247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.23, \"learn_time_ms\": 8749.957, \"total_train_time_s\": 9.8068265914917}", "{\"n\": 3248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.23, \"learn_time_ms\": 8704.594, \"total_train_time_s\": 9.703381776809692}", "{\"n\": 3249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.14, \"learn_time_ms\": 8466.96, \"total_train_time_s\": 8.258307695388794}", "{\"n\": 3250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.32, \"learn_time_ms\": 8462.524, \"total_train_time_s\": 10.52439022064209}", "{\"n\": 3251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.32, \"learn_time_ms\": 8356.057, \"total_train_time_s\": 9.88362717628479}", "{\"n\": 3252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.6, \"learn_time_ms\": 8495.862, \"total_train_time_s\": 11.564362525939941}", "{\"n\": 3253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.47, \"learn_time_ms\": 8550.361, \"total_train_time_s\": 10.69324278831482}", "{\"n\": 3254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.47, \"learn_time_ms\": 8600.853, \"total_train_time_s\": 10.695094108581543}", "{\"n\": 3255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.47, \"learn_time_ms\": 8739.899, \"total_train_time_s\": 9.999464988708496}", "{\"n\": 3256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.09, \"learn_time_ms\": 8578.502, \"total_train_time_s\": 8.800132036209106}", "{\"n\": 3257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.46, \"learn_time_ms\": 8663.354, \"total_train_time_s\": 10.637449741363525}", "{\"n\": 3258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.46, \"learn_time_ms\": 8666.57, \"total_train_time_s\": 9.69881796836853}", "{\"n\": 3259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.1, \"learn_time_ms\": 8938.817, \"total_train_time_s\": 11.035345554351807}", "{\"n\": 3260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.76, \"learn_time_ms\": 9089.709, \"total_train_time_s\": 12.068007230758667}", "{\"n\": 3261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.76, \"learn_time_ms\": 8983.292, \"total_train_time_s\": 8.769997835159302}", "{\"n\": 3262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.17, \"learn_time_ms\": 9037.248, \"total_train_time_s\": 12.182759284973145}", "{\"n\": 3263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.13, \"learn_time_ms\": 8890.544, \"total_train_time_s\": 9.22625994682312}", "{\"n\": 3264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.13, \"learn_time_ms\": 8825.423, \"total_train_time_s\": 10.056313514709473}", "{\"n\": 3265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.91, \"learn_time_ms\": 8895.646, \"total_train_time_s\": 10.712491273880005}", "{\"n\": 3266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.75, \"learn_time_ms\": 8989.856, \"total_train_time_s\": 9.754998683929443}", "{\"n\": 3267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.69, \"learn_time_ms\": 8943.018, \"total_train_time_s\": 10.221089363098145}", "{\"n\": 3268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.47, \"learn_time_ms\": 8987.647, \"total_train_time_s\": 10.141223192214966}", "{\"n\": 3269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.98, \"learn_time_ms\": 8844.516, \"total_train_time_s\": 9.528648138046265}", "{\"n\": 3270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.48, \"learn_time_ms\": 8750.683, \"total_train_time_s\": 11.078877687454224}", "{\"n\": 3271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.08, \"learn_time_ms\": 8869.212, \"total_train_time_s\": 9.980619430541992}", "{\"n\": 3272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.08, \"learn_time_ms\": 8627.292, \"total_train_time_s\": 9.713308811187744}", "{\"n\": 3273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.07, \"learn_time_ms\": 8741.325, \"total_train_time_s\": 10.435326337814331}", "{\"n\": 3274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.31, \"learn_time_ms\": 8615.815, \"total_train_time_s\": 8.81151533126831}", "{\"n\": 3275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.96, \"learn_time_ms\": 8637.671, \"total_train_time_s\": 10.928669929504395}", "{\"n\": 3276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.2, \"learn_time_ms\": 8711.294, \"total_train_time_s\": 10.47391128540039}", "{\"n\": 3277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.87, \"learn_time_ms\": 8804.487, \"total_train_time_s\": 11.14556622505188}", "{\"n\": 3278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.26, \"learn_time_ms\": 8806.929, \"total_train_time_s\": 10.185502767562866}", "{\"n\": 3279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.12, \"learn_time_ms\": 8900.552, \"total_train_time_s\": 10.51006269454956}", "{\"n\": 3280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.75, \"learn_time_ms\": 8828.131, \"total_train_time_s\": 10.406021118164062}", "{\"n\": 3281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.51, \"learn_time_ms\": 8888.605, \"total_train_time_s\": 10.617138385772705}", "{\"n\": 3282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.14, \"learn_time_ms\": 8844.661, \"total_train_time_s\": 9.269710063934326}", "{\"n\": 3283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.55, \"learn_time_ms\": 8759.622, \"total_train_time_s\": 9.498934268951416}", "{\"n\": 3284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.19, \"learn_time_ms\": 8755.031, \"total_train_time_s\": 8.772999286651611}", "{\"n\": 3285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.42, \"learn_time_ms\": 8725.39, \"total_train_time_s\": 10.636216878890991}", "{\"n\": 3286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.04, \"learn_time_ms\": 8793.173, \"total_train_time_s\": 11.163818597793579}", "{\"n\": 3287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.15, \"learn_time_ms\": 8642.066, \"total_train_time_s\": 9.582005262374878}", "{\"n\": 3288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.81, \"learn_time_ms\": 8596.018, \"total_train_time_s\": 9.748439073562622}", "{\"n\": 3289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.12, \"learn_time_ms\": 8598.346, \"total_train_time_s\": 10.573476314544678}", "{\"n\": 3290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.39, \"learn_time_ms\": 8612.467, \"total_train_time_s\": 10.538819551467896}", "{\"n\": 3291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.3, \"learn_time_ms\": 8769.956, \"total_train_time_s\": 12.135891914367676}", "{\"n\": 3292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.35, \"learn_time_ms\": 8853.973, \"total_train_time_s\": 10.08718466758728}", "{\"n\": 3293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.72, \"learn_time_ms\": 8944.078, \"total_train_time_s\": 10.445508241653442}", "{\"n\": 3294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3230.87, \"learn_time_ms\": 9061.818, \"total_train_time_s\": 9.97037124633789}", "{\"n\": 3295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.99, \"learn_time_ms\": 8936.851, \"total_train_time_s\": 9.377461910247803}", "{\"n\": 3296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.73, \"learn_time_ms\": 8920.18, \"total_train_time_s\": 10.99503469467163}", "{\"n\": 3297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.96, \"learn_time_ms\": 8917.839, \"total_train_time_s\": 9.552921056747437}", "{\"n\": 3298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.53, \"learn_time_ms\": 8856.476, \"total_train_time_s\": 9.121176719665527}", "{\"n\": 3299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.69, \"learn_time_ms\": 8707.611, \"total_train_time_s\": 9.039108514785767}", "{\"n\": 3300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.7, \"learn_time_ms\": 8703.389, \"total_train_time_s\": 10.531259536743164}", "{\"n\": 3301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8350.383, \"total_train_time_s\": 8.639348983764648}", "{\"n\": 3302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.72, \"learn_time_ms\": 8268.609, \"total_train_time_s\": 9.276909589767456}", "{\"n\": 3303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.36, \"learn_time_ms\": 8271.785, \"total_train_time_s\": 10.499844789505005}", "{\"n\": 3304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.27, \"learn_time_ms\": 8266.749, \"total_train_time_s\": 9.89021348953247}", "{\"n\": 3305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.98, \"learn_time_ms\": 8311.944, \"total_train_time_s\": 9.860470533370972}", "{\"n\": 3306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.46, \"learn_time_ms\": 8135.045, \"total_train_time_s\": 9.18866491317749}", "{\"n\": 3307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.45, \"learn_time_ms\": 8206.53, \"total_train_time_s\": 10.300023555755615}", "{\"n\": 3308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.45, \"learn_time_ms\": 8307.83, \"total_train_time_s\": 10.106570959091187}", "{\"n\": 3309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.94, \"learn_time_ms\": 8532.952, \"total_train_time_s\": 11.26462459564209}", "{\"n\": 3310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.45, \"learn_time_ms\": 8513.121, \"total_train_time_s\": 10.274021625518799}", "{\"n\": 3311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.92, \"learn_time_ms\": 8604.157, \"total_train_time_s\": 9.542604446411133}", "{\"n\": 3312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.92, \"learn_time_ms\": 8611.59, \"total_train_time_s\": 9.360309839248657}", "{\"n\": 3313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.88, \"learn_time_ms\": 8834.168, \"total_train_time_s\": 12.721203804016113}", "{\"n\": 3314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.51, \"learn_time_ms\": 9027.852, \"total_train_time_s\": 11.849992036819458}", "{\"n\": 3315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.89, \"learn_time_ms\": 9159.87, \"total_train_time_s\": 11.129758596420288}", "{\"n\": 3316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.65, \"learn_time_ms\": 9142.074, \"total_train_time_s\": 9.06508493423462}", "{\"n\": 3317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.75, \"learn_time_ms\": 9043.656, \"total_train_time_s\": 9.323595762252808}", "{\"n\": 3318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.75, \"learn_time_ms\": 9121.031, \"total_train_time_s\": 10.882598638534546}", "{\"n\": 3319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.75, \"learn_time_ms\": 9011.423, \"total_train_time_s\": 10.18523907661438}", "{\"n\": 3320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.13, \"learn_time_ms\": 8964.035, \"total_train_time_s\": 9.835675716400146}", "{\"n\": 3321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.12, \"learn_time_ms\": 9143.161, \"total_train_time_s\": 11.326222658157349}", "{\"n\": 3322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.12, \"learn_time_ms\": 9179.479, \"total_train_time_s\": 9.684658527374268}", "{\"n\": 3323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.15, \"learn_time_ms\": 9044.387, \"total_train_time_s\": 11.322720289230347}", "{\"n\": 3324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.85, \"learn_time_ms\": 8841.306, \"total_train_time_s\": 9.76883578300476}", "{\"n\": 3325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.85, \"learn_time_ms\": 8896.176, \"total_train_time_s\": 11.688728094100952}", "{\"n\": 3326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.85, \"learn_time_ms\": 9030.333, \"total_train_time_s\": 10.395668029785156}", "{\"n\": 3327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.26, \"learn_time_ms\": 9030.322, \"total_train_time_s\": 9.307933330535889}", "{\"n\": 3328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.26, \"learn_time_ms\": 8860.053, \"total_train_time_s\": 9.213851690292358}", "{\"n\": 3329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.26, \"learn_time_ms\": 9039.814, \"total_train_time_s\": 11.95356822013855}", "{\"n\": 3330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.01, \"learn_time_ms\": 9052.998, \"total_train_time_s\": 9.930742502212524}", "{\"n\": 3331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.01, \"learn_time_ms\": 9031.181, \"total_train_time_s\": 11.071484327316284}", "{\"n\": 3332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.05, \"learn_time_ms\": 8966.577, \"total_train_time_s\": 9.105219602584839}", "{\"n\": 3333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.17, \"learn_time_ms\": 8910.295, \"total_train_time_s\": 10.774404764175415}", "{\"n\": 3334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.72, \"learn_time_ms\": 8931.034, \"total_train_time_s\": 10.022830486297607}", "{\"n\": 3335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.64, \"learn_time_ms\": 8688.757, \"total_train_time_s\": 9.323716878890991}", "{\"n\": 3336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.66, \"learn_time_ms\": 8607.137, \"total_train_time_s\": 9.559159278869629}", "{\"n\": 3337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.69, \"learn_time_ms\": 8758.551, \"total_train_time_s\": 10.807281017303467}", "{\"n\": 3338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.69, \"learn_time_ms\": 8669.017, \"total_train_time_s\": 8.2647864818573}", "{\"n\": 3339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.81, \"learn_time_ms\": 8422.253, \"total_train_time_s\": 9.544057607650757}", "{\"n\": 3340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.47, \"learn_time_ms\": 8540.941, \"total_train_time_s\": 11.162310123443604}", "{\"n\": 3341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.47, \"learn_time_ms\": 8502.532, \"total_train_time_s\": 10.748649597167969}", "{\"n\": 3342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.52, \"learn_time_ms\": 8652.97, \"total_train_time_s\": 10.636352777481079}", "{\"n\": 3343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.68, \"learn_time_ms\": 8594.464, \"total_train_time_s\": 10.226699829101562}", "{\"n\": 3344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.68, \"learn_time_ms\": 8659.121, \"total_train_time_s\": 10.676191329956055}", "{\"n\": 3345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.22, \"learn_time_ms\": 8923.962, \"total_train_time_s\": 11.914443492889404}", "{\"n\": 3346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.2, \"learn_time_ms\": 9044.951, \"total_train_time_s\": 10.802355766296387}", "{\"n\": 3347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.97, \"learn_time_ms\": 8840.128, \"total_train_time_s\": 8.765009880065918}", "{\"n\": 3348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.18, \"learn_time_ms\": 9067.431, \"total_train_time_s\": 10.557370662689209}", "{\"n\": 3349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.07, \"learn_time_ms\": 9016.302, \"total_train_time_s\": 8.959768772125244}", "{\"n\": 3350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.69, \"learn_time_ms\": 8925.532, \"total_train_time_s\": 10.277743339538574}", "{\"n\": 3351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.12, \"learn_time_ms\": 8894.207, \"total_train_time_s\": 10.43639612197876}", "{\"n\": 3352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.12, \"learn_time_ms\": 8805.605, \"total_train_time_s\": 9.740825653076172}", "{\"n\": 3353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.65, \"learn_time_ms\": 8803.837, \"total_train_time_s\": 10.18345594406128}", "{\"n\": 3354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.26, \"learn_time_ms\": 8665.429, \"total_train_time_s\": 9.304126739501953}", "{\"n\": 3355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.26, \"learn_time_ms\": 8599.884, \"total_train_time_s\": 11.269726753234863}", "{\"n\": 3356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.93, \"learn_time_ms\": 8703.439, \"total_train_time_s\": 11.804017782211304}", "{\"n\": 3357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.97, \"learn_time_ms\": 8936.491, \"total_train_time_s\": 11.077503442764282}", "{\"n\": 3358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.88, \"learn_time_ms\": 8863.706, \"total_train_time_s\": 9.822819232940674}", "{\"n\": 3359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.87, \"learn_time_ms\": 9057.56, \"total_train_time_s\": 10.953275203704834}", "{\"n\": 3360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.88, \"learn_time_ms\": 9032.739, \"total_train_time_s\": 9.997661352157593}", "{\"n\": 3361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.13, \"learn_time_ms\": 9164.718, \"total_train_time_s\": 11.715155124664307}", "{\"n\": 3362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.09, \"learn_time_ms\": 9224.233, \"total_train_time_s\": 10.295360803604126}", "{\"n\": 3363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.02, \"learn_time_ms\": 9121.159, \"total_train_time_s\": 9.121224403381348}", "{\"n\": 3364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.13, \"learn_time_ms\": 9156.3, \"total_train_time_s\": 9.618447542190552}", "{\"n\": 3365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.13, \"learn_time_ms\": 9027.12, \"total_train_time_s\": 10.007791519165039}", "{\"n\": 3366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.78, \"learn_time_ms\": 8804.883, \"total_train_time_s\": 9.649219274520874}", "{\"n\": 3367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.78, \"learn_time_ms\": 8697.216, \"total_train_time_s\": 9.984518051147461}", "{\"n\": 3368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.79, \"learn_time_ms\": 8792.992, \"total_train_time_s\": 10.813488245010376}", "{\"n\": 3369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.22, \"learn_time_ms\": 8788.606, \"total_train_time_s\": 10.92686676979065}", "{\"n\": 3370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.46, \"learn_time_ms\": 8879.958, \"total_train_time_s\": 10.8961923122406}", "{\"n\": 3371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.22, \"learn_time_ms\": 8662.069, \"total_train_time_s\": 9.563976764678955}", "{\"n\": 3372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.36, \"learn_time_ms\": 8672.058, \"total_train_time_s\": 10.456478834152222}", "{\"n\": 3373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.06, \"learn_time_ms\": 8778.028, \"total_train_time_s\": 10.21634817123413}", "{\"n\": 3374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.29, \"learn_time_ms\": 8878.355, \"total_train_time_s\": 10.627708911895752}", "{\"n\": 3375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.29, \"learn_time_ms\": 8823.363, \"total_train_time_s\": 9.383959293365479}", "{\"n\": 3376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.1, \"learn_time_ms\": 8960.081, \"total_train_time_s\": 10.950177431106567}", "{\"n\": 3377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.1, \"learn_time_ms\": 9097.938, \"total_train_time_s\": 11.40204644203186}", "{\"n\": 3378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.67, \"learn_time_ms\": 9138.799, \"total_train_time_s\": 11.191569089889526}", "{\"n\": 3379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.16, \"learn_time_ms\": 9030.897, \"total_train_time_s\": 9.824091911315918}", "{\"n\": 3380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.16, \"learn_time_ms\": 8989.086, \"total_train_time_s\": 10.488691091537476}", "{\"n\": 3381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.27, \"learn_time_ms\": 8988.358, \"total_train_time_s\": 9.564061403274536}", "{\"n\": 3382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.37, \"learn_time_ms\": 9024.03, \"total_train_time_s\": 10.81546688079834}", "{\"n\": 3383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.37, \"learn_time_ms\": 9128.351, \"total_train_time_s\": 11.26025128364563}", "{\"n\": 3384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.57, \"learn_time_ms\": 9111.405, \"total_train_time_s\": 10.496348857879639}", "{\"n\": 3385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.27, \"learn_time_ms\": 9171.022, \"total_train_time_s\": 10.028165340423584}", "{\"n\": 3386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.27, \"learn_time_ms\": 9065.138, \"total_train_time_s\": 9.896812677383423}", "{\"n\": 3387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.04, \"learn_time_ms\": 9009.857, \"total_train_time_s\": 10.85544204711914}", "{\"n\": 3388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.37, \"learn_time_ms\": 8913.191, \"total_train_time_s\": 10.267370462417603}", "{\"n\": 3389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.48, \"learn_time_ms\": 9003.139, \"total_train_time_s\": 10.75868821144104}", "{\"n\": 3390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.02, \"learn_time_ms\": 8987.407, \"total_train_time_s\": 10.329825639724731}", "{\"n\": 3391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.21, \"learn_time_ms\": 8920.98, \"total_train_time_s\": 8.83721923828125}", "{\"n\": 3392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.61, \"learn_time_ms\": 8746.239, \"total_train_time_s\": 9.012239933013916}", "{\"n\": 3393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.21, \"learn_time_ms\": 8632.724, \"total_train_time_s\": 10.091418027877808}", "{\"n\": 3394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.21, \"learn_time_ms\": 8724.691, \"total_train_time_s\": 11.375868797302246}", "{\"n\": 3395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.51, \"learn_time_ms\": 8738.739, \"total_train_time_s\": 10.142808198928833}", "{\"n\": 3396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.02, \"learn_time_ms\": 8727.686, \"total_train_time_s\": 9.809447765350342}", "{\"n\": 3397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.02, \"learn_time_ms\": 8601.704, \"total_train_time_s\": 9.574497938156128}", "{\"n\": 3398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.53, \"learn_time_ms\": 8534.518, \"total_train_time_s\": 9.661089897155762}", "{\"n\": 3399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.53, \"learn_time_ms\": 8430.266, \"total_train_time_s\": 9.68961787223816}", "{\"n\": 3400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.53, \"learn_time_ms\": 8365.169, \"total_train_time_s\": 9.648557186126709}", "{\"n\": 3401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.04, \"learn_time_ms\": 8429.087, \"total_train_time_s\": 9.558410406112671}", "{\"n\": 3402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.82, \"learn_time_ms\": 8675.578, \"total_train_time_s\": 11.459684133529663}", "{\"n\": 3403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.82, \"learn_time_ms\": 8602.674, \"total_train_time_s\": 9.374439477920532}", "{\"n\": 3404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.06, \"learn_time_ms\": 8497.191, \"total_train_time_s\": 10.350819826126099}", "{\"n\": 3405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.5, \"learn_time_ms\": 8551.131, \"total_train_time_s\": 10.717410564422607}", "{\"n\": 3406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.5, \"learn_time_ms\": 8460.203, \"total_train_time_s\": 8.904048204421997}", "{\"n\": 3407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.19, \"learn_time_ms\": 8408.384, \"total_train_time_s\": 9.132359504699707}", "{\"n\": 3408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.79, \"learn_time_ms\": 8340.401, \"total_train_time_s\": 8.919584035873413}", "{\"n\": 3409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.36, \"learn_time_ms\": 8393.946, \"total_train_time_s\": 10.223174571990967}", "{\"n\": 3410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.36, \"learn_time_ms\": 8490.417, \"total_train_time_s\": 10.612282752990723}", "{\"n\": 3411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.37, \"learn_time_ms\": 8645.865, \"total_train_time_s\": 11.078389883041382}", "{\"n\": 3412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.74, \"learn_time_ms\": 8494.751, \"total_train_time_s\": 9.956467390060425}", "{\"n\": 3413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.74, \"learn_time_ms\": 8591.67, \"total_train_time_s\": 10.323605060577393}", "{\"n\": 3414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.18, \"learn_time_ms\": 8580.7, \"total_train_time_s\": 10.219337701797485}", "{\"n\": 3415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.73, \"learn_time_ms\": 8537.406, \"total_train_time_s\": 10.26794958114624}", "{\"n\": 3416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.73, \"learn_time_ms\": 8517.662, \"total_train_time_s\": 8.69080924987793}", "{\"n\": 3417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.78, \"learn_time_ms\": 8743.312, \"total_train_time_s\": 11.32130742073059}", "{\"n\": 3418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.54, \"learn_time_ms\": 8800.533, \"total_train_time_s\": 9.477782011032104}", "{\"n\": 3419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.54, \"learn_time_ms\": 8824.426, \"total_train_time_s\": 10.480275392532349}", "{\"n\": 3420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.12, \"learn_time_ms\": 8633.833, \"total_train_time_s\": 8.736680746078491}", "{\"n\": 3421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.18, \"learn_time_ms\": 8564.36, \"total_train_time_s\": 10.410501956939697}", "{\"n\": 3422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.18, \"learn_time_ms\": 8693.749, \"total_train_time_s\": 11.256929874420166}", "{\"n\": 3423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.46, \"learn_time_ms\": 8694.479, \"total_train_time_s\": 10.344277143478394}", "{\"n\": 3424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.13, \"learn_time_ms\": 8687.855, \"total_train_time_s\": 10.123505592346191}", "{\"n\": 3425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.13, \"learn_time_ms\": 8602.575, \"total_train_time_s\": 9.390240669250488}", "{\"n\": 3426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.71, \"learn_time_ms\": 8711.555, \"total_train_time_s\": 9.778255701065063}", "{\"n\": 3427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.59, \"learn_time_ms\": 8769.053, \"total_train_time_s\": 11.887256860733032}", "{\"n\": 3428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.59, \"learn_time_ms\": 8983.169, \"total_train_time_s\": 11.658812999725342}", "{\"n\": 3429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.99, \"learn_time_ms\": 9005.099, \"total_train_time_s\": 10.689171314239502}", "{\"n\": 3430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.68, \"learn_time_ms\": 9187.045, \"total_train_time_s\": 10.569249391555786}", "{\"n\": 3431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.68, \"learn_time_ms\": 9145.808, \"total_train_time_s\": 9.985179662704468}", "{\"n\": 3432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.07, \"learn_time_ms\": 9078.32, \"total_train_time_s\": 10.582470417022705}", "{\"n\": 3433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.76, \"learn_time_ms\": 9005.672, \"total_train_time_s\": 9.607433795928955}", "{\"n\": 3434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.76, \"learn_time_ms\": 8952.527, \"total_train_time_s\": 9.545366525650024}", "{\"n\": 3435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.91, \"learn_time_ms\": 9140.571, \"total_train_time_s\": 11.271794557571411}", "{\"n\": 3436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.86, \"learn_time_ms\": 9197.204, \"total_train_time_s\": 10.324387311935425}", "{\"n\": 3437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.86, \"learn_time_ms\": 9034.792, \"total_train_time_s\": 10.33405876159668}", "{\"n\": 3438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.86, \"learn_time_ms\": 8988.9, \"total_train_time_s\": 11.154826879501343}", "{\"n\": 3439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.93, \"learn_time_ms\": 8861.67, \"total_train_time_s\": 9.38994312286377}", "{\"n\": 3440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.24, \"learn_time_ms\": 8848.742, \"total_train_time_s\": 10.405877590179443}", "{\"n\": 3441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.24, \"learn_time_ms\": 8796.72, \"total_train_time_s\": 9.465020656585693}", "{\"n\": 3442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.69, \"learn_time_ms\": 8859.226, \"total_train_time_s\": 11.199685096740723}", "{\"n\": 3443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.87, \"learn_time_ms\": 8874.133, \"total_train_time_s\": 9.737922430038452}", "{\"n\": 3444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.87, \"learn_time_ms\": 9002.344, \"total_train_time_s\": 10.90637493133545}", "{\"n\": 3445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.45, \"learn_time_ms\": 8985.317, \"total_train_time_s\": 11.135649919509888}", "{\"n\": 3446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.55, \"learn_time_ms\": 8989.771, \"total_train_time_s\": 10.352578163146973}", "{\"n\": 3447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.55, \"learn_time_ms\": 8943.752, \"total_train_time_s\": 9.791851997375488}", "{\"n\": 3448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.7, \"learn_time_ms\": 8787.831, \"total_train_time_s\": 9.602760553359985}", "{\"n\": 3449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.66, \"learn_time_ms\": 8792.035, \"total_train_time_s\": 9.479371309280396}", "{\"n\": 3450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3178.66, \"learn_time_ms\": 8851.044, \"total_train_time_s\": 10.99687933921814}", "{\"n\": 3451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.85, \"learn_time_ms\": 8864.495, \"total_train_time_s\": 9.566120147705078}", "{\"n\": 3452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.45, \"learn_time_ms\": 8748.449, \"total_train_time_s\": 10.018810272216797}", "{\"n\": 3453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.92, \"learn_time_ms\": 8784.555, \"total_train_time_s\": 10.155372381210327}", "{\"n\": 3454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.92, \"learn_time_ms\": 8670.164, \"total_train_time_s\": 9.75601601600647}", "{\"n\": 3455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.78, \"learn_time_ms\": 8579.299, \"total_train_time_s\": 10.211409091949463}", "{\"n\": 3456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.14, \"learn_time_ms\": 8566.821, \"total_train_time_s\": 10.273175239562988}", "{\"n\": 3457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.14, \"learn_time_ms\": 8520.225, \"total_train_time_s\": 9.362935304641724}", "{\"n\": 3458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3181.99, \"learn_time_ms\": 8576.785, \"total_train_time_s\": 10.152305603027344}", "{\"n\": 3459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.6, \"learn_time_ms\": 8602.844, \"total_train_time_s\": 9.711153030395508}", "{\"n\": 3460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.6, \"learn_time_ms\": 8494.7, \"total_train_time_s\": 9.894029140472412}", "{\"n\": 3461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3186.8, \"learn_time_ms\": 8533.996, \"total_train_time_s\": 9.955358743667603}", "{\"n\": 3462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3188.37, \"learn_time_ms\": 8582.479, \"total_train_time_s\": 10.511490106582642}", "{\"n\": 3463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 8572.846, \"total_train_time_s\": 10.02938199043274}", "{\"n\": 3464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3195.11, \"learn_time_ms\": 8565.521, \"total_train_time_s\": 9.675657510757446}", "{\"n\": 3465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3196.68, \"learn_time_ms\": 8632.917, \"total_train_time_s\": 10.894925355911255}", "{\"n\": 3466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 8826.243, \"total_train_time_s\": 12.215345859527588}", "{\"n\": 3467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 8951.491, \"total_train_time_s\": 10.531077146530151}", "{\"n\": 3468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3193.77, \"learn_time_ms\": 8927.039, \"total_train_time_s\": 9.915692329406738}", "{\"n\": 3469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.11, \"learn_time_ms\": 8915.822, \"total_train_time_s\": 9.606761932373047}", "{\"n\": 3470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.11, \"learn_time_ms\": 8863.922, \"total_train_time_s\": 9.433302164077759}", "{\"n\": 3471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.45, \"learn_time_ms\": 8726.582, \"total_train_time_s\": 8.56223440170288}", "{\"n\": 3472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.61, \"learn_time_ms\": 8672.349, \"total_train_time_s\": 9.984867572784424}", "{\"n\": 3473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.61, \"learn_time_ms\": 8816.918, \"total_train_time_s\": 11.507851600646973}", "{\"n\": 3474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.61, \"learn_time_ms\": 8999.86, \"total_train_time_s\": 11.529947280883789}", "{\"n\": 3475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.82, \"learn_time_ms\": 9022.811, \"total_train_time_s\": 11.113814115524292}", "{\"n\": 3476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.77, \"learn_time_ms\": 8901.537, \"total_train_time_s\": 10.966785192489624}", "{\"n\": 3477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.67, \"learn_time_ms\": 8704.864, \"total_train_time_s\": 8.64262318611145}", "{\"n\": 3478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.62, \"learn_time_ms\": 8825.558, \"total_train_time_s\": 11.153820037841797}", "{\"n\": 3479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.04, \"learn_time_ms\": 8755.269, \"total_train_time_s\": 8.870954513549805}", "{\"n\": 3480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.32, \"learn_time_ms\": 8882.56, \"total_train_time_s\": 10.693833351135254}", "{\"n\": 3481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.37, \"learn_time_ms\": 9173.923, \"total_train_time_s\": 11.502927780151367}", "{\"n\": 3482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.61, \"learn_time_ms\": 9172.276, \"total_train_time_s\": 9.972573041915894}", "{\"n\": 3483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.61, \"learn_time_ms\": 9034.532, \"total_train_time_s\": 10.13952922821045}", "{\"n\": 3484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.51, \"learn_time_ms\": 8904.545, \"total_train_time_s\": 10.204897403717041}", "{\"n\": 3485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.19, \"learn_time_ms\": 8795.808, \"total_train_time_s\": 10.049710035324097}", "{\"n\": 3486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.19, \"learn_time_ms\": 8659.675, \"total_train_time_s\": 9.604399681091309}", "{\"n\": 3487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.1, \"learn_time_ms\": 8660.426, \"total_train_time_s\": 8.593745470046997}", "{\"n\": 3488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.38, \"learn_time_ms\": 8633.713, \"total_train_time_s\": 10.863331079483032}", "{\"n\": 3489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.38, \"learn_time_ms\": 8730.987, \"total_train_time_s\": 9.842288732528687}", "{\"n\": 3490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.55, \"learn_time_ms\": 8651.772, \"total_train_time_s\": 9.855183839797974}", "{\"n\": 3491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.37, \"learn_time_ms\": 8564.259, \"total_train_time_s\": 10.613813877105713}", "{\"n\": 3492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.17, \"learn_time_ms\": 8655.968, \"total_train_time_s\": 10.881820917129517}", "{\"n\": 3493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.53, \"learn_time_ms\": 8663.875, \"total_train_time_s\": 10.25978422164917}", "{\"n\": 3494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.91, \"learn_time_ms\": 8688.283, \"total_train_time_s\": 10.47933030128479}", "{\"n\": 3495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.01, \"learn_time_ms\": 8652.601, \"total_train_time_s\": 9.688955783843994}", "{\"n\": 3496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.55, \"learn_time_ms\": 8626.623, \"total_train_time_s\": 9.364325284957886}", "{\"n\": 3497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.71, \"learn_time_ms\": 8807.962, \"total_train_time_s\": 10.458368062973022}", "{\"n\": 3498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.27, \"learn_time_ms\": 8730.703, \"total_train_time_s\": 10.12873649597168}", "{\"n\": 3499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.27, \"learn_time_ms\": 8730.361, \"total_train_time_s\": 9.852977275848389}", "{\"n\": 3500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.22, \"learn_time_ms\": 8646.413, \"total_train_time_s\": 9.066031217575073}", "{\"n\": 3501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.75, \"learn_time_ms\": 8596.485, \"total_train_time_s\": 10.15222978591919}", "{\"n\": 3502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.75, \"learn_time_ms\": 8566.76, \"total_train_time_s\": 10.576012372970581}", "{\"n\": 3503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.7, \"learn_time_ms\": 8645.292, \"total_train_time_s\": 11.02478551864624}", "{\"n\": 3504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.68, \"learn_time_ms\": 8626.761, \"total_train_time_s\": 10.296019077301025}", "{\"n\": 3505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.68, \"learn_time_ms\": 8647.306, \"total_train_time_s\": 9.873846769332886}", "{\"n\": 3506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.68, \"learn_time_ms\": 8635.076, \"total_train_time_s\": 9.284804344177246}", "{\"n\": 3507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.24, \"learn_time_ms\": 8727.492, \"total_train_time_s\": 11.394500017166138}", "{\"n\": 3508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.5, \"learn_time_ms\": 8842.128, \"total_train_time_s\": 11.222410440444946}", "{\"n\": 3509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.5, \"learn_time_ms\": 8856.476, \"total_train_time_s\": 10.00359058380127}", "{\"n\": 3510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.08, \"learn_time_ms\": 9053.021, \"total_train_time_s\": 11.063393592834473}", "{\"n\": 3511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.47, \"learn_time_ms\": 9040.62, \"total_train_time_s\": 9.999955415725708}", "{\"n\": 3512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.47, \"learn_time_ms\": 8889.419, \"total_train_time_s\": 9.086313247680664}", "{\"n\": 3513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.38, \"learn_time_ms\": 8783.954, \"total_train_time_s\": 9.920437574386597}", "{\"n\": 3514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.03, \"learn_time_ms\": 8824.317, \"total_train_time_s\": 10.713560104370117}", "{\"n\": 3515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.03, \"learn_time_ms\": 8836.423, \"total_train_time_s\": 10.01498293876648}", "{\"n\": 3516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.03, \"learn_time_ms\": 8869.713, \"total_train_time_s\": 9.545214414596558}", "{\"n\": 3517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.57, \"learn_time_ms\": 8865.055, \"total_train_time_s\": 11.326647520065308}", "{\"n\": 3518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.86, \"learn_time_ms\": 8891.004, \"total_train_time_s\": 11.48304796218872}", "{\"n\": 3519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.86, \"learn_time_ms\": 8921.04, \"total_train_time_s\": 10.287482738494873}", "{\"n\": 3520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3262.87, \"learn_time_ms\": 8756.896, \"total_train_time_s\": 9.341609954833984}", "{\"n\": 3521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3272.42, \"learn_time_ms\": 8900.912, \"total_train_time_s\": 11.452439069747925}", "{\"n\": 3522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3272.42, \"learn_time_ms\": 8766.966, \"total_train_time_s\": 7.760218858718872}", "{\"n\": 3523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.15, \"learn_time_ms\": 8811.566, \"total_train_time_s\": 10.388128995895386}", "{\"n\": 3524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.81, \"learn_time_ms\": 8836.139, \"total_train_time_s\": 10.967435121536255}", "{\"n\": 3525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.81, \"learn_time_ms\": 8862.382, \"total_train_time_s\": 10.27779507637024}", "{\"n\": 3526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.81, \"learn_time_ms\": 9033.321, \"total_train_time_s\": 11.26180362701416}", "{\"n\": 3527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.89, \"learn_time_ms\": 8863.668, \"total_train_time_s\": 9.629916429519653}", "{\"n\": 3528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.09, \"learn_time_ms\": 8871.625, \"total_train_time_s\": 11.571720600128174}", "{\"n\": 3529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.09, \"learn_time_ms\": 8961.488, \"total_train_time_s\": 11.193954467773438}", "{\"n\": 3530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.45, \"learn_time_ms\": 9045.307, \"total_train_time_s\": 10.233104467391968}", "{\"n\": 3531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.35, \"learn_time_ms\": 8954.441, \"total_train_time_s\": 10.533493518829346}", "{\"n\": 3532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.35, \"learn_time_ms\": 9179.459, \"total_train_time_s\": 9.984559774398804}", "{\"n\": 3533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3284.74, \"learn_time_ms\": 9114.464, \"total_train_time_s\": 9.698318481445312}", "{\"n\": 3534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.88, \"learn_time_ms\": 8925.407, \"total_train_time_s\": 9.047631740570068}", "{\"n\": 3535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.88, \"learn_time_ms\": 8926.596, \"total_train_time_s\": 10.260420083999634}", "{\"n\": 3536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.46, \"learn_time_ms\": 8840.564, \"total_train_time_s\": 10.392374038696289}", "{\"n\": 3537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.28, \"learn_time_ms\": 8893.822, \"total_train_time_s\": 10.166093587875366}", "{\"n\": 3538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.26, \"learn_time_ms\": 8683.375, \"total_train_time_s\": 9.462004899978638}", "{\"n\": 3539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.63, \"learn_time_ms\": 8597.684, \"total_train_time_s\": 10.422651529312134}", "{\"n\": 3540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.36, \"learn_time_ms\": 8711.757, \"total_train_time_s\": 11.349490642547607}", "{\"n\": 3541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.37, \"learn_time_ms\": 8688.892, \"total_train_time_s\": 10.29360055923462}", "{\"n\": 3542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.85, \"learn_time_ms\": 8625.787, \"total_train_time_s\": 9.386656999588013}", "{\"n\": 3543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.83, \"learn_time_ms\": 8716.554, \"total_train_time_s\": 10.682770490646362}", "{\"n\": 3544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.19, \"learn_time_ms\": 8775.924, \"total_train_time_s\": 9.622074365615845}", "{\"n\": 3545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.19, \"learn_time_ms\": 8942.463, \"total_train_time_s\": 11.926080703735352}", "{\"n\": 3546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.4, \"learn_time_ms\": 9000.797, \"total_train_time_s\": 11.039637804031372}", "{\"n\": 3547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.31, \"learn_time_ms\": 8822.461, \"total_train_time_s\": 8.365352392196655}", "{\"n\": 3548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.31, \"learn_time_ms\": 8882.153, \"total_train_time_s\": 10.06667709350586}", "{\"n\": 3549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.04, \"learn_time_ms\": 9028.615, \"total_train_time_s\": 11.8486487865448}", "{\"n\": 3550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.4, \"learn_time_ms\": 8981.828, \"total_train_time_s\": 10.918208599090576}", "{\"n\": 3551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.4, \"learn_time_ms\": 8853.009, \"total_train_time_s\": 9.022334814071655}", "{\"n\": 3552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.07, \"learn_time_ms\": 8936.099, \"total_train_time_s\": 10.17568063735962}", "{\"n\": 3553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3268.4, \"learn_time_ms\": 8934.088, \"total_train_time_s\": 10.66741943359375}", "{\"n\": 3554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3268.4, \"learn_time_ms\": 8933.06, \"total_train_time_s\": 9.622657299041748}", "{\"n\": 3555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.01, \"learn_time_ms\": 8749.451, \"total_train_time_s\": 10.1358482837677}", "{\"n\": 3556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.01, \"learn_time_ms\": 8732.833, \"total_train_time_s\": 10.868198156356812}", "{\"n\": 3557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3261.66, \"learn_time_ms\": 8841.96, \"total_train_time_s\": 9.494041681289673}", "{\"n\": 3558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3256.8, \"learn_time_ms\": 8916.149, \"total_train_time_s\": 10.87058424949646}", "{\"n\": 3559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3256.8, \"learn_time_ms\": 8647.993, \"total_train_time_s\": 9.090557098388672}", "{\"n\": 3560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3263.28, \"learn_time_ms\": 8663.609, \"total_train_time_s\": 11.052073955535889}", "{\"n\": 3561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3263.28, \"learn_time_ms\": 8829.316, \"total_train_time_s\": 10.695641040802002}", "{\"n\": 3562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.26, \"learn_time_ms\": 8772.614, \"total_train_time_s\": 9.611345052719116}", "{\"n\": 3563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.35, \"learn_time_ms\": 8785.49, \"total_train_time_s\": 10.76032567024231}", "{\"n\": 3564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.35, \"learn_time_ms\": 8913.822, \"total_train_time_s\": 10.89255976676941}", "{\"n\": 3565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3277.33, \"learn_time_ms\": 8900.713, \"total_train_time_s\": 10.020805358886719}", "{\"n\": 3566, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.35, \"learn_time_ms\": 8911.94, \"total_train_time_s\": 10.942132711410522}", "{\"n\": 3567, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.42, \"learn_time_ms\": 8877.844, \"total_train_time_s\": 9.113553285598755}", "{\"n\": 3568, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.38, \"learn_time_ms\": 8815.858, \"total_train_time_s\": 10.178727865219116}", "{\"n\": 3569, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.29, \"learn_time_ms\": 8936.277, \"total_train_time_s\": 10.33206820487976}", "{\"n\": 3570, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.52, \"learn_time_ms\": 8912.85, \"total_train_time_s\": 10.810391426086426}", "{\"n\": 3571, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.2, \"learn_time_ms\": 8852.125, \"total_train_time_s\": 10.084756135940552}", "{\"n\": 3572, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.48, \"learn_time_ms\": 9058.699, \"total_train_time_s\": 11.683547496795654}", "{\"n\": 3573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.61, \"learn_time_ms\": 9187.92, \"total_train_time_s\": 12.063469409942627}", "{\"n\": 3574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.59, \"learn_time_ms\": 9208.981, \"total_train_time_s\": 11.123486042022705}", "{\"n\": 3575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.58, \"learn_time_ms\": 9155.617, \"total_train_time_s\": 9.431578397750854}", "{\"n\": 3576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.42, \"learn_time_ms\": 9151.094, \"total_train_time_s\": 10.96464729309082}", "{\"n\": 3577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.01, \"learn_time_ms\": 9416.147, \"total_train_time_s\": 11.802859544754028}", "{\"n\": 3578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.01, \"learn_time_ms\": 9499.731, \"total_train_time_s\": 11.05156421661377}", "{\"n\": 3579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.11, \"learn_time_ms\": 9501.797, \"total_train_time_s\": 10.366959571838379}", "{\"n\": 3580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.11, \"learn_time_ms\": 9417.981, \"total_train_time_s\": 9.95177435874939}", "{\"n\": 3581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.52, \"learn_time_ms\": 9389.116, \"total_train_time_s\": 9.763037204742432}", "{\"n\": 3582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.56, \"learn_time_ms\": 9172.283, \"total_train_time_s\": 9.510494709014893}", "{\"n\": 3583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.56, \"learn_time_ms\": 8893.296, \"total_train_time_s\": 9.21591591835022}", "{\"n\": 3584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.23, \"learn_time_ms\": 8629.545, \"total_train_time_s\": 8.436731576919556}", "{\"n\": 3585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.86, \"learn_time_ms\": 8734.454, \"total_train_time_s\": 10.53342890739441}", "{\"n\": 3586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.53, \"learn_time_ms\": 8743.793, \"total_train_time_s\": 11.052865505218506}", "{\"n\": 3587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.61, \"learn_time_ms\": 8588.091, \"total_train_time_s\": 10.288064002990723}", "{\"n\": 3588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.92, \"learn_time_ms\": 8615.933, \"total_train_time_s\": 11.288976192474365}", "{\"n\": 3589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.8, \"learn_time_ms\": 8578.895, \"total_train_time_s\": 9.993646144866943}", "{\"n\": 3590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.8, \"learn_time_ms\": 8697.979, \"total_train_time_s\": 11.190932989120483}", "{\"n\": 3591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.67, \"learn_time_ms\": 8761.606, \"total_train_time_s\": 10.423641443252563}", "{\"n\": 3592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.62, \"learn_time_ms\": 8798.858, \"total_train_time_s\": 9.896749258041382}", "{\"n\": 3593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.66, \"learn_time_ms\": 8857.052, \"total_train_time_s\": 9.81348705291748}", "{\"n\": 3594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.88, \"learn_time_ms\": 9088.213, \"total_train_time_s\": 10.774169445037842}", "{\"n\": 3595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.25, \"learn_time_ms\": 9033.444, \"total_train_time_s\": 9.940067291259766}", "{\"n\": 3596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.32, \"learn_time_ms\": 8991.995, \"total_train_time_s\": 10.595830917358398}", "{\"n\": 3597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.8, \"learn_time_ms\": 8886.982, \"total_train_time_s\": 9.196085691452026}", "{\"n\": 3598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.19, \"learn_time_ms\": 8813.788, \"total_train_time_s\": 10.584058046340942}", "{\"n\": 3599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.19, \"learn_time_ms\": 8824.327, \"total_train_time_s\": 10.102622985839844}", "{\"n\": 3600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.9, \"learn_time_ms\": 8802.903, \"total_train_time_s\": 10.970818758010864}", "{\"n\": 3601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.95, \"learn_time_ms\": 8738.062, \"total_train_time_s\": 9.777411699295044}", "{\"n\": 3602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.25, \"learn_time_ms\": 8583.955, \"total_train_time_s\": 8.348088502883911}", "{\"n\": 3603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.07, \"learn_time_ms\": 8571.941, \"total_train_time_s\": 9.721031665802002}", "{\"n\": 3604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.98, \"learn_time_ms\": 8622.613, \"total_train_time_s\": 11.319941282272339}", "{\"n\": 3605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.92, \"learn_time_ms\": 8747.855, \"total_train_time_s\": 11.170696258544922}", "{\"n\": 3606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.31, \"learn_time_ms\": 8739.92, \"total_train_time_s\": 10.541195392608643}", "{\"n\": 3607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.31, \"learn_time_ms\": 8909.925, \"total_train_time_s\": 10.864896774291992}", "{\"n\": 3608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.26, \"learn_time_ms\": 8881.714, \"total_train_time_s\": 10.273850440979004}", "{\"n\": 3609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.79, \"learn_time_ms\": 8895.588, \"total_train_time_s\": 10.239819288253784}", "{\"n\": 3610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.79, \"learn_time_ms\": 8902.549, \"total_train_time_s\": 10.991702318191528}", "{\"n\": 3611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.51, \"learn_time_ms\": 8909.136, \"total_train_time_s\": 9.865870952606201}", "{\"n\": 3612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.01, \"learn_time_ms\": 9223.48, \"total_train_time_s\": 11.497681617736816}", "{\"n\": 3613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.01, \"learn_time_ms\": 9296.673, \"total_train_time_s\": 10.45510745048523}", "{\"n\": 3614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.76, \"learn_time_ms\": 9362.287, \"total_train_time_s\": 11.906722068786621}", "{\"n\": 3615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.98, \"learn_time_ms\": 9319.326, \"total_train_time_s\": 10.795462846755981}", "{\"n\": 3616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.98, \"learn_time_ms\": 9300.611, \"total_train_time_s\": 10.300798177719116}", "{\"n\": 3617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.98, \"learn_time_ms\": 9248.279, \"total_train_time_s\": 10.329304695129395}", "{\"n\": 3618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.08, \"learn_time_ms\": 9379.153, \"total_train_time_s\": 11.606707572937012}", "{\"n\": 3619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.83, \"learn_time_ms\": 9249.414, \"total_train_time_s\": 8.917938947677612}", "{\"n\": 3620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.83, \"learn_time_ms\": 9037.538, \"total_train_time_s\": 8.878763198852539}", "{\"n\": 3621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.28, \"learn_time_ms\": 9150.729, \"total_train_time_s\": 11.015220642089844}", "{\"n\": 3622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.07, \"learn_time_ms\": 8993.438, \"total_train_time_s\": 9.894529104232788}", "{\"n\": 3623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.07, \"learn_time_ms\": 9028.341, \"total_train_time_s\": 10.79267930984497}", "{\"n\": 3624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.4, \"learn_time_ms\": 8840.726, \"total_train_time_s\": 10.039804697036743}", "{\"n\": 3625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.42, \"learn_time_ms\": 8768.348, \"total_train_time_s\": 10.070743322372437}", "{\"n\": 3626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.42, \"learn_time_ms\": 8686.52, \"total_train_time_s\": 9.46221399307251}", "{\"n\": 3627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.95, \"learn_time_ms\": 8780.245, \"total_train_time_s\": 11.308195114135742}", "{\"n\": 3628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.58, \"learn_time_ms\": 8627.228, \"total_train_time_s\": 10.04443073272705}", "{\"n\": 3629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.58, \"learn_time_ms\": 8802.349, \"total_train_time_s\": 10.709493160247803}", "{\"n\": 3630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.25, \"learn_time_ms\": 8857.537, \"total_train_time_s\": 9.430248498916626}", "{\"n\": 3631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.17, \"learn_time_ms\": 8857.201, \"total_train_time_s\": 10.990903854370117}", "{\"n\": 3632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.17, \"learn_time_ms\": 8810.335, \"total_train_time_s\": 9.401241064071655}", "{\"n\": 3633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.06, \"learn_time_ms\": 8911.254, \"total_train_time_s\": 11.786106586456299}", "{\"n\": 3634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.11, \"learn_time_ms\": 8960.091, \"total_train_time_s\": 10.55090618133545}", "{\"n\": 3635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.86, \"learn_time_ms\": 8809.771, \"total_train_time_s\": 8.553248643875122}", "{\"n\": 3636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.86, \"learn_time_ms\": 8983.781, \"total_train_time_s\": 11.211730480194092}", "{\"n\": 3637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8930.393, \"total_train_time_s\": 10.773677349090576}", "{\"n\": 3638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.18, \"learn_time_ms\": 9004.197, \"total_train_time_s\": 10.793173789978027}", "{\"n\": 3639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.18, \"learn_time_ms\": 8999.162, \"total_train_time_s\": 10.627795457839966}", "{\"n\": 3640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.44, \"learn_time_ms\": 9124.058, \"total_train_time_s\": 10.72069525718689}", "{\"n\": 3641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.0, \"learn_time_ms\": 8970.693, \"total_train_time_s\": 9.436359405517578}", "{\"n\": 3642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.0, \"learn_time_ms\": 8953.612, \"total_train_time_s\": 9.290338516235352}", "{\"n\": 3643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.71, \"learn_time_ms\": 8707.245, \"total_train_time_s\": 9.336752653121948}", "{\"n\": 3644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.2, \"learn_time_ms\": 8710.663, \"total_train_time_s\": 10.554914951324463}", "{\"n\": 3645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.2, \"learn_time_ms\": 8853.57, \"total_train_time_s\": 9.941323041915894}", "{\"n\": 3646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 8771.74, \"total_train_time_s\": 10.40265941619873}", "{\"n\": 3647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.8, \"learn_time_ms\": 8732.702, \"total_train_time_s\": 10.360734462738037}", "{\"n\": 3648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.8, \"learn_time_ms\": 8691.434, \"total_train_time_s\": 10.373488187789917}", "{\"n\": 3649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.69, \"learn_time_ms\": 8496.224, \"total_train_time_s\": 8.670706510543823}", "{\"n\": 3650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.76, \"learn_time_ms\": 8502.093, \"total_train_time_s\": 10.760239124298096}", "{\"n\": 3651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.76, \"learn_time_ms\": 8725.741, \"total_train_time_s\": 11.660643339157104}", "{\"n\": 3652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.73, \"learn_time_ms\": 8855.873, \"total_train_time_s\": 10.585814476013184}", "{\"n\": 3653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.9, \"learn_time_ms\": 8965.331, \"total_train_time_s\": 10.402589321136475}", "{\"n\": 3654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.04, \"learn_time_ms\": 8938.278, \"total_train_time_s\": 10.308155536651611}", "{\"n\": 3655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.67, \"learn_time_ms\": 8993.718, \"total_train_time_s\": 10.547495126724243}", "{\"n\": 3656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.2, \"learn_time_ms\": 8894.377, \"total_train_time_s\": 9.461953401565552}", "{\"n\": 3657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.61, \"learn_time_ms\": 8970.714, \"total_train_time_s\": 11.131371259689331}", "{\"n\": 3658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.61, \"learn_time_ms\": 8995.678, \"total_train_time_s\": 10.649853944778442}", "{\"n\": 3659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.05, \"learn_time_ms\": 8980.766, \"total_train_time_s\": 8.558982133865356}", "{\"n\": 3660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.93, \"learn_time_ms\": 8882.11, \"total_train_time_s\": 9.772381782531738}", "{\"n\": 3661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.82, \"learn_time_ms\": 8823.906, \"total_train_time_s\": 11.079835891723633}", "{\"n\": 3662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.68, \"learn_time_ms\": 8825.79, \"total_train_time_s\": 10.580224990844727}", "{\"n\": 3663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.37, \"learn_time_ms\": 8859.901, \"total_train_time_s\": 10.752668142318726}", "{\"n\": 3664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.66, \"learn_time_ms\": 8943.573, \"total_train_time_s\": 11.14238429069519}", "{\"n\": 3665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.66, \"learn_time_ms\": 8986.327, \"total_train_time_s\": 10.98265290260315}", "{\"n\": 3666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.8, \"learn_time_ms\": 9091.852, \"total_train_time_s\": 10.488886833190918}", "{\"n\": 3667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.08, \"learn_time_ms\": 9134.056, \"total_train_time_s\": 11.564058780670166}", "{\"n\": 3668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.08, \"learn_time_ms\": 9144.137, \"total_train_time_s\": 10.755365371704102}", "{\"n\": 3669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.8, \"learn_time_ms\": 9286.175, \"total_train_time_s\": 9.907393217086792}", "{\"n\": 3670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.06, \"learn_time_ms\": 9301.462, \"total_train_time_s\": 9.916560173034668}", "{\"n\": 3671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.06, \"learn_time_ms\": 9179.444, \"total_train_time_s\": 9.882238149642944}", "{\"n\": 3672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.17, \"learn_time_ms\": 9031.28, \"total_train_time_s\": 9.095511674880981}", "{\"n\": 3673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.73, \"learn_time_ms\": 9114.824, \"total_train_time_s\": 11.618968486785889}", "{\"n\": 3674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.73, \"learn_time_ms\": 9039.804, \"total_train_time_s\": 10.427636623382568}", "{\"n\": 3675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.44, \"learn_time_ms\": 9127.473, \"total_train_time_s\": 11.845593452453613}", "{\"n\": 3676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.9, \"learn_time_ms\": 9088.11, \"total_train_time_s\": 10.090869903564453}", "{\"n\": 3677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.85, \"learn_time_ms\": 8867.307, \"total_train_time_s\": 9.32731819152832}", "{\"n\": 3678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.77, \"learn_time_ms\": 8791.926, \"total_train_time_s\": 9.983322381973267}", "{\"n\": 3679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.71, \"learn_time_ms\": 8852.362, \"total_train_time_s\": 10.575158834457397}", "{\"n\": 3680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.5, \"learn_time_ms\": 8825.591, \"total_train_time_s\": 9.675461053848267}", "{\"n\": 3681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.24, \"learn_time_ms\": 8781.578, \"total_train_time_s\": 9.449257373809814}", "{\"n\": 3682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.76, \"learn_time_ms\": 8851.666, \"total_train_time_s\": 9.86124324798584}", "{\"n\": 3683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.09, \"learn_time_ms\": 8896.737, \"total_train_time_s\": 12.086359977722168}", "{\"n\": 3684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.09, \"learn_time_ms\": 8723.45, \"total_train_time_s\": 8.692970752716064}", "{\"n\": 3685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.14, \"learn_time_ms\": 8669.38, \"total_train_time_s\": 11.299181699752808}", "{\"n\": 3686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.65, \"learn_time_ms\": 8768.836, \"total_train_time_s\": 11.106074571609497}", "{\"n\": 3687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.3, \"learn_time_ms\": 8856.444, \"total_train_time_s\": 10.242042303085327}", "{\"n\": 3688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.01, \"learn_time_ms\": 8938.189, \"total_train_time_s\": 10.833152532577515}", "{\"n\": 3689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.47, \"learn_time_ms\": 8789.817, \"total_train_time_s\": 9.111780643463135}", "{\"n\": 3690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.56, \"learn_time_ms\": 8730.721, \"total_train_time_s\": 9.065638303756714}", "{\"n\": 3691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.82, \"learn_time_ms\": 8782.912, \"total_train_time_s\": 10.003227710723877}", "{\"n\": 3692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.81, \"learn_time_ms\": 8763.321, \"total_train_time_s\": 9.616901397705078}", "{\"n\": 3693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 8421.91, \"total_train_time_s\": 8.629730224609375}", "{\"n\": 3694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.62, \"learn_time_ms\": 8491.484, \"total_train_time_s\": 9.380892276763916}", "{\"n\": 3695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.95, \"learn_time_ms\": 8448.723, \"total_train_time_s\": 10.87431788444519}", "{\"n\": 3696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.01, \"learn_time_ms\": 8387.896, \"total_train_time_s\": 10.47040843963623}", "{\"n\": 3697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.41, \"learn_time_ms\": 8394.783, \"total_train_time_s\": 10.292290687561035}", "{\"n\": 3698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.41, \"learn_time_ms\": 8292.867, \"total_train_time_s\": 9.787242412567139}", "{\"n\": 3699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.33, \"learn_time_ms\": 8406.556, \"total_train_time_s\": 10.24976396560669}", "{\"n\": 3700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.5, \"learn_time_ms\": 8696.318, \"total_train_time_s\": 11.929312229156494}", "{\"n\": 3701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.17, \"learn_time_ms\": 8663.007, \"total_train_time_s\": 9.617530345916748}", "{\"n\": 3702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.71, \"learn_time_ms\": 8623.3, \"total_train_time_s\": 9.233933687210083}", "{\"n\": 3703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.97, \"learn_time_ms\": 8782.471, \"total_train_time_s\": 10.25478458404541}", "{\"n\": 3704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.19, \"learn_time_ms\": 8812.5, \"total_train_time_s\": 9.705496311187744}", "{\"n\": 3705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.19, \"learn_time_ms\": 8810.287, \"total_train_time_s\": 10.819396495819092}", "{\"n\": 3706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.8, \"learn_time_ms\": 8885.338, \"total_train_time_s\": 11.259385347366333}", "{\"n\": 3707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.34, \"learn_time_ms\": 8787.458, \"total_train_time_s\": 9.36715292930603}", "{\"n\": 3708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.34, \"learn_time_ms\": 8891.685, \"total_train_time_s\": 10.813416481018066}", "{\"n\": 3709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.79, \"learn_time_ms\": 8893.745, \"total_train_time_s\": 10.240591287612915}", "{\"n\": 3710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.27, \"learn_time_ms\": 8687.767, \"total_train_time_s\": 9.905938863754272}", "{\"n\": 3711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.27, \"learn_time_ms\": 8771.614, \"total_train_time_s\": 10.46860671043396}", "{\"n\": 3712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.67, \"learn_time_ms\": 8863.031, \"total_train_time_s\": 10.147400379180908}", "{\"n\": 3713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.84, \"learn_time_ms\": 8779.232, \"total_train_time_s\": 9.414839029312134}", "{\"n\": 3714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.84, \"learn_time_ms\": 8883.947, \"total_train_time_s\": 10.706584692001343}", "{\"n\": 3715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.89, \"learn_time_ms\": 8857.092, \"total_train_time_s\": 10.580585241317749}", "{\"n\": 3716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.47, \"learn_time_ms\": 8842.625, \"total_train_time_s\": 11.085086345672607}", "{\"n\": 3717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.32, \"learn_time_ms\": 8861.324, \"total_train_time_s\": 9.483291864395142}", "{\"n\": 3718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.57, \"learn_time_ms\": 8859.591, \"total_train_time_s\": 10.825947761535645}", "{\"n\": 3719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.13, \"learn_time_ms\": 8692.924, \"total_train_time_s\": 8.551400184631348}", "{\"n\": 3720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.97, \"learn_time_ms\": 8658.266, \"total_train_time_s\": 9.557313919067383}", "{\"n\": 3721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.97, \"learn_time_ms\": 8690.286, \"total_train_time_s\": 10.768896579742432}", "{\"n\": 3722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.52, \"learn_time_ms\": 8804.712, \"total_train_time_s\": 11.30388069152832}", "{\"n\": 3723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.48, \"learn_time_ms\": 8994.933, \"total_train_time_s\": 11.303934097290039}", "{\"n\": 3724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.63, \"learn_time_ms\": 8855.588, \"total_train_time_s\": 9.352915048599243}", "{\"n\": 3725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.97, \"learn_time_ms\": 8826.74, \"total_train_time_s\": 10.26904559135437}", "{\"n\": 3726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.58, \"learn_time_ms\": 8859.99, \"total_train_time_s\": 11.387616395950317}", "{\"n\": 3727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.92, \"learn_time_ms\": 8950.185, \"total_train_time_s\": 10.41365909576416}", "{\"n\": 3728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.07, \"learn_time_ms\": 8881.152, \"total_train_time_s\": 10.134443044662476}", "{\"n\": 3729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.07, \"learn_time_ms\": 9080.496, \"total_train_time_s\": 10.57689118385315}", "{\"n\": 3730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.67, \"learn_time_ms\": 9166.093, \"total_train_time_s\": 10.440324544906616}", "{\"n\": 3731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.53, \"learn_time_ms\": 9129.8, \"total_train_time_s\": 10.434267044067383}", "{\"n\": 3732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.53, \"learn_time_ms\": 8988.373, \"total_train_time_s\": 9.88895583152771}", "{\"n\": 3733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.55, \"learn_time_ms\": 8952.11, \"total_train_time_s\": 10.966133117675781}", "{\"n\": 3734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.13, \"learn_time_ms\": 8972.089, \"total_train_time_s\": 9.580156087875366}", "{\"n\": 3735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.13, \"learn_time_ms\": 8957.267, \"total_train_time_s\": 10.134496927261353}", "{\"n\": 3736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.51, \"learn_time_ms\": 8963.17, \"total_train_time_s\": 11.518723249435425}", "{\"n\": 3737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3250.32, \"learn_time_ms\": 9112.887, \"total_train_time_s\": 11.920816898345947}", "{\"n\": 3738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.3, \"learn_time_ms\": 9195.1, \"total_train_time_s\": 10.91029167175293}", "{\"n\": 3739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.67, \"learn_time_ms\": 9197.925, \"total_train_time_s\": 10.566556215286255}", "{\"n\": 3740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3239.9, \"learn_time_ms\": 9334.564, \"total_train_time_s\": 11.76246690750122}", "{\"n\": 3741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.07, \"learn_time_ms\": 9292.442, \"total_train_time_s\": 9.975977897644043}", "{\"n\": 3742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.88, \"learn_time_ms\": 9371.487, \"total_train_time_s\": 10.63404655456543}", "{\"n\": 3743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.63, \"learn_time_ms\": 9252.408, \"total_train_time_s\": 9.763710021972656}", "{\"n\": 3744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.67, \"learn_time_ms\": 9300.989, \"total_train_time_s\": 10.032330513000488}", "{\"n\": 3745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.67, \"learn_time_ms\": 9454.948, \"total_train_time_s\": 11.65646505355835}", "{\"n\": 3746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.1, \"learn_time_ms\": 9228.788, \"total_train_time_s\": 9.221212387084961}", "{\"n\": 3747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.83, \"learn_time_ms\": 9089.078, \"total_train_time_s\": 10.511887073516846}", "{\"n\": 3748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.83, \"learn_time_ms\": 9102.022, \"total_train_time_s\": 11.086850643157959}", "{\"n\": 3749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.6, \"learn_time_ms\": 8984.12, \"total_train_time_s\": 9.431782960891724}", "{\"n\": 3750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.6, \"learn_time_ms\": 8866.143, \"total_train_time_s\": 10.614958047866821}", "{\"n\": 3751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.51, \"learn_time_ms\": 8829.867, \"total_train_time_s\": 9.615801334381104}", "{\"n\": 3752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.93, \"learn_time_ms\": 8822.723, \"total_train_time_s\": 10.636645555496216}", "{\"n\": 3753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.93, \"learn_time_ms\": 8960.072, \"total_train_time_s\": 11.096824169158936}", "{\"n\": 3754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.17, \"learn_time_ms\": 8870.053, \"total_train_time_s\": 9.12438416481018}", "{\"n\": 3755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.18, \"learn_time_ms\": 8761.173, \"total_train_time_s\": 10.583046197891235}", "{\"n\": 3756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.18, \"learn_time_ms\": 8756.412, \"total_train_time_s\": 9.138144969940186}", "{\"n\": 3757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.95, \"learn_time_ms\": 8726.162, \"total_train_time_s\": 10.190284729003906}", "{\"n\": 3758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.5, \"learn_time_ms\": 8587.355, \"total_train_time_s\": 9.735857248306274}", "{\"n\": 3759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.36, \"learn_time_ms\": 8649.809, \"total_train_time_s\": 10.004741191864014}", "{\"n\": 3760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.82, \"learn_time_ms\": 8699.871, \"total_train_time_s\": 11.069428205490112}", "{\"n\": 3761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.82, \"learn_time_ms\": 8778.529, \"total_train_time_s\": 10.458198308944702}", "{\"n\": 3762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.32, \"learn_time_ms\": 8753.766, \"total_train_time_s\": 10.380805015563965}", "{\"n\": 3763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.42, \"learn_time_ms\": 8761.648, \"total_train_time_s\": 11.181946516036987}", "{\"n\": 3764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.42, \"learn_time_ms\": 8985.158, \"total_train_time_s\": 11.300462484359741}", "{\"n\": 3765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.17, \"learn_time_ms\": 8758.5, \"total_train_time_s\": 8.319663286209106}", "{\"n\": 3766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.68, \"learn_time_ms\": 9001.647, \"total_train_time_s\": 11.569955348968506}", "{\"n\": 3767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.68, \"learn_time_ms\": 8928.888, \"total_train_time_s\": 9.470750093460083}", "{\"n\": 3768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.74, \"learn_time_ms\": 9039.448, \"total_train_time_s\": 10.785223722457886}", "{\"n\": 3769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.92, \"learn_time_ms\": 9043.126, \"total_train_time_s\": 10.102179765701294}", "{\"n\": 3770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.92, \"learn_time_ms\": 8971.434, \"total_train_time_s\": 10.34822154045105}", "{\"n\": 3771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.06, \"learn_time_ms\": 8927.455, \"total_train_time_s\": 9.933310508728027}", "{\"n\": 3772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.39, \"learn_time_ms\": 8904.156, \"total_train_time_s\": 10.099833488464355}", "{\"n\": 3773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.48, \"learn_time_ms\": 8941.179, \"total_train_time_s\": 11.546932220458984}", "{\"n\": 3774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.1, \"learn_time_ms\": 8949.965, \"total_train_time_s\": 11.46093225479126}", "{\"n\": 3775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.1, \"learn_time_ms\": 9132.93, \"total_train_time_s\": 10.1442289352417}", "{\"n\": 3776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.58, \"learn_time_ms\": 9102.463, \"total_train_time_s\": 11.329739093780518}", "{\"n\": 3777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.38, \"learn_time_ms\": 9190.907, \"total_train_time_s\": 10.347958087921143}", "{\"n\": 3778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.38, \"learn_time_ms\": 9133.205, \"total_train_time_s\": 10.209120988845825}", "{\"n\": 3779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.44, \"learn_time_ms\": 9219.543, \"total_train_time_s\": 10.88735055923462}", "{\"n\": 3780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.06, \"learn_time_ms\": 9304.975, \"total_train_time_s\": 11.210935115814209}", "{\"n\": 3781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.9, \"learn_time_ms\": 9436.391, \"total_train_time_s\": 11.242880821228027}", "{\"n\": 3782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.68, \"learn_time_ms\": 9395.793, \"total_train_time_s\": 9.692772388458252}", "{\"n\": 3783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.54, \"learn_time_ms\": 9432.179, \"total_train_time_s\": 11.881179571151733}", "{\"n\": 3784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.03, \"learn_time_ms\": 9305.05, \"total_train_time_s\": 10.188398599624634}", "{\"n\": 3785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.62, \"learn_time_ms\": 9454.041, \"total_train_time_s\": 11.62491226196289}", "{\"n\": 3786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.54, \"learn_time_ms\": 9259.155, \"total_train_time_s\": 9.385313749313354}", "{\"n\": 3787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.25, \"learn_time_ms\": 9268.997, \"total_train_time_s\": 10.454688310623169}", "{\"n\": 3788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.03, \"learn_time_ms\": 9318.021, \"total_train_time_s\": 10.703152179718018}", "{\"n\": 3789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.64, \"learn_time_ms\": 9155.041, \"total_train_time_s\": 9.269275903701782}", "{\"n\": 3790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.22, \"learn_time_ms\": 8990.931, \"total_train_time_s\": 9.590721130371094}", "{\"n\": 3791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.22, \"learn_time_ms\": 8716.409, \"total_train_time_s\": 8.529995679855347}", "{\"n\": 3792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.14, \"learn_time_ms\": 8705.042, \"total_train_time_s\": 9.5970299243927}", "{\"n\": 3793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.42, \"learn_time_ms\": 8528.345, \"total_train_time_s\": 10.116263151168823}", "{\"n\": 3794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.42, \"learn_time_ms\": 8409.69, \"total_train_time_s\": 8.99526047706604}", "{\"n\": 3795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.64, \"learn_time_ms\": 8195.235, \"total_train_time_s\": 9.54393482208252}", "{\"n\": 3796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.91, \"learn_time_ms\": 8129.912, \"total_train_time_s\": 8.68119502067566}", "{\"n\": 3797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.91, \"learn_time_ms\": 8167.091, \"total_train_time_s\": 10.796637773513794}", "{\"n\": 3798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.39, \"learn_time_ms\": 8163.056, \"total_train_time_s\": 10.671247959136963}", "{\"n\": 3799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.34, \"learn_time_ms\": 8197.797, \"total_train_time_s\": 9.679428100585938}", "{\"n\": 3800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.2, \"learn_time_ms\": 8231.066, \"total_train_time_s\": 9.96305799484253}", "{\"n\": 3801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.2, \"learn_time_ms\": 8436.527, \"total_train_time_s\": 10.584305047988892}", "{\"n\": 3802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.28, \"learn_time_ms\": 8624.693, \"total_train_time_s\": 11.458058595657349}", "{\"n\": 3803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.4, \"learn_time_ms\": 8695.383, \"total_train_time_s\": 10.842537879943848}", "{\"n\": 3804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.4, \"learn_time_ms\": 8847.624, \"total_train_time_s\": 10.486664056777954}", "{\"n\": 3805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.6, \"learn_time_ms\": 8882.542, \"total_train_time_s\": 9.868191719055176}", "{\"n\": 3806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.35, \"learn_time_ms\": 9135.41, \"total_train_time_s\": 11.239379405975342}", "{\"n\": 3807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.35, \"learn_time_ms\": 9210.185, \"total_train_time_s\": 11.591540336608887}", "{\"n\": 3808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.84, \"learn_time_ms\": 9105.936, \"total_train_time_s\": 9.636158227920532}", "{\"n\": 3809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.54, \"learn_time_ms\": 9083.203, \"total_train_time_s\": 9.418097496032715}", "{\"n\": 3810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.54, \"learn_time_ms\": 9134.954, \"total_train_time_s\": 10.415111303329468}", "{\"n\": 3811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.97, \"learn_time_ms\": 9086.103, \"total_train_time_s\": 10.126285314559937}", "{\"n\": 3812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.18, \"learn_time_ms\": 8928.075, \"total_train_time_s\": 9.887640237808228}", "{\"n\": 3813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.24, \"learn_time_ms\": 8879.257, \"total_train_time_s\": 10.40458059310913}", "{\"n\": 3814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.01, \"learn_time_ms\": 8826.266, \"total_train_time_s\": 9.981098651885986}", "{\"n\": 3815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.58, \"learn_time_ms\": 8850.706, \"total_train_time_s\": 10.071238040924072}", "{\"n\": 3816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.58, \"learn_time_ms\": 8666.286, \"total_train_time_s\": 9.345545530319214}", "{\"n\": 3817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.07, \"learn_time_ms\": 8404.841, \"total_train_time_s\": 8.93885326385498}", "{\"n\": 3818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.81, \"learn_time_ms\": 8387.821, \"total_train_time_s\": 9.460914134979248}", "{\"n\": 3819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.81, \"learn_time_ms\": 8452.628, \"total_train_time_s\": 10.033198833465576}", "{\"n\": 3820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.23, \"learn_time_ms\": 8358.497, \"total_train_time_s\": 9.50800371170044}", "{\"n\": 3821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.32, \"learn_time_ms\": 8366.907, \"total_train_time_s\": 10.170988321304321}", "{\"n\": 3822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.52, \"learn_time_ms\": 8328.309, \"total_train_time_s\": 9.500916004180908}", "{\"n\": 3823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.84, \"learn_time_ms\": 8324.172, \"total_train_time_s\": 10.334834814071655}", "{\"n\": 3824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.96, \"learn_time_ms\": 8371.872, \"total_train_time_s\": 10.439777851104736}", "{\"n\": 3825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.16, \"learn_time_ms\": 8511.79, \"total_train_time_s\": 11.468943357467651}", "{\"n\": 3826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.36, \"learn_time_ms\": 8611.898, \"total_train_time_s\": 10.330695152282715}", "{\"n\": 3827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.36, \"learn_time_ms\": 8698.943, \"total_train_time_s\": 9.844367265701294}", "{\"n\": 3828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.09, \"learn_time_ms\": 8804.327, \"total_train_time_s\": 10.49793291091919}", "{\"n\": 3829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.09, \"learn_time_ms\": 8698.353, \"total_train_time_s\": 9.016536712646484}", "{\"n\": 3830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.13, \"learn_time_ms\": 8843.275, \"total_train_time_s\": 10.943552732467651}", "{\"n\": 3831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.01, \"learn_time_ms\": 8682.301, \"total_train_time_s\": 8.619219779968262}", "{\"n\": 3832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.01, \"learn_time_ms\": 8777.843, \"total_train_time_s\": 10.443179845809937}", "{\"n\": 3833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.12, \"learn_time_ms\": 8720.969, \"total_train_time_s\": 9.757241010665894}", "{\"n\": 3834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.55, \"learn_time_ms\": 8705.784, \"total_train_time_s\": 10.265507936477661}", "{\"n\": 3835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.09, \"learn_time_ms\": 8674.112, \"total_train_time_s\": 11.17074704170227}", "{\"n\": 3836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.95, \"learn_time_ms\": 8638.913, \"total_train_time_s\": 9.988399028778076}", "{\"n\": 3837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.0, \"learn_time_ms\": 8604.613, \"total_train_time_s\": 9.460598707199097}", "{\"n\": 3838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.41, \"learn_time_ms\": 8457.037, \"total_train_time_s\": 9.05062747001648}", "{\"n\": 3839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.38, \"learn_time_ms\": 8481.964, \"total_train_time_s\": 9.321191787719727}", "{\"n\": 3840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.38, \"learn_time_ms\": 8415.113, \"total_train_time_s\": 10.216540336608887}", "{\"n\": 3841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.6, \"learn_time_ms\": 8583.239, \"total_train_time_s\": 10.302204132080078}", "{\"n\": 3842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.46, \"learn_time_ms\": 8467.397, \"total_train_time_s\": 9.308926820755005}", "{\"n\": 3843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.46, \"learn_time_ms\": 8467.573, \"total_train_time_s\": 9.754554033279419}", "{\"n\": 3844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.68, \"learn_time_ms\": 8434.254, \"total_train_time_s\": 9.988027095794678}", "{\"n\": 3845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.68, \"learn_time_ms\": 8461.655, \"total_train_time_s\": 11.413107872009277}", "{\"n\": 3846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.97, \"learn_time_ms\": 8482.096, \"total_train_time_s\": 10.217943906784058}", "{\"n\": 3847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.8, \"learn_time_ms\": 8659.903, \"total_train_time_s\": 11.22933053970337}", "{\"n\": 3848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.9, \"learn_time_ms\": 8779.191, \"total_train_time_s\": 10.233139276504517}", "{\"n\": 3849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.51, \"learn_time_ms\": 8925.437, \"total_train_time_s\": 10.749999046325684}", "{\"n\": 3850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.51, \"learn_time_ms\": 8845.94, \"total_train_time_s\": 9.506948709487915}", "{\"n\": 3851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.89, \"learn_time_ms\": 8656.619, \"total_train_time_s\": 8.396754503250122}", "{\"n\": 3852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.89, \"learn_time_ms\": 8797.012, \"total_train_time_s\": 10.70401406288147}", "{\"n\": 3853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.48, \"learn_time_ms\": 8945.879, \"total_train_time_s\": 11.267472267150879}", "{\"n\": 3854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 9028.824, \"total_train_time_s\": 10.745364904403687}", "{\"n\": 3855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 9030.442, \"total_train_time_s\": 11.450078248977661}", "{\"n\": 3856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.26, \"learn_time_ms\": 9167.563, \"total_train_time_s\": 11.615968227386475}", "{\"n\": 3857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.33, \"learn_time_ms\": 8944.173, \"total_train_time_s\": 9.016144275665283}", "{\"n\": 3858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.33, \"learn_time_ms\": 8910.109, \"total_train_time_s\": 9.836036682128906}", "{\"n\": 3859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.85, \"learn_time_ms\": 8765.411, \"total_train_time_s\": 9.286762714385986}", "{\"n\": 3860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.81, \"learn_time_ms\": 8840.192, \"total_train_time_s\": 10.284737825393677}", "{\"n\": 3861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.84, \"learn_time_ms\": 8964.683, \"total_train_time_s\": 9.638644933700562}", "{\"n\": 3862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.86, \"learn_time_ms\": 9051.67, \"total_train_time_s\": 11.578086614608765}", "{\"n\": 3863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.48, \"learn_time_ms\": 8913.581, \"total_train_time_s\": 9.884168863296509}", "{\"n\": 3864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.48, \"learn_time_ms\": 8778.716, \"total_train_time_s\": 9.400195121765137}", "{\"n\": 3865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.62, \"learn_time_ms\": 8711.355, \"total_train_time_s\": 10.778271675109863}", "{\"n\": 3866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.78, \"learn_time_ms\": 8571.427, \"total_train_time_s\": 10.223274946212769}", "{\"n\": 3867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.78, \"learn_time_ms\": 8713.641, \"total_train_time_s\": 10.401192903518677}", "{\"n\": 3868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.18, \"learn_time_ms\": 8657.513, \"total_train_time_s\": 9.285526514053345}", "{\"n\": 3869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.72, \"learn_time_ms\": 8690.1, \"total_train_time_s\": 9.592742681503296}", "{\"n\": 3870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 8443.752, \"total_train_time_s\": 7.783143043518066}", "{\"n\": 3871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 8491.354, \"total_train_time_s\": 10.066318035125732}", "{\"n\": 3872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.09, \"learn_time_ms\": 8369.121, \"total_train_time_s\": 10.389025449752808}", "{\"n\": 3873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.5, \"learn_time_ms\": 8400.297, \"total_train_time_s\": 10.19336748123169}", "{\"n\": 3874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.5, \"learn_time_ms\": 8563.802, \"total_train_time_s\": 11.046798467636108}", "{\"n\": 3875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.49, \"learn_time_ms\": 8425.135, \"total_train_time_s\": 9.411077499389648}", "{\"n\": 3876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.37, \"learn_time_ms\": 8571.816, \"total_train_time_s\": 11.71402907371521}", "{\"n\": 3877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.37, \"learn_time_ms\": 8469.307, \"total_train_time_s\": 9.447638511657715}", "{\"n\": 3878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.37, \"learn_time_ms\": 8591.205, \"total_train_time_s\": 10.519556283950806}", "{\"n\": 3879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.36, \"learn_time_ms\": 8709.427, \"total_train_time_s\": 10.784218549728394}", "{\"n\": 3880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.36, \"learn_time_ms\": 8963.661, \"total_train_time_s\": 10.29744291305542}", "{\"n\": 3881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.36, \"learn_time_ms\": 9004.879, \"total_train_time_s\": 10.46579647064209}", "{\"n\": 3882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.88, \"learn_time_ms\": 8996.541, \"total_train_time_s\": 10.251372337341309}", "{\"n\": 3883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.83, \"learn_time_ms\": 9074.007, \"total_train_time_s\": 10.995882749557495}", "{\"n\": 3884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.83, \"learn_time_ms\": 9030.778, \"total_train_time_s\": 10.6452157497406}", "{\"n\": 3885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.63, \"learn_time_ms\": 9239.81, \"total_train_time_s\": 11.51611065864563}", "{\"n\": 3886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.35, \"learn_time_ms\": 9182.003, \"total_train_time_s\": 11.085345268249512}", "{\"n\": 3887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.35, \"learn_time_ms\": 9226.015, \"total_train_time_s\": 9.887674331665039}", "{\"n\": 3888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.87, \"learn_time_ms\": 9237.408, \"total_train_time_s\": 10.676473617553711}", "{\"n\": 3889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.37, \"learn_time_ms\": 9137.317, \"total_train_time_s\": 9.752054214477539}", "{\"n\": 3890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.37, \"learn_time_ms\": 9128.588, \"total_train_time_s\": 10.224534749984741}", "{\"n\": 3891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.23, \"learn_time_ms\": 9122.138, \"total_train_time_s\": 10.484384059906006}", "{\"n\": 3892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.88, \"learn_time_ms\": 9190.056, \"total_train_time_s\": 10.98173975944519}", "{\"n\": 3893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.88, \"learn_time_ms\": 9077.243, \"total_train_time_s\": 9.880197525024414}", "{\"n\": 3894, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.88, \"learn_time_ms\": 9009.607, \"total_train_time_s\": 9.945069789886475}", "{\"n\": 3895, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.64, \"learn_time_ms\": 8813.033, \"total_train_time_s\": 9.509288549423218}", "{\"n\": 3896, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.94, \"learn_time_ms\": 8733.241, \"total_train_time_s\": 10.312185287475586}", "{\"n\": 3897, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.94, \"learn_time_ms\": 8577.508, \"total_train_time_s\": 8.327074766159058}", "{\"n\": 3898, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.21, \"learn_time_ms\": 8489.344, \"total_train_time_s\": 9.740704536437988}", "{\"n\": 3899, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.98, \"learn_time_ms\": 8548.991, \"total_train_time_s\": 10.352496862411499}", "{\"n\": 3900, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.98, \"learn_time_ms\": 8548.105, \"total_train_time_s\": 10.194962978363037}", "{\"n\": 3901, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.56, \"learn_time_ms\": 8661.611, \"total_train_time_s\": 11.56489634513855}", "{\"n\": 3902, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.68, \"learn_time_ms\": 8624.226, \"total_train_time_s\": 10.569650173187256}", "{\"n\": 3903, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.68, \"learn_time_ms\": 8731.942, \"total_train_time_s\": 10.944833517074585}", "{\"n\": 3904, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.48, \"learn_time_ms\": 8840.839, \"total_train_time_s\": 11.023701190948486}", "{\"n\": 3905, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.76, \"learn_time_ms\": 9023.812, \"total_train_time_s\": 11.303645849227905}", "{\"n\": 3906, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.48, \"learn_time_ms\": 9051.122, \"total_train_time_s\": 10.565942287445068}", "{\"n\": 3907, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.29, \"learn_time_ms\": 9320.162, \"total_train_time_s\": 11.009471416473389}", "{\"n\": 3908, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.86, \"learn_time_ms\": 9387.904, \"total_train_time_s\": 10.484206438064575}", "{\"n\": 3909, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.38, \"learn_time_ms\": 9376.891, \"total_train_time_s\": 10.275492429733276}", "{\"n\": 3910, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.38, \"learn_time_ms\": 9425.899, \"total_train_time_s\": 10.694480657577515}", "{\"n\": 3911, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.39, \"learn_time_ms\": 9315.124, \"total_train_time_s\": 10.475696563720703}", "{\"n\": 3912, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 9265.457, \"total_train_time_s\": 10.085524559020996}", "{\"n\": 3913, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 9182.775, \"total_train_time_s\": 10.068921566009521}", "{\"n\": 3914, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.82, \"learn_time_ms\": 9013.111, \"total_train_time_s\": 9.389431953430176}", "{\"n\": 3915, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.2, \"learn_time_ms\": 8825.015, \"total_train_time_s\": 9.466289758682251}", "{\"n\": 3916, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.31, \"learn_time_ms\": 8829.009, \"total_train_time_s\": 10.610893726348877}", "{\"n\": 3917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.75, \"learn_time_ms\": 8786.308, \"total_train_time_s\": 10.611118793487549}", "{\"n\": 3918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.46, \"learn_time_ms\": 8795.165, \"total_train_time_s\": 10.569298505783081}", "{\"n\": 3919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.1, \"learn_time_ms\": 8843.182, \"total_train_time_s\": 10.768543243408203}", "{\"n\": 3920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.18, \"learn_time_ms\": 8785.903, \"total_train_time_s\": 10.16714358329773}", "{\"n\": 3921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.19, \"learn_time_ms\": 8682.408, \"total_train_time_s\": 9.456919193267822}", "{\"n\": 3922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.54, \"learn_time_ms\": 8736.383, \"total_train_time_s\": 10.615986347198486}", "{\"n\": 3923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.54, \"learn_time_ms\": 8955.267, \"total_train_time_s\": 12.330075740814209}", "{\"n\": 3924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.24, \"learn_time_ms\": 9035.722, \"total_train_time_s\": 10.159219980239868}", "{\"n\": 3925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.49, \"learn_time_ms\": 9173.873, \"total_train_time_s\": 10.902602195739746}", "{\"n\": 3926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.49, \"learn_time_ms\": 9132.726, \"total_train_time_s\": 10.251768112182617}", "{\"n\": 3927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.85, \"learn_time_ms\": 9199.37, \"total_train_time_s\": 11.20205807685852}", "{\"n\": 3928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.38, \"learn_time_ms\": 9150.584, \"total_train_time_s\": 10.090610980987549}", "{\"n\": 3929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.38, \"learn_time_ms\": 9066.065, \"total_train_time_s\": 9.905529499053955}", "{\"n\": 3930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.38, \"learn_time_ms\": 9115.283, \"total_train_time_s\": 10.58941650390625}", "{\"n\": 3931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.96, \"learn_time_ms\": 9288.378, \"total_train_time_s\": 11.174433708190918}", "{\"n\": 3932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.96, \"learn_time_ms\": 9239.147, \"total_train_time_s\": 10.157031536102295}", "{\"n\": 3933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.96, \"learn_time_ms\": 8909.389, \"total_train_time_s\": 8.954627513885498}", "{\"n\": 3934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.95, \"learn_time_ms\": 8867.644, \"total_train_time_s\": 9.725706100463867}", "{\"n\": 3935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.95, \"learn_time_ms\": 8800.928, \"total_train_time_s\": 10.17564582824707}", "{\"n\": 3936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.95, \"learn_time_ms\": 8773.372, \"total_train_time_s\": 9.921133756637573}", "{\"n\": 3937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.56, \"learn_time_ms\": 8621.066, \"total_train_time_s\": 9.719862699508667}", "{\"n\": 3938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.84, \"learn_time_ms\": 8810.191, \"total_train_time_s\": 11.912871599197388}", "{\"n\": 3939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.84, \"learn_time_ms\": 8904.065, \"total_train_time_s\": 10.832822799682617}", "{\"n\": 3940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.18, \"learn_time_ms\": 8970.239, \"total_train_time_s\": 11.260635614395142}", "{\"n\": 3941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.42, \"learn_time_ms\": 8823.243, \"total_train_time_s\": 9.711556434631348}", "{\"n\": 3942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.42, \"learn_time_ms\": 8729.675, \"total_train_time_s\": 9.204517364501953}", "{\"n\": 3943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.42, \"learn_time_ms\": 8893.168, \"total_train_time_s\": 10.61763596534729}", "{\"n\": 3944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.91, \"learn_time_ms\": 8858.891, \"total_train_time_s\": 9.421447277069092}", "{\"n\": 3945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.91, \"learn_time_ms\": 8740.414, \"total_train_time_s\": 8.98895263671875}", "{\"n\": 3946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.91, \"learn_time_ms\": 8895.104, \"total_train_time_s\": 11.440989017486572}", "{\"n\": 3947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.79, \"learn_time_ms\": 9014.701, \"total_train_time_s\": 10.909790515899658}", "{\"n\": 3948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.79, \"learn_time_ms\": 8899.278, \"total_train_time_s\": 10.777575731277466}", "{\"n\": 3949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.79, \"learn_time_ms\": 9082.271, \"total_train_time_s\": 12.668282270431519}", "{\"n\": 3950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.41, \"learn_time_ms\": 8976.385, \"total_train_time_s\": 10.252630472183228}", "{\"n\": 3951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.57, \"learn_time_ms\": 9030.799, \"total_train_time_s\": 10.228829860687256}", "{\"n\": 3952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.57, \"learn_time_ms\": 9172.283, \"total_train_time_s\": 10.615229606628418}", "{\"n\": 3953, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.03, \"learn_time_ms\": 9099.09, \"total_train_time_s\": 9.918998718261719}", "{\"n\": 3954, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.62, \"learn_time_ms\": 9198.912, \"total_train_time_s\": 10.37324595451355}", "{\"n\": 3955, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.62, \"learn_time_ms\": 9467.863, \"total_train_time_s\": 11.683346033096313}", "{\"n\": 3956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.9, \"learn_time_ms\": 9358.539, \"total_train_time_s\": 10.320890665054321}", "{\"n\": 3957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.21, \"learn_time_ms\": 9355.999, \"total_train_time_s\": 10.880835771560669}", "{\"n\": 3958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.21, \"learn_time_ms\": 9297.186, \"total_train_time_s\": 10.151130676269531}", "{\"n\": 3959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.21, \"learn_time_ms\": 8944.449, \"total_train_time_s\": 9.153838872909546}", "{\"n\": 3960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.0, \"learn_time_ms\": 8950.818, \"total_train_time_s\": 10.266186237335205}", "{\"n\": 3961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.27, \"learn_time_ms\": 9009.143, \"total_train_time_s\": 10.802725553512573}", "{\"n\": 3962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.27, \"learn_time_ms\": 9068.035, \"total_train_time_s\": 11.19945740699768}", "{\"n\": 3963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.5, \"learn_time_ms\": 9074.84, \"total_train_time_s\": 9.961382627487183}", "{\"n\": 3964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.99, \"learn_time_ms\": 9101.3, \"total_train_time_s\": 10.638979196548462}", "{\"n\": 3965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.99, \"learn_time_ms\": 9015.739, \"total_train_time_s\": 10.825055360794067}", "{\"n\": 3966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.22, \"learn_time_ms\": 9002.073, \"total_train_time_s\": 10.198797225952148}", "{\"n\": 3967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.54, \"learn_time_ms\": 8891.502, \"total_train_time_s\": 9.795004606246948}", "{\"n\": 3968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.54, \"learn_time_ms\": 8977.019, \"total_train_time_s\": 11.081322431564331}", "{\"n\": 3969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.14, \"learn_time_ms\": 9139.676, \"total_train_time_s\": 10.789197444915771}", "{\"n\": 3970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.78, \"learn_time_ms\": 9196.3, \"total_train_time_s\": 10.867829322814941}", "{\"n\": 3971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.07, \"learn_time_ms\": 9217.225, \"total_train_time_s\": 11.092095375061035}", "{\"n\": 3972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.07, \"learn_time_ms\": 9216.142, \"total_train_time_s\": 11.180256366729736}", "{\"n\": 3973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.73, \"learn_time_ms\": 9188.418, \"total_train_time_s\": 9.644865989685059}", "{\"n\": 3974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.26, \"learn_time_ms\": 8955.868, \"total_train_time_s\": 8.354288339614868}", "{\"n\": 3975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.26, \"learn_time_ms\": 8997.812, \"total_train_time_s\": 11.212652921676636}", "{\"n\": 3976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.15, \"learn_time_ms\": 9141.752, \"total_train_time_s\": 11.67330527305603}", "{\"n\": 3977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.95, \"learn_time_ms\": 9085.485, \"total_train_time_s\": 9.24683928489685}", "{\"n\": 3978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.95, \"learn_time_ms\": 9090.312, \"total_train_time_s\": 11.107647895812988}", "{\"n\": 3979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.27, \"learn_time_ms\": 9004.553, \"total_train_time_s\": 9.910888910293579}", "{\"n\": 3980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.53, \"learn_time_ms\": 9009.376, \"total_train_time_s\": 10.920455694198608}", "{\"n\": 3981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.54, \"learn_time_ms\": 8831.448, \"total_train_time_s\": 9.24499225616455}", "{\"n\": 3982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.08, \"learn_time_ms\": 8809.937, \"total_train_time_s\": 10.975268363952637}", "{\"n\": 3983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.49, \"learn_time_ms\": 8865.743, \"total_train_time_s\": 10.241066694259644}", "{\"n\": 3984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.49, \"learn_time_ms\": 8881.996, \"total_train_time_s\": 8.472318887710571}", "{\"n\": 3985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.81, \"learn_time_ms\": 8950.955, \"total_train_time_s\": 11.955790042877197}", "{\"n\": 3986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.28, \"learn_time_ms\": 9055.382, \"total_train_time_s\": 12.740674018859863}", "{\"n\": 3987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.28, \"learn_time_ms\": 9172.095, \"total_train_time_s\": 10.426424503326416}", "{\"n\": 3988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.82, \"learn_time_ms\": 9118.149, \"total_train_time_s\": 10.567799806594849}", "{\"n\": 3989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.7, \"learn_time_ms\": 9181.49, \"total_train_time_s\": 10.572023868560791}", "{\"n\": 3990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.98, \"learn_time_ms\": 9162.106, \"total_train_time_s\": 10.756990194320679}", "{\"n\": 3991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.55, \"learn_time_ms\": 9025.187, \"total_train_time_s\": 7.946035623550415}", "{\"n\": 3992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.36, \"learn_time_ms\": 9065.599, \"total_train_time_s\": 11.391338348388672}", "{\"n\": 3993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.06, \"learn_time_ms\": 9083.059, \"total_train_time_s\": 10.412233591079712}", "{\"n\": 3994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.06, \"learn_time_ms\": 9261.142, \"total_train_time_s\": 10.23834753036499}", "{\"n\": 3995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.96, \"learn_time_ms\": 9125.305, \"total_train_time_s\": 10.565677881240845}", "{\"n\": 3996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.95, \"learn_time_ms\": 8811.893, \"total_train_time_s\": 9.589990139007568}", "{\"n\": 3997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.95, \"learn_time_ms\": 8916.052, \"total_train_time_s\": 11.44750165939331}", "{\"n\": 3998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.42, \"learn_time_ms\": 8884.343, \"total_train_time_s\": 10.266048431396484}", "{\"n\": 3999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.65, \"learn_time_ms\": 8845.654, \"total_train_time_s\": 10.19938039779663}", "{\"n\": 4000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.65, \"learn_time_ms\": 8767.67, \"total_train_time_s\": 9.94020676612854}", "{\"n\": 4001, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.06, \"learn_time_ms\": 9064.325, \"total_train_time_s\": 10.837912559509277}", "{\"n\": 4002, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.98, \"learn_time_ms\": 8947.671, \"total_train_time_s\": 10.225540399551392}", "{\"n\": 4003, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.98, \"learn_time_ms\": 8938.272, \"total_train_time_s\": 10.300004720687866}", "{\"n\": 4004, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.39, \"learn_time_ms\": 8869.637, \"total_train_time_s\": 9.611512899398804}", "{\"n\": 4005, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.14, \"learn_time_ms\": 8916.559, \"total_train_time_s\": 11.107927799224854}", "{\"n\": 4006, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.52, \"learn_time_ms\": 8928.942, \"total_train_time_s\": 9.72589659690857}", "{\"n\": 4007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.6, \"learn_time_ms\": 8674.021, \"total_train_time_s\": 8.855613231658936}", "{\"n\": 4008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.06, \"learn_time_ms\": 8619.485, \"total_train_time_s\": 9.679378747940063}", "{\"n\": 4009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.5, \"learn_time_ms\": 8664.918, \"total_train_time_s\": 10.627482175827026}", "{\"n\": 4010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.5, \"learn_time_ms\": 8737.675, \"total_train_time_s\": 10.653308391571045}", "{\"n\": 4011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.81, \"learn_time_ms\": 8610.129, \"total_train_time_s\": 9.574166774749756}", "{\"n\": 4012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.56, \"learn_time_ms\": 8668.294, \"total_train_time_s\": 10.767874479293823}", "{\"n\": 4013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.54, \"learn_time_ms\": 8658.803, \"total_train_time_s\": 10.228978395462036}", "{\"n\": 4014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.17, \"learn_time_ms\": 8816.387, \"total_train_time_s\": 11.18114423751831}", "{\"n\": 4015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.09, \"learn_time_ms\": 8720.135, \"total_train_time_s\": 10.08664584159851}", "{\"n\": 4016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.22, \"learn_time_ms\": 8791.655, \"total_train_time_s\": 10.370086908340454}", "{\"n\": 4017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.95, \"learn_time_ms\": 8908.084, \"total_train_time_s\": 9.993701934814453}", "{\"n\": 4018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.36, \"learn_time_ms\": 8856.096, \"total_train_time_s\": 9.177333116531372}", "{\"n\": 4019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.36, \"learn_time_ms\": 8852.986, \"total_train_time_s\": 10.607038021087646}", "{\"n\": 4020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.66, \"learn_time_ms\": 8882.339, \"total_train_time_s\": 10.944556713104248}", "{\"n\": 4021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.66, \"learn_time_ms\": 8919.391, \"total_train_time_s\": 9.92479157447815}", "{\"n\": 4022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.2, \"learn_time_ms\": 8828.706, \"total_train_time_s\": 9.899365901947021}", "{\"n\": 4023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.67, \"learn_time_ms\": 8874.457, \"total_train_time_s\": 10.67137360572815}", "{\"n\": 4024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.6, \"learn_time_ms\": 8795.0, \"total_train_time_s\": 10.3527991771698}", "{\"n\": 4025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.07, \"learn_time_ms\": 8891.917, \"total_train_time_s\": 11.049097776412964}", "{\"n\": 4026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.53, \"learn_time_ms\": 8875.014, \"total_train_time_s\": 10.251135110855103}", "{\"n\": 4027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.55, \"learn_time_ms\": 8744.386, \"total_train_time_s\": 8.753264427185059}", "{\"n\": 4028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.79, \"learn_time_ms\": 8939.794, \"total_train_time_s\": 11.120486974716187}", "{\"n\": 4029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.98, \"learn_time_ms\": 8891.834, \"total_train_time_s\": 10.116340637207031}", "{\"n\": 4030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.47, \"learn_time_ms\": 8704.738, \"total_train_time_s\": 9.081464052200317}", "{\"n\": 4031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.96, \"learn_time_ms\": 8713.785, \"total_train_time_s\": 10.030532121658325}", "{\"n\": 4032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.81, \"learn_time_ms\": 8848.7, \"total_train_time_s\": 11.267143487930298}", "{\"n\": 4033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.72, \"learn_time_ms\": 8880.701, \"total_train_time_s\": 11.00089955329895}", "{\"n\": 4034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.53, \"learn_time_ms\": 8901.011, \"total_train_time_s\": 10.606426000595093}", "{\"n\": 4035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.95, \"learn_time_ms\": 8820.793, \"total_train_time_s\": 10.307056903839111}", "{\"n\": 4036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.95, \"learn_time_ms\": 8836.33, \"total_train_time_s\": 10.361358404159546}", "{\"n\": 4037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.01, \"learn_time_ms\": 8949.169, \"total_train_time_s\": 9.849013328552246}", "{\"n\": 4038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.67, \"learn_time_ms\": 8835.435, \"total_train_time_s\": 10.051448583602905}", "{\"n\": 4039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.67, \"learn_time_ms\": 8895.405, \"total_train_time_s\": 10.757023811340332}", "{\"n\": 4040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.26, \"learn_time_ms\": 8993.726, \"total_train_time_s\": 10.07699966430664}", "{\"n\": 4041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.63, \"learn_time_ms\": 8923.695, \"total_train_time_s\": 9.32542896270752}", "{\"n\": 4042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.63, \"learn_time_ms\": 8840.737, \"total_train_time_s\": 10.4031822681427}", "{\"n\": 4043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.06, \"learn_time_ms\": 8618.466, \"total_train_time_s\": 8.767118215560913}", "{\"n\": 4044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.06, \"learn_time_ms\": 8421.546, \"total_train_time_s\": 8.613060474395752}", "{\"n\": 4045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.56, \"learn_time_ms\": 8592.311, \"total_train_time_s\": 11.979358673095703}", "{\"n\": 4046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.62, \"learn_time_ms\": 8747.389, \"total_train_time_s\": 11.976958513259888}", "{\"n\": 4047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.35, \"learn_time_ms\": 8796.489, \"total_train_time_s\": 10.352145671844482}", "{\"n\": 4048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.27, \"learn_time_ms\": 8754.459, \"total_train_time_s\": 9.542033433914185}", "{\"n\": 4049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.27, \"learn_time_ms\": 8703.163, \"total_train_time_s\": 10.165564775466919}", "{\"n\": 4050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.25, \"learn_time_ms\": 8969.198, \"total_train_time_s\": 12.730385780334473}", "{\"n\": 4051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.82, \"learn_time_ms\": 8996.637, \"total_train_time_s\": 9.621449947357178}", "{\"n\": 4052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.1, \"learn_time_ms\": 8992.456, \"total_train_time_s\": 10.394323110580444}", "{\"n\": 4053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.63, \"learn_time_ms\": 9102.636, \"total_train_time_s\": 9.910169839859009}", "{\"n\": 4054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.36, \"learn_time_ms\": 9149.659, \"total_train_time_s\": 9.069947719573975}", "{\"n\": 4055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.36, \"learn_time_ms\": 8878.944, \"total_train_time_s\": 9.252357959747314}", "{\"n\": 4056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.79, \"learn_time_ms\": 8667.426, \"total_train_time_s\": 9.852189540863037}", "{\"n\": 4057, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.2, \"learn_time_ms\": 8534.169, \"total_train_time_s\": 9.016831874847412}", "{\"n\": 4058, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.2, \"learn_time_ms\": 8706.39, \"total_train_time_s\": 11.295521259307861}", "{\"n\": 4059, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.96, \"learn_time_ms\": 8729.782, \"total_train_time_s\": 10.434085845947266}", "{\"n\": 4060, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.01, \"learn_time_ms\": 8441.517, \"total_train_time_s\": 9.865641832351685}", "{\"n\": 4061, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.2, \"learn_time_ms\": 8506.812, \"total_train_time_s\": 10.293049097061157}", "{\"n\": 4062, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.75, \"learn_time_ms\": 8577.851, \"total_train_time_s\": 11.110698938369751}", "{\"n\": 4063, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.59, \"learn_time_ms\": 8699.094, \"total_train_time_s\": 11.131353855133057}", "{\"n\": 4064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.57, \"learn_time_ms\": 8818.24, \"total_train_time_s\": 10.287410736083984}", "{\"n\": 4065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.57, \"learn_time_ms\": 8952.894, \"total_train_time_s\": 10.623289108276367}", "{\"n\": 4066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.79, \"learn_time_ms\": 8877.604, \"total_train_time_s\": 9.078167200088501}", "{\"n\": 4067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.92, \"learn_time_ms\": 8936.134, \"total_train_time_s\": 9.65988302230835}", "{\"n\": 4068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.45, \"learn_time_ms\": 8839.185, \"total_train_time_s\": 10.32583737373352}", "{\"n\": 4069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.4, \"learn_time_ms\": 8881.343, \"total_train_time_s\": 10.814770221710205}", "{\"n\": 4070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.55, \"learn_time_ms\": 8756.07, \"total_train_time_s\": 8.580690860748291}", "{\"n\": 4071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.38, \"learn_time_ms\": 8891.512, \"total_train_time_s\": 11.610832929611206}", "{\"n\": 4072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.41, \"learn_time_ms\": 8846.335, \"total_train_time_s\": 10.6559419631958}", "{\"n\": 4073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.4, \"learn_time_ms\": 8805.639, \"total_train_time_s\": 10.698607683181763}", "{\"n\": 4074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.46, \"learn_time_ms\": 8842.869, \"total_train_time_s\": 10.693028688430786}", "{\"n\": 4075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.27, \"learn_time_ms\": 8894.917, \"total_train_time_s\": 11.174623489379883}", "{\"n\": 4076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.91, \"learn_time_ms\": 9003.811, \"total_train_time_s\": 10.18632698059082}", "{\"n\": 4077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.64, \"learn_time_ms\": 9181.467, \"total_train_time_s\": 11.409911870956421}", "{\"n\": 4078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.15, \"learn_time_ms\": 9207.955, \"total_train_time_s\": 10.581130981445312}", "{\"n\": 4079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.15, \"learn_time_ms\": 9140.071, \"total_train_time_s\": 10.166938543319702}", "{\"n\": 4080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.35, \"learn_time_ms\": 9436.852, \"total_train_time_s\": 11.582640886306763}", "{\"n\": 4081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.44, \"learn_time_ms\": 9275.36, \"total_train_time_s\": 10.078445434570312}", "{\"n\": 4082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.21, \"learn_time_ms\": 9181.959, \"total_train_time_s\": 9.712158441543579}", "{\"n\": 4083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.05, \"learn_time_ms\": 9198.872, \"total_train_time_s\": 10.843008041381836}", "{\"n\": 4084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.81, \"learn_time_ms\": 9137.638, \"total_train_time_s\": 10.044504642486572}", "{\"n\": 4085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.89, \"learn_time_ms\": 8994.71, \"total_train_time_s\": 9.68510890007019}", "{\"n\": 4086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.67, \"learn_time_ms\": 9040.621, \"total_train_time_s\": 10.615433931350708}", "{\"n\": 4087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.69, \"learn_time_ms\": 8927.443, \"total_train_time_s\": 10.263029098510742}", "{\"n\": 4088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.03, \"learn_time_ms\": 8953.6, \"total_train_time_s\": 10.829729318618774}", "{\"n\": 4089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.4, \"learn_time_ms\": 8913.527, \"total_train_time_s\": 9.754383325576782}", "{\"n\": 4090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.4, \"learn_time_ms\": 8795.643, \"total_train_time_s\": 10.368265151977539}", "{\"n\": 4091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.92, \"learn_time_ms\": 8799.387, \"total_train_time_s\": 10.016754865646362}", "{\"n\": 4092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.19, \"learn_time_ms\": 8839.187, \"total_train_time_s\": 10.073719263076782}", "{\"n\": 4093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.96, \"learn_time_ms\": 8736.382, \"total_train_time_s\": 9.813702821731567}", "{\"n\": 4094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.05, \"learn_time_ms\": 8664.932, \"total_train_time_s\": 9.331375122070312}", "{\"n\": 4095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.39, \"learn_time_ms\": 8600.641, \"total_train_time_s\": 9.0816490650177}", "{\"n\": 4096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.88, \"learn_time_ms\": 8560.99, \"total_train_time_s\": 10.249125003814697}", "{\"n\": 4097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.29, \"learn_time_ms\": 8608.483, \"total_train_time_s\": 10.752214670181274}", "{\"n\": 4098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.29, \"learn_time_ms\": 8662.291, \"total_train_time_s\": 11.428802728652954}", "{\"n\": 4099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.06, \"learn_time_ms\": 8692.765, \"total_train_time_s\": 10.100594997406006}", "{\"n\": 4100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.75, \"learn_time_ms\": 8673.869, \"total_train_time_s\": 10.163061380386353}", "{\"n\": 4101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.54, \"learn_time_ms\": 8678.366, \"total_train_time_s\": 10.05135464668274}", "{\"n\": 4102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.0, \"learn_time_ms\": 8639.382, \"total_train_time_s\": 9.742711305618286}", "{\"n\": 4103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.0, \"learn_time_ms\": 8690.467, \"total_train_time_s\": 10.326297760009766}", "{\"n\": 4104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.99, \"learn_time_ms\": 8748.872, \"total_train_time_s\": 9.912646770477295}", "{\"n\": 4105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.99, \"learn_time_ms\": 8934.285, \"total_train_time_s\": 10.920775413513184}", "{\"n\": 4106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.38, \"learn_time_ms\": 8873.45, \"total_train_time_s\": 9.659287214279175}", "{\"n\": 4107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.9, \"learn_time_ms\": 8947.448, \"total_train_time_s\": 11.502457857131958}", "{\"n\": 4108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.26, \"learn_time_ms\": 8931.517, \"total_train_time_s\": 11.226993083953857}", "{\"n\": 4109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.18, \"learn_time_ms\": 9003.851, \"total_train_time_s\": 10.774320125579834}", "{\"n\": 4110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.66, \"learn_time_ms\": 8981.326, \"total_train_time_s\": 9.971983432769775}", "{\"n\": 4111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.66, \"learn_time_ms\": 9000.913, \"total_train_time_s\": 10.245827198028564}", "{\"n\": 4112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.6, \"learn_time_ms\": 9126.715, \"total_train_time_s\": 10.92864203453064}", "{\"n\": 4113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.47, \"learn_time_ms\": 9137.866, \"total_train_time_s\": 10.441867589950562}", "{\"n\": 4114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.47, \"learn_time_ms\": 9068.216, \"total_train_time_s\": 9.232413291931152}", "{\"n\": 4115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.48, \"learn_time_ms\": 9049.015, \"total_train_time_s\": 10.737545013427734}", "{\"n\": 4116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.31, \"learn_time_ms\": 9035.833, \"total_train_time_s\": 9.50877594947815}", "{\"n\": 4117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.31, \"learn_time_ms\": 8822.75, \"total_train_time_s\": 9.372109413146973}", "{\"n\": 4118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.31, \"learn_time_ms\": 8619.567, \"total_train_time_s\": 9.195147514343262}", "{\"n\": 4119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.86, \"learn_time_ms\": 8463.391, \"total_train_time_s\": 9.229451417922974}", "{\"n\": 4120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.59, \"learn_time_ms\": 8392.34, \"total_train_time_s\": 9.239969730377197}", "{\"n\": 4121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.59, \"learn_time_ms\": 8352.285, \"total_train_time_s\": 9.877321243286133}", "{\"n\": 4122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.9, \"learn_time_ms\": 8337.921, \"total_train_time_s\": 10.831616640090942}", "{\"n\": 4123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.9, \"learn_time_ms\": 8249.782, \"total_train_time_s\": 9.59545350074768}", "{\"n\": 4124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.9, \"learn_time_ms\": 8321.399, \"total_train_time_s\": 9.955809831619263}", "{\"n\": 4125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.54, \"learn_time_ms\": 8216.903, \"total_train_time_s\": 9.712327480316162}", "{\"n\": 4126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.8, \"learn_time_ms\": 8098.736, \"total_train_time_s\": 8.37383508682251}", "{\"n\": 4127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.8, \"learn_time_ms\": 8151.334, \"total_train_time_s\": 9.90211820602417}", "{\"n\": 4128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.72, \"learn_time_ms\": 8168.295, \"total_train_time_s\": 9.375028133392334}", "{\"n\": 4129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.94, \"learn_time_ms\": 8288.652, \"total_train_time_s\": 10.424762725830078}", "{\"n\": 4130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.94, \"learn_time_ms\": 8523.962, \"total_train_time_s\": 11.593549728393555}", "{\"n\": 4131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.35, \"learn_time_ms\": 8564.713, \"total_train_time_s\": 10.258118152618408}", "{\"n\": 4132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.58, \"learn_time_ms\": 8442.563, \"total_train_time_s\": 9.577597618103027}", "{\"n\": 4133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.59, \"learn_time_ms\": 8532.179, \"total_train_time_s\": 10.438910961151123}", "{\"n\": 4134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.51, \"learn_time_ms\": 8522.235, \"total_train_time_s\": 9.816322565078735}", "{\"n\": 4135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.8, \"learn_time_ms\": 8499.747, \"total_train_time_s\": 9.505720615386963}", "{\"n\": 4136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.71, \"learn_time_ms\": 8703.424, \"total_train_time_s\": 10.370800018310547}", "{\"n\": 4137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.12, \"learn_time_ms\": 8757.036, \"total_train_time_s\": 10.426971197128296}", "{\"n\": 4138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.77, \"learn_time_ms\": 8925.563, \"total_train_time_s\": 11.066160917282104}", "{\"n\": 4139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.85, \"learn_time_ms\": 8984.237, \"total_train_time_s\": 11.017924785614014}", "{\"n\": 4140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.55, \"learn_time_ms\": 8808.391, \"total_train_time_s\": 9.867361783981323}", "{\"n\": 4141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.17, \"learn_time_ms\": 8843.251, \"total_train_time_s\": 10.655882835388184}", "{\"n\": 4142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.24, \"learn_time_ms\": 8908.695, \"total_train_time_s\": 10.245762825012207}", "{\"n\": 4143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.4, \"learn_time_ms\": 8927.662, \"total_train_time_s\": 10.6774423122406}", "{\"n\": 4144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.2, \"learn_time_ms\": 9079.749, \"total_train_time_s\": 11.338313341140747}", "{\"n\": 4145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.2, \"learn_time_ms\": 9148.988, \"total_train_time_s\": 10.126507043838501}", "{\"n\": 4146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.59, \"learn_time_ms\": 9132.43, \"total_train_time_s\": 10.216490507125854}", "{\"n\": 4147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.34, \"learn_time_ms\": 9096.545, \"total_train_time_s\": 9.993740320205688}", "{\"n\": 4148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.2, \"learn_time_ms\": 8914.861, \"total_train_time_s\": 9.271895170211792}", "{\"n\": 4149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.8, \"learn_time_ms\": 9006.788, \"total_train_time_s\": 11.921921014785767}", "{\"n\": 4150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.44, \"learn_time_ms\": 9151.183, \"total_train_time_s\": 11.33193826675415}", "{\"n\": 4151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.61, \"learn_time_ms\": 9072.121, \"total_train_time_s\": 9.864598989486694}", "{\"n\": 4152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.61, \"learn_time_ms\": 9021.973, \"total_train_time_s\": 9.732074737548828}", "{\"n\": 4153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.22, \"learn_time_ms\": 9162.203, \"total_train_time_s\": 12.067297458648682}", "{\"n\": 4154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.22, \"learn_time_ms\": 9137.425, \"total_train_time_s\": 11.09338665008545}", "{\"n\": 4155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.43, \"learn_time_ms\": 9084.263, \"total_train_time_s\": 9.597691535949707}", "{\"n\": 4156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.48, \"learn_time_ms\": 9056.681, \"total_train_time_s\": 9.918944835662842}", "{\"n\": 4157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.59, \"learn_time_ms\": 8979.966, \"total_train_time_s\": 9.293944358825684}", "{\"n\": 4158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.59, \"learn_time_ms\": 9131.453, \"total_train_time_s\": 10.7423677444458}", "{\"n\": 4159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.69, \"learn_time_ms\": 8988.431, \"total_train_time_s\": 10.553380727767944}", "{\"n\": 4160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.15, \"learn_time_ms\": 8883.04, \"total_train_time_s\": 10.279552459716797}", "{\"n\": 4161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.22, \"learn_time_ms\": 8845.153, \"total_train_time_s\": 9.51350450515747}", "{\"n\": 4162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.47, \"learn_time_ms\": 8928.287, \"total_train_time_s\": 10.553057670593262}", "{\"n\": 4163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.24, \"learn_time_ms\": 8935.741, \"total_train_time_s\": 12.083503723144531}", "{\"n\": 4164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 8749.451, \"total_train_time_s\": 9.211809158325195}", "{\"n\": 4165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.25, \"learn_time_ms\": 8819.61, \"total_train_time_s\": 10.323514223098755}", "{\"n\": 4166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.17, \"learn_time_ms\": 8837.9, \"total_train_time_s\": 10.100614547729492}", "{\"n\": 4167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.71, \"learn_time_ms\": 8964.206, \"total_train_time_s\": 10.565432786941528}", "{\"n\": 4168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.62, \"learn_time_ms\": 8805.611, \"total_train_time_s\": 9.225360870361328}", "{\"n\": 4169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.28, \"learn_time_ms\": 8719.887, \"total_train_time_s\": 9.664591073989868}", "{\"n\": 4170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.71, \"learn_time_ms\": 8556.314, \"total_train_time_s\": 8.570589303970337}", "{\"n\": 4171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.72, \"learn_time_ms\": 8555.241, \"total_train_time_s\": 9.466323375701904}", "{\"n\": 4172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.62, \"learn_time_ms\": 8567.589, \"total_train_time_s\": 10.742785215377808}", "{\"n\": 4173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.33, \"learn_time_ms\": 8295.534, \"total_train_time_s\": 9.406726121902466}", "{\"n\": 4174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.33, \"learn_time_ms\": 8353.209, \"total_train_time_s\": 9.832674980163574}", "{\"n\": 4175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.97, \"learn_time_ms\": 8209.119, \"total_train_time_s\": 8.843647956848145}", "{\"n\": 4176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.19, \"learn_time_ms\": 8211.032, \"total_train_time_s\": 10.077476739883423}", "{\"n\": 4177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.19, \"learn_time_ms\": 8245.758, \"total_train_time_s\": 10.886610269546509}", "{\"n\": 4178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.17, \"learn_time_ms\": 8527.47, \"total_train_time_s\": 12.02949595451355}", "{\"n\": 4179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.72, \"learn_time_ms\": 8611.947, \"total_train_time_s\": 10.481874465942383}", "{\"n\": 4180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.72, \"learn_time_ms\": 8819.749, \"total_train_time_s\": 10.634519338607788}", "{\"n\": 4181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.32, \"learn_time_ms\": 8922.969, \"total_train_time_s\": 10.531110286712646}", "{\"n\": 4182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.54, \"learn_time_ms\": 8765.398, \"total_train_time_s\": 9.081109762191772}", "{\"n\": 4183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.95, \"learn_time_ms\": 8841.117, \"total_train_time_s\": 10.09814977645874}", "{\"n\": 4184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.02, \"learn_time_ms\": 8759.872, \"total_train_time_s\": 8.989667415618896}", "{\"n\": 4185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.31, \"learn_time_ms\": 8827.331, \"total_train_time_s\": 9.555887460708618}", "{\"n\": 4186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.68, \"learn_time_ms\": 8762.551, \"total_train_time_s\": 9.496453046798706}", "{\"n\": 4187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.84, \"learn_time_ms\": 8730.97, \"total_train_time_s\": 10.5789475440979}", "{\"n\": 4188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.63, \"learn_time_ms\": 8372.715, \"total_train_time_s\": 8.3828866481781}", "{\"n\": 4189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.97, \"learn_time_ms\": 8477.86, \"total_train_time_s\": 11.533130884170532}", "{\"n\": 4190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.9, \"learn_time_ms\": 8434.428, \"total_train_time_s\": 10.23442792892456}", "{\"n\": 4191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.9, \"learn_time_ms\": 8192.399, \"total_train_time_s\": 8.068016767501831}", "{\"n\": 4192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.0, \"learn_time_ms\": 8221.358, \"total_train_time_s\": 9.43842077255249}", "{\"n\": 4193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8217.315, \"total_train_time_s\": 10.12733268737793}", "{\"n\": 4194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8447.357, \"total_train_time_s\": 11.31794786453247}", "{\"n\": 4195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.87, \"learn_time_ms\": 8616.112, \"total_train_time_s\": 11.273688554763794}", "{\"n\": 4196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.01, \"learn_time_ms\": 8772.768, \"total_train_time_s\": 11.126652956008911}", "{\"n\": 4197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.02, \"learn_time_ms\": 8894.752, \"total_train_time_s\": 11.80558180809021}", "{\"n\": 4198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.02, \"learn_time_ms\": 9048.959, \"total_train_time_s\": 9.999735593795776}", "{\"n\": 4199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.41, \"learn_time_ms\": 8934.777, \"total_train_time_s\": 10.432276964187622}", "{\"n\": 4200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.28, \"learn_time_ms\": 8963.139, \"total_train_time_s\": 10.55223274230957}", "{\"n\": 4201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.96, \"learn_time_ms\": 9065.947, \"total_train_time_s\": 9.112639665603638}", "{\"n\": 4202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.83, \"learn_time_ms\": 9206.676, \"total_train_time_s\": 10.797536849975586}", "{\"n\": 4203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.89, \"learn_time_ms\": 9357.537, \"total_train_time_s\": 11.658188104629517}", "{\"n\": 4204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.22, \"learn_time_ms\": 9275.388, \"total_train_time_s\": 10.456665754318237}", "{\"n\": 4205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.22, \"learn_time_ms\": 9165.613, \"total_train_time_s\": 10.110301494598389}", "{\"n\": 4206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.36, \"learn_time_ms\": 9141.881, \"total_train_time_s\": 10.840696811676025}", "{\"n\": 4207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.76, \"learn_time_ms\": 8910.834, \"total_train_time_s\": 9.49032998085022}", "{\"n\": 4208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.16, \"learn_time_ms\": 8842.408, \"total_train_time_s\": 9.247775793075562}", "{\"n\": 4209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.7, \"learn_time_ms\": 8767.574, \"total_train_time_s\": 9.639185667037964}", "{\"n\": 4210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.39, \"learn_time_ms\": 8639.951, \"total_train_time_s\": 9.27269721031189}", "{\"n\": 4211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.67, \"learn_time_ms\": 8795.206, \"total_train_time_s\": 10.638694763183594}", "{\"n\": 4212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.67, \"learn_time_ms\": 8754.81, \"total_train_time_s\": 10.396856784820557}", "{\"n\": 4213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.23, \"learn_time_ms\": 8649.926, \"total_train_time_s\": 10.596538305282593}", "{\"n\": 4214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.54, \"learn_time_ms\": 8559.493, \"total_train_time_s\": 9.539342880249023}", "{\"n\": 4215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.8, \"learn_time_ms\": 8454.079, \"total_train_time_s\": 9.09723973274231}", "{\"n\": 4216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.8, \"learn_time_ms\": 8387.867, \"total_train_time_s\": 10.146212577819824}", "{\"n\": 4217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.72, \"learn_time_ms\": 8414.153, \"total_train_time_s\": 9.745311737060547}", "{\"n\": 4218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3250.43, \"learn_time_ms\": 8647.781, \"total_train_time_s\": 11.634372234344482}", "{\"n\": 4219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3241.52, \"learn_time_ms\": 8638.783, \"total_train_time_s\": 9.566365957260132}", "{\"n\": 4220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.06, \"learn_time_ms\": 8741.192, \"total_train_time_s\": 10.290327072143555}", "{\"n\": 4221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.05, \"learn_time_ms\": 8587.858, \"total_train_time_s\": 9.078476190567017}", "{\"n\": 4222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.45, \"learn_time_ms\": 8728.472, \"total_train_time_s\": 11.82394027709961}", "{\"n\": 4223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.59, \"learn_time_ms\": 8672.837, \"total_train_time_s\": 10.009865760803223}", "{\"n\": 4224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.59, \"learn_time_ms\": 8765.817, \"total_train_time_s\": 10.476783275604248}", "{\"n\": 4225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.14, \"learn_time_ms\": 8926.074, \"total_train_time_s\": 10.667781829833984}", "{\"n\": 4226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.9, \"learn_time_ms\": 9050.697, \"total_train_time_s\": 11.379851818084717}", "{\"n\": 4227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.67, \"learn_time_ms\": 9090.633, \"total_train_time_s\": 10.160972595214844}", "{\"n\": 4228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.19, \"learn_time_ms\": 8982.981, \"total_train_time_s\": 10.509613513946533}", "{\"n\": 4229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.19, \"learn_time_ms\": 8988.232, \"total_train_time_s\": 9.62145209312439}", "{\"n\": 4230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.8, \"learn_time_ms\": 9000.125, \"total_train_time_s\": 10.392566680908203}", "{\"n\": 4231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.29, \"learn_time_ms\": 9146.544, \"total_train_time_s\": 10.563224792480469}", "{\"n\": 4232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.29, \"learn_time_ms\": 9061.788, \"total_train_time_s\": 10.981576204299927}", "{\"n\": 4233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.59, \"learn_time_ms\": 9209.502, \"total_train_time_s\": 11.527565002441406}", "{\"n\": 4234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.59, \"learn_time_ms\": 9274.631, \"total_train_time_s\": 11.150659322738647}", "{\"n\": 4235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.93, \"learn_time_ms\": 9412.342, \"total_train_time_s\": 12.03782343864441}", "{\"n\": 4236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.28, \"learn_time_ms\": 9361.566, \"total_train_time_s\": 10.850034713745117}", "{\"n\": 4237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.29, \"learn_time_ms\": 9309.325, \"total_train_time_s\": 9.641730308532715}", "{\"n\": 4238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.89, \"learn_time_ms\": 9133.93, \"total_train_time_s\": 8.788678884506226}", "{\"n\": 4239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.89, \"learn_time_ms\": 9275.926, \"total_train_time_s\": 11.016541242599487}", "{\"n\": 4240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.7, \"learn_time_ms\": 9298.574, \"total_train_time_s\": 10.600767374038696}", "{\"n\": 4241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.86, \"learn_time_ms\": 9280.695, \"total_train_time_s\": 10.398268222808838}", "{\"n\": 4242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 9189.08, \"total_train_time_s\": 10.052734851837158}", "{\"n\": 4243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.43, \"learn_time_ms\": 8885.03, \"total_train_time_s\": 8.47876524925232}", "{\"n\": 4244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.37, \"learn_time_ms\": 8804.273, \"total_train_time_s\": 10.37028193473816}", "{\"n\": 4245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.68, \"learn_time_ms\": 8640.302, \"total_train_time_s\": 10.423502683639526}", "{\"n\": 4246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.02, \"learn_time_ms\": 8540.285, \"total_train_time_s\": 9.869502782821655}", "{\"n\": 4247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.72, \"learn_time_ms\": 8616.605, \"total_train_time_s\": 10.324153900146484}", "{\"n\": 4248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.45, \"learn_time_ms\": 8675.526, \"total_train_time_s\": 9.374125957489014}", "{\"n\": 4249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.83, \"learn_time_ms\": 8535.33, \"total_train_time_s\": 9.621533393859863}", "{\"n\": 4250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.21, \"learn_time_ms\": 8593.077, \"total_train_time_s\": 11.188426494598389}", "{\"n\": 4251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3196.81, \"learn_time_ms\": 8569.123, \"total_train_time_s\": 10.157689809799194}", "{\"n\": 4252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.29, \"learn_time_ms\": 8565.119, \"total_train_time_s\": 10.053486347198486}", "{\"n\": 4253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.66, \"learn_time_ms\": 8721.618, \"total_train_time_s\": 10.032785177230835}", "{\"n\": 4254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.37, \"learn_time_ms\": 8745.233, \"total_train_time_s\": 10.601433515548706}", "{\"n\": 4255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.4, \"learn_time_ms\": 8732.779, \"total_train_time_s\": 10.364885330200195}", "{\"n\": 4256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.72, \"learn_time_ms\": 8841.009, \"total_train_time_s\": 11.014677286148071}", "{\"n\": 4257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.64, \"learn_time_ms\": 8958.824, \"total_train_time_s\": 11.555270195007324}", "{\"n\": 4258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.89, \"learn_time_ms\": 9119.456, \"total_train_time_s\": 10.973186254501343}", "{\"n\": 4259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.1, \"learn_time_ms\": 9241.41, \"total_train_time_s\": 10.838323593139648}", "{\"n\": 4260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.91, \"learn_time_ms\": 9114.03, \"total_train_time_s\": 9.934717178344727}", "{\"n\": 4261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3185.33, \"learn_time_ms\": 9244.728, \"total_train_time_s\": 11.47022271156311}", "{\"n\": 4262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.81, \"learn_time_ms\": 9306.92, \"total_train_time_s\": 10.63227367401123}", "{\"n\": 4263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 9261.066, \"total_train_time_s\": 9.55753493309021}", "{\"n\": 4264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.14, \"learn_time_ms\": 9159.9, \"total_train_time_s\": 9.566956996917725}", "{\"n\": 4265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.14, \"learn_time_ms\": 9123.053, \"total_train_time_s\": 9.934137105941772}", "{\"n\": 4266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.27, \"learn_time_ms\": 9084.625, \"total_train_time_s\": 10.602744579315186}", "{\"n\": 4267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3172.85, \"learn_time_ms\": 8900.153, \"total_train_time_s\": 9.728867053985596}", "{\"n\": 4268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.24, \"learn_time_ms\": 8784.8, \"total_train_time_s\": 9.78859567642212}", "{\"n\": 4269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.16, \"learn_time_ms\": 8754.536, \"total_train_time_s\": 10.566185474395752}", "{\"n\": 4270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.97, \"learn_time_ms\": 8843.06, \"total_train_time_s\": 10.831442594528198}", "{\"n\": 4271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.77, \"learn_time_ms\": 8680.974, \"total_train_time_s\": 9.899303197860718}", "{\"n\": 4272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.11, \"learn_time_ms\": 8551.158, \"total_train_time_s\": 9.377761363983154}", "{\"n\": 4273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.53, \"learn_time_ms\": 8653.258, \"total_train_time_s\": 10.585315704345703}", "{\"n\": 4274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.0, \"learn_time_ms\": 8732.6, \"total_train_time_s\": 10.354376554489136}", "{\"n\": 4275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.0, \"learn_time_ms\": 8611.443, \"total_train_time_s\": 8.71168828010559}", "{\"n\": 4276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.85, \"learn_time_ms\": 8422.797, \"total_train_time_s\": 8.690455198287964}", "{\"n\": 4277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.95, \"learn_time_ms\": 8467.717, \"total_train_time_s\": 10.149877786636353}", "{\"n\": 4278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.95, \"learn_time_ms\": 8593.354, \"total_train_time_s\": 11.033590078353882}", "{\"n\": 4279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.89, \"learn_time_ms\": 8520.384, \"total_train_time_s\": 9.88274621963501}", "{\"n\": 4280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.73, \"learn_time_ms\": 8417.59, \"total_train_time_s\": 9.807275533676147}", "{\"n\": 4281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.73, \"learn_time_ms\": 8395.603, \"total_train_time_s\": 9.605282068252563}", "{\"n\": 4282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.86, \"learn_time_ms\": 8651.922, \"total_train_time_s\": 11.912087678909302}", "{\"n\": 4283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.05, \"learn_time_ms\": 8675.932, \"total_train_time_s\": 10.825727939605713}", "{\"n\": 4284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.11, \"learn_time_ms\": 8557.637, \"total_train_time_s\": 9.22816276550293}", "{\"n\": 4285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.69, \"learn_time_ms\": 8745.379, \"total_train_time_s\": 10.622801065444946}", "{\"n\": 4286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.45, \"learn_time_ms\": 9005.697, \"total_train_time_s\": 11.283656120300293}", "{\"n\": 4287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.13, \"learn_time_ms\": 9101.951, \"total_train_time_s\": 11.181472063064575}", "{\"n\": 4288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.13, \"learn_time_ms\": 9093.448, \"total_train_time_s\": 10.976926803588867}", "{\"n\": 4289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.31, \"learn_time_ms\": 9132.703, \"total_train_time_s\": 10.243014097213745}", "{\"n\": 4290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.02, \"learn_time_ms\": 9150.342, \"total_train_time_s\": 9.955562829971313}", "{\"n\": 4291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.02, \"learn_time_ms\": 9204.234, \"total_train_time_s\": 10.143234491348267}", "{\"n\": 4292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.92, \"learn_time_ms\": 8950.334, \"total_train_time_s\": 9.33227801322937}", "{\"n\": 4293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.24, \"learn_time_ms\": 8948.814, \"total_train_time_s\": 10.821516036987305}", "{\"n\": 4294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.24, \"learn_time_ms\": 9094.599, \"total_train_time_s\": 10.601827383041382}", "{\"n\": 4295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.74, \"learn_time_ms\": 9077.969, \"total_train_time_s\": 10.43906044960022}", "{\"n\": 4296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.65, \"learn_time_ms\": 8945.973, \"total_train_time_s\": 9.972121477127075}", "{\"n\": 4297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.65, \"learn_time_ms\": 8945.239, \"total_train_time_s\": 11.081361770629883}", "{\"n\": 4298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.2, \"learn_time_ms\": 8839.521, \"total_train_time_s\": 9.891285419464111}", "{\"n\": 4299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.97, \"learn_time_ms\": 8890.936, \"total_train_time_s\": 10.739801406860352}", "{\"n\": 4300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.97, \"learn_time_ms\": 8876.193, \"total_train_time_s\": 9.839590787887573}", "{\"n\": 4301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.99, \"learn_time_ms\": 8920.897, \"total_train_time_s\": 10.603408575057983}", "{\"n\": 4302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.39, \"learn_time_ms\": 8856.557, \"total_train_time_s\": 8.70545220375061}", "{\"n\": 4303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.85, \"learn_time_ms\": 8884.478, \"total_train_time_s\": 11.03477144241333}", "{\"n\": 4304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.85, \"learn_time_ms\": 8930.031, \"total_train_time_s\": 11.134559869766235}", "{\"n\": 4305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.23, \"learn_time_ms\": 8850.33, \"total_train_time_s\": 9.661357164382935}", "{\"n\": 4306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.11, \"learn_time_ms\": 8992.998, \"total_train_time_s\": 11.431977987289429}", "{\"n\": 4307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.11, \"learn_time_ms\": 8991.319, \"total_train_time_s\": 11.117358446121216}", "{\"n\": 4308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.24, \"learn_time_ms\": 9028.996, \"total_train_time_s\": 10.266700744628906}", "{\"n\": 4309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.84, \"learn_time_ms\": 8883.919, \"total_train_time_s\": 9.309271335601807}", "{\"n\": 4310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.84, \"learn_time_ms\": 8878.441, \"total_train_time_s\": 9.771271228790283}", "{\"n\": 4311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.61, \"learn_time_ms\": 8873.867, \"total_train_time_s\": 10.57277512550354}", "{\"n\": 4312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.16, \"learn_time_ms\": 9091.544, \"total_train_time_s\": 10.928038597106934}", "{\"n\": 4313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.72, \"learn_time_ms\": 8957.524, \"total_train_time_s\": 9.716235876083374}", "{\"n\": 4314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.33, \"learn_time_ms\": 8896.815, \"total_train_time_s\": 10.456323862075806}", "{\"n\": 4315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.4, \"learn_time_ms\": 8943.564, \"total_train_time_s\": 10.073370695114136}", "{\"n\": 4316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.4, \"learn_time_ms\": 8842.012, \"total_train_time_s\": 10.318167686462402}", "{\"n\": 4317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.76, \"learn_time_ms\": 8831.335, \"total_train_time_s\": 10.994132280349731}", "{\"n\": 4318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.2, \"learn_time_ms\": 8840.903, \"total_train_time_s\": 10.426460981369019}", "{\"n\": 4319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.74, \"learn_time_ms\": 8950.107, \"total_train_time_s\": 10.344717025756836}", "{\"n\": 4320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.28, \"learn_time_ms\": 8984.866, \"total_train_time_s\": 10.106711149215698}", "{\"n\": 4321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.31, \"learn_time_ms\": 8926.799, \"total_train_time_s\": 10.011930704116821}", "{\"n\": 4322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.64, \"learn_time_ms\": 8809.514, \"total_train_time_s\": 9.726724624633789}", "{\"n\": 4323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.62, \"learn_time_ms\": 8736.02, \"total_train_time_s\": 9.002777814865112}", "{\"n\": 4324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3150.26, \"learn_time_ms\": 8578.63, \"total_train_time_s\": 8.894742965698242}", "{\"n\": 4325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.71, \"learn_time_ms\": 8527.786, \"total_train_time_s\": 9.536057472229004}", "{\"n\": 4326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.74, \"learn_time_ms\": 8493.765, \"total_train_time_s\": 10.018907308578491}", "{\"n\": 4327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3164.25, \"learn_time_ms\": 8581.358, \"total_train_time_s\": 11.881599426269531}", "{\"n\": 4328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.12, \"learn_time_ms\": 8618.967, \"total_train_time_s\": 10.894474744796753}", "{\"n\": 4329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.12, \"learn_time_ms\": 8596.796, \"total_train_time_s\": 10.12365984916687}", "{\"n\": 4330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.42, \"learn_time_ms\": 8551.25, \"total_train_time_s\": 9.664900302886963}", "{\"n\": 4331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.86, \"learn_time_ms\": 8575.268, \"total_train_time_s\": 10.163460493087769}", "{\"n\": 4332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3163.86, \"learn_time_ms\": 8592.911, \"total_train_time_s\": 9.901767492294312}", "{\"n\": 4333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.97, \"learn_time_ms\": 8776.826, \"total_train_time_s\": 10.862266540527344}", "{\"n\": 4334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.03, \"learn_time_ms\": 8888.356, \"total_train_time_s\": 10.000473976135254}", "{\"n\": 4335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.96, \"learn_time_ms\": 9043.509, \"total_train_time_s\": 11.123716354370117}", "{\"n\": 4336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.6, \"learn_time_ms\": 9077.482, \"total_train_time_s\": 10.371277093887329}", "{\"n\": 4337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.92, \"learn_time_ms\": 8862.445, \"total_train_time_s\": 9.714167594909668}", "{\"n\": 4338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.59, \"learn_time_ms\": 8702.995, \"total_train_time_s\": 9.167284488677979}", "{\"n\": 4339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.22, \"learn_time_ms\": 8704.964, \"total_train_time_s\": 10.1926589012146}", "{\"n\": 4340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.54, \"learn_time_ms\": 8933.227, \"total_train_time_s\": 11.914902448654175}", "{\"n\": 4341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.54, \"learn_time_ms\": 8946.625, \"total_train_time_s\": 10.343496322631836}", "{\"n\": 4342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.08, \"learn_time_ms\": 9057.617, \"total_train_time_s\": 11.026465892791748}", "{\"n\": 4343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.9, \"learn_time_ms\": 8875.862, \"total_train_time_s\": 9.033031940460205}", "{\"n\": 4344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.9, \"learn_time_ms\": 9001.751, \"total_train_time_s\": 11.279285430908203}", "{\"n\": 4345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.85, \"learn_time_ms\": 8916.743, \"total_train_time_s\": 10.290886402130127}", "{\"n\": 4346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.49, \"learn_time_ms\": 9099.67, \"total_train_time_s\": 12.184437990188599}", "{\"n\": 4347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.49, \"learn_time_ms\": 9117.455, \"total_train_time_s\": 9.890060663223267}", "{\"n\": 4348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.79, \"learn_time_ms\": 9298.934, \"total_train_time_s\": 10.959741592407227}", "{\"n\": 4349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 9456.13, \"total_train_time_s\": 11.744799613952637}", "{\"n\": 4350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.09, \"learn_time_ms\": 9191.219, \"total_train_time_s\": 9.249884605407715}", "{\"n\": 4351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.82, \"learn_time_ms\": 9164.669, \"total_train_time_s\": 10.108489274978638}", "{\"n\": 4352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.2, \"learn_time_ms\": 9100.807, \"total_train_time_s\": 10.381777048110962}", "{\"n\": 4353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.48, \"learn_time_ms\": 9233.668, \"total_train_time_s\": 10.450215101242065}", "{\"n\": 4354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.48, \"learn_time_ms\": 9076.939, \"total_train_time_s\": 9.714646816253662}", "{\"n\": 4355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.69, \"learn_time_ms\": 9102.43, \"total_train_time_s\": 10.54501724243164}", "{\"n\": 4356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.89, \"learn_time_ms\": 8875.849, \"total_train_time_s\": 9.93833065032959}", "{\"n\": 4357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.14, \"learn_time_ms\": 8897.489, \"total_train_time_s\": 10.093194484710693}", "{\"n\": 4358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.55, \"learn_time_ms\": 8723.834, \"total_train_time_s\": 9.347646474838257}", "{\"n\": 4359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.55, \"learn_time_ms\": 8460.123, \"total_train_time_s\": 9.137831926345825}", "{\"n\": 4360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.15, \"learn_time_ms\": 8543.191, \"total_train_time_s\": 10.111589908599854}", "{\"n\": 4361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.91, \"learn_time_ms\": 8584.648, \"total_train_time_s\": 10.510678768157959}", "{\"n\": 4362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.48, \"learn_time_ms\": 8647.921, \"total_train_time_s\": 10.994754791259766}", "{\"n\": 4363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3193.12, \"learn_time_ms\": 8656.233, \"total_train_time_s\": 10.441070318222046}", "{\"n\": 4364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.29, \"learn_time_ms\": 8596.203, \"total_train_time_s\": 9.100203514099121}", "{\"n\": 4365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.78, \"learn_time_ms\": 8469.231, \"total_train_time_s\": 9.297246932983398}", "{\"n\": 4366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.37, \"learn_time_ms\": 8346.867, \"total_train_time_s\": 8.6770658493042}", "{\"n\": 4367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.34, \"learn_time_ms\": 8280.251, \"total_train_time_s\": 9.428299188613892}", "{\"n\": 4368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.23, \"learn_time_ms\": 8296.212, \"total_train_time_s\": 9.427152395248413}", "{\"n\": 4369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.19, \"learn_time_ms\": 8496.493, \"total_train_time_s\": 11.065939903259277}", "{\"n\": 4370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.87, \"learn_time_ms\": 8433.539, \"total_train_time_s\": 9.46994662284851}", "{\"n\": 4371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.78, \"learn_time_ms\": 8422.932, \"total_train_time_s\": 10.414484739303589}", "{\"n\": 4372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.4, \"learn_time_ms\": 8393.351, \"total_train_time_s\": 10.72646164894104}", "{\"n\": 4373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.55, \"learn_time_ms\": 8450.108, \"total_train_time_s\": 11.077902793884277}", "{\"n\": 4374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.42, \"learn_time_ms\": 8611.034, \"total_train_time_s\": 10.760253667831421}", "{\"n\": 4375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.71, \"learn_time_ms\": 8677.139, \"total_train_time_s\": 9.951368808746338}", "{\"n\": 4376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.63, \"learn_time_ms\": 8756.577, \"total_train_time_s\": 9.50046157836914}", "{\"n\": 4377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.48, \"learn_time_ms\": 8822.86, \"total_train_time_s\": 10.115405797958374}", "{\"n\": 4378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.54, \"learn_time_ms\": 8823.409, \"total_train_time_s\": 9.405153751373291}", "{\"n\": 4379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.81, \"learn_time_ms\": 8735.958, \"total_train_time_s\": 10.270619869232178}", "{\"n\": 4380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.72, \"learn_time_ms\": 8804.424, \"total_train_time_s\": 10.108578443527222}", "{\"n\": 4381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.07, \"learn_time_ms\": 8776.169, \"total_train_time_s\": 10.094080209732056}", "{\"n\": 4382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.33, \"learn_time_ms\": 8666.666, \"total_train_time_s\": 9.608777284622192}", "{\"n\": 4383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.33, \"learn_time_ms\": 8594.538, \"total_train_time_s\": 10.269169330596924}", "{\"n\": 4384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.85, \"learn_time_ms\": 8454.046, \"total_train_time_s\": 9.303871154785156}", "{\"n\": 4385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.89, \"learn_time_ms\": 8417.7, \"total_train_time_s\": 9.603092908859253}", "{\"n\": 4386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3212.44, \"learn_time_ms\": 8522.966, \"total_train_time_s\": 10.611893892288208}", "{\"n\": 4387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.8, \"learn_time_ms\": 8588.429, \"total_train_time_s\": 10.938167572021484}", "{\"n\": 4388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.15, \"learn_time_ms\": 8703.749, \"total_train_time_s\": 10.590422630310059}", "{\"n\": 4389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.93, \"learn_time_ms\": 8667.593, \"total_train_time_s\": 9.867966413497925}", "{\"n\": 4390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.93, \"learn_time_ms\": 8623.013, \"total_train_time_s\": 9.717265367507935}", "{\"n\": 4391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.23, \"learn_time_ms\": 8664.199, \"total_train_time_s\": 10.539887189865112}", "{\"n\": 4392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.53, \"learn_time_ms\": 8716.829, \"total_train_time_s\": 10.128417015075684}", "{\"n\": 4393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.05, \"learn_time_ms\": 8750.741, \"total_train_time_s\": 10.618447065353394}", "{\"n\": 4394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.63, \"learn_time_ms\": 8887.654, \"total_train_time_s\": 10.70110273361206}", "{\"n\": 4395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.18, \"learn_time_ms\": 8899.052, \"total_train_time_s\": 9.663837671279907}", "{\"n\": 4396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.18, \"learn_time_ms\": 8943.433, \"total_train_time_s\": 10.998261451721191}", "{\"n\": 4397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.28, \"learn_time_ms\": 8911.637, \"total_train_time_s\": 10.44866156578064}", "{\"n\": 4398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.89, \"learn_time_ms\": 8773.663, \"total_train_time_s\": 9.167346954345703}", "{\"n\": 4399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.21, \"learn_time_ms\": 8781.877, \"total_train_time_s\": 9.962704181671143}", "{\"n\": 4400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.88, \"learn_time_ms\": 8818.813, \"total_train_time_s\": 10.095476865768433}", "{\"n\": 4401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.33, \"learn_time_ms\": 8730.901, \"total_train_time_s\": 9.65359878540039}", "{\"n\": 4402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.29, \"learn_time_ms\": 8721.169, \"total_train_time_s\": 10.020794153213501}", "{\"n\": 4403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.2, \"learn_time_ms\": 8608.488, \"total_train_time_s\": 9.475287675857544}", "{\"n\": 4404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 8552.108, \"total_train_time_s\": 10.114128828048706}", "{\"n\": 4405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.9, \"learn_time_ms\": 8623.17, \"total_train_time_s\": 10.436602115631104}", "{\"n\": 4406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.64, \"learn_time_ms\": 8534.64, \"total_train_time_s\": 10.115726470947266}", "{\"n\": 4407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.88, \"learn_time_ms\": 8513.592, \"total_train_time_s\": 10.203726053237915}", "{\"n\": 4408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.88, \"learn_time_ms\": 8639.508, \"total_train_time_s\": 10.48348355293274}", "{\"n\": 4409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.94, \"learn_time_ms\": 8755.389, \"total_train_time_s\": 11.134479284286499}", "{\"n\": 4410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.64, \"learn_time_ms\": 8828.361, \"total_train_time_s\": 10.83123779296875}", "{\"n\": 4411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.74, \"learn_time_ms\": 8844.915, \"total_train_time_s\": 9.8710196018219}", "{\"n\": 4412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.41, \"learn_time_ms\": 8813.412, \"total_train_time_s\": 9.711380958557129}", "{\"n\": 4413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.7, \"learn_time_ms\": 8779.735, \"total_train_time_s\": 9.150611400604248}", "{\"n\": 4414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.77, \"learn_time_ms\": 8767.15, \"total_train_time_s\": 10.030433654785156}", "{\"n\": 4415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.78, \"learn_time_ms\": 8677.948, \"total_train_time_s\": 9.471515417098999}", "{\"n\": 4416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.08, \"learn_time_ms\": 8582.466, \"total_train_time_s\": 9.138176679611206}", "{\"n\": 4417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.26, \"learn_time_ms\": 8759.159, \"total_train_time_s\": 12.027480363845825}", "{\"n\": 4418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.26, \"learn_time_ms\": 8710.312, \"total_train_time_s\": 10.01474380493164}", "{\"n\": 4419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.29, \"learn_time_ms\": 8642.99, \"total_train_time_s\": 10.40730595588684}", "{\"n\": 4420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.36, \"learn_time_ms\": 8502.769, \"total_train_time_s\": 9.412250518798828}", "{\"n\": 4421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.36, \"learn_time_ms\": 8558.701, \"total_train_time_s\": 10.38619327545166}", "{\"n\": 4422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.36, \"learn_time_ms\": 8546.309, \"total_train_time_s\": 9.603111743927002}", "{\"n\": 4423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.02, \"learn_time_ms\": 8743.668, \"total_train_time_s\": 11.138954639434814}", "{\"n\": 4424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.36, \"learn_time_ms\": 8674.686, \"total_train_time_s\": 9.290952205657959}", "{\"n\": 4425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.36, \"learn_time_ms\": 8709.687, \"total_train_time_s\": 9.874073505401611}", "{\"n\": 4426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.35, \"learn_time_ms\": 8799.378, \"total_train_time_s\": 10.0582914352417}", "{\"n\": 4427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.35, \"learn_time_ms\": 8682.059, \"total_train_time_s\": 10.77443242073059}", "{\"n\": 4428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.35, \"learn_time_ms\": 8611.156, \"total_train_time_s\": 9.251784324645996}", "{\"n\": 4429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.56, \"learn_time_ms\": 8555.084, \"total_train_time_s\": 9.892164468765259}", "{\"n\": 4430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.2, \"learn_time_ms\": 8568.985, \"total_train_time_s\": 9.532052040100098}", "{\"n\": 4431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.2, \"learn_time_ms\": 8472.817, \"total_train_time_s\": 9.464195489883423}", "{\"n\": 4432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.39, \"learn_time_ms\": 8468.241, \"total_train_time_s\": 9.550687074661255}", "{\"n\": 4433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.22, \"learn_time_ms\": 8371.978, \"total_train_time_s\": 10.19963002204895}", "{\"n\": 4434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.22, \"learn_time_ms\": 8393.111, \"total_train_time_s\": 9.506917715072632}", "{\"n\": 4435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.98, \"learn_time_ms\": 8300.123, \"total_train_time_s\": 8.976861476898193}", "{\"n\": 4436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.85, \"learn_time_ms\": 8450.826, \"total_train_time_s\": 11.564608335494995}", "{\"n\": 4437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.85, \"learn_time_ms\": 8382.81, \"total_train_time_s\": 10.113099336624146}", "{\"n\": 4438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.19, \"learn_time_ms\": 8421.77, \"total_train_time_s\": 9.679094791412354}", "{\"n\": 4439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.05, \"learn_time_ms\": 8385.028, \"total_train_time_s\": 9.519023418426514}", "{\"n\": 4440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.89, \"learn_time_ms\": 8521.565, \"total_train_time_s\": 10.95406436920166}", "{\"n\": 4441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.91, \"learn_time_ms\": 8575.54, \"total_train_time_s\": 10.000106573104858}", "{\"n\": 4442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.04, \"learn_time_ms\": 8556.487, \"total_train_time_s\": 9.356959342956543}", "{\"n\": 4443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8484.482, \"total_train_time_s\": 9.495041847229004}", "{\"n\": 4444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 8587.118, \"total_train_time_s\": 10.584827184677124}", "{\"n\": 4445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.14, \"learn_time_ms\": 8665.311, \"total_train_time_s\": 9.696277618408203}", "{\"n\": 4446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.53, \"learn_time_ms\": 8578.236, \"total_train_time_s\": 10.722940921783447}", "{\"n\": 4447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.53, \"learn_time_ms\": 8592.925, \"total_train_time_s\": 10.28279995918274}", "{\"n\": 4448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.17, \"learn_time_ms\": 8499.606, \"total_train_time_s\": 8.702231884002686}", "{\"n\": 4449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.81, \"learn_time_ms\": 8472.112, \"total_train_time_s\": 9.251550912857056}", "{\"n\": 4450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.81, \"learn_time_ms\": 8358.219, \"total_train_time_s\": 9.78103494644165}", "{\"n\": 4451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.34, \"learn_time_ms\": 8495.876, \"total_train_time_s\": 11.339564085006714}", "{\"n\": 4452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.34, \"learn_time_ms\": 8569.918, \"total_train_time_s\": 10.101439714431763}", "{\"n\": 4453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.45, \"learn_time_ms\": 8650.555, \"total_train_time_s\": 10.25107455253601}", "{\"n\": 4454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.36, \"learn_time_ms\": 8584.219, \"total_train_time_s\": 9.87005066871643}", "{\"n\": 4455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.73, \"learn_time_ms\": 8544.447, \"total_train_time_s\": 9.298885822296143}", "{\"n\": 4456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.16, \"learn_time_ms\": 8373.238, \"total_train_time_s\": 9.011151552200317}", "{\"n\": 4457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.69, \"learn_time_ms\": 8224.374, \"total_train_time_s\": 8.823959112167358}", "{\"n\": 4458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.95, \"learn_time_ms\": 8362.684, \"total_train_time_s\": 10.09799337387085}", "{\"n\": 4459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.51, \"learn_time_ms\": 8551.553, \"total_train_time_s\": 11.100951194763184}", "{\"n\": 4460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.27, \"learn_time_ms\": 8548.617, \"total_train_time_s\": 9.806227684020996}", "{\"n\": 4461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.17, \"learn_time_ms\": 8352.291, \"total_train_time_s\": 9.410263776779175}", "{\"n\": 4462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.17, \"learn_time_ms\": 8288.708, \"total_train_time_s\": 9.465733051300049}", "{\"n\": 4463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.29, \"learn_time_ms\": 8294.721, \"total_train_time_s\": 10.311732769012451}", "{\"n\": 4464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.82, \"learn_time_ms\": 8214.098, \"total_train_time_s\": 9.075390338897705}", "{\"n\": 4465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.82, \"learn_time_ms\": 8316.817, \"total_train_time_s\": 10.290499925613403}", "{\"n\": 4466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.06, \"learn_time_ms\": 8351.497, \"total_train_time_s\": 9.3484365940094}", "{\"n\": 4467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.06, \"learn_time_ms\": 8436.956, \"total_train_time_s\": 9.632190465927124}", "{\"n\": 4468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.06, \"learn_time_ms\": 8206.769, \"total_train_time_s\": 7.777486324310303}", "{\"n\": 4469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.8, \"learn_time_ms\": 8052.058, \"total_train_time_s\": 9.617470741271973}", "{\"n\": 4470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.99, \"learn_time_ms\": 7991.152, \"total_train_time_s\": 9.175923347473145}", "{\"n\": 4471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.32, \"learn_time_ms\": 8248.322, \"total_train_time_s\": 11.953358888626099}", "{\"n\": 4472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.38, \"learn_time_ms\": 8177.387, \"total_train_time_s\": 8.746483325958252}", "{\"n\": 4473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.77, \"learn_time_ms\": 8393.577, \"total_train_time_s\": 12.479939937591553}", "{\"n\": 4474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.77, \"learn_time_ms\": 8420.331, \"total_train_time_s\": 9.357455253601074}", "{\"n\": 4475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.84, \"learn_time_ms\": 8488.709, \"total_train_time_s\": 11.027204275131226}", "{\"n\": 4476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.7, \"learn_time_ms\": 8651.76, \"total_train_time_s\": 10.934495210647583}", "{\"n\": 4477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.17, \"learn_time_ms\": 8585.256, \"total_train_time_s\": 8.976294994354248}", "{\"n\": 4478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.59, \"learn_time_ms\": 8842.006, \"total_train_time_s\": 10.333446025848389}", "{\"n\": 4479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.09, \"learn_time_ms\": 8985.914, \"total_train_time_s\": 10.993803024291992}", "{\"n\": 4480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.26, \"learn_time_ms\": 9199.787, \"total_train_time_s\": 11.336987733840942}", "{\"n\": 4481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.65, \"learn_time_ms\": 9083.916, \"total_train_time_s\": 10.836274147033691}", "{\"n\": 4482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.38, \"learn_time_ms\": 9188.331, \"total_train_time_s\": 9.774630784988403}", "{\"n\": 4483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.32, \"learn_time_ms\": 8965.275, \"total_train_time_s\": 10.252094030380249}", "{\"n\": 4484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.52, \"learn_time_ms\": 9081.938, \"total_train_time_s\": 10.512648582458496}", "{\"n\": 4485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.89, \"learn_time_ms\": 9071.04, \"total_train_time_s\": 10.888664245605469}", "{\"n\": 4486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.43, \"learn_time_ms\": 9040.097, \"total_train_time_s\": 10.651065349578857}", "{\"n\": 4487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.1, \"learn_time_ms\": 9096.755, \"total_train_time_s\": 9.523795366287231}", "{\"n\": 4488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.75, \"learn_time_ms\": 9152.446, \"total_train_time_s\": 10.897614240646362}", "{\"n\": 4489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.29, \"learn_time_ms\": 9117.045, \"total_train_time_s\": 10.624441862106323}", "{\"n\": 4490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.19, \"learn_time_ms\": 8969.709, \"total_train_time_s\": 9.849416732788086}", "{\"n\": 4491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.72, \"learn_time_ms\": 8906.913, \"total_train_time_s\": 10.156663417816162}", "{\"n\": 4492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.01, \"learn_time_ms\": 9121.709, \"total_train_time_s\": 11.955726146697998}", "{\"n\": 4493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.99, \"learn_time_ms\": 9205.102, \"total_train_time_s\": 11.117570877075195}", "{\"n\": 4494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.5, \"learn_time_ms\": 9074.564, \"total_train_time_s\": 9.204975843429565}", "{\"n\": 4495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.57, \"learn_time_ms\": 9002.036, \"total_train_time_s\": 10.222033500671387}", "{\"n\": 4496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.97, \"learn_time_ms\": 8985.88, \"total_train_time_s\": 10.532428979873657}", "{\"n\": 4497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.32, \"learn_time_ms\": 9063.102, \"total_train_time_s\": 10.419979572296143}", "{\"n\": 4498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.77, \"learn_time_ms\": 8962.512, \"total_train_time_s\": 9.91346526145935}", "{\"n\": 4499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.8, \"learn_time_ms\": 8919.875, \"total_train_time_s\": 10.23421311378479}", "{\"n\": 4500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.8, \"learn_time_ms\": 8966.743, \"total_train_time_s\": 10.254089832305908}", "{\"n\": 4501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.99, \"learn_time_ms\": 8886.886, \"total_train_time_s\": 9.367058992385864}", "{\"n\": 4502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.99, \"learn_time_ms\": 8685.923, \"total_train_time_s\": 9.957360982894897}", "{\"n\": 4503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.37, \"learn_time_ms\": 8536.303, \"total_train_time_s\": 9.614732265472412}", "{\"n\": 4504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.3, \"learn_time_ms\": 8696.62, \"total_train_time_s\": 10.802347660064697}", "{\"n\": 4505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.76, \"learn_time_ms\": 8687.121, \"total_train_time_s\": 10.114835739135742}", "{\"n\": 4506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.56, \"learn_time_ms\": 8651.768, \"total_train_time_s\": 10.282940864562988}", "{\"n\": 4507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.56, \"learn_time_ms\": 8744.472, \"total_train_time_s\": 11.262644529342651}", "{\"n\": 4508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3187.19, \"learn_time_ms\": 8665.884, \"total_train_time_s\": 9.14277195930481}", "{\"n\": 4509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3194.42, \"learn_time_ms\": 8606.276, \"total_train_time_s\": 9.695765018463135}", "{\"n\": 4510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3194.42, \"learn_time_ms\": 8645.587, \"total_train_time_s\": 10.69581127166748}", "{\"n\": 4511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3200.63, \"learn_time_ms\": 8864.434, \"total_train_time_s\": 11.562167167663574}", "{\"n\": 4512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3200.63, \"learn_time_ms\": 8853.225, \"total_train_time_s\": 9.79402232170105}", "{\"n\": 4513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.05, \"learn_time_ms\": 8759.637, \"total_train_time_s\": 8.666848182678223}", "{\"n\": 4514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3199.99, \"learn_time_ms\": 8710.688, \"total_train_time_s\": 10.301016330718994}", "{\"n\": 4515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3206.21, \"learn_time_ms\": 8730.421, \"total_train_time_s\": 10.256660223007202}", "{\"n\": 4516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3213.9, \"learn_time_ms\": 8645.999, \"total_train_time_s\": 9.34066653251648}", "{\"n\": 4517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3217.55, \"learn_time_ms\": 8425.442, \"total_train_time_s\": 9.05186915397644}", "{\"n\": 4518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3230.08, \"learn_time_ms\": 8469.145, \"total_train_time_s\": 9.527234077453613}", "{\"n\": 4519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3228.35, \"learn_time_ms\": 8584.06, \"total_train_time_s\": 10.778834819793701}", "{\"n\": 4520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3228.35, \"learn_time_ms\": 8558.831, \"total_train_time_s\": 10.452478408813477}", "{\"n\": 4521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3224.82, \"learn_time_ms\": 8514.011, \"total_train_time_s\": 11.127285242080688}", "{\"n\": 4522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3223.37, \"learn_time_ms\": 8637.636, \"total_train_time_s\": 11.110834121704102}", "{\"n\": 4523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3223.37, \"learn_time_ms\": 8696.848, \"total_train_time_s\": 9.268919944763184}", "{\"n\": 4524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3217.46, \"learn_time_ms\": 8667.48, \"total_train_time_s\": 10.015209913253784}", "{\"n\": 4525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.79, \"learn_time_ms\": 8754.972, \"total_train_time_s\": 11.147349119186401}", "{\"n\": 4526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3222.65, \"learn_time_ms\": 8789.818, \"total_train_time_s\": 9.60239863395691}", "{\"n\": 4527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3224.59, \"learn_time_ms\": 8879.539, \"total_train_time_s\": 10.002939701080322}", "{\"n\": 4528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3217.78, \"learn_time_ms\": 9077.599, \"total_train_time_s\": 11.544323205947876}", "{\"n\": 4529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3218.35, \"learn_time_ms\": 9011.424, \"total_train_time_s\": 10.14614748954773}", "{\"n\": 4530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3221.03, \"learn_time_ms\": 9147.342, \"total_train_time_s\": 11.816025495529175}", "{\"n\": 4531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.14, \"learn_time_ms\": 9085.847, \"total_train_time_s\": 10.516162157058716}", "{\"n\": 4532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3226.55, \"learn_time_ms\": 9037.517, \"total_train_time_s\": 10.615778684616089}", "{\"n\": 4533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3226.55, \"learn_time_ms\": 9035.474, \"total_train_time_s\": 9.215972185134888}", "{\"n\": 4534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3223.89, \"learn_time_ms\": 8979.728, \"total_train_time_s\": 9.462435960769653}", "{\"n\": 4535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3232.13, \"learn_time_ms\": 8900.347, \"total_train_time_s\": 10.38111662864685}", "{\"n\": 4536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.65, \"learn_time_ms\": 9011.022, \"total_train_time_s\": 10.775083541870117}", "{\"n\": 4537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.17, \"learn_time_ms\": 8962.024, \"total_train_time_s\": 9.463012456893921}", "{\"n\": 4538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.45, \"learn_time_ms\": 8795.253, \"total_train_time_s\": 9.8847177028656}", "{\"n\": 4539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3239.59, \"learn_time_ms\": 8657.875, \"total_train_time_s\": 8.753454208374023}", "{\"n\": 4540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3240.79, \"learn_time_ms\": 8539.009, \"total_train_time_s\": 10.594887733459473}", "{\"n\": 4541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.82, \"learn_time_ms\": 8631.232, \"total_train_time_s\": 11.412121057510376}", "{\"n\": 4542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3254.82, \"learn_time_ms\": 8446.459, \"total_train_time_s\": 8.715232372283936}", "{\"n\": 4543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3261.5, \"learn_time_ms\": 8653.203, \"total_train_time_s\": 11.27455735206604}", "{\"n\": 4544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3264.86, \"learn_time_ms\": 8802.349, \"total_train_time_s\": 10.964210748672485}", "{\"n\": 4545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3264.86, \"learn_time_ms\": 8703.517, \"total_train_time_s\": 9.389863729476929}", "{\"n\": 4546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3267.83, \"learn_time_ms\": 8607.428, \"total_train_time_s\": 9.789031267166138}", "{\"n\": 4547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.31, \"learn_time_ms\": 8724.158, \"total_train_time_s\": 10.646912813186646}", "{\"n\": 4548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.72, \"learn_time_ms\": 8762.338, \"total_train_time_s\": 10.260239839553833}", "{\"n\": 4549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.58, \"learn_time_ms\": 8907.924, \"total_train_time_s\": 10.249567031860352}", "{\"n\": 4550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.91, \"learn_time_ms\": 8956.311, \"total_train_time_s\": 11.082020044326782}", "{\"n\": 4551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.64, \"learn_time_ms\": 8815.4, \"total_train_time_s\": 9.988453149795532}", "{\"n\": 4552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.23, \"learn_time_ms\": 8942.244, \"total_train_time_s\": 10.035881996154785}", "{\"n\": 4553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.87, \"learn_time_ms\": 8870.172, \"total_train_time_s\": 10.557257652282715}", "{\"n\": 4554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.99, \"learn_time_ms\": 8720.483, \"total_train_time_s\": 9.490181922912598}", "{\"n\": 4555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.49, \"learn_time_ms\": 8882.797, \"total_train_time_s\": 10.990241527557373}", "{\"n\": 4556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.53, \"learn_time_ms\": 8869.732, \"total_train_time_s\": 9.678390264511108}", "{\"n\": 4557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.67, \"learn_time_ms\": 8916.306, \"total_train_time_s\": 11.096879005432129}", "{\"n\": 4558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.67, \"learn_time_ms\": 8944.416, \"total_train_time_s\": 10.567106246948242}", "{\"n\": 4559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3266.35, \"learn_time_ms\": 9076.502, \"total_train_time_s\": 11.547398090362549}", "{\"n\": 4560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3258.59, \"learn_time_ms\": 8946.858, \"total_train_time_s\": 9.82638669013977}", "{\"n\": 4561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3258.59, \"learn_time_ms\": 9015.303, \"total_train_time_s\": 10.699816226959229}", "{\"n\": 4562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3263.49, \"learn_time_ms\": 9110.819, \"total_train_time_s\": 10.983437538146973}", "{\"n\": 4563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.32, \"learn_time_ms\": 9008.528, \"total_train_time_s\": 9.57756519317627}", "{\"n\": 4564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3259.65, \"learn_time_ms\": 9043.701, \"total_train_time_s\": 9.811971187591553}", "{\"n\": 4565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.99, \"learn_time_ms\": 9023.718, \"total_train_time_s\": 10.835233449935913}", "{\"n\": 4566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3269.99, \"learn_time_ms\": 9017.736, \"total_train_time_s\": 9.557121276855469}", "{\"n\": 4567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.2, \"learn_time_ms\": 8909.304, \"total_train_time_s\": 10.022907972335815}", "{\"n\": 4568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.63, \"learn_time_ms\": 8750.343, \"total_train_time_s\": 8.911436796188354}", "{\"n\": 4569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.47, \"learn_time_ms\": 8699.167, \"total_train_time_s\": 11.038581132888794}", "{\"n\": 4570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.65, \"learn_time_ms\": 8767.195, \"total_train_time_s\": 10.49408745765686}", "{\"n\": 4571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.65, \"learn_time_ms\": 8686.802, \"total_train_time_s\": 9.871526718139648}", "{\"n\": 4572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.25, \"learn_time_ms\": 8496.28, \"total_train_time_s\": 9.060685157775879}", "{\"n\": 4573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.52, \"learn_time_ms\": 8657.839, \"total_train_time_s\": 11.202789306640625}", "{\"n\": 4574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.52, \"learn_time_ms\": 8662.999, \"total_train_time_s\": 9.877388715744019}", "{\"n\": 4575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3287.03, \"learn_time_ms\": 8487.681, \"total_train_time_s\": 9.036574840545654}", "{\"n\": 4576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.16, \"learn_time_ms\": 8506.038, \"total_train_time_s\": 9.764283895492554}", "{\"n\": 4577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.55, \"learn_time_ms\": 8530.673, \"total_train_time_s\": 10.244974851608276}", "{\"n\": 4578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.2, \"learn_time_ms\": 8610.132, \"total_train_time_s\": 9.752837896347046}", "{\"n\": 4579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.2, \"learn_time_ms\": 8426.364, \"total_train_time_s\": 9.17424488067627}", "{\"n\": 4580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.68, \"learn_time_ms\": 8362.787, \"total_train_time_s\": 9.865478515625}", "{\"n\": 4581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.67, \"learn_time_ms\": 8411.899, \"total_train_time_s\": 10.403522968292236}", "{\"n\": 4582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3293.35, \"learn_time_ms\": 8543.436, \"total_train_time_s\": 10.428558826446533}", "{\"n\": 4583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.2, \"learn_time_ms\": 8492.327, \"total_train_time_s\": 10.689023971557617}", "{\"n\": 4584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.2, \"learn_time_ms\": 8429.264, \"total_train_time_s\": 9.246017932891846}", "{\"n\": 4585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.11, \"learn_time_ms\": 8704.294, \"total_train_time_s\": 11.834842681884766}", "{\"n\": 4586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.68, \"learn_time_ms\": 8803.288, \"total_train_time_s\": 10.82704758644104}", "{\"n\": 4587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8867.267, \"total_train_time_s\": 10.94221305847168}", "{\"n\": 4588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.29, \"learn_time_ms\": 8902.28, \"total_train_time_s\": 10.12461543083191}", "{\"n\": 4589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.85, \"learn_time_ms\": 9143.019, \"total_train_time_s\": 11.650894403457642}", "{\"n\": 4590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.22, \"learn_time_ms\": 9282.947, \"total_train_time_s\": 11.239058017730713}", "{\"n\": 4591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.22, \"learn_time_ms\": 9270.749, \"total_train_time_s\": 10.235161781311035}", "{\"n\": 4592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.04, \"learn_time_ms\": 9293.279, \"total_train_time_s\": 10.599258422851562}", "{\"n\": 4593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.42, \"learn_time_ms\": 9422.463, \"total_train_time_s\": 11.965665340423584}", "{\"n\": 4594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.65, \"learn_time_ms\": 9679.551, \"total_train_time_s\": 11.82420301437378}", "{\"n\": 4595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.87, \"learn_time_ms\": 9447.726, \"total_train_time_s\": 9.49546504020691}", "{\"n\": 4596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.23, \"learn_time_ms\": 9202.176, \"total_train_time_s\": 8.3612539768219}", "{\"n\": 4597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.91, \"learn_time_ms\": 9194.713, \"total_train_time_s\": 10.829071283340454}", "{\"n\": 4598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.05, \"learn_time_ms\": 9266.138, \"total_train_time_s\": 10.81139612197876}", "{\"n\": 4599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.87, \"learn_time_ms\": 9138.197, \"total_train_time_s\": 10.328690767288208}", "{\"n\": 4600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.59, \"learn_time_ms\": 8971.615, \"total_train_time_s\": 9.551084995269775}", "{\"n\": 4601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.72, \"learn_time_ms\": 8973.09, \"total_train_time_s\": 10.251246690750122}", "{\"n\": 4602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.72, \"learn_time_ms\": 8892.991, \"total_train_time_s\": 9.83017635345459}", "{\"n\": 4603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8690.975, \"total_train_time_s\": 9.936154127120972}", "{\"n\": 4604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8560.363, \"total_train_time_s\": 10.525813817977905}", "{\"n\": 4605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.63, \"learn_time_ms\": 8601.997, \"total_train_time_s\": 9.912173986434937}", "{\"n\": 4606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.63, \"learn_time_ms\": 8724.622, \"total_train_time_s\": 9.53917121887207}", "{\"n\": 4607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.52, \"learn_time_ms\": 8789.905, \"total_train_time_s\": 11.439678192138672}", "{\"n\": 4608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.3, \"learn_time_ms\": 8703.738, \"total_train_time_s\": 9.953039646148682}", "{\"n\": 4609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 8736.968, \"total_train_time_s\": 10.653048276901245}", "{\"n\": 4610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.14, \"learn_time_ms\": 8663.037, \"total_train_time_s\": 8.832003355026245}", "{\"n\": 4611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.65, \"learn_time_ms\": 8767.242, \"total_train_time_s\": 11.310194253921509}", "{\"n\": 4612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.65, \"learn_time_ms\": 8852.22, \"total_train_time_s\": 10.62981629371643}", "{\"n\": 4613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.77, \"learn_time_ms\": 8914.183, \"total_train_time_s\": 10.54672884941101}", "{\"n\": 4614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.77, \"learn_time_ms\": 8878.32, \"total_train_time_s\": 10.159096717834473}", "{\"n\": 4615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.69, \"learn_time_ms\": 8873.995, \"total_train_time_s\": 9.833344221115112}", "{\"n\": 4616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.86, \"learn_time_ms\": 8824.951, \"total_train_time_s\": 9.00771427154541}", "{\"n\": 4617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.4, \"learn_time_ms\": 8620.999, \"total_train_time_s\": 9.459493398666382}", "{\"n\": 4618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.44, \"learn_time_ms\": 8579.312, \"total_train_time_s\": 9.602713346481323}", "{\"n\": 4619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.44, \"learn_time_ms\": 8538.569, \"total_train_time_s\": 10.19902515411377}", "{\"n\": 4620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.7, \"learn_time_ms\": 8657.052, \"total_train_time_s\": 10.006385087966919}", "{\"n\": 4621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.71, \"learn_time_ms\": 8394.78, \"total_train_time_s\": 8.673098087310791}", "{\"n\": 4622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.54, \"learn_time_ms\": 8157.693, \"total_train_time_s\": 8.25449538230896}", "{\"n\": 4623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.75, \"learn_time_ms\": 8259.935, \"total_train_time_s\": 11.552332401275635}", "{\"n\": 4624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.75, \"learn_time_ms\": 8207.782, \"total_train_time_s\": 9.622215270996094}", "{\"n\": 4625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.44, \"learn_time_ms\": 8383.142, \"total_train_time_s\": 11.63154149055481}", "{\"n\": 4626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.11, \"learn_time_ms\": 8521.032, \"total_train_time_s\": 10.43042516708374}", "{\"n\": 4627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.11, \"learn_time_ms\": 8548.181, \"total_train_time_s\": 9.68671703338623}", "{\"n\": 4628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.66, \"learn_time_ms\": 8627.276, \"total_train_time_s\": 10.308864116668701}", "{\"n\": 4629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.7, \"learn_time_ms\": 8618.794, \"total_train_time_s\": 10.173008680343628}", "{\"n\": 4630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.7, \"learn_time_ms\": 8612.797, \"total_train_time_s\": 9.953496217727661}", "{\"n\": 4631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.87, \"learn_time_ms\": 8616.711, \"total_train_time_s\": 8.75645112991333}", "{\"n\": 4632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.65, \"learn_time_ms\": 8883.997, \"total_train_time_s\": 10.96150541305542}", "{\"n\": 4633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.65, \"learn_time_ms\": 8732.384, \"total_train_time_s\": 10.086422443389893}", "{\"n\": 4634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.73, \"learn_time_ms\": 8800.557, \"total_train_time_s\": 10.335644721984863}", "{\"n\": 4635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.07, \"learn_time_ms\": 8671.058, \"total_train_time_s\": 10.338085412979126}", "{\"n\": 4636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.05, \"learn_time_ms\": 8583.145, \"total_train_time_s\": 9.547232627868652}", "{\"n\": 4637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.05, \"learn_time_ms\": 8637.246, \"total_train_time_s\": 10.242426633834839}", "{\"n\": 4638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.15, \"learn_time_ms\": 8393.63, \"total_train_time_s\": 7.924135446548462}", "{\"n\": 4639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.83, \"learn_time_ms\": 8511.668, \"total_train_time_s\": 11.32786226272583}", "{\"n\": 4640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.83, \"learn_time_ms\": 8485.051, \"total_train_time_s\": 9.656788110733032}", "{\"n\": 4641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.04, \"learn_time_ms\": 8653.835, \"total_train_time_s\": 10.45959997177124}", "{\"n\": 4642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.78, \"learn_time_ms\": 8507.14, \"total_train_time_s\": 9.465267181396484}", "{\"n\": 4643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.55, \"learn_time_ms\": 8504.247, \"total_train_time_s\": 10.052422285079956}", "{\"n\": 4644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.92, \"learn_time_ms\": 8494.539, \"total_train_time_s\": 10.245310544967651}", "{\"n\": 4645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.92, \"learn_time_ms\": 8494.676, \"total_train_time_s\": 10.30610179901123}", "{\"n\": 4646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.47, \"learn_time_ms\": 8681.929, \"total_train_time_s\": 11.46206283569336}", "{\"n\": 4647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.47, \"learn_time_ms\": 8781.887, \"total_train_time_s\": 11.24363112449646}", "{\"n\": 4648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.42, \"learn_time_ms\": 9033.833, \"total_train_time_s\": 10.379719495773315}", "{\"n\": 4649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.24, \"learn_time_ms\": 8911.335, \"total_train_time_s\": 10.093462944030762}", "{\"n\": 4650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.24, \"learn_time_ms\": 9030.646, \"total_train_time_s\": 10.895418643951416}", "{\"n\": 4651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.09, \"learn_time_ms\": 9065.752, \"total_train_time_s\": 10.767959833145142}", "{\"n\": 4652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.29, \"learn_time_ms\": 9145.084, \"total_train_time_s\": 10.25321340560913}", "{\"n\": 4653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.29, \"learn_time_ms\": 9113.868, \"total_train_time_s\": 9.730961084365845}", "{\"n\": 4654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.34, \"learn_time_ms\": 9084.244, \"total_train_time_s\": 9.89497685432434}", "{\"n\": 4655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.56, \"learn_time_ms\": 8991.024, \"total_train_time_s\": 9.403889417648315}", "{\"n\": 4656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.36, \"learn_time_ms\": 9070.066, \"total_train_time_s\": 12.268655776977539}", "{\"n\": 4657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.54, \"learn_time_ms\": 9035.568, \"total_train_time_s\": 10.872934818267822}", "{\"n\": 4658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.68, \"learn_time_ms\": 9019.248, \"total_train_time_s\": 10.229981899261475}", "{\"n\": 4659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.59, \"learn_time_ms\": 8938.957, \"total_train_time_s\": 9.302272081375122}", "{\"n\": 4660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.59, \"learn_time_ms\": 8928.063, \"total_train_time_s\": 10.804860353469849}", "{\"n\": 4661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.09, \"learn_time_ms\": 9003.771, \"total_train_time_s\": 11.543641328811646}", "{\"n\": 4662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.58, \"learn_time_ms\": 9018.999, \"total_train_time_s\": 10.439816236495972}", "{\"n\": 4663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.06, \"learn_time_ms\": 9090.219, \"total_train_time_s\": 10.455407857894897}", "{\"n\": 4664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.4, \"learn_time_ms\": 9191.354, \"total_train_time_s\": 10.980241060256958}", "{\"n\": 4665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.46, \"learn_time_ms\": 9208.893, \"total_train_time_s\": 9.529160976409912}", "{\"n\": 4666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.45, \"learn_time_ms\": 8965.918, \"total_train_time_s\": 9.785248279571533}", "{\"n\": 4667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.45, \"learn_time_ms\": 8993.015, \"total_train_time_s\": 11.18816351890564}", "{\"n\": 4668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.07, \"learn_time_ms\": 9070.039, \"total_train_time_s\": 11.017050981521606}", "{\"n\": 4669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.74, \"learn_time_ms\": 9167.665, \"total_train_time_s\": 10.282942056655884}", "{\"n\": 4670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.63, \"learn_time_ms\": 9141.721, \"total_train_time_s\": 10.512826919555664}", "{\"n\": 4671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.39, \"learn_time_ms\": 9081.194, \"total_train_time_s\": 10.9326651096344}", "{\"n\": 4672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.94, \"learn_time_ms\": 9105.149, \"total_train_time_s\": 10.72037386894226}", "{\"n\": 4673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.94, \"learn_time_ms\": 9119.41, \"total_train_time_s\": 10.616818189620972}", "{\"n\": 4674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.96, \"learn_time_ms\": 9145.83, \"total_train_time_s\": 11.210373401641846}", "{\"n\": 4675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.89, \"learn_time_ms\": 9098.383, \"total_train_time_s\": 9.076338052749634}", "{\"n\": 4676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.89, \"learn_time_ms\": 9192.148, \"total_train_time_s\": 10.694082260131836}", "{\"n\": 4677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.08, \"learn_time_ms\": 9053.392, \"total_train_time_s\": 9.781455993652344}", "{\"n\": 4678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.92, \"learn_time_ms\": 9041.879, \"total_train_time_s\": 10.903476476669312}", "{\"n\": 4679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.92, \"learn_time_ms\": 9159.477, \"total_train_time_s\": 11.434794902801514}", "{\"n\": 4680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.64, \"learn_time_ms\": 9222.252, \"total_train_time_s\": 11.155159950256348}", "{\"n\": 4681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.97, \"learn_time_ms\": 9192.185, \"total_train_time_s\": 10.625057458877563}", "{\"n\": 4682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.97, \"learn_time_ms\": 8968.312, \"total_train_time_s\": 8.398131847381592}", "{\"n\": 4683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.97, \"learn_time_ms\": 8971.681, \"total_train_time_s\": 10.615238428115845}", "{\"n\": 4684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.33, \"learn_time_ms\": 8854.113, \"total_train_time_s\": 10.018318891525269}", "{\"n\": 4685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.31, \"learn_time_ms\": 8867.375, \"total_train_time_s\": 9.226310729980469}", "{\"n\": 4686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.31, \"learn_time_ms\": 8840.761, \"total_train_time_s\": 10.428671836853027}", "{\"n\": 4687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.31, \"learn_time_ms\": 8818.31, \"total_train_time_s\": 9.577529430389404}", "{\"n\": 4688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 8686.967, \"total_train_time_s\": 9.583110332489014}", "{\"n\": 4689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 8477.49, \"total_train_time_s\": 9.347779035568237}", "{\"n\": 4690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.28, \"learn_time_ms\": 8308.225, \"total_train_time_s\": 9.425947904586792}", "{\"n\": 4691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.86, \"learn_time_ms\": 8201.16, \"total_train_time_s\": 9.537450075149536}", "{\"n\": 4692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.44, \"learn_time_ms\": 8491.039, \"total_train_time_s\": 11.290162086486816}", "{\"n\": 4693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.44, \"learn_time_ms\": 8496.138, \"total_train_time_s\": 10.635478973388672}", "{\"n\": 4694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.37, \"learn_time_ms\": 8376.477, \"total_train_time_s\": 8.876745462417603}", "{\"n\": 4695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.38, \"learn_time_ms\": 8542.572, \"total_train_time_s\": 10.931600570678711}", "{\"n\": 4696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.13, \"learn_time_ms\": 8525.134, \"total_train_time_s\": 10.264715433120728}", "{\"n\": 4697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.22, \"learn_time_ms\": 8538.283, \"total_train_time_s\": 9.69981575012207}", "{\"n\": 4698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.58, \"learn_time_ms\": 8518.787, \"total_train_time_s\": 9.416263818740845}", "{\"n\": 4699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.35, \"learn_time_ms\": 8638.2, \"total_train_time_s\": 10.561274528503418}", "{\"n\": 4700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.33, \"learn_time_ms\": 8678.465, \"total_train_time_s\": 9.841363906860352}", "{\"n\": 4701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.58, \"learn_time_ms\": 8968.079, \"total_train_time_s\": 12.427273273468018}", "{\"n\": 4702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3300.32, \"learn_time_ms\": 8757.083, \"total_train_time_s\": 9.250689029693604}", "{\"n\": 4703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.04, \"learn_time_ms\": 8700.701, \"total_train_time_s\": 10.14111614227295}", "{\"n\": 4704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.21, \"learn_time_ms\": 8852.065, \"total_train_time_s\": 10.38229775428772}", "{\"n\": 4705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.61, \"learn_time_ms\": 8892.148, \"total_train_time_s\": 11.310359001159668}", "{\"n\": 4706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.54, \"learn_time_ms\": 8809.542, \"total_train_time_s\": 9.51253890991211}", "{\"n\": 4707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.76, \"learn_time_ms\": 8832.89, \"total_train_time_s\": 9.967499017715454}", "{\"n\": 4708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.11, \"learn_time_ms\": 9009.068, \"total_train_time_s\": 11.129382848739624}", "{\"n\": 4709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.15, \"learn_time_ms\": 9053.939, \"total_train_time_s\": 11.003718376159668}", "{\"n\": 4710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.15, \"learn_time_ms\": 9175.2, \"total_train_time_s\": 11.051809787750244}", "{\"n\": 4711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.42, \"learn_time_ms\": 8991.566, \"total_train_time_s\": 10.606355667114258}", "{\"n\": 4712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.4, \"learn_time_ms\": 9130.981, \"total_train_time_s\": 10.615402221679688}", "{\"n\": 4713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.92, \"learn_time_ms\": 9147.324, \"total_train_time_s\": 10.304206848144531}", "{\"n\": 4714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.61, \"learn_time_ms\": 9165.32, \"total_train_time_s\": 10.489903688430786}", "{\"n\": 4715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.38, \"learn_time_ms\": 9072.065, \"total_train_time_s\": 10.320126056671143}", "{\"n\": 4716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.37, \"learn_time_ms\": 9156.049, \"total_train_time_s\": 10.298545598983765}", "{\"n\": 4717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.47, \"learn_time_ms\": 9129.264, \"total_train_time_s\": 9.646140575408936}", "{\"n\": 4718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.47, \"learn_time_ms\": 9117.985, \"total_train_time_s\": 11.045449495315552}", "{\"n\": 4719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.68, \"learn_time_ms\": 9024.699, \"total_train_time_s\": 10.038665533065796}", "{\"n\": 4720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.71, \"learn_time_ms\": 9008.284, \"total_train_time_s\": 10.916713237762451}", "{\"n\": 4721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.71, \"learn_time_ms\": 8809.711, \"total_train_time_s\": 8.588327407836914}", "{\"n\": 4722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.53, \"learn_time_ms\": 8776.212, \"total_train_time_s\": 10.301073551177979}", "{\"n\": 4723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.49, \"learn_time_ms\": 8877.638, \"total_train_time_s\": 11.327490329742432}", "{\"n\": 4724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.49, \"learn_time_ms\": 8743.973, \"total_train_time_s\": 9.193349361419678}", "{\"n\": 4725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.3, \"learn_time_ms\": 8719.204, \"total_train_time_s\": 10.10079312324524}", "{\"n\": 4726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.23, \"learn_time_ms\": 8705.532, \"total_train_time_s\": 10.165190696716309}", "{\"n\": 4727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.23, \"learn_time_ms\": 8737.799, \"total_train_time_s\": 9.959835052490234}", "{\"n\": 4728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.88, \"learn_time_ms\": 8758.556, \"total_train_time_s\": 11.217668771743774}", "{\"n\": 4729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.71, \"learn_time_ms\": 8620.782, \"total_train_time_s\": 8.658993482589722}", "{\"n\": 4730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.71, \"learn_time_ms\": 8485.786, \"total_train_time_s\": 9.575721263885498}", "{\"n\": 4731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.41, \"learn_time_ms\": 8729.905, \"total_train_time_s\": 11.071547508239746}", "{\"n\": 4732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.45, \"learn_time_ms\": 8710.407, \"total_train_time_s\": 10.068319320678711}", "{\"n\": 4733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.45, \"learn_time_ms\": 8576.175, \"total_train_time_s\": 9.882084846496582}", "{\"n\": 4734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.32, \"learn_time_ms\": 8720.878, \"total_train_time_s\": 10.672932386398315}", "{\"n\": 4735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.64, \"learn_time_ms\": 8712.424, \"total_train_time_s\": 10.122278213500977}", "{\"n\": 4736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.92, \"learn_time_ms\": 8640.256, \"total_train_time_s\": 9.445450782775879}", "{\"n\": 4737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.4, \"learn_time_ms\": 8808.733, \"total_train_time_s\": 11.644469976425171}", "{\"n\": 4738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.81, \"learn_time_ms\": 8530.805, \"total_train_time_s\": 8.446025609970093}", "{\"n\": 4739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.73, \"learn_time_ms\": 8731.652, \"total_train_time_s\": 10.710644960403442}", "{\"n\": 4740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.3, \"learn_time_ms\": 8806.344, \"total_train_time_s\": 10.294728517532349}", "{\"n\": 4741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.3, \"learn_time_ms\": 8663.379, \"total_train_time_s\": 9.638469457626343}", "{\"n\": 4742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.84, \"learn_time_ms\": 8517.622, \"total_train_time_s\": 8.656307458877563}", "{\"n\": 4743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.58, \"learn_time_ms\": 8575.315, \"total_train_time_s\": 10.526429891586304}", "{\"n\": 4744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3255.58, \"learn_time_ms\": 8473.393, \"total_train_time_s\": 9.573513984680176}", "{\"n\": 4745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.14, \"learn_time_ms\": 8395.35, \"total_train_time_s\": 9.212029457092285}", "{\"n\": 4746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.53, \"learn_time_ms\": 8506.479, \"total_train_time_s\": 10.59022045135498}", "{\"n\": 4747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.51, \"learn_time_ms\": 8309.569, \"total_train_time_s\": 9.706313371658325}", "{\"n\": 4748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.74, \"learn_time_ms\": 8503.355, \"total_train_time_s\": 10.429962873458862}", "{\"n\": 4749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.55, \"learn_time_ms\": 8426.561, \"total_train_time_s\": 9.95506739616394}", "{\"n\": 4750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.18, \"learn_time_ms\": 8416.218, \"total_train_time_s\": 10.218794584274292}", "{\"n\": 4751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.18, \"learn_time_ms\": 8641.128, \"total_train_time_s\": 11.880470275878906}", "{\"n\": 4752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.07, \"learn_time_ms\": 8906.509, \"total_train_time_s\": 11.282892942428589}", "{\"n\": 4753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.13, \"learn_time_ms\": 8853.365, \"total_train_time_s\": 9.95467472076416}", "{\"n\": 4754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.13, \"learn_time_ms\": 8733.316, \"total_train_time_s\": 8.400564193725586}", "{\"n\": 4755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.38, \"learn_time_ms\": 8873.647, \"total_train_time_s\": 10.615921974182129}", "{\"n\": 4756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.38, \"learn_time_ms\": 8933.612, \"total_train_time_s\": 11.161792993545532}", "{\"n\": 4757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.9, \"learn_time_ms\": 8991.328, \"total_train_time_s\": 10.251938581466675}", "{\"n\": 4758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.17, \"learn_time_ms\": 8981.052, \"total_train_time_s\": 10.325057983398438}", "{\"n\": 4759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.07, \"learn_time_ms\": 8965.437, \"total_train_time_s\": 9.774194478988647}", "{\"n\": 4760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.27, \"learn_time_ms\": 9073.45, \"total_train_time_s\": 11.26609992980957}", "{\"n\": 4761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.96, \"learn_time_ms\": 8929.105, \"total_train_time_s\": 10.476697206497192}", "{\"n\": 4762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.52, \"learn_time_ms\": 8762.968, \"total_train_time_s\": 9.623875856399536}", "{\"n\": 4763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3267.07, \"learn_time_ms\": 8856.35, \"total_train_time_s\": 10.903682231903076}", "{\"n\": 4764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.72, \"learn_time_ms\": 8981.227, \"total_train_time_s\": 9.655935525894165}", "{\"n\": 4765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.93, \"learn_time_ms\": 9010.283, \"total_train_time_s\": 10.93463921546936}", "{\"n\": 4766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.93, \"learn_time_ms\": 9093.345, \"total_train_time_s\": 11.989285469055176}", "{\"n\": 4767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.36, \"learn_time_ms\": 8991.29, \"total_train_time_s\": 9.273097038269043}", "{\"n\": 4768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.72, \"learn_time_ms\": 9070.556, \"total_train_time_s\": 11.076676845550537}", "{\"n\": 4769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.63, \"learn_time_ms\": 9124.593, \"total_train_time_s\": 10.336698293685913}", "{\"n\": 4770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.63, \"learn_time_ms\": 9007.577, \"total_train_time_s\": 10.102357387542725}", "{\"n\": 4771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.33, \"learn_time_ms\": 9007.144, \"total_train_time_s\": 10.418399333953857}", "{\"n\": 4772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.06, \"learn_time_ms\": 8967.938, \"total_train_time_s\": 9.227282285690308}", "{\"n\": 4773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.06, \"learn_time_ms\": 9079.09, \"total_train_time_s\": 12.007498502731323}", "{\"n\": 4774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 9120.881, \"total_train_time_s\": 10.082839488983154}", "{\"n\": 4775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.56, \"learn_time_ms\": 9049.012, \"total_train_time_s\": 10.269717693328857}", "{\"n\": 4776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.56, \"learn_time_ms\": 8885.984, \"total_train_time_s\": 10.34843897819519}", "{\"n\": 4777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.83, \"learn_time_ms\": 8891.301, \"total_train_time_s\": 9.307886123657227}", "{\"n\": 4778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.78, \"learn_time_ms\": 8739.552, \"total_train_time_s\": 9.539517879486084}", "{\"n\": 4779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.78, \"learn_time_ms\": 8699.851, \"total_train_time_s\": 9.928649663925171}", "{\"n\": 4780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.98, \"learn_time_ms\": 8675.714, \"total_train_time_s\": 9.861830949783325}", "{\"n\": 4781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.01, \"learn_time_ms\": 8708.792, \"total_train_time_s\": 10.737051248550415}", "{\"n\": 4782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.01, \"learn_time_ms\": 8842.817, \"total_train_time_s\": 10.563664674758911}", "{\"n\": 4783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.48, \"learn_time_ms\": 8818.826, \"total_train_time_s\": 11.799853563308716}", "{\"n\": 4784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.18, \"learn_time_ms\": 8811.889, \"total_train_time_s\": 10.003535985946655}", "{\"n\": 4785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.18, \"learn_time_ms\": 8896.927, \"total_train_time_s\": 11.073760509490967}", "{\"n\": 4786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3200.04, \"learn_time_ms\": 8871.296, \"total_train_time_s\": 10.104722023010254}", "{\"n\": 4787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.31, \"learn_time_ms\": 9043.75, \"total_train_time_s\": 11.06886100769043}", "{\"n\": 4788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.0, \"learn_time_ms\": 9107.548, \"total_train_time_s\": 10.177128553390503}", "{\"n\": 4789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.0, \"learn_time_ms\": 9183.025, \"total_train_time_s\": 10.665974140167236}", "{\"n\": 4790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.75, \"learn_time_ms\": 9238.26, \"total_train_time_s\": 10.38045048713684}", "{\"n\": 4791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.03, \"learn_time_ms\": 9155.517, \"total_train_time_s\": 9.957984685897827}", "{\"n\": 4792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.03, \"learn_time_ms\": 9206.77, \"total_train_time_s\": 11.045904874801636}", "{\"n\": 4793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.71, \"learn_time_ms\": 9102.772, \"total_train_time_s\": 10.759028434753418}", "{\"n\": 4794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.99, \"learn_time_ms\": 9128.405, \"total_train_time_s\": 10.250426292419434}", "{\"n\": 4795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.99, \"learn_time_ms\": 8897.531, \"total_train_time_s\": 8.764566421508789}", "{\"n\": 4796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.99, \"learn_time_ms\": 8974.347, \"total_train_time_s\": 10.845442056655884}", "{\"n\": 4797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.59, \"learn_time_ms\": 8899.973, \"total_train_time_s\": 10.255674123764038}", "{\"n\": 4798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.39, \"learn_time_ms\": 8959.11, \"total_train_time_s\": 10.7998948097229}", "{\"n\": 4799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.39, \"learn_time_ms\": 8949.833, \"total_train_time_s\": 10.571518182754517}", "{\"n\": 4800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.52, \"learn_time_ms\": 9015.502, \"total_train_time_s\": 11.088073968887329}", "{\"n\": 4801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.16, \"learn_time_ms\": 8799.473, \"total_train_time_s\": 7.754680871963501}", "{\"n\": 4802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.16, \"learn_time_ms\": 8688.188, \"total_train_time_s\": 10.053547859191895}", "{\"n\": 4803, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.58, \"learn_time_ms\": 8531.73, \"total_train_time_s\": 9.214629173278809}", "{\"n\": 4804, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.9, \"learn_time_ms\": 8507.19, \"total_train_time_s\": 10.010530471801758}", "{\"n\": 4805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.9, \"learn_time_ms\": 8571.832, \"total_train_time_s\": 9.422893762588501}", "{\"n\": 4806, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.86, \"learn_time_ms\": 8518.261, \"total_train_time_s\": 10.381980419158936}", "{\"n\": 4807, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.44, \"learn_time_ms\": 8587.573, \"total_train_time_s\": 10.966354846954346}", "{\"n\": 4808, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.83, \"learn_time_ms\": 8382.452, \"total_train_time_s\": 8.72743558883667}", "{\"n\": 4809, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.41, \"learn_time_ms\": 8336.95, \"total_train_time_s\": 10.122114896774292}", "{\"n\": 4810, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.68, \"learn_time_ms\": 8243.849, \"total_train_time_s\": 10.124002933502197}", "{\"n\": 4811, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.37, \"learn_time_ms\": 8613.237, \"total_train_time_s\": 11.432070970535278}", "{\"n\": 4812, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.87, \"learn_time_ms\": 8566.405, \"total_train_time_s\": 9.499266147613525}", "{\"n\": 4813, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.47, \"learn_time_ms\": 8832.16, \"total_train_time_s\": 11.828192710876465}", "{\"n\": 4814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.47, \"learn_time_ms\": 8802.157, \"total_train_time_s\": 9.709413528442383}", "{\"n\": 4815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.31, \"learn_time_ms\": 8858.729, \"total_train_time_s\": 9.967697858810425}", "{\"n\": 4816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.92, \"learn_time_ms\": 8816.905, \"total_train_time_s\": 9.880745887756348}", "{\"n\": 4817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.5, \"learn_time_ms\": 8705.463, \"total_train_time_s\": 9.882502794265747}", "{\"n\": 4818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.5, \"learn_time_ms\": 8872.332, \"total_train_time_s\": 10.406702995300293}", "{\"n\": 4819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.32, \"learn_time_ms\": 8932.465, \"total_train_time_s\": 10.713318109512329}", "{\"n\": 4820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.32, \"learn_time_ms\": 9025.169, \"total_train_time_s\": 11.036415100097656}", "{\"n\": 4821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.19, \"learn_time_ms\": 8833.133, \"total_train_time_s\": 9.5212984085083}", "{\"n\": 4822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.71, \"learn_time_ms\": 8958.857, \"total_train_time_s\": 10.827997207641602}", "{\"n\": 4823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.71, \"learn_time_ms\": 8772.418, \"total_train_time_s\": 9.982064962387085}", "{\"n\": 4824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.46, \"learn_time_ms\": 8690.341, \"total_train_time_s\": 8.870054006576538}", "{\"n\": 4825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.89, \"learn_time_ms\": 8732.397, \"total_train_time_s\": 10.350036144256592}", "{\"n\": 4826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.89, \"learn_time_ms\": 8878.893, \"total_train_time_s\": 11.381294250488281}", "{\"n\": 4827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.02, \"learn_time_ms\": 9135.391, \"total_train_time_s\": 12.418144226074219}", "{\"n\": 4828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.02, \"learn_time_ms\": 9145.531, \"total_train_time_s\": 10.533753633499146}", "{\"n\": 4829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.91, \"learn_time_ms\": 9105.26, \"total_train_time_s\": 10.332967042922974}", "{\"n\": 4830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.43, \"learn_time_ms\": 8976.233, \"total_train_time_s\": 9.753152847290039}", "{\"n\": 4831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.64, \"learn_time_ms\": 8930.961, \"total_train_time_s\": 9.120079278945923}", "{\"n\": 4832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.79, \"learn_time_ms\": 8879.524, \"total_train_time_s\": 10.211291313171387}", "{\"n\": 4833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.79, \"learn_time_ms\": 8815.131, \"total_train_time_s\": 9.334249258041382}", "{\"n\": 4834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.78, \"learn_time_ms\": 8993.634, \"total_train_time_s\": 10.68903374671936}", "{\"n\": 4835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.81, \"learn_time_ms\": 9038.496, \"total_train_time_s\": 10.865397214889526}", "{\"n\": 4836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.45, \"learn_time_ms\": 8946.767, \"total_train_time_s\": 10.436894655227661}", "{\"n\": 4837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.95, \"learn_time_ms\": 8803.929, \"total_train_time_s\": 11.009909629821777}", "{\"n\": 4838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.61, \"learn_time_ms\": 8726.096, \"total_train_time_s\": 9.759275436401367}", "{\"n\": 4839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.27, \"learn_time_ms\": 8881.239, \"total_train_time_s\": 11.851888656616211}", "{\"n\": 4840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.75, \"learn_time_ms\": 8913.651, \"total_train_time_s\": 10.049396514892578}", "{\"n\": 4841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.34, \"learn_time_ms\": 8840.054, \"total_train_time_s\": 8.351308107376099}", "{\"n\": 4842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.14, \"learn_time_ms\": 8872.03, \"total_train_time_s\": 10.556188106536865}", "{\"n\": 4843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.92, \"learn_time_ms\": 8928.755, \"total_train_time_s\": 9.858699798583984}", "{\"n\": 4844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.54, \"learn_time_ms\": 8996.956, \"total_train_time_s\": 11.366024732589722}", "{\"n\": 4845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.09, \"learn_time_ms\": 8915.011, \"total_train_time_s\": 10.021440505981445}", "{\"n\": 4846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.79, \"learn_time_ms\": 8899.305, \"total_train_time_s\": 10.27570629119873}", "{\"n\": 4847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.23, \"learn_time_ms\": 8794.15, \"total_train_time_s\": 9.940592050552368}", "{\"n\": 4848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.46, \"learn_time_ms\": 8881.339, \"total_train_time_s\": 10.656181573867798}", "{\"n\": 4849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.29, \"learn_time_ms\": 8722.317, \"total_train_time_s\": 10.319710493087769}", "{\"n\": 4850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.37, \"learn_time_ms\": 8817.122, \"total_train_time_s\": 11.043044090270996}", "{\"n\": 4851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.85, \"learn_time_ms\": 8984.771, \"total_train_time_s\": 10.05508303642273}", "{\"n\": 4852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.1, \"learn_time_ms\": 8991.736, \"total_train_time_s\": 10.60196566581726}", "{\"n\": 4853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3172.13, \"learn_time_ms\": 9026.459, \"total_train_time_s\": 10.217858076095581}", "{\"n\": 4854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.69, \"learn_time_ms\": 8916.417, \"total_train_time_s\": 10.21748661994934}", "{\"n\": 4855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.94, \"learn_time_ms\": 8917.092, \"total_train_time_s\": 10.044466733932495}", "{\"n\": 4856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.94, \"learn_time_ms\": 8808.933, \"total_train_time_s\": 9.199084758758545}", "{\"n\": 4857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.05, \"learn_time_ms\": 8741.792, \"total_train_time_s\": 9.23733901977539}", "{\"n\": 4858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.11, \"learn_time_ms\": 8568.528, \"total_train_time_s\": 8.872846841812134}", "{\"n\": 4859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.11, \"learn_time_ms\": 8560.278, \"total_train_time_s\": 10.208422183990479}", "{\"n\": 4860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.23, \"learn_time_ms\": 8430.174, \"total_train_time_s\": 9.739599227905273}", "{\"n\": 4861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.35, \"learn_time_ms\": 8598.101, \"total_train_time_s\": 11.71477198600769}", "{\"n\": 4862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.35, \"learn_time_ms\": 8485.576, \"total_train_time_s\": 9.50986099243164}", "{\"n\": 4863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.13, \"learn_time_ms\": 8453.202, \"total_train_time_s\": 9.982161283493042}", "{\"n\": 4864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.27, \"learn_time_ms\": 8472.069, \"total_train_time_s\": 10.443001508712769}", "{\"n\": 4865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.27, \"learn_time_ms\": 8467.613, \"total_train_time_s\": 10.007628440856934}", "{\"n\": 4866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.11, \"learn_time_ms\": 8636.095, \"total_train_time_s\": 10.912015438079834}", "{\"n\": 4867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.99, \"learn_time_ms\": 8725.867, \"total_train_time_s\": 10.20989203453064}", "{\"n\": 4868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.99, \"learn_time_ms\": 8961.531, \"total_train_time_s\": 11.244024753570557}", "{\"n\": 4869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.45, \"learn_time_ms\": 8999.295, \"total_train_time_s\": 10.580262899398804}", "{\"n\": 4870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.2, \"learn_time_ms\": 9117.723, \"total_train_time_s\": 10.909068584442139}", "{\"n\": 4871, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3167.2, \"learn_time_ms\": 8974.633, \"total_train_time_s\": 10.26652979850769}", "{\"n\": 4872, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.24, \"learn_time_ms\": 9121.601, \"total_train_time_s\": 10.986464500427246}", "{\"n\": 4873, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.12, \"learn_time_ms\": 9144.945, \"total_train_time_s\": 10.173980236053467}", "{\"n\": 4874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.97, \"learn_time_ms\": 9206.386, \"total_train_time_s\": 11.04412579536438}", "{\"n\": 4875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.88, \"learn_time_ms\": 9084.706, \"total_train_time_s\": 8.759618759155273}", "{\"n\": 4876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.12, \"learn_time_ms\": 9029.964, \"total_train_time_s\": 10.387067079544067}", "{\"n\": 4877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.12, \"learn_time_ms\": 9015.096, \"total_train_time_s\": 10.050310373306274}", "{\"n\": 4878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.79, \"learn_time_ms\": 9019.385, \"total_train_time_s\": 11.324059009552002}", "{\"n\": 4879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3129.4, \"learn_time_ms\": 9017.41, \"total_train_time_s\": 10.597032070159912}", "{\"n\": 4880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3126.86, \"learn_time_ms\": 8967.793, \"total_train_time_s\": 10.426334619522095}", "{\"n\": 4881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3124.09, \"learn_time_ms\": 8999.008, \"total_train_time_s\": 10.602567434310913}", "{\"n\": 4882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.35, \"learn_time_ms\": 8881.39, \"total_train_time_s\": 9.806584596633911}", "{\"n\": 4883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3125.27, \"learn_time_ms\": 9089.314, \"total_train_time_s\": 12.218573808670044}", "{\"n\": 4884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3125.27, \"learn_time_ms\": 9048.646, \"total_train_time_s\": 10.656373023986816}", "{\"n\": 4885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.91, \"learn_time_ms\": 9084.198, \"total_train_time_s\": 9.14886212348938}", "{\"n\": 4886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.34, \"learn_time_ms\": 9097.1, \"total_train_time_s\": 10.52846884727478}", "{\"n\": 4887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.34, \"learn_time_ms\": 9143.848, \"total_train_time_s\": 10.511926651000977}", "{\"n\": 4888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.07, \"learn_time_ms\": 9204.101, \"total_train_time_s\": 11.89471697807312}", "{\"n\": 4889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.64, \"learn_time_ms\": 9213.867, \"total_train_time_s\": 10.661634683609009}", "{\"n\": 4890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.25, \"learn_time_ms\": 9263.664, \"total_train_time_s\": 10.92336392402649}", "{\"n\": 4891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.41, \"learn_time_ms\": 9307.894, \"total_train_time_s\": 11.059574842453003}", "{\"n\": 4892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.62, \"learn_time_ms\": 9490.134, \"total_train_time_s\": 11.620920419692993}", "{\"n\": 4893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.72, \"learn_time_ms\": 9209.26, \"total_train_time_s\": 9.421588659286499}", "{\"n\": 4894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.92, \"learn_time_ms\": 9135.008, \"total_train_time_s\": 9.91235899925232}", "{\"n\": 4895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.77, \"learn_time_ms\": 9279.475, \"total_train_time_s\": 10.61392092704773}", "{\"n\": 4896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3126.77, \"learn_time_ms\": 9300.821, \"total_train_time_s\": 10.680314779281616}", "{\"n\": 4897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.28, \"learn_time_ms\": 9216.337, \"total_train_time_s\": 9.665403842926025}", "{\"n\": 4898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.42, \"learn_time_ms\": 9041.102, \"total_train_time_s\": 10.155242681503296}", "{\"n\": 4899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.58, \"learn_time_ms\": 9044.149, \"total_train_time_s\": 10.684889793395996}", "{\"n\": 4900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.24, \"learn_time_ms\": 8951.152, \"total_train_time_s\": 10.031279802322388}", "{\"n\": 4901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.08, \"learn_time_ms\": 8988.505, \"total_train_time_s\": 11.474230527877808}", "{\"n\": 4902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.78, \"learn_time_ms\": 8879.99, \"total_train_time_s\": 10.509043455123901}", "{\"n\": 4903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.08, \"learn_time_ms\": 8890.623, \"total_train_time_s\": 9.499539613723755}", "{\"n\": 4904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.15, \"learn_time_ms\": 8816.958, \"total_train_time_s\": 9.170304536819458}", "{\"n\": 4905, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3161.12, \"learn_time_ms\": 8686.682, \"total_train_time_s\": 9.240128755569458}", "{\"n\": 4906, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.94, \"learn_time_ms\": 8577.224, \"total_train_time_s\": 9.58780026435852}", "{\"n\": 4907, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.27, \"learn_time_ms\": 8637.006, \"total_train_time_s\": 10.223512411117554}", "{\"n\": 4908, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.63, \"learn_time_ms\": 8674.318, \"total_train_time_s\": 10.504307985305786}", "{\"n\": 4909, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.21, \"learn_time_ms\": 8592.428, \"total_train_time_s\": 9.877574682235718}", "{\"n\": 4910, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.39, \"learn_time_ms\": 8496.342, \"total_train_time_s\": 9.032691955566406}", "{\"n\": 4911, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.39, \"learn_time_ms\": 8438.817, \"total_train_time_s\": 10.79699993133545}", "{\"n\": 4912, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.91, \"learn_time_ms\": 8500.316, \"total_train_time_s\": 11.163284063339233}", "{\"n\": 4913, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.57, \"learn_time_ms\": 8544.025, \"total_train_time_s\": 9.978053092956543}", "{\"n\": 4914, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.54, \"learn_time_ms\": 8585.344, \"total_train_time_s\": 9.607619524002075}", "{\"n\": 4915, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.38, \"learn_time_ms\": 8666.627, \"total_train_time_s\": 10.063478469848633}", "{\"n\": 4916, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.38, \"learn_time_ms\": 8734.482, \"total_train_time_s\": 10.288716554641724}", "{\"n\": 4917, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.55, \"learn_time_ms\": 8854.084, \"total_train_time_s\": 11.433264255523682}", "{\"n\": 4918, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.7, \"learn_time_ms\": 8869.683, \"total_train_time_s\": 10.613422393798828}", "{\"n\": 4919, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.7, \"learn_time_ms\": 8865.26, \"total_train_time_s\": 9.817737579345703}", "{\"n\": 4920, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.12, \"learn_time_ms\": 9068.458, \"total_train_time_s\": 11.072828531265259}", "{\"n\": 4921, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.56, \"learn_time_ms\": 8818.991, \"total_train_time_s\": 8.355703353881836}", "{\"n\": 4922, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.75, \"learn_time_ms\": 8788.775, \"total_train_time_s\": 10.82379698753357}", "{\"n\": 4923, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.99, \"learn_time_ms\": 8760.118, \"total_train_time_s\": 9.698466300964355}", "{\"n\": 4924, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.99, \"learn_time_ms\": 8804.0, \"total_train_time_s\": 10.023876190185547}", "{\"n\": 4925, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.2, \"learn_time_ms\": 8728.067, \"total_train_time_s\": 9.296475172042847}", "{\"n\": 4926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.75, \"learn_time_ms\": 8643.221, \"total_train_time_s\": 9.446418762207031}", "{\"n\": 4927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.75, \"learn_time_ms\": 8462.657, \"total_train_time_s\": 9.629478454589844}", "{\"n\": 4928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.66, \"learn_time_ms\": 8432.62, \"total_train_time_s\": 10.404451608657837}", "{\"n\": 4929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.19, \"learn_time_ms\": 8493.207, \"total_train_time_s\": 10.419817924499512}", "{\"n\": 4930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.19, \"learn_time_ms\": 8316.142, \"total_train_time_s\": 9.292017936706543}", "{\"n\": 4931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.75, \"learn_time_ms\": 8580.065, \"total_train_time_s\": 10.989630460739136}", "{\"n\": 4932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.98, \"learn_time_ms\": 8541.442, \"total_train_time_s\": 10.473406791687012}", "{\"n\": 4933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.98, \"learn_time_ms\": 8764.462, \"total_train_time_s\": 11.890713214874268}", "{\"n\": 4934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.98, \"learn_time_ms\": 8637.514, \"total_train_time_s\": 8.728851318359375}", "{\"n\": 4935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.29, \"learn_time_ms\": 8666.384, \"total_train_time_s\": 9.585851907730103}", "{\"n\": 4936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.89, \"learn_time_ms\": 8739.095, \"total_train_time_s\": 10.151986837387085}", "{\"n\": 4937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.89, \"learn_time_ms\": 8786.372, \"total_train_time_s\": 10.13945984840393}", "{\"n\": 4938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.87, \"learn_time_ms\": 8716.633, \"total_train_time_s\": 9.682066440582275}", "{\"n\": 4939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.46, \"learn_time_ms\": 8762.755, \"total_train_time_s\": 10.918430805206299}", "{\"n\": 4940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.46, \"learn_time_ms\": 8903.458, \"total_train_time_s\": 10.67220950126648}", "{\"n\": 4941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.46, \"learn_time_ms\": 8869.266, \"total_train_time_s\": 10.625298738479614}", "{\"n\": 4942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.5, \"learn_time_ms\": 8777.068, \"total_train_time_s\": 9.564112186431885}", "{\"n\": 4943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3189.39, \"learn_time_ms\": 8553.647, \"total_train_time_s\": 9.67628264427185}", "{\"n\": 4944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.16, \"learn_time_ms\": 8873.613, \"total_train_time_s\": 11.979353904724121}", "{\"n\": 4945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.72, \"learn_time_ms\": 8953.972, \"total_train_time_s\": 10.422143936157227}", "{\"n\": 4946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.62, \"learn_time_ms\": 8967.187, \"total_train_time_s\": 10.264301776885986}", "{\"n\": 4947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.62, \"learn_time_ms\": 8996.259, \"total_train_time_s\": 10.386110544204712}", "{\"n\": 4948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.7, \"learn_time_ms\": 9062.157, \"total_train_time_s\": 10.35818600654602}", "{\"n\": 4949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.1, \"learn_time_ms\": 9102.886, \"total_train_time_s\": 11.289748668670654}", "{\"n\": 4950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.1, \"learn_time_ms\": 9020.875, \"total_train_time_s\": 9.887100458145142}", "{\"n\": 4951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.56, \"learn_time_ms\": 9036.244, \"total_train_time_s\": 10.791221380233765}", "{\"n\": 4952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.03, \"learn_time_ms\": 9318.816, \"total_train_time_s\": 12.33906602859497}", "{\"n\": 4953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.03, \"learn_time_ms\": 9419.505, \"total_train_time_s\": 10.649351358413696}", "{\"n\": 4954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.52, \"learn_time_ms\": 9240.928, \"total_train_time_s\": 10.193179845809937}", "{\"n\": 4955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.52, \"learn_time_ms\": 9161.917, \"total_train_time_s\": 9.626307010650635}", "{\"n\": 4956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.35, \"learn_time_ms\": 9134.683, \"total_train_time_s\": 9.989451885223389}", "{\"n\": 4957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.42, \"learn_time_ms\": 9064.624, \"total_train_time_s\": 9.70533299446106}", "{\"n\": 4958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.86, \"learn_time_ms\": 9116.664, \"total_train_time_s\": 10.867950439453125}", "{\"n\": 4959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.86, \"learn_time_ms\": 9125.69, \"total_train_time_s\": 11.428759574890137}", "{\"n\": 4960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.93, \"learn_time_ms\": 9121.093, \"total_train_time_s\": 9.870591640472412}", "{\"n\": 4961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.08, \"learn_time_ms\": 9132.812, \"total_train_time_s\": 10.940051555633545}", "{\"n\": 4962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.08, \"learn_time_ms\": 9048.329, \"total_train_time_s\": 11.500165939331055}", "{\"n\": 4963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.05, \"learn_time_ms\": 9143.58, \"total_train_time_s\": 11.649434804916382}", "{\"n\": 4964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.16, \"learn_time_ms\": 9182.028, \"total_train_time_s\": 10.574030637741089}", "{\"n\": 4965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.16, \"learn_time_ms\": 9317.729, \"total_train_time_s\": 11.00038743019104}", "{\"n\": 4966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.2, \"learn_time_ms\": 9446.432, \"total_train_time_s\": 11.293309926986694}", "{\"n\": 4967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.01, \"learn_time_ms\": 9580.054, \"total_train_time_s\": 11.052016496658325}", "{\"n\": 4968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.01, \"learn_time_ms\": 9382.709, \"total_train_time_s\": 8.838792085647583}", "{\"n\": 4969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.01, \"learn_time_ms\": 9347.632, \"total_train_time_s\": 11.014017581939697}", "{\"n\": 4970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.3, \"learn_time_ms\": 9375.497, \"total_train_time_s\": 10.107155323028564}", "{\"n\": 4971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.39, \"learn_time_ms\": 9466.629, \"total_train_time_s\": 11.812143802642822}", "{\"n\": 4972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.39, \"learn_time_ms\": 9253.599, \"total_train_time_s\": 9.404901266098022}", "{\"n\": 4973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.72, \"learn_time_ms\": 9121.804, \"total_train_time_s\": 10.283843517303467}", "{\"n\": 4974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.2, \"learn_time_ms\": 9158.052, \"total_train_time_s\": 10.980247735977173}", "{\"n\": 4975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.2, \"learn_time_ms\": 9156.799, \"total_train_time_s\": 10.996678352355957}", "{\"n\": 4976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.2, \"learn_time_ms\": 9153.008, \"total_train_time_s\": 11.304209470748901}", "{\"n\": 4977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.2, \"learn_time_ms\": 8990.388, \"total_train_time_s\": 9.424224138259888}", "{\"n\": 4978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.77, \"learn_time_ms\": 9045.58, \"total_train_time_s\": 9.439864873886108}", "{\"n\": 4979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.18, \"learn_time_ms\": 9094.613, \"total_train_time_s\": 11.520455598831177}", "{\"n\": 4980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.41, \"learn_time_ms\": 9216.032, \"total_train_time_s\": 11.320907592773438}", "{\"n\": 4981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.7, \"learn_time_ms\": 9140.897, \"total_train_time_s\": 11.082758665084839}", "{\"n\": 4982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.7, \"learn_time_ms\": 9228.749, \"total_train_time_s\": 10.248327255249023}", "{\"n\": 4983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.92, \"learn_time_ms\": 9178.346, \"total_train_time_s\": 9.85188627243042}", "{\"n\": 4984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.91, \"learn_time_ms\": 9071.361, \"total_train_time_s\": 9.830124855041504}", "{\"n\": 4985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.88, \"learn_time_ms\": 9139.983, \"total_train_time_s\": 11.602881669998169}", "{\"n\": 4986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.33, \"learn_time_ms\": 9013.063, \"total_train_time_s\": 10.002621412277222}", "{\"n\": 4987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.07, \"learn_time_ms\": 9178.158, \"total_train_time_s\": 11.044976711273193}", "{\"n\": 4988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.07, \"learn_time_ms\": 9389.014, \"total_train_time_s\": 11.520760774612427}", "{\"n\": 4989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.16, \"learn_time_ms\": 9108.177, \"total_train_time_s\": 8.730217218399048}", "{\"n\": 4990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3252.6, \"learn_time_ms\": 9121.5, \"total_train_time_s\": 11.457167387008667}", "{\"n\": 4991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.51, \"learn_time_ms\": 9035.731, \"total_train_time_s\": 10.182109117507935}", "{\"n\": 4992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.33, \"learn_time_ms\": 8906.139, \"total_train_time_s\": 8.973697185516357}", "{\"n\": 4993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.71, \"learn_time_ms\": 8962.034, \"total_train_time_s\": 10.353229999542236}", "{\"n\": 4994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.71, \"learn_time_ms\": 8901.519, \"total_train_time_s\": 9.255439043045044}", "{\"n\": 4995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.98, \"learn_time_ms\": 8922.18, \"total_train_time_s\": 11.87987756729126}", "{\"n\": 4996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.48, \"learn_time_ms\": 9142.314, \"total_train_time_s\": 12.302785873413086}", "{\"n\": 4997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.48, \"learn_time_ms\": 9150.165, \"total_train_time_s\": 11.138968229293823}", "{\"n\": 4998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.1, \"learn_time_ms\": 9014.93, \"total_train_time_s\": 10.164539098739624}", "{\"n\": 4999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.82, \"learn_time_ms\": 9188.124, \"total_train_time_s\": 10.465219736099243}", "{\"n\": 5000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.1, \"learn_time_ms\": 9014.895, \"total_train_time_s\": 9.748315811157227}", "{\"n\": 5001, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.17, \"learn_time_ms\": 8981.447, \"total_train_time_s\": 9.845947504043579}", "{\"n\": 5002, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.19, \"learn_time_ms\": 9061.787, \"total_train_time_s\": 9.788588047027588}", "{\"n\": 5003, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.05, \"learn_time_ms\": 9029.677, \"total_train_time_s\": 10.049211502075195}", "{\"n\": 5004, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.1, \"learn_time_ms\": 9129.216, \"total_train_time_s\": 10.226397514343262}", "{\"n\": 5005, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.72, \"learn_time_ms\": 9010.075, \"total_train_time_s\": 10.660043239593506}", "{\"n\": 5006, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.63, \"learn_time_ms\": 8788.787, \"total_train_time_s\": 10.00804352760315}", "{\"n\": 5007, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.05, \"learn_time_ms\": 8670.12, \"total_train_time_s\": 9.955205917358398}", "{\"n\": 5008, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.09, \"learn_time_ms\": 8627.266, \"total_train_time_s\": 9.734904050827026}", "{\"n\": 5009, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.1, \"learn_time_ms\": 8789.054, \"total_train_time_s\": 12.04196572303772}", "{\"n\": 5010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.1, \"learn_time_ms\": 8843.085, \"total_train_time_s\": 10.259912014007568}", "{\"n\": 5011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.16, \"learn_time_ms\": 8990.219, \"total_train_time_s\": 11.355478763580322}", "{\"n\": 5012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.27, \"learn_time_ms\": 8930.228, \"total_train_time_s\": 9.219197750091553}", "{\"n\": 5013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.1, \"learn_time_ms\": 8855.794, \"total_train_time_s\": 9.331361055374146}", "{\"n\": 5014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.1, \"learn_time_ms\": 8778.316, \"total_train_time_s\": 9.46353530883789}", "{\"n\": 5015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.19, \"learn_time_ms\": 8718.094, \"total_train_time_s\": 10.050346374511719}", "{\"n\": 5016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.56, \"learn_time_ms\": 8774.558, \"total_train_time_s\": 10.553715705871582}", "{\"n\": 5017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.01, \"learn_time_ms\": 8753.516, \"total_train_time_s\": 9.782867193222046}", "{\"n\": 5018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.37, \"learn_time_ms\": 8801.518, \"total_train_time_s\": 10.253796100616455}", "{\"n\": 5019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.37, \"learn_time_ms\": 8535.847, \"total_train_time_s\": 9.411216020584106}", "{\"n\": 5020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.16, \"learn_time_ms\": 8401.815, \"total_train_time_s\": 8.944536447525024}", "{\"n\": 5021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.21, \"learn_time_ms\": 8419.053, \"total_train_time_s\": 11.51358699798584}", "{\"n\": 5022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.21, \"learn_time_ms\": 8505.043, \"total_train_time_s\": 10.000501155853271}", "{\"n\": 5023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.08, \"learn_time_ms\": 8535.286, \"total_train_time_s\": 9.613293647766113}", "{\"n\": 5024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.61, \"learn_time_ms\": 8617.95, \"total_train_time_s\": 10.271753549575806}", "{\"n\": 5025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.61, \"learn_time_ms\": 8652.469, \"total_train_time_s\": 10.423749685287476}", "{\"n\": 5026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.75, \"learn_time_ms\": 8726.825, \"total_train_time_s\": 11.268070936203003}", "{\"n\": 5027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.91, \"learn_time_ms\": 8677.447, \"total_train_time_s\": 9.256688594818115}", "{\"n\": 5028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.03, \"learn_time_ms\": 8633.785, \"total_train_time_s\": 9.814301013946533}", "{\"n\": 5029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.83, \"learn_time_ms\": 8684.484, \"total_train_time_s\": 9.96371603012085}", "{\"n\": 5030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.43, \"learn_time_ms\": 8732.614, \"total_train_time_s\": 9.415520906448364}", "{\"n\": 5031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.4, \"learn_time_ms\": 8664.698, \"total_train_time_s\": 10.829660892486572}", "{\"n\": 5032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.86, \"learn_time_ms\": 8730.055, \"total_train_time_s\": 10.680318117141724}", "{\"n\": 5033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.32, \"learn_time_ms\": 8846.777, \"total_train_time_s\": 10.74970555305481}", "{\"n\": 5034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.32, \"learn_time_ms\": 8910.434, \"total_train_time_s\": 10.914769172668457}", "{\"n\": 5035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.99, \"learn_time_ms\": 8757.919, \"total_train_time_s\": 8.882304668426514}", "{\"n\": 5036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.62, \"learn_time_ms\": 8755.726, \"total_train_time_s\": 11.255651235580444}", "{\"n\": 5037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.62, \"learn_time_ms\": 8845.057, \"total_train_time_s\": 10.14606499671936}", "{\"n\": 5038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.77, \"learn_time_ms\": 8853.477, \"total_train_time_s\": 9.89646315574646}", "{\"n\": 5039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.29, \"learn_time_ms\": 8826.906, \"total_train_time_s\": 9.678414583206177}", "{\"n\": 5040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.59, \"learn_time_ms\": 9097.822, \"total_train_time_s\": 12.087462902069092}", "{\"n\": 5041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.31, \"learn_time_ms\": 9004.88, \"total_train_time_s\": 9.87637972831726}", "{\"n\": 5042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.79, \"learn_time_ms\": 8878.07, \"total_train_time_s\": 9.396949052810669}", "{\"n\": 5043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.71, \"learn_time_ms\": 8877.002, \"total_train_time_s\": 10.768234252929688}", "{\"n\": 5044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.39, \"learn_time_ms\": 8926.478, \"total_train_time_s\": 11.402328491210938}", "{\"n\": 5045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.78, \"learn_time_ms\": 9150.531, \"total_train_time_s\": 11.110934257507324}", "{\"n\": 5046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.78, \"learn_time_ms\": 9034.833, \"total_train_time_s\": 10.114224672317505}", "{\"n\": 5047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.84, \"learn_time_ms\": 8940.004, \"total_train_time_s\": 9.191561222076416}", "{\"n\": 5048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.9, \"learn_time_ms\": 8833.287, \"total_train_time_s\": 8.836861848831177}", "{\"n\": 5049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.9, \"learn_time_ms\": 8807.253, \"total_train_time_s\": 9.434847593307495}", "{\"n\": 5050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.86, \"learn_time_ms\": 8609.058, \"total_train_time_s\": 10.171036958694458}", "{\"n\": 5051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3178.73, \"learn_time_ms\": 8809.63, \"total_train_time_s\": 11.901406049728394}", "{\"n\": 5052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.43, \"learn_time_ms\": 8891.309, \"total_train_time_s\": 10.230379104614258}", "{\"n\": 5053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.34, \"learn_time_ms\": 8830.806, \"total_train_time_s\": 10.230727434158325}", "{\"n\": 5054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.29, \"learn_time_ms\": 8675.381, \"total_train_time_s\": 9.841394662857056}", "{\"n\": 5055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.51, \"learn_time_ms\": 8570.332, \"total_train_time_s\": 10.068365573883057}", "{\"n\": 5056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.59, \"learn_time_ms\": 8580.008, \"total_train_time_s\": 10.238013505935669}", "{\"n\": 5057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.3, \"learn_time_ms\": 8775.904, \"total_train_time_s\": 11.166005849838257}", "{\"n\": 5058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.4, \"learn_time_ms\": 8913.768, \"total_train_time_s\": 10.208064317703247}", "{\"n\": 5059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.76, \"learn_time_ms\": 9086.901, \"total_train_time_s\": 11.142258405685425}", "{\"n\": 5060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.57, \"learn_time_ms\": 9200.929, \"total_train_time_s\": 11.261954307556152}", "{\"n\": 5061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.3, \"learn_time_ms\": 9084.815, \"total_train_time_s\": 10.780332803726196}", "{\"n\": 5062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.53, \"learn_time_ms\": 9039.8, \"total_train_time_s\": 9.81518030166626}", "{\"n\": 5063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.77, \"learn_time_ms\": 8948.944, \"total_train_time_s\": 9.240050554275513}", "{\"n\": 5064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.1, \"learn_time_ms\": 8845.344, \"total_train_time_s\": 8.80046796798706}", "{\"n\": 5065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.05, \"learn_time_ms\": 8893.65, \"total_train_time_s\": 10.544516324996948}", "{\"n\": 5066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.83, \"learn_time_ms\": 8819.468, \"total_train_time_s\": 9.448376178741455}", "{\"n\": 5067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.36, \"learn_time_ms\": 8492.774, \"total_train_time_s\": 7.944846153259277}", "{\"n\": 5068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.14, \"learn_time_ms\": 8486.168, \"total_train_time_s\": 10.137287139892578}", "{\"n\": 5069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.32, \"learn_time_ms\": 8486.706, \"total_train_time_s\": 11.156092405319214}", "{\"n\": 5070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.21, \"learn_time_ms\": 8244.549, \"total_train_time_s\": 8.851117372512817}", "{\"n\": 5071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.66, \"learn_time_ms\": 8323.37, \"total_train_time_s\": 11.53236198425293}", "{\"n\": 5072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.31, \"learn_time_ms\": 8393.28, \"total_train_time_s\": 10.491021633148193}", "{\"n\": 5073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.44, \"learn_time_ms\": 8403.211, \"total_train_time_s\": 9.357582330703735}", "{\"n\": 5074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.16, \"learn_time_ms\": 8392.528, \"total_train_time_s\": 8.751564264297485}", "{\"n\": 5075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.28, \"learn_time_ms\": 8400.691, \"total_train_time_s\": 10.653745651245117}", "{\"n\": 5076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.03, \"learn_time_ms\": 8431.382, \"total_train_time_s\": 9.805973529815674}", "{\"n\": 5077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.03, \"learn_time_ms\": 8679.717, \"total_train_time_s\": 10.35106611251831}", "{\"n\": 5078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.79, \"learn_time_ms\": 8695.723, \"total_train_time_s\": 10.292877912521362}", "{\"n\": 5079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.31, \"learn_time_ms\": 8858.461, \"total_train_time_s\": 12.763592004776001}", "{\"n\": 5080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.31, \"learn_time_ms\": 8948.566, \"total_train_time_s\": 9.77970814704895}", "{\"n\": 5081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.25, \"learn_time_ms\": 8914.653, \"total_train_time_s\": 11.216610431671143}", "{\"n\": 5082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.25, \"learn_time_ms\": 8968.506, \"total_train_time_s\": 11.041394710540771}", "{\"n\": 5083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.96, \"learn_time_ms\": 9050.035, \"total_train_time_s\": 10.156994581222534}", "{\"n\": 5084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.45, \"learn_time_ms\": 9200.137, \"total_train_time_s\": 10.208007097244263}", "{\"n\": 5085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.45, \"learn_time_ms\": 9243.292, \"total_train_time_s\": 11.03675889968872}", "{\"n\": 5086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.32, \"learn_time_ms\": 9158.314, \"total_train_time_s\": 8.982548236846924}", "{\"n\": 5087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.32, \"learn_time_ms\": 9093.64, \"total_train_time_s\": 9.721230506896973}", "{\"n\": 5088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.77, \"learn_time_ms\": 9043.618, \"total_train_time_s\": 9.77127480506897}", "{\"n\": 5089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.74, \"learn_time_ms\": 8800.347, \"total_train_time_s\": 10.320902109146118}", "{\"n\": 5090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.74, \"learn_time_ms\": 8895.94, \"total_train_time_s\": 10.687480211257935}", "{\"n\": 5091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.16, \"learn_time_ms\": 8825.586, \"total_train_time_s\": 10.50044560432434}", "{\"n\": 5092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.78, \"learn_time_ms\": 8768.109, \"total_train_time_s\": 10.438543558120728}", "{\"n\": 5093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.38, \"learn_time_ms\": 8704.889, \"total_train_time_s\": 9.527970314025879}", "{\"n\": 5094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.49, \"learn_time_ms\": 8770.809, \"total_train_time_s\": 10.909632921218872}", "{\"n\": 5095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.39, \"learn_time_ms\": 8792.096, \"total_train_time_s\": 11.274240255355835}", "{\"n\": 5096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.39, \"learn_time_ms\": 9026.706, \"total_train_time_s\": 11.254798173904419}", "{\"n\": 5097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.42, \"learn_time_ms\": 9010.652, \"total_train_time_s\": 9.578587055206299}", "{\"n\": 5098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.11, \"learn_time_ms\": 9099.337, \"total_train_time_s\": 10.689257860183716}", "{\"n\": 5099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.11, \"learn_time_ms\": 9034.875, \"total_train_time_s\": 9.710220575332642}", "{\"n\": 5100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.24, \"learn_time_ms\": 9026.127, \"total_train_time_s\": 10.590490818023682}", "{\"n\": 5101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.79, \"learn_time_ms\": 9019.974, \"total_train_time_s\": 10.432491779327393}", "{\"n\": 5102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.2, \"learn_time_ms\": 8890.283, \"total_train_time_s\": 9.150917053222656}", "{\"n\": 5103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.2, \"learn_time_ms\": 8857.386, \"total_train_time_s\": 9.178954124450684}", "{\"n\": 5104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.61, \"learn_time_ms\": 8966.878, \"total_train_time_s\": 11.997807264328003}", "{\"n\": 5105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.05, \"learn_time_ms\": 8931.395, \"total_train_time_s\": 10.886943340301514}", "{\"n\": 5106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.47, \"learn_time_ms\": 8953.738, \"total_train_time_s\": 11.470337867736816}", "{\"n\": 5107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.53, \"learn_time_ms\": 9048.318, \"total_train_time_s\": 10.484104633331299}", "{\"n\": 5108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.53, \"learn_time_ms\": 9005.599, \"total_train_time_s\": 10.235129117965698}", "{\"n\": 5109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.3, \"learn_time_ms\": 9030.397, \"total_train_time_s\": 9.901000022888184}", "{\"n\": 5110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.73, \"learn_time_ms\": 8934.292, \"total_train_time_s\": 9.646512269973755}", "{\"n\": 5111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.04, \"learn_time_ms\": 8884.705, \"total_train_time_s\": 9.879127979278564}", "{\"n\": 5112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.18, \"learn_time_ms\": 9103.069, \"total_train_time_s\": 11.283148527145386}", "{\"n\": 5113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.18, \"learn_time_ms\": 9214.213, \"total_train_time_s\": 10.288800716400146}", "{\"n\": 5114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.77, \"learn_time_ms\": 9127.467, \"total_train_time_s\": 11.079278707504272}", "{\"n\": 5115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.68, \"learn_time_ms\": 9025.006, \"total_train_time_s\": 9.897279977798462}", "{\"n\": 5116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.1, \"learn_time_ms\": 8807.157, \"total_train_time_s\": 9.288573503494263}", "{\"n\": 5117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.44, \"learn_time_ms\": 8810.231, \"total_train_time_s\": 10.59571886062622}", "{\"n\": 5118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.22, \"learn_time_ms\": 8766.642, \"total_train_time_s\": 9.803832292556763}", "{\"n\": 5119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.22, \"learn_time_ms\": 8672.363, \"total_train_time_s\": 9.01523494720459}", "{\"n\": 5120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.22, \"learn_time_ms\": 8661.281, \"total_train_time_s\": 9.567632675170898}", "{\"n\": 5121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.39, \"learn_time_ms\": 8605.529, \"total_train_time_s\": 9.385184526443481}", "{\"n\": 5122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.93, \"learn_time_ms\": 8529.589, \"total_train_time_s\": 10.64295482635498}", "{\"n\": 5123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.93, \"learn_time_ms\": 8413.733, \"total_train_time_s\": 9.158107995986938}", "{\"n\": 5124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.48, \"learn_time_ms\": 8284.114, \"total_train_time_s\": 9.807478427886963}", "{\"n\": 5125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.15, \"learn_time_ms\": 8335.542, \"total_train_time_s\": 10.418197393417358}", "{\"n\": 5126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.15, \"learn_time_ms\": 8421.873, \"total_train_time_s\": 10.176580429077148}", "{\"n\": 5127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.15, \"learn_time_ms\": 8293.562, \"total_train_time_s\": 9.22413182258606}", "{\"n\": 5128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.83, \"learn_time_ms\": 8186.413, \"total_train_time_s\": 8.69814419746399}", "{\"n\": 5129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.23, \"learn_time_ms\": 8307.923, \"total_train_time_s\": 10.164838075637817}", "{\"n\": 5130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.23, \"learn_time_ms\": 8407.655, \"total_train_time_s\": 10.527406930923462}", "{\"n\": 5131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.44, \"learn_time_ms\": 8485.706, \"total_train_time_s\": 10.116915702819824}", "{\"n\": 5132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.31, \"learn_time_ms\": 8322.83, \"total_train_time_s\": 8.964386463165283}", "{\"n\": 5133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.31, \"learn_time_ms\": 8427.182, \"total_train_time_s\": 10.170643091201782}", "{\"n\": 5134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.74, \"learn_time_ms\": 8419.612, \"total_train_time_s\": 9.714122295379639}", "{\"n\": 5135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.18, \"learn_time_ms\": 8261.338, \"total_train_time_s\": 8.79001235961914}", "{\"n\": 5136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3252.18, \"learn_time_ms\": 8281.269, \"total_train_time_s\": 10.348079204559326}", "{\"n\": 5137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.16, \"learn_time_ms\": 8355.633, \"total_train_time_s\": 10.001251697540283}", "{\"n\": 5138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.61, \"learn_time_ms\": 8616.78, \"total_train_time_s\": 11.358960151672363}", "{\"n\": 5139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 8690.439, \"total_train_time_s\": 10.936105728149414}", "{\"n\": 5140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 8731.863, \"total_train_time_s\": 10.999899864196777}", "{\"n\": 5141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.27, \"learn_time_ms\": 8721.726, \"total_train_time_s\": 10.067664384841919}", "{\"n\": 5142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.91, \"learn_time_ms\": 8779.279, \"total_train_time_s\": 9.518720626831055}", "{\"n\": 5143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.91, \"learn_time_ms\": 8795.549, \"total_train_time_s\": 10.378591060638428}", "{\"n\": 5144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.84, \"learn_time_ms\": 8889.952, \"total_train_time_s\": 10.72245979309082}", "{\"n\": 5145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.7, \"learn_time_ms\": 8953.698, \"total_train_time_s\": 9.46903109550476}", "{\"n\": 5146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.7, \"learn_time_ms\": 9070.95, \"total_train_time_s\": 11.561344146728516}", "{\"n\": 5147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.67, \"learn_time_ms\": 9134.607, \"total_train_time_s\": 10.644074201583862}", "{\"n\": 5148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.09, \"learn_time_ms\": 9133.6, \"total_train_time_s\": 11.363616466522217}", "{\"n\": 5149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.76, \"learn_time_ms\": 9052.099, \"total_train_time_s\": 10.08804988861084}", "{\"n\": 5150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.16, \"learn_time_ms\": 9108.253, \"total_train_time_s\": 11.57922911643982}", "{\"n\": 5151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3226.87, \"learn_time_ms\": 9042.219, \"total_train_time_s\": 9.410333633422852}", "{\"n\": 5152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.04, \"learn_time_ms\": 9152.666, \"total_train_time_s\": 10.636575698852539}", "{\"n\": 5153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.75, \"learn_time_ms\": 9221.3, \"total_train_time_s\": 11.07543396949768}", "{\"n\": 5154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.73, \"learn_time_ms\": 9024.683, \"total_train_time_s\": 8.721810579299927}", "{\"n\": 5155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.75, \"learn_time_ms\": 9117.994, \"total_train_time_s\": 10.394807577133179}", "{\"n\": 5156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.75, \"learn_time_ms\": 8883.967, \"total_train_time_s\": 9.241741418838501}", "{\"n\": 5157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.74, \"learn_time_ms\": 8918.483, \"total_train_time_s\": 11.018969774246216}", "{\"n\": 5158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.18, \"learn_time_ms\": 8968.214, \"total_train_time_s\": 11.848207712173462}", "{\"n\": 5159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.17, \"learn_time_ms\": 9106.77, \"total_train_time_s\": 11.530784845352173}", "{\"n\": 5160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.17, \"learn_time_ms\": 8932.334, \"total_train_time_s\": 9.750476598739624}", "{\"n\": 5161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.23, \"learn_time_ms\": 9102.617, \"total_train_time_s\": 11.070221900939941}", "{\"n\": 5162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.8, \"learn_time_ms\": 9100.529, \"total_train_time_s\": 10.635840892791748}", "{\"n\": 5163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.09, \"learn_time_ms\": 9125.355, \"total_train_time_s\": 11.329481363296509}", "{\"n\": 5164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.13, \"learn_time_ms\": 9194.762, \"total_train_time_s\": 9.402897596359253}", "{\"n\": 5165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.62, \"learn_time_ms\": 9074.903, \"total_train_time_s\": 9.207559585571289}", "{\"n\": 5166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.02, \"learn_time_ms\": 9292.868, \"total_train_time_s\": 11.41591477394104}", "{\"n\": 5167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.13, \"learn_time_ms\": 9340.443, \"total_train_time_s\": 11.489038467407227}", "{\"n\": 5168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 9305.687, \"total_train_time_s\": 11.453935384750366}", "{\"n\": 5169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.66, \"learn_time_ms\": 9245.555, \"total_train_time_s\": 10.870245695114136}", "{\"n\": 5170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.35, \"learn_time_ms\": 9297.196, \"total_train_time_s\": 10.314944744110107}", "{\"n\": 5171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.29, \"learn_time_ms\": 9315.168, \"total_train_time_s\": 11.316570043563843}", "{\"n\": 5172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.46, \"learn_time_ms\": 9364.647, \"total_train_time_s\": 11.142019987106323}", "{\"n\": 5173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.91, \"learn_time_ms\": 9124.667, \"total_train_time_s\": 8.880013942718506}", "{\"n\": 5174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.91, \"learn_time_ms\": 9114.637, \"total_train_time_s\": 9.29395318031311}", "{\"n\": 5175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.51, \"learn_time_ms\": 9000.361, \"total_train_time_s\": 8.066044569015503}", "{\"n\": 5176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.71, \"learn_time_ms\": 8819.646, \"total_train_time_s\": 9.604911088943481}", "{\"n\": 5177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.58, \"learn_time_ms\": 8798.449, \"total_train_time_s\": 11.264148235321045}", "{\"n\": 5178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.95, \"learn_time_ms\": 8564.468, \"total_train_time_s\": 9.159984588623047}", "{\"n\": 5179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.16, \"learn_time_ms\": 8550.988, \"total_train_time_s\": 10.769414901733398}", "{\"n\": 5180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.49, \"learn_time_ms\": 8423.695, \"total_train_time_s\": 9.000245332717896}", "{\"n\": 5181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.58, \"learn_time_ms\": 8267.073, \"total_train_time_s\": 9.746928930282593}", "{\"n\": 5182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.31, \"learn_time_ms\": 8139.622, \"total_train_time_s\": 9.797987461090088}", "{\"n\": 5183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.89, \"learn_time_ms\": 8373.811, \"total_train_time_s\": 11.24887228012085}", "{\"n\": 5184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.52, \"learn_time_ms\": 8332.859, \"total_train_time_s\": 8.906268835067749}", "{\"n\": 5185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.78, \"learn_time_ms\": 8485.907, \"total_train_time_s\": 9.660691738128662}", "{\"n\": 5186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.78, \"learn_time_ms\": 8618.779, \"total_train_time_s\": 10.912928342819214}", "{\"n\": 5187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.43, \"learn_time_ms\": 8456.161, \"total_train_time_s\": 9.635696411132812}", "{\"n\": 5188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.74, \"learn_time_ms\": 8572.164, \"total_train_time_s\": 10.349773645401001}", "{\"n\": 5189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.71, \"learn_time_ms\": 8543.074, \"total_train_time_s\": 10.49319577217102}", "{\"n\": 5190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.85, \"learn_time_ms\": 8663.716, \"total_train_time_s\": 10.239251136779785}", "{\"n\": 5191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.85, \"learn_time_ms\": 8634.399, \"total_train_time_s\": 9.429413557052612}", "{\"n\": 5192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.66, \"learn_time_ms\": 8666.537, \"total_train_time_s\": 10.109057426452637}", "{\"n\": 5193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8682.961, \"total_train_time_s\": 11.419652700424194}", "{\"n\": 5194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.32, \"learn_time_ms\": 8835.096, \"total_train_time_s\": 10.466158151626587}", "{\"n\": 5195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.03, \"learn_time_ms\": 8945.675, \"total_train_time_s\": 10.699756145477295}", "{\"n\": 5196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.52, \"learn_time_ms\": 8925.849, \"total_train_time_s\": 10.716151475906372}", "{\"n\": 5197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.52, \"learn_time_ms\": 9063.449, \"total_train_time_s\": 10.980368852615356}", "{\"n\": 5198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.88, \"learn_time_ms\": 8995.508, \"total_train_time_s\": 9.600771427154541}", "{\"n\": 5199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.88, \"learn_time_ms\": 8990.597, \"total_train_time_s\": 10.413193702697754}", "{\"n\": 5200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.73, \"learn_time_ms\": 8960.429, \"total_train_time_s\": 9.902341604232788}", "{\"n\": 5201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.93, \"learn_time_ms\": 9074.23, \"total_train_time_s\": 10.574236154556274}", "{\"n\": 5202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.93, \"learn_time_ms\": 9130.629, \"total_train_time_s\": 10.733953952789307}", "{\"n\": 5203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.98, \"learn_time_ms\": 8944.855, \"total_train_time_s\": 9.547126770019531}", "{\"n\": 5204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.65, \"learn_time_ms\": 8882.682, \"total_train_time_s\": 9.775849342346191}", "{\"n\": 5205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.65, \"learn_time_ms\": 8938.331, \"total_train_time_s\": 11.207613706588745}", "{\"n\": 5206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.1, \"learn_time_ms\": 9009.498, \"total_train_time_s\": 11.405452966690063}", "{\"n\": 5207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.85, \"learn_time_ms\": 9042.491, \"total_train_time_s\": 11.320184469223022}", "{\"n\": 5208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.11, \"learn_time_ms\": 9019.043, \"total_train_time_s\": 9.36128544807434}", "{\"n\": 5209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.11, \"learn_time_ms\": 8962.32, \"total_train_time_s\": 9.879812479019165}", "{\"n\": 5210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.46, \"learn_time_ms\": 8928.686, \"total_train_time_s\": 9.58803415298462}", "{\"n\": 5211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.67, \"learn_time_ms\": 8945.617, \"total_train_time_s\": 10.765339851379395}", "{\"n\": 5212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.67, \"learn_time_ms\": 8900.323, \"total_train_time_s\": 10.258274793624878}", "{\"n\": 5213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.34, \"learn_time_ms\": 8990.518, \"total_train_time_s\": 10.496257781982422}", "{\"n\": 5214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.85, \"learn_time_ms\": 8986.144, \"total_train_time_s\": 9.785180807113647}", "{\"n\": 5215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.85, \"learn_time_ms\": 8890.13, \"total_train_time_s\": 10.277591466903687}", "{\"n\": 5216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.79, \"learn_time_ms\": 8760.914, \"total_train_time_s\": 10.148807287216187}", "{\"n\": 5217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.15, \"learn_time_ms\": 8627.612, \"total_train_time_s\": 10.004344463348389}", "{\"n\": 5218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8879.873, \"total_train_time_s\": 11.933284997940063}", "{\"n\": 5219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8863.773, \"total_train_time_s\": 9.738293647766113}", "{\"n\": 5220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.77, \"learn_time_ms\": 8895.648, \"total_train_time_s\": 9.89442491531372}", "{\"n\": 5221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.41, \"learn_time_ms\": 8843.511, \"total_train_time_s\": 10.194631099700928}", "{\"n\": 5222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.41, \"learn_time_ms\": 8674.944, \"total_train_time_s\": 8.567543983459473}", "{\"n\": 5223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.41, \"learn_time_ms\": 8650.294, \"total_train_time_s\": 10.200242042541504}", "{\"n\": 5224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.41, \"learn_time_ms\": 8609.755, \"total_train_time_s\": 9.37182354927063}", "{\"n\": 5225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.41, \"learn_time_ms\": 8543.548, \"total_train_time_s\": 9.637409448623657}", "{\"n\": 5226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.41, \"learn_time_ms\": 8648.597, \"total_train_time_s\": 11.218914031982422}", "{\"n\": 5227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.88, \"learn_time_ms\": 8740.304, \"total_train_time_s\": 10.921406030654907}", "{\"n\": 5228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.88, \"learn_time_ms\": 8739.289, \"total_train_time_s\": 11.893349647521973}", "{\"n\": 5229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.88, \"learn_time_ms\": 8802.724, \"total_train_time_s\": 10.301981687545776}", "{\"n\": 5230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.59, \"learn_time_ms\": 8838.04, \"total_train_time_s\": 10.285586833953857}", "{\"n\": 5231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.54, \"learn_time_ms\": 8848.239, \"total_train_time_s\": 10.318920135498047}", "{\"n\": 5232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.54, \"learn_time_ms\": 8919.529, \"total_train_time_s\": 9.267717361450195}", "{\"n\": 5233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.1, \"learn_time_ms\": 8841.324, \"total_train_time_s\": 9.399584531784058}", "{\"n\": 5234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.37, \"learn_time_ms\": 8932.619, \"total_train_time_s\": 10.242624282836914}", "{\"n\": 5235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.37, \"learn_time_ms\": 8910.476, \"total_train_time_s\": 9.386416912078857}", "{\"n\": 5236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.76, \"learn_time_ms\": 8843.917, \"total_train_time_s\": 10.55310344696045}", "{\"n\": 5237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.51, \"learn_time_ms\": 8908.74, \"total_train_time_s\": 11.56407618522644}", "{\"n\": 5238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.82, \"learn_time_ms\": 8929.248, \"total_train_time_s\": 12.108149766921997}", "{\"n\": 5239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.78, \"learn_time_ms\": 8897.525, \"total_train_time_s\": 10.03789234161377}", "{\"n\": 5240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.5, \"learn_time_ms\": 8876.922, \"total_train_time_s\": 10.044111967086792}", "{\"n\": 5241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.61, \"learn_time_ms\": 8858.325, \"total_train_time_s\": 10.116674184799194}", "{\"n\": 5242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.01, \"learn_time_ms\": 8922.724, \"total_train_time_s\": 9.911219835281372}", "{\"n\": 5243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.3, \"learn_time_ms\": 9151.861, \"total_train_time_s\": 11.761384725570679}", "{\"n\": 5244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.32, \"learn_time_ms\": 9066.137, \"total_train_time_s\": 9.46001386642456}", "{\"n\": 5245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.56, \"learn_time_ms\": 9220.447, \"total_train_time_s\": 10.936166286468506}", "{\"n\": 5246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.1, \"learn_time_ms\": 9116.066, \"total_train_time_s\": 9.490046501159668}", "{\"n\": 5247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.02, \"learn_time_ms\": 8943.753, \"total_train_time_s\": 9.848192691802979}", "{\"n\": 5248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.58, \"learn_time_ms\": 8755.926, \"total_train_time_s\": 10.249529600143433}", "{\"n\": 5249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.56, \"learn_time_ms\": 8858.129, \"total_train_time_s\": 11.026821613311768}", "{\"n\": 5250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.67, \"learn_time_ms\": 8899.474, \"total_train_time_s\": 10.442154169082642}", "{\"n\": 5251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.59, \"learn_time_ms\": 8780.532, \"total_train_time_s\": 8.937109470367432}", "{\"n\": 5252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.61, \"learn_time_ms\": 8980.438, \"total_train_time_s\": 11.917290687561035}", "{\"n\": 5253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.3, \"learn_time_ms\": 8826.461, \"total_train_time_s\": 10.20439076423645}", "{\"n\": 5254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.3, \"learn_time_ms\": 8819.162, \"total_train_time_s\": 9.330877780914307}", "{\"n\": 5255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.91, \"learn_time_ms\": 8724.221, \"total_train_time_s\": 10.032621383666992}", "{\"n\": 5256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.43, \"learn_time_ms\": 8750.107, \"total_train_time_s\": 9.754034280776978}", "{\"n\": 5257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.87, \"learn_time_ms\": 8793.556, \"total_train_time_s\": 10.296956777572632}", "{\"n\": 5258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.53, \"learn_time_ms\": 8643.834, \"total_train_time_s\": 8.755366086959839}", "{\"n\": 5259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.4, \"learn_time_ms\": 8590.087, \"total_train_time_s\": 10.501626253128052}", "{\"n\": 5260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.18, \"learn_time_ms\": 8637.714, \"total_train_time_s\": 10.934751272201538}", "{\"n\": 5261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.28, \"learn_time_ms\": 8717.923, \"total_train_time_s\": 9.692167043685913}", "{\"n\": 5262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.94, \"learn_time_ms\": 8383.374, \"total_train_time_s\": 8.57603907585144}", "{\"n\": 5263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.34, \"learn_time_ms\": 8594.561, \"total_train_time_s\": 12.288617372512817}", "{\"n\": 5264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.68, \"learn_time_ms\": 8663.228, \"total_train_time_s\": 10.040752649307251}", "{\"n\": 5265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.82, \"learn_time_ms\": 8719.007, \"total_train_time_s\": 10.630144357681274}", "{\"n\": 5266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.61, \"learn_time_ms\": 8719.37, \"total_train_time_s\": 9.759605884552002}", "{\"n\": 5267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.56, \"learn_time_ms\": 8648.651, \"total_train_time_s\": 9.543354511260986}", "{\"n\": 5268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.56, \"learn_time_ms\": 8820.448, \"total_train_time_s\": 10.45357370376587}", "{\"n\": 5269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.97, \"learn_time_ms\": 8993.695, \"total_train_time_s\": 12.25577449798584}", "{\"n\": 5270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 9053.067, \"total_train_time_s\": 11.608183145523071}", "{\"n\": 5271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 9187.419, \"total_train_time_s\": 11.102577686309814}", "{\"n\": 5272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.58, \"learn_time_ms\": 9423.088, \"total_train_time_s\": 10.952631950378418}", "{\"n\": 5273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.93, \"learn_time_ms\": 9316.348, \"total_train_time_s\": 11.21157431602478}", "{\"n\": 5274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.58, \"learn_time_ms\": 9493.095, \"total_train_time_s\": 11.775212049484253}", "{\"n\": 5275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.71, \"learn_time_ms\": 9482.864, \"total_train_time_s\": 10.45250678062439}", "{\"n\": 5276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.38, \"learn_time_ms\": 9592.745, \"total_train_time_s\": 10.817955732345581}", "{\"n\": 5277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.78, \"learn_time_ms\": 9594.333, \"total_train_time_s\": 9.563588619232178}", "{\"n\": 5278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.59, \"learn_time_ms\": 9465.952, \"total_train_time_s\": 9.184505224227905}", "{\"n\": 5279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.17, \"learn_time_ms\": 9125.094, \"total_train_time_s\": 8.826287031173706}", "{\"n\": 5280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.73, \"learn_time_ms\": 8962.349, \"total_train_time_s\": 9.947348356246948}", "{\"n\": 5281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.86, \"learn_time_ms\": 8867.462, \"total_train_time_s\": 10.19507646560669}", "{\"n\": 5282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.04, \"learn_time_ms\": 8766.483, \"total_train_time_s\": 10.014756679534912}", "{\"n\": 5283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.62, \"learn_time_ms\": 8775.151, \"total_train_time_s\": 11.280493021011353}", "{\"n\": 5284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.62, \"learn_time_ms\": 8532.893, \"total_train_time_s\": 9.342586040496826}", "{\"n\": 5285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.4, \"learn_time_ms\": 8463.792, \"total_train_time_s\": 9.792436361312866}", "{\"n\": 5286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.58, \"learn_time_ms\": 8385.943, \"total_train_time_s\": 10.077858209609985}", "{\"n\": 5287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.58, \"learn_time_ms\": 8566.286, \"total_train_time_s\": 11.376305341720581}", "{\"n\": 5288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.44, \"learn_time_ms\": 8667.344, \"total_train_time_s\": 10.208981275558472}", "{\"n\": 5289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.45, \"learn_time_ms\": 8792.647, \"total_train_time_s\": 10.062612533569336}", "{\"n\": 5290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.7, \"learn_time_ms\": 8946.208, \"total_train_time_s\": 11.43231201171875}", "{\"n\": 5291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.24, \"learn_time_ms\": 8922.728, \"total_train_time_s\": 9.875224590301514}", "{\"n\": 5292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.97, \"learn_time_ms\": 8986.748, \"total_train_time_s\": 10.597304344177246}", "{\"n\": 5293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.97, \"learn_time_ms\": 8705.992, \"total_train_time_s\": 8.53762674331665}", "{\"n\": 5294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.11, \"learn_time_ms\": 8718.335, \"total_train_time_s\": 9.503633737564087}", "{\"n\": 5295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.54, \"learn_time_ms\": 8708.907, \"total_train_time_s\": 9.66507601737976}", "{\"n\": 5296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.54, \"learn_time_ms\": 8757.588, \"total_train_time_s\": 10.560734033584595}", "{\"n\": 5297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.58, \"learn_time_ms\": 8585.687, \"total_train_time_s\": 9.67798638343811}", "{\"n\": 5298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.58, \"learn_time_ms\": 8571.731, \"total_train_time_s\": 10.049861192703247}", "{\"n\": 5299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.15, \"learn_time_ms\": 8678.572, \"total_train_time_s\": 11.212303638458252}", "{\"n\": 5300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.42, \"learn_time_ms\": 8453.48, \"total_train_time_s\": 9.203453063964844}", "{\"n\": 5301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.8, \"learn_time_ms\": 8491.42, \"total_train_time_s\": 10.271697044372559}", "{\"n\": 5302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.36, \"learn_time_ms\": 8475.206, \"total_train_time_s\": 10.405872821807861}", "{\"n\": 5303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.66, \"learn_time_ms\": 8664.139, \"total_train_time_s\": 10.342785358428955}", "{\"n\": 5304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.59, \"learn_time_ms\": 8650.128, \"total_train_time_s\": 9.308857679367065}", "{\"n\": 5305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.82, \"learn_time_ms\": 8625.846, \"total_train_time_s\": 9.438101530075073}", "{\"n\": 5306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.6, \"learn_time_ms\": 8470.485, \"total_train_time_s\": 8.96959376335144}", "{\"n\": 5307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.79, \"learn_time_ms\": 8418.95, \"total_train_time_s\": 9.176600217819214}", "{\"n\": 5308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.62, \"learn_time_ms\": 8379.449, \"total_train_time_s\": 9.676432132720947}", "{\"n\": 5309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.05, \"learn_time_ms\": 8207.161, \"total_train_time_s\": 9.44144058227539}", "{\"n\": 5310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.66, \"learn_time_ms\": 8127.494, \"total_train_time_s\": 8.398149967193604}", "{\"n\": 5311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.92, \"learn_time_ms\": 8134.526, \"total_train_time_s\": 10.317445278167725}", "{\"n\": 5312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.84, \"learn_time_ms\": 8066.365, \"total_train_time_s\": 9.732832670211792}", "{\"n\": 5313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.66, \"learn_time_ms\": 8122.317, \"total_train_time_s\": 10.897397994995117}", "{\"n\": 5314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.66, \"learn_time_ms\": 8222.575, \"total_train_time_s\": 10.317253112792969}", "{\"n\": 5315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.17, \"learn_time_ms\": 8303.63, \"total_train_time_s\": 10.210322618484497}", "{\"n\": 5316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.47, \"learn_time_ms\": 8579.852, \"total_train_time_s\": 11.757873773574829}", "{\"n\": 5317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.47, \"learn_time_ms\": 8716.203, \"total_train_time_s\": 10.50425934791565}", "{\"n\": 5318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.34, \"learn_time_ms\": 8890.557, \"total_train_time_s\": 11.38809609413147}", "{\"n\": 5319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.9, \"learn_time_ms\": 9078.918, \"total_train_time_s\": 11.380071640014648}", "{\"n\": 5320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3189.9, \"learn_time_ms\": 9402.743, \"total_train_time_s\": 11.633476495742798}", "{\"n\": 5321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.84, \"learn_time_ms\": 9464.963, \"total_train_time_s\": 10.964191913604736}", "{\"n\": 5322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.39, \"learn_time_ms\": 9505.811, \"total_train_time_s\": 10.15556025505066}", "{\"n\": 5323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.39, \"learn_time_ms\": 9443.431, \"total_train_time_s\": 10.333991527557373}", "{\"n\": 5324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.01, \"learn_time_ms\": 9478.285, \"total_train_time_s\": 10.707186698913574}", "{\"n\": 5325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.23, \"learn_time_ms\": 9655.508, \"total_train_time_s\": 11.988327980041504}", "{\"n\": 5326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.23, \"learn_time_ms\": 9528.055, \"total_train_time_s\": 10.456076860427856}", "{\"n\": 5327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.67, \"learn_time_ms\": 9626.124, \"total_train_time_s\": 11.480831861495972}", "{\"n\": 5328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.81, \"learn_time_ms\": 9482.994, \"total_train_time_s\": 10.009890079498291}", "{\"n\": 5329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.81, \"learn_time_ms\": 9512.034, \"total_train_time_s\": 11.588194131851196}", "{\"n\": 5330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.81, \"learn_time_ms\": 9526.797, \"total_train_time_s\": 11.790104866027832}", "{\"n\": 5331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3181.27, \"learn_time_ms\": 9511.102, \"total_train_time_s\": 10.805641174316406}", "{\"n\": 5332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.31, \"learn_time_ms\": 9405.387, \"total_train_time_s\": 9.058614492416382}", "{\"n\": 5333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3182.31, \"learn_time_ms\": 9386.219, \"total_train_time_s\": 10.098323822021484}", "{\"n\": 5334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3180.9, \"learn_time_ms\": 9256.378, \"total_train_time_s\": 9.43339991569519}", "{\"n\": 5335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.52, \"learn_time_ms\": 9044.52, \"total_train_time_s\": 9.94579792022705}", "{\"n\": 5336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.0, \"learn_time_ms\": 8854.493, \"total_train_time_s\": 8.608218669891357}", "{\"n\": 5337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.18, \"learn_time_ms\": 8654.464, \"total_train_time_s\": 9.475520610809326}", "{\"n\": 5338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.28, \"learn_time_ms\": 8710.756, \"total_train_time_s\": 10.5568368434906}", "{\"n\": 5339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.63, \"learn_time_ms\": 8668.037, \"total_train_time_s\": 11.175874948501587}", "{\"n\": 5340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.62, \"learn_time_ms\": 8363.251, \"total_train_time_s\": 8.725573778152466}", "{\"n\": 5341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.19, \"learn_time_ms\": 8344.692, \"total_train_time_s\": 10.638040542602539}", "{\"n\": 5342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.38, \"learn_time_ms\": 8483.997, \"total_train_time_s\": 10.495047807693481}", "{\"n\": 5343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.63, \"learn_time_ms\": 8605.226, \"total_train_time_s\": 11.320405721664429}", "{\"n\": 5344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.78, \"learn_time_ms\": 8652.813, \"total_train_time_s\": 9.89937448501587}", "{\"n\": 5345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.79, \"learn_time_ms\": 8509.391, \"total_train_time_s\": 8.474449157714844}", "{\"n\": 5346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.08, \"learn_time_ms\": 8745.825, \"total_train_time_s\": 10.963669061660767}", "{\"n\": 5347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.08, \"learn_time_ms\": 8735.823, \"total_train_time_s\": 9.420608043670654}", "{\"n\": 5348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.99, \"learn_time_ms\": 8687.825, \"total_train_time_s\": 10.039001703262329}", "{\"n\": 5349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.36, \"learn_time_ms\": 8602.581, \"total_train_time_s\": 10.326139211654663}", "{\"n\": 5350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.36, \"learn_time_ms\": 8847.043, \"total_train_time_s\": 11.198399782180786}", "{\"n\": 5351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.1, \"learn_time_ms\": 8852.097, \"total_train_time_s\": 10.705131769180298}", "{\"n\": 5352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.52, \"learn_time_ms\": 8897.84, \"total_train_time_s\": 10.924287557601929}", "{\"n\": 5353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.34, \"learn_time_ms\": 8862.804, \"total_train_time_s\": 10.934351921081543}", "{\"n\": 5354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.42, \"learn_time_ms\": 8722.047, \"total_train_time_s\": 8.492065906524658}", "{\"n\": 5355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.42, \"learn_time_ms\": 8994.891, \"total_train_time_s\": 11.168083667755127}", "{\"n\": 5356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.32, \"learn_time_ms\": 8930.502, \"total_train_time_s\": 10.330638408660889}", "{\"n\": 5357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.88, \"learn_time_ms\": 9039.609, \"total_train_time_s\": 10.474782228469849}", "{\"n\": 5358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.1, \"learn_time_ms\": 9084.934, \"total_train_time_s\": 10.472315788269043}", "{\"n\": 5359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.06, \"learn_time_ms\": 9190.117, \"total_train_time_s\": 11.401910066604614}", "{\"n\": 5360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.88, \"learn_time_ms\": 9159.501, \"total_train_time_s\": 10.891139030456543}", "{\"n\": 5361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.92, \"learn_time_ms\": 9229.699, \"total_train_time_s\": 11.353708505630493}", "{\"n\": 5362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.74, \"learn_time_ms\": 9124.852, \"total_train_time_s\": 9.847330808639526}", "{\"n\": 5363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.56, \"learn_time_ms\": 9085.293, \"total_train_time_s\": 10.544364929199219}", "{\"n\": 5364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.99, \"learn_time_ms\": 9195.903, \"total_train_time_s\": 9.586830615997314}", "{\"n\": 5365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.99, \"learn_time_ms\": 9037.15, \"total_train_time_s\": 9.593542098999023}", "{\"n\": 5366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.85, \"learn_time_ms\": 8924.471, \"total_train_time_s\": 9.203516960144043}", "{\"n\": 5367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.94, \"learn_time_ms\": 9217.074, \"total_train_time_s\": 13.386775493621826}", "{\"n\": 5368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.94, \"learn_time_ms\": 9159.496, \"total_train_time_s\": 9.932352066040039}", "{\"n\": 5369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.44, \"learn_time_ms\": 9070.061, \"total_train_time_s\": 10.485936164855957}", "{\"n\": 5370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.97, \"learn_time_ms\": 9029.623, \"total_train_time_s\": 10.524283409118652}", "{\"n\": 5371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.72, \"learn_time_ms\": 8945.834, \"total_train_time_s\": 10.554453372955322}", "{\"n\": 5372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.08, \"learn_time_ms\": 8965.682, \"total_train_time_s\": 10.113648176193237}", "{\"n\": 5373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.69, \"learn_time_ms\": 8982.437, \"total_train_time_s\": 10.746394395828247}", "{\"n\": 5374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.99, \"learn_time_ms\": 9052.965, \"total_train_time_s\": 10.279517889022827}", "{\"n\": 5375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.46, \"learn_time_ms\": 9417.122, \"total_train_time_s\": 13.243592500686646}", "{\"n\": 5376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.41, \"learn_time_ms\": 9518.822, \"total_train_time_s\": 10.1698579788208}", "{\"n\": 5377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.72, \"learn_time_ms\": 9070.238, \"total_train_time_s\": 8.922454118728638}", "{\"n\": 5378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.59, \"learn_time_ms\": 9230.033, \"total_train_time_s\": 11.51168966293335}", "{\"n\": 5379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.17, \"learn_time_ms\": 9258.29, \"total_train_time_s\": 10.742530584335327}", "{\"n\": 5380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.13, \"learn_time_ms\": 9312.885, \"total_train_time_s\": 11.043131828308105}", "{\"n\": 5381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.13, \"learn_time_ms\": 9257.34, \"total_train_time_s\": 10.043107032775879}", "{\"n\": 5382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.93, \"learn_time_ms\": 9280.441, \"total_train_time_s\": 10.325076818466187}", "{\"n\": 5383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.43, \"learn_time_ms\": 9124.98, \"total_train_time_s\": 9.222727060317993}", "{\"n\": 5384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.43, \"learn_time_ms\": 9075.113, \"total_train_time_s\": 9.729601383209229}", "{\"n\": 5385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.49, \"learn_time_ms\": 8791.186, \"total_train_time_s\": 10.371633291244507}", "{\"n\": 5386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.75, \"learn_time_ms\": 8835.265, \"total_train_time_s\": 10.62921142578125}", "{\"n\": 5387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.35, \"learn_time_ms\": 9016.07, \"total_train_time_s\": 10.696666717529297}", "{\"n\": 5388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.7, \"learn_time_ms\": 8962.197, \"total_train_time_s\": 10.915112972259521}", "{\"n\": 5389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.97, \"learn_time_ms\": 8896.276, \"total_train_time_s\": 10.097229242324829}", "{\"n\": 5390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.5, \"learn_time_ms\": 8792.806, \"total_train_time_s\": 10.004526615142822}", "{\"n\": 5391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.27, \"learn_time_ms\": 8707.349, \"total_train_time_s\": 9.096320390701294}", "{\"n\": 5392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.71, \"learn_time_ms\": 8770.193, \"total_train_time_s\": 10.897469282150269}", "{\"n\": 5393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.78, \"learn_time_ms\": 8941.193, \"total_train_time_s\": 10.906840324401855}", "{\"n\": 5394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.07, \"learn_time_ms\": 9132.07, \"total_train_time_s\": 11.680263757705688}", "{\"n\": 5395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.08, \"learn_time_ms\": 9101.847, \"total_train_time_s\": 10.061183214187622}", "{\"n\": 5396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.05, \"learn_time_ms\": 9049.49, \"total_train_time_s\": 10.074386358261108}", "{\"n\": 5397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.15, \"learn_time_ms\": 8911.287, \"total_train_time_s\": 9.350611448287964}", "{\"n\": 5398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.15, \"learn_time_ms\": 8828.75, \"total_train_time_s\": 10.110905647277832}", "{\"n\": 5399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.2, \"learn_time_ms\": 8770.209, \"total_train_time_s\": 9.506292819976807}", "{\"n\": 5400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.21, \"learn_time_ms\": 8829.294, \"total_train_time_s\": 10.568317413330078}", "{\"n\": 5401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.21, \"learn_time_ms\": 8896.446, \"total_train_time_s\": 9.796327114105225}", "{\"n\": 5402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.65, \"learn_time_ms\": 8780.022, \"total_train_time_s\": 9.777102708816528}", "{\"n\": 5403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.82, \"learn_time_ms\": 8633.731, \"total_train_time_s\": 9.419006586074829}", "{\"n\": 5404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.82, \"learn_time_ms\": 8417.711, \"total_train_time_s\": 9.512640237808228}", "{\"n\": 5405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.64, \"learn_time_ms\": 8436.853, \"total_train_time_s\": 10.272531032562256}", "{\"n\": 5406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.13, \"learn_time_ms\": 8284.775, \"total_train_time_s\": 8.60375165939331}", "{\"n\": 5407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.13, \"learn_time_ms\": 8305.379, \"total_train_time_s\": 9.568115711212158}", "{\"n\": 5408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.13, \"learn_time_ms\": 8336.275, \"total_train_time_s\": 10.42740511894226}", "{\"n\": 5409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.06, \"learn_time_ms\": 8419.088, \"total_train_time_s\": 10.370737075805664}", "{\"n\": 5410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.02, \"learn_time_ms\": 8415.906, \"total_train_time_s\": 10.551932334899902}", "{\"n\": 5411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.02, \"learn_time_ms\": 8394.152, \"total_train_time_s\": 9.57542371749878}", "{\"n\": 5412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.61, \"learn_time_ms\": 8496.929, \"total_train_time_s\": 10.778784275054932}", "{\"n\": 5413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.19, \"learn_time_ms\": 8640.104, \"total_train_time_s\": 10.845693826675415}", "{\"n\": 5414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.36, \"learn_time_ms\": 8759.481, \"total_train_time_s\": 10.725788116455078}", "{\"n\": 5415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.35, \"learn_time_ms\": 8932.576, \"total_train_time_s\": 12.020675659179688}", "{\"n\": 5416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.52, \"learn_time_ms\": 9168.239, \"total_train_time_s\": 10.965799331665039}", "{\"n\": 5417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.95, \"learn_time_ms\": 9182.353, \"total_train_time_s\": 9.725996255874634}", "{\"n\": 5418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.37, \"learn_time_ms\": 9092.572, \"total_train_time_s\": 9.581398487091064}", "{\"n\": 5419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.46, \"learn_time_ms\": 9094.423, \"total_train_time_s\": 10.399850845336914}", "{\"n\": 5420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.47, \"learn_time_ms\": 9131.775, \"total_train_time_s\": 10.932796478271484}", "{\"n\": 5421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.43, \"learn_time_ms\": 9120.692, \"total_train_time_s\": 9.451339483261108}", "{\"n\": 5422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.39, \"learn_time_ms\": 9003.303, \"total_train_time_s\": 9.622292757034302}", "{\"n\": 5423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.08, \"learn_time_ms\": 8874.778, \"total_train_time_s\": 9.593177556991577}", "{\"n\": 5424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.97, \"learn_time_ms\": 8809.142, \"total_train_time_s\": 10.07011103630066}", "{\"n\": 5425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.02, \"learn_time_ms\": 8551.231, \"total_train_time_s\": 9.417658567428589}", "{\"n\": 5426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.59, \"learn_time_ms\": 8601.801, \"total_train_time_s\": 11.438769340515137}", "{\"n\": 5427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.59, \"learn_time_ms\": 8707.707, \"total_train_time_s\": 10.723941564559937}", "{\"n\": 5428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.23, \"learn_time_ms\": 8690.222, \"total_train_time_s\": 9.419928073883057}", "{\"n\": 5429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.52, \"learn_time_ms\": 8625.37, \"total_train_time_s\": 9.802247047424316}", "{\"n\": 5430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.52, \"learn_time_ms\": 8492.571, \"total_train_time_s\": 9.594989538192749}", "{\"n\": 5431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.82, \"learn_time_ms\": 8436.277, \"total_train_time_s\": 8.925500392913818}", "{\"n\": 5432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.47, \"learn_time_ms\": 8483.482, \"total_train_time_s\": 10.094820261001587}", "{\"n\": 5433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.74, \"learn_time_ms\": 8536.677, \"total_train_time_s\": 10.1593759059906}", "{\"n\": 5434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.18, \"learn_time_ms\": 8577.198, \"total_train_time_s\": 10.495830535888672}", "{\"n\": 5435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 8459.739, \"total_train_time_s\": 8.300415992736816}", "{\"n\": 5436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 8350.794, \"total_train_time_s\": 10.353142976760864}", "{\"n\": 5437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 8265.885, \"total_train_time_s\": 9.91443681716919}", "{\"n\": 5438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8467.1, \"total_train_time_s\": 11.414585590362549}", "{\"n\": 5439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8574.406, \"total_train_time_s\": 10.810633420944214}", "{\"n\": 5440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8624.844, \"total_train_time_s\": 10.107908487319946}", "{\"n\": 5441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.97, \"learn_time_ms\": 8868.62, \"total_train_time_s\": 11.338167428970337}", "{\"n\": 5442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.26, \"learn_time_ms\": 8852.619, \"total_train_time_s\": 9.92717170715332}", "{\"n\": 5443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.26, \"learn_time_ms\": 8899.791, \"total_train_time_s\": 10.624550104141235}", "{\"n\": 5444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.44, \"learn_time_ms\": 9021.317, \"total_train_time_s\": 11.699143409729004}", "{\"n\": 5445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.27, \"learn_time_ms\": 9218.895, \"total_train_time_s\": 10.236659049987793}", "{\"n\": 5446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.27, \"learn_time_ms\": 9308.521, \"total_train_time_s\": 11.239568948745728}", "{\"n\": 5447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.09, \"learn_time_ms\": 9240.281, \"total_train_time_s\": 9.202308416366577}", "{\"n\": 5448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.8, \"learn_time_ms\": 9054.127, \"total_train_time_s\": 9.532857418060303}", "{\"n\": 5449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.8, \"learn_time_ms\": 8992.062, \"total_train_time_s\": 10.148653745651245}", "{\"n\": 5450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.99, \"learn_time_ms\": 8917.624, \"total_train_time_s\": 9.38293719291687}", "{\"n\": 5451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.63, \"learn_time_ms\": 8929.78, \"total_train_time_s\": 11.514412879943848}", "{\"n\": 5452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.76, \"learn_time_ms\": 8936.278, \"total_train_time_s\": 9.973905801773071}", "{\"n\": 5453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.1, \"learn_time_ms\": 8935.556, \"total_train_time_s\": 10.582325220108032}", "{\"n\": 5454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.32, \"learn_time_ms\": 8806.254, \"total_train_time_s\": 10.410710096359253}", "{\"n\": 5455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.1, \"learn_time_ms\": 8929.317, \"total_train_time_s\": 11.468782901763916}", "{\"n\": 5456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.96, \"learn_time_ms\": 8844.433, \"total_train_time_s\": 10.458800554275513}", "{\"n\": 5457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.35, \"learn_time_ms\": 8996.742, \"total_train_time_s\": 10.76314115524292}", "{\"n\": 5458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.64, \"learn_time_ms\": 8991.342, \"total_train_time_s\": 9.497771263122559}", "{\"n\": 5459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.11, \"learn_time_ms\": 8866.609, \"total_train_time_s\": 8.90782380104065}", "{\"n\": 5460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.44, \"learn_time_ms\": 8959.126, \"total_train_time_s\": 10.278424739837646}", "{\"n\": 5461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.09, \"learn_time_ms\": 8923.224, \"total_train_time_s\": 11.097580671310425}", "{\"n\": 5462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.09, \"learn_time_ms\": 8904.049, \"total_train_time_s\": 9.7938973903656}", "{\"n\": 5463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.21, \"learn_time_ms\": 8866.626, \"total_train_time_s\": 10.179800748825073}", "{\"n\": 5464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.0, \"learn_time_ms\": 8806.129, \"total_train_time_s\": 9.792295932769775}", "{\"n\": 5465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.0, \"learn_time_ms\": 8724.254, \"total_train_time_s\": 10.651477575302124}", "{\"n\": 5466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.55, \"learn_time_ms\": 8668.107, \"total_train_time_s\": 9.877432584762573}", "{\"n\": 5467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.97, \"learn_time_ms\": 8636.994, \"total_train_time_s\": 10.43534779548645}", "{\"n\": 5468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.97, \"learn_time_ms\": 8700.414, \"total_train_time_s\": 10.079031467437744}", "{\"n\": 5469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.27, \"learn_time_ms\": 8830.584, \"total_train_time_s\": 10.221062421798706}", "{\"n\": 5470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.7, \"learn_time_ms\": 8903.172, \"total_train_time_s\": 11.083243370056152}", "{\"n\": 5471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.7, \"learn_time_ms\": 8835.285, \"total_train_time_s\": 10.445565938949585}", "{\"n\": 5472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.89, \"learn_time_ms\": 8816.705, \"total_train_time_s\": 9.619894742965698}", "{\"n\": 5473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.12, \"learn_time_ms\": 8735.32, \"total_train_time_s\": 9.4104483127594}", "{\"n\": 5474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.92, \"learn_time_ms\": 8668.943, \"total_train_time_s\": 9.118391513824463}", "{\"n\": 5475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.92, \"learn_time_ms\": 8535.287, \"total_train_time_s\": 9.309016227722168}", "{\"n\": 5476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.84, \"learn_time_ms\": 8554.215, \"total_train_time_s\": 10.008739709854126}", "{\"n\": 5477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.3, \"learn_time_ms\": 8706.896, \"total_train_time_s\": 12.01465106010437}", "{\"n\": 5478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.6, \"learn_time_ms\": 8728.059, \"total_train_time_s\": 10.312131881713867}", "{\"n\": 5479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.97, \"learn_time_ms\": 8749.021, \"total_train_time_s\": 10.437527179718018}", "{\"n\": 5480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.45, \"learn_time_ms\": 8692.433, \"total_train_time_s\": 10.451525688171387}", "{\"n\": 5481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.45, \"learn_time_ms\": 8624.151, \"total_train_time_s\": 9.760196447372437}", "{\"n\": 5482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.01, \"learn_time_ms\": 8748.974, \"total_train_time_s\": 10.843757152557373}", "{\"n\": 5483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.1, \"learn_time_ms\": 8552.579, \"total_train_time_s\": 7.430052042007446}", "{\"n\": 5484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.72, \"learn_time_ms\": 8686.488, \"total_train_time_s\": 10.43441891670227}", "{\"n\": 5485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.3, \"learn_time_ms\": 8740.481, \"total_train_time_s\": 9.87751579284668}", "{\"n\": 5486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.59, \"learn_time_ms\": 8783.329, \"total_train_time_s\": 10.465256929397583}", "{\"n\": 5487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.34, \"learn_time_ms\": 8536.471, \"total_train_time_s\": 9.46853756904602}", "{\"n\": 5488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.62, \"learn_time_ms\": 8575.01, \"total_train_time_s\": 10.729640007019043}", "{\"n\": 5489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.58, \"learn_time_ms\": 8562.474, \"total_train_time_s\": 10.319021701812744}", "{\"n\": 5490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.64, \"learn_time_ms\": 8565.877, \"total_train_time_s\": 10.508622169494629}", "{\"n\": 5491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.85, \"learn_time_ms\": 8625.216, \"total_train_time_s\": 10.355278253555298}", "{\"n\": 5492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.56, \"learn_time_ms\": 8416.832, \"total_train_time_s\": 8.807120561599731}", "{\"n\": 5493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.56, \"learn_time_ms\": 8735.68, \"total_train_time_s\": 10.676621913909912}", "{\"n\": 5494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.76, \"learn_time_ms\": 8624.16, \"total_train_time_s\": 9.34512734413147}", "{\"n\": 5495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.21, \"learn_time_ms\": 8456.854, \"total_train_time_s\": 8.203019618988037}", "{\"n\": 5496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.26, \"learn_time_ms\": 8417.655, \"total_train_time_s\": 10.068817377090454}", "{\"n\": 5497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.93, \"learn_time_ms\": 8474.906, \"total_train_time_s\": 10.050459861755371}", "{\"n\": 5498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.51, \"learn_time_ms\": 8332.011, \"total_train_time_s\": 9.241093158721924}", "{\"n\": 5499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.68, \"learn_time_ms\": 8291.043, \"total_train_time_s\": 9.906442642211914}", "{\"n\": 5500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.27, \"learn_time_ms\": 8270.317, \"total_train_time_s\": 10.272199392318726}", "{\"n\": 5501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.84, \"learn_time_ms\": 8270.34, \"total_train_time_s\": 10.365324258804321}", "{\"n\": 5502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.75, \"learn_time_ms\": 8422.067, \"total_train_time_s\": 10.305349111557007}", "{\"n\": 5503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.25, \"learn_time_ms\": 8499.282, \"total_train_time_s\": 11.44867730140686}", "{\"n\": 5504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.64, \"learn_time_ms\": 8642.797, \"total_train_time_s\": 10.80593991279602}", "{\"n\": 5505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.7, \"learn_time_ms\": 8853.875, \"total_train_time_s\": 10.30589485168457}", "{\"n\": 5506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.07, \"learn_time_ms\": 8720.11, \"total_train_time_s\": 8.717563390731812}", "{\"n\": 5507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.07, \"learn_time_ms\": 8746.334, \"total_train_time_s\": 10.327926874160767}", "{\"n\": 5508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.41, \"learn_time_ms\": 8967.343, \"total_train_time_s\": 11.525250911712646}", "{\"n\": 5509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.46, \"learn_time_ms\": 9187.944, \"total_train_time_s\": 12.1405189037323}", "{\"n\": 5510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.46, \"learn_time_ms\": 9171.619, \"total_train_time_s\": 10.061476945877075}", "{\"n\": 5511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.72, \"learn_time_ms\": 9234.326, \"total_train_time_s\": 11.000509023666382}", "{\"n\": 5512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.19, \"learn_time_ms\": 9224.924, \"total_train_time_s\": 10.211684465408325}", "{\"n\": 5513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.19, \"learn_time_ms\": 9239.055, \"total_train_time_s\": 11.517311096191406}", "{\"n\": 5514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.12, \"learn_time_ms\": 9217.978, \"total_train_time_s\": 10.56835412979126}", "{\"n\": 5515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.42, \"learn_time_ms\": 9245.027, \"total_train_time_s\": 10.559749841690063}", "{\"n\": 5516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.42, \"learn_time_ms\": 9344.226, \"total_train_time_s\": 9.722749710083008}", "{\"n\": 5517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.25, \"learn_time_ms\": 9283.3, \"total_train_time_s\": 9.689829111099243}", "{\"n\": 5518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.33, \"learn_time_ms\": 9189.224, \"total_train_time_s\": 10.614289045333862}", "{\"n\": 5519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.33, \"learn_time_ms\": 9100.569, \"total_train_time_s\": 11.185759782791138}", "{\"n\": 5520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.95, \"learn_time_ms\": 9167.568, \"total_train_time_s\": 10.76860761642456}", "{\"n\": 5521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.82, \"learn_time_ms\": 9094.427, \"total_train_time_s\": 10.25272798538208}", "{\"n\": 5522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.82, \"learn_time_ms\": 9098.377, \"total_train_time_s\": 10.262341499328613}", "{\"n\": 5523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.82, \"learn_time_ms\": 9043.234, \"total_train_time_s\": 10.981920957565308}", "{\"n\": 5524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.2, \"learn_time_ms\": 9177.053, \"total_train_time_s\": 11.9486563205719}", "{\"n\": 5525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.2, \"learn_time_ms\": 9116.866, \"total_train_time_s\": 10.004769086837769}", "{\"n\": 5526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.2, \"learn_time_ms\": 9252.301, \"total_train_time_s\": 11.104720115661621}", "{\"n\": 5527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.84, \"learn_time_ms\": 9241.197, \"total_train_time_s\": 9.625246286392212}", "{\"n\": 5528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.93, \"learn_time_ms\": 9189.996, \"total_train_time_s\": 10.030431270599365}", "{\"n\": 5529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.93, \"learn_time_ms\": 9134.545, \"total_train_time_s\": 10.65704894065857}", "{\"n\": 5530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.25, \"learn_time_ms\": 8974.467, \"total_train_time_s\": 9.223530292510986}", "{\"n\": 5531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.95, \"learn_time_ms\": 8896.34, \"total_train_time_s\": 9.444114446640015}", "{\"n\": 5532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.95, \"learn_time_ms\": 8925.415, \"total_train_time_s\": 10.528881788253784}", "{\"n\": 5533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.92, \"learn_time_ms\": 8806.522, \"total_train_time_s\": 9.796030044555664}", "{\"n\": 5534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.78, \"learn_time_ms\": 8738.119, \"total_train_time_s\": 11.21821403503418}", "{\"n\": 5535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.78, \"learn_time_ms\": 8739.757, \"total_train_time_s\": 9.964187860488892}", "{\"n\": 5536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.09, \"learn_time_ms\": 8677.675, \"total_train_time_s\": 10.44295358657837}", "{\"n\": 5537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.54, \"learn_time_ms\": 8750.757, \"total_train_time_s\": 10.350291013717651}", "{\"n\": 5538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.54, \"learn_time_ms\": 8675.888, \"total_train_time_s\": 9.262828826904297}", "{\"n\": 5539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.49, \"learn_time_ms\": 8556.69, \"total_train_time_s\": 9.496508598327637}", "{\"n\": 5540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.38, \"learn_time_ms\": 8717.478, \"total_train_time_s\": 10.752673387527466}", "{\"n\": 5541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.38, \"learn_time_ms\": 8737.74, \"total_train_time_s\": 9.6717848777771}", "{\"n\": 5542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.38, \"learn_time_ms\": 8723.955, \"total_train_time_s\": 10.345258712768555}", "{\"n\": 5543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.64, \"learn_time_ms\": 8773.607, \"total_train_time_s\": 10.31639313697815}", "{\"n\": 5544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.64, \"learn_time_ms\": 8774.955, \"total_train_time_s\": 11.221872329711914}", "{\"n\": 5545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.64, \"learn_time_ms\": 8902.262, \"total_train_time_s\": 11.269859313964844}", "{\"n\": 5546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.06, \"learn_time_ms\": 8820.976, \"total_train_time_s\": 9.60629940032959}", "{\"n\": 5547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.54, \"learn_time_ms\": 8815.337, \"total_train_time_s\": 10.290412425994873}", "{\"n\": 5548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.54, \"learn_time_ms\": 8840.47, \"total_train_time_s\": 9.521159887313843}", "{\"n\": 5549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.75, \"learn_time_ms\": 8901.461, \"total_train_time_s\": 10.117412805557251}", "{\"n\": 5550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.61, \"learn_time_ms\": 8824.142, \"total_train_time_s\": 10.003834009170532}", "{\"n\": 5551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.61, \"learn_time_ms\": 8927.511, \"total_train_time_s\": 10.709838628768921}", "{\"n\": 5552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.61, \"learn_time_ms\": 9057.083, \"total_train_time_s\": 11.738439559936523}", "{\"n\": 5553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.65, \"learn_time_ms\": 9094.117, \"total_train_time_s\": 10.705339431762695}", "{\"n\": 5554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.0, \"learn_time_ms\": 9015.736, \"total_train_time_s\": 10.436387538909912}", "{\"n\": 5555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.0, \"learn_time_ms\": 8738.853, \"total_train_time_s\": 8.486841440200806}", "{\"n\": 5556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.22, \"learn_time_ms\": 8709.924, \"total_train_time_s\": 9.356299638748169}", "{\"n\": 5557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.85, \"learn_time_ms\": 8791.701, \"total_train_time_s\": 11.088060140609741}", "{\"n\": 5558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.85, \"learn_time_ms\": 9013.585, \"total_train_time_s\": 11.77417254447937}", "{\"n\": 5559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.59, \"learn_time_ms\": 8977.508, \"total_train_time_s\": 9.731820583343506}", "{\"n\": 5560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.49, \"learn_time_ms\": 8995.531, \"total_train_time_s\": 10.198783874511719}", "{\"n\": 5561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.49, \"learn_time_ms\": 8940.165, \"total_train_time_s\": 10.147485733032227}", "{\"n\": 5562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.86, \"learn_time_ms\": 8814.354, \"total_train_time_s\": 10.408518552780151}", "{\"n\": 5563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.65, \"learn_time_ms\": 8707.355, \"total_train_time_s\": 9.672298908233643}", "{\"n\": 5564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.65, \"learn_time_ms\": 8732.891, \"total_train_time_s\": 10.73726773262024}", "{\"n\": 5565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.73, \"learn_time_ms\": 8806.991, \"total_train_time_s\": 9.203341245651245}", "{\"n\": 5566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.82, \"learn_time_ms\": 8847.672, \"total_train_time_s\": 9.736641883850098}", "{\"n\": 5567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.88, \"learn_time_ms\": 8878.835, \"total_train_time_s\": 11.434633255004883}", "{\"n\": 5568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.25, \"learn_time_ms\": 8794.218, \"total_train_time_s\": 10.920398473739624}", "{\"n\": 5569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.53, \"learn_time_ms\": 8778.097, \"total_train_time_s\": 9.53764295578003}", "{\"n\": 5570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.95, \"learn_time_ms\": 8813.243, \"total_train_time_s\": 10.545357942581177}", "{\"n\": 5571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.95, \"learn_time_ms\": 8744.9, \"total_train_time_s\": 9.463215112686157}", "{\"n\": 5572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.92, \"learn_time_ms\": 8786.813, \"total_train_time_s\": 10.84598422050476}", "{\"n\": 5573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.29, \"learn_time_ms\": 8940.705, \"total_train_time_s\": 11.158557891845703}", "{\"n\": 5574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.29, \"learn_time_ms\": 8863.482, \"total_train_time_s\": 9.913939476013184}", "{\"n\": 5575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.29, \"learn_time_ms\": 8912.401, \"total_train_time_s\": 9.699547529220581}", "{\"n\": 5576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.74, \"learn_time_ms\": 8983.206, \"total_train_time_s\": 10.495399236679077}", "{\"n\": 5577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.05, \"learn_time_ms\": 8855.014, \"total_train_time_s\": 10.119717597961426}", "{\"n\": 5578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.05, \"learn_time_ms\": 8747.531, \"total_train_time_s\": 9.793713569641113}", "{\"n\": 5579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.55, \"learn_time_ms\": 8764.42, \"total_train_time_s\": 9.701214790344238}", "{\"n\": 5580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 8758.8, \"total_train_time_s\": 10.476554870605469}", "{\"n\": 5581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.55, \"learn_time_ms\": 8768.338, \"total_train_time_s\": 9.532487392425537}", "{\"n\": 5582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.12, \"learn_time_ms\": 8666.584, \"total_train_time_s\": 9.882933378219604}", "{\"n\": 5583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.82, \"learn_time_ms\": 8662.315, \"total_train_time_s\": 11.112964630126953}", "{\"n\": 5584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.82, \"learn_time_ms\": 8705.852, \"total_train_time_s\": 10.395263195037842}", "{\"n\": 5585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.12, \"learn_time_ms\": 8746.991, \"total_train_time_s\": 10.116281509399414}", "{\"n\": 5586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.92, \"learn_time_ms\": 8583.649, \"total_train_time_s\": 8.858473300933838}", "{\"n\": 5587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.16, \"learn_time_ms\": 8626.684, \"total_train_time_s\": 10.6005380153656}", "{\"n\": 5588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.16, \"learn_time_ms\": 8757.883, \"total_train_time_s\": 11.120396375656128}", "{\"n\": 5589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.26, \"learn_time_ms\": 8781.794, \"total_train_time_s\": 10.012056589126587}", "{\"n\": 5590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.97, \"learn_time_ms\": 8712.371, \"total_train_time_s\": 9.791343927383423}", "{\"n\": 5591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.97, \"learn_time_ms\": 8734.636, \"total_train_time_s\": 9.764105081558228}", "{\"n\": 5592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.04, \"learn_time_ms\": 8744.71, \"total_train_time_s\": 9.92293930053711}", "{\"n\": 5593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.44, \"learn_time_ms\": 8521.166, \"total_train_time_s\": 8.87410593032837}", "{\"n\": 5594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.74, \"learn_time_ms\": 8450.304, \"total_train_time_s\": 9.655160903930664}", "{\"n\": 5595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.28, \"learn_time_ms\": 8441.258, \"total_train_time_s\": 9.998483657836914}", "{\"n\": 5596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.53, \"learn_time_ms\": 8546.025, \"total_train_time_s\": 9.877992630004883}", "{\"n\": 5597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.04, \"learn_time_ms\": 8459.171, \"total_train_time_s\": 9.720126628875732}", "{\"n\": 5598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.2, \"learn_time_ms\": 8404.263, \"total_train_time_s\": 10.66817331314087}", "{\"n\": 5599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.85, \"learn_time_ms\": 8440.984, \"total_train_time_s\": 10.327301502227783}", "{\"n\": 5600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.48, \"learn_time_ms\": 8433.781, \"total_train_time_s\": 9.68995976448059}", "{\"n\": 5601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.0, \"learn_time_ms\": 8505.508, \"total_train_time_s\": 10.473218441009521}", "{\"n\": 5602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.13, \"learn_time_ms\": 8633.261, \"total_train_time_s\": 11.243056774139404}", "{\"n\": 5603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.61, \"learn_time_ms\": 8795.744, \"total_train_time_s\": 10.488880634307861}", "{\"n\": 5604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.0, \"learn_time_ms\": 8853.115, \"total_train_time_s\": 10.261003017425537}", "{\"n\": 5605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.0, \"learn_time_ms\": 8845.476, \"total_train_time_s\": 9.990394592285156}", "{\"n\": 5606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.06, \"learn_time_ms\": 8882.955, \"total_train_time_s\": 10.232373237609863}", "{\"n\": 5607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.98, \"learn_time_ms\": 8886.168, \"total_train_time_s\": 9.725853204727173}", "{\"n\": 5608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.98, \"learn_time_ms\": 8841.972, \"total_train_time_s\": 10.150709390640259}", "{\"n\": 5609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.49, \"learn_time_ms\": 8844.431, \"total_train_time_s\": 10.396891593933105}", "{\"n\": 5610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.76, \"learn_time_ms\": 8790.59, \"total_train_time_s\": 9.148892641067505}", "{\"n\": 5611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.76, \"learn_time_ms\": 8662.745, \"total_train_time_s\": 9.236635208129883}", "{\"n\": 5612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.1, \"learn_time_ms\": 8695.576, \"total_train_time_s\": 11.541405439376831}", "{\"n\": 5613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.36, \"learn_time_ms\": 8760.485, \"total_train_time_s\": 11.115617752075195}", "{\"n\": 5614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.36, \"learn_time_ms\": 8744.446, \"total_train_time_s\": 10.081987380981445}", "{\"n\": 5615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.29, \"learn_time_ms\": 8765.456, \"total_train_time_s\": 10.161765813827515}", "{\"n\": 5616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.1, \"learn_time_ms\": 8709.948, \"total_train_time_s\": 9.739304542541504}", "{\"n\": 5617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.1, \"learn_time_ms\": 8835.37, \"total_train_time_s\": 10.958124160766602}", "{\"n\": 5618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.1, \"learn_time_ms\": 8985.047, \"total_train_time_s\": 11.685550689697266}", "{\"n\": 5619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.22, \"learn_time_ms\": 9015.619, \"total_train_time_s\": 10.669660091400146}", "{\"n\": 5620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.22, \"learn_time_ms\": 9296.451, \"total_train_time_s\": 11.988009691238403}", "{\"n\": 5621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.22, \"learn_time_ms\": 9348.936, \"total_train_time_s\": 9.721149206161499}", "{\"n\": 5622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.02, \"learn_time_ms\": 9253.578, \"total_train_time_s\": 10.627474784851074}", "{\"n\": 5623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.24, \"learn_time_ms\": 9060.598, \"total_train_time_s\": 9.209653854370117}", "{\"n\": 5624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.24, \"learn_time_ms\": 9032.791, \"total_train_time_s\": 9.809634685516357}", "{\"n\": 5625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.0, \"learn_time_ms\": 9062.651, \"total_train_time_s\": 10.501873016357422}", "{\"n\": 5626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.99, \"learn_time_ms\": 9167.012, \"total_train_time_s\": 10.816290140151978}", "{\"n\": 5627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.99, \"learn_time_ms\": 9110.959, \"total_train_time_s\": 10.402966976165771}", "{\"n\": 5628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.17, \"learn_time_ms\": 8909.24, \"total_train_time_s\": 9.638769388198853}", "{\"n\": 5629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.43, \"learn_time_ms\": 9078.334, \"total_train_time_s\": 12.361552476882935}", "{\"n\": 5630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.55, \"learn_time_ms\": 8823.966, \"total_train_time_s\": 9.430449485778809}", "{\"n\": 5631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.55, \"learn_time_ms\": 8892.074, \"total_train_time_s\": 10.472639560699463}", "{\"n\": 5632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.57, \"learn_time_ms\": 8791.614, \"total_train_time_s\": 9.642727851867676}", "{\"n\": 5633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.78, \"learn_time_ms\": 8826.191, \"total_train_time_s\": 9.569095134735107}", "{\"n\": 5634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.78, \"learn_time_ms\": 8783.652, \"total_train_time_s\": 9.373878002166748}", "{\"n\": 5635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 8929.64, \"total_train_time_s\": 11.885672092437744}", "{\"n\": 5636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 9002.291, \"total_train_time_s\": 11.48546838760376}", "{\"n\": 5637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.48, \"learn_time_ms\": 8970.492, \"total_train_time_s\": 10.080440282821655}", "{\"n\": 5638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.04, \"learn_time_ms\": 9092.593, \"total_train_time_s\": 10.86311149597168}", "{\"n\": 5639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.36, \"learn_time_ms\": 8909.408, \"total_train_time_s\": 10.504875659942627}", "{\"n\": 5640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.97, \"learn_time_ms\": 8907.037, \"total_train_time_s\": 9.443589448928833}", "{\"n\": 5641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.55, \"learn_time_ms\": 8755.276, \"total_train_time_s\": 8.94196605682373}", "{\"n\": 5642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.61, \"learn_time_ms\": 8769.44, \"total_train_time_s\": 9.739043474197388}", "{\"n\": 5643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.61, \"learn_time_ms\": 8873.958, \"total_train_time_s\": 10.577207803726196}", "{\"n\": 5644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.37, \"learn_time_ms\": 9104.664, \"total_train_time_s\": 11.657906293869019}", "{\"n\": 5645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.07, \"learn_time_ms\": 8982.226, \"total_train_time_s\": 10.751346588134766}", "{\"n\": 5646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.07, \"learn_time_ms\": 8893.689, \"total_train_time_s\": 10.60128140449524}", "{\"n\": 5647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3275.77, \"learn_time_ms\": 8917.367, \"total_train_time_s\": 10.335254907608032}", "{\"n\": 5648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.06, \"learn_time_ms\": 8999.902, \"total_train_time_s\": 11.688871622085571}", "{\"n\": 5649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.06, \"learn_time_ms\": 8864.447, \"total_train_time_s\": 9.146134376525879}", "{\"n\": 5650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.83, \"learn_time_ms\": 8918.405, \"total_train_time_s\": 9.979035377502441}", "{\"n\": 5651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.26, \"learn_time_ms\": 9019.401, \"total_train_time_s\": 9.896186590194702}", "{\"n\": 5652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.26, \"learn_time_ms\": 9007.091, \"total_train_time_s\": 9.6039719581604}", "{\"n\": 5653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3285.52, \"learn_time_ms\": 9054.618, \"total_train_time_s\": 11.036858797073364}", "{\"n\": 5654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.82, \"learn_time_ms\": 8872.456, \"total_train_time_s\": 9.840070009231567}", "{\"n\": 5655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 8801.432, \"total_train_time_s\": 9.975633382797241}", "{\"n\": 5656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.17, \"learn_time_ms\": 8728.325, \"total_train_time_s\": 9.845126390457153}", "{\"n\": 5657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3270.35, \"learn_time_ms\": 8697.719, \"total_train_time_s\": 10.060377836227417}", "{\"n\": 5658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.78, \"learn_time_ms\": 8438.56, \"total_train_time_s\": 9.08362364768982}", "{\"n\": 5659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3270.79, \"learn_time_ms\": 8619.958, \"total_train_time_s\": 10.993512153625488}", "{\"n\": 5660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.11, \"learn_time_ms\": 8580.193, \"total_train_time_s\": 9.584709644317627}", "{\"n\": 5661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.11, \"learn_time_ms\": 8618.097, \"total_train_time_s\": 10.277013778686523}", "{\"n\": 5662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.51, \"learn_time_ms\": 8792.506, \"total_train_time_s\": 11.338005065917969}", "{\"n\": 5663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.03, \"learn_time_ms\": 8564.334, \"total_train_time_s\": 8.755540370941162}", "{\"n\": 5664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.64, \"learn_time_ms\": 8571.578, \"total_train_time_s\": 9.951568126678467}", "{\"n\": 5665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.64, \"learn_time_ms\": 8609.265, \"total_train_time_s\": 10.350903034210205}", "{\"n\": 5666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.45, \"learn_time_ms\": 8573.912, \"total_train_time_s\": 9.538994312286377}", "{\"n\": 5667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.03, \"learn_time_ms\": 8588.132, \"total_train_time_s\": 10.194917917251587}", "{\"n\": 5668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.03, \"learn_time_ms\": 8655.998, \"total_train_time_s\": 9.744472980499268}", "{\"n\": 5669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3259.97, \"learn_time_ms\": 8755.898, \"total_train_time_s\": 12.033834218978882}", "{\"n\": 5670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3269.19, \"learn_time_ms\": 8844.491, \"total_train_time_s\": 10.476371049880981}", "{\"n\": 5671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3269.19, \"learn_time_ms\": 8798.112, \"total_train_time_s\": 9.82526183128357}", "{\"n\": 5672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3269.53, \"learn_time_ms\": 8651.721, \"total_train_time_s\": 9.896660089492798}", "{\"n\": 5673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.24, \"learn_time_ms\": 8713.562, \"total_train_time_s\": 9.43628478050232}", "{\"n\": 5674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3265.83, \"learn_time_ms\": 8645.554, \"total_train_time_s\": 9.264834642410278}", "{\"n\": 5675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3263.09, \"learn_time_ms\": 8652.779, \"total_train_time_s\": 10.483206510543823}", "{\"n\": 5676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3260.54, \"learn_time_ms\": 8756.489, \"total_train_time_s\": 10.520451307296753}", "{\"n\": 5677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.16, \"learn_time_ms\": 8794.921, \"total_train_time_s\": 10.564706087112427}", "{\"n\": 5678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3266.54, \"learn_time_ms\": 8930.866, \"total_train_time_s\": 11.14689564704895}", "{\"n\": 5679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3266.54, \"learn_time_ms\": 8777.324, \"total_train_time_s\": 10.432060718536377}", "{\"n\": 5680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3277.28, \"learn_time_ms\": 8759.549, \"total_train_time_s\": 10.291422367095947}", "{\"n\": 5681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3277.28, \"learn_time_ms\": 8763.131, \"total_train_time_s\": 9.856986045837402}", "{\"n\": 5682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3275.6, \"learn_time_ms\": 8913.662, \"total_train_time_s\": 11.386257648468018}", "{\"n\": 5683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.61, \"learn_time_ms\": 9062.702, \"total_train_time_s\": 10.920036792755127}", "{\"n\": 5684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.56, \"learn_time_ms\": 9252.559, \"total_train_time_s\": 11.18345046043396}", "{\"n\": 5685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3268.3, \"learn_time_ms\": 9307.955, \"total_train_time_s\": 11.044012784957886}", "{\"n\": 5686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.53, \"learn_time_ms\": 9267.956, \"total_train_time_s\": 10.183764696121216}", "{\"n\": 5687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.6, \"learn_time_ms\": 9091.827, \"total_train_time_s\": 8.82049298286438}", "{\"n\": 5688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 8887.84, \"total_train_time_s\": 9.103517532348633}", "{\"n\": 5689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.6, \"learn_time_ms\": 8881.822, \"total_train_time_s\": 10.37459135055542}", "{\"n\": 5690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.42, \"learn_time_ms\": 8817.516, \"total_train_time_s\": 9.69180965423584}", "{\"n\": 5691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.5, \"learn_time_ms\": 8864.098, \"total_train_time_s\": 10.370965003967285}", "{\"n\": 5692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.5, \"learn_time_ms\": 8892.285, \"total_train_time_s\": 11.674501657485962}", "{\"n\": 5693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.77, \"learn_time_ms\": 8864.357, \"total_train_time_s\": 10.632914781570435}", "{\"n\": 5694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.88, \"learn_time_ms\": 8803.37, \"total_train_time_s\": 10.567225933074951}", "{\"n\": 5695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.88, \"learn_time_ms\": 8643.9, \"total_train_time_s\": 9.408632278442383}", "{\"n\": 5696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3277.37, \"learn_time_ms\": 8598.672, \"total_train_time_s\": 9.712678909301758}", "{\"n\": 5697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.78, \"learn_time_ms\": 8886.308, \"total_train_time_s\": 11.674489259719849}", "{\"n\": 5698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.78, \"learn_time_ms\": 9056.313, \"total_train_time_s\": 10.815012216567993}", "{\"n\": 5699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3275.66, \"learn_time_ms\": 9275.185, \"total_train_time_s\": 12.588691711425781}", "{\"n\": 5700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.34, \"learn_time_ms\": 9268.93, \"total_train_time_s\": 9.529791593551636}", "{\"n\": 5701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.96, \"learn_time_ms\": 9248.926, \"total_train_time_s\": 10.140785932540894}", "{\"n\": 5702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.96, \"learn_time_ms\": 9016.541, \"total_train_time_s\": 9.382134437561035}", "{\"n\": 5703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.6, \"learn_time_ms\": 9006.423, \"total_train_time_s\": 10.541685819625854}", "{\"n\": 5704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.81, \"learn_time_ms\": 8870.8, \"total_train_time_s\": 9.201703548431396}", "{\"n\": 5705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.81, \"learn_time_ms\": 8957.608, \"total_train_time_s\": 10.235122680664062}", "{\"n\": 5706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3288.55, \"learn_time_ms\": 9019.461, \"total_train_time_s\": 10.36100149154663}", "{\"n\": 5707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.56, \"learn_time_ms\": 8916.542, \"total_train_time_s\": 10.627961158752441}", "{\"n\": 5708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.56, \"learn_time_ms\": 8797.668, \"total_train_time_s\": 9.602307558059692}", "{\"n\": 5709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.41, \"learn_time_ms\": 8565.681, \"total_train_time_s\": 10.23671817779541}", "{\"n\": 5710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.17, \"learn_time_ms\": 8719.808, \"total_train_time_s\": 11.116870641708374}", "{\"n\": 5711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.04, \"learn_time_ms\": 8713.563, \"total_train_time_s\": 10.082897663116455}", "{\"n\": 5712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.58, \"learn_time_ms\": 8693.231, \"total_train_time_s\": 9.15699315071106}", "{\"n\": 5713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3277.53, \"learn_time_ms\": 8681.082, \"total_train_time_s\": 10.433411121368408}", "{\"n\": 5714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3284.01, \"learn_time_ms\": 8734.854, \"total_train_time_s\": 9.73082709312439}", "{\"n\": 5715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3280.37, \"learn_time_ms\": 8571.583, \"total_train_time_s\": 8.64759349822998}", "{\"n\": 5716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.7, \"learn_time_ms\": 8550.011, \"total_train_time_s\": 10.083165407180786}", "{\"n\": 5717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.7, \"learn_time_ms\": 8536.847, \"total_train_time_s\": 10.500924348831177}", "{\"n\": 5718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.48, \"learn_time_ms\": 8604.365, \"total_train_time_s\": 10.29671025276184}", "{\"n\": 5719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.98, \"learn_time_ms\": 8689.158, \"total_train_time_s\": 11.101200103759766}", "{\"n\": 5720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.98, \"learn_time_ms\": 8721.48, \"total_train_time_s\": 11.380818128585815}", "{\"n\": 5721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.67, \"learn_time_ms\": 8649.973, \"total_train_time_s\": 9.362576007843018}", "{\"n\": 5722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.03, \"learn_time_ms\": 8754.038, \"total_train_time_s\": 10.204237937927246}", "{\"n\": 5723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.03, \"learn_time_ms\": 8649.818, \"total_train_time_s\": 9.36893367767334}", "{\"n\": 5724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.03, \"learn_time_ms\": 8600.564, \"total_train_time_s\": 9.205349683761597}", "{\"n\": 5725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.93, \"learn_time_ms\": 8742.049, \"total_train_time_s\": 10.077073812484741}", "{\"n\": 5726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.93, \"learn_time_ms\": 8843.461, \"total_train_time_s\": 11.094895124435425}", "{\"n\": 5727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.93, \"learn_time_ms\": 8776.913, \"total_train_time_s\": 9.824823379516602}", "{\"n\": 5728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.72, \"learn_time_ms\": 8815.055, \"total_train_time_s\": 10.665398597717285}", "{\"n\": 5729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.28, \"learn_time_ms\": 8823.767, \"total_train_time_s\": 11.160427570343018}", "{\"n\": 5730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.28, \"learn_time_ms\": 8737.824, \"total_train_time_s\": 10.566747188568115}", "{\"n\": 5731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.89, \"learn_time_ms\": 8928.864, \"total_train_time_s\": 11.311053276062012}", "{\"n\": 5732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.29, \"learn_time_ms\": 8919.006, \"total_train_time_s\": 10.10427451133728}", "{\"n\": 5733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.29, \"learn_time_ms\": 8950.956, \"total_train_time_s\": 9.829965114593506}", "{\"n\": 5734, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3262.88, \"learn_time_ms\": 8844.435, \"total_train_time_s\": 8.184579849243164}", "{\"n\": 5735, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.06, \"learn_time_ms\": 8897.2, \"total_train_time_s\": 10.57692551612854}", "{\"n\": 5736, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.06, \"learn_time_ms\": 8845.625, \"total_train_time_s\": 10.64001750946045}", "{\"n\": 5737, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3263.14, \"learn_time_ms\": 9030.268, \"total_train_time_s\": 11.742503881454468}", "{\"n\": 5738, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.09, \"learn_time_ms\": 9027.541, \"total_train_time_s\": 10.673773288726807}", "{\"n\": 5739, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.09, \"learn_time_ms\": 8966.437, \"total_train_time_s\": 10.635199069976807}", "{\"n\": 5740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.09, \"learn_time_ms\": 8889.634, \"total_train_time_s\": 9.831906080245972}", "{\"n\": 5741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.22, \"learn_time_ms\": 8832.877, \"total_train_time_s\": 10.699289321899414}", "{\"n\": 5742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.22, \"learn_time_ms\": 8993.274, \"total_train_time_s\": 11.714713096618652}", "{\"n\": 5743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.22, \"learn_time_ms\": 9044.344, \"total_train_time_s\": 10.167343139648438}", "{\"n\": 5744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.96, \"learn_time_ms\": 9225.612, \"total_train_time_s\": 10.011981010437012}", "{\"n\": 5745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.96, \"learn_time_ms\": 9208.187, \"total_train_time_s\": 10.454020738601685}", "{\"n\": 5746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.96, \"learn_time_ms\": 9132.787, \"total_train_time_s\": 9.869048357009888}", "{\"n\": 5747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.04, \"learn_time_ms\": 9155.017, \"total_train_time_s\": 11.911123752593994}", "{\"n\": 5748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.04, \"learn_time_ms\": 9107.703, \"total_train_time_s\": 10.150490999221802}", "{\"n\": 5749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.04, \"learn_time_ms\": 9003.008, \"total_train_time_s\": 9.535050630569458}", "{\"n\": 5750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3259.83, \"learn_time_ms\": 9086.683, \"total_train_time_s\": 10.647046327590942}", "{\"n\": 5751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.58, \"learn_time_ms\": 9094.94, \"total_train_time_s\": 10.819949865341187}", "{\"n\": 5752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.58, \"learn_time_ms\": 8901.421, \"total_train_time_s\": 9.744533777236938}", "{\"n\": 5753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3243.75, \"learn_time_ms\": 8852.137, \"total_train_time_s\": 9.719831705093384}", "{\"n\": 5754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.16, \"learn_time_ms\": 8864.214, \"total_train_time_s\": 10.076703310012817}", "{\"n\": 5755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.16, \"learn_time_ms\": 8749.043, \"total_train_time_s\": 9.204473972320557}", "{\"n\": 5756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.13, \"learn_time_ms\": 8793.603, \"total_train_time_s\": 10.293683052062988}", "{\"n\": 5757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.25, \"learn_time_ms\": 8654.845, \"total_train_time_s\": 10.586944103240967}", "{\"n\": 5758, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.25, \"learn_time_ms\": 8780.847, \"total_train_time_s\": 11.407667398452759}", "{\"n\": 5759, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.43, \"learn_time_ms\": 8994.553, \"total_train_time_s\": 11.664146423339844}", "{\"n\": 5760, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.51, \"learn_time_ms\": 8976.165, \"total_train_time_s\": 10.509926319122314}", "{\"n\": 5761, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.39, \"learn_time_ms\": 9053.569, \"total_train_time_s\": 11.574137687683105}", "{\"n\": 5762, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.29, \"learn_time_ms\": 9117.331, \"total_train_time_s\": 10.389594078063965}", "{\"n\": 5763, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.83, \"learn_time_ms\": 9260.445, \"total_train_time_s\": 11.157058954238892}", "{\"n\": 5764, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.8, \"learn_time_ms\": 9226.336, \"total_train_time_s\": 9.723693370819092}", "{\"n\": 5765, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.69, \"learn_time_ms\": 9314.075, \"total_train_time_s\": 10.132042646408081}", "{\"n\": 5766, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.0, \"learn_time_ms\": 9327.372, \"total_train_time_s\": 10.454431056976318}", "{\"n\": 5767, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.93, \"learn_time_ms\": 9316.256, \"total_train_time_s\": 10.408493518829346}", "{\"n\": 5768, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.93, \"learn_time_ms\": 9100.555, \"total_train_time_s\": 9.2899169921875}", "{\"n\": 5769, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.48, \"learn_time_ms\": 8997.817, \"total_train_time_s\": 10.645320177078247}", "{\"n\": 5770, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.3, \"learn_time_ms\": 8889.659, \"total_train_time_s\": 9.43494701385498}", "{\"n\": 5771, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3208.3, \"learn_time_ms\": 8743.955, \"total_train_time_s\": 10.101644515991211}", "{\"n\": 5772, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.07, \"learn_time_ms\": 8691.211, \"total_train_time_s\": 9.86116909980774}", "{\"n\": 5773, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.87, \"learn_time_ms\": 8580.831, \"total_train_time_s\": 10.044564962387085}", "{\"n\": 5774, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.87, \"learn_time_ms\": 8540.102, \"total_train_time_s\": 9.340440511703491}", "{\"n\": 5775, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.01, \"learn_time_ms\": 8484.074, \"total_train_time_s\": 9.556989192962646}", "{\"n\": 5776, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.01, \"learn_time_ms\": 8414.309, \"total_train_time_s\": 9.720193862915039}", "{\"n\": 5777, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.84, \"learn_time_ms\": 8285.632, \"total_train_time_s\": 9.125118255615234}", "{\"n\": 5778, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.84, \"learn_time_ms\": 8441.88, \"total_train_time_s\": 10.795531272888184}", "{\"n\": 5779, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.35, \"learn_time_ms\": 8310.193, \"total_train_time_s\": 9.322682619094849}", "{\"n\": 5780, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.35, \"learn_time_ms\": 8333.725, \"total_train_time_s\": 9.564636707305908}", "{\"n\": 5781, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.35, \"learn_time_ms\": 8370.874, \"total_train_time_s\": 10.440080642700195}", "{\"n\": 5782, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.75, \"learn_time_ms\": 8365.478, \"total_train_time_s\": 9.767404794692993}", "{\"n\": 5783, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.21, \"learn_time_ms\": 8298.594, \"total_train_time_s\": 9.37982177734375}", "{\"n\": 5784, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.21, \"learn_time_ms\": 8315.05, \"total_train_time_s\": 9.510801076889038}", "{\"n\": 5785, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.26, \"learn_time_ms\": 8562.213, \"total_train_time_s\": 12.064131498336792}", "{\"n\": 5786, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.05, \"learn_time_ms\": 8640.154, \"total_train_time_s\": 10.516281127929688}", "{\"n\": 5787, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.05, \"learn_time_ms\": 8746.969, \"total_train_time_s\": 10.189834594726562}", "{\"n\": 5788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.87, \"learn_time_ms\": 8755.54, \"total_train_time_s\": 10.970172882080078}", "{\"n\": 5789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.85, \"learn_time_ms\": 8732.184, \"total_train_time_s\": 9.112051248550415}", "{\"n\": 5790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.15, \"learn_time_ms\": 8680.83, \"total_train_time_s\": 9.101126194000244}", "{\"n\": 5791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.15, \"learn_time_ms\": 8708.793, \"total_train_time_s\": 10.76787257194519}", "{\"n\": 5792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.43, \"learn_time_ms\": 8735.167, \"total_train_time_s\": 10.083016633987427}", "{\"n\": 5793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.92, \"learn_time_ms\": 8779.846, \"total_train_time_s\": 9.804235219955444}", "{\"n\": 5794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.92, \"learn_time_ms\": 8703.815, \"total_train_time_s\": 8.713408946990967}", "{\"n\": 5795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.36, \"learn_time_ms\": 8348.814, \"total_train_time_s\": 8.48775315284729}", "{\"n\": 5796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.49, \"learn_time_ms\": 8177.614, \"total_train_time_s\": 8.816906929016113}", "{\"n\": 5797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.46, \"learn_time_ms\": 8228.859, \"total_train_time_s\": 10.778334140777588}", "{\"n\": 5798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3227.02, \"learn_time_ms\": 8180.077, \"total_train_time_s\": 10.469297170639038}", "{\"n\": 5799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.86, \"learn_time_ms\": 8332.788, \"total_train_time_s\": 10.625499248504639}", "{\"n\": 5800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.68, \"learn_time_ms\": 8386.066, \"total_train_time_s\": 9.601857662200928}", "{\"n\": 5801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.28, \"learn_time_ms\": 8265.837, \"total_train_time_s\": 9.539812564849854}", "{\"n\": 5802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.86, \"learn_time_ms\": 8223.397, \"total_train_time_s\": 9.654864072799683}", "{\"n\": 5803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.14, \"learn_time_ms\": 8201.427, \"total_train_time_s\": 9.608201503753662}", "{\"n\": 5804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.33, \"learn_time_ms\": 8360.514, \"total_train_time_s\": 10.351828336715698}", "{\"n\": 5805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.94, \"learn_time_ms\": 8576.987, \"total_train_time_s\": 10.64693021774292}", "{\"n\": 5806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.91, \"learn_time_ms\": 8704.637, \"total_train_time_s\": 10.04055142402649}", "{\"n\": 5807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.22, \"learn_time_ms\": 8540.482, \"total_train_time_s\": 9.07661247253418}", "{\"n\": 5808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.75, \"learn_time_ms\": 8529.94, \"total_train_time_s\": 10.321328163146973}", "{\"n\": 5809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3195.52, \"learn_time_ms\": 8539.766, \"total_train_time_s\": 10.703064203262329}", "{\"n\": 5810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.9, \"learn_time_ms\": 8600.445, \"total_train_time_s\": 10.263933897018433}", "{\"n\": 5811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.76, \"learn_time_ms\": 8721.953, \"total_train_time_s\": 10.72532844543457}", "{\"n\": 5812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.76, \"learn_time_ms\": 8729.535, \"total_train_time_s\": 9.679890632629395}", "{\"n\": 5813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.86, \"learn_time_ms\": 8784.665, \"total_train_time_s\": 10.09455919265747}", "{\"n\": 5814, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.27, \"learn_time_ms\": 8807.092, \"total_train_time_s\": 10.579878568649292}", "{\"n\": 5815, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.27, \"learn_time_ms\": 8780.799, \"total_train_time_s\": 10.342905044555664}", "{\"n\": 5816, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.0, \"learn_time_ms\": 8733.116, \"total_train_time_s\": 9.54762887954712}", "{\"n\": 5817, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.4, \"learn_time_ms\": 8912.65, \"total_train_time_s\": 10.845908403396606}", "{\"n\": 5818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3214.48, \"learn_time_ms\": 8795.612, \"total_train_time_s\": 9.164520740509033}", "{\"n\": 5819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.98, \"learn_time_ms\": 8528.532, \"total_train_time_s\": 8.056785821914673}", "{\"n\": 5820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.0, \"learn_time_ms\": 8616.794, \"total_train_time_s\": 11.114682674407959}", "{\"n\": 5821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.13, \"learn_time_ms\": 8541.701, \"total_train_time_s\": 10.031692028045654}", "{\"n\": 5822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.69, \"learn_time_ms\": 8466.26, \"total_train_time_s\": 8.98668646812439}", "{\"n\": 5823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.4, \"learn_time_ms\": 8490.817, \"total_train_time_s\": 10.376062154769897}", "{\"n\": 5824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.22, \"learn_time_ms\": 8555.821, \"total_train_time_s\": 11.268798828125}", "{\"n\": 5825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.22, \"learn_time_ms\": 8372.331, \"total_train_time_s\": 8.57399582862854}", "{\"n\": 5826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.72, \"learn_time_ms\": 8453.475, \"total_train_time_s\": 10.440980434417725}", "{\"n\": 5827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.04, \"learn_time_ms\": 8392.947, \"total_train_time_s\": 10.231963872909546}", "{\"n\": 5828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.58, \"learn_time_ms\": 8527.788, \"total_train_time_s\": 10.532282829284668}", "{\"n\": 5829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.73, \"learn_time_ms\": 8787.756, \"total_train_time_s\": 10.685168981552124}", "{\"n\": 5830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.77, \"learn_time_ms\": 8611.617, \"total_train_time_s\": 9.31521725654602}", "{\"n\": 5831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.46, \"learn_time_ms\": 8612.791, \"total_train_time_s\": 9.995080947875977}", "{\"n\": 5832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.27, \"learn_time_ms\": 8868.79, \"total_train_time_s\": 11.53458309173584}", "{\"n\": 5833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8808.118, \"total_train_time_s\": 9.747714519500732}", "{\"n\": 5834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.76, \"learn_time_ms\": 8649.663, \"total_train_time_s\": 9.61607551574707}", "{\"n\": 5835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.63, \"learn_time_ms\": 8818.094, \"total_train_time_s\": 10.253556966781616}", "{\"n\": 5836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.63, \"learn_time_ms\": 8961.671, \"total_train_time_s\": 11.864704132080078}", "{\"n\": 5837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.35, \"learn_time_ms\": 8846.114, \"total_train_time_s\": 9.096020460128784}", "{\"n\": 5838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.86, \"learn_time_ms\": 8766.765, \"total_train_time_s\": 9.720586776733398}", "{\"n\": 5839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.37, \"learn_time_ms\": 8664.156, \"total_train_time_s\": 9.656185388565063}", "{\"n\": 5840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.86, \"learn_time_ms\": 8827.36, \"total_train_time_s\": 10.978602409362793}", "{\"n\": 5841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.07, \"learn_time_ms\": 8816.897, \"total_train_time_s\": 9.883194923400879}", "{\"n\": 5842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.9, \"learn_time_ms\": 8819.674, \"total_train_time_s\": 11.577844858169556}", "{\"n\": 5843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.2, \"learn_time_ms\": 8929.685, \"total_train_time_s\": 10.880437135696411}", "{\"n\": 5844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.98, \"learn_time_ms\": 9047.943, \"total_train_time_s\": 10.882879972457886}", "{\"n\": 5845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.98, \"learn_time_ms\": 9112.712, \"total_train_time_s\": 10.912686347961426}", "{\"n\": 5846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3233.34, \"learn_time_ms\": 8985.311, \"total_train_time_s\": 10.55253267288208}", "{\"n\": 5847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3232.49, \"learn_time_ms\": 9073.648, \"total_train_time_s\": 10.002464056015015}", "{\"n\": 5848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3228.78, \"learn_time_ms\": 9116.155, \"total_train_time_s\": 10.142453670501709}", "{\"n\": 5849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.51, \"learn_time_ms\": 9168.719, \"total_train_time_s\": 10.16701626777649}", "{\"n\": 5850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.07, \"learn_time_ms\": 9071.648, \"total_train_time_s\": 9.982940673828125}", "{\"n\": 5851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.38, \"learn_time_ms\": 8996.976, \"total_train_time_s\": 9.308216094970703}", "{\"n\": 5852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.92, \"learn_time_ms\": 8870.093, \"total_train_time_s\": 10.303159475326538}", "{\"n\": 5853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.92, \"learn_time_ms\": 8782.505, \"total_train_time_s\": 10.004631996154785}", "{\"n\": 5854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.65, \"learn_time_ms\": 8856.947, \"total_train_time_s\": 11.572806596755981}", "{\"n\": 5855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.6, \"learn_time_ms\": 8647.115, \"total_train_time_s\": 8.75214958190918}", "{\"n\": 5856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.77, \"learn_time_ms\": 8614.998, \"total_train_time_s\": 10.248015403747559}", "{\"n\": 5857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.29, \"learn_time_ms\": 8556.579, \"total_train_time_s\": 9.410557985305786}", "{\"n\": 5858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.99, \"learn_time_ms\": 8458.087, \"total_train_time_s\": 9.150989294052124}", "{\"n\": 5859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.67, \"learn_time_ms\": 8399.875, \"total_train_time_s\": 9.55071210861206}", "{\"n\": 5860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.35, \"learn_time_ms\": 8357.483, \"total_train_time_s\": 9.623336553573608}", "{\"n\": 5861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.16, \"learn_time_ms\": 8512.238, \"total_train_time_s\": 10.697775602340698}", "{\"n\": 5862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.29, \"learn_time_ms\": 8473.33, \"total_train_time_s\": 9.951492071151733}", "{\"n\": 5863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.45, \"learn_time_ms\": 8409.766, \"total_train_time_s\": 9.373450994491577}", "{\"n\": 5864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.45, \"learn_time_ms\": 8333.704, \"total_train_time_s\": 10.794057130813599}", "{\"n\": 5865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.82, \"learn_time_ms\": 8501.089, \"total_train_time_s\": 10.520503520965576}", "{\"n\": 5866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.53, \"learn_time_ms\": 8499.058, \"total_train_time_s\": 10.206346035003662}", "{\"n\": 5867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3191.19, \"learn_time_ms\": 8568.527, \"total_train_time_s\": 10.106907606124878}", "{\"n\": 5868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.62, \"learn_time_ms\": 8589.655, \"total_train_time_s\": 9.362857818603516}", "{\"n\": 5869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.62, \"learn_time_ms\": 8686.422, \"total_train_time_s\": 10.490035772323608}", "{\"n\": 5870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.64, \"learn_time_ms\": 8871.722, \"total_train_time_s\": 11.464003324508667}", "{\"n\": 5871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.64, \"learn_time_ms\": 8917.901, \"total_train_time_s\": 11.178747177124023}", "{\"n\": 5872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.56, \"learn_time_ms\": 9049.604, \"total_train_time_s\": 11.245196342468262}", "{\"n\": 5873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.04, \"learn_time_ms\": 9157.466, \"total_train_time_s\": 10.43044137954712}", "{\"n\": 5874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.04, \"learn_time_ms\": 9039.091, \"total_train_time_s\": 9.640429496765137}", "{\"n\": 5875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.11, \"learn_time_ms\": 9019.849, \"total_train_time_s\": 10.244447469711304}", "{\"n\": 5876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.06, \"learn_time_ms\": 9015.788, \"total_train_time_s\": 10.161133050918579}", "{\"n\": 5877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.42, \"learn_time_ms\": 9039.136, \"total_train_time_s\": 10.33468770980835}", "{\"n\": 5878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.42, \"learn_time_ms\": 9189.703, \"total_train_time_s\": 10.843165636062622}", "{\"n\": 5879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.72, \"learn_time_ms\": 9124.62, \"total_train_time_s\": 9.862431287765503}", "{\"n\": 5880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.86, \"learn_time_ms\": 8939.384, \"total_train_time_s\": 9.59525203704834}", "{\"n\": 5881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3199.03, \"learn_time_ms\": 8940.643, \"total_train_time_s\": 11.166252374649048}", "{\"n\": 5882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.47, \"learn_time_ms\": 8912.079, \"total_train_time_s\": 10.973822116851807}", "{\"n\": 5883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.68, \"learn_time_ms\": 9086.0, \"total_train_time_s\": 12.198185205459595}", "{\"n\": 5884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3204.91, \"learn_time_ms\": 9073.119, \"total_train_time_s\": 9.503197193145752}", "{\"n\": 5885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.65, \"learn_time_ms\": 9130.676, \"total_train_time_s\": 10.878127098083496}", "{\"n\": 5886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.65, \"learn_time_ms\": 9037.812, \"total_train_time_s\": 9.252870321273804}", "{\"n\": 5887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.88, \"learn_time_ms\": 9021.428, \"total_train_time_s\": 10.133734703063965}", "{\"n\": 5888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.88, \"learn_time_ms\": 9002.428, \"total_train_time_s\": 10.675174951553345}", "{\"n\": 5889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.55, \"learn_time_ms\": 9000.535, \"total_train_time_s\": 9.89219331741333}", "{\"n\": 5890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.28, \"learn_time_ms\": 9142.775, \"total_train_time_s\": 11.017893552780151}", "{\"n\": 5891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.66, \"learn_time_ms\": 9202.721, \"total_train_time_s\": 11.807290315628052}", "{\"n\": 5892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.36, \"learn_time_ms\": 8918.078, \"total_train_time_s\": 8.119202613830566}", "{\"n\": 5893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.77, \"learn_time_ms\": 8635.512, \"total_train_time_s\": 9.345659255981445}", "{\"n\": 5894, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.77, \"learn_time_ms\": 8902.098, \"total_train_time_s\": 12.15763235092163}", "{\"n\": 5895, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.33, \"learn_time_ms\": 8927.644, \"total_train_time_s\": 11.129884481430054}", "{\"n\": 5896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.15, \"learn_time_ms\": 8937.441, \"total_train_time_s\": 9.355957746505737}", "{\"n\": 5897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.0, \"learn_time_ms\": 9048.226, \"total_train_time_s\": 11.317607641220093}", "{\"n\": 5898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.0, \"learn_time_ms\": 9058.265, \"total_train_time_s\": 10.76572036743164}", "{\"n\": 5899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.69, \"learn_time_ms\": 9067.722, \"total_train_time_s\": 9.97496223449707}", "{\"n\": 5900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.55, \"learn_time_ms\": 8957.649, \"total_train_time_s\": 9.88144326210022}", "{\"n\": 5901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.55, \"learn_time_ms\": 8795.903, \"total_train_time_s\": 10.151118993759155}", "{\"n\": 5902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3199.42, \"learn_time_ms\": 9121.867, \"total_train_time_s\": 11.376621007919312}", "{\"n\": 5903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3208.46, \"learn_time_ms\": 9162.782, \"total_train_time_s\": 9.751479148864746}", "{\"n\": 5904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3215.04, \"learn_time_ms\": 8972.783, \"total_train_time_s\": 10.274146318435669}", "{\"n\": 5905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3203.4, \"learn_time_ms\": 8943.545, \"total_train_time_s\": 10.779261350631714}", "{\"n\": 5906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3211.25, \"learn_time_ms\": 8967.436, \"total_train_time_s\": 9.548108577728271}", "{\"n\": 5907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3217.22, \"learn_time_ms\": 8904.631, \"total_train_time_s\": 10.631220579147339}", "{\"n\": 5908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3222.24, \"learn_time_ms\": 8784.674, \"total_train_time_s\": 9.556428909301758}", "{\"n\": 5909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3224.41, \"learn_time_ms\": 8779.194, \"total_train_time_s\": 9.94246506690979}", "{\"n\": 5910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3228.23, \"learn_time_ms\": 8730.858, \"total_train_time_s\": 9.448447704315186}", "{\"n\": 5911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3226.66, \"learn_time_ms\": 8653.932, \"total_train_time_s\": 9.444981336593628}", "{\"n\": 5912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3228.57, \"learn_time_ms\": 8611.623, \"total_train_time_s\": 10.887225151062012}", "{\"n\": 5913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3225.48, \"learn_time_ms\": 8628.496, \"total_train_time_s\": 9.94527268409729}", "{\"n\": 5914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3219.58, \"learn_time_ms\": 8749.914, \"total_train_time_s\": 11.500202655792236}", "{\"n\": 5915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.4, \"learn_time_ms\": 8780.406, \"total_train_time_s\": 11.16237211227417}", "{\"n\": 5916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.61, \"learn_time_ms\": 8912.969, \"total_train_time_s\": 10.940444707870483}", "{\"n\": 5917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3205.26, \"learn_time_ms\": 8955.707, \"total_train_time_s\": 11.065259456634521}", "{\"n\": 5918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3202.5, \"learn_time_ms\": 9069.265, \"total_train_time_s\": 10.70384693145752}", "{\"n\": 5919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3200.34, \"learn_time_ms\": 9169.373, \"total_train_time_s\": 10.901437282562256}", "{\"n\": 5920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3201.7, \"learn_time_ms\": 9270.114, \"total_train_time_s\": 10.431266069412231}", "{\"n\": 5921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3206.71, \"learn_time_ms\": 9257.224, \"total_train_time_s\": 9.301402807235718}", "{\"n\": 5922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.3, \"learn_time_ms\": 9210.622, \"total_train_time_s\": 10.433809518814087}", "{\"n\": 5923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3204.3, \"learn_time_ms\": 9216.983, \"total_train_time_s\": 10.006868124008179}", "{\"n\": 5924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3208.94, \"learn_time_ms\": 9069.466, \"total_train_time_s\": 10.005068302154541}", "{\"n\": 5925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3207.78, \"learn_time_ms\": 8955.02, \"total_train_time_s\": 9.969128608703613}", "{\"n\": 5926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3205.75, \"learn_time_ms\": 8911.444, \"total_train_time_s\": 10.481232404708862}", "{\"n\": 5927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3205.47, \"learn_time_ms\": 8903.976, \"total_train_time_s\": 11.00708293914795}", "{\"n\": 5928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3209.99, \"learn_time_ms\": 8673.61, \"total_train_time_s\": 8.419668674468994}", "{\"n\": 5929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.77, \"learn_time_ms\": 8615.963, \"total_train_time_s\": 10.380217552185059}", "{\"n\": 5930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3210.77, \"learn_time_ms\": 8627.686, \"total_train_time_s\": 10.575639247894287}", "{\"n\": 5931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.13, \"learn_time_ms\": 8692.048, \"total_train_time_s\": 9.914300203323364}", "{\"n\": 5932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3215.93, \"learn_time_ms\": 8646.125, \"total_train_time_s\": 10.019480466842651}", "{\"n\": 5933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3215.93, \"learn_time_ms\": 8686.635, \"total_train_time_s\": 10.408387660980225}", "{\"n\": 5934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.41, \"learn_time_ms\": 8676.967, \"total_train_time_s\": 9.88448429107666}", "{\"n\": 5935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.97, \"learn_time_ms\": 8681.638, \"total_train_time_s\": 9.999831676483154}", "{\"n\": 5936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.97, \"learn_time_ms\": 8738.858, \"total_train_time_s\": 11.00382947921753}", "{\"n\": 5937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3224.82, \"learn_time_ms\": 8600.095, \"total_train_time_s\": 9.591509103775024}", "{\"n\": 5938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3224.39, \"learn_time_ms\": 8783.115, \"total_train_time_s\": 10.247516393661499}", "{\"n\": 5939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.03, \"learn_time_ms\": 8637.252, \"total_train_time_s\": 8.898983716964722}", "{\"n\": 5940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3213.15, \"learn_time_ms\": 8571.138, \"total_train_time_s\": 9.911136150360107}", "{\"n\": 5941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3214.61, \"learn_time_ms\": 8667.756, \"total_train_time_s\": 10.881632089614868}", "{\"n\": 5942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3214.8, \"learn_time_ms\": 8679.082, \"total_train_time_s\": 10.136045217514038}", "{\"n\": 5943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.05, \"learn_time_ms\": 8597.978, \"total_train_time_s\": 9.55764651298523}", "{\"n\": 5944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3216.05, \"learn_time_ms\": 8581.532, \"total_train_time_s\": 9.723481178283691}", "{\"n\": 5945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3219.92, \"learn_time_ms\": 8589.786, \"total_train_time_s\": 10.118377447128296}", "{\"n\": 5946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3218.14, \"learn_time_ms\": 8411.923, \"total_train_time_s\": 9.258148431777954}", "{\"n\": 5947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3218.14, \"learn_time_ms\": 8448.514, \"total_train_time_s\": 9.93797516822815}", "{\"n\": 5948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.89, \"learn_time_ms\": 8512.621, \"total_train_time_s\": 10.874095916748047}", "{\"n\": 5949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.46, \"learn_time_ms\": 8599.76, \"total_train_time_s\": 9.775514602661133}", "{\"n\": 5950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.09, \"learn_time_ms\": 8635.259, \"total_train_time_s\": 10.23954439163208}", "{\"n\": 5951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3231.04, \"learn_time_ms\": 8752.596, \"total_train_time_s\": 12.075394630432129}", "{\"n\": 5952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.43, \"learn_time_ms\": 8628.337, \"total_train_time_s\": 8.915650367736816}", "{\"n\": 5953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3227.04, \"learn_time_ms\": 8644.127, \"total_train_time_s\": 9.813517332077026}", "{\"n\": 5954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3223.68, \"learn_time_ms\": 8539.75, \"total_train_time_s\": 8.718341588973999}", "{\"n\": 5955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3222.67, \"learn_time_ms\": 8523.782, \"total_train_time_s\": 9.907941341400146}", "{\"n\": 5956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.75, \"learn_time_ms\": 8716.2, \"total_train_time_s\": 11.180973529815674}", "{\"n\": 5957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.75, \"learn_time_ms\": 8676.018, \"total_train_time_s\": 9.601390361785889}", "{\"n\": 5958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3234.48, \"learn_time_ms\": 8661.05, \"total_train_time_s\": 10.76832890510559}", "{\"n\": 5959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.53, \"learn_time_ms\": 8784.703, \"total_train_time_s\": 11.019713401794434}", "{\"n\": 5960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.53, \"learn_time_ms\": 8794.931, \"total_train_time_s\": 10.392573595046997}", "{\"n\": 5961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3229.53, \"learn_time_ms\": 8577.088, \"total_train_time_s\": 9.895034551620483}", "{\"n\": 5962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.19, \"learn_time_ms\": 8762.855, \"total_train_time_s\": 10.763376235961914}", "{\"n\": 5963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.19, \"learn_time_ms\": 8739.08, \"total_train_time_s\": 9.504147052764893}", "{\"n\": 5964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.19, \"learn_time_ms\": 8899.196, \"total_train_time_s\": 10.34233832359314}", "{\"n\": 5965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3242.66, \"learn_time_ms\": 8855.545, \"total_train_time_s\": 9.475170373916626}", "{\"n\": 5966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3252.75, \"learn_time_ms\": 8850.605, \"total_train_time_s\": 11.152663946151733}", "{\"n\": 5967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3252.75, \"learn_time_ms\": 9026.769, \"total_train_time_s\": 11.301037788391113}", "{\"n\": 5968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3243.06, \"learn_time_ms\": 8994.257, \"total_train_time_s\": 10.381356239318848}", "{\"n\": 5969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3246.26, \"learn_time_ms\": 9004.803, \"total_train_time_s\": 11.096577644348145}", "{\"n\": 5970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3246.26, \"learn_time_ms\": 8922.121, \"total_train_time_s\": 9.488595008850098}", "{\"n\": 5971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3238.78, \"learn_time_ms\": 9027.093, \"total_train_time_s\": 10.928193092346191}", "{\"n\": 5972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3236.73, \"learn_time_ms\": 9107.756, \"total_train_time_s\": 11.541815042495728}", "{\"n\": 5973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3235.4, \"learn_time_ms\": 9057.556, \"total_train_time_s\": 8.984046936035156}", "{\"n\": 5974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3239.21, \"learn_time_ms\": 9012.685, \"total_train_time_s\": 9.810004472732544}", "{\"n\": 5975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3248.95, \"learn_time_ms\": 8983.362, \"total_train_time_s\": 9.182124853134155}", "{\"n\": 5976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3248.95, \"learn_time_ms\": 8904.346, \"total_train_time_s\": 10.367116451263428}", "{\"n\": 5977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3248.95, \"learn_time_ms\": 8864.943, \"total_train_time_s\": 10.94193410873413}", "{\"n\": 5978, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3258.18, \"learn_time_ms\": 8876.094, \"total_train_time_s\": 10.52064561843872}", "{\"n\": 5979, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3253.1, \"learn_time_ms\": 8859.923, \"total_train_time_s\": 10.968987941741943}", "{\"n\": 5980, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3253.1, \"learn_time_ms\": 9091.123, \"total_train_time_s\": 11.796842813491821}", "{\"n\": 5981, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3253.01, \"learn_time_ms\": 9056.918, \"total_train_time_s\": 10.569340229034424}", "{\"n\": 5982, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3251.88, \"learn_time_ms\": 8861.294, \"total_train_time_s\": 9.59208059310913}", "{\"n\": 5983, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3251.88, \"learn_time_ms\": 8973.686, \"total_train_time_s\": 10.146782875061035}", "{\"n\": 5984, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3251.88, \"learn_time_ms\": 8980.775, \"total_train_time_s\": 9.928610563278198}", "{\"n\": 5985, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3251.68, \"learn_time_ms\": 9133.789, \"total_train_time_s\": 10.768113374710083}", "{\"n\": 5986, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.55, \"learn_time_ms\": 9077.249, \"total_train_time_s\": 9.815030813217163}", "{\"n\": 5987, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.55, \"learn_time_ms\": 9005.927, \"total_train_time_s\": 10.239063262939453}", "{\"n\": 5988, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3249.0, \"learn_time_ms\": 8860.254, \"total_train_time_s\": 9.034414291381836}", "{\"n\": 5989, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3250.86, \"learn_time_ms\": 8781.139, \"total_train_time_s\": 10.143097162246704}", "{\"n\": 5990, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3250.86, \"learn_time_ms\": 8515.218, \"total_train_time_s\": 9.159923315048218}", "{\"n\": 5991, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3257.67, \"learn_time_ms\": 8330.494, \"total_train_time_s\": 8.773165225982666}", "{\"n\": 5992, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3256.43, \"learn_time_ms\": 8410.087, \"total_train_time_s\": 10.33091139793396}", "{\"n\": 5993, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3258.8, \"learn_time_ms\": 8318.104, \"total_train_time_s\": 9.167383432388306}", "{\"n\": 5994, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3255.47, \"learn_time_ms\": 8289.827, \"total_train_time_s\": 9.622146129608154}", "{\"n\": 5995, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3260.65, \"learn_time_ms\": 8195.009, \"total_train_time_s\": 9.80118465423584}", "{\"n\": 5996, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3262.33, \"learn_time_ms\": 8075.898, \"total_train_time_s\": 8.612499952316284}", "{\"n\": 5997, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3265.83, \"learn_time_ms\": 8061.53, \"total_train_time_s\": 10.078896760940552}", "{\"n\": 5998, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3277.04, \"learn_time_ms\": 8163.419, \"total_train_time_s\": 10.070780038833618}", "{\"n\": 5999, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.85, \"learn_time_ms\": 8188.361, \"total_train_time_s\": 10.390213251113892}", "{\"n\": 6000, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.85, \"learn_time_ms\": 8286.144, \"total_train_time_s\": 10.144548416137695}"]